contentType,identifier,title,publicationName,doi,publisher,publicationDate,onlineDate,abstract,url,database
Chapter ConferencePaper,doi:10.1007/978-3-030-84760-9_55,Traffic Sign Detection and Recognition for Hazy Images: ADAS,Second International Conference on Image Processing and Capsule Networks,10.1007/978-3-030-84760-9_55,Springer,2022-01-01,2021-09-10,"Self driving cars are picking up pace and thus serves as a challenging research domain. One of the most crucial functions in an autonomous vehicle is accurately detecting and recognising the traffic signs. Traffic sign detection is a crucial task in traffic sign recognition systems. Deep neural networks are proven powerful in traffic sign classification. As traffic sign violation leads to law and order disruption, posing a threat to human life, there is a need for robust algorithms with efficient actuation to perform the delegated task. Thus, this paper proposes a robust algorithm which addresses challenges like haze, fog, unclear images due to improper condition of roads to efficiently detect and recognize traffic signs using Image manipulation, Optical Character Recognition (OCR) algorithm and You Only Look Once (YOLOv3) detection algorithm. The proposed algorithm in this paper for hazy images that aids in ADAS applications has an accuracy of 87.29%. This contributes to the emerging research domains of autonomous vehicles and self-driving cars.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-84760-9_55,springer
Chapter ConferencePaper,doi:10.1007/978-981-33-4597-3_80,Rain Classification for Autonomous Vehicle Navigation Using Machine Learning,Recent Trends in Mechatronics Towards Industry 4.0,10.1007/978-981-33-4597-3_80,Springer,2022-01-01,2021-07-16,"Autonomous vehicles (AV) has gained popularity in research and development in many countries due to the advancement of sensor technology that is used in the AV system. Despite that, sensing and perceiving in harsh weather conditions has been an issue in this modern sensor technology as it needs the ability to adapt to human behaviour in various situations. This paper aims to classify clear and rainy weather using a physical-based simulator to imitate the real-world environment which consists of roads, vehicles, and buildings. The real-world environment was constructed in a physical-based simulator to publish the data logging and testing using the ROS network. Point cloud data generated from LiDAR with a different frame of different weather are to be coupled with three machine learning models namely Naïve Bayes (NB), Random Forest (RF), and k-Nearest Neighbour (kNN) as classifiers. The preliminary analysis demonstrated that with the proposed methodology, the RF machine learning model attained a test classification accuracy (CA) of 99.9% on the test dataset, followed by kNN with a test CA of 99.4% and NB at 92.4%. Therefore, the proposed strategy has the potential to classify clear and rainy weather that provides objective-based judgement.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-4597-3_80,springer
Chapter ConferencePaper,doi:10.1007/978-981-16-2937-2_14,Enhanced Behavioral Cloning-Based Self-driving Car Using Transfer Learning,"Data Management, Analytics and Innovation",10.1007/978-981-16-2937-2_14,Springer,2022-01-01,2021-09-20,"Sumanth, Uppala Punn, Narinder Singh Sonbhadra, Sanjay Kumar Agarwal, Sonali With the growing phase of artificial intelligence and autonomous learning, the self-driving car is one of the promising areas of research and emerging as a center of focus for automobile industries. Behavioral cloning is the process of replicating human behavior via visuomotor policies by means of machine learning algorithms. In recent years, several deep learning-based behavioral cloning approaches have been developed in the context of self-driving cars specifically based on the concept of transfer learning. Concerning the same, the present paper proposes a transfer learning approach using VGG16 architecture, which is fine-tuned by retraining the last block while keeping other blocks as non-trainable. The performance of proposed architecture is further compared with existing NVIDIA’s architecture and its pruned variants (pruned by 22.2 and 33.85% using $$1\times 1$$ 1 × 1 filter to decrease the total number of parameters). Experimental results show that the VGG16 with transfer learning architecture has outperformed other discussed approaches with faster convergence.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-2937-2_14,springer
Chapter,doi:10.1007/978-3-030-79766-9_1,Security Challenges in 5G and IoT Networks: A Review,Secure Communication for 5G and IoT Networks,10.1007/978-3-030-79766-9_1,Springer,2022-01-01,2021-10-29,"5G networks are poised to satisfy the anticipated growth in Internet of Technology (IoT) devices and their related systems. The invasion of 5G networks brings along with it an accelerated need for security and privacy. The need for tailor-made security solutions has become the need of the hour to ensure data integrity, confidentiality, and authentication in 5G-based IoT networks. Since IoT initiates sensors and actuators in a totally smart environment, IoT security will involve protecting the total deployment architecture of IoT from internal and external attacks. Integration of cryptographical algorithms and quantum cryptography has been used effectively to secure data in 5G networks. Privacy and identity management has been a mandatory requirement in networks carrying delicate data involved in retail shops, traffic services, and health monitoring systems. Securing data in 5G and IoT networks and detection of trustworthy and rogue nodes, proper monitoring, logging, and broadcasting are the vital necessities of any security system. The exhaustive survey on the security issues in the 5G-IoT scenario, highlights the application of the latest technologies, incorporation of hybrid methodologies in securing them, and also emphasizes on the open issues yet to be addressed and research challenges that are to be explored.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-79766-9_1,springer
Chapter ConferencePaper,doi:10.1007/978-981-16-4016-2_65,The Mythical or Realistic Implementation of AI-powered Driverless Cars in Africa: A Review of Challenges and Risks,Smart Trends in Computing and Communications,10.1007/978-981-16-4016-2_65,Springer,2022-01-01,2021-10-26,"In recent times, African nations have been mostly absent in discussions concerning artificial intelligence (AI)-powered driverless cars. Additionally, it was also discovered that several global surveys and other studies on driverless car acceptance, popularity and confidence excluded Africa. This is in the light of its immense benefits which include the reduction of road accidents, an effectual car-sharing and transport structure and accurate navigation with less consideration of distractions. Therefore, we examined the challenges and risks attendant to the deployment of self-driving cars in a developing region such as Africa. Several challenges were identified, and they include lack of needed infrastructure, absence of law and order, cost, absence of image detection and recognition projects, absence of practical artificial intelligence courseware, need for an advanced AI-based algorithm, weak legal framework and other ethical issues, criminalization, security and privacy and high tendency to cause more unemployment. The paper highlights several risks attendant to such forms of advancement in Africa.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-4016-2_65,springer
Chapter ConferencePaper,doi:10.1007/978-981-16-1866-6_8,Advancing e-Government Using Internet of Things,Mobile Computing and Sustainable Informatics,10.1007/978-981-16-1866-6_8,Springer,2022-01-01,2021-07-23,"Internet of Things (IoT) is the most revolutionary and attractive technology of today without which it is nearly impossible to imagine the future due to its applications in numerous fields such as smart cities, home automation, wearable devices, etc., and its ability to make human life much easier via integration with other technologies such as cloud computing and artificial intelligence. In this paper, we have conducted a survey on the ways IoT can be utilized in various sectors of an e-Government such as pollution control, health care and voting. We have also described a six-layer IoT-based model for smart agriculture and studied the benefits of using unmanned aerial vehicles in smart agriculture. This paper further introduces the concept of a “smart” government and its realization via integration of fog computing with IoT leading to a Fog-of-Things (FoT) architecture.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-1866-6_8,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-85540-6_1,"Human and Machine Trust Considerations, Concerns and Constraints for Lethal Autonomous Weapon Systems (LAWS)","Human Interaction, Emerging Technologies and Future Systems V",10.1007/978-3-030-85540-6_1,Springer,2022-01-01,2021-09-10,"Trust and autonomous systems, especially weapon systems, could be the most difficult technological challenge facing defense industries, militaries, politicians, and the public because the algorithms have to be trusted. Furthermore, the operator, the military, defense industry, politicians and the public need to trust the system to also follow ethical and legal rules. This paper briefly describes the trust considerations, concerns and constraints regarding autonomous weapons systems and concludes with a brief description of the current development programs and projects by the various US military services.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-85540-6_1,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-87178-9_5,Neural Network Adaptation of the Kalman Filter for Odometry Fusion,Proceedings of the Fifth International Scientific Conference “Intelligent Information Technologies for Industry” (IITI’21),10.1007/978-3-030-87178-9_5,Springer,2022-01-01,2021-09-16,"In navigation systems for unmanned vehicles, an important task is fusion of the pose estimations (odometry and localization) obtained from different sensors: cameras, LiDARs, wheel encoders, inertial measurement modules, etc. To solve this task, it is necessary to know the covariance matrices for each of the odometry sources, which characterize the prediction accuracy of the corresponding pose. In this paper we propose a neural network adaptation of noise covariances in Kalman filter for odometry fusion task. Instead of specifying process and measurement noise covariances manually, we use optimization technique and neural network on input time series data to automatically predict values of these covariance matrices. Our approach fuses the vehicle 3D position and orientation obtained using visual and LiDAR-based methods for simultaneously localization and mapping. The experiments were conducted on a dataset from unmanned ground robot Clearpath Husky. Comparing to Kalman filter without adaptation, our method is more precise. We made a software implementation of the proposed approach based on PyTorch deep learning framework.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-87178-9_5,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-87178-9_58,Analysis of the Possibility of Intellectualization of Algorithms for Estimating the Parameters of Dynamic Systems Based on Adaptive Model of Motion,Proceedings of the Fifth International Scientific Conference “Intelligent Information Technologies for Industry” (IITI’21),10.1007/978-3-030-87178-9_58,Springer,2022-01-01,2021-09-16,"Existing onboard systems for processing measurement information do not always provide the necessary accuracy in estimating the parameters of movement of unmanned aerial vehicles. These errors are due to the use of kinematic motion models based on filtering algorithms, which does not allow to take into account the action of external forces on the control object. The possibility of intellectualizing the adaptive algorithms for estimating the parameters of dynamic systems is considered. The proposed adaptive motion model with an intelligent system to determine the adaptation parameter as a part of the angular position estimation filter makes it possible to increase the estimation accuracy in comparison with the classical Kalman filter. The effectiveness of the proposed approach is confirmed by the comparative analysis of the results of numerical modeling of the process of estimation of the roll angle of the unmanned aerial vehicle model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-87178-9_58,springer
Chapter ConferencePaper,doi:10.1007/978-981-16-2406-3_70,Autonomous Lane Navigation: Using Hand-Coded Method and Deep Learning Method,Proceedings of the 12th National Technical Seminar on Unmanned System Technology 2020,10.1007/978-981-16-2406-3_70,Springer,2022-01-01,2021-09-25,"Autonomous vehicle is known as a vehicle that requires no or little human decision while in motion because it’s capable of sensing its environment, it has been a continuous field of research and falls under autonomous navigation system (ANS). Autonomous navigation depicts that a vehicle is capable to plot its path and achieve its plan without human interference remote navigation aids are used in the planning process. In this project, the navigation aid is a front-facing camera mounted and images from the camera are used to compute steering commands. This work made use of two methods which are the handcrafted method for lane navigation and the end to end learning scheme developed by Nvidia cooperation to train a model to compute steering command from a front-facing camera. The deep learning model is compared with the handcraft method of computing steering angle. The difference between these two methods is presented in this work as the navigation of a modelled car which navigates through the designed lanes using both methods, the accuracy of the car following the lanes is used to determine the better method for lane navigation. Which turns out to be the end to end learning method for lane navigation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-2406-3_70,springer
Chapter ConferencePaper,doi:10.1007/978-981-16-1866-6_42,Obstacle Avoidance and Ranging Using LIDAR,Mobile Computing and Sustainable Informatics,10.1007/978-981-16-1866-6_42,Springer,2022-01-01,2021-07-23,"For many years, engineers are searching solutions for car accidents that are caused by human error due to drowsiness or by a person who comes out of nowhere in front of the vehicle. In such a situation, vehicle accident may occur. So, there is a need to develop a vehicle that saves human life from a dangerous accident. Autonomous vehicle have emerged with cameras and sensors to avoid the strategic accidents of human error. Autonomous vehicle systems get information about other vehicles, pedestrians, and other immediate surroundings that is necessary to detect the presence of pedestrians, vehicles and other related entity objects. In this paper, novel LIDAR technologies for automotive applications and the perception algorithms based on field of view (FOV) are used for obstacle avoidance, and ranging of object or vehicle nearby to avoid collision of data in crucial conditions is discussed. This paper is structured based on a vehicle detection and processing of 2D LIDAR sensor to avoid traffic accidents and save life of the people with the help of deep learning algorithm concept. The LIDAR serves as image sensor, and the output response is a steering response, based on the image decisions taken either stop or turn the vehicle depending on the object in front of the vehicle based on road boundary detection.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-1866-6_42,springer
Chapter ConferencePaper,doi:10.1007/978-981-16-3880-0_20,Machine Learning-Based Imaging in Connected Vehicles Environment,Proceedings of 2021 International Conference on Medical Imaging and Computer-Aided Diagnosis (MICAD 2021),10.1007/978-981-16-3880-0_20,Springer,2022-01-01,2021-08-15,"Intelligent algorithms greatly influence imaging. Machine learning techniques find applicability in correcting and highlighting medical images generated by X-rays, Computed Tomography (CT) scan, Positron Emission Tomography (PET) scan, Magnetic Resonance Imaging (MRI). Such techniques increase the reliability and quality of diagnosis to aid the doctors in devising an effective treatment. These systems have found wide applicability under clinical settings. Imaging is also an essential task in autonomous vehicle development and Connected Vehicles. Research on Connected Vehicles is evolving at a staggering rate with an objective to reduce road accidents significantly and replace drivers with fully autonomous self-driving vehicles. Driver monitoring system (DMS) is a new area of research where drivers are monitored using cameras and other medical sensor networks to detect the drivers’ medical state, mental state as well as cognitive state. Objective biomarkers allow such systems to predict these states. Imaging plays an essential role in the diagnosis aided by the state of the art machine learning algorithms. This paper addresses the challenges posed by imaging under driving environments for diagnosis of medical and cognition of drivers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-3880-0_20,springer
Chapter ConferencePaper,doi:10.1007/978-981-16-3368-3_27,Autonomous Ground Vehicle for Off-the-Road Applications Based on Neural Network,Proceedings of International Conference on Computational Intelligence and Computing,10.1007/978-981-16-3368-3_27,Springer,2022-01-01,2021-07-29,"The technology for autonomy in vehicles has a momentous advancement. Autonomous ground vehicles (AGV) for off-the-road applications will aid various sectors of the society such as mining, constructions, forest path maneuvering, and defense. This project demonstrates a working prototype of a 1/10th scale autonomous car that has been developed using a custom neural network model. The prototype uses Raspberry pi-4 as the core processor to compute real-time images collected from the camera as the key input. The results illustrate the optimized capability of path planning for the AGV using the custom convolutional neural network model with data augmentation. This paper summarizes the results derived and compares the accuracy of the steering in AGV which can be translated for off-road applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-3368-3_27,springer
Chapter ConferencePaper,doi:10.1007/978-981-16-4016-2_38,Analysing and Identifying Harm Propagation of Cyber Threats in Autonomous Vehicles and Mitigation Through ANN,Smart Trends in Computing and Communications,10.1007/978-981-16-4016-2_38,Springer,2022-01-01,2021-10-26,"Connected and autonomous vehicle industry is fostering advancements in technologies such as artificial intelligence, machine learning, Internet of Things and Big data applications. Connected and autonomous vehicles rely on a variety of electronics, sensors and computer systems. They require strong cyber security mitigations to ensure that these systems work reliable and to reduce security risks. While the possibilities for integrating devices and vehicles seem endless, new threats and dangers arise every day. Due to their connectivity, there are also security risks to the networks they are connected to, such as road network sensors, electrical infrastructure or vehicle control features and so on. Systems should be created in order to reduce all the possible threats and vulnerabilities. In the study, we will analyse the various cyber security vulnerabilities and threats which are possible in autonomous vehicles by constructing graph from observing harm propagation of the cyber threats and propose a mitigation model for the same.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-4016-2_38,springer
Article,doi:10.1007/s13198-021-01127-6,Deep learning using computer vision in self driving cars for lane and traffic sign detection,International Journal of System Assurance Engineering and Management,10.1007/s13198-021-01127-6,Springer,2021-12-01,2021-05-14,"Recently, the amount of research in the field of self-driving cars has grown significantly with autonomous vehicles having clocked in more than 10 million miles, providing a substantial amount of data for use in training and testing. The most complex part of training is the use of computer vision for feature extraction and object detection in real-time. Much relevant research has been done on improving the algorithms in the area of image segmentation. The proposed idea presents the use of Convoluted Neural Networks using Spatial Transformer Networks and lane detection in real time to increase the efficiency of autonomous vehicles. The depth of the neural network will help in training vehicles and during the testing phase, the vehicles will learn to make decisions based on the training data. In case of sudden changes to the environment, the vehicle will be able to make decisions quickly to prevent damage or danger to lives. Along with lane detection, a self-driving car must also be able to detect traffic signs. The proposed approach uses the Adam Optimizer which runs on top of the LeNet-5 architecture. The LeNet-5 architecture is analyzed and compared with the Feed Forward Neural Network approach. The accuracy of the LeNet-5 architecture was found to be 97% while the accuracy of the Feed Forward Neural Network was 94%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13198-021-01127-6,springer
Article,doi:10.1007/s12596-021-00770-3,UAV detection in airborne optic videos using dilated convolutions,Journal of Optics,10.1007/s12596-021-00770-3,Springer,2021-12-01,2021-09-17,"In this paper, a real-time unmanned aerial vehicles (UAVs) detection framework is proposed for GPU embedded applications. To achieve this, this paper proposed a new modified model based on You Only Look Once (YOLO) to detect multi-UAV in aerial images with a complex background. The proposed CNN architecture uses five inception module and dilated convolution with two different factors to increase detection accuracy of YOLOv3 tiny, while preserving its computational time. To further improve the detection accuracy, Generalized Intersection over Union loss is replaced with the bounding box regression loss in the original YOLOv3 tiny loss function. To obtain higher frame rate, scalable kernel correlation filter (sKCF) algorithm is integrated to the detection model. More specifically, the proposed UAV detection method is used to initialize the sKCF tracker at every $$n\mathrm{th}$$ n th frame. Thus, the detected UAVs can be detected in intermediate frames with a low memory footprint. The proposed model and compared models are trained and tested on a variety of training and test airborne videos, captured under different outdoor scenarios. The average precision of the proposed model is 0.8265 and achieves 32 FPS performance on Jetson-TX2. The results show that the proposed model which is widened with inception module using  dilated convolutions has a very high performance in terms of accuracy and speed even when it is compared with deep CNN architectures such as Darknet 53.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12596-021-00770-3,springer
Article,doi:10.1007/s10586-021-03434-w,Intelligent ubiquitous computing for future UAV-enabled MEC network systems,Cluster Computing,10.1007/s10586-021-03434-w,Springer,2021-11-02,2021-11-02,"In this paper, we investigate intelligent ubiquitous computing for future unmanned aerial vehicle (UAV)-enabled mobile edge computing network (MEC) systems, where multiple users process some computational tasks with the help of one computational access point (CAP), under the jamming from a UAV attack. Taking into account that the system may operate in a dynamic varying scenario, we optimize the system performance by using the reinforcement learning and transfer learning algorithms in order to reduce the latency and energy consumption. Specifically, we firstly use the reinforcement learning to devise the offloading strategy that meets the latency and energy consumption constraints as well as to alleviate the effect caused by jamming attack. We then propose to use the transfer learning to speed up the training process and improve the performance of reinforcement learning. Simulation results are provided to reveal that the proposed offloading strategy can outperform the conventional ones, and using transfer learning can achieve a better system performance while reducing the training time significantly.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10586-021-03434-w,springer
Article,doi:10.1007/s10846-021-01481-4,Multi-Sound-Source Localization Using Machine Learning for Small Autonomous Unmanned Vehicles with a Self-Rotating Bi-Microphone Array,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01481-4,Springer,2021-10-27,2021-10-27,"While vision-based localization techniques have been widely studied for small autonomous unmanned vehicles (SAUVs), sound-source localization capabilities have not been fully enabled for SAUVs. This paper presents two novel approaches for SAUVs to perform three-dimensional (3D) multi-sound-sources localization (MSSL) using only the inter-channel time difference (ICTD) signal generated by a self-rotating bi-microphone array. The proposed two approaches are based on two machine learning techniques viz., Density-Based Spatial Clustering of Applications with Noise (DBSCAN) and Random Sample Consensus (RANSAC) algorithms, respectively, whose performances were tested and compared in both simulations and experiments. The results show that both approaches are capable of correctly identifying the number of sound sources along with their 3D orientations in a reverberant environment.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-021-01481-4,springer
Article,doi:10.1007/s11276-021-02789-7,Energy-efficient UAV-enabled computation offloading for industrial internet of things: a deep reinforcement learning approach,Wireless Networks,10.1007/s11276-021-02789-7,Springer,2021-10-12,2021-10-12,"Industrial Internet of Things (IIoT) has been envisioned as a killer application of 5G and beyond. However, due to the shortness of computation ablility and batery capacity, it is challenging for IIoT devices to process latency-sensitive and resource-sensitive tasks. Moblie Edge Computing (MEC), as a promising paradigm for handling tasks with high quality of service (QoS) requirement and for energy-constrained IIoT devices, allows IIoT devices to offload their tasks to MEC servers, which can significantly reduce the task process delay and energy consumptions. However, the deployment of the MEC servers rely heavily on communication infrastructure, which greatly reduce the flexibility. Toward this end, in this paper, we consider multiple Unmanned Aerial Vehicles (UAV) eqqipped with transceivers as aerial MEC servers to provide IIoT devices computation offloading opportunities due to their high controbility. IIoT devices can choose to offload the tasks to UAVs through air-ground links, or to offload the tasks to the remote cloud center through ground cellular network, or to process the tasks locally. We formulate the multi-UAV-Enabled computation offloading problem as a mixed integer non-linear programming (MINLP) problem and prove its NP-hardness. To obtain the energy-efficient and low complexity solution, we propose an intelligent computation offloading algorithm called multi-agent deep Q-learning with stochastic prioritized replay (MDSPR). Numerical results show that the proposed MDSPR converges fast and outperforms the benchmark algorithms, including random method, deep Q-learning method and double deep Q-learning method in terms of energy efficiency and task successful rate.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11276-021-02789-7,springer
Article,doi:10.1007/s11676-020-01245-0,Tree species classification using deep learning and RGB optical images obtained by an unmanned aerial vehicle,Journal of Forestry Research,10.1007/s11676-020-01245-0,Springer,2021-10-01,2020-11-05,"The diversity of tree species and the complexity of land use in cities create challenging issues for tree species classification. The combination of deep learning methods and RGB optical images obtained by unmanned aerial vehicles (UAVs) provides a new research direction for urban tree species classification. We proposed an RGB optical image dataset with 10 urban tree species, termed TCC10, which is a benchmark for tree canopy classification (TCC). TCC10 dataset contains two types of data: tree canopy images with simple backgrounds and those with complex backgrounds. The objective was to examine the possibility of using deep learning methods (AlexNet, VGG-16, and ResNet-50) for individual tree species classification. The results of convolutional neural networks (CNNs) were compared with those of K-nearest neighbor (KNN) and BP neural network. Our results demonstrated: (1) ResNet-50 achieved an overall accuracy (OA) of 92.6% and a kappa coefficient of 0.91 for tree species classification on TCC10 and outperformed AlexNet and VGG-16. (2) The classification accuracy of KNN and BP neural network was less than 70%, while the accuracy of CNNs was relatively higher. (3) The classification accuracy of tree canopy images with complex backgrounds was lower than that for images with simple backgrounds. For the deciduous tree species in TCC10, the classification accuracy of ResNet-50 was higher in summer than that in autumn. Therefore, the deep learning is effective for urban tree species classification using RGB optical images.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11676-020-01245-0,springer
Article,doi:10.1007/s13369-021-05522-w,Power Transmission Line Fault Detection and Diagnosis Based on Artificial Intelligence Approach and its Development in UAV: A Review,Arabian Journal for Science and Engineering,10.1007/s13369-021-05522-w,Springer,2021-10-01,2021-04-22,"This paper provides a systematic, comprehensive, up-to-date study of the various artificial intelligence (AI) techniques on the detection and classification of faults on power transmission line. We review the latest start of the art of various intelligent approaches and even discuss the differences and outcomes of implementing intelligent methods in the protection scheme and the integrated protection scheme. Besides, there has been an increase in demand and interest for the application of AI approaches in drone to aid in detection and classification of faults. However, there are not many surveys pertaining to the development of the unmanned aerial vehicle (UAV) for the application of intelligent methods in this field. Thus, we also include in this paper the literature relevant to the implementation of various intelligent approaches in the unmanned aerial vehicle (UAV) for the fault detection and classification on power transmission line. Finally, we discuss the challenges and limitations faced in the implementation and propose ways to bridge the gap in the field for further research. This comprehensive study can act as a platform for new researchers to assess the possible different intelligent methods in detecting and classifying faults on power transmission line with a set of references that were dedicated to the attentive contributions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13369-021-05522-w,springer
Article,doi:10.1007/s11063-021-10544-4,A Neural Network Based System for Efficient Semantic Segmentation of Radar Point Clouds,Neural Processing Letters,10.1007/s11063-021-10544-4,Springer,2021-10-01,2021-05-29,"The last decade has witnessed important advancements in the field of computer vision and scene understanding, enabling applications such us autonomous vehicles. Radar is a commonly adopted sensor in automotive industry, but its suitability to machine learning techniques still remains an open question. In this work, we propose a neural network (NN) based solution to efficiently process radar data. We introduce RadarPCNN, an architecture specifically designed for performing semantic segmentation on radar point clouds. It uses PointNet $$++$$ + + as a building-block—enhancing the sampling stage with mean-shift—and an attention mechanism to fuse information. Additionally, we propose a machine learning radar pre-processing module that confers the network the ability to learn from radar features. We show that our solutions are effective, yielding superior performance than the state-of-the-art.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11063-021-10544-4,springer
Article,doi:10.1007/s00521-021-06523-4,Extraction of landslide features in UAV remote sensing images based on machine vision and image enhancement technology,Neural Computing and Applications,10.1007/s00521-021-06523-4,Springer,2021-09-22,2021-09-22,"To improve the effect of landslide feature extraction, this paper improves the remote sensing image recognition algorithm with the support of a machine learning algorithm. Moreover, this paper combines UAV remote sensing images to extract landslide features, classifies and introduces the evaluation criteria for target detection and several representative target detectors. This paper also constructs the functional structure of the system according to the landslide feature extraction requirements and designs a set of optimization schemes for landslide feature data collection and control measurement suitable for field operations. In addition, this paper analyses the system kernel algorithm process and analyses the system function realization through simulation research. Finally, this paper designs an experiment to evaluate the practicability of the system constructed in this paper. From the results of experimental statistics, we can see that the system constructed in this paper has good practicability.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-021-06523-4,springer
Article,doi:10.1007/s10846-021-01489-w,End-to-End Probabilistic Depth Perception and 3D Obstacle Avoidance using POMDP,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01489-w,Springer,2021-09-17,2021-09-17,"In most real world applications, noisy and incomplete information about the robot proximity is inevitable due to imperfections coupled with the onboard sensors. The perception and control problems go hand in hand in order to efficiently plan safe robot maneuvers. This paper proposes a method to generate robot actions directly from a sequence of depth images. The notion of Artificial Potential Field (APF) approach is used where a robot action is obtained by combining the attractive and repulsive actions generated by the goal and the obstacles respectively. This article assumes environment perception uncertainty that relates to the estimation of an obstacle’s location relative to the robot. The repulsive action generation is formulated as a Partially Observable Markov Decision Process (POMDP). A Particle Filter (PF) approach is used to estimate and track valid scene points in the robot sensing horizon from an imperfect depth image stream. The most probable candidates for an occupied region are used to generate a velocity action that minimizes the repulsive potential at each time instant. Approximately optimal solutions to the POMDP are obtained using the QMDP technique which enables us to perform computationally expensive operations prior to a robot run. Consequently, suitable repulsive actions are generated onboard the robot, each time an image is received, in a computationally feasible way. An attractive action, obtained by solving for the negative gradient of the attractive potential is finally added to the repulsive action to generate a final robot action at every time step. Lastly, the robustness and reliability of this approach is demonstrated close-loop on a quadrotor UAV equipped with a depth camera. The experiments also demonstrate that the method is very computationally efficient and can be run on a variety of platforms that have limited resources on-board.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-021-01489-w,springer
Article,doi:10.1186/s13007-021-00796-5,Improving the estimation of alpine grassland fractional vegetation cover using optimized algorithms and multi-dimensional features,Plant Methods,10.1186/s13007-021-00796-5,BioMed Central,2021-09-17,2021-09-17,"Background Fractional vegetation cover (FVC) is an important basic parameter for the quantitative monitoring of the alpine grassland ecosystem on the Qinghai-Tibetan Plateau. Based on unmanned aerial vehicle (UAV) acquisition of measured data and matching it with satellite remote sensing images at the pixel scale, the proper selection of driving data and inversion algorithms can be determined and is crucial for generating high-precision alpine grassland FVC products. Methods This study presents estimations of alpine grassland FVC using optimized algorithms and multi-dimensional features. The multi-dimensional feature set (using original spectral bands, 22 vegetation indices, and topographical factors) was constructed from many sources of information, then the optimal feature subset was determined based on different feature selection algorithms as the driving data for optimized machine learning algorithms. Finally, the inversion accuracy, sensitivity to sample size, and computational efficiency of the four machine learning algorithms were evaluated. Results (1) The random forest (RF) algorithm (R^2: 0.861, RMSE: 9.5%) performed the best for FVC inversion among the four machine learning algorithms driven by the four typical vegetation indices. (2) Compared with the four typical vegetation indices, using multi-dimensional feature sets as driving data obviously improved the FVC inversion accuracy of the four machine learning algorithms (R^2 of the RF algorithm increased to 0.890). (3) Among the three variable selection algorithms (Boruta, sequential forward selection [SFS], and permutation importance-recursive feature elimination [PI-RFE]), the constructed PI-RFE feature selection algorithm had the best dimensionality reduction effect on the multi-dimensional feature set. (4) The hyper-parameter optimization of the machine learning algorithms and feature selection of the multi-dimensional feature set further improved FVC inversion accuracy (R^2: 0.917 and RMSE: 7.9% in the optimized RF algorithm). Conclusion This study provides a highly precise, optimized algorithm with an optimal multi-dimensional feature set for FVC inversion, which is vital for the quantitative monitoring of the ecological environment of alpine grassland.",https://www.biomedcentral.com/openurl?doi=10.1186/s13007-021-00796-5,springer
Article,doi:10.1007/s43681-021-00091-y,Coarse ethics: how to ethically assess explainable artificial intelligence,AI and Ethics,10.1007/s43681-021-00091-y,Springer,2021-09-12,2021-09-12,"The integration of artificial intelligence (AI) into human society mandates that their decision-making process is explicable to users, as exemplified in Asimov’s Three Laws of Robotics. Such human interpretability calls for explainable AI (XAI), of which this paper cites various models. However, the transaction between computable accuracy and human interpretability can be a trade-off, requiring answers to questions about the negotiable conditions and the degrees of AI prediction accuracy that may be sacrificed to enable user-interpretability. The extant research has focussed on technical issues, but it is also desirable to apply a branch of ethics to deal with the trade-off problem. This scholarly domain is labelled coarse ethics in this study, which discusses two issues vis-à-vis AI prediction as a type of evaluation. First, which formal conditions would allow trade-offs? The study posits two minimal requisites: adequately high coverage and order-preservation. The second issue concerns conditions that could justify the trade-off between computable accuracy and human interpretability, to which the study suggests two justification methods: impracticability and adjustment of perspective from machine-computable to human-interpretable. This study contributes by connecting ethics to autonomous systems for future regulation by formally assessing the adequacy of AI rationales.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43681-021-00091-y,springer
Article,doi:10.1007/s00146-021-01277-y,"Morals, ethics, and the technology capabilities and limitations of automated and self-driving vehicles",AI & SOCIETY,10.1007/s00146-021-01277-y,Springer,2021-09-10,2021-09-10,"We motivate the desire for self-driving and explain its potential and limitations, and explore the need for—and potential implementation of—morals, ethics, and other value systems as complementary “capabilities” to the Deep Technologies behind self-driving. We consider how the incorporation of such systems may drive or slow adoption of high automation within vehicles. First, we explore the role for morals, ethics, and other value systems in self-driving through a representative hypothetical dilemma faced by a self-driving car. Through the lens of engineering, we explain in simple terms common moral and ethical frameworks including utilitarianism, deontology, and virtue ethics before characterizing their relationship to the fundamental algorithms enabling self-driving. The concepts of behavior cloning, state-based modeling, and reinforcement learning are introduced, with some algorithms being more suitable for the implementation of value systems than others. We touch upon the contemporary cross-disciplinary landscape of morals and ethics in self-driving systems from a joint philosophical and technical perspective, and close with considerations for practitioners and the public, particularly as individuals may not appreciate the nuance and complexity of using imperfect information to navigate diverse scenarios and tough-to-quantify value systems, while “typical” software development reduces complex problems to black and white decision-making.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-021-01277-y,springer
Article,doi:10.1007/s43681-021-00088-7,God does not play dice but self-driving cars should,AI and Ethics,10.1007/s43681-021-00088-7,Springer,2021-09-08,2021-09-08,"Advances and improvements in computing power and processing have led to a clear upward progression in the degree to which autonomous vehicles can operate freely without human involvement. Advances in autonomous vehicle technology may reduce the incidence of vehicle accidents born from human error and would be a general benefit if widely used and properly regulated. However, with increases in machine agency comes the corresponding challenge of machine ethics that must keep pace with the increasing number of decisions autonomous cars need to make. In this paper, I explore and advance a view on how autonomous vehicles ought to respond in a particular tragic choice scenario under a specific set of constraints where any one person needs to die for the sake of many more. I argue that in such cases autonomous vehicles ought to randomly select who to sacrifice and that such random selection ought to be blind to particulars that set people apart from each other, including whether a potential sacrifice is a passenger or owner of the self-driving car in question.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43681-021-00088-7,springer
Article,doi:10.1007/s40435-020-00722-y,Adaptive nonlinear robust control of an underactuated micro UAV,International Journal of Dynamics and Control,10.1007/s40435-020-00722-y,Springer,2021-09-01,2021-01-05,"In this article, we investigate a robust nonlinear control strategy to solve the trajectory tracking for a micro unmanned aerial vehicle, the quadrotor. The control technique is the computed torque control (CTC), this technique is widely used in the robot manipulators control. The CTC technique needs a strong knowledge of the model. In this regard, the complete dynamic model of the quadrotor has been established by the Euler–Lagrange formalism. After that, a robust nonlinear H_∞ controller has been designed to stabilize the system with robustness. The proposed controller takes into account the underactuation characteristic of the quadrotor, so the controller is designed for the actuated degrees of freedom (DOF) with their coupling with the underactuated DOF. For the position tracking, we propose the backstepping controller. In both controllers, nonlinear H_∞ and backstepping, the integral action is considered to get a null steady-state error. In order to improve performance quality, the control law has been reinforced by an adaptive action. This last has been performed by the linear parameterization property and the neural networks. The results show efficiency in the parametric uncertainties.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40435-020-00722-y,springer
Article,doi:10.1007/s00521-020-05001-7,A hybrid approach for search and rescue using 3DCNN and PSO,Neural Computing and Applications,10.1007/s00521-020-05001-7,Springer,2021-09-01,2020-06-02,"Search and rescue are essential applications of disaster management in which people are evacuated from the disaster-prone area to a safer place. This overall process of search and rescue can be more efficient if an automated system can quickly locate the human or area where rescue is required. To provide a faster and accurate search of those places, this paper proposes a novel approach to search and rescue using automated drone surveillance. In this paper, a complex scene classification problem is solved using the proposed 3DCNN model. The proposed model uses spatial as well as temporal features of the video for the classification of the scene as help or non-help in the natural disaster. Due to the unavailability of such kind of dataset, it is impossible to train the model. Therefore, it is essential to develop a dataset for search and rescue. The proposed dataset is a first and unique dataset for scene classification using drone surveillance. The major contribution of this paper is (1) a novel 3DCNN powered model for scene classification in drone surveillance, (2) to develop the required dataset for the training of scene classification model, and (3) particular swarm optimization (PSO)-based hyper-parameter tuning for getting the best value of multiple parameters used for training the model. Our hybridization of parameter tuning with PSO helps for the convergence of parameter values of proposed 3DCNN model, and the proposed scene classification model (3DCNN+PSO) is applied to the dataset. The proposed model gives an impressive performance to help situation identification with 98% training and 99% validation accuracy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-020-05001-7,springer
Article,doi:10.1007/s11370-021-00383-6,Leveraging single-shot detection and random sample consensus for wind turbine blade inspection,Intelligent Service Robotics,10.1007/s11370-021-00383-6,Springer,2021-09-01,2021-09-03,"Wind turbines require periodic inspection to ensure efficient power generation and a prolonged lifetime. Traditionally, inspection involves the risk of a person falling while abseiling from the top of the nacelle. To avoid this, drones have been controlled by operators to inspect the blades. However, this task requires expert pilots, who experience fatigue quickly. Alternatively, autonomous drones are not subject to human tiredness and can follow trajectories in a repeatable manner. Motivated by the latter, we introduce a vision-based blade detector capable of recognizing their orientation and relative position to generate a flight plan that allows it to safely collect image data. The proposed blade detector extracts line features with the camera, which are filtered to reduce the search space by using bounding boxes. They are obtained with a single-shot detector based on a convolutional neural network. Finally, a random sample consensus procedure finds the lines that best fit a geometrical model of the wind turbine. We compare our deep learning approach against a color segmentation method, showing that it is up to 6 times faster. We also compare against guided search during random sampling, which exploits the separate boxes detected by the network, seeking to reduce the number of outliers. We conclude with an illustrative example of how our proposed detector could be used for autonomous wind turbine inspection.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-021-00383-6,springer
Article,doi:10.1007/s00146-020-01089-6,Making moral machines: why we need artificial moral agents,AI & SOCIETY,10.1007/s00146-020-01089-6,Springer,2021-09-01,2020-11-03,"As robots and Artificial Intelligences become more enmeshed in rich social contexts, it seems inevitable that we will have to make them into moral machines equipped with moral skills. Apart from the technical difficulties of how we could achieve this goal, we can also ask the ethical question of whether we should seek to create such Artificial Moral Agents (AMAs). Recently, several papers have argued that we have strong reasons not to develop AMAs. In response, we develop a comprehensive analysis of the relevant arguments for and against creating AMAs, and we argue that all things considered we have strong reasons to continue to responsibly develop AMAs. The key contributions of this paper are threefold. First, to provide the first comprehensive response to the important arguments made against AMAs by Wynsberghe and Robbins (in “Critiquing the Reasons for Making Artificial Moral Agents”, Science and Engineering Ethics 25, 2019) and to introduce several novel lines of argument in the process. Second, to collate and thematise for the first time the key arguments for and against AMAs in a single paper. Third, to recast the debate away from blanket arguments for or against AMAs in general, to a more nuanced discussion about the use of what sort of AMAs, in what sort of contexts, and for what sort of purposes is morally appropriate.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-020-01089-6,springer
Article,doi:10.1007/s12083-021-01073-x,Blockchain-based Secure and Intelligent Sensing Scheme for Autonomous Vehicles Activity Tracking Beyond 5G Networks,Peer-to-Peer Networking and Applications,10.1007/s12083-021-01073-x,Springer,2021-09-01,2021-02-24,"For the past few years, the automation of transportation becomes a hot research topic for smart cities. Intelligent Transportation System (ITS) aims to manage and optimize the traffic congestion, road accidents, parking allocation using Autonomous Vehicles (AV) system, where the AVs are internally connected for message passing and critical decision making in time-sensitive applications. The data security in such applications can be offered using Blockchain (BC) technology. But, as per the existing literature, there exists no system which can call AVs automatically based on the situation, i.e., call an ambulance in case of an accident, call logistic service in case of home transfer, and call the traffic department in case of traffic jam. Motivated from the aforementioned reasons, in this article, we propose a BC-based secure and intelligent sensing and tracking architecture for AV system using beyond 5G communication network. Recently, AVs are facing issues with sensing and tracking technology as well as the data thefts. AV system contains sensitive information and transfers it through a communication channel to Connected AVs (CAVs), where the corrupted information or delay of a fraction of a second can lead to a critical situation. So, here we present possib the attacks and safety countermeasures using BC technology to protect the AV system. The proposed architecture ensures secure sensing and tracking of an object through BC by deploying AI algorithms at the edge servers. Also, the beyond 5G network enables communications with low latency and high reliability to meet the desires of the aforementioned time-sensitive applications. The proposed system is evaluated by considering the parameters as mobility and data transfer time against the traditional LTE-A and 5G communication networks. The proposed system outperforms traditional systems and can be suitable for diverse applications where latency, reliability, and security are the prime concerns.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12083-021-01073-x,springer
Article,doi:10.1007/s00500-021-05614-7,An intelligent energy management and traffic predictive model for autonomous vehicle systems,Soft Computing,10.1007/s00500-021-05614-7,Springer,2021-09-01,2021-02-02,"In recent times, the utilization of autonomous vehicles (AVs) has been significantly increased over the globe. It is because of the tremendous rise in familiarity and the usage of artificial intelligence approaches in distinct application areas. Though AVs offer several benefits like congestion control, accident prevention, and so on, energy management and traffic flow prediction (TFP) remain a challenging issue. This paper concentrates on the design of intelligent energy management and TFP (IEMTFP) technique for AVs using multi-objective reinforced whale optimization algorithm (RWOA) and deep learning (DL). The proposed model involves an energy management module using fuzzy logic system to reach the specified engine torque with respect to different measures. For optimal tuning of the variables involved in the fuzzy logic membership functions (MFs), RWOA is employed to further reduce the energy utilization. Besides, the proposed model uses a DL-based bidirectional long short-term memory (Bi-LSTM) technique to perform TFP. For validating the efficacy of the IEMTFP technique, an extensive experimental validation is carried out. The resultant values ensured the goodness of the IEMTFP model in terms of energy management and TFP.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-021-05614-7,springer
Article,doi:10.1186/s10033-021-00598-9,ML-ANet: A Transfer Learning Approach Using Adaptation Network for Multi-label Image Classification in Autonomous Driving,Chinese Journal of Mechanical Engineering,10.1186/s10033-021-00598-9,Springer,2021-08-23,2021-08-23,"To reduce the discrepancy between the source and target domains, a new multi-label adaptation network (ML-ANet) based on multiple kernel variants with maximum mean discrepancies is proposed in this paper. The hidden representations of the task-specific layers in ML-ANet are embedded in the reproducing kernel Hilbert space (RKHS) so that the mean-embeddings of specific features in different domains could be precisely matched. Multiple kernel functions are used to improve feature distribution efficiency for explicit mean embedding matching, which can further reduce domain discrepancy. Adverse weather and cross-camera adaptation examinations are conducted to verify the effectiveness of our proposed ML-ANet. The results show that our proposed ML-ANet achieves higher accuracies than the compared state-of-the-art methods for multi-label image classification in both the adverse weather adaptation and cross-camera adaptation experiments. These results indicate that ML-ANet can alleviate the reliance on fully labeled training data and improve the accuracy of multi-label image classification in various domain shift scenarios.",http://link.springer.com/openurl/fulltext?id=doi:10.1186/s10033-021-00598-9,springer
Article,doi:10.1007/s11227-021-03988-x,Automatic lane marking prediction using convolutional neural network and S-Shaped Binary Butterfly Optimization,The Journal of Supercomputing,10.1007/s11227-021-03988-x,Springer,2021-08-06,2021-08-06,"Lane detection is a technique that uses geometric features as an input to the autonomous vehicle to automatically distinguish lane markings. To process the intricate features present in the lane images, traditional computer vision (CV) techniques are typically time-consuming, need more computing resources, and use complex algorithms. To address this problem, this paper presents a deep convolutional neural network (CNN) architecture that prevents the complexities of traditional CV techniques. CNN is regarded as a reasonable method for lane marking prediction, while improved performance requires hyperparameter tuning. To enhance the initial parameter setting of the CNN, an S-Shaped Binary Butterfly Optimization Algorithm (SBBOA) is utilized in this paper. In this way, the relative parameters of CNN are selected for accurate lane marking. To evaluate the performance of the proposed SBBOA-CNN model, extensive experiments are conducted using the TUSimple and CULane datasets. The experimental results obtained show that the proposed approach outperforms other state-of-the-art techniques in terms of classification accuracy, precision, F 1-score, and recall. The proposed model also considerably outperforms the CNN in terms of classification accuracy, average elapsed time, and receiver operating characteristics curve measure. This result demonstrates that the SBBOA optimized CNN exhibits higher robustness and stability than CNN.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11227-021-03988-x,springer
Article,doi:10.1007/s00521-021-05764-7,A dynamic discarding technique to increase speed and preserve accuracy for YOLOv3,Neural Computing and Applications,10.1007/s00521-021-05764-7,Springer,2021-08-01,2021-03-05,"This paper proposes an acceleration technique to minimise the unnecessary operations on a state-of-the-art machine learning model and thus to improve the processing speed while maintaining the accuracy. After the study of the main bottlenecks that negatively affect the performance of convolutional neural networks, this paper designs and implements a discarding technique for YOLOv3-based algorithms to increase the speed and maintain accuracy. After applying the discarding technique, YOLOv3 can achieve a 22% of improvement in terms of speed. Moreover, the results of this new discarding technique were tested on Tiny-YOLOv3 with three output layers on an autonomous vehicle for pedestrian detection and it achieved an improvement of 48.7% in speed. The dynamic discarding technique just needs one training process to create the model and thus execute the approach, which preserves accuracy. The improved detector based on the discarding technique is able to readily alert the operator of the autonomous vehicle to take the emergency brake of the vehicle in order to avoid collision and consequently save lives.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-021-05764-7,springer
Article,doi:10.1186/s10033-021-00568-1,Deep Learning Based Data Fusion for Sensor Fault Diagnosis and Tolerance in Autonomous Vehicles,Chinese Journal of Mechanical Engineering,10.1186/s10033-021-00568-1,Springer,2021-07-20,2021-07-20,"Environmental perception is one of the key technologies to realize autonomous vehicles. Autonomous vehicles are often equipped with multiple sensors to form a multi-source environmental perception system. Those sensors are very sensitive to light or background conditions, which will introduce a variety of global and local fault signals that bring great safety risks to autonomous driving system during long-term running. In this paper, a real-time data fusion network with fault diagnosis and fault tolerance mechanism is designed. By introducing prior features to realize the lightweight network, the features of the input data can be extracted in real time. A new sensor reliability evaluation method is proposed by calculating the global and local confidence of sensors. Through the temporal and spatial correlation between sensor data, the sensor redundancy is utilized to diagnose the local and global confidence level of sensor data in real time, eliminate the fault data, and ensure the accuracy and reliability of data fusion. Experiments show that the network achieves state-of-the-art results in speed and accuracy, and can accurately detect the location of the target when some sensors are out of focus or out of order. The fusion framework proposed in this paper is proved to be effective for intelligent vehicles in terms of real-time performance and reliability.",http://link.springer.com/openurl/fulltext?id=doi:10.1186/s10033-021-00568-1,springer
Article,doi:10.1186/s13007-021-00761-2,Prediction of plant-level tomato biomass and yield using machine learning with unmanned aerial vehicle imagery,Plant Methods,10.1186/s13007-021-00761-2,BioMed Central,2021-07-15,2021-07-15,"Background The objective of this study is twofold. First, ascertain the important variables that predict tomato yields from plant height (PH) and vegetation index (VI) maps. The maps were derived from images taken by unmanned aerial vehicles (UAVs). Second, examine the accuracy of predictions of tomato fresh shoot masses (SM), fruit weights (FW), and the number of fruits (FN) from multiple machine learning algorithms using selected variable sets. To realize our objective, ultra-high-resolution RGB and multispectral images were collected by a UAV on ten days in 2020’s tomato growing season. From these images, 756 total variables, including first- (e.g., average, standard deviation, skewness, range, and maximum) and second-order (e.g., gray-level co-occurrence matrix features and growth rates of PH and VIs) statistics for each plant, were extracted. Several selection algorithms (i.e., Boruta, DALEX, genetic algorithm, least absolute shrinkage and selection operator, and recursive feature elimination) were used to select the variable sets useful for predicting SM, FW, and FN. Random forests, ridge regressions, and support vector machines were used to predict the yield using the top five selected variable sets. Results First-order statistics of PH and VIs collected during the early to mid-fruit formation periods, about one month prior to harvest, were important variables for predicting SM. Similar to the case for SM, variables collected approximately one month prior to harvest were important for predicting FW and FN. Furthermore, variables related to PH were unimportant for prediction. Compared with predictions obtained using only first-order statistics, those obtained using the second-order statistics of VIs were more accurate for FW and FN. The prediction accuracy of SM, FW, and FN by models constructed from all variables (rRMSE = 8.8–28.1%) was better than that from first-order statistics (rRMSE = 10.0–50.1%). Conclusions In addition to basic statistics (e.g., average and standard deviation), we derived second-order statistics of PH and VIs at the plant level using the ultra-high resolution UAV images. Our findings indicated that our variable selection method reduced the number variables needed for tomato yield prediction, improving the efficiency of phenotypic data collection and assisting with the selection of high-yield lines within breeding programs.",https://www.biomedcentral.com/openurl?doi=10.1186/s13007-021-00761-2,springer
Article,doi:10.1007/s10664-021-09982-4,Can Offline Testing of Deep Neural Networks Replace Their Online Testing?,Empirical Software Engineering,10.1007/s10664-021-09982-4,Springer,2021-07-05,2021-07-05,"We distinguish two general modes of testing for Deep Neural Networks (DNNs): Offline testing where DNNs are tested as individual units based on test datasets obtained without involving the DNNs under test, and online testing where DNNs are embedded into a specific application environment and tested in a closed-loop mode in interaction with the application environment. Typically, DNNs are subjected to both types of testing during their development life cycle where offline testing is applied immediately after DNN training and online testing follows after offline testing and once a DNN is deployed within a specific application environment. In this paper, we study the relationship between offline and online testing. Our goal is to determine how offline testing and online testing differ or complement one another and if offline testing results can be used to help reduce the cost of online testing? Though these questions are generally relevant to all autonomous systems, we study them in the context of automated driving systems where, as study subjects, we use DNNs automating end-to-end controls of steering functions of self-driving vehicles. Our results show that offline testing is less effective than online testing as many safety violations identified by online testing could not be identified by offline testing, while large prediction errors generated by offline testing always led to severe safety violations detectable by online testing. Further, we cannot exploit offline testing results to reduce the cost of online testing in practice since we are not able to identify specific situations where offline testing could be as accurate as online testing in identifying safety requirement violations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10664-021-09982-4,springer
Article,doi:10.1134/S1054661821030068,Using Machine Learning Techniques to Detect Defects in Images of Metal Structures,Pattern Recognition and Image Analysis,10.1134/S1054661821030068,Springer,2021-07-01,2021-09-21,"Abstract This paper is devoted to studying the capabilities of modern neural networks in image processing for solving the problem of monitoring the state of steel and reinforced concrete structures. The article presents a method for solving monitoring problems based on the use of a combination of several neural networks focused on recognizing a fragment of a structure and parts of a structure. Methods for training neural networks on small training samples are proposed. The results of the operation of the algorithms on real images are presented, showing the consistency and efficiency of the proposed solution.",http://link.springer.com/openurl/fulltext?id=doi:10.1134/S1054661821030068,springer
Article,doi:10.1007/s10677-021-10190-8,The Relativistic Car: Applying Metaethics to the Debate about Self-Driving Vehicles,Ethical Theory and Moral Practice,10.1007/s10677-021-10190-8,Springer,2021-07-01,2021-05-22,"Almost all participants in the debate about the ethics of accidents with self-driving cars have so far assumed moral universalism. However, universalism may be philosophically more controversial than is commonly thought, and may lead to undesirable results in terms of non-moral consequences and feasibility. There thus seems to be a need to also start considering what I refer to as the “relativistic car” — a car that is programmed under the assumption that what is morally right, wrong, good, bad, etc. is determined by the moral beliefs of one’s society or culture. My investigation of this idea involves six steps. First, I explain why and how the moral universalism/relativism debate is relevant to the issue of self-driving cars. Second, I argue that there are good reasons to consider accident algorithms that assume relativism. Third, I outline how a relativistic car would be programmed to behave. Fourth, I address what advantages such a car would have, both in terms of its non-moral consequences and feasibility. Fifth, I address the relativistic car’s disadvantages. Finally, I qualify and conclude my considerations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10677-021-10190-8,springer
Article,doi:10.1134/S1054661821030238,Memory Consumption and Computation Efficiency Improvements of Viola–Jones Object Detection Method for Remote Sensing Applications,Pattern Recognition and Image Analysis,10.1134/S1054661821030238,Springer,2021-07-01,2021-09-21,"Abstract In this paper, we consider object classification and detection problems. We propose an algorithm that is effective from the point of view of computational complexity and memory consumption. The proposed algorithm can be successfully used as a basic tool for building different remote sensing systems which are, in general, installed on UAVs. The algorithm is based on the Viola–Jones method. It is shown in the paper, that the Viola–Jones method is the most preferable approach to detect objects on-board UAVs, because it needs the least amount of memory and the number of computational operations to solve the object detection problem. To ensure sufficient accuracy, we use a modified feature: rectangular Haar-like features, calculated over the magnitude of the image gradient. To increase computational efficiency, the L1 norm was used to calculate the magnitude of the image gradient. To train orientation-independent complex classifier we use a more generic decision tree form of complex classifier instead of a cascade scheme. All mentioned improvements were evaluated during detection of the following objects: the PSN-10 inflatable life raft (an example of an object that is detected during rescue operations using UAVs), oil tank storage (such kind of objects are usually detected during the inspection of industrial infrastructure), and aircraft on an area of hardstand. The performance of the trained detectors was estimated on real data (including data obtained during the rescue operation of the trawler Dalniy Vostok and a subset of real images from the DOTA dataset).",http://link.springer.com/openurl/fulltext?id=doi:10.1134/S1054661821030238,springer
Article,doi:10.1007/s12144-021-01956-5,Plenty of blame to go around: Attributions of responsibility in a fatal autonomous vehicle accident,Current Psychology,10.1007/s12144-021-01956-5,Nature,2021-06-26,2021-06-26,"Autonomous vehicles (AV) promise a reduction in the number of deadly traffic accidents. However, should accidents occur, attributions of responsibility are complicated by the fact that there is a human agent (driver) and a non-human agent (AV), and thus responsibility is likely shared between parties. In two studies, participants ( n  = 310 and n  = 260) read a vignette modeled after an actual lethal AV accident. Across four experimental conditions, participants were told that the human driver either needed to maintain oversight of the AV; did not need to maintain oversight of the AV; did not specify whether the human needed to maintain oversight of the AV; or the artificial intelligence was turned off and the human driver was fully in control. Participants assigned responsibility to the human driver, the AV company, the pedestrian, and an act of God, and determined whether the human driver and company CEO should be held criminally responsible in court. Consistent with previous research, the human driver was held most responsible regardless of oversight condition. However, companies were not absolved of responsibility, even when they required the human driver to maintain oversight of the AV. Implications of these findings for the introduction and legal regulation of AVs are discussed.",https://www.nature.com/articles/s12144-021-01956-5,springer
Article,doi:10.1007/s10846-021-01387-1,Improving Control Performance of Unmanned Aerial Vehicles through Shared Experience,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01387-1,Springer,2021-06-25,2021-06-25,"This work proposes a novel approach for improving the control performance of Unmanned Aerial Vehicles (UAVs) through cooperative reinforcement learning. By sharing their experience, it is shown that multiple UAVs can work together to converge on a set of optimal Model Predictive Control (MPC) parameters faster than when working on their own. In order to benefit from this shared experience, the UAVs must coordinate their learning strategies. Here, we proposed a Leader-Follower approach, whereby the Leader ensures all trials are drawn from the same distribution and contribute to a common payoff game of Learning Automata. Experimental results show that this approach results in faster learning without any loss of performance.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-021-01387-1,springer
Article,doi:10.1186/s13677-021-00246-6,Computation offloading strategy based on deep reinforcement learning for connected and autonomous vehicle in vehicular edge computing,Journal of Cloud Computing,10.1186/s13677-021-00246-6,Springer,2021-06-08,2021-06-08,"Connected and Automated Vehicle (CAV) is a transformative technology that has great potential to improve urban traffic and driving safety. Electric Vehicle (EV) is becoming the key subject of next-generation CAVs by virtue of its advantages in energy saving. Due to the limited endurance and computing capacity of EVs, it is challenging to meet the surging demand for computing-intensive and delay-sensitive in-vehicle intelligent applications. Therefore, computation offloading has been employed to extend a single vehicle’s computing capacity. Although various offloading strategies have been proposed to achieve good computing performace in the Vehicular Edge Computing (VEC) environment, it remains challenging to jointly optimize the offloading failure rate and the total energy consumption of the offloading process. To address this challenge, in this paper, we establish a computation offloading model based on Markov Decision Process (MDP), taking into consideration task dependencies, vehicle mobility, and different computing resources for task offloading. We then design a computation offloading strategy based on deep reinforcement learning, and leverage the Deep Q-Network based on Simulated Annealing (SA-DQN) algorithm to optimize the joint objectives. Experimental results show that the proposed strategy effectively reduces the offloading failure rate and the total energy consumption for application offloading.",https://www.biomedcentral.com/openurl?doi=10.1186/s13677-021-00246-6,springer
Article,doi:10.1007/s11760-020-01800-6,Human activity recognition-based path planning for autonomous vehicles,"Signal, Image and Video Processing",10.1007/s11760-020-01800-6,Springer,2021-06-01,2020-10-16,"Human activity recognition (HAR) is a wide research topic in a field of computer science. Improving HAR can lead to massive breakthrough in humanoid robotics, robots used in medicine and in the field of autonomous vehicles. The system that is able to recognise human and its activity without any errors and anomalies would lead to safer and more empathetic autonomous systems. During this research work, multiple neural networks models, with different complexity, are being investigated. Each model is re-trained on the proposed unique data set, gathered on automated guided vehicle (AGV) with the latest and the modest sensors used commonly on autonomous vehicles. The best model is picked out based on the final accuracy for action recognition. Best models pipeline is fused with YOLOv3, to enhance the human detection. In addition to pipeline improvement, multiple action direction estimation methods are proposed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11760-020-01800-6,springer
Article,doi:10.1007/s00521-021-06101-8,Path-tracking control for autonomous vehicles using double-hidden-layer output feedback neural network fast nonsingular terminal sliding mode,Neural Computing and Applications,10.1007/s00521-021-06101-8,Springer,2021-05-17,2021-05-17,"In this paper, a double-hidden-layer output feedback neural network fast nonsingular terminal sliding mode control strategy is developed for path-tracking tasks of autonomous vehicles. First, a vehicle kinematic-and-dynamic model is established to describe the vehicle’s fundamental lateral dynamics in path-tracking behavior. Afterwards, detailed design procedure of the proposed controller is shown, where the control system’s stability is verified in the Lyapunov sense. Finally, MATLAB-Carsim co-simulations are executed for the aim of testing the control performance. Simulation results illustrate that the designed control algorithm possesses remarkable superiority reflected in higher tracking precision, faster convergence rate and firmer robustness in comparison with a conventional sliding mode controller and a nonsingular terminal sliding mode controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-021-06101-8,springer
Article,doi:10.1007/s12369-021-00790-w,Designing AI for Explainability and Verifiability: A Value Sensitive Design Approach to Avoid Artificial Stupidity in Autonomous Vehicles,International Journal of Social Robotics,10.1007/s12369-021-00790-w,Springer,2021-05-15,2021-05-15,"One of the primary, if not most critical, difficulties in the design and implementation of autonomous systems is the black-boxed nature of the decision-making structures and logical pathways. How human values are embodied and actualised in situ may ultimately prove to be harmful if not outright recalcitrant. For this reason, the values of stakeholders become of particular significance given the risks posed by opaque structures of intelligent agents. This paper explores how decision matrix algorithms, via the belief-desire-intention model for autonomous vehicles, can be designed to minimize the risks of opaque architectures. Primarily through an explicit orientation towards designing for the values of explainability and verifiability. In doing so, this research adopts the Value Sensitive Design (VSD) approach as a principled framework for the incorporation of such values within design. VSD is recognized as a potential starting point that offers a systematic way for engineering teams to formally incorporate existing technical solutions within ethical design, while simultaneously remaining pliable to emerging issues and needs. It is concluded that the VSD methodology offers at least a strong enough foundation from which designers can begin to anticipate design needs and formulate salient design flows that can be adapted to the changing ethical landscapes required for utilisation in autonomous vehicles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-021-00790-w,springer
Article,doi:10.1007/s00607-021-00953-7,Cloud-backed mobile cognition,Computing,10.1007/s00607-021-00953-7,Springer,2021-05-15,2021-05-15,"Low-power embedded technology offers a roadmap for enabling deep learning (DL) applications in mobile scenarios, like future autonomous vehicles. However, the lack of breakthrough power efficiency improvements can jeopardize the realization of truly “cognitive” mobile systems that meet real-time deadlines. This work focuses on the new generation cloud-backed mobile cognition system architecture where vehicles execute DL applications with dynamic assistance from the cloud. We unveil opportunities for power-efficient inferencing at the edge through a technique that balances inference execution across the cloud and the vehicle. This level of adaptation results in significant power efficiency improvements compared to all or nothing solutions, where inferences execute either completely on the vehicle or completely in the cloud. In addition, the cloud can have an active role in helping the vehicle to improve its DL capabilities by communicating relevant model updates, with up to 63% bandwidth savings and negligible accuracy degradation when the proposed relevance-driven federated learning technique is used. Finally, the cloud-backed mobile cognition concept is extended to the case of “flying clouds” where vehicles connect to flying drones that provide services while in flight. Although their capabilities are not on par with the stationary cloud, the flying cloud reduces services’ latency significantly and enables critical functionalities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00607-021-00953-7,springer
Article,doi:10.1007/s12665-021-09695-3,Predicting sediment deposition rate in check-dams using machine learning techniques and high-resolution DEMs,Environmental Earth Sciences,10.1007/s12665-021-09695-3,Springer,2021-05-14,2021-05-14,"Sediments accumulated in check dams are a valuable measure to estimate soil erosion rates. Here, geographic information systems (GIS) and three machine learning techniques (MARS-multivariate adaptive regression splines, RF-random forest and SVM-support vector machine) were used, for the first time, to predict sediment deposition rate ( SR ) in check-dams located in six watersheds in SW Spain. There, 160 dry-stone check dams (~ 77.8 check-dams km^−2), accumulated sediments during a period that varied from 11 to 23 years. The SR was estimated in former research using a topographical method and a high-resolution Digital Elevation Model (DEM) (average of 0.14 m^3 ha^−1 year^−1). Nine environmental-topographic parameters were calculated and employed as predictors of the SR . The ability of MARS, RF and SVM was evaluated by using a five-fold cross-validation, considering the entire area (ALL), the check dams on the hillslope (HILL) and the valley-bottoms (VALLEY), as well as the three catchments (B, C and D) with the highest number of check dams. The accuracy of the models was assessed by the relative root mean square error ( RRMSE ) and the mean absolute error ( MAE ). The results revealed that RF and SVM are able to predict SR with higher and more stable accuracy than MARS. This is evident for the datasets ALL, VALLEY and D, where errors of prediction exhibited by MARS were from 44 to 77% ( RRMSE ) and from 37 to 62% ( MAE ) higher than those achieved by RF and SVM, but it also held for the datasets HILL and B where the difference of RRMSE and MAE was 7–10% and 12–17%, respectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12665-021-09695-3,springer
Article,doi:10.1186/s13007-021-00750-5,Leaf area index estimation model for UAV image hyperspectral data based on wavelength variable selection and machine learning methods,Plant Methods,10.1186/s13007-021-00750-5,BioMed Central,2021-05-03,2021-05-03,"Background To accurately estimate winter wheat leaf area index (LAI) using unmanned aerial vehicle (UAV) hyperspectral imagery is crucial for crop growth monitoring, fertilization management, and development of precision agriculture. Methods The UAV hyperspectral imaging data, Analytical Spectral Devices (ASD) data, and LAI were simultaneously obtained at main growth stages (jointing stage, booting stage, and filling stage) of various winter wheat varieties under various nitrogen fertilizer treatments. The characteristic bands related to LAI were extracted from UAV hyperspectral data with different algorithms including first derivative (FD), successive projections algorithm (SPA), competitive adaptive reweighed sampling (CARS), and competitive adaptive reweighed sampling combined with successive projections algorithm (CARS_SPA). Furthermore, three modeling machine learning methods including partial least squares regression (PLSR), support vector machine regression (SVR), and extreme gradient boosting (Xgboost) were used to build LAI estimation models. Results The results show that the correlation coefficient between UAV and ASD hyperspectral data is greater than 0.99, indicating the UAV data can be used for estimation of wheat growth information. The LAI bands selected by using different algorithms were slightly different among the 15 models built in this study. The Xgboost model using nine consecutive characteristic bands selected by CARS_SPA algorithm as input was proved to have the best performance. This model yielded identical results of coefficient of determination (0.89) for both calibration set and validation set, indicating a high accuracy of this model. Conclusions The Xgboost modeling method in combine with CARS_SPA algorithm can reduce input variables and improve the efficiency of model operation. The results provide reference and technical support for nondestructive and rapid estimation of winter wheat LAI by using UAV.",https://www.biomedcentral.com/openurl?doi=10.1186/s13007-021-00750-5,springer
Article,doi:10.1631/FITEE.1900637,Pre-training with asynchronous supervised learning for reinforcement learning based autonomous driving,Frontiers of Information Technology & Electronic Engineering,10.1631/FITEE.1900637,Springer,2021-05-01,2021-05-28,"基于人定规则所设计的自动驾驶系统可能会因大规模相互耦合的规则而变得越来越复杂, 因此许多研究人员致力于探索基于学习的解决方案. 强化学习 (reinforcement learning, RL) 因其在各种顺序控制问题上的出色表现而被应用于自动驾驶系统设计. 然而, 基于RL的自动驾驶系统落地应用所面临的主要挑战是其初始性能不佳. 强化学习训练需要大量训练数据, 然后模型才能达到合理的性能要求, 这使得基于强化学习的模型不适用于现实环境, 尤其在数据昂贵的情况下. 本文为基于强化学习的端到端自动驾驶模型提出一种异步监督学习 (asynchronous supervised learning, ASL) 方法, 以解决在实际环境中训练基于强化学习模型时初始性能差的问题. 具体而言, 通过在多个驾驶演示数据集上并行且异步执行多个监督学习过程, 在异步监督学习预训练阶段引入先验知识。经过预训练后, 模型将被部署到真实车辆上进一步开展强化学习训练, 以适应实际环境并不断突破性能极限. 本文在赛车模拟器TORCS (The Open Racing Car Simulator) 上对所提出的预训练方法进行评估, 以验证该方法在改善强化学习训练阶段端到端自动驾驶模型的初始性能和收敛速度方面足够可靠. 此外, 建立一个实车验证系统, 以验证所提预训练方法在实车部署中的可行性. 仿真结果表明, 在有监督的预训练阶段使用一些演示, 可以显著提高强化学习训练阶段的初始性能和收敛速度. Rule-based autonomous driving systems may suffer from increased complexity with large-scale intercoupled rules, so many researchers are exploring learning-based approaches. Reinforcement learning (RL) has been applied in designing autonomous driving systems because of its outstanding performance on a wide variety of sequential control problems. However, poor initial performance is a major challenge to the practical implementation of an RL-based autonomous driving system. RL training requires extensive training data before the model achieves reasonable performance, making an RL-based model inapplicable in a real-world setting, particularly when data are expensive. We propose an asynchronous supervised learning (ASL) method for the RL-based end-to-end autonomous driving model to address the problem of poor initial performance before training this RL-based model in real-world settings. Specifically, prior knowledge is introduced in the ASL pre-training stage by asynchronously executing multiple supervised learning processes in parallel, on multiple driving demonstration data sets. After pre-training, the model is deployed on a real vehicle to be further trained by RL to adapt to the real environment and continuously break the performance limit. The presented pre-training method is evaluated on the race car simulator, TORCS (The Open Racing Car Simulator), to verify that it can be sufficiently reliable in improving the initial performance and convergence speed of an end-to-end autonomous driving model in the RL training stage. In addition, a real-vehicle verification system is built to verify the feasibility of the proposed pre-training method in a real-vehicle deployment. Simulations results show that using some demonstrations during a supervised pre-training stage allows significant improvements in initial performance and convergence speed in the RL training stage.",http://link.springer.com/openurl/pdf?id=doi:10.1631/FITEE.1900637,springer
Article,doi:10.1007/s42421-021-00038-z,Model Free Identification of Traffic Conditions Using Unmanned Aerial Vehicles and Deep Learning,Journal of Big Data Analytics in Transportation,10.1007/s42421-021-00038-z,Springer,2021-04-01,2021-03-08,"The purpose of this paper is to provide a methodological framework to identify traffic conditions based on non-calibrated video recordings captured from unmanned aerial vehicles (UAV) using deep learning. To this end, we propose two complementary to each other approaches: (i) identify in real time, with minimal computational cost, traffic conditions, (ii) localize, classify vehicles and approximate traffic variables (volume, speed, density) on a road segment from video captured by UAVs. Both problems are formulated as classification problems and tackled using Convolutional Neural Networks (CNN). The use of pre-trained CNNs is also investigated. Both approaches are, then, analysed based on their accuracy and feasibility in implementation. Findings indicate that all models developed achieve a detection accuracy of 89% and higher. The CNN with the best performance can classify traffic conditions between constrained and unconstrained traffic with 91% accuracy higher than what a pretrained model achieved and with significantly faster training times. Furthermore, findings indicated that pretrained neural network for traffic localization was able to predict the position and type of vehicles with a precision of 0.91. Based on the fundamental traffic diagram, it was shown that the two approaches provide compatible results and a feasible representation of traffic on the study area. Finally, possible applications in the field of transportation and traffic monitoring are discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42421-021-00038-z,springer
Article,doi:10.1007/s11227-020-03399-4,Improving the learning of self-driving vehicles based on real driving behavior using deep neural network techniques,The Journal of Supercomputing,10.1007/s11227-020-03399-4,Springer,2021-04-01,2020-08-31,"Considering the significant advancements in autonomous vehicle technology, research in this field is of interest to researchers. To drive vehicles autonomously, controlling steer angle, gas hatch, and brakes needs to be learned. The behavioral cloning method is used to imitate humans’ driving behavior. We created a dataset of driving in different routes and conditions, and using the designed model, the output used for controlling the vehicle is obtained. In this paper, the learning of self-driving vehicles based on real driving behavior using deep neural network techniques (LSV-DNN) is proposed. We designed a convolutional network which uses the real driving data obtained through the vehicle’s camera and computer. The response of the driver during driving is recorded in different situations, and by converting the real driver’s driving video to images and transferring the data to an Excel file, obstacle detection is carried out with the best accuracy and speed using the Yolo algorithm version 3. This way, the network learns the response of the driver to obstacles in different locations and the network is trained with the Yolo algorithm version 3 and the output of obstacle detection. Then, it outputs the steer angle and amount of brake, gas, and vehicle acceleration. This study focuses on designing a convolutional network using behavioral cloning and motion planning of autonomous vehicle using a deep learning framework. Neural networks are effective systems for finding relationships between data, modeling, and predict new data or classify data. As a result Neural networks with input real data predict steer angle and speed for autonomous driving. The LSV-DNN is evaluated here via extensive simulations carried out in Python and TensorFlow environment. We evaluated the network error using the loss function. The results confirmed that our scheme is capable of exhibiting high prediction accuracy (exceeding 92.93%). In addition, our proposed scheme has high speed (more than 64.41%), low FPR (less than 6.89%), and low FNR (less than 3.95%), in comparison with the other approaches currently being employed. By comparing other methods which were conducted on the simulator’s data, we obtained good performance results for the designed network on the data from KITTI benchmark, the data collected using a private vehicle, and the data we collected.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11227-020-03399-4,springer
Article,doi:10.1007/s00542-019-04695-7,Machine learning based null allocation design for adaptive beamforming in unmanned aerial vehicle communications,Microsystem Technologies,10.1007/s00542-019-04695-7,Springer,2021-04-01,2019-12-19,"In order to communicate with target unmanned aerial vehicles (UAVs), ground control stations (GCSs) typically adopt adaptive beamforming with high antenna gain and co-channel interference rejection. Multiple interfering signals arriving from different directions arise from other UAVs and other GCSs, and the beamformer installed in the home GCS will usually attempt to null unwanted signals from all these directions of arrival (DoAs) without analyzing the distribution of the angles of arrival. Consequently, the beamformer will fail to allocate nulls in some directions, and the signal-to-interference-plus-noise (SINR) performance of the home GCS is impaired. In this paper, a new approach to null allocation is proposed, based on machine learning using k -means clustering. The design first involves the collection of information about the DoAs and the corresponding received signal strengths of all the interfering signals into a two-dimensional dataset. Secondly, this dataset is broken down into clusters by using k -means clustering, and the cluster centroids are calculated. In each cluster, the interfering signal that has the shortest Euclidean distance to the centroid is identified as the approximated centroid. Only the approximated centroids are selected as input to the beamformer, with the aim that each complete cluster of interference sources can be nulled by allocating one null per cluster. To optimize the number of clusters k used in the null allocation process, the design adopts the particle swarm optimization technique to adaptively update the value of k to maximize the SINR at the home GCS. Simulation results show that our design yields a maximum SINR improvement of about 12 dB when compared to cases where no null allocation is considered. Moreover, our design also outperforms null steering in the UAV scenarios. Advantageously, this enhanced performance is obtained without the need for additional power amplification or hardware modification to the beamformer.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00542-019-04695-7,springer
Article,doi:10.1007/s10657-020-09671-5,Grounding the case for a European approach to the regulation of automated driving: the technology-selection effect of liability rules,European Journal of Law and Economics,10.1007/s10657-020-09671-5,Springer,2021-04-01,2020-11-20,"In the current paper, we discuss the need for regulation at EU level of Connected and Automated Driving solutions (henceforth CAD) based on multiple considerations, namely (i) the need for uniformity of criteria across European Member States, and (ii) the impact that regulation—or the absence of it—has on the proliferation of specific technological solutions. The analysis is grounded on legal and economic considerations of possible interactions between vehicles with different levels of automation, and shows how the existing framework delays innovation. A Risk-Management Approach, identifying one sole responsible party ex ante (one-stop-shop), liable under all circumstances—pursuant to a strict, if not absolute liability rule—is to be preferred. We analyse the solution adopted by some Member States in light of those considerations and conclude that none truly corresponds to a RMA approach, and differences will also cause market fragmentation. We conclude that because legal rules determine what kind of technological application is favoured over others—and thence they are not technology-neutral—uniformity across MSs is of essential relevance, and discuss possible policy approaches to be adopted at European level.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10657-020-09671-5,springer
Article,doi:10.1007/s11370-020-00343-6,RCNet: road classification convolutional neural networks for intelligent vehicle system,Intelligent Service Robotics,10.1007/s11370-020-00343-6,Springer,2021-04-01,2021-02-12,"Vision-based techniques for intelligent vehicles in heterogeneous road environments are gaining significant attention from researchers and industrialists. Unfortunately, the mechanisms in this domain suffer from limited performance due to scene complexity, varying road structure, and improper illumination conditions. These challenging situations may lead an intelligent vehicle into dangerous situations such as collisions or road accidents and may cause higher mortality. The application of intelligent methods and other machine learning techniques for road surface classification is little explored in the existing literature. Thus, we propose a convolutional neural network-based road classification network (RCNet) for the accurate classification of road surfaces. This procedure includes the classification of five major categories of road surfaces: curvy, dry, ice, rough, and wet roads. The experimental results reveal the behavior of the proposed RCNet under various optimizer techniques. The standard performance evaluation measures have been used to test and validate the proposed method on the Oxford RobotCar dataset. RCNet achieves classification accuracy, precision, and sensitivity of 99.90%, and 99.97% of specificity. Results of implemented work are significantly higher than available state-of-the-art techniques and show accurate and effective performance in the complex road environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-020-00343-6,springer
Article,doi:10.1007/s12524-020-01231-3,Deep Learning Based Supervised Image Classification Using UAV Images for Forest Areas Classification,Journal of the Indian Society of Remote Sensing,10.1007/s12524-020-01231-3,Springer,2021-03-01,2020-11-07,"Applications of unmanned aerial vehicles (UAVs) based remote sensing is increasing rapidly due to their advanced accessibility, capability for fast and easy deployment, capability for miniaturization of sensors and efficient collection of remotely-sensed data from relatively low altitudes. Recently, UAV data sets have been found to be quite useful for forest feature identification due to their relatively high spatial resolution. Several machine learning algorithms have been broadly used for remotely-sensed image classification. In remote sensing image classification, deep learning based methods can be considered quite effective techniques as they have achieved promising results. In this study, we have used deep learning based supervised image classification algorithm and images collected using UAV for classification of forest areas. The deep learning algorithm stacked Auto-encoder has been found to have tremendous potential regarding image classification and the assessment of forest coverage area. Our experimental results show that deep learning method provides better accuracy compared to other machine learning algorithms. Cross-validation showed that the overall accuracy of the deep learning method is about 93%. This study highlights the essential role that UAV observations and deep learning could play in the planning and management of forest areas which are often under the threat of deforestation and forest encroachment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12524-020-01231-3,springer
Article,doi:10.1007/s12667-020-00414-8,Application of AI in image recognition technology for power line inspection,Energy Systems,10.1007/s12667-020-00414-8,Springer,2021-02-04,2021-02-04,"Artificial Intelligence (AI) is an energetic consideration in the electric power company for the scrutiny of the power lines in the forest area. The inspection is escorted to reduce input resources, less cost, rehabilitate electricity, and avoid overhead transmission and distribution lines. The imperfection in the electric companies is deliberate outage management, safety hazards, and diversified system, expensive and not flexible, which disturb the inspection in the forest areas. To recognize the images and status of the power lines, the Naïve Bayesian classifier with Automatic Classification (NBC-AC) algorithms is implemented to classify the observed probabilistic variables of inspection accurately. To monitor the images in long-distance, an Unmanned Aerial Vehicle–Hunter (UAV-H) is proposed to predict the different features of power lines. Hence NBC-AC algorithms with UAV-H systems are used to recognize and classify the characteristics of the power line images with 95% accuracy in the forest area for the electric power company. This encouraging technique contributes to high efficiency and accuracy with the best quality of images and the results were obtained for many AI applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12667-020-00414-8,springer
Article,doi:10.1007/s12652-021-02900-y,Simultaneous detection and tracking using deep learning and integrated channel feature for ambint traffic light recognition,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-021-02900-y,Springer,2021-01-30,2021-01-30,"Perceiving the information about ambient traffic lights is an inevitable task for autonomous vehicles. To deal with the issue, this work develops an accurate and fast traffic light recognition strategy for autonomous vehicles by an onboard camera. In this paper, deep learning based detection and object tracking is synthesized to determine the position and color of traffic lights. First, the mechanism of simultaneous detection and tracking is founded, wherein the video reading module, convolutional neural network (CNN) module, integrated channel feature tracking (ICFT) module are run simultaneously. Then, the respective modules of detection and tracking are introduced. CNN model is designed and trained to obtain the position of traffic lights utilized as initial information for tracking. ICFT is applied to continually track the traffic light targets and determine the light color. Finally, the effectiveness of the presented method is validated via comparing with the state of art. Experiments results indicate that the proposed technique can improve the accuracy and speed of recognition. Our contributions are: (1) Establish a mechanism for simultaneous detection and tracking of traffic lights; (2) Carefully design the CNN architecture and ICFT features; (3)The precision and recall rates on traffic lights recognition reached 0.962 and 0.909, respectively, and the recognition speed reached 21.4FPS (GPU: Nvidia Titan Xp).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-021-02900-y,springer
Article,doi:10.1007/s43545-020-00043-z,In support of “no-fault” civil liability rules for artificial intelligence,SN Social Sciences,10.1007/s43545-020-00043-z,Nature,2021-01-11,2021-01-11,"Civil liability is traditionally understood as indirect market regulation, since the risk of incurring liability for damages gives incentives to invest in safety. Such an approach, however, is inappropriate in the markets of artificial intelligence devices. In fact, according to the current paradigm of civil liability, compensation is allowed only to the extent that “someone” is identified as a debtor. However, in many cases it would not be useful to impose the obligation to pay such compensation to producers and programmers: the algorithms, in fact, can “behave” far independently from the instructions initially provided by programmers so that they can err despite no flaw in design or implementation. Therefore, application of “traditional” civil liability to AI may represent a disincentive to new technologies based on artificial intelligence. This is why I think artificial intelligence requires that the law evolves, on this matter, from an issue of civil liability into one of financial management of losses. No-fault redress schemes could be an interesting and worthy regulatory strategy in order to enable this evolution. Of course, such schemes should apply only in cases where there is no evidence that producers and programmers have acted under conditions of negligence, imprudence or unskillfulness and their activity is adequately compliant with scientifically validated standards.",https://www.nature.com/articles/s43545-020-00043-z,springer
Chapter,doi:10.1007/978-981-16-0598-7_11,Design of a Machine Learning-Based Self-driving Car,Machine Learning for Robotics Applications,10.1007/978-981-16-0598-7_11,Springer,2021-01-01,2021-04-24,"In this work, an algorithm of machine learning for self-driving car using udacity and unity self-driving car simulation software has been presented. Using the software, the car is driven on the simulated circuit having three cameras mounted on car hood which generate three images simultaneously and acceleration and de-acceleration of the car steering angle and brake. This method includes a behavior cloning approach and tries to replicate a behavior of human driver. For training the model, approximately, 18,000 training samples are required, and by using image augmentation technique, an increase in the data sample with few times is obtained, which leads to little robust simulated self-driving car.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-0598-7_11,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-9774-9_58,Self-driving Car in Virtual Simulation: A Non-AI Approach,Emerging Technologies in Data Mining and Information Security,10.1007/978-981-15-9774-9_58,Springer,2021-01-01,2021-05-05,"Over the last few decades, the self-driving car industry has come a long way and is going toward a future where human drivers might no longer exist. Researchers and engineers in motor companies are trying to innovate new ways to make and train self-driving cars to reduce the number of collisions. So, a lot of progress has been made but the cost of making them grew up with them. In this paper, we propose a simpler version of making and training a self-driving car in a simulated environment using a non-AI approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-9774-9_58,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-3383-9_19,Traffic Sign Recognition for Self-driving Cars with Deep Learning,Advanced Machine Learning Technologies and Applications,10.1007/978-981-15-3383-9_19,Springer,2021-01-01,2020-05-26,"The purpose of this research was to create a model for an autonomous car in traffic sign recognition. A high-accuracy model is needed to analyze the signs. Previous studies have mainly been centered on European countries, and the models created in Europe are not applicable to American autonomous cars. The contributions of this paper are twofold. First, this study generated a dataset that was collected and annotated in order to establish a suitable model for the USA. The dataset was custom made and acquired by using camera footage that was converted into individual frames. The dataset was named Cyber Identity and Biometrics Lab Traffic Sign Dataset Version 1 (CIB TS V1). Then, it was annotated into different classes and labels with LabelIMG. With a customized program, we used the annotations to crop out images and categorized them. Second, the data was run through a deep learning algorithm called modified AlexNet. A lighter version of the AlexNet was used for our experiments. Results showed that the model achieved above 99% accuracy on the validation set.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-3383-9_19,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-76426-5_13,Neuroevolution vs Reinforcement Learning for Training Non Player Characters in Games: The Case of a Self Driving Car,Intelligent Technologies for Interactive Entertainment,10.1007/978-3-030-76426-5_13,Springer,2021-01-01,2021-05-19,"The aim of this project is to compare two popular machine learning methods, a non-gradient-based algorithm such as neuro-evolution with a gradient-based reinforcement learning on an irregular task of training a car to self-drive around 3D circuits with varying complexity. A series of 3D circuits with a physics based car model were modeled using the Unity game engine. The data collected during evaluation show that neuro-evolution converges faster to a solution when compared to the reinforcement learning approach. However, when the reinforcement learning approach is allowed to train for long enough, it outperforms the neuro-evolution in terms of car speed and lap times achieved by the trained model of the car.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-76426-5_13,springer
Chapter ConferencePaper,doi:10.1007/978-981-33-4572-0_114,Artificial Intelligence in the Field of Driverless Cars,Big Data Analytics for Cyber-Physical System in Smart City,10.1007/978-981-33-4572-0_114,Springer,2021-01-01,2020-12-18,"Nowadays, new technologies led by artificial intelligence and big data are booming, and have been widely used in many fields such as medical, transportation, military, and industrial. Automobile driving is one of the main application directions of artificial intelligence in the field of transportation. The purpose of this article is to explore the application of artificial intelligence technology in the field of driverless cars, with a view to bringing precision and real-time improvement to pedestrian detection in driverless systems. In this paper, based on the verification model and the pedestrian recognition algorithm based on the recognition model, a new recognition algorithm combining two types of models is proposed. After optimization and testing on the Market1501 pedestrian re-identification data set, it is concluded that the multi-camera test mAP of this algorithm is 72.55%, which greatly improves the detection accuracy compared with other mainstream re-identification algorithms. The research in this paper basically solves the problems of low accuracy, poor real-time performance and discontinuous cross-camera detection, which is beneficial to the successful application of pedestrian detection in unmanned driving.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-4572-0_114,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-68154-8_91,AutoMove: An End-to-End Deep Learning System for Self-driving Vehicles,Intelligent Computing and Optimization,10.1007/978-3-030-68154-8_91,Springer,2021-01-01,2021-02-08,"End to End learning is a deep learning approach that has been used to solve complex problems that would usually be carried out by humans with great effect. A deep structure was designed within this study to simulate humans’ steering patterns in highway driving situations. The architecture of the network was based on image processing algorithm which is integrated with deep learning convolutional neural network (CNN). There are five aspects in this work, which enables the vehicle to detect the lanes, detect the speed of the vehicle, detect the angle of the road, recognize the objects on the road and predict the steering angle of the vehicle. A self-derived mathematical model is used to calculate the road angles for the prediction of vehicle’s steering angles. The model is trained on 2937 video frame samples and validated on 1259 samples with 30 epochs. The video of the local road was set as the output which will show the difference between actual steering angles and predicted steering angle. The experiments have been carried out in a newly built industrial park with suitable industry 4.0 standard design of urban smart development.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-68154-8_91,springer
Chapter ConferencePaper,doi:10.1007/978-981-33-6546-9_39,The Categorization of Artificial Intelligence (AI) Based on the Autonomous Vehicles and Its Other Applications,Proceedings of International Conference on Communication and Artificial Intelligence,10.1007/978-981-33-6546-9_39,Springer,2021-01-01,2021-05-11,"The artificial intelligence (AI) is creating the great impacts and revolution in the technological world, education world, industry world, and business world. The concepts in artificial intelligence are improving themselves day by day, and it is becoming a part of human’s everyday activities. It plays a major role in the human life, and the situation becomes the people cannot live without this AI. In this book chapter, the categorization of artificial intelligence based on the autonomous vehicles and its other applications is to be discussed in brief. The artificial intelligence technique is based on the artificial neural network (ANN), machine learning (ML), deep neural network (DNN), recurrent neural network (RNN), and convolution neural network (CNN). To implement these types of neural network, the system should use the programming languages like MATLAB programming, Python programming, R programming, etc.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-6546-9_39,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-8377-3_18,Behavioral Cloning for Self-driving Cars Using Deep Learning,"Proceedings of International Conference on Big Data, Machine Learning and their Applications",10.1007/978-981-15-8377-3_18,Springer,2021-01-01,2020-12-23,"We are presenting a model for self-driving car simulator provided by Udacity as an open-source simulator. We will then use the simulator to create our own training data for our model which will be driving a car through training mode on its track in the simulator. We are taking images at each instance of the drive. These images are used as a training dataset, and the labels are steering angle for each specific image at that instance. We will then input all those images to our Nvidia’s convolutional neural network model and allow it to learn how to drive autonomously by learning from our behavior as the manual driver. Our main variable is the steering angle which our model learns to adjust at any given instance. Now, as our model is perfectly trained, we use autonomous mode to find the performance of our model by driving the car autonomously.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-8377-3_18,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-5329-5_30,Object and Obstacle Detection for Self-Driving Cars Using GoogLeNet and Deep Learning,Artificial Intelligence Techniques for Advanced Computing Applications,10.1007/978-981-15-5329-5_30,Springer,2021-01-01,2020-07-24,"Self-driving cars are the latest innovation in which the car runs by itself. The self-driving cars can be called as autonomous cars. This involves many technologies like artificial intelligence, machine learning and deep learning. When coming to the self-driving cars, the main aspect which it needed to be taken care of is the obstacle detection and the object detection. The object detection by a car in more simpler words object recognition process done by a machine which involves the concepts of machine learning and deep learning. Deep learning helps in achieving the object and the obstacle detection. There are various algorithms which help in the object detection like artificial neural network, convolutional neural network, AlexNet, VGG Net, GoogleNet, etc. GoogleNet is the CNN architecture which makes the image recognition an easier task. For the self-driving cars, obstacle and object detection GoogLeNet are not much addressed in the recent works. So, it can be considered as a latest technology. In this paper, the recent works about the self-driving cars and object detection and obstacle detection and the future scope of it are discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-5329-5_30,springer
Chapter ConferencePaper,doi:10.1007/978-981-33-6984-9_40,Attitude Control in Unmanned Aerial Vehicles Using Reinforcement Learning—A Survey,Congress on Intelligent Systems,10.1007/978-981-33-6984-9_40,Springer,2021-01-01,2021-06-02,"Agarwal, Varun Ranjan Tewari, Rajiv Unmanned Aerial Vehicles (UAVs) have great potential in various fields. With ongoing research, the day is not far when they would be directly impacting our lives. The promise of deep learning techniques like reinforcement learning has created a window of opportunity for their use in a plethora of tasks, like the attitude control problem of UAVs. Attitude of a UAV is the angle at which it is flying relative to the ground. Attitude control is the management of the orientation of a UAV with respect to the inertial frame. In this paper, we have surveyed reinforcement learning algorithms to learn attitude control of UAVs and be able to take decisions in unforeseen circumstances. Reinforcement learning is the branch of deep learning where there is no human intervention in training the model. Instead, the system learns over time by trial and error. Since navigation in the air presents scenarios that may be new and unexpected for a UAV, reinforcement learning presents a viable option for their use in attitude control in them.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-6984-9_40,springer
Chapter,doi:10.1007/978-3-030-52624-5_14,"Precision Agriculture Using Advanced Technology of IoT, Unmanned Aerial Vehicle, Augmented Reality, and Machine Learning",Smart Sensors for Industrial Internet of Things,10.1007/978-3-030-52624-5_14,Springer,2021-01-01,2021-02-02,"Agriculture is one of the primary processes for quality food production in the globe. Unfortunately, the productivity of agriculture is very low, and many factors affect the yield level of it. Precision agriculture (PA) is one of the solutions for the above problem. PA uses site-specific crop management concept based on measured data using sensors and data analytics to find the root cause of yield reduction. Precision agriculture automates farming which involves the collection of data and analysis of them for better decision-making to gain high yield and quality of the agricultural product. The agriculture system integrated with data analytics and machine learning is called as smart farming or smart agriculture The goal of smart agriculture is to develop a decision-making support system for farming management. The precision smart agriculture can be enhanced with the help of latest technologies of Internet of Technology (IoT), unmanned aerial vehicle (UAV), augmented reality (AR) system, and machine learning (ML) algorithms. This chapter focuses on the illustration and utilization of those advanced technologies for smart farming.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-52624-5_14,springer
Chapter ConferencePaper,doi:10.1007/978-981-16-2712-5_6,Low-Altitude Unmanned Aerial Vehicle for Real-Time Greenhouse Plant Disease Monitoring Using Convolutional Neural Network,Soft Computing for Problem Solving,10.1007/978-981-16-2712-5_6,Springer,2021-01-01,2021-10-14,"This study presents a novel approach to real-time plant infection detection and automatic pesticide spraying using an unmanned aerial vehicle (UAV) inside greenhouses. Greenhouse maintains controlled environments for plant growth, which is presently achieved by using conventional labor-driven methods that are proven to be inefficient causing lower yields. To overcome such difficulties and improve the yields, a multipurpose unmanned aerial vehicle capable of capturing vision data has been developed to detect infected areas and automatically spray useful chemicals based on the detection. Onboard the UAV is an edge device connected to environmental parameters sensors continuously uploading data to ThingSpeak. The IOT cloud platform provides real-time temperature and humidity of the precise location. In this research work, a fast-semantic segmentation algorithm called LinkNet-34 is employed for real-time segmentation of the infected region. The experimental results during manual flights indicate a detection accuracy of 0.922 (MIoU) with LinkNet-34. The UAV can achieve 14 min of flight-time while spraying 500 mm of pesticide over 42 m^2 area, during which time, a field map highlighting the infected regions is automatically generated and uploaded to the cloud for future analysis.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-2712-5_6,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-65283-8_22,Detection of Scenes Features for Path Following on a Local Map of a Mobile Robot Using Neural Networks,Recent Research in Control Engineering and Decision Making,10.1007/978-3-030-65283-8_22,Springer,2021-01-01,2020-12-02,"This article describes a software package for analyzing images from the camera of a mobile robot using neural networks. A key feature of the proposed solution is the model that generates recommendations for the robot about the direction of the further movement. This model receives raw video frames from the camera and generates a target rotation angle for the robot relative to the central axis of the robot, which must be followed at the next time in the control loop. Such a control loop is executed with a certain frequency in order to achieve the continuous adjustment of the robot’s driving direction to avoid collision with obstacles. A key feature of the proposed method is the high processing speed of video frames and acceptable quality. These characteristics are achieved due to the simple architecture of the neural network, without reinforcement learning, which is commonly used in robotics. The designed module can be used in addition to the existing navigation systems of a mobile robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-65283-8_22,springer
Chapter,doi:10.1007/978-3-030-77939-9_1,Deep Learning for Unmanned Autonomous Vehicles: A Comprehensive Review,Deep Learning for Unmanned Systems,10.1007/978-3-030-77939-9_1,Springer,2021-01-01,2021-10-02,"In recent years, deep learning as a subfield of machine learning has gained increasing attention due to its potential advantages in empowering autonomous systems with the ability to automatically learn underlying features in data at different levels of abstractions, to build complex concepts out of simpler ones and to get better with experience without being explicitly programmed. This book chapter provides a comprehensive review on the applications of deep learning in unmanned autonomous vehicles. We focus on particular research efforts that employ deep learning techniques to endow autonomous vehicles with different cognitive functionality, following the cognitive cycle of autonomous vehicles. This cognitive cycle of Sense-Aware-Decide-Act-Adapt-Learn extends the deliberative cycle of Sense-Decide-Act by adding situation awareness, adaptation and learning capabilities to autonomous vehicles. Potential applications of deep learning and major challenges are highlighted in this chapter.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77939-9_1,springer
Chapter,doi:10.1007/978-3-030-65661-4_4,Enhanced End-to-End System for Autonomous Driving Using Deep Convolutional Networks,Deep Learning and Big Data for Intelligent Transportation,10.1007/978-3-030-65661-4_4,Springer,2021-01-01,2021-04-11,"The emergence of autonomous cars in today’s world makes it imperative to develop superlative steering algorithms. Deep convolutional neural networks are widely adopted in vision problems for their adept nature to classify images. End-to-end models have acted as an excellent substitute for handcrafted feature extraction. This chapter’s proposed system, which comprises of steering angle prediction, road detection, road centering, and object detection, is a facilitated version of an autonomous steering system over just considering a single-blind end-to-end architecture. The benefits of proposing such an algorithm for the makeover of existing cars include reduced costs, increased safety, and increased mobility.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-65661-4_4,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-60577-3_14,Providing Situational Awareness in the Control of Unmanned Vehicles,"Advances in Neural Computation, Machine Learning, and Cognitive Research IV",10.1007/978-3-030-60577-3_14,Springer,2021-01-01,2020-10-02,"The article considers one of the aspects of the situational awareness problem for control systems of unmanned vehicles. We interpret this problem as getting information about the current situation in which, for example, an unmanned aerial vehicle (UAV) is operating. This information is required as source data for decision-making in the UAV behavior control process. One possible component of situational awareness is information about objects in the space surrounding the UAV. At the same time, it is important to know along which trajectories these objects move. Also, we need to predict the motion of the observed objects. We consider this task in the article as a formation example for one of the elements of situational awareness. To solve this problem, we prepare a data set using the FlightGear flight simulator. We extract from this set the training, validation, and test sets required to obtain a neural network that predicts the trajectory of the object being tracked. Then, based on the collected data that characterize the behavior of the desired object, we design a neural network model based on recurrent neural networks to solve the problem of predicting the trajectory of a dynamic object.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60577-3_14,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-70665-4_119,Machine Learning Based Approach for Weed Detection in Chilli Field Using RGB Images,"Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery",10.1007/978-3-030-70665-4_119,Springer,2021-01-01,2021-06-27,"Smart farming has become imperative these days due to competition, and use of Unmanned Aerial Vehicle (UAV) imagery is becoming an integral part of the process. Machine learning techniques have been successfully applied to capture UAV imagery of various spectral bands to identify weed infestations. Identification of weeds in chilli crop is a challenging task. In this paper, RGB images captured by drones have been used to detect weed in chilli field. This task has been addressed through orthomasaicking of images, feature extraction, labelling of images to train machine learning algorithms, and use of unsupervised learning with random forest for classification. MATLAB has been used for all computations and out-of-bag accuracy achieved for identifying weeds is 96 $$\%$$ % .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-70665-4_119,springer
Chapter ConferencePaper,doi:10.1007/978-981-16-1244-2_29,Obstacle Avoidance for Aerial Vehicles in Autonomous Navigation,International Virtual Conference on Industry 4.0,10.1007/978-981-16-1244-2_29,Springer,2021-01-01,2021-08-04,"Obstacle avoidance is the back bone of autonomous navigation as it enables vehicles to reach desired location avoiding hurdles in the path. It is one of the ongoing challenging researches in the arena of cyber physical systems. In this article, comparison of various obstacle avoidance algorithms such as Artificial Potential Field (APF) approach, Vector Field Histogram (VFH) approach, Bubble Band approach, Mounted Sonar approach, Dist-Bug approach, bug-1 and bug-2 approach and Tangent Bug approach has been addressed. The main objective is obstacle avoidance, where obstacle can be in the form of radars or any other type of equipment. A novel obstacle avoidance procedure for low-altitude flying vehicles (Static Obstacle Avoidance) and high-altitude flying vehicle (Dynamic Obstacle Avoidance) has been proposed using A-Star and Deep Q-Network Reinforcement Learning techniques, respectively. Test bed has been created considering object model, sensor model, obstacle environment and controller. Implementation of the same has been done through visualization using Pygame for A-Star approach and Director for Deep Q-Network Reinforcement Learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-1244-2_29,springer
Article,doi:10.1007/s10489-020-01827-9,Deep learning and control algorithms of direct perception for autonomous driving,Applied Intelligence,10.1007/s10489-020-01827-9,Springer,2021-01-01,2020-08-08,"We propose an end-to-end machine learning model that integrates multi-task (MT) learning, convolutional neural networks (CNNs), and control algorithms to achieve efficient inference and stable driving for self-driving cars. The CNN-MT model can simultaneously perform regression and classification tasks for estimating perception indicators and driving decisions, respectively, based on the direct perception paradigm of autonomous driving. The model can also be used to evaluate the inference efficiency and driving stability of different CNNs on the metrics of CNN’s size, complexity, accuracy, processing speed, and collision number, respectively, in a dynamic traffic. We also propose new algorithms for controllers to drive a car using the indicators and its short-range sensory data to avoid collisions in real-time testing. We collect a set of images from a camera of The Open Racing Car Simulator in various driving scenarios, train the model using this dataset, test it in unseen traffics, and find that it outperforms earlier models in highway traffic. The stability of end-to-end learning and self driving depends crucially on the dynamic interplay between CNN and control algorithms. The source code and data of this work are available on our website, which can be used as a simulation platform to evaluate different learning models on equal footing and quantify collisions precisely for further studies on autonomous driving.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-020-01827-9,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-1275-9_44,Autonomous Cars: Technical Challenges and a Solution to Blind Spot,Advances in Computational Intelligence and Communication Technology,10.1007/978-981-15-1275-9_44,Springer,2021-01-01,2020-06-19,"Automotive industry is progressing forward toward the future, where the role of driver is becoming smaller and leading to become ideally driverless. Designing a fully driverless car (DC) or self-driving car is a most challenging automation project, since we are trying to automate complex processing and decision-making of driving a heavy and fast-moving vehicle in public. There are many scenarios where self-driving cars are not able to perform like human drivers. There are a lot of technical, non-technical, ethical and moral challenges to be addressed. Furthermore, two recent accidents caused by self-driving cars of Uber [ 1 ] and Tesla [ 2 ] have raised a concern toward the readiness and safety of using these cars. Therefore, it is necessary to address these challenges and issues of DC’s. In this paper, we have surveyed various technical challenges and scenarios where DCs are still facing issues. We have also addressed an issue of blind spots and proposed a systematic solution to tackle the issue. Before self-driving cars go live on road, we have to overcome these challenges and work on technology barriers so that we can make the DCs safe and trustworthy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-1275-9_44,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-60577-3_19,Deep Neural Networks for Ortophoto-Based Vehicle Localization,"Advances in Neural Computation, Machine Learning, and Cognitive Research IV",10.1007/978-3-030-60577-3_19,Springer,2021-01-01,2020-10-02,"Navigation of unmanned vehicle especially using orthophoto is a topic of active research. This paper is dedicated to study of different methods of orthophoto-based localization methods. For this task new dataset was created. It consists of pairs of ground level and bird’s eye view images collected on vehicle test site of the technology contest Up Great “Winter City”. Different deep network approaches to localization were used: 1) embedding-based, 2) based on synthesis of bird’s eye view using Pix2pix conditional generative adversarial network and masked cross-correlation in map subwindow. The second approach has demonstrated good applicability for the proposed dataset. Mean absolute error of localization on known scenes reached 1 m. The average total time of bird’s eye view generation and subsequent localization is from 0.1 s to 0.2 s. This is an acceptable quality for the task solution and its further use as part of the navigation systems of unmanned vehicles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60577-3_19,springer
Chapter,doi:10.1007/978-3-030-59897-6_8,Artificial Intelligence and Sensor Technology in the Automotive Industry: An Overview,Automotive Embedded Systems,10.1007/978-3-030-59897-6_8,Springer,2021-01-01,2021-04-25,"Recently, artificial intelligence (AI) has contributed a key role in the field of automotive industry in the form of self-driving cars or automated vehicles (AV) with innovative features. The automotive industry is driven by various potential technologies such as sensor technology, communication techniques, machine learning and deep learning algorithms. Using AI, a lot of innovative products and applications have been developed in the automotive industry and they have reduced most of the human errors such as aggressive driving, accidents and traffic collisions, etc. This article explores AI-based applications in the automotive industry and also discusses relevant algorithms behind this new era of AV. Moreover, this article investigates the role of sensors and actuators which are the prime requisite of building an AV. This also discusses the challenges involved in the AV.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-59897-6_8,springer
Chapter ConferencePaper,doi:10.1007/978-981-16-7502-7_7,Anti Intelligent Mine Unmanned Ground Vehicle Based on Reinforcement Learning,Data Mining and Big Data,10.1007/978-981-16-7502-7_7,Springer,2021-01-01,2021-10-30,"In recent years, with the rapid development of military technology and the evolution of battlefield mines, intelligent mines are the important embodiment of active attack mines. In the future, unmanned vehicles need to chase and capture intelligent mines, improve the efficiency of mine clearance, and reduce the casualties of soldiers. Therefore, it is necessary to study how to improve the efficiency of unmanned ground vehicle pursuit. Among them, the game method of pursuit and evasion between intelligent mines and unmanned ground vehicles based on reinforcement learning in the 2D simulation environment can effectively achieve this goal. The trained intelligent mines have active attack ability, unmanned ground vehicles have basic mine clearance ability, and the success rate of intelligent mine blasting is as high as 90%. In addition, unmanned ground vehicles can also effectively defend against the active attack of intelligent mines, and the defense success rate is also as high as 90%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7502-7_7,springer
Chapter ConferencePaper,doi:10.1007/978-981-16-1483-5_23,A Deep Learning Approach for Autonomous Navigation of UAV,Futuristic Trends in Network and Communication Technologies,10.1007/978-981-16-1483-5_23,Springer,2021-01-01,2021-03-31,"Unmanned Aerial Vehicle is an aircraft that operates and flies without a human pilot. It can reach at places where humans may not reach easily, such as search and rescue operations, earthquake mapping and flood mapping. It is additionally valuable for autonomous tasks such as the delivery of any item and target tracking which requires self-governing navigation. Motivated by the mentioned applications, in this paper we present a deep learning model for self-governing navigation of UAV. Our model exploits transfer learning from a well-known network architecture called MobileNet and it is trained on a dataset of images, collected from the various indoor environments. From an image, the model classifies actions such as either to go forward or to stop. Furthermore, after some experiments and results, we infer that among all Convolution Neural Network (CNN) architectures, the MobileNet architecture is ideal and appropriate for our purposed approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-1483-5_23,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-53669-5_16,UAV Autonomous Navigation by Image Processing with Uncertainty Trajectory Estimation,Proceedings of the 5th International Symposium on Uncertainty Quantification and Stochastic Modelling,10.1007/978-3-030-53669-5_16,Springer,2021-01-01,2020-08-20,"Unmanned Aerial Vehicles (UAV) is a technology under strong development, with application on several fields. For the UAV autonomous navigation, a standard scheme is to use signal from a Global Navigation System by Satellite (GNSS) onboard. However, such signal can suffer natural or human interference. Our approach applies image processing procedure for the UAV positioning: image edge extraction and correlation between drone image and georeferenced satellite image. A data fusion is also applied, for combining the inertial sensor data and positioning by image. The data fusion is performed by using neural network. The output from the data fusion neural network is the correction for the UAV trajectory. Here, the variance of the trajectory error is also predicted to quantify the uncertainty.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-53669-5_16,springer
Chapter,doi:10.1007/978-3-030-72065-0_18,Artificial Intelligence Techniques in Smart Cities Surveillance Using UAVs: A Survey,Machine Intelligence and Data Analytics for Sustainable Future Smart Cities,10.1007/978-3-030-72065-0_18,Springer,2021-01-01,2021-06-01,"The security and urbanization challenge is expected to rise to 90% by 2050, and to leverage existing resources, technology is the solitary means to cope with this anticipated raise in entail. The Smart City is focused on the smooth convergence of Information and Communication Technology with the most technological innovations like well-connected home and equipment. Smart city augments the lifestyle of its residents by providing efficacious infrastructure and enhanced security. Surveillance is a recurring and monotonous assignment that descends the performance of human guards when continued for a longer period of time. Unmanned Aerial Vehicles (UAVs) or Drones can be deployed as security cameras to augment human guards. It can be deployed to track intruders, monitor unusual activities such as theft, violence and unprecedented corona-virus pandemic scenarios. UAV based visual surveillance in Smart cities, produces a huge amount of multimedia data. The need to process and analyze the data automatically in real-time is critical. Artificial Intelligence and Deep learning imitates human intelligence and provides excellent analytical capabilities to learn about complex data obtained in real environments. The integrated solution of Deep learning technology with the UAVs an electronic eye-in-the-sky has leveraged the capability of detection, recognition and deterrence in a scalable surveillance system. A comprehensive review on the potential benefits of UAVs and its applications for surveillance in smart cities has been presented. This chapter elaborates seamless integration of UAVs and Deep Learning technologies solutions for smart city surveillance. The paper concludes with a description of main challenges for the application of UAVs in deep learning solutions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-72065-0_18,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-53980-1_112,3D Modeling System of Lidar Point Cloud Processing Algorithm Based on Artificial Intelligence,2020 International Conference on Applications and Techniques in Cyber Intelligence,10.1007/978-3-030-53980-1_112,Springer,2021-01-01,2020-08-13,"With the continuous expansion of the application field of artificial intelligence-based unmanned vehicles and the rapid development of lidar scanning technology, the application of lidar gradually spread to many artificial intelligence-based unmanned vehicles such as environmental perception, augmented reality, and environmental modeling Technology area. Therefore, the research of lidar in the application of artificial intelligence-based unmanned vehicles has become an inevitable trend in the field of unmanned vehicles. At the same time, the research of lidar data processing technology is of great significance to the development of artificial intelligence unmanned vehicles. This article is based on the research of lidar-based 3D environment modeling technology based on lidar. The research content mainly involves vehicle lidar point cloud 3D environment modeling method, adaptive lidar point cloud data matching algorithm, lidar point cloud-based 3D map modeling application. Through theoretical research and experimental verification of related technical issues, an in-depth study of the three-dimensional terrain modeling technology of unmanned vehicles based on artificial intelligence based on lidar is carried out. This paper proposes a three-dimensional environment modeling method for vehicle lidar point cloud. First, preprocessing processes such as data filtering and terrain segmentation are performed on the original lidar data, and then a three-dimensional geometric model of the environment including surface obstacles and terrain is established through data interpolation and gridding. The verification of the measured data on the typical environment shows the effectiveness of the method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-53980-1_112,springer
Chapter ConferencePaper,doi:10.1007/978-981-16-0041-8_16,It is not a Driverless Car!—A Framework for Interacting with the AI in Autonomous Vehicles,Design for Tomorrow—Volume 1,10.1007/978-981-16-0041-8_16,Springer,2021-01-01,2021-04-27,"With autonomous vehicles (AV) fast becoming a reality, in the not so distant future, streets are expected to be populated with these intelligent autonomous beings ferrying passengers alongside human-driven vehicles and pedestrians. The bulk of research today seems to focus on setting up the required software and hardware systems, alongside policies and transportation infrastructure. A gap is seen to exist within the realm where the passengers and vehicle AI interface. This calls for research in developing capabilities for the AI in AVs a form of social transactions that are more familiar to human beings, taking cues from natural conversations and body language signals. The reason for this is that autonomous vehicles not only need to perform navigational duties, but also need to communicate, respond, and reciprocate in a social manner. This would give the AI the dignity they deserve when performing their functions, as performing these activities accords with the capabilities of a self-aware, intelligent being. This paper proposes a framework for future communication between autonomous vehicles and humans, focusing on the working relationship between the vehicle and its passengers taking references of the communications theory related to human-to-human interactions, extrapolating to human-to-AI interaction within the AV.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-0041-8_16,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-78459-1_18,Smart UAV Monitoring System for Parking Supervision,Future Access Enablers for Ubiquitous and Intelligent Infrastructures,10.1007/978-3-030-78459-1_18,Springer,2021-01-01,2021-06-20,"Unmanned Aerial Vehicles (UAVs), or drones, are used in the field of remote collection of images at the time of flight. They can also detect irregularities in vehicle parking and issue fines in case of parking violations. The parking monitoring system uses real-time visual information. In this paper, the proposed solution is for real-time monitoring of areas and detecting irregularities in-vehicle parking using a fleet of drones. In this study, a camera mounted on UAVs applies for taking pictures of public areas at predetermined points. For monitoring of area will be used Observer UAVs while for detection will be used, Inspector UAVs. Visual information collected with UAVs is used to detect irregularities in vehicle parking, while the processing of collected data is performed by an artificial neural network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-78459-1_18,springer
Chapter,doi:10.1007/978-3-030-54173-6_11,Designing Robots for the Battlefield: State of the Art,"Robotics, AI, and Humanity",10.1007/978-3-030-54173-6_11,Springer,2021-01-01,2021-02-13,"There is currently a global arms race for the development of artificial intelligence (AI) and unmanned robotic systems that are empowered by AI (AI-robots). This paper examines the current use of AI-robots on the battlefield and offers a framework for understanding AI and AI-robots. It examines the limitations and risks of AI-robots on the battlefield and posits the future direction of battlefield AI-robots. It then presents research performed at the Johns Hopkins University Applied Physics Laboratory (JHU/APL) related to the development, testing, and control of AI-robots, as well as JHU/APL work on human trust of autonomy and developing self-regulating and ethical robotic systems. Finally, it examines multiple possible future paths for the relationship between humans and AI-robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-54173-6_11,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-77626-8_35,Drone-Based AI and 3D Reconstruction for Digital Twin Augmentation,Social Computing and Social Media: Experience Design and Social Network Analysis,10.1007/978-3-030-77626-8_35,Springer,2021-01-01,2021-07-03,"Digital Twin is an emerging technology at the forefront of Industry 4.0, with the ultimate goal of combining the physical space and the virtual space. To date, the Digital Twin concept has been applied in many engineering fields, providing useful insights in the areas of engineering design, manufacturing, automation, and construction industry. While the nexus of various technologies opens up new opportunities with Digital Twin, the technology requires a framework to integrate the different technologies, such as the Building Information Model used in the Building and Construction industry. In this work, an Information Fusion framework is proposed to seamlessly fuse heterogeneous components in a Digital Twin framework from the variety of technologies involved. This study aims to augment Digital Twin in buildings with the use of AI and 3D reconstruction empowered by unmanned aviation vehicles. We proposed a drone-based Digital Twin augmentation framework with reusable and customisable components. A proof of concept is also developed, and extensive evaluation is conducted for 3D reconstruction and applications of AI for defect detection.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77626-8_35,springer
Chapter,doi:10.1007/978-981-33-6726-5_3,Reinforcement Learning Based Communication Security for Unmanned Aerial Vehicles,Cyber Security Meets Machine Learning,10.1007/978-981-33-6726-5_3,Springer,2021-01-01,2021-01-22,"With the rapid development of unmanned aerial vehicles (UAVs) in communications, networking, and sensing applications, UAVs have gained considerable research interest in the last decade. Although UAV applications have been widely applied in many different fields, especially the military surveillance and environment monitoring, UAV communication process is not sufficiently safe due to jamming attacks. By imposing jamming signals on the controller during the communication process of the drones, a jammer can interfere with the sensing data reception of the controller, exhaust the drone battery, or keep the drone from following the specified sensing mission waypoint.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-6726-5_3,springer
Article,doi:10.1007/s10514-020-09951-8,Deep reinforcement learning for quadrotor path following with adaptive velocity,Autonomous Robots,10.1007/s10514-020-09951-8,Springer,2021-01-01,2020-10-24,"This paper proposes a solution for the path following problem of a quadrotor vehicle based on deep reinforcement learning theory. Three different approaches implementing the Deep Deterministic Policy Gradient algorithm are presented. Each approach emerges as an improved version of the preceding one. The first approach uses only instantaneous information of the path for solving the problem. The second approach includes a structure that allows the agent to anticipate to the curves. The third agent is capable to compute the optimal velocity according to the path’s shape. A training framework that combines the tensorflow-python environment with Gazebo-ROS using the RotorS simulator is built. The three agents are tested in RotorS and experimentally with the Asctec Hummingbird quadrotor. Experimental results prove the validity of the agents, which are able to achieve a generalized solution for the path following problem.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-020-09951-8,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-69066-3_22,Delay Minimization in Multi-UAV Assisted Wireless Networks: A Reinforcement Learning Approach,Artificial Intelligence for Communications and Networks,10.1007/978-3-030-69066-3_22,Springer,2021-01-01,2021-02-19,"Unmanned Aerial Vehicles (UAVs) assisted communications are promising technology for meeting the demand of unprecedented demands for wireless services. In this paper, we propose a novel framework for delay minimization driven deployment of multiple UAVs. The problem of joint non-convex three dimensional (3D) deployment for minimizing average delay is formulated and solved by Deep Q network (DQN), which is a reinforcement learning based algorithm. Firstly, we obtain the cell partition by K-means algorithm. Then, we find the optimal 3D position for each UAV in each cluster to provide low delay service. Finally, when users are roaming, the UAVs are still able to track the real-time users. Numerical results show that the proposed DQN-based delay algorithm shows a fast convergence after a small number of iterations. Additionally, the proposed deployment algorithm outperforms several benchmarks in terms of average delay.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-69066-3_22,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-69069-4_36,Collaborative Interference Source Search and Localization Based on Reinforcement Learning and Two-Stage Clustering,Wireless and Satellite Systems,10.1007/978-3-030-69069-4_36,Springer,2021-01-01,2021-02-28,"Exploiting unmanned aerial vehicles (UAVs) to locate the position of interferences has attracted intensive research interests, due to UAVs’ flexibility and the feature of suffering less multi-path interference. However, in order to find the position of an interference source, off-the-shelf Q-learning-based schemes require the UAV to keep searching until it arrives at the target. This obviously degrades time efficiency of localization. To balance the accuracy and the efficiency of searching and localization, this paper proposes a collaborative search and localization approach, where search and remote localization are iteratively performed with a swarm of UAVs. For searching, a low-complexity reinforcement learning algorithm is proposed to decide the direction of flight (in every time interval) for each UAV. In the following remote localization phase, a two-stage clustering algorithm is proposed to estimate the position of the interference source, by processing intersections of the extensions of UAVs’ trajectories. Numerical results reveal that in the proposed collaborative search and localization scheme, the proposed reinforcement-learning-based searching can benefit the collaborative localization, in terms of the accuracy of localization. Moreover, compared to the Q-learning-based approach, the proposed approach enables remote localization and can well balance accuracy, the robustness and time efficiency of localization.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-69069-4_36,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-51295-8_76,Unmanned Aerial Vehicles and Digital Image Processing with Deep Learning for the Detection of Pathological Manifestations on Facades,Proceedings of the 18th International Conference on Computing in Civil and Building Engineering,10.1007/978-3-030-51295-8_76,Springer,2021-01-01,2020-07-14,"In the diagnosis phase of pathological manifestations in facades, the visual inspection stage deserves special attention due to its inherent complexity (height, size, access difficulties and exposure conditions). In recent years, the use of deep learning techniques to detect and classify specific features in images and videos has been increasing, which when combined with the use of Unmanned Aerial Vehicles (UAVs) for capturing images, is a potential useful tool that can assist and automate the visual inspection procedure of facades. This paper aimed to perform the analysis of Digital Image Processing (DIP) for automatic detection of cracks in building ceramic tiles, associated with UAV, which would potentially result in benefits (time, cost and safety) with respect to diagnosis. Thus, the research results showed the technical feasibility of detection of cracks by DIP techniques, however, the main limitation for this purpose is the lack of a dataset of images of pathological manifestations in facades publicly available, restricting the computer learning process and consequently compromising the recognition capacity. Still, the project was able to develop a simple and efficient methodology to what was proposed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-51295-8_76,springer
Chapter,doi:10.1007/978-3-030-71998-2_8,Location Intelligence Powered by Machine Learning Automation for Mapping Malaria Mosquito Habitats Employing an Unmanned Aerial Vehicle (UAV) for Implementing “Seek and Destroy” for Commercial Roadside Ditch Foci and Real Time Larviciding Rock Pit Quarry Habitats in Peri-Domestic Agro-Pastureland Ecosystems in Northern Uganda,Sensemaking for Security,10.1007/978-3-030-71998-2_8,Springer,2021-01-01,2021-06-01,"Public health emergencies stemming from infectious disease outbreaks is creating a serious threat to global health security. For example, climate change and extreme weather events threaten to alter and affect geographic areas pertaining to disease vulnerability, such as greater risks of mosquito-borne diseases (dengue, malaria, yellow fever and Zika). The emergence of these disease outbreaks and their influence globally has sparked a renewed attention on global health security and the application of location intelligence. Persistent outbreaks characterize a ‘new normal’ that points to major deficiencies in preparedness, response and recovery initiatives. Malaria mosquito An. gambiae s.l., arabiensis s.s. and funestus s.s represent the main malaria mosquito vectors in sub-Saharan Africa. As reported in WHO (Jacob et al. in Open Remote Sensing 17:11–24, [ 1 ]), Malaria is a life-threatening disease caused by parasites that are transmitted to people through the bites of infected female Anopheles mosquitoes. It is preventable and curable. In 2019, there were an estimated 229 million cases of malaria worldwide. The estimated number of malaria deaths stood at 409,000 in 2019. Children aged under 5 years are the most vulnerable group affected by malaria; in 2019, they accounted for 67% (274,000) of all malaria deaths worldwide. The WHO African Region carries a disproportionately high share of the global malaria burden. In 2019, the region was home to 94% of malaria cases and deaths. Sensemaking lies at the heart of location intelligence. Location intelligence is defined as the collection and analysis of geospatial data that are transformed into strategic insights to support operations. Weick (Krizhevsky et al. in Advances in Neural Information Processing Systems, pp 1097–1105, [ 2 ]) refers to sensemaking in terms of ‘…how we structure the unknown so as to be able to act in it. Sensemaking involves coming up with a plausible understanding—a map—of a shifting world; testing this map with others through data collection, action, and conversation; and then refining, or abandoning, the map depending on how credible it is’ (Lin et al. in Proceedings of the IEEE International Conference on Computer Vision 2017, pp. 2980–2988, [ 3 ]). The application of machine learning algorithms are emerging as key public health intelligence approaches to support tactical, operational and strategic sensemaking. Recent advances that identify the reflective signatures of active mosquito breeding sites, and their temporal evolution, have made predictive algorithms possible to search and identify previously unidentified larval habitats from a Unmanned Aerial Vehicle (UAV), and monitor their activity in real time. Spectral signature is the variation of reflectance of a material (i.e., emittance as a function of wavelength) ( www.esri.com ). These real time aerial surveys can provide spatiotemporal data for targeting interventions to eliminate vectors before they become adult airborne biting mosquitoes, to reduce malaria transmission. Reference capture point habitats for Anopheles gambiae s.l., An. arabiensis s.s. and An. funestus s.s, the main malaria mosquito vectors in sub- Saharan Africa [ www.who.int ], may also be separately identified with this methodology. This chapter points to the application of predictive algorithms coupled with drone surveillance to support sensemaking in support of spatiotemporal data for targeting interventions to eliminate vectors before they become adult airborne biting mosquitoes, to reduce malaria transmission. The sensemaking applies not only to the targeted interventions to eliminate vectors, but also strategic sensemaking that contextualizes this intervention as part of a more holistic/systemic and strategic intervention encompassing a myriad of coordinated interventions across the disaster management spectrum (mitigation, preparedness, response, recovery).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-71998-2_8,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-79157-5_19,A Multimodal AI-Leveraged Counter-UAV Framework for Diverse Environments,Artificial Intelligence Applications and Innovations. AIAI 2021 IFIP WG 12.5 International Workshops,10.1007/978-3-030-79157-5_19,Springer,2021-01-01,2021-06-22,"Unmanned Aerial Vehicles (UAVs) have become a major part of everyday life, as well as an emerging research field, by establishing their versatility in a variety of applications. Nevertheless, this rapid spread of UAVs reputation has provoked serious security issues that can probably affect homeland security. Defence communities have started to investigate large field-of-view sensor-based methods to enable various civil protection applications, including the detection and localisation of flying threat objects. Counter-UAV (c-UAV) detection challenges may be granted from a fusion of sensors to enhance the confidence of flying threats identification. The real-time monitoring of the environment is absolutely rigorous and demands accurate methods to detect promptly the occurrence of harmful conditions. Deep learning (DL) based techniques are capable of tackling the challenges that are associated with generic objects detection and explicitly UAV identification. In this paper, we present a novel multimodal DL methodology that combines data from individual unimodal approaches that are associated with UAV detection. Specifically, this work aims to identify and classify potential targets of UAVs based on fusion methods in two different cases of operational environments, i.e. rural and urban scenarios. A dedicated architecture is designed based on the development of deep neural networks (DNNs) frameworks that has been trained and validated employing real UAV flights scenarios. The proposed approach has achieved prominent detection accuracies over different background environments, exhibiting potential employment even in major defence applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-79157-5_19,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-79157-5_19,A Multimodal AI-Leveraged Counter-UAV Framework for Diverse Environments,Artificial Intelligence Applications and Innovations. AIAI 2021 IFIP WG 12.5 International Workshops,10.1007/978-3-030-79157-5_19,Springer,2021-01-01,2021-06-22,"Unmanned Aerial Vehicles (UAVs) have become a major part of everyday life, as well as an emerging research field, by establishing their versatility in a variety of applications. Nevertheless, this rapid spread of UAVs reputation has provoked serious security issues that can probably affect homeland security. Defence communities have started to investigate large field-of-view sensor-based methods to enable various civil protection applications, including the detection and localisation of flying threat objects. Counter-UAV (c-UAV) detection challenges may be granted from a fusion of sensors to enhance the confidence of flying threats identification. The real-time monitoring of the environment is absolutely rigorous and demands accurate methods to detect promptly the occurrence of harmful conditions. Deep learning (DL) based techniques are capable of tackling the challenges that are associated with generic objects detection and explicitly UAV identification. In this paper, we present a novel multimodal DL methodology that combines data from individual unimodal approaches that are associated with UAV detection. Specifically, this work aims to identify and classify potential targets of UAVs based on fusion methods in two different cases of operational environments, i.e. rural and urban scenarios. A dedicated architecture is designed based on the development of deep neural networks (DNNs) frameworks that has been trained and validated employing real UAV flights scenarios. The proposed approach has achieved prominent detection accuracies over different background environments, exhibiting potential employment even in major defence applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-79157-5_19,springer
Chapter ConferencePaper,doi:10.1007/978-981-16-1086-8_42,Crop Classification from UAV-Based Multi-spectral Images Using Deep Learning,Computer Vision and Image Processing,10.1007/978-981-16-1086-8_42,Springer,2021-01-01,2021-03-26,"This work explores the suitability of various deep convolutional neural network (CNN) architectures for semantic segmentation of agricultural crops such as cotton, maize etc. from multi-spectral UAV (unmanned aerial vehicle) data. Initially, the UAV data were preprocessed and training samples for each crop type were manually annotated from multiple UAV scenes. Different CNN architectures such as U-Net, SegNet and PSPNet (Pyramid Scene Parsing Network) were trained with various combinations of input spectral bands along with select band derived indices such as NDVI (Normalized Difference Vegetation Index) and EVI (Enhanced Vegetation Index) as additional features. The experimental results indicated that inclusion of NIR (near-infrared) band and NDVI in the input data yielded high segmentation accuracy of more than 90%. U-Net proved to be the best among the three architectures with 97% overall accuracy while dealing with three classes separation problem. This study demonstrated the scope of deep neural network based semantic segmentation techniques in crop classification from multi-spectral UAV data.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-1086-8_42,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-86702-7_9,Heterogeneous Acoustic Features Space for Automatic Classification of Drone Audio Signals,Applied Computer Sciences in Engineering,10.1007/978-3-030-86702-7_9,Springer,2021-01-01,2021-09-29,"The incremented use of unmanned aerial vehicles (UAV) in recent years, have leaded to security flaws that demand a solution oriented to UAV monitoring. An attractive solution to this problem is based on the analysis of UAV audio signals. Such approach aims to extract a set of acoustic features and to use them as inputs of machine learning algorithms. Current works on this topic are mainly focused in using a specific set of acoustic features, such as linear prediction and cepstral metrics. However, relevant UAV acoustic information may be missing by considering a single type of features. In this work, we propose a heterogenous acoustic features space for solving UAV automatic classification problems. Temporal, spectral and time-frequency analysis are implemented to extract features from UAV audio signals and thus building a high dimensional features space. By applying features selection techniques, the most relevant acoustic features are identified and they are used to train machine learning algorithms. Our results show that, the heterogeneous features space yields high performance in automatic UAV classification tasks of binary and multiclass type. The classification results outperform the overall classification performance of other studies using set of homogeneous features. Furthermore, the metrics extracted using the wavelet packet transform are the most prevalent in the features spaces that yield the best classification results for the binary and muticlass classification tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-86702-7_9,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-88081-1_44,Semantic Segmentation of Small Region of Interest for Agricultural Research Applications,Computational Collective Intelligence,10.1007/978-3-030-88081-1_44,Springer,2021-01-01,2021-09-30,"The artificial intelligence and, in particular, the artificial neural networks proved to be useful tools in the field of computer vision, with promising results of applications in various domains, such as: industry, agriculture, medicine, transport, and environment . Detecting and locating crops using images received from aerial robots can make a positive contribution to assessing possible damage, reducing losses and minimizing analysis time . The paper proposed different implementation of the conditional generative adversarial network to better accomplish the task of semantic segmentation the agricultural region of interest . To this end the images were acquired by unmanned aerial vehicles. The network consists of a generator built using the U-Net architecture model and a discriminator that provides a probability matrix for each prediction, the elements of the matrix corresponding to portions of the input image . The resulting model, implemented with GPU processors provided by Google, performs a binary segmentation of images to determine the areas containing crops. The results of five experiments obtained, in the best configuration of hyper-parameters tested, an average accuracy of 97.93% in relation to reference (manual) segmentation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-88081-1_44,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-6403-1_20,The Importance of Applying Artificial Intelligence on Unmanned Aerial Vehicle,Proceedings of the 4th International Conference on Electrical Engineering and Control Applications,10.1007/978-981-15-6403-1_20,Springer,2021-01-01,2020-09-30,"Unmanned Aerial Vehicles (UAVs) are used in several applications and they are growing in popularity. Recent progress in unmanned aerial vehicles and artificial intelligence constitutes a new chance for an autonomous operation and flight. Nowadays, artificial intelligence and deep learning are driving the evolution of UAVs and fueling their autonomous future. Computer vision achieved very important progress in image classification and segmentation, and object detection, which make it very attractive research field when it is applied on unmanned aerial vehicle. Artificial intelligence is not only important and benefic, but can be rather, dangerous and serious matter since the UAVs learns through algorithms, and use that for future decision making. This work is a survey, where we present works, challenges and dangerous part of using artificial intelligence on UAVs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-6403-1_20,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-78459-1_19,Object Detection and Mapping with Unmanned Aerial Vehicles Using Convolutional Neural Networks,Future Access Enablers for Ubiquitous and Intelligent Infrastructures,10.1007/978-3-030-78459-1_19,Springer,2021-01-01,2021-06-20,"Significant progress has been made in the field of deep learning through intensive research over the last decade. So-called convolutional neural networks are an essential component of this research. In this type of neural network, the mathematical convolution operator is used to extract characteristics or anomalies. The purpose of this work is to investigate the extent to which it is possible in certain initial settings to input aerial recordings and flight data of Unmanned Aerial Vehicles (UAVs) in the architecture of a neural network and to detect and map an object. Using the calculated contours or dimensions of the so-called bounding boxes, the position of the objects can be determined relative to the current UAV location.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-78459-1_19,springer
Chapter,doi:10.1007/978-3-030-60188-1_4,"Digital Transformation and Emerging Technologies for COVID-19 Pandemic: Social, Global, and Industry Perspectives",Artificial Intelligence and Machine Learning for COVID-19,10.1007/978-3-030-60188-1_4,Springer,2021-01-01,2021-02-20,"COVID-19 disease pandemic is affecting the lives of millions of people in one or another manner. To handle the COVID-19 pandemic situation, technological aspects play a vital role in parallel to medical and healthcare facilities. With the use of existing infrastructure, technologies such as artificial intelligence, neural network, blockchain technology, cloud computing, drone-based monitoring, etc. have given the important observations and awareness to many. It is observed that with the combined efforts of technology and healthcare system, recognition of the outbreak is much faster compared to earlier infections. However, many are working continuously to collect and analyze the available COVID-19-related data and introspect the future. The whole of this work is performed to maximize the use of technology and reduce the risk of a continuous outbreak. This work has discussed the recent work done over the use of technologies in handling the COVID-19 scenario. Here, a comparative analysis of various parameters in each technological aspect is discussed to have an understanding of the preferred approaches in different places. Further, brief surveys are conducted in each technological aspect for a better understanding of technological advantage in handling pandemic.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60188-1_4,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-79997-7_6,Lethal Autonomous Weapon Systems: An Advocacy Paper,"Advances in Human Factors in Robots, Unmanned Systems and Cybersecurity",10.1007/978-3-030-79997-7_6,Springer,2021-01-01,2021-06-27,"Some countries, human rights organizations, artificial intelligence experts and academics have expressed doubts about the moral, ethical, and legal development and use of Lethal Autonomous Weapon Systems (LAWS). The United States, United Kingdom, Israel, Russia and many other countries have disagreed with these concerns. This paper will argue that (1) LAWS already exist and are in use by many countries for both defensive and offensive purposes and (2) LAWS cannot be legislated away; the technology is pervasive from smart cars and autonomous ships to military self-protection systems. As long as countries and their respective militaries follow internationally accepted norms when using LAWS such as the Laws of War, principles of war, and have a systematic legal review process, militaries will have the sufficient and necessary controls to address those who criticize and oppose their development and use.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-79997-7_6,springer
Chapter,doi:10.1007/978-3-030-53532-2_1,Challenges in the Realm of Embedded Real-Time Image Processing,Towards Ubiquitous Low-power Image Processing Platforms,10.1007/978-3-030-53532-2_1,Springer,2021-01-01,2020-12-16,"The development of power-efficient solutions gives new embedded products the ability to analyse images and thereby brings more intelligence to embedded systems—providing more and better services of higher quality as well as advanced capabilities such as self-adaptation and autonomy. This will allow cars to drive safer, medical devices to assist surgeons, and autonomous drones to find people that have gotten lost. For small-series products, one needs to find an embedded platform that provides enough performance, does not exceed the target price, and has sufficiently low-power consumption. As these requirements are typically conflicting, image processing engineers spend considerable time identifying the best possible trade-off for their algorithm implementation on the chosen platform. Providing a common platform that allows the efficient implementation of image processing systems across diverse application domains—a key objective of our Tulipp project—requires a solid understanding of the constraints and challenges of each domain. In this paper, we report the key challenges we identified within the medical, Unmanned Aerial Vehicle (UAV), and automotive domains to aid the community in developing the next generation of embedded image processing systems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-53532-2_1,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-55180-3_44,Drone-Based Cattle Detection Using Deep Neural Networks,Intelligent Systems and Applications,10.1007/978-3-030-55180-3_44,Springer,2021-01-01,2020-08-25,"Cattle form an important source of farming in many countries. In literature, several attempts have been conducted to detect farm animals for different applications and purposes. However, these approaches have been based on detecting animals from images captured from ground level and most approaches use traditional machine learning approaches for their automated detection. In this modern era, Drones facilitate accessing images in challenging environments and scanning large-scale areas with minimum time, which enables many new applications to be established. Considering the fact that drones typically are flown at high altitude to facilitate coverage of large areas within a short time, the captured object size tend to be small and hence this significantly challenges the possible use of traditional machine learning algorithms for object detection. This research proposes a novel methodology to detect cattle in farms established in desert areas using Deep Neural Networks. We propose to detect animals based on a ‘group-of-animals’ concept and associated features in which different group sizes and animal density distribution are used. Two state-of-the-art Convolutional Neural Network (CNN ) architectures, SSD-500 and YOLO V-3, are effectively configured, trained and used for the purpose and their performance efficiencies are compared. The results demonstrate the capability of the two generated CNN models to detect groups-of-animals in which the highest accuracy recorded was when using SSD-500 giving a F-score of 0.93, accuracy of 0.89 and mAP rate of 84.7.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-55180-3_44,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-74728-2_3,Palm Tree Detection in Drone Images Using Deep Convolutional Neural Networks: Investigating the Effective Use of YOLO V3,Digital Interaction and Machine Intelligence,10.1007/978-3-030-74728-2_3,Springer,2021-01-01,2021-06-26,"Owing to the agricultural and economic importance to many countries, computer based automated palm-tree detection from aerial images, has been an area of research significance to the computer vision research community worldwide. Most previous approaches have applied traditional machine learning algorithms for palm-tree detection. However, in the recent past, deep neural network based learning has been proven to be a far more superior approach for general object detection and recognition tasks in many application areas. Alongside this technological development lightweight UAVs, e.g. Drones , have been widely accepted as having great practical potential and economic benefit in the surveillance of large areas of land, in significantly higher resolution, as compared to the traditional use of satellite images or more expensive large UAVs. This research presents a novel methodology based on the latest YOLO Version-3 Convolutional Neural Network object detector for detecting palm-trees in drone images captured in a desert area that includes palm-trees of different sizes, resolution, ground spread, degree of overlap, etc. In particular, we discuss the specific training strategy adopted and hyper-parameter optimisations carried out to improve the accuracy from a modest 0.78 to 0.96.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-74728-2_3,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-70665-4_96,Semantic 3D Scene Classification Based on Holoscopic 3D Camera for Autonomous Vehicles,"Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery",10.1007/978-3-030-70665-4_96,Springer,2021-01-01,2021-06-27,"An autonomous vehicle navigates by perceiving the environment through the sensors and acting on the received data by making sense of the surroundings. In this paper, innovative holoscopic 3D scene classification based on the single aperture holoscopic 3D camera is proposed to recognise continuous 3D scene of environment. The deep learning network AlexNet is used to evaluate the proposed approach, and the outcome exhibits promising results compared to 2D images.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-70665-4_96,springer
Chapter,doi:10.1007/978-3-030-81907-1_19,Autonomous Vehicles: From Whether and When to Where and How,"Ethics, Governance, and Policies in Artificial Intelligence",10.1007/978-3-030-81907-1_19,Springer,2021-01-01,2021-11-03,"Mobility is an essential component of life in any society, so a transformation of mobility will affect the foundations of any society, and it is hard to imagine a more profound transformation of mobility than autonomous driving. This is why understanding attitudes towards the benefits and shortcomings of autonomous vehicles means being able to address societal welfare and individual well-being more successfully. In this chapter I argue that digital technologies have made it possible to detach the journey from the trip. It seems that, in the near future, we may be increasingly able to enjoy trips rather than journeys, with more freedom to choose to travel because we want to rather than because we need to.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-81907-1_19,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-63128-4_22,"The Impact of Artificial Intelligence on Work, Education, Mobility and Economy","Proceedings of the Future Technologies Conference (FTC) 2020, Volume 1",10.1007/978-3-030-63128-4_22,Springer,2021-01-01,2020-10-31,"This article studies artificial intelligence, its possible influence on how people work, move and study. Artificial intelligence may create technology-based industries, transforming daily life across the world. It also shows the potential role of artificial intelligence in the world economy. IT industry, in which AI is sourced, is currently estimated at about 5 trillion USD. Despite economic ups and downs, including the recent financial and economic crisis, AI solutions remain at a healthy level and its consumers enjoy the benefits of economic value creation. This will increase production efficiency through automation in different sectors of the economy. AI-related patent applications are on the rise worldwide. Companies developing AI solutions will be the ones that benefit from it in the future. Its economic impact will be visible over time, resulting in autonomous cars, a transformation of worker skills and how education is delivered.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-63128-4_22,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-73280-6_37,UAV On-Board Emergency Safe Landing Spot Detection System Combining Classical and Deep Learning-Based Segmentation Methods,Intelligent Information and Database Systems,10.1007/978-3-030-73280-6_37,Springer,2021-01-01,2021-04-05,This article proposes the system designed for automatic detection of emergency landing sites for horizontally landing unmanned aerial vehicles (UAV). The presented solution combines the classic computer vision algorithms and novel segmentation methods based on deep learning techniques using the U-Net inspired network architecture. The presented system uses a single nadir camera mounted on a UAV and the energy-efficient compute module capable of highly-parallelized calculations.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-73280-6_37,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-51992-6_24,Priority Levels and Danger in Usage of Artificial Intelligence in the World of Autonomous Vehicle,Soft Computing Applications,10.1007/978-3-030-51992-6_24,Springer,2021-01-01,2020-08-15,"Nowadays more and more vehicles are on the road wherein driver assistance functions are available but there are some which are capable for self-driving in special conditions. At the same time, autonomous vehicles have been developing in numerous country, so, in a latter part of the development, these vehicles will show up on the roads en masse. In 10 years, autonomous vehicles will spread on roads, because numerous producer works on its developing and testing. The common is that they all use, as base of the system, Artificial Intelligence. Some kind of priority needed by situations in traffic for example, cars should provide a clear way for ambulance in case of emergency. A recommendation had been made for this hierarchy in the article to make safer the transport. Behaviour of AI depends on its teaching method – that was used when it had been programmed – and it could be a major risk for human in the vehicle. The article highlights teaching methods, which could rush people into danger. Before integrity of AI into the vehicle, its behaviour and teaching method should be widely tested. Considering development of this area lately, vehicle of state leaders and its escort could be autonomous also, in the future. The article contains an analysis about this theme to point out its disadvantages and suggest to avoid usage of fully autonomous vehicles in case of state leaders.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-51992-6_24,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-71187-0_40,In-Car State Classification with RGB Images,Intelligent Systems Design and Applications,10.1007/978-3-030-71187-0_40,Springer,2021-01-01,2021-06-03,"In the next years, shared autonomous vehicles are going to be a new reality. The absence of the human driver is going to create a new paradigm for in-car safety. This paper addresses this problematic by presenting a monitoring system capable of classifying the state of the vehicle interior, i.e. good or bad condition. We propose the use of classifiers, with RGB images, to infer the in-car cleanliness state. Moreover, 18 state-of-the-art classifiers were trained and evaluated, using pre-trained models. To be able to train and evaluate these approaches an in-car dataset was created with 3488 samples from 135 cars, and then split in 2439 train, 351 validation and 689 test RGB images. From all the evaluated, ResNet-18 showed the best results, achieving an average accuracy of 91.24% 123 Hz.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-71187-0_40,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-7106-0_53,Autonomous Vehicle Simulation Using Deep Reinforcement Learning,Machine Learning for Predictive Analysis,10.1007/978-981-15-7106-0_53,Springer,2021-01-01,2020-10-23,"The reinforcement learning algorithms have been proven to be extremely accurate in performing a variety of tasks. These algorithms have outperformed humans in traditional games. This paper proposes a reinforcement learning based approach to autonomous driving. The autonomous vehicles must be able to deal with all external situations to ensure safety and to avoid undesired circumstances such as collisions. Thus, we propose the use of deep deterministic policy gradient (DDPG) algorithm which is able to work in a complex and continuous domain. To avoid physical damage and reduce costs, we choose to use a simulator to test the proposed approach. The CARLA simulator would be used as the environment. To fit the DDPG algorithm to the CARLA environment, our network architecture consists of critic and actor networks. The performance would be evaluated based on rewards generated by the agent while driving in the simulated environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-7106-0_53,springer
Chapter,doi:10.1007/978-981-16-0598-7_12,Prediction of Traffic Movement for Autonomous Vehicles,Machine Learning for Robotics Applications,10.1007/978-981-16-0598-7_12,Springer,2021-01-01,2021-04-24,"Living in the twenty-first century, there has been a massive growth in the number of autonomous vehicles present on the streets. Technology which once seemed impossible is being used in increasing number of vehicles day-by-day. With the technical advancement also comes challenges, it is not at all easy to develop and safely deploy these self-driving vehicles. So, in this chapter, a particular problem is being tackled, which is to predict future coordinates of all agents like cars, pedestrians, cyclists, etc., around AV. The main motive of this particular chapter is to measure the result efficiency of different deep learning models by evaluating the root mean square error (MSE) score. The models take as input the present state of the surroundings and based on that predicts the movement of the agents.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-0598-7_12,springer
Chapter,doi:10.1007/978-3-030-66042-0_12,The Deep Learning Method for Image Segmentation to Improve the Efficiency of Data Processing Without Compromising the Accuracy of an Autonomous Driving Country-Road Pilot System After Image Classification,Towards Connected and Autonomous Vehicle Highways,10.1007/978-3-030-66042-0_12,Springer,2021-01-01,2021-06-18,"Autonomous driving requires object recognition for vehicles to automatically generate a path according to their recognised environment, the conditions of which have different dims of light, from daylight to night. High-resolution images require high amounts of expensive storage as automated driving moves from urban to rural areas, where driving at night and recognising traffic signs and lights are necessary for all light conditions. Therefore, a reliable source of input, allowing for the intended performance of an autonomous driving system such as the country or rural road pilot, is necessary for adequate deployment of its functionality in its target environment. For quality criteria such as intended performance, functional reliability, safety, and correct driving behaviour are to be ensured; accuracy metrics can be a substantial contribution to the product quality criteria. Furthermore, since autonomous technology faces the challenge of being costly, thus any new innovative methods for saving costs, without comprising quality, would help to develop and enhance the chance of this developing technology being installed into more advanced automated or autonomous driving vehicles once the product safety as quality criteria can be validated on target roads. Part of this work’s limitation was that only a simulation environment was used for testing the image processing and autonomous driving accuracy models. Through research, certain algorithms were found that may be used in storage size minimisation for taking a high-resolution image; its size had to be reduced for use without compromising accuracy in the classification process. Further research in their validation may be necessary.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-66042-0_12,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-74893-7_24,LiDAR Localization and Mapping for Autonomous Vehicles: Recent Solutions and Trends,"Automation 2021: Recent Achievements in Automation, Robotics and Measurement Techniques",10.1007/978-3-030-74893-7_24,Springer,2021-01-01,2021-04-30,"This paper presents a brief survey of the current achievements in LiDAR SLAM and discusses some recent trends and new ideas in this area. The focus is on LiDAR SLAM applied to autonomous vehicles, which still strugle with real-world complexity. We identify the challenges in efficient environment representation, robust estimation over large state spaces, and real-time handling of the scene dynamics and diversified semantics. Some of these issues are illustrated by preliminary results of our recent research in LiDAR SLAM.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-74893-7_24,springer
Chapter,doi:10.1007/978-981-15-6759-9_10,Vehicular Localisation at High and Low Estimation Rates During GNSS Outages: A Deep Learning Approach,"Deep Learning Applications, Volume 2",10.1007/978-981-15-6759-9_10,Springer,2021-01-01,2020-09-25,"Road localisation of autonomous vehicles is reliant on consistent accurate GNSS (Global Navigation Satellite System) positioning information. Commercial GNSS receivers usually sample at 1 Hz, which is not sufficient to robustly and accurately track a vehicle in certain scenarios, such as driving on the highway, where the vehicle could travel at medium to high speeds, or in safety-critical scenarios. In addition, the GNSS relies on a number of satellites to perform triangulation and may experience signal loss around tall buildings, bridges, tunnels and trees. An approach to overcoming this problem involves integrating the GNSS with a vehicle-mounted Inertial Navigation Sensor (INS) system to provide a continuous and more reliable high rate positioning solution. INSs are however plagued by unbounded exponential error drifts during the double integration of the acceleration to displacement. Several deep learning algorithms have been employed to learn the error drift for a better positioning prediction. We therefore investigate in this chapter the performance of Long Short-Term Memory (LSTM), Input Delay Neural Network (IDNN), Multi-Layer Neural Network (MLNN) and Kalman Filter (KF) for high data rate positioning. We show that Deep Neural Network-based solutions can exhibit better performances for high data rate positioning of vehicles in comparison to commonly used approaches like the Kalman filter.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-6759-9_10,springer
Chapter,doi:10.1007/978-3-030-80083-3_7,The Governance of AI and Its Legal Context-Dependency,The 2020 Yearbook of the Digital Ethics Lab,10.1007/978-3-030-80083-3_7,Springer,2021-01-01,2021-10-31,"The paper examines today’s debate on the legal governance of AI. Scholars have recommended models of monitored self-regulation, new internal accountability structures for the industry and the implementation of independent monitoring and transparency efforts, down to new forms of co-regulation, such as the model of data governance set up by the EU legislators with the 2016 general data protection regulation, i.e. the GDPR. As shown by current regulations on self-driving cars, drones, e-health, etc., most legal systems, however, already govern the field of AI in a context-dependent way. The aim of this paper is to stress that such context-dependency does not preclude an all-embracing structure of legal regulation. The adaptability, modularity and flexibility of the regulatory system suggest a sort of middle ground between traditional top-down approaches and bottom-up solutions, between legislators and stakeholders. By fleshing out the legal constraints for every model of AI governance, the context-dependency of the law makes clear some of the features that such models should ultimately incorporate in the governance of AI.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-80083-3_7,springer
Chapter ConferencePaper,doi:10.1007/978-981-33-6912-2_46,Electric Vehicle Steering Design and Automated Control Using CNN and Reinforcement Learning,Soft Computing and Signal Processing,10.1007/978-981-33-6912-2_46,Springer,2021-01-01,2021-05-21,"Autonomous vehicles are one of the engrossing technological trends in the present automotive industry. These vehicles enticed substantial attention in industry as well as in academia. With the rising trend in research and development of autonomous vehicles, it is important to keep in mind the safety, control, and cost effectiveness of the system. The cost and implementation of self-driving technologies hinder the development of similar systems in academia and research. In this paper, we are mainly focused on developing a vision system, an automated steering system in an electric vehicle platform for academia and research. The developed system has a provision to incorporate deep learning—Convolutional neural network (CNN) and reinforcement learning (RL) for automated steering control. The proposed automated steering model uses end-to-end learning and reinforcement learning for predicting the steering angles with at most 85% accuracy and control the steering.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-6912-2_46,springer
Chapter,doi:10.1007/978-3-030-59897-6_11,Internet of Things and Artificial Intelligence-Enabled Secure Autonomous Vehicles for Smart Cities,Automotive Embedded Systems,10.1007/978-3-030-59897-6_11,Springer,2021-01-01,2021-04-25,"The ever-increasing count of vehicles wrecks several cities in the global scenario. Smart cities have evolved as a winning strategy that helps to cope up with this issue and overcome the urban problems such as pollution, traffic, waste management, optimization of energy consumption, and so on. Technologies such as machine learning (ML), Internet of Things (IoT), artificial intelligence (AI), big data analytics, cloud computing, and smart sensors serve as tools that provide enormous possibilities in the smart revolution. Several researchers are working on developing a complete system that performs information gathering, alternate identification, smart predictions, review of choices, decision-making, and taking suitable actions. These systems impose various challenges in terms of governance, economy, mobility, environment, people, and living. This chapter provides an in-depth analysis of these challenges in smart cities with respect to autonomous vehicles and also offers real-time solutions to overcome these challenges. A comparative analysis of the existing algorithms is done, and the optimal algorithms that can help in implementation of the system with a user-friendly approach and linguistic flexibility are proposed. Factors such as use of unmanned aerial vehicles (UAV), vehicle-to-vehicle and vehicle-to-infrastructure communication, deployment of location and path planning, data routing, dynamic coordination, data transmission, privacy, and cybersecurity are also considered while designing the system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-59897-6_11,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-86534-4_11,Contextual and Behavior Factors Extraction from Pedestrian Encounter Scenes Using Deep Language Models,Big Data Analytics and Knowledge Discovery,10.1007/978-3-030-86534-4_11,Springer,2021-01-01,2021-09-05,"This study introduces an NLP framework including deep language models to automate the contextual and behavior factors extraction from a narrative text that describes the environment and pedestrian behaviors at the pedestrian encounter scenes. The performance is compared against a baseline BiLSTM-CRF model trained for each factor separately. The evaluation results show that the proposed NLP framework outperforms the baseline model. We show that the proposed framework can successfully extract nested, overlapping, and flat factors from sentences through the case studies. This model can also be applied to other descriptions when physical context and human behaviors need to be extracted from the narrative content to understand the behavioral interaction between subjects further.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-86534-4_11,springer
Chapter ConferencePaper,doi:10.1007/978-981-16-3264-8_19,2D Autonomous Robot Localization Using Fast SLAM 2.0 and YOLO in Long Corridors,Human Centred Intelligent Systems,10.1007/978-981-16-3264-8_19,Springer,2021-01-01,2021-05-29,"Autonomous navigation is one of the main areas of research in mobile robots and intelligent connected vehicles. In this context, we are interested in presenting a general view on robotics, the progress of research, and advanced methods related to this field to improve autonomous robots’ localization. We seek to evaluate algorithms and techniques that give robots the ability to move safely and autonomously in a complex and dynamic environment. Under these constraints, we focused our work in the paper on a specific problem: to evaluate a simple, fast and light SLAM algorithm that can minimize localization errors. We presented and validated a FastSLAM 2.0 system combining scan matching and loop closure detection. To allow the robot to perceive the environment and detect objects, we have studied one of the best deep learning technique using convolutional neural networks (CNN). We validate our testing using the YOLOv3 algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-3264-8_19,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-75762-5_11,Autonomous Vehicle Path Prediction Using Conditional Variational Autoencoder Networks,Advances in Knowledge Discovery and Data Mining,10.1007/978-3-030-75762-5_11,Springer,2021-01-01,2021-05-09,"Path prediction of autonomous vehicles is an essential requirement under any given traffic scenario. Trajectory of several agent vehicles in the vicinity of ego vehicle, at least for a short future, is needed to be predicted in order to decide upon the maneuver of the ego vehicle. We explore variational autoencoder networks to obtain multimodal trajectories of agent vehicles. In our work, we condition the network on past trajectories of agents and traffic scenes as well. The latent space representation of traffic scenes is achieved by using another variational autoencoder network. The performance of the proposed networks is compared against a residual baseline model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-75762-5_11,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-60467-7_7,Intelligent and Autonomous Guidance Through a Geometric Model for Conventional Vehicles,Innovation and Research,10.1007/978-3-030-60467-7_7,Springer,2021-01-01,2020-11-22,"Cyber-physical systems (CPS) in the automobile industry are facing major challenges related to the use and validation of these CPS, which entails high costs in the implementation and training tests in the physical world, thus limiting research. Therefore, there is a need to shorten the validation times of these CPS with the use of 3D simulation software. This research article proposes to simulate a CPS in the simulation software Webots, with the aim of emulating the autonomous movement of conventional vehicles by integrating a GPS sensor and a compass sensor which provide information on location and orientation, these data are used for the implementation of a geometric model by vectors, the same one that is developed in a controller that allows to take actions on the vehicles in the simulation software in order to emulate an urban traffic. Finally, a series of configurations have been made to evaluate the geometric model, managing to maintain the default speed of 94.194% with curves greater than 90 degrees. In addition, the validation of this system in a real environment through the instrumentation in land vehicles is drawn as future lines.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60467-7_7,springer
Chapter ConferencePaper,doi:10.1007/978-981-33-6862-0_28,Object Detection for Autonomous Vehicles Using Deep Learning Algorithm,Computational Vision and Bio-Inspired Computing,10.1007/978-981-33-6862-0_28,Springer,2021-01-01,2021-06-15,"Self-driving cars is recently gaining an increasing interest from the people across the globe. Over 33,000 Americans are killed in car accidents every year and lots of those accidents are often avoided by implementing the autonomous vehicle detection. Different ways are developed to manage and detect the road obstacles with the help of the techniques like machine learning and artificial intelligence. To resolve the issues associated with the existing vehicle detection like vehicle type recognition, low detection accuracy, and slow speed, many algorithms like the fast and faster region-based convolutional neural networks (RCNNs) are implemented but those were not supportive in real time because of the speed at which they compute and its two-step architecture with the faster RCNN, which is the enhanced version of RCNNs that runs at a speed of 7 frames per second. As it is observed that the CNN family has two steps (object detection and classification), which can reduce the response time in real time with good accuracy and high image resolution. So, the vehicle detection model like YOLOv2 and YOLOv3 is taken into consideration in this paper as they are very useful in real-time detection with a comparatively higher frame rate. As YOLO family of algorithms will mostly use the single step detection and classification. YOLO has an FPS rate of 45 which is pretty good in the real-time scenarios. We had an average of 90.4 using the taken algorithm for each image in this paper with a lower resolution image alone.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-6862-0_28,springer
Chapter ConferencePaper,doi:10.1007/978-981-33-4501-0_47,Robustness Analysis of Behavioral Cloning-Based Deep Learning Models for Obstacle Mitigation in Autonomous Vehicles,Proceedings of 6th International Conference on Recent Trends in Computing,10.1007/978-981-33-4501-0_47,Springer,2021-01-01,2021-04-21,Maneuvering a steady on-road obstacle at high speed involves taking multiple decisions in split seconds. An inaccurate decision may result in a crash. One of the key decisions that need to be taken is can the on-road steady obstacle be surpassed. The model learns to clone the driver’s behavior of maneuvering a non-surpass-able obstacle and pass through a surpass-able obstacle. No data with labels of “surpass-able” and “non-surpass-able” was provided during training. We have developed an array of test cases to verify the robustness of CNN models used in autonomous driving. Experimenting between activation functions and dropouts the model achieves an accuracy of 87.33% and run time of 4478 s with input of only 4881 images (training + testing). The model is trained for limited on-road steady obstacles. This paper provides a unique method to verify the robustness of CNN models for obstacle mitigation in autonomous vehicles.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-4501-0_47,springer
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-15145-4_65-2,Deep Learning for LiDAR-Based Autonomous Vehicles in Smart Cities,Handbook of Smart Cities,10.1007/978-3-030-15145-4_65-2,Springer,2021-01-01,2021-02-14,"Autonomous vehicles and deep learning are an integral part of smart cities. They interact and communicate with their surroundings, requiring high computer vision accuracy to maintain driver and pedestrian safety. Many autonomous vehicles leverage deep learning for detection and utilize a suite of sensors that are specific to their environment or use case. In such deep learning environment, sensor data is used as input to neural networks that make decisions regarding the vehicle’s response or reaction to its environment. These sensors in autonomous vehicles provide details regarding the vehicle’s surroundings and potential obstacles. Many sensor suites are starting to contain light detection and ranging (LiDAR) sensors, as the cost of the technology decreases and becomes more widely available. LiDAR technology uses focused light to detect distance, providing an accurate description of the sensor’s surroundings, such precise account is crucial for autonomous driving in ever-changing smart city environments. This chapter covers different applications of LiDAR technology and the use of the sensor data in deep learning applications for smart cities. A case study is also featured to illustrate a potential implementation, which is followed by discussion of future research directions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-15145-4_65-2,springer
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-69698-6_65,Deep Learning for LiDAR-Based Autonomous Vehicles in Smart Cities,Handbook of Smart Cities,10.1007/978-3-030-69698-6_65,Springer,2021-01-01,2021-07-10,"Autonomous vehicles and deep learning are an integral part of smart cities. They interact and communicate with their surroundings, requiring high computer vision accuracy to maintain driver and pedestrian safety. Many autonomous vehicles leverage deep learning for detection and utilize a suite of sensors that are specific to their environment or use case. In such deep learning environment, sensor data is used as input to neural networks that make decisions regarding the vehicle’s response or reaction to its environment. These sensors in autonomous vehicles provide details regarding the vehicle’s surroundings and potential obstacles. Many sensor suites are starting to contain light detection and ranging (LiDAR) sensors, as the cost of the technology decreases and becomes more widely available. LiDAR technology uses focused light to detect distance, providing an accurate description of the sensor’s surroundings, such precise account is crucial for autonomous driving in ever-changing smart city environments. This chapter covers different applications of LiDAR technology and the use of the sensor data in deep learning applications for smart cities. A case study is also featured to illustrate a potential implementation, which is followed by discussion of future research directions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-69698-6_65,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-71187-0_88,Transfer Learning for Autonomous Vehicles Obstacle Avoidance with Virtual Simulation Platform,Intelligent Systems Design and Applications,10.1007/978-3-030-71187-0_88,Springer,2021-01-01,2021-06-03,"Over the last few years, autonomous vehicles have expanded considerably. Autonomous driving systems are getting more complex and must be tested successfully prior to implementation. We are exploring a model for high quality prediction of obstacle avoidance for autonomous vehicles based on images created by a virtual simulation platform and then using a VGG 16 deep learning technique, including transfer learning. This paper proposes a transfer of learning strategy using the VGG16 architecture, while the output of the proposed architecture is further compared to the existing NVIDIA architecture. Experimental results indicate that the VGG16 with the transfer learning architecture has surpassed other tested methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-71187-0_88,springer
Chapter,doi:10.1007/978-3-030-58728-4_5,Evaluation of Deep Learning Algorithms for Traffic Sign Detection to Implement on Embedded Systems,Recent Advances of Hybrid Intelligent Systems Based on Soft Computing,10.1007/978-3-030-58728-4_5,Springer,2021-01-01,2020-11-07,"Nowadays, machine learning algorithms are trendy and are used to solve different problems of autonomous vehicles obtaining good results. Among these algorithms, deep learning has emerged as an excellent alternative to improve the results of the state-of-the-art in machine vision applications. An essential task in autonomous vehicles is the detection of traffic signs. Some metrics used for these detectors focus on assessing precision and recall. However, it is necessary to consider other factors, such as the implementation of these models on an embedded system. In this work, we implement deep learning algorithms on an embedded system to evaluate two different detection algorithms: Faster R-CNN and Single Shot Multibox Detector (SSD) with two feature extractors, ResNet V1 101 and MobileNet V1 to determine the location of traffic signs within the observed scenario. The contribution of this work focuses on evaluating the implementation of traffic sign detection systems based on deep learning algorithms on embedded systems. The experiments were achieved on the experimental embedded system board Nvidia Jetson Nano. The inference time and memory consumption of these detection systems were evaluated; they delivered good performance (81–98%) measure by average precision for each superclass (prohibitory, warning, and mandatory).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-58728-4_5,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-5113-0_40,Tweets About Self-Driving Cars: Deep Sentiment Analysis Using Long Short-Term Memory Network (LSTM),International Conference on Innovative Computing and Communications,10.1007/978-981-15-5113-0_40,Springer,2021-01-01,2020-08-02,"Due to the extensive growth of social media usage, sentiment analysis using social media data such as Twitter is an important task. The current study presents an empirical investigation of consumer sentiment toward self-driving cars or autonomous vehicles (AVs) based on the acquired self-driving car-related tweets. Information retrieval in social media is a complex task that requires technical insights. We used a hierarchical attention-based long short-term memory network (LSTM), a popular deep learning tool, to classify sentiment-specific document representations. The findings show that favorable attitudes toward AVs are associated with technological advantages and safety improvements, while more negative attitudes are associated with self-driving car-related crashes, media coverage, and deployment uncertainty. The results show that the estimated accuracy of LSTM is 85%. Our study indicates the necessity of examining big social media data in understanding the perceptions of end-users toward autonomous vehicles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-5113-0_40,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-67369-7_15,Deep Anomaly Detector Based on Spatio-Temporal Clustering for Connected Autonomous Vehicles,Ad Hoc Networks,10.1007/978-3-030-67369-7_15,Springer,2021-01-01,2021-01-31,"Connected Autonomous Vehicles (CAV) are expected to revolutionize the transportation sector. However, given that CAV are connected to internet, they face a principal challenge to ensure security, safety and confidentiality. It is highly valuable to provide a real-time and proactive anomaly detection approach for Vehicular Ad hoc Network (VANET) exchanged data since such an approach helps to trigger prompt countermeasures to be undertaken allowing the damage avoidance. Recent machine learning methods show great efficiency, especially due to their capacity to handle nonlinear problems. However, an accurate anomaly detection in a space–time series is a challenging problem because of the heterogeneity of space–time data and the spatio-temporal correlations. An anomalous behavior can be seen as normal in different context. Thus, using one deep learning model to classify the observations into normal and abnormal or to identify the type of the anomaly is usually not efficient for large high-dimensional multi-variate time-series datasets. In this paper, we propose a stepwise method in which the time-series data are clustered on spatio-temporal clusters using Long Short Term Memory (LSTM) auto-encoder for dimension reduction and Grey Wolf Optimizer based clustering. Then, the anomaly detection is performed on each cluster apart using a hybrid method consisting of Auto-Encoder for feature extraction and Convolution Neural Network for classification. The results shows an increase in the accuracy by $$2\%$$ 2 % in average and in the precision by approximately $$1.5\%$$ 1.5 % .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-67369-7_15,springer
Chapter,doi:10.1007/978-981-15-9255-3_1,Challenges for and with Autonomous Vehicles: An Introduction,Autonomous Vehicles,10.1007/978-981-15-9255-3_1,Springer,2021-01-01,2020-12-22,"The deployment of autonomous vehicles has been announced for years. Yet, full autonomous vehicles are not on public roads. Elon Musk Elon Musk , speaking at an event during the first half of 2020, stated that his firm will be able to present a fully autonomous vehicle technology by the end of the year. This statement is met with skepticism, especially because several of the challenges that existed have not been solved. Road traffic laws have not been adjusted to face the reality of driving by an autonomous machine. The only way that full autonomous vehicles can hit public roads is through test procedures. There also exists quite some uncertainty on who should be liable for accidents with autonomous vehicles. Accidents may occur, and this is something that adversarial machine learning Adversarial machine learning is showing. Even with the best set of sensors, the interpretation of the sensed environment may be misinterpreted. Connectivity Connectivity is being suggested as a possible solution to several of the problems autonomous vehicles are facing. Deploying autonomous vehicles will also challenge business organization, as car manufacturers Manufacturer may turn their business vehicles into mobility service providers. This may require a different type of organization within the firm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-9255-3_1,springer
Chapter,doi:10.1007/978-3-030-65661-4_11,"Synergy of Internet of Things with Cloud, Artificial Intelligence and Blockchain for Empowering Autonomous Vehicles",Deep Learning and Big Data for Intelligent Transportation,10.1007/978-3-030-65661-4_11,Springer,2021-01-01,2021-04-11,"Out of the advancements in Information Technology, the Internet of Things (IoT) plays an important and major role as it metamorphose the object from real world Scenario to intelligent virtual form. The term Internet of Things is coined from two phrases such as Internet and Thing which states that the physical objects such as computing devices acts through the network of connection. This technological ecosystem allows the object or thing to collect and transfer the data through the internet, without any physical assistance. It includes four major processes such as collect, communicate, analyse and act. The main purpose of IoT is making the human life smart thereby reducing the human effort. The cloud is an environment that seems to be a reinforcement of booming technology. It provides everything as service, right from storage to computing power through internet. It seems to be a flexible computing model that has intensified the growth of information technology. It enchanted the sprout of IoT as it needs more storage for the data that are acquired from the objects. Another booming technology is artificial intelligence where the intelligence of machine is used for enabling smart tasks than using the human intelligence. It is in existence since 1950 s but the resurgence of it happens during twenty-first century with the advances in computing power and storage of voluminous data. The main purpose of AI is to achieve accurate interpretation of voluminous data and extract valuable learning from the data thereby achieving the appropriate goals in a flexible manner. The IoT with this gleaming AI allows the physical objects to collect the valuable data through continuous streaming and allows it to perceive its tasks and domains for greatest chance of prosperous goal achievement. Blockchain is another revolution of the information technology. The blockchain or Distributed Ledger Technology is a promising technology where the digital assets of myriad users are managed by maintaining the transparency and evading the undesirable alterations. It stores and manages the data in the form of multiple blocks with respective cryptographic hashing. It is a distributed and decentralized model where the digital form of transactions are recorded in multiple devices, this allows the system to do any alterations or changes in each and every blocks so as to make changes in the record. This model avoids the precarious changes that may occur in the digital world. The IoT with this blockchain technology or the blockchain of thing may allow the digital environment to create a permanent, verifiable and secure method of managing the valuable data through intelligent machines. It will enable humanless interventions for decision making through proper environment interactions. This chapter elaborates all the four technologies such as IoT, AI, Cloud and Blockchain with regard to the autonomous vehicles. The need for these flickering technologies are explored and exposed so as to understand these technologies. The synergies of IoT with other three technologies are discussed for better understanding and upgradation of the technology. It also scrutinizes the recent developments with all these technological synergies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-65661-4_11,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-77626-8_13,Human-Machine Interaction for Autonomous Vehicles: A Review,Social Computing and Social Media: Experience Design and Social Network Analysis,10.1007/978-3-030-77626-8_13,Springer,2021-01-01,2021-07-03,"The rate of advancement in autonomous systems has been increasing and humans rely on such systems for every aspect of daily life. This is especially true in the area of autonomous vehicles, where new techniques and discoveries have been uncovered and Society of Automotive Engineers (SAE) Level 5 self-driving might be a reality in a few years. Despite the significant body of work on self driving technology, many people are still sceptical about the idea of riding in a fully autonomous vehicle (AV). There is a need to build trust between humans and vehicles for successful adoption of AVs. In this paper we complement existing surveys by describing 3 active research areas that are key for enhancing trust in autonomous vehicles, namely 1) Trust in Autonomous Vehicles, 2) Human Machine Interfaces, and 3) Driver Activity Detection. We discuss and highlight the key ideas and techniques in recent research works of each field, and discuss potential future directions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77626-8_13,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-79150-6_12,Enhanced Security Framework for Enabling Facial Recognition in Autonomous Shuttles Public Transportation During COVID-19,Artificial Intelligence Applications and Innovations,10.1007/978-3-030-79150-6_12,Springer,2021-01-01,2021-06-22,"Autonomous Vehicles (AVs) can potentially reduce the accident risk while a human is driving. They can also improve the public transportation by connecting city centers with main mass transit systems. The development of technologies that can provide a sense of security to the passenger when the driver is missing remains a challenging task. Moreover, such technologies are forced to adopt to the new reality formed by the COVID-19 pandemic, as it has created significant restrictions to passenger mobility through public transportation. In this work, an image-based approach, supported by novel AI algorithms, is proposed as a service to increase autonomy of non-fully autonomous people such as kids, grandparents and disabled people. The proposed real-time service, can identify family members via facial characteristics and efficiently ignore face masks, while providing notifications for their condition to their supervisor relatives. The envisioned AI-supported security framework, apart from enhancing the trust to autonomous mobility, could be advantageous in other applications also related to domestic security and defense.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-79150-6_12,springer
Article,doi:10.1007/s10846-020-01295-w,Controlling Draft Interactions Between Quadcopter Unmanned Aerial Vehicles with Physics-aware Modeling,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01295-w,Springer,2020-12-15,2020-12-15,"In this paper, we address the problem of multiple quadcopter control, where the quadcopters maneuver in close proximity resulting in interference due to air-drafts. We use sparse experimental data to estimate the interference area between palm sized quadcopters and to derive physics-infused models that describe how the air-draft generated by two quadcopters (flying one above the other) affect each other. The observed significant altitude deviations due to airdraft interactions, mainly in the lower quadcopter, is adequately captured by our physics infused machine learning model. We use two strategies to mitigate these effects. First, we propose non-invasive, online and offline trajectory re-planning strategies that allow avoiding the interference zone while reducing the deviations from desired minimum snap trajectories. Second, we propose invasive strategies that re-design control algorithms by incorporating the interference model. We demonstrate how to modify the standard quadcopter PID controller, and how to formulate a model predictive control approach when considering the interference model. Both invasive and non-invasive strategies show significant reduction in tracking error and control signal energy as compared to the case where the interference area is ignored.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-020-01295-w,springer
Article,doi:10.1007/s10846-020-01274-1,A Dynamically Feasible Fast Replanning Strategy with Deep Reinforcement Learning,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01274-1,Springer,2020-12-11,2020-12-11,"In this work, we aim to develop a fast trajectory replanning methodology enabling highly agile aerial vehicles to navigate in cluttered environments. By focusing on reducing complexity and accelerating the replanning problem under strict dynamical constraints, we employ the b-spline theory with local support property for defining the high dimensional agile flight trajectories. We utilize the differential flatness model of an aerial vehicle, allowing us to directly map the desired output trajectory into input states to track a high dimensional trajectory. Dynamically feasible replanning problem is addressed through regenerating the local b-splines with control point reallocation. As the geometric form of the trajectory based on the location of the control points and the knot intervals, the control point reallocation for fast replanning with dynamical constraints is turned into a constrained optimization problem and solved through deep reinforcement learning. The proposed methodology enables generating dynamically feasible local trajectory segments, which are continuous to the existing, hence provides fast local replanning for collision avoidance. The DRL agent is trained with different environmental complexities, and through the batch simulations, it is shown that the proposed methodology allows to solve fast trajectory replanning problem under given or hard dynamical constraints and provide real-time applicability for such collision avoidance applications in agile unmanned aerial vehicles. Hardware implementation tests of the algorithm with the agile trajectory tracker to a small UAV can bee seen in the following video link: https://youtu.be/8IiLQFQ3V0E .",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-020-01274-1,springer
Article,doi:10.1007/s10846-020-01284-z,Deep Learning-based Monocular Obstacle Avoidance for Unmanned Aerial Vehicle Navigation in Tree Plantations,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01284-z,Springer,2020-12-08,2020-12-08,"In recent years, Unmanned Aerial Vehicles (UAVs) are widely utilized in precision agriculture, such as tree plantations. Due to limited intelligence, these UAVs can only operate at high altitudes, leading to the use of expensive and heavy sensors for obtaining important health information of the plants. To fly at low altitudes, these UAVs must possess the capability of obstacle avoidance to prevent crashes. However, most current obstacle avoidance systems with active sensors are not applicable to small aerial vehicles due to the cost, weight, and power consumption constraints. To this end, this paper presents a novel approach to the autonomous navigation of a small UAV in tree plantations only using a single camera. As the monocular vision does not provide depth information, a machine learning model, Faster Region-based Convolutional Neural Network (Faster R-CNN), was trained for the tree trunk detection. A control strategy was implemented to avoid the collision with trees. The detection model uses image heights of detected trees to indicate their distances from the UAV and image widths between trees to find the widest obstacle-free space. The control strategy allows the UAV to navigate until any approaching obstacle is detected and to turn to the safest area before continuing its flight. This paper demonstrates the feasibility and performance of the proposed algorithms by carrying out 11 flight tests in real tree plantation environments at two different locations, one of which is a new place. All the successful results indicate that the proposed method is accurate and robust for autonomous navigation in tree plantations.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-020-01284-z,springer
Article,doi:10.1007/s10846-020-01254-5,Autonomous UAV Trail Navigation with Obstacle Avoidance Using Deep Neural Networks,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01254-5,Springer,2020-12-01,2020-09-22,"This paper proposes a vision-based bike trail following approach with obstacle avoidance using CNN (Convolutional Neural Network) for the UAV (Unmanned Aerial Vehicle). The UAV is controlled to follow a given trail while keeping its position near the center of the trail using the CNN. Also, to return to the original path when the UAV goes out of the path or the camera misses the trail due to disturbances such as wind, the control commands from the CNN are stored for a certain duration of time and used for recovering from such disturbances. To avoid obstacles during the trail navigation, the optical flow computed with another CNN is used to determine the safe maneuver. By combining these methods of i) trail following, ii) disturbance recovery, and iii) obstacle avoidance, the UAV deals with various situations encountered when traveling on the trail. The feasibility and performance of the proposed approach are verified through realistic simulations and flight experiments in real-world environments.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-020-01254-5,springer
Article,doi:10.1007/s11227-020-03251-9,Secure decentralized peer-to-peer training of deep neural networks based on distributed ledger technology,The Journal of Supercomputing,10.1007/s11227-020-03251-9,Springer,2020-12-01,2020-03-19,"The accuracy and performance of deep neural network models become important issues as the applications of deep learning increase. For example, the navigation system of autonomous self-driving vehicles requires very accurate deep learning models. If a self-driving car fails to detect a pedestrian in bad weather, the result can be devastating. If we can increase the model accuracy by increasing the training data, the probability of avoiding such scenarios increases significantly. However, the problem of privacy for consumers and lack of enthusiasm for sharing their personal data, e.g., the recordings of their self-driving car, is an obstacle for using this valuable data. In Blockchain technology, many entities which cannot trust each other in normal conditions can join together to achieve a mutual goal. In this paper, a secure decentralized peer-to-peer framework for training the deep neural network models based on the distributed ledger technology in Blockchain ecosystem is proposed. The proposed framework anonymizes the identity of data providers and therefore can be used as an incentive for consumers to share their private data for training deep learning models. The proposed framework uses the Stellar Blockchain infrastructure for secure decentralized training of the deep models. A deep learning coin is proposed for Blockchain compensation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11227-020-03251-9,springer
Article,doi:10.1007/s10846-020-01227-8,UAV Model-based Flight Control with Artificial Neural Networks: A Survey,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01227-8,Springer,2020-12-01,2020-09-21,"Model-Based Control (MBC) techniques have dominated flight controller designs for Unmanned Aerial Vehicles (UAVs). Despite their success, MBC-based designs rely heavily on the accuracy of the mathematical model of the real plant and they suffer from the explosion of complexity problem. These two challenges may be mitigated by Artificial Neural Networks (ANNs) that have been widely studied due to their unique features and advantages in system identification and controller design. Viewed from this perspective, this survey provides a comprehensive literature review on combined MBC-ANN techniques that are suitable for UAV flight control, i.e., low-level control. The objective is to pave the way and establish a foundation for efficient controller designs with performance guarantees. A reference template is used throughout the survey as a common basis for comparative studies to fairly determine capabilities and limitations of existing research. The end-result offers supported information for advantages, disadvantages and applicability of a family of relevant controllers to UAV prototypes.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-020-01227-8,springer
Article,doi:10.1007/s12008-020-00717-1,Explainable navigation system using fuzzy reinforcement learning,International Journal on Interactive Design and Manufacturing (IJIDeM),10.1007/s12008-020-00717-1,Springer,2020-12-01,2020-10-06,"Abstract Explainable outcomes in autonomous navigation have become crucial for drivers, other vehicles, as well as for pedestrians. Creating trustworthy strategies is mandatory for the integration of self-driving cars into quotidian environments. This paper presents the successful implementation of an explainable Fuzzy Deep Reinforcement Learning approach for autonomous vehicles based on the AWS DeepRacer $$^{\mathrm{TM}}$$ TM platform. A model of the environment is created by transforming crisp values into linguistic variables. A fuzzy inference system is used to define the reward of the vehicle depending on its current state. Guidelines to define the actions and to improve performance of the reinforcement learning agent are given based on the characteristics of the existing hardware. The performance of the models is tested on tracks with distinctive properties using agents with different policies and action spaces, and shows explainable and successful navigation of the agent on diverse scenarios. Graphic Abstract ",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12008-020-00717-1,springer
Article,doi:10.1007/s42154-020-00113-1,Deep Reinforcement Learning Enabled Decision-Making for Autonomous Driving at Intersections,Automotive Innovation,10.1007/s42154-020-00113-1,Springer,2020-12-01,2020-11-13,"Road intersection is one of the most complex and accident-prone traffic scenarios, so it’s challenging for autonomous vehicles (AVs) to make safe and efficient decisions at the intersections. Most of the related studies focus on the solution to a single scenario or only guarantee safety without considering driving efficiency. To address these problems, this study proposed a deep reinforcement learning enabled decision-making framework for AVs to drive through intersections automatically, safely and efficiently. The mapping relationship between traffic images and vehicle operations was obtained by an end-to-end decision-making framework established by convolutional neural networks. Traffic images collected at two timesteps were used to calculate the relative velocity between vehicles. Markov decision process was employed to model the interaction between AVs and other vehicles, and the deep Q-network algorithm was utilized to obtain the optimal driving policy regarding safety and efficiency. To verify the effectiveness of the proposed decision-making framework, the top three accident-prone crossing path crash scenarios at intersections were simulated, when different initial vehicle states were adopted for better generalization capability. The results showed that the developed method could make AVs drive safely and efficiently through intersections in all of the tested scenarios.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42154-020-00113-1,springer
Article,doi:10.1007/s11569-020-00374-4,Programming Away Human Rights and Responsibilities? “The Moral Machine Experiment” and the Need for a More “Humane” AV Future,NanoEthics,10.1007/s11569-020-00374-4,Springer,2020-12-01,2020-11-25,"Dilemma situations involving the choice of which human life to save in the case of unavoidable accidents are expected to arise only rarely in the context of autonomous vehicles (AVs). Nonetheless, the scientific community has devoted significant attention to finding appropriate and (socially) acceptable automated decisions in the event that AVs or drivers of AVs were indeed to face such situations. Awad and colleagues, in their now famous paper “The Moral Machine Experiment”, used a “multilingual online ‘serious game’ for collecting large-scale data on how citizens would want AVs to solve moral dilemmas in the context of unavoidable accidents.” Awad and colleagues undoubtedly collected an impressive and philosophically useful data set of armchair intuitions. However, we argue that applying their findings to the development of “global, socially acceptable principles for machine learning” would violate basic tenets of human rights law and fundamental principles of human dignity. To make its arguments, our paper cites principles of tort law, relevant case law, provisions from the Universal Declaration of Human Rights, and rules from the German Ethics Code for Autonomous and Connected Driving.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11569-020-00374-4,springer
Article,doi:10.1007/s10670-020-00331-3,"Robot Ethics 2.0. From Autonomous Cars to Artificial Intelligence—Edited by Patrick Lin, Keith Abney, Ryan Jenkins. New York: Oxford University Press, 2017. Pp xiii + 421",Erkenntnis,10.1007/s10670-020-00331-3,Springer,2020-10-22,2020-10-22,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10670-020-00331-3,springer
Article,doi:10.1134/S2075108720040100,UAV Navigation System Autonomous Correction Algorithm Based on Road and River Network Recognition,Gyroscopy and Navigation,10.1134/S2075108720040100,Springer,2020-10-01,2021-02-19,Abstract —The paper considers an original autonomous correction algorithm for UAV navigation system based on comparison between terrain images obtained by onboard machine vision system and vector topographic map images. Comparison is performed by calculating the homography of vision system images segmented using the convolutional neural network and the vector map images. The presented results of mathematical and flight experiments confirm the algorithm effectiveness for navigation applications.,http://link.springer.com/openurl/fulltext?id=doi:10.1134/S2075108720040100,springer
Article,doi:10.1007/s11948-020-00242-0,Toward Implementing the ADC Model of Moral Judgment in Autonomous Vehicles,Science and Engineering Ethics,10.1007/s11948-020-00242-0,Springer,2020-10-01,2020-07-06,"Autonomous vehicles (AVs)—and accidents they are involved in—attest to the urgent need to consider the ethics of artificial intelligence (AI). The question dominating the discussion so far has been whether we want AVs to behave in a ‘selfish’ or utilitarian manner. Rather than considering modeling self-driving cars on a single moral system like utilitarianism, one possible way to approach programming for AI would be to reflect recent work in neuroethics. The agent–deed–consequence (ADC) model (Dubljević and Racine in AJOB Neurosci 5(4):3–20, 2014a, Behav Brain Sci 37(5):487–488, 2014b) provides a promising descriptive and normative account while also lending itself well to implementation in AI. The ADC model explains moral judgments by breaking them down into positive or negative intuitive evaluations of the agent, deed, and consequence in any given situation. These intuitive evaluations combine to produce a positive or negative judgment of moral acceptability. For example, the overall judgment of moral acceptability in a situation in which someone committed a deed that is judged as negative (e.g., breaking a law) would be mitigated if the agent had good intentions and the action had a good consequence. This explains the considerable flexibility and stability of human moral judgment that has yet to be replicated in AI. This paper examines the advantages and disadvantages of implementing the ADC model and how the model could inform future work on ethics of AI in general.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-020-00242-0,springer
Article,doi:10.1007/s42979-020-00323-8,Theoretical Understanding of Deep Learning in UAV Biomedical Engineering Technologies Analysis,SN Computer Science,10.1007/s42979-020-00323-8,Nature,2020-09-24,2020-09-24,"The unmanned aerial vehicles (UAVs) emerged into a promising research trend within the recurrent year where current and future networks are to use enhanced connectivity in these digital immigrations in different fields like medical, communication, search, and rescue operations among others. The current technologies are using fixed base stations to operate on-site and off-site in the fixed position with its associated problems like poor connectivity. This opens gates for the UAVs technology to be used as a mobile alternative to increase accessibility with a fifth-generation (5G) connectivity that focuses on increased availability and connectivity. There has been less usage of wireless technologies in the medical field. This paper first presents a study on deep learning to medical field application in general, and provides detailed steps that are involved in the multi-armed bandit approach in solving UAV biomedical engineering technologies devices and medical exploration to exploitation dilemma. The paper further presents a detailed description of the bandit network applicability to achieve close optimal medical engineered devices’ performance and efficiency. The simulated results depicted that a multi-armed bandit problem approach can be applied in optimizing the performance of any medical networked device issue compared to the Thompson sampling, Bayesian algorithm, and ε-greedy algorithm. The results obtained further illustrated the optimized utilization of biomedical engineering technologies systems achieving thus close optimal performance on the average period through deep learning of realistic medical situations.",https://www.nature.com/articles/s42979-020-00323-8,springer
Article,doi:10.1007/s42421-020-00021-0,Automated Vehicle Control at Freeway Lane-drops: a Deep Reinforcement Learning Approach,Journal of Big Data Analytics in Transportation,10.1007/s42421-020-00021-0,Springer,2020-08-01,2020-08-06,"This study develops an optimal, real-time and adaptive control algorithm for helping a Connected and Automated Vehicle (CAV), navigate a freeway lane-drop site (e.g. work zones). The proposed traffic control strategy is based on the Deep Q-Network (DQN) Reinforcement Learning (RL) algorithm, and is designed to determine the driving speed and lane-change maneuvers that would enable the CAV to go through the bottleneck, with the least amount of delay. The DQN RL agent was trained using the microscopic traffic simulator VISSIM, where the learning focused on how the CAV may be able to optimally maneuver the lane drop site while driving as close as possible to the freeway speed limit. VISSIM was also used to compare the performance of the DQN-controlled AV, as opposed to a human-driven vehicle with no intelligent control, in terms of the driving speed or travel time needed to traverse the lane drop site, under a congested, real life-like traffic scenario. The research findings demonstrate the promise of DQN RL in allowing the CAV to intelligently, and optimally navigate, through the lane drop site. Specifically, for the scenario for which the agent was trained, the reduction in the CAV travel time was around 96 percent, compared to the base case. The robustness of the RL agent was further tested on various scenarios different from the training case. For those cases, the mean and standard deviation of the reductions in the travel of the DQN-controlled CAV travel times, compared to the base case, were around 31% and 61%, respectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42421-020-00021-0,springer
Article,doi:10.1007/s00521-019-04653-4,An unmanned aerial vehicle-aided node localization using an efficient multilayer perceptron neural network in wireless sensor networks,Neural Computing and Applications,10.1007/s00521-019-04653-4,Springer,2020-08-01,2019-12-07,"Localization of sensor node is decisive for many localization-based scenarios of wireless sensor networks (WSNs). Node localization using fixed terrestrial anchor nodes (ANs) equipped with global positioning system (GPS) modules suffers from high deployment cost and poor localization accuracy, because the terrestrial AN propagates signals to the unknown nodes (UNs) through unreliable ground-to-ground channel. However, the ANs deployed in unmanned aerial vehicles (UAVs) with a single GPS module communicate over reliable air-to-ground channel, where almost clear line-of-sight path exists. Thus, the localization accuracy and deployment cost are better with aerial anchors than terrestrial anchors. However, still the nonlinear distortions imposed in propagation channel limit the performance of classical RSSI and least square localization schemes. So, the neural network (NN) models can become good alternative for node localization under such nonlinear conditions as they can do complex nonlinear mapping between input and output. Since the multilayer perceptron (MLP) is a robust tool in the assembly of NNs, MLP-based localization scheme is proposed for UN localization in UAV-aided WSNs. The detailed simulation analysis provided in this paper prefers the MLP localization scheme as they exhibit improved localization accuracy and deployment cost.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-019-04653-4,springer
Article,doi:10.1186/s12544-020-00438-2,Towards behaviour based testing to understand the black box of autonomous cars,European Transport Research Review,10.1186/s12544-020-00438-2,Springer,2020-07-29,2020-07-29,"Background Autonomous cars could make traffic safer, more convenient, efficient and sustainable. They promise the convenience of a personal taxi, without the need for a human driver. Artificial intelligence would operate the vehicle instead. Especially deep neural networks (DNNs) offer a way towards this vision due to their exceptional performance particularly in perception. DNNs excel in identifying objects in sensor data which is essential for autonomous driving. These networks build their decision logic through training instead of explicit programming. A drawback of this technology is that the source code cannot be reviewed to assess the safety of a system. This leads to a situation where currently used methods for regulatory approval do not work to validate a promising new piece of technology. Objective In this paper four approaches are highlighted that might help understanding black box technical systems for autonomous cars by focusing on its behaviour instead. The method of experimental psychology is proposed to model the inner workings of DNNs by observing its behaviour in specific situations. It is argued that penetration testing can be applied to identify weaknesses of the system. Both can be applied to improve autonomous driving systems. The shadowing method reveals behaviour in a naturalistic setting while ensuring safety. It can be seen as a theoretical driving exam. The supervised driving method can be utilised to decide if the technology is safe enough. It has potential to be developed into a practical driving exam.",http://link.springer.com/openurl/fulltext?id=doi:10.1186/s12544-020-00438-2,springer
Article,doi:10.1007/s00500-019-04574-3,A passive detection algorithm for low-altitude small target based on a wavelet neural network,Soft Computing,10.1007/s00500-019-04574-3,Springer,2020-07-01,2019-12-05,"A passive detection algorithm is presented for multiple low-altitude small targets, which employs a wavelet neural network (WNN). The slope, kurtosis, and skewness are employed as the features for low-altitude small target detection, and an algorithm is given to determine the number of targets. A WNN is used to establish a relationship between signal classes and the signal characteristics using training signals. Then, signals are classified as either target present or target not present using the WNN. Indoor data from a research laboratory and outdoor data from a bridge in the Jimo District, Qingdao, were used for training and evaluation. The performance results show that the error rate with the proposed WNN-based algorithm is better than those based on the slope, skewness, and kurtosis of signal. Furthermore, the proposed algorithm is better than those based on other neural networks such as BPNN, RBFNN, SOMNN, and SVM. At a distance of 3 km, the recognition rate is greater than 84%, which is better than other techniques such as visual recognition, acoustic, and active radar.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-019-04574-3,springer
Article,doi:10.1007/s11948-019-00130-2,"The Future of Transportation: Ethical, Legal, Social and Economic Impacts of Self-driving Vehicles in the Year 2025",Science and Engineering Ethics,10.1007/s11948-019-00130-2,Springer,2020-06-01,2019-09-03,"Self-driving vehicles (SDVs) offer great potential to improve efficiency on roads, reduce traffic accidents, increase productivity, and minimise our environmental impact in the process. However, they have also seen resistance from different groups claiming that they are unsafe, pose a risk of being hacked, will threaten jobs, and increase environmental pollution from increased driving as a result of their convenience. In order to reap the benefits of SDVs, while avoiding some of the many pitfalls, it is important to effectively determine what challenges we will face in the future and what steps need to be taken now to avoid them. The approach taken in this paper is the construction of a likely future (the year 2025), through the process of a policy scenario methodology, if we continue certain trajectories over the coming years. The purpose of this is to articulate issues we currently face and the construction of a foresight analysis of how these may develop in the next 6 years. It will highlight many of the key facilitators and inhibitors behind this change and the societal impacts caused as a result. This paper will synthesise the wide range of ethical, legal, social and economic impacts that may result from SDV use and implementation by 2025, such as issues of autonomy, privacy, liability, security, data protection, and safety. It will conclude with providing steps that we need to take to avoid these pitfalls, while ensuring we reap the benefits that SDVs bring.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-019-00130-2,springer
Article,doi:10.1007/s12205-020-2074-y,UAV-RFID Integration for Construction Resource Localization,KSCE Journal of Civil Engineering,10.1007/s12205-020-2074-y,Springer,2020-06-01,2020-05-08,"Location data of construction resources are important in understanding on the context of a construction site, yet most sites still rely on people’s observations to localize their resources. Among then various localization technologies, radio frequency identification (RFID) is considered as a good solution. However, RFID either provides limited location data when fixed receivers are used, or it requires considerable manpower for scanning the tagged resources when hand-held receivers are used. These requirements result in inefficiency and impractical demands on time and cost, particularly in the case of complex or large-scale sites. This study attempted to overcome the limitations by proposing an integrated unmanned aerial vehicle-RFID (UAV-RFID) platform to replace the considerable manpower with the UAV and to enable identifying tags on a site. It applies deep learning algorithms to localize an RFID tag position within an acceptable range of accuracy, thereby demonstrating the feasibility of the integrated platform for construction resource localization.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s12205-020-2074-y,springer
Article,doi:10.1007/s10812-020-01001-6,Desertification Glassland Classification and Three-Dimensional Convolution Neural Network Model for Identifying Desert Grassland Landforms with Unmanned Aerial Vehicle Hyperspectral Remote Sensing Images,Journal of Applied Spectroscopy,10.1007/s10812-020-01001-6,Springer,2020-05-01,2020-05-21,"Based on deep learning, a desertification grassland classification (DGC) and three-dimensional convolution neural network (3D-CNN) model is established. The F-norm^ 2 paradigm is used to reduce the data; the data volume was effectively reduced while ensuring the integrity of the spatial information. Through structure and parameter optimization, the accuracy of the model is further improved by 9.8%, with an overall recognition accuracy of the optimized model greater than 96.16%. Accordingly, high-precision classification of desert grassland features is achieved, informing continued grassland remote sensing research.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10812-020-01001-6,springer
Article,doi:10.1007/s10846-019-01073-3,Towards Real-Time Path Planning through Deep Reinforcement Learning for a UAV in Dynamic Environments,Journal of Intelligent & Robotic Systems,10.1007/s10846-019-01073-3,Springer,2020-05-01,2019-09-07,"Path planning remains a challenge for Unmanned Aerial Vehicles (UAVs) in dynamic environments with potential threats. In this paper, we have proposed a Deep Reinforcement Learning (DRL) approach for UAV path planning based on the global situation information. We have chosen the STAGE Scenario software to provide the simulation environment where a situation assessment model is developed with consideration of the UAV survival probability under enemy radar detection and missile attack. We have employed the dueling double deep Q-networks (D3QN) algorithm that takes a set of situation maps as input to approximate the Q-values corresponding to all candidate actions. In addition, the ε-greedy strategy is combined with heuristic search rules to select an action. We have demonstrated the performance of the proposed method under both static and dynamic task settings.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-019-01073-3,springer
Article,doi:10.1007/s11053-019-09573-7,Prediction of Blast-Induced Ground Vibration Intensity in Open-Pit Mines Using Unmanned Aerial Vehicle and a Novel Intelligence System,Natural Resources Research,10.1007/s11053-019-09573-7,Springer,2020-04-01,2019-10-28,"Predicting and reducing blast-induced ground vibrations is a common concern among engineers and mining enterprises. Dealing with these vibrations is a challenging issue as they may result in the instability of the surrounding structures, highways, water pipes, railways, and residential areas. In this study, the effects of blasting in a quarry mine in Vietnam were examined. A total of 25 blasting events were investigated with the help of an unmanned aerial vehicle, micromate instruments, and blast patterns, and 83 observations were recorded. Subsequently, the fuzzy C-means clustering (FCM) algorithm was applied to classify the 83 observations based on the blast parameters. Finally, based on the classification of the blasts, quantile regression neural network (QRNN) models were developed. The combination of FCM and QRNN models resulted in a novel, hybrid model (FCM-QRNN) for predicting blast-induced ground vibration. The US Bureau of Mines (USBM), random forest (RF), QRNN (without clustering), and artificial neural network (ANN) models were also considered and compared with the FCM-QRNN model to obtain a comprehensive assessment of the proposed model. The results indicate that the proposed FCM-QRNN model has a higher accuracy than the other models: USBM, QRNN, RF, and ANN. The proposed model can be used to control the undesirable effects of blast-induced ground vibration. Although this study and the proposed FCM-QRNN model are original works with positive results, the performance of this model in other locations still needs to be considered as a case study for further scientific information.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11053-019-09573-7,springer
Article,doi:10.1007/s40435-018-0478-z,Novel SMC control design for path following of autonomous vehicles with uncertainties and mismatched disturbances,International Journal of Dynamics and Control,10.1007/s40435-018-0478-z,Springer,2020-03-01,2018-12-03,"The article propose a novel robust, accurate, and fast control strategy with uncertainties/mismatched disturbances for path following control of autonomous vehicles using an innovative sliding mode control (SMC).The molded SMC is based on gain scheduling with fuzzy system, the algorithm of a radial basis function neural networks (RBFNN) and disturbance observer (DOB). The fuzzy system provide an automatic adjustment of the gain of SMC in order to compensate variations of system parameters; the use of DOB is to estimate the mismatched disturbances, and the RBFNN is for assessing the uncertainties. In addition, the stability of the closed-loop system is proved by the Lyapunov stability theorem. The proposed controller is applied to the path following of autonomous vehicle in extreme driving condition at high speed and under different road adhesion conditions. To show the effectiveness of our controller, simulation results have been compared with other robust strategies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40435-018-0478-z,springer
Article,doi:10.1007/s10846-019-01031-z,An Intelligent Hybrid Artificial Neural Network-Based Approach for Control of Aerial Robots,Journal of Intelligent & Robotic Systems,10.1007/s10846-019-01031-z,Springer,2020-02-01,2019-05-04,"In this work, a learning model-free control method is proposed for accurate trajectory tracking and safe landing of unmanned aerial vehicles (UAVs). A realistic scenario is considered where the UAV commutes between stations at high-speeds, experiences a single motor failure while surveying an area, and thus requires to land safely at a designated secure location. The proposed challenge is viewed solely as a control problem. A hybrid control architecture – an artificial neural network (ANN)-assisted proportional-derivative controller – is able to learn the system dynamics online and compensate for the error generated during different phases of the considered scenario: fast and agile flight, motor failure, and safe landing. Firstly, it deals with unmodelled dynamics and operational uncertainties and demonstrates superior performance compared to a conventional proportional-integral-derivative controller during fast and agile flight. Secondly, it behaves as a fault-tolerant controller for a single motor failure case in a coaxial hexacopter thanks to its proposed sliding mode control theory-based learning architecture. Lastly, it yields reliable performance for a safe landing at a secure location in case of an emergency condition. The tuning of weights is not required as the structure of the ANN controller starts to learn online, each time it is initialised, even when the scenario changes – thus, making it completely model-free. Moreover, the simplicity of the neural network-based controller allows for the implementation on a low-cost low-power onboard computer. Overall, the real-time experiments show that the proposed controller outperforms the conventional controller.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-019-01031-z,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-30465-2_75,Distance Measurement for Self-driving Vehicles Using Data Fusion and Machine Learning,"Intelligent Computing, Information and Control Systems",10.1007/978-3-030-30465-2_75,Springer,2020-01-01,2019-10-19,"For certain mobile robots and self driving vehicles, accurate measurement of distance ahead of them is indispensable. Several sensors are utilized to achieve this. This work is on fusing the obtained data from two sensors namely Leddar M-16 and RPLidar 360. A comparison of the accuracy of the distance measured from the vehicle to obstacle using Leddar M-16 and RPLidar 360 is being done. Also these results are being compared to the improved accuracy of the resultant from both sensors after the data is fused together to produce a different set of values. Analysis on the data is done using a tool named Weka. Test bed and experiments were designed for collection of data. A machine learning technique, linear regression is used for improving accuracy of the measurement.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30465-2_75,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-44289-7_50,Path Planning of a Self Driving Vehicle Using Artificial Intelligence Techniques and Machine Vision,Proceedings of the International Conference on Artificial Intelligence and Computer Vision (AICV2020),10.1007/978-3-030-44289-7_50,Springer,2020-01-01,2020-03-24,"This paper aims to implement an efficient model of the most optimum path to follow an object on a Self Driving Vehicle (SDV). The path of the vehicle is predicted by using Machine Vision (MV) and Neural networks (NN) model. The NN model uses numerous amounts of training data. First the system works by using the MV algorithms to detect objects with predefined colors. Then, the location of the object is fed to the trained NN to get the speeds of the motors needed to reach the object. The training data are obtained from the manual driving of the vehicle in different experiment settings. In this paper, the neural model is compared with two other methods: object detection using MV model and fuzzy logic (FL) model to prove the efficiency of the neural model. All the three models depend on the live record of the camera board and its fast detection of objects using MV algorithms. The three models showed quite similar results; however, the NN model was much more stable and closer to the optimum path.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-44289-7_50,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-1081-6_5,End-to-End Reinforcement Learning for Self-driving Car,Advanced Computing and Intelligent Engineering,10.1007/978-981-15-1081-6_5,Springer,2020-01-01,2020-02-19,"Most of the current self-driving cars make use of multiple algorithms to drive. Furthermore, most of the approaches use supervised learning to train a model to drive the car autonomously. This approach leads to human bias being incorporated into the model. We implement the Deep Q -Learning algorithm to control a simulated car, end-to-end, autonomously. The algorithm is based on reinforcement learning which teaches machines what to do through interactions with the environment. The application of reinforcement learning for driving is of high relevance as it is highly dependent on interactions with the environment. Our model incorporates a CNN as the deep Q network. The system was tested on an open-source car-racing simulator called TORCS. The Deep Q -Learning approach allows the system to be more efficient and robust than a system that has been trained solely through supervised training. Our simulation results show that the system is able to drive autonomously and maneuver complex curves.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-1081-6_5,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-4301-2_17,Steering Angle Estimation for Self-driving Car Using Deep Learning,"Machine Learning and Metaheuristics Algorithms, and Applications",10.1007/978-981-15-4301-2_17,Springer,2020-01-01,2020-04-05,"The contemporary age has seen a tremendous increase in the number of road accidents. Traffic accidents are commonly caused by driver error, mobile phone usage, in-car audio and video entertainment systems, and extensive traffic. The road accident in India causes one death every four minutes. Imagine if everyone can easily and safely get around while driving is not tired, drunk or distracted. Self-driving means of transport are those in which drivers are never required to drive the vehicle. In self-driving car, time spent on travel may well be time spent doing what one needs, because all driving is handled by the car. Also referred to as autonomous or “driverless” cars, they mix sensors and code to manage, navigate, and drive the vehicle. The self-driving cars have huge potential to alter the means of transportation. We have proposed an end-to-end method based on deep learning for estimating the steering angle and the accuracy obtained is 98.6%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-4301-2_17,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-44267-5_27,Traffic Sign Classification Using Embedding Learning Approach for Self-driving Cars,"Human Interaction, Emerging Technologies and Future Applications II",10.1007/978-3-030-44267-5_27,Springer,2020-01-01,2020-04-03,"Image classification is one of the most popular and important problems in computer vision. In self-driving cars image classification is used to classify detected traffic signs. Modern state-of-the-art algorithms based on deep neural networks use softmax function to interpret the output of the network as the probability that the input data belongs to a certain class. This approach works well, however it has several disadvantages. More precisely, it is necessary to know the number of classes in advance, and if one wants to add a new class, then it is necessary to retrain the network. Moreover, a large number of images of each class are required. In the case of road signs, datasets may contain only the most frequent signs while ignoring rarely used ones. Thus, the traffic signs recognition module in autonomous cars will not recognize traffic signs not included into training dataset, which can lead to accidents. In this paper we put forward another approach that does not have disadvantages of networks with softmax. The approach is based on learning image embeddings in which models are trained to bring closer objects of one class and to move away objects of other classes in embeddings space. Therefore, having even a small number of images of rare classes it becomes possible to create a working classification system. In this work, we test the applicability of these algorithms in the traffic signs classification problem, and also compare its accuracy with neural networks with softmax and with networks pre-trained on softmax. We developed publicly available toolbox for training and testing embedding networks with different loss functions, backbone models, training strategies and other configuration parameters and embedding space visualization tools. All our experiments were carried out on the russian road signs dataset. To simplify the process of conducting training experiments, a framework for embedding learning based neural networks making was created. The framework can be found at https://github.com/RocketFlash/EmbeddingNet .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-44267-5_27,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-0694-9_27,Pedestrian–Autonomous Vehicles Interaction Challenges: A Survey and a Solution to Pedestrian Intent Identification,Advances in Data and Information Sciences,10.1007/978-981-15-0694-9_27,Springer,2020-01-01,2020-01-03,"Autonomous Vehicles are on rise around the globe, millions of them are already there on road with medium levels of automation but still there is a long way to go for full autonomy. One of the biggest roadblocks for autonomous vehicles to reach full autonomy is driving in urban environments. To make autonomous vehicles fully autonomous, they require the ability to communicate with other road users (pedestrian, vehicles, and other road users) and understand their intentions. Social interaction is a complex task, there are uncountable scenarios that happen on roads that require human interaction both verbal and nonverbal. Deciding whether a person standing on the sidewalk is about to cross the road, or they are just waiting near the sidewalk is a difficult task for an autonomous vehicle, and it could be a matter of life-and-death in case of a vehicle driving at very high speed. So, it is very important for self-driving cars to identify true intentions of on-road pedestrians and understand social interaction norms. In this paper, we go through some of the challenges in Pedestrian and Autonomous vehicles interaction that autonomous vehicles might face while driving in an urban environment; after that we propose a novel architecture for identifying pedestrian’s intention using pedestrian’s detection, pose estimation, and classification algorithms while discussing different methods of each.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-0694-9_27,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-59535-7_6,Navigating Autonomous Vehicle at the Road Intersection Simulator with Reinforcement Learning,Artificial Intelligence,10.1007/978-3-030-59535-7_6,Springer,2020-01-01,2020-09-22,"In this paper, we consider the problem of controlling an agent that simulates the behavior of an self-driving car when passing a road intersection together with other vehicles. We consider the case of using smart city systems, which allow the agent to get full information about what is happening at the intersection in the form of video frames from surveillance cameras. The paper proposes the implementation of a control system based on a trainable behavior generation module. The agent’s model is implemented using reinforcement learning (RL) methods. In our work, we analyze various RL methods (PPO, Rainbow, TD3), and variants of the computer vision subsystem of the agent. Also, we present our results of the best implementation of the agent when driving together with other participants in compliance with traffic rules.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-59535-7_6,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-30465-2_11,Object Detection for Autonomous Vehicle Using TensorFlow,"Intelligent Computing, Information and Control Systems",10.1007/978-3-030-30465-2_11,Springer,2020-01-01,2019-10-19,"The area of computer vision is emerging continually with the increasing interaction and development to provide a comfortable interaction between human and machines. One of the key aspects in the process of computer vision is object detection. Either objects can be identified partially or close to the original objects. The accuracy in detecting the objects can be improved by using state-of-the-art deep learning models like faster-Regional Convoluted Neural Network (faster-RCNN), You Only Look Once model (YOLO), Single Shot Detector (SSD) etc. Traditional algorithms can’t recognize objects as efficiently due to its limitations. Whereas the deep learning models require large amount of data for training the dataset, which has more resource and labour intensive in nature. The selection of algorithm determines its precision in object detection as well as its reliability. The recognition and classification of object begins with preparing dataset followed by splitting the dataset into training dataset and test dataset. The task of training the dataset can be assisted by both traditional as well as modern deep neural networks. The loss per step or epoch is calculated on the training dataset to signify the efficiency and accuracy of the model. In this model, the loss per step is 2.73. We have achieved a maximum accuracy of about 85.18% after training the dataset used.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30465-2_11,springer
Chapter ConferencePaper,doi:10.1007/978-981-13-9042-5_59,Self Driving Car,Computational Intelligence in Pattern Recognition,10.1007/978-981-13-9042-5_59,Springer,2020-01-01,2019-08-18,"The self-driving car is capable Kumar, Ankit  of sensing its environment and navigating without human input Mukherjee, Mayukh  which it applies the technology of autonomous vehicle that allows the car to experiment driverless experience. Software designed Mukhopadhyay, Preetam  to drive from point A to point B without requiring any human intervention is implemented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-9042-5_59,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-0694-9_34,Self-driving Cars: An Overview of Various Autonomous Driving Systems,Advances in Data and Information Sciences,10.1007/978-981-15-0694-9_34,Springer,2020-01-01,2020-01-03,"A car that can navigate by itself without being dependent on human for inputs is known as a self-driving car. There has been a great advancement in automobile industry which is bringing new technologies every day. There are various types of autonomous cars and they are divided based on their level of automation, which includes level 0 to level 5. Advanced methodologies are used to build these cars, and concepts like machine learning and computer vision play a vital role in development of these cars. The accuracy varies based on lots of factors including both internal and external factors. This paper presents survey done on various technologies used in these cars with their results and also about their current trends.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-0694-9_34,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-58817-5_72,Detection of Obstacle Features Using Neural Networks with Attention in the Task of Autonomous Navigation of Mobile Robots,Computational Science and Its Applications – ICCSA 2020,10.1007/978-3-030-58817-5_72,Springer,2020-01-01,2020-09-30,"This article describes the design process of a software package for image recognition of a mobile robot camera using neural networks with attention, which allows to identify the probability of a robot colliding with obstacles standing in its way. A key feature of this software is using a dataset that is prepared without manual labeling of all obstacles and the probability of a collision. Currently, an important task in mobile robotics is the need to use numerous heuristics and deterministic algorithms in control programs along with neural networks. The use of a single neural network that solves all the tasks of scene analysis (the so-called “end-to-end” solution) is impossible for several reasons: the high complexity of the training samples due to the large parameter space of the environment of the robot and the insufficient formalization of these parameters, as well as the computational complexity of machine learning algorithms, which is critical for mobile robots with strict energy requirements. Therefore, the development of a universal algorithm (end-to-end) is a laborious process. The article describes a method that allows to use weakly formalized parameters of the robot environment for training convolutional neural networks with attention using the obstacle recognition task. At the same time, weak formalization reduces the time-consuming process of manual data labeling due to automatically generated datasets in the NVIDIA Isaac environment, and the attention mechanism allows increasing the interpretability of the analysis results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-58817-5_72,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-39512-4_8,The Future of User Experience Design in the Interior of Autonomous Car Driven by AI,Intelligent Human Systems Integration 2020,10.1007/978-3-030-39512-4_8,Springer,2020-01-01,2020-01-22,"Today it is not easy to imagine what would be the future of user experience (UX) design in the world of Artificial Intelligence (AI). Referring to the sector of autonomous vehicles the paper aims to explore the changes that will be brought by artificial intelligence to the innovative sector of the self-driving car. According to these transformation car interiors and passengers experiences will become very different from the actual one. The aim of the research is, starting from different kind of passengers needs (Human Centered Design approach) individuating essential factors to design autonomous cars interiors and in particular to design innovative interfaces for a better communication with the passengers and a high level of living experience for different kind of users.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-39512-4_8,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-19562-5_18,Enhancing Cooperative Spectrum Sensing in Flying Cell Towers for Disaster Management Using Convolutional Neural Networks,EAI International Conference on Big Data Innovation for Sustainable Cognitive Computing,10.1007/978-3-030-19562-5_18,Springer,2020-01-01,2019-10-19,Natural calamities are increasing every year and communication plays a major role in post disaster measures to save human lives. This work utilizes the adaptation of the emerging dynamic radio technology called cognitive radio networks over Unmanned Aerial vehicles (UAV). Enhancing emergency communication over disaster affected zones where the mobile network base stations are completely destroyed is enabled by mounting drones with an omni antenna base station. This chapter analyses the cooperative spectrum sensing (CSS) technique of the intelligent radio to study incoming primary user (PU) when the available spectrum consists of multiple secondary users (SUs). A deep learning based technique called SpecCNN (Spectrum sensing Convolutional Neural Network) is proposed for performing intelligent spectrum sensing by analysing hidden cyclostationary features from drone data (image) of disastrous areas.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-19562-5_18,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-30425-6_34,Automated Determination of Forest-Vegetation Characteristics with the Use of a Neural Network of Deep Learning,"Advances in Neural Computation, Machine Learning, and Cognitive Research III",10.1007/978-3-030-30425-6_34,Springer,2020-01-01,2019-09-04,"The article proposes a method of automated solution for determining the species composition, stock coefficient and other characteristics of forest plantations with the use of deep learning. The analysis of existing approaches and ways of forest inventory, which include the use of LiDAR systems and machine learning methods, is carried out. An algorithm is proposed for solving this problem and features of its implementation are given. The problem of combining the data of a “dense cloud” and a lidar survey is considered, a possible solution is proposed. The problem of segmentation of tree crowns among many other objects in this data is also considered. For the segmentation of crowns, it is proposed to use the PointNet neural network of deep learning, which allows segmentation of objects by submitting a point cloud to the input. The description of the architecture and the main features of the neural network use are briefly given. The path of further research is determined.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30425-6_34,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-0633-8_102,Image Processing for UAV Using Deep Convolutional Encoder–Decoder Networks with Symmetric Skip Connections on a System on Chip (SoC),International Conference on Intelligent Computing and Smart Communication 2019,10.1007/978-981-15-0633-8_102,Springer,2020-01-01,2019-12-20,"Unmanned Aerial Vehicle (UAV) applications require capturing and analysis of aerial images and thus necessitate identification of obstacles, recognition of objects from a given set within images, and analogous tasks. In situations where the navigation or further action depends on the results of the analysis there exist time constraints. Ground based analysis is not feasible due to latency, connectivity or bandwidth constraints. A possible approach is to use a System on Chip (SoC) having GPU with their substantial parallel analysis capability for onboard image analysis. Developments in the domain of Deep Neural Networks have enabled a mechanism to design efficient and tailored solutions for image analysis. This research proposes the use of Deep Convolutional Encoder–Decoder Networks with Symmetric Skip Connections on a SoC having GPU to perform image analysis. The outlined trained network successfully completes the task of image segmentation using the SpaceNet dataset on a NVIDIA Jetson TX2 embedded computer.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-0633-8_102,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-32456-8_9,Unmanned Aerial Vehicles Path Planning Based on Deep Reinforcement Learning,"Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery",10.1007/978-3-030-32456-8_9,Springer,2020-01-01,2019-11-07,"Obstacle avoidance and path planning of unmanned aerial vehicles (UAVs) is an essential and challenging task, especially in the unknown environment with dynamic obstacles. To address this problem, a method of UAV path planning based on Deep Q-Learning is proposed. The experience replay mechanism is introduced in the deep reinforcement learning (DRL) process, and a value network is established to calculate the optimal value for the action of the UAV. The optimal flight policy of the UAV is determined through the $$\epsilon $$ -greed algorithm. The experimental results show that the UAV with well-trained model can avoid the obstacles in motion perfectly, and the cruise time is reduced by half compared with the untrained UAV.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-32456-8_9,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-6113-9_4,UAV – Virtual Migration Based on Obstacle Avoidance Model,Cognitive Cities,10.1007/978-981-15-6113-9_4,Springer,2020-01-01,2020-06-20,"In recent years, the obstacles avoidance technology of unmanned aerial vehicles has been developed rapidly. It takes a lot of manpower to control un-manned aerial vehicles, so many researches use reinforcement learning to make unmanned aerial vehicles fly autonomously. In the real environment using rein-for cement learning to train aircraft is an expensive and time-consuming work, because reinforcement learning is a way to learn from mistakes, so there are often bumps in the learning process. In Wu’s research, they trained a good model, but the realistic environment and simulation environment differs very big, so we will train this model again and transferred to the real environment, makes unmanned aerial vehicle in the realistic environment can use cheaper and quickly achieve the same task.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-6113-9_4,springer
Chapter,doi:10.1007/978-981-15-0327-6_15,"Artificial Intelligence in Japan: Policy, Prospects, and Obstacles in the Automotive Industry",Transforming Japanese Business,10.1007/978-981-15-0327-6_15,Springer,2020-01-01,2019-12-07,"As artificial intelligence (AI) has progressed, it seems inevitable for countries and firms across the world to change their old notions and attitudes toward new technologies. Since AI could have a major impact on many aspects of business and society, the future competitiveness of nations, let alone of companies, will hinge upon the effective utilization of AI technologies. However, Japan is currently falling behind the USA and China in the global technology race. Many Japanese companies that were market leaders at some point have lost their position in the international market. Toyota, the global leading car brand that also leads Japan’s automotive industry, is an exceptional case in the Japanese economy today. However, even Toyota is facing multiple challenges because AI is significantly changing the competitive landscape. Whereas the major carmakers have been keeping an eye on AI-directed self-driving cars, initially Toyota had some reservations about the development of self-driving cars. However, the company has recently changed its strategy. Despite sluggish government policies, Toyota has been accelerating its move into the new phase of competition with an unprecedented commitment to self-driving cars. Toyota’s recent activities somewhat contrast with the slow response of the Japanese government and most Japanese firms to the global trend. This chapter first provides an overview of Japan’s AI, followed by the Japanese government’s plan for self-driving cars. The third section depicts Toyota’s recent activities, focusing on self-driving cars. Reflecting on Toyota’s strategic changes as a benchmark, the last section discusses what Japan needs to do in order to transform itself and compete in the digital age.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-0327-6_15,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-51935-3_9,Vine Disease Detection by Deep Learning Method Combined with 3D Depth Information,Image and Signal Processing,10.1007/978-3-030-51935-3_9,Springer,2020-01-01,2020-07-08,"Vine disease detection (VDD) is an important asset to predict a probable contagion of virus or fungi. Diseases that spreads through the vineyard has a huge economic impact, therefore it is considered as a challenge for viticulture. Automatic detection and mapping of vine disease in earlier stage can help to limit its impact and reduces the use of chemicals. This study deals with the problem of locating symptomatic areas in images from an unmanned aerial vehicle (UAV) using the visible and infrared domains. This paper, proposes a new method, based on segmentation by a convolutional neuron network SegNet and a depth map (DM), to delineate the asymptomatic regions in the vine canopy. The results obtained showed that SegNet combined with the depth information give better accuracy than a SegNet segmentation alone.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-51935-3_9,springer
Chapter ConferencePaper,doi:10.1007/978-981-13-9406-5_43,Research on the Intelligent Unmanned Vehicle Measurement System,"Recent Trends in Intelligent Computing, Communication and Devices",10.1007/978-981-13-9406-5_43,Springer,2020-01-01,2019-10-02,"With the expansion of cities and the development of modern life, the traditional vehicle-mounted measurement control system has been difficult to meet the measurement demand in some cases. In order to meet the requirements of vehicle-mounted measurement intelligence and solve the problems of complicated and refined measurement tasks, an intelligent unmanned vehicle-mounted measurement system is proposed. This paper is based on artificial intelligence technology, unmanned vehicle as a platform, the control system modular design, realized unmanned vehicle measurement. This paper presents part of the data obtained from the current manned vehicle measurement, briefly introduces the control system, and discusses the advantages of the intelligent unmanned vehicle measurement system. This study provides some suggestions for the development of intelligent unmanned vehicle measurement equipment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-9406-5_43,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-19738-4_12,Road Tracking Using Deep Reinforcement Learning for Self-driving Car Applications,Progress in Computer Recognition Systems,10.1007/978-3-030-19738-4_12,Springer,2020-01-01,2019-05-08,"Deep reinforcement learning has received wide attentions recently. It combines deep learning with reinforcement learning and shows to be able to solve unprecedented challenging tasks. This paper proposes an efficient approach based on deep reinforcement learning to tackle the road tracking problem arisen from self-driving car applications. We propose a new neural network which collects input states from forward car facing views and produces suitable road tracking actions. The actions are derived from encoding the tracking directions and movements. We perform extensive experiments and demonstrate the efficacy of our approach. In particular, our approach has achieved 93.94% driving accuracy, outperforming the state-of-the-art approaches in literature.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-19738-4_12,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-4163-6_83,Application and Development of Artificial Intelligence Technology for Unmanned Aerial Vehicles,"Signal and Information Processing, Networking and Computers",10.1007/978-981-15-4163-6_83,Springer,2020-01-01,2020-04-05,"With the development of artificial intelligence, which has driven the revolution of the UAV (Unmanned Aerial Vehicles) industry. This paper introduces the development status of artificial intelligence technology in the field of UAV, and analyses the application of artificial intelligence technology in the field of UAV, Including the three aspects, intelligent perception, intelligent processing, intelligent decision-making, and proposed the development of intelligent UAS.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-4163-6_83,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-54549-9_13,Assuring the Safety of Machine Learning for Pedestrian Detection at Crossings,"Computer Safety, Reliability, and Security",10.1007/978-3-030-54549-9_13,Springer,2020-01-01,2020-07-31,"Machine Learnt Models (MLMs) are now commonly used in self-driving cars, particularly for tasks such as object detection and classification within the perception pipeline. The failure of such models to perform as intended could lead to hazardous events such as failing to stop for a pedestrian at a crossing. It is therefore crucial that the safety of the MLM can be proactively assured and should be driven by explicit and concrete safety requirements. In our previous work, we defined a process that integrates the development and assurance activities for MLMs within safety-related systems. This is used to incrementally generate the safety argument and evidence. In this paper, we apply the approach to pedestrian detection at crossings and provide an evaluation using the publicly available JAAD data set. In particular, we focus on the elicitation and analysis of ML safety requirements and how such requirements should drive the assurance activities within the data management and model learning phases. We explain the benefits of the approach and identify outstanding challenges in the context of self-driving cars.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-54549-9_13,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-29135-8_3,The AI Driving Olympics at NeurIPS 2018,The NeurIPS '18 Competition,10.1007/978-3-030-29135-8_3,Springer,2020-01-01,2019-11-30,"Despite recent breakthroughs, the ability of deep learning and reinforcement learning to outperform traditional approaches to control physically embodied robotic agents remains largely unproven. To help bridge this gap, we present the “AI Driving Olympics” (AI-DO), a competition with the objective of evaluating the state of the art in machine learning and artificial intelligence for mobile robotics. Based on the simple and well-specified autonomous driving and navigation environment called “Duckietown,” the AI-DO includes a series of tasks of increasing complexity—from simple lane-following to fleet management. For each task, we provide tools for competitors to use in the form of simulators, logs, code templates, baseline implementations and low-cost access to robotic hardware. We evaluate submissions in simulation online, on standardized hardware environments, and finally at the competition event. The first AI-DO, AI-DO 1, occurred at the Neural Information Processing Systems (NeurIPS) conference in December 2018. In this paper we will describe the AI-DO 1 including the motivation and design objections, the challenges, the provided infrastructure, an overview of the approaches of the top submissions, and a frank assessment of what worked well as well as what needs improvement. The results of AI-DO 1 highlight the need for better benchmarks, which are lacking in robotics, as well as improved mechanisms to bridge the gap between simulation and reality.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-29135-8_3,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-63486-5_16,Deep Learning-Based Decision Making for Autonomous Vehicle at Roundabout,Towards Autonomous Robotic Systems,10.1007/978-3-030-63486-5_16,Springer,2020-01-01,2020-12-03,"This study looks at the facilitation of computer vision and machine learning, which helps Autonomous vehicles (AVs) make pertinent decisions before entering a roundabout. A deep learning-based decision-making system (DBDM) is proposed in order to make a correct “Enter” or “Wait” decision when an AV enters a roundabout. In this regard, videos of human drivers negotiating different normal roundabouts, differing in terms of size, are employed alongside a range of different learning algorithms (e.g. VGG-16, Resnet-50 and Xception). In total, 130 videos captured at normal roundabouts were used to test the models, and VGG-16 performed best with an accuracy rate of 92.57% comparing with pervious work (GBIPA-SC-NR), thus suggesting that the proposed DBDM method can be applied effectively for AVs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-63486-5_16,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-30465-2_44,Simulation of a Self-Driving Car and Comparison of Various Training Methods,"Intelligent Computing, Information and Control Systems",10.1007/978-3-030-30465-2_44,Springer,2020-01-01,2019-10-19,"A simulation environment is presented in this paper for the autonomous driving of a car, along with its respective obstacles, tracks and tests. Unity 3D, which is a cross-platform game development platform and engine, powers this environment by providing basic navigation controls along with the functions for creating and recording the car’s parameters as an input dataset. Using a convolutional neural network, the system predicts the future output, thus achieving complete autonomous navigation, compatible with any environment. The paper also compares various pre-processing methods used on the input data, so as to find the most efficient model and to study which method contributes the most to effective autonomous driving.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30465-2_44,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-49062-1_23,Designing an AI-Companion to Support the Driver in Highly Autonomous Cars,Human-Computer Interaction. Multimodal and Natural Interaction,10.1007/978-3-030-49062-1_23,Springer,2020-01-01,2020-07-10,"In this paper, we propose a model for an AI-Companion for conditionally automated cars, able to maintain awareness of the driver regarding the environment but also to able design take-over requests (TOR) on the fly, with the goal of better support the driver in case of a disengagement. Our AI-Companion would interact with the driver in two ways: first, it could provide feedback to the driver in order to raise the driver Situation Awareness (SA), prevent them to get out of the supervision loop and so, improve takeover during critical situations by decreasing their cognitive workload. Second, in the case of TOR with a smart choice of modalities for convey the request to the driver. In particular, the AI-Companion can interact with the driver using many modalities, such as visual messages (warning lights, images, text, etc.), auditory signals (sound, speech, etc.) and haptic technologies (vibrations in different parts of the seat: back, headrest, etc.). The ultimate goal of the proposed approach is to design smart HMIs in semi-autonomous vehicles that are able to understand 1) the user state and fitness to drive, 2) the current external situation (vehicle status and behavior) in order to minimize the automation surprise and maximizing safety and trust, and 3) leverage AI to provide adaptive TOR and useful feedback to the driver.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-49062-1_23,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-38040-3_11,Lane Keep Assist System for an Autonomous Vehicle Using Support Vector Machine Learning Algorithm,Innovative Data Communication Technologies and Application,10.1007/978-3-030-38040-3_11,Springer,2020-01-01,2020-01-31,"Autonomous self driving vehicles are getting greater attention and this would be the future requirement in Automotive domain. However, Fail proof driving is the only solution to reduce the rate of accidents and that makes the driverless vehicles as a possible one. In man handled vehicles, by using Advance Driver Authorization System (ADAS), accident free driving can be ensured. This paper focuses on one of the ways to contribute towards accident free driving of autonomous vehicles by deploying a novel Lane Keep Assist (LKA) system. A Machine Learning algorithm has been used in proposed LKA system for tracking the lane of the autonomous vehicles by providing the required inputs. Proposed LKA system has been demonstrated in Matlab/Simulink platform and the results have been presented in this paper.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-38040-3_11,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-0474-7_32,Fuzzy Neural Network PID Control of Quadrotor Unmanned Aerial Vehicle Based on PSO-GA Optimization,"Proceedings of the 11th International Conference on Modelling, Identification and Control (ICMIC2019)",10.1007/978-981-15-0474-7_32,Springer,2020-01-01,2019-12-04,"Aiming at the characteristics of strict nonlinearity, strong coupling and instability of quadrotor UAV, a fuzzy neural network PID controller based on a hybrid particle swarm algorithm (PSO-GA) is designed. The global optimization ability is improved by integrating the crossover and mutation operations of the genetic algorithm into the particle swarm optimization algorithm. In this paper, the initial value of each parameter of fuzzy neural network is optimized offline by PSO-GA algorithm and adjusted online by gradient descent method. The optimized PID controller can be applied to the attitude control of the quadrotor UAV. The simulation results show that the system has faster response speed, stronger robustness, less steady-state error and stronger tracking ability than the traditional control algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-0474-7_32,springer
Chapter,doi:10.1007/978-3-030-38445-6_4,3 DOF Autonomous Control Analysis of an Quadcopter Using Artificial Neural Network,Modern Approaches in Machine Learning and Cognitive Science: A Walkthrough,10.1007/978-3-030-38445-6_4,Springer,2020-01-01,2020-02-05,"The Quadcopter is an Unmanned Aerial Vehicle (UAV) which has turned out to be exceptionally mainstream among specialists in the recent past due to the advantages it offers over conventional helicopters. Quadcopter is extremely unique and interesting, however it is inherently unsteady from streamlined features perspective and aerodynamics point of view. In recent past scientists have proposed many control schemes for the stability of quadcopter, but Artificial Neural Network (ANN) systems provide us with the fusion of human intelligence, logic and reasoning. The research focuses on the use of ANN for the control plant systems whose plant dynamics are expensive to model, inaccurate or change with time and environment. In this paper, we explore the Linear Quadratic Regulator (LQR) and Sliding Mode Control (SMC) control is designed for an quadcopter with 3 Degree Of freedom (DOF) Hover model by Quancer. The main benefits of this approach are the model’s ability of adapt quickly to unmodeled aerodynamics, disturbances, component failure due to battle damage, etc. It eliminates the costs and time associated with the wind tunnel testing and generation of control derivatives for the UAV’s.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-38445-6_4,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-37629-1_66,Smart Life Saving Navigation System for Emergency Vehicles,Innovations in Smart Cities Applications Edition 3,10.1007/978-3-030-37629-1_66,Springer,2020-01-01,2020-02-01,"Autonomous vehicles will establish their predominance in the near future and humans will experience a hassle-free travel as these vehicles do not demand human intervention. Autonomy diminishes disasters that may happen due to driver’s negligence. Emergency Vehicles (EVs) play a vital role in saving lives. An unobstructed path is to be provided to them to ease the mobility of EVs along busy roads. In this paper, the EVs are identified using Deep Learning (DL) based algorithms. Though they are driven by Neural Networks (NNs), there are some situations in which they have to mimic a human. The ability to perceive and respond to EVs is addressed in this paper. Self-Driving Vehicles (SDVs) are to be incorporated with the knowledge of a fast approaching EV using algorithms like Convolutional Neural Network (CNN), Fast Region-based Convolutional Network (Fast R-CNN) and You Only Look Once (YOLO) algorithm. It is seen that YOLO offers better results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-37629-1_66,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-65218-0_26,Intelligent Unmanned Aerial Vehicle Technology in Urban Environments,Digital Transformation and Global Society,10.1007/978-3-030-65218-0_26,Springer,2020-01-01,2021-01-09,"Sustainable development of megacities requires a transition to the new management methods and technologies, based on the wide use of a large amount of heterogeneous data. Managing the urban economy needs to consider environmental restrictions, environmental monitoring tasks, engineering facilities, and transport. Operational control over the urban environment and the surrounding area can be produced using unmanned aerial vehicles (UAVs), and the collected data can be processed using a wide range of software and hardware technologies related to the field of artificial intelligence. However, along with any fairly new technology, intelligent unmanned technologies have both advantages and disadvantages. Strengths are mobility and efficiency, relative cheapness, the possibility of a high degree of automation, whereas weaknesses are short flight time, dependence on weather conditions, the certain outstanding tasks of data management and processing. This paper considers the possibilities of using intelligent unmanned technologies based on UAVs for solving the problems of monitoring the urban environment of the Kazakhstan megalopolises. Consideration is also being given to the scope for extending possibilities of applying these technologies to the field of environmental monitoring, monitoring of hazardous geological processes, technical constructions and vehicles. Furthermore, technological and economic issues, as well as necessary data processing technologies, are discussed. The economic effect of the use of IUVAT is estimated at $ 70-200 million, but it requires solving a set of data processing, control and technical problems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-65218-0_26,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-65299-9_4,Unsupervised Intrusion Detection System for Unmanned Aerial Vehicle with Less Labeling Effort,Information Security Applications,10.1007/978-3-030-65299-9_4,Springer,2020-01-01,2020-12-09,"Along with the importance of safety, an IDS has become a significant task in the real world. Prior studies proposed various intrusion detection models for the UAV. Past rule-based approaches provided a concrete baseline IDS model, and the machine learning-based method achieved a precise intrusion detection performance on the UAV with supervised learning models. However, previous methods have room for improvement to be implemented in the real world. Prior methods required a large labeling effort on the dataset, and the model could not identify attacks that were not trained before. To jump over these hurdles, we propose an IDS with unsupervised learning. As unsupervised learning does not require labeling, our model let the practitioner not to label every type of attack from the flight data. Moreover, the model can identify an abnormal status of the UAV regardless of the type of attack. We trained an autoencoder with the benign flight data only and checked the model provides a different reconstruction loss at the benign flight and the flight under attack. We discovered that the model produces much higher reconstruction loss with the flight under attack than the benign flight; thus, this reconstruction loss can be utilized to recognize an intrusion to the UAV. With consideration of the computation overhead and the detection performance in the wild, we expect our model can be a concrete and practical baseline IDS on the UAV.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-65299-9_4,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-0035-0_5,Autonomous Vehicle for Obstacle Detection and Avoidance Using Reinforcement Learning,Soft Computing for Problem Solving,10.1007/978-981-15-0035-0_5,Springer,2020-01-01,2019-11-28,"Obstacle detection and avoidance during navigation of an autonomous vehicle is one of the challenging problems. Different sensors like RGB camera, Radar, and Lidar are presently used to analyze the environment around the vehicle for obstacle detection. Analyzing the environment using supervised learning techniques has proven to be an expensive process due to the training of different obstacle for different scenarios. In order to overcome such difficulty, in this paper Reinforcement Learning (RL) techniques are used to understand the uncertain environment based on sensor information to make the decision. Policy free, model-free Q-learning based RL algorithm with the multilayer perceptron neural network (MLP-NN) is applied and trained to predict optimal vehicle future action based on the current state of the vehicle. Further, the proposed Q-Learning with MLP-NN based approach is compared with the state of the art, namely, Q-learning. A simulated urban area obstacles scenario is considered with the different number of ultrasonic radar sensors in detecting obstacles. The experimental result shows that Q-learning with MLP-NN along with the ultrasonic sensors is proven to be more accurate than conventional Q-learning technique with the ultrasonic sensors. Hence it is demonstrated that combining Q-learning with MLP-NN will improve in predicting obstacles for autonomous vehicle navigation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-0035-0_5,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-0936-0_47,Computer Vision Based Position and Speed Estimation for Accident Avoidance in Driverless Cars,ICT Systems and Sustainability,10.1007/978-981-15-0936-0_47,Springer,2020-01-01,2020-02-29,"In the field of driverless cars, safety is the main concern. The safety systems for these cars are mainly dependent on the inputs of cameras and sensors like Light Detection and Ranging (LIDARs). Lidar is an essential component in driverless cars which creates 3D map of the surrounding and assists the car for driving. Lidar based safety systems are effective but are very expensive as the lidars are costly. Hence, there is a need to design a system which can assist the car effectively on the road, without using the lidar. This paper presents a proposed design of accident avoidance system for driverless cars, which uses computer vision techniques and works on the input of single video camera. It analyzes the video frames and shows accident warnings while on turn or lane change. The system is cost effective and can work with IoT devices having low computational power. To verify the performance of the system, we have performed experiments on various scenarios including cars at different positions moving with different speed and we obtained satisfactory results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-0936-0_47,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-38919-2_25,Crowd Detection for Drone Safe Landing Through Fully-Convolutional Neural Networks,SOFSEM 2020: Theory and Practice of Computer Science,10.1007/978-3-030-38919-2_25,Springer,2020-01-01,2020-01-17,"In this paper, we propose a novel crowd detection method for drone safe landing, based on an extremely light and fast fully convolutional neural network. Such a computer vision application takes advantage of the technical tools some commercial drones are equipped with. The proposed architecture is based on a two-loss model in which the main classification task, aimed at distinguishing between crowded and non-crowded scenes, is simultaneously assisted by a regression task, aimed at people counting. In addition, the proposed method provides class activation heatmaps, useful to semantically augment the flight maps. To evaluate the effectiveness of the proposed approach, we used the challenging VisDrone dataset, characterized by a very large variety of locations, environments, lighting conditions, and so on. The model developed by the proposed two-loss deep architecture achieves good values of prediction accuracy and average precision, outperforming models developed by a similar one-loss architecture and a more classic scheme based on MobileNet. Moreover, by lowering the confidence threshold, the network achieves very high recall, without sacrificing too much precision. The method also compares favorably with the state-of-the-art, providing an effective and efficient tool for several safe drone applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-38919-2_25,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-66823-5_35,Multi-view Convolutional Network for Crowd Counting in Drone-Captured Images,Computer Vision – ECCV 2020 Workshops,10.1007/978-3-030-66823-5_35,Springer,2020-01-01,2021-01-03,"This paper proposes a novel lightweight and fast convolutional neural network to learn a regression model for crowd counting in images captured from drones. The learning system is initially based on a multi-input model trained on two different views of the same input for the task at hand: ( i ) real-world images; and ( ii ) corresponding synthetically created “crowd heatmaps”. The synthetic input is intended to help the network focus on the most important parts of the images. The network is trained from scratch on a subset of the VisDrone dataset. During inference, the synthetic path of the network is disregarded resulting in a traditional single-view model optimized for resource-constrained devices. The derived model achieves promising results on the test images, outperforming models developed by state-of-the-art lightweight architectures that can be used for crowd counting and detection.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-66823-5_35,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-24097-4_20,System to Detect and Approach Humans from an Aerial View for the Landing Phase in a UAV Delivery Service,"Ambient Intelligence – Software and Applications –,10th International Symposium on Ambient Intelligence",10.1007/978-3-030-24097-4_20,Springer,2020-01-01,2019-06-23,"The possibility to engage in autonomous flight through geolocation-based missions turns Unmanned Aerial Vehicles (UAV) into valuable tools that save time and resources in services like deliveries and surveillance. Amazon is already developing a drop-by delivery service, but there are limitations regarding the client’s id, that can be analyzed in three phases: the approach to the potential receiver, the authorization through the client id and the delivery itself. This work shows a solution for the first of these phases. Firstly, the receiver identifies the GPS coordinates where he wants to receive the package. The UAV flights to that place and tries to locate the receiver on the arrival through Computer Vision (CV) techniques, more precisely Deep Neural Networks (DNN), to continue to the next phase, the identification. After the proposal of the system’s architecture and the prototype’s implementation, a test scenario to analyze the feasibility of the proposed techniques was created. The results were quite good considering a system to look for one person in a limited area defined by the destination coordinates, confirming the detection of one person with an up to 92% accuracy from a 10 m height and 5 m horizontal distance in low resolution images.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-24097-4_20,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-35990-4_9,Evaluation of Lightweight Convolutional Neural Networks for Real-Time Electrical Assets Detection,Robot 2019: Fourth Iberian Robotics Conference,10.1007/978-3-030-35990-4_9,Springer,2020-01-01,2019-11-20,"The big growth of electrical demand by the countries required larger and more complex power systems, which have led to a greater need for monitoring and maintenance of these systems. To overcome this problem, UAVs equipped with appropriated sensors have emerged, allowing the reduction of the costs and risks when compared with traditional methods. The development of UAVs together with the great advance of the deep learning technologies, more precisely in the detection of objects, allowed to increase the level of automation in the process of inspection. This work presents an electrical assets monitoring system for detection of insulators and structures (poles and pylons) from images captured through a UAV. The proposed detection system is based on lightweight Convolutional Neural Networks and it is able to run on a portable device, aiming for a low cost, accurate and modular system, capable of running in real time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-35990-4_9,springer
Chapter,doi:10.1007/978-3-030-32710-1_9,Hierarchical Neuro-Game Model of the FANET Based Remote Monitoring System Resources Balancing,Smart Electromechanical Systems,10.1007/978-3-030-32710-1_9,Springer,2020-01-01,2019-11-03,The article discusses the basic principles of the methodology for the resource control optimizing of the remote monitoring system based on the FANET (Flying Ad Hoc Network) in real time. The hierarchical game model of optimization of control of system resources in the conditions of uncertainty on the basis of the coordinated stably-effective compromises is developed. The problem of synthesis of game algorithms of load balancing in communication channels based on neural networks of radial basis functions is solved. The developed situational model and neurofeedback algorithms provide structural adaptation of the system to the changing operating conditions and a given level of time delays in communication channels under the conditions of uncertainty of the input data queues.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-32710-1_9,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-37629-1_60,Applying External Guidance Commands to Deep Reinforcement Learning for Autonomous Driving,Innovations in Smart Cities Applications Edition 3,10.1007/978-3-030-37629-1_60,Springer,2020-01-01,2020-02-01,"End-to-end deep reinforcement learning [ 1 ] algorithms used in autonomous car field and trained on lane-keeping task achieve good results in roads that don’t require decision making but cannot deal with situations where getting driving direction is mandatory like choosing to turn left or right in an upcoming crossroads, deciding when to leave a traffic circle or toward which path/destination to go. In this paper we introduce a new Deep Reinforcement Learning model that enable to integrate guidance commands at test time as a complementary input that indicate the right direction, that we call Deep Reinforcement Learning with guidance (DRLG), we apply the DRLG architecture on two algorithms, the asynchronous advantage actor-critic A3C and the Deep Deterministic Policy Gradient algorithm DDPG. For the training and experimentations of the new model, we adopt the CARLA virtual environment, a High-fidelity realistic driving simulator as a testbed since leading driving tests in the real world turns out to be neither safe nor affordable in term of materials and requirements. The results of testing show that DDPG and A3C with Guidance (DDPGG and A3CG) models succeed on their driving task through roads/roundabouts, by being appropriately responsive to the external commands, which allow to the autonomous car to follow the indicated route and take the right turns.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-37629-1_60,springer
Chapter ConferencePaper,doi:10.1007/978-981-13-9267-2_26,A Rule-Based Approach for Controlling UAVs Formation Flight,Proceedings of 14th International Conference on Electromechanics and Robotics “Zavalishin's Readings”,10.1007/978-981-13-9267-2_26,Springer,2020-01-01,2019-08-30,"In this paper, we formulate the problems of forming a desired structure and controlling the obtained formation for a group of unmanned aerial vehicles (UAVs). Two general solution schemes of the formulated problems are proposed, and the mathematical apparatus for forming and controlling the desired formation is given. First scheme implies the optimal assignment of UAVs to goal positions in the desired formation, collision avoidance by sequential modification of the basic plan and planning ideal trajectories. As an alternative scheme, we propose to apply Kohonen network algorithm extended by a mechanism for detecting collisions. When necessary trajectories are obtained, an original rule-based approach is applied that comes down to pursuing a target, which simulates the reference flight. Each UAV in a group implements behavioral strategies for maintaining formation flight and avoiding collisions in the restless atmosphere. In the experimental part, we present simulation results of controlling the formation of several unmanned aerial vehicles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-9267-2_26,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-37393-1_20,Comparison of Performance of Artificial Neural Network (ANN) and Random Forest (RF) in the Classification of Land Cover Zones of Urban Slum Region,Proceedings of UASG 2019,10.1007/978-3-030-37393-1_20,Springer,2020-01-01,2020-02-23,"India is one of the world’s largest economies and economic growth has remained continuous. This has led to accelerating urbanization which requires proper planning and monitoring. As the urban areas are expanding, urban slum areas are also increasing along with it. These growing urban slum areas require proper observation so that existing resources can be employed to provide these regions with the best possible livelihood conditions. For this purpose, urban slum areas as well as surrounding land resources should be well identified and classified so that the existing land resources can be appropriately utilized for future implementation of development activities. Machine learning classification algorithms are found to be very suitable for the identification and classification of remotely sensed images. Their efficiency in feature identification and extraction has established these algorithms as important tools in decision making. In this study, our major objective is to identify and classify different land cover zones in the urban slums areas of Chingrajpara area of Chhattisgarh using remotely-sensed images. For this purpose, high-resolution images, collected using unmanned aerial vehicles (UAVs), are used and these images are classified into different land cover features using two different machine learning algorithms Artificial Neural Network (ANN) and Random Forest (RF). The results obtained show that the overall accuracy achieved by ANN and RF are 72.6% and 84.35% respectively. The study highlights the role and importance of landcover classification for future planning and management.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-37393-1_20,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-38651-1_12,Predicting Steering for Autonomous Vehicles Based on Crowd Sensing and Deep Learning,Internet of Vehicles. Technologies and Services Toward Smart Cities,10.1007/978-3-030-38651-1_12,Springer,2020-01-01,2020-01-19,"The challenge in ensuring the reliability of autonomous vehicles is full awareness of the surrounding environment and high-precision steering control. The latest solutions to this challenge include deep learning technologies that provide end-to-end solutions to predict steering angles directly from environmental cognition information with high accuracy. Under the background of 5G technology, edge device has certain computing power, which can reduce the load of on-board computing equipment. In this paper, we present a new distributed perception-decision network model. This model allows the network’s computing tasks to be offloaded to the edge computing devices to reduce the consumption of vehicle-mounted computing devices. The feasibility of the model is verified by experiments. Compared with the existing methods, the model also has a higher accuracy of steering prediction.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-38651-1_12,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-44289-7_28,A Hybrid Deep Learning Based Autonomous Vehicle Navigation and Obstacles Avoidance,Proceedings of the International Conference on Artificial Intelligence and Computer Vision (AICV2020),10.1007/978-3-030-44289-7_28,Springer,2020-01-01,2020-03-24,"Technological revolution has reached all life activities starting from day planning reaching communication, entertainment, industry, and transportation. Each of previously mentioned categories get improved in a way making human life easier and safer. In the use of automatic control, several researches focused on automating vehicles’ systems to make driving easier and safer. The availability of autonomous vehicles will avoid accidents caused by taking a late decision or lack of driving experience in such situation. Approaching autonomous driving, an autonomous vehicle must be able to respond to the state of objects in the surrounding, be it stationary or in motion. This paper outlines the techniques which enable the car to become conscious of its immediate environment while it moves independently and to decide its next course of action to avoid obstacles. It investigates two approaches which are Neuro-Fuzzy System tuned by Particle Swarm Optimization (PSO) and Convolutional Neural Network (CNN) tuned by Adaptive Moment estimation (Adam). Such control can allow cars on roads to operate smoothly and, according to trained data, take quick accurate decisions. Results showed high performance of deep learning algorithms specially CNN with Adam; however, it needs more computational time than Neuro-Fuzzy system tuned with PSO.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-44289-7_28,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-50439-7_30,Computing with Words in Maritime Piracy and Attack Detection Systems,Augmented Cognition. Human Cognition and Behavior,10.1007/978-3-030-50439-7_30,Springer,2020-01-01,2020-07-10,"In this paper, we propose to apply recent advances in deep learning to design and train algorithms to localize, identify, and track small maritime objects under varying conditions (e.g., a snowstorm, high glare, night), and in computing-with-words to identify threatening activities where lack of training data precludes the use of deep learning. The recent rise of maritime piracy and attacks on transportation ships has cost the global economy several billion dollars. To counter the threat, researchers have proposed agent-driven modeling to capture the dynamics of the maritime transportation system, and to score the potential of a range of piracy countermeasures. Combining information from onboard sensors and cameras with intelligence from external sources for early piracy threat detection has shown promising results but lacks real-time updates for situational context. Such systems can benefit from early warnings, such as “a boat is approaching the ship and accelerating,” “a boat is circling the ship,” or “two boats are diverging close to the ship.” Existing onboard cameras capture these activities, but there are no automated processing procedures of this type of patterns to inform the early warning system. Visual data feed is used by crew only after they have been alerted of a possible attack. Camera sensors are inexpensive but transforming the incoming video data streams into actionable items still requires expensive human processing.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-50439-7_30,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-30465-2_35,Real-Time Speed Bump Detection Using Image Segmentation for Autonomous Vehicles,"Intelligent Computing, Information and Control Systems",10.1007/978-3-030-30465-2_35,Springer,2020-01-01,2019-10-19,"Autonomous vehicle technology, which is evolving at a faster pace than predicted is promising to deliver higher safety benefits. Detecting the obstacles accurately and reliably is important for safer navigation. Speed bumps are the obstacles installed on the roads in order to force the vehicle driver to reduce the speed of the vehicle in the critical road areas, such as hospitals and schools. Autonomous vehicles have to detect and slower the speed appropriately to drive safely over the speed bump. In this paper, we propose a novel method to detect the upcoming speed bump by using a deep learning algorithm called SegNet, which is a deep convolutional neural network architecture for semantic pixel-wise segmentation. The trained model will give segmented output from the monocular camera feed placed in front of the vehicle.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30465-2_35,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-36674-2_4,A Literature Review of Steering Angle Prediction Algorithms for Self-driving Cars,Advanced Intelligent Systems for Sustainable Development (AI2SD’2019),10.1007/978-3-030-36674-2_4,Springer,2020-01-01,2020-02-06,"A crucial requirement for intelligent, driverless cars is to maneuver without moving out of its drivable region of the road. It is well known that steering angle calculation plays an important role in maintaining the vehicle in the center of the road or within the boundary lanes to meet safety critical requirements. This paper presents a review of autonomous steering techniques for self driving cars which is a relatively unexplored task in the fields of computer vision, robotics and machine learning. Our principle aim is to find out the state-of-the-art models in traditional computer vision approach and end-to-end Deep learning approach. Subsequently we have analyzed and compared the performance of each model based on the reported experimental results. Our research investigations lead us to conclude that ResNet50 Deep network combined with event cameras can be assumed to give better prediction of the due wheel angle in comparison to the use of traditional cameras. An overview of future research direction and applications is also given.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-36674-2_4,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-50334-5_10,Beyond the Buzzwords: On the Perspective of AI in UX and Vice Versa,Artificial Intelligence in HCI,10.1007/978-3-030-50334-5_10,Springer,2020-01-01,2020-07-10,"Integrating Artificial Intelligence (AI) technologies promises to open new possibilities for the development of smart systems and the creation of positive user experiences. While the acronym «AI»has often been used inflationary in recent marketese advertisements, the goal of the paper is to explore the relationship of AI and UX in concrete detail by referring to three case studies from our lab. The first case study is taken from a project targeted at the development of a clinical decision support system, while the second study focuses on the development of an autonomous mobility-on-demand system. The final project explores an innovative, AI-injected prototyping tool. We discuss challenges and the application of available guidelines when designing AI-based systems and provide insights into our learnings from the presented case studies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-50334-5_10,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-60117-1_32,Safety Analytics for AI Systems,HCI International 2020 - Late Breaking Papers: Multimodality and Intelligence,10.1007/978-3-030-60117-1_32,Springer,2020-01-01,2020-10-17,"Growing AI technologies are a threat to safety and security in systems due to its obscurity and uncertainty. This study introduces a prevailing Deep Learning model, Convolutional Neural Network (CNN) and it’s deep weaknesses through a simple case study of the CNN model based on Keras for handwriting recognition. It reveals that CNN algorithms don’t adapt well to changes. Adding new cases to the training data may improve accuracy, but not to the same level as before. Synthetic training data may improve the accuracy superficially because of the similarity of data distributions between generated data and original data. Prevailing ML models such as Generative Adversarial Networks (GAN) have their limitations such as similarity-addiction and modality collapse. They could be toxic to safety engineering without domain expertise. The study proposed four test strategies: 1) AI systems should be tested by the third parties, not the developers; 2) test datasets should be categorically different from training datasets; the test data should not be a part of the training data; the test data should be collected from independent sources to increase the “diversity” of data modality; 3) avoid fake data, or simulated data; and 4) don’t collect the data that are conveniently available, but actively collect disastrous event data, unexpected, or the worst scenarios that may destroy the model. The study also introduces a multidimensional checklist for AI safety analysis, including sensors, data and environments, default and recovery mode, system architectures, and human-system interaction.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60117-1_32,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-30465-2_34,"DeepTrackNet: Camera Based End to End Deep Learning Framework for Real Time Detection, Localization and Tracking for Autonomous Vehicles","Intelligent Computing, Information and Control Systems",10.1007/978-3-030-30465-2_34,Springer,2020-01-01,2019-10-19,"Vehicle detection and tracking in real time remains as the most challenging tasks for the autonomous vehicles and mobile robots. The designed algorithms should have less latency and with high accuracy and performance. This paper proposed a unified end to end deep learning framework for real-time detection, localization and tracking for autonomous vehicles called DeepTrackNet. In the proposed DeepTrackNet architecture Mobilenet SSD is used for vehicle detection, localization and deep regression network is used for vehicle tracking. Based on the experimental analysis performed we infer that the proposed DeepTrackNet architecture has produced satisfactory results for real-time vehicle detection and tracking on an Nvidia Jetson embedded computing platform using monocular camera with a reasonable latency. Mobilenet SSD took 84 (ms) median detection time and deep regression tracker has the least overall average failure frames at 4.388 on the VTB TB-100 dataset ( http://cvlab.hanyang.ac.kr/tracker_benchmark/datasets.html ). The code along with detailed results are available in the GitHub repository ( https://github.com/dineshresearch/DeepTrackNet ).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30465-2_34,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-38077-9_132,Flow Field and Neural Network Guided Steering Control for Rigid Autonomous Vehicles,Advances in Dynamics of Vehicles on Roads and Tracks,10.1007/978-3-030-38077-9_132,Springer,2020-01-01,2020-02-13,"This paper studies the steering control for low-speed manoeuvring of autonomous ground vehicles. A guidance method combining flow analogy and a neural network model is proposed to produce the proper angular velocity for the vehicle, which can be used as a reference for the control of the steering wheel. In a previous study, fluid flow itself has shown outstanding global search capabilities in guiding the vehicle through complicated environments. But the vehicle is not always able to follow the motion of the flow due to the difference of their nature. In this paper, the heat flow analogy is used instead of fluid flow, and a neural network model is added upon the flow layer in order to produce a steering reference more suitable for a rigid vehicle. Simulated results demonstrate that, except for the branching situations, the proposed method is able to guide the vehicle towards its desired destination.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-38077-9_132,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-60239-0_18,Fast Segmentation-Based Object Tracking Model for Autonomous Vehicles,Algorithms and Architectures for Parallel Processing,10.1007/978-3-030-60239-0_18,Springer,2020-01-01,2020-09-29,"On-road object tracking is a critical module for both Advanced Driving Assistant System (ADAS) and autonomous vehicles. Commonly, this function can be achieved through single vehicle sensors, such as a camera or LiDAR. Consider the low cost and wide application of optical cameras, a simple image segmentation-based on-road object tracking model is proposed. Different from the detection-based tracking with bounding box, our model improves tracking performance from the following three aspects: 1) the Positional Normalization (PONO) feature is used to enhance the target outline with common convolutional layers. 2) The inter-frame correlation of each target used for tracking relies on mask, this helps the model reducing the influences caused by the background around the targets. 3) By using a bidirectional LSTM module capable of capturing timing correlation information, the forward and reverse matching of the targets in consecutive frames is performed. We also evaluate the presented model on the KITTI MOTS (Multi-Object and Segmentation) task which collected from out door environment for autonomous vehicle. Results show that our model is three times faster than Track RCNN with slightly drop on sMOTSA, and is more suitable for deployment on vehicular low-power edge computing equipment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60239-0_18,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-35990-4_19,Joint Instance Segmentation of Obstacles and Lanes Using Convolutional Neural Networks,Robot 2019: Fourth Iberian Robotics Conference,10.1007/978-3-030-35990-4_19,Springer,2020-01-01,2019-11-20,"Autonomous vehicles aim at higher levels of intelligence to recognize all the elements in the surrounding environment; in order to be able to make decisions efficiently and in real time. For this reason, a convolutional neural networks capable of perform semantic segmentation of these elements have been implemented. In this work it is proposed to use the ERFNet architecture to segment the main obstacles and lanes in a road environment. One of the requirements for training this type of networks is to have a complete and large dataset with these two types of labels. In order to avoid manual labeling, an automatic way of carrying out this process is proposed, using convolutional neural networks and different dataset already labeled. The generated dataset contains 19000 images tagged with obstacles and lanes, to be used to train a network of ERFnet architecture. From the experiment, the obtained results show the performance of the proposed approach providing accuracy of 74.42%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-35990-4_19,springer
Chapter,doi:10.1007/978-3-030-31760-7_6,Traffic Light and Vehicle Signal Recognition with High Dynamic Range Imaging and Deep Learning,Deep Learning: Algorithms and Applications,10.1007/978-3-030-31760-7_6,Springer,2020-01-01,2019-10-24,"Use of autonomous vehicles Autonomous vehicle aims to eventually reduce the number of motor vehicle fatalities caused by humans. Deep learning plays an important role in making this possible because it can leverage the huge amount of training data that comes from autonomous car sensors. Automatic recognition of traffic light and vehicle signal is a perception module critical to autonomous vehicles Autonomous vehicle because a deadly car accident could happen if a vehicle fails to follow traffic lights or vehicle signals. A practical Traffic Light Recognition Traffic light recognition (TLR) or Vehicle Signal Recognition Vehicle signal recognition (VSR) faces some challenges, including varying illumination conditions, false positives and long computation time. In this chapter, we propose a novel approach to recognize Traffic Light (TL) and Vehicle Signal (VS) with high dynamic range imaging and deep learning in real-time. Different from existing approaches which use only bright images, we use both high exposure/bright and low exposure/dark images provided by a high dynamic range camera. TL candidates can be detected robustly from low exposure/dark frames because they have a clean dark background. The TL candidates on the consecutive high exposure/bright frames are then classified accurately using a convolutional Neural networks neural network Convolutional neural network . The dual-channel mechanism can achieve promising results because it uses undistorted color and shape information of low exposure/dark frames as well as rich texture of high exposure/bright frames. Furthermore, the TLR performance is boosted by incorporating a temporal trajectory tracking method. To speed up the process, a region of interest is generated to reduce the search regions for the TL candidates. The experimental results on a large dual-channel database have shown that our dual-channel approach outperforms the state of the art which uses only bright images. Encouraged by the promising performance of the TLR, we extend the dual-channel approach to vehicle signal recognition Vehicle signal recognition . The algorithm reported in this chapter has been integrated into our autonomous vehicle Autonomous vehicle via Data Distribute Service Data distribute service (DDS) and works robustly in real roads.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-31760-7_6,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-38040-3_13,Adaptive Neuro Fuzzy Inference System Based Obstacle Avoidance System for Autonomous Vehicle,Innovative Data Communication Technologies and Application,10.1007/978-3-030-38040-3_13,Springer,2020-01-01,2020-01-31,"Adaptive Neuro Fuzzy Inference System (ANFIS) is a well proven technology for predicting the output based on the set of inputs. ANFIS is predominantly used to track the set of inputs and output in order to achieve the target. In this paper, authors have proposed a Nonlinear ANFIS algorithm to track the distance between the autonomous vehicle and the obstacle while vehicle is moving and the brake force required. By tuning neuro fuzzy algorithm, accurate brake force requirement has been achieved and the results are captured in this paper. Back propagation algorithm based neural network & Sugeno model based Fuzzy inference system have been used in the proposed technique. Matlab/Simulink software platform is used to implement the proposed algorithm and proven the expected results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-38040-3_13,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-56441-4_39,Supporting Process Design in the Autonomous Era with New Standards and Guidelines,"Systems, Software and Services Process Improvement",10.1007/978-3-030-56441-4_39,Springer,2020-01-01,2020-08-10,"It isn’t easy to define a general and clear process in a new system such as an autonomous vehicle. The new technology is complex and lacks experience. In this paper, we reconsider the process used for system development. We assume that the process changes depending on the characteristics of a project [ 1 ]. Of course, this is a general agreement. In autonomous vehicles, new technological elements such as AI and ensuring safety are further required. So, it is meaningful to consider how to think about the development process. New standards, guidelines and documents such as UL4600 are emerging for autonomous vehicles. In addition to many standards, dealing with these presents difficulties. We believe that better process design is possible by using the Toulmin model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-56441-4_39,springer
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-15145-4_65-1,Deep Learning for LiDAR-Based Autonomous Vehicles in Smart Cities,Handbook of Smart Cities,10.1007/978-3-030-15145-4_65-1,Springer,2020-01-01,2020-10-29,"Autonomous vehicles and deep learning are an integral part of smart cities. They interact and communicate with their surroundings, requiring high computer vision accuracy to maintain driver and pedestrian safety. Many autonomous vehicles leverage deep learning for detection and utilize a suite of sensors that are specific to their environment or use case. In such deep learning environment, sensor data is used as input to neural networks that make decisions regarding the vehicle’s response or reaction to its environment. These sensors in autonomous vehicles provide details regarding the vehicle’s surroundings and potential obstacles. Many sensor suites are starting to contain light detection and ranging (LiDAR) sensors, as the cost of the technology decreases and becomes more widely available. LiDAR technology uses focused light to detect distance, providing an accurate description of the sensor’s surroundings, such precise account is crucial for autonomous driving in ever-changing smart city environments. This chapter covers different applications of LiDAR technology and the use of the sensor data in deep learning applications for smart cities. A case study is also featured to illustrate a potential implementation, which is followed by discussion of future research directions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-15145-4_65-1,springer
Chapter,doi:10.1007/978-3-030-13705-2_6,Comparison of Decision Trees and Deep Learning for Object Classification in Autonomous Driving,Smart Infrastructure and Applications,10.1007/978-3-030-13705-2_6,Springer,2020-01-01,2019-06-21,"Road transportation is among the grand global challenges affecting human lives, health, society, and economy. Autonomous vehicles (AVs) are the latest among the radical solutions to address transportation challenges. AVs have become a reality although their penetration in real environments needs more time. The foremost challenge for AVs is to recognize objects in real driving environment with highest certainty. This paper is an extension of our earlier work where we developed a methodology to integrate supervised learning and decision fusion to enhance object classification accuracy in a driving environment, i.e., to enable an auto-pilot to take better driving decisions. This problem equates to pixel classification. Our study revealed that the C5.0 decision tree classifier performs similar to deep learning. This paper extends and investigates the topic further and provides an in-depth performance comparison of deep learning and C5.0 decision tree classifier for object classification in driving environments using a bigger dataset. We manually label images from a subset of KITTI road dataset by using free-form selection (polygon) rather than a box or rectangular selection enabling highly accurate pixel labeling. Our analysis reveals that C5.0 and deep learning provide similar accuracies while deep learning is over 30% faster than C5.0.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-13705-2_6,springer
Chapter,doi:10.1007/978-3-030-35445-9_23,Multi-objective Evaluation of Deep Learning Based Semantic Segmentation for Autonomous Driving Systems,Intuitionistic and Type-2 Fuzzy Logic Enhancements in Neural and Optimization Algorithms: Theory and Applications,10.1007/978-3-030-35445-9_23,Springer,2020-01-01,2020-02-28,"Recent applications of deep learning (DL) architectures for semantic segmentation had led to a significant development in autonomous driving systems (ADS). Most of the semantic segmentation applications for ADS consider a plethora of classes. Nevertheless, we believe that focusing only on the segmentation of drivable roads, sidewalks, traffic signs, and cars, can drive the improvement of navigation and control techniques in autonomous vehicles. In this study, some state-of-the-art topologies are analyzed to find a strategy that can achieve a uniform performance for the four classes. We propose a multiple objective evaluation method with the purpose of finding the non-dominated solutions in different DL architectures. Numerical results are shown using CityScapes, SYNTHIA, and CamVid datasets.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-35445-9_23,springer
Chapter,doi:10.1007/978-3-030-30367-9_7,Intelligent and Connected Cyber-Physical Systems: A Perspective from Connected Autonomous Vehicles,Intelligent Internet of Things,10.1007/978-3-030-30367-9_7,Springer,2020-01-01,2020-01-22,"Cyber-physical systems (CPS) have broad applications in the automotive, avionics, robotics, healthcare, and power grid, where the cyber components involving information processing and networking closely interact with the physical processes. Conventionally, there is a separate design flow of CPS. For instance, control algorithms managing the physical dynamics are designed using model-based approaches, without considering details of the cyber implementation platforms. Modern CPS are getting increasingly intelligent and connected. A new design methodology taking all the layers of CPS and their interplays into account is being developed, aiming for assurance of safety and security, as well as high robustness and resource efficiency. This chapter presents the technical background of CPS, with an emphasis on the cyber and physical interactions, corresponding to the new design methodology. Case studies on connected autonomous vehicles (CAVs) are used to illustrate the most recent development in CPS.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30367-9_7,springer
Chapter,doi:10.1007/978-981-15-1350-3_1,Legal Aspects of Decentralized and Platform-Driven Economies,Legal Tech and the New Sharing Economy,10.1007/978-981-15-1350-3_1,Springer,2020-01-01,,"The sharing economy Sharing economies is sprawling across almost every sector and activity around the world. About a decade ago, there were only a handful of platform-driven companies operating on the market. Zipcar, BlaBlaCar and Couchsurfing among them. Then Airbnb Airbnb and Uber Uber revolutionized the transportation and hospitality industries with a presence in virtually every major city Cities . “Access over ownership” is the paradigm shift from the traditional business model that grants individuals the use of products or services without the necessity of buying them. Digital platforms, data Data and algorithm Algorithm -driven companies as well as decentralized blockchain Blockchain technologies have tremendous potential. But they are also changing the “rules of the game.” One of such technologies challenging the legal system are AI Artificial Intelligence (AI) systems that will also reshape the current legal framework concerning the liability Liability of operators, users and manufacturers. Therefore, this introductory chapter deals with explaining and describing the legal issues of some of these disruptive technologies. The chapter argues for a more forward-thinking and flexible regulatory structure.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-1350-3_1,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-42058-1_40,Scenario Generation for Validating Artificial Intelligence Based Autonomous Vehicles,Intelligent Information and Database Systems,10.1007/978-3-030-42058-1_40,Springer,2020-01-01,2020-03-04,"The progress in the development of artificial intelligence engines has been driving the autonomous vehicle technology, which is projected to be a significant market disruptor for various industries. For the public acceptance though, the autonomous vehicles must be proven to be reliable and their functionalities must be thoroughly validated. This is essential for improving the public trust for these vehicles and creating a communication medium between the manufacturers and the regulation authorities. Existing testing methods fall short of this goal and provide no clear certification scheme for autonomous vehicles. In this paper, we present a simulation scenario generation methodology with pseudo-random test generation and edge scenario discovery capabilities for testing autonomous vehicles. The validation framework separates the validation concerns and divides the testing scheme into several phases accordingly. The method uses a semantic language to generate scenarios with a particular focus on the validation of autonomous vehicle decisions, independent of environmental factors.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-42058-1_40,springer
Chapter,doi:10.1007/978-3-030-18963-1_2,Artificial Intelligence and Internet of Things for Autonomous Vehicles,Nonlinear Approaches in Engineering Applications,10.1007/978-3-030-18963-1_2,Springer,2020-01-01,2019-08-07,"Artificial Intelligence (AI) is a machine intelligence tool providing enormous possibilities for smart industrial revolution. Internet of Things (IoT) is the axiom of industry 4.0 revolution, including a worldwide infrastructure for collecting and processing of the data/information from storage, actuation, sensing, advanced services and communication technologies. The combination of high-speed, resilient, low-latency connectivity, and technologies of AI and IoT will enable the transformation towards fully smart Autonomous Vehicle (AV) that illustrate the complementary between real world and digital knowledge for industry 4.0. The purpose of this articla is to examine how the latest approaches in AI and IoT can assist in the search for the Autonomous Vehicles. It has been shown that human errors are the source of 90% of automotive crashes, and the safest drivers drive ten times better than the average (Wu et al. Accident Analysis and Prevention, 117, 21–31, 2018). The automated vehicle safety is significant, and users are requiring 1000 times smaller acceptable risk level. Some of the incredible benefits of AVs are: (1) increasing vehicle safety, (2) reduction of accidents, (3) reduction of fuel consumption, (4) releasing of driver time and business opportunities, (5) new potential market opportunities, and (6) reduced emissions and dust particles. However, AVs must use large-scale data/information from their sensors and devices.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-18963-1_2,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-64556-4_31,FA3D: Fast and Accurate 3D Object Detection,Advances in Visual Computing,10.1007/978-3-030-64556-4_31,Springer,2020-01-01,2020-12-07,"Fast and accurate detection of objects, in 3D, is one of the critical components in an advanced driver assistance system. In this paper, we aim to develop an accurate 3D object detector that runs in near real-time on low-end embedded systems. We propose an efficient framework that converts raw point cloud into a 3D occupancy cuboid and detects cars using a deep convolutional neural network. Even though the complexity of our proposed model is high, it runs at 7.27 FPS on a Jetson Xavier and at 57.83 FPS on a high-end workstation that is $$18\%$$ 18 % and $$43\%$$ 43 % faster than the fastest published method while having a comparable performance with state-of-the-art models on the KITTI dataset. We conduct a comprehensive error analysis on our model and show that two quantities are the principal sources of error among nine predicted attributes. Our source code is available at https://github.com/Selameab/FA3D .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-64556-4_31,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-63007-2_32,Early Unsafety Detection in Autonomous Vehicles,Computational Collective Intelligence,10.1007/978-3-030-63007-2_32,Springer,2020-01-01,2020-11-23,"Autonomous vehicles have been investigated broadly during the last decade and predicted to decrease road fatalities by shifting control of safety-critical tasks from humans to machines. An early unsafety detection consequently becomes a key feature in every self-driving cars and trucks. In this paper, we present a promising approach for the safety prediction problem in autonomous vehicles by using one dataset collected from the competition CMDC 2019, which can capture multiple safe or unsafe situations from a front car camera put in different autonomous buses. We consider various ways to extract potential features from images provided and apply numerous machine learning techniques to learn an efficient detection algorithm. The experimental results show that by combining Histogram-of-Gradients (HOG) features as well as deep-learning ones computed from both ResNet50 and our proposed deep neural networks (MRNets), we can achieve an auspicious performance in terms of both micro-averaged F1-score and macro-averaged F1-score. The outcome of our papers can give an additional contribution to the current study of the problem.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-63007-2_32,springer
Chapter ConferencePaper,doi:10.1007/978-981-15-0644-4_65,A Novel Multiple Object Tracking Algorithm for Autonomous Vehicles,"Green, Smart and Connected Transportation Systems",10.1007/978-981-15-0644-4_65,Springer,2020-01-01,2020-03-24,"Multiple object tracking is a vital task for autonomous vehicle environment perception. In this paper, we design a novel multi-object tracking method for autonomous vehicles. In the detection section, we utilize popular Faster-RCNN as our baseline method. Then, in data association, we combine appearance, motion, and interaction model to build a unified feature descriptor to explore the nature of tracking object. We evaluate our algorithm on a popular and standard benchmark and compare with the state-of-the-art methods. The results denote that our algorithm achieve good performance at high frame rates.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-0644-4_65,springer
Article,doi:10.1007/s12239-019-0113-9,"Development of Three Driver State Detection Models from Driving Information Using Vehicle Simulator; Normal, Drowsy and Drunk Driving",International Journal of Automotive Technology,10.1007/s12239-019-0113-9,Springer,2019-12-01,2019-09-16,"Detection of drivers' states is the essential technology not only to prevent car accidents related with their state but to develop self-driving car. Detecting technology generally uses two types of methods; physiological measures and vehicle-based measures. Vehicle-based measures have advantages compared to physiological method such as non-additional device, unsophisticated process and less computational power. For these reasons, vehicle-based measures are used for this study to build the detection system about 3 states; normal, drowsy and drunk driving. In order to achieve this purpose, three types of algorithm models are suggested using vehicle simulator experiments with twelve participants on three states; normal, drowsy and drunk. By analyzing the accuracy of each input packet data combination, the feature values, the configuration of the input data calculated through the vehicle driving data is used to derive the influential factors for predicting the driver state. The results of the models indicate high accuracy and give the possibility to be applied on detecting 3 states in real driving vehicles with the system using combination of developed models.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s12239-019-0113-9,springer
Article,doi:10.1007/s12065-019-00278-7,UCRLF: unified constrained reinforcement learning framework for phase-aware architectures for autonomous vehicle signaling and trajectory optimization,Evolutionary Intelligence,10.1007/s12065-019-00278-7,Springer,2019-12-01,2019-09-04,"Signaling and trajectory optimization work as contention and researchers have debated on what should be the best for the vehicle, but it seems that both components are complement to each other and there can be combined situations with bounds where maximum optimization can be achieved. This paper introduces a novel approach called Phase-Aware Deep Learning and Constrained Reinforcement Learning for optimization and constant improvement of signal and trajectory for autonomous vehicle operation modules for an intersection. It deals with all the components required for the signaling system to operate, communicate and also navigate the vehicle with proper trajectory so that it faces less waiting time and the overall system operates with minimum waiting time and comparable throughput rate. We have done analysis on the operating time and the vehicle movement as these are vital for pollution and energy consumption. Our methodologies are not only efficient in time and computation but also have incorporated highly optimized data representation to reduce the overhead of maintaining and accessing the data. This ensures very efficient time complexity and theoretical computation time and better lower bounds. Constrained Reinforcement Learning concept is the main contribution of this work and it helped in decreasing 84% of the waiting time for the vehicles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12065-019-00278-7,springer
Article,doi:10.1007/s12008-019-00619-x,Hardware in the loop framework proposal for a semi-autonomous car architecture in a closed route environment,International Journal on Interactive Design and Manufacturing (IJIDeM),10.1007/s12008-019-00619-x,Springer,2019-12-01,2019-10-05,"The development of intelligent vehicles has been increasing at great speed in recent years, which has allowed to improve their capabilities in autonomous driving systems. Many of these features are related to advanced driving assistance systems and autonomous driving systems. This capability improvement, has been achieved because of recent developments of automation oriented software and hardware. Such improvements, allowed the vehicle to achieve a more precise perception of it’s working environment. For this improvement it is important the integration and simulation of the systems in different configurations, such as hardware-in-the-loop, software-in-the-loop and model-in-the-loop. In this paper, we present a framework proposal that allows the design and testing of computer vision and control systems for the partial automation of a vehicle, with the use of hardware and software systems in the loop. This proposal is focused on the rapid experimental development of these systems for the implementation by autonomous vehicle designers and engineers. Our proposal allows faster data capture, either in a real or simulated environment, to improve and optimize data training with machine learning algorithms; this proposal integrates several open source systems and hardware with the necessary capacity for real-time implementation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12008-019-00619-x,springer
Article,doi:10.1007/s11042-018-5816-9,Architecture design and implementation of image based autonomous car: THUNDER-1,Multimedia Tools and Applications,10.1007/s11042-018-5816-9,Springer,2019-10-01,2018-03-03,"Autonomous driving with high velocity is a research hotspot which challenges the scientists and engineers all over the world. This paper proposes a scheme of indoor autonomous car based on ROS which combines the method of Deep Learning using Convolutional Neural Network (CNN) with statistical approach using liDAR images and achieves a robust obstacle avoidance rate in cruise mode. In addition, the design and implementation of autonomous car are also presented in detail which involves the design of Software Framework, Hector Simultaneously Localization and Mapping (Hector SLAM) by Teleoperation, Autonomous Exploration, Path Plan, Pose Estimation, Command Processing, and Data Recording (Co- collection). what’s more, the schemes of outdoor autonomous car, communication, and security are also discussed. Finally, all functional modules are integrated in nVidia Jetson TX1.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11042-018-5816-9,springer
Article,doi:10.3103/S1060992X19040118,Object Detection with Deep Neural Networks for Reinforcement Learning in the Task of Autonomous Vehicles Path Planning at the Intersection,Optical Memory and Neural Networks,10.3103/S1060992X19040118,Springer,2019-10-01,2020-02-10,"Abstract Among a number of problems in the behavior planning of an unmanned vehicle the central one is movement in difficult areas. In particular, such areas are intersections at which direct interaction with other road agents takes place. In our work, we offer a new approach to train of the intelligent agent that simulates the behavior of an unmanned vehicle, based on the integration of reinforcement learning and computer vision. Using full visual information about the road intersection obtained from aerial photographs, it is studied automatic detection the relative positions of all road agents with various architectures of deep neural networks (YOLOv3, Faster R-CNN, RetinaNet, Cascade R-CNN, Mask R-CNN, Cascade Mask R-CNN). The possibilities of estimation of the vehicle orientation angle based on a convolutional neural network are also investigated. Obtained additional features are used in the modern effective reinforcement learning methods of Soft Actor Critic and Rainbow, which allows to accelerate the convergence of its learning process. To demonstrate the operation of the developed system, an intersection simulator was developed, at which a number of model experiments were carried out.",http://link.springer.com/openurl/fulltext?id=doi:10.3103/S1060992X19040118,springer
Article,doi:10.1007/s12652-019-01496-8,A new lane following method based on deep learning for automated vehicles using surround view images,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-019-01496-8,Springer,2019-09-19,2019-09-19,"In this study, a lane following method based on deep learning from surround view images for autonomous driving of a ground vehicle is proposed. Previous methods can be suffered from false detection by hand-craft feature extraction in color-based binarization especially when the surround view images are exposed to unfavorable conditions such as strong shadow, sunlight reflections or shallow puddles on the roads. Thus the proposed method adopts a modified convolutional neural network structure to estimate the 6 coefficients of the left and right lane lines modeled by two quadratic functions from the surround view images of a vehicle. Then, a desired steering wheel angle is calculated using Stanley method to make a test vehicle follow a test lane autonomously by the proposed method. Autonomous driving experiment of the test vehicle using the proposed method was carried out on the test lane with various unfavorable conditions high-curvature lane of a test field. Experiment results showed that the vehicle was self-driven autonomously and stably without any lane departures on the test lane.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-019-01496-8,springer
Article,doi:10.1007/s11263-019-01177-1,Deep Learning Approach in Aerial Imagery for Supporting Land Search and Rescue Missions,International Journal of Computer Vision,10.1007/s11263-019-01177-1,Springer,2019-09-01,2019-03-27,"In this paper, we propose a novel approach to person detection in UAV aerial images for search and rescue tasks in Mediterranean and Sub-Mediterranean landscapes. Person detection in very high spatial resolution images involves target objects that are relatively small and often camouflaged within the environment; thus, such detection is a challenging and demanding task. The proposed method starts by reducing the search space through a visual attention algorithm that detects the salient or most prominent segments in the image. To reduce the number of non-relevant salient regions, we selected those regions most likely to contain a person using pre-trained and fine-tuned convolutional neural networks (CNNs) for detection. We established a special database called HERIDAL to train and test our model. This database was compiled for training purposes, and it contains over 68,750 image patches of wilderness acquired from an aerial perspective as well as approximately 500 labelled full-size real-world images intended for testing purposes. The proposed method achieved a detection rate of 88.9% and a precision of 34.8%, which demonstrates better effectiveness than the system currently used by Croatian Mountain search and rescue (SAR) teams (IPSAR), which is based on mean-shift segmentation. We also used the HERIDAL database to train and test a state-of-the-art region proposal network, Faster R-CNN (Ren et al. in Faster R-CNN: towards real-time object detection with region proposal networks, 2015 . CoRR arXiv:1506.01497 ), which achieved comparable but slightly worse results than those of our proposed method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11263-019-01177-1,springer
Article,doi:10.1007/s11036-019-01319-2,TAAWUN: a Decision Fusion and Feature Specific Road Detection Approach for Connected Autonomous Vehicles,Mobile Networks and Applications,10.1007/s11036-019-01319-2,Springer,2019-08-01,2019-08-01,"Road transportation is among the global grand challenges affecting human lives, health, society, and economy, caused due to road accidents, traffic congestion, and other transportation deficiencies. Autonomous vehicles (AVs) are set to address major transportation challenges including safety, efficiency, reliability, sustainability, and personalization. The foremost challenge for AVs is to perceive their environments in real-time with the highest possible certainty. Relatedly, connected vehicles (CVs) have been another major driver of innovation in transportation. In this paper, we bring autonomous and connected vehicles together and propose TAAWUN, a novel approach based on the fusion of data from multiple vehicles. The aim herein is to share the information between multiple vehicles about their environments, enhance the information available to the vehicles, and make better decisions regarding the perception of their environments. TAWUN shares, among the vehicles, visual data acquired from cameras installed on individual vehicles, as well as the perceived information about the driving environments. The environment is perceived using deep learning, random forest (RF), and C5.0 classifiers. A key aspect of the TAAWUN approach is that it uses problem specific feature sets to enhance the prediction accuracy in challenging environments such as problematic shadows, extreme sunlight, and mirage. TAAWUN has been evaluated using multiple metrics, accuracy, sensitivity, specificity, and area-under-the-curve (AUC). It performs consistently better than the base schemes. Directions for future work to extend the tool are provided. This is the first work where visual information and decision fusion are used in CAVs to enhance environment perception for autonomous driving.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11036-019-01319-2,springer
Article,doi:10.1186/s41074-019-0059-x,Deep learning-based strategies for the detection and tracking of drones using several cameras,IPSJ Transactions on Computer Vision and Applications,10.1186/s41074-019-0059-x,Springer,2019-07-24,2019-07-24,"Commercial Unmanned aerial vehicle (UAV) industry, which is publicly known as drone , has seen a tremendous increase in last few years, making these devices highly accessible to public. This phenomenon has immediately raised security concerns due to fact that these devices can intentionally or unintentionally cause serious hazards. In order to protect critical locations, the academia and industry have proposed several solutions in recent years. Computer vision is extensively used to detect drones autonomously compared to other proposed solutions such as RADAR, acoustics and RF signal analysis thanks to its robustness. Among these computer vision-based approaches, we see the preference of deep learning algorithms thanks to their effectiveness. In this paper, we are presenting an autonomous drone detection and tracking system which uses a static wide-angle camera and a lower-angle camera mounted on a rotating turret. In order to use memory and time efficiently, we propose a combined multi-frame deep learning detection technique, where the frame coming from the zoomed camera on the turret is overlaid on the wide-angle static camera’s frame. With this approach, we are able to build an efficient pipeline where the initial detection of small sized aerial intruders on the main image plane and their detection on the zoomed image plane is performed simultaneously, minimizing the cost of resource exhaustive detection algorithm. In addition to this, we present the integral system including tracking algorithms, deep learning classification architectures and the protocols.",https://www.biomedcentral.com/openurl?doi=10.1186/s41074-019-0059-x,springer
Article,doi:10.1007/s12115-019-00358-5,"Society Caught in a Labyrinth of Algorithms: Disputes, Promises, and Limitations of the New Order of Things",Society,10.1007/s12115-019-00358-5,Springer,2019-06-15,2019-06-12,"We are in the interim of the massive expansion of the new and fundamental technology, which is represented by the advanced algorithms of AI. No one knows the real potential of machine learning and AI. Letting the algorithms drive autonomous vehicles (driverless cars) is like running the Boston Marathon. Creating an ethically completely autonomous AI system is like a piloted flight to Alpha Centauri. Nevertheless, we still live in the world of algorithms. Today there are algorithms in every corner of civilization, as quantum fluctuations they are integrally interwoven into the structure of everyday life. They are not just in your mobile phone or laptop. Algorithms plan flights and then fly with planes. Algorithms run factories, the bank is a vast array of algorithms, evaluating our credit score, algorithms collect revenue and keep records, read medical images, diagnose cancer, drive cars, write scientific texts, compose music, conduct symphony orchestras, navigate drones, speak to us and for us, write film scenarios, invent chemical formulations for a new cosmetic cream, order, advise, paint pictures. Climate models decide what is a safe carbon dioxide level in the atmosphere, NSA algorithms decide whether you are a potential terrorist. If every algorithm suddenly stopped working, it would be the end of the world as we know it. How did this new alliance, this interim world come into existence, does it suit us, and how and where will it develop? What AI algorithms have shown and offered to us so far is just a prelude, and even today it turns out that politics, ethics and law do not know what to do with the consequences of these changes. However, when we experience computer control by a mere idea, complex genetic modifications, and DNA enhancement using CRISPR, or perhaps flying cars, we can expect real challenges related to the power of algorithms. Then AI ​​algorithms will really transform everything. The study analyzes the social contradictions, promises and limitations associated with how the desire to move higher on technological prominence in the realm of artificial intelligence faces the ethical, legal and political barriers of the existing order of things.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12115-019-00358-5,springer
Article,doi:10.1007/s10846-018-0884-7,A Fast Learning Control Strategy for Unmanned Aerial Manipulators,Journal of Intelligent & Robotic Systems,10.1007/s10846-018-0884-7,Springer,2019-06-14,2018-06-11,"We present an artificial intelligence-based control approach, the fusion of artificial neural networks and type-2 fuzzy logic controllers, namely type-2 fuzzy-neural networks, for the outer adaptive position controller of unmanned aerial manipulators. The performance comparison of proportional-derivative (PD) controller working alone and the proposed intelligent control structures working in parallel with a PD controller is presented. The simulation and real-time results show that the proposed online adaptation laws eliminate the need for precise tuning of conventional controllers by learning system dynamics and disturbances online. The proposed approach is also computationally inexpensive due to the implementation of the fast sliding mode control theory-based learning algorithm which does not require matrix inversions or partial derivatives. Both simulation and experimental results have shown that the proposed artificial intelligence-based learning controller is capable of reducing the root-mean-square error by around 50% over conventional PD and PID controllers.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-018-0884-7,springer
Article,doi:10.1631/FITEE.1800569,Decentralized fault-tolerant cooperative control of multiple UAVs with prescribed attitude synchronization tracking performance under directed communication topology,Frontiers of Information Technology & Electronic Engineering,10.1631/FITEE.1800569,Springer,2019-05-01,2019-06-18,"In this paper, a decentralized fault-tolerant cooperative control scheme is developed for multiple unmanned aerial vehicles (UAVs) in the presence of actuator faults and a directed communication network. To counteract in-flight actuator faults and enhance formation flight safety, neural networks (NNs) are used to approximate unknown nonlinear terms due to the inherent nonlinearities in UAV models and the actuator loss of control effectiveness faults. To further compensate for NN approximation errors and actuator bias faults, the disturbance observer (DO) technique is incorporated into the control scheme to increase the composite approximation capability. Moreover, the prediction errors, which represent the approximation qualities of the states induced by NNs and DOs to the measured states, are integrated into the developed fault-tolerant cooperative control scheme. Furthermore, prescribed performance functions are imposed on the attitude synchronization tracking errors, to guarantee the prescribed synchronization tracking performance. One of the key features of the proposed strategy is that unknown terms due to the inherent nonlinearities in UAVs and actuator faults are compensated for by the composite approximators constructed by NNs, DOs, and prediction errors. Another key feature is that the attitude synchronization tracking errors are strictly constrained within the prescribed bounds. Finally, simulation results are provided and have demonstrated the effectiveness of the proposed control scheme.",http://link.springer.com/openurl/pdf?id=doi:10.1631/FITEE.1800569,springer
Article,doi:10.1007/s11948-017-0006-0,Self-Driving Cars and Engineering Ethics: The Need for a System Level Analysis,Science and Engineering Ethics,10.1007/s11948-017-0006-0,Springer,2019-04-15,2017-11-13,"The literature on self-driving cars and ethics continues to grow. Yet much of it focuses on ethical complexities emerging from an individual vehicle. That is an important but insufficient step towards determining how the technology will impact human lives and society more generally. What must complement ongoing discussions is a broader, system level of analysis that engages with the interactions and effects that these cars will have on one another and on the socio-technical systems in which they are embedded. To bring the conversation of self-driving cars to the system level, we make use of two traffic scenarios which highlight some of the complexities that designers, policymakers, and others should consider related to the technology. We then describe three approaches that could be used to address such complexities and their associated shortcomings. We conclude by bringing attention to the “Moral Responsibility for Computing Artifacts: The Rules”, a framework that can provide insight into how to approach ethical issues related to self-driving cars.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-017-0006-0,springer
Article,doi:10.1631/FITEE.1800571,Motion planning of a quadrotor robot game using a simulation-based projected policy iteration method,Frontiers of Information Technology & Electronic Engineering,10.1631/FITEE.1800571,Springer,2019-04-01,2019-05-18,"Making rational decisions for sequential decision problems in complex environments has been challenging researchers in various fields for decades. Such problems consist of state transition dynamics, stochastic uncertainties, long-term utilities, and other factors that assemble high barriers including the curse of dimensionality. Recently, the state-of-the-art algorithms in reinforcement learning studies have been developed, providing a strong potential to efficiently break the barriers and make it possible to deal with complex and practical decision problems with decent performance. We propose a formulation of a velocity varying one-on-one quadrotor robot game problem in the three-dimensional space and an approximate dynamic programming approach using a projected policy iteration method for learning the utilities of game states and improving motion policies. In addition, a simulation-based iterative scheme is employed to overcome the curse of dimensionality. Simulation results demonstrate that the proposed decision strategy can generate effective and efficient motion policies that can contend with the opponent quadrotor and gather advantaged status during the game. Flight experiments, which are conducted in the Networked Autonomous Vehicles (NAV) Lab at the Concordia University, have further validated the performance of the proposed decision strategy in the real-time environment.",http://link.springer.com/openurl/pdf?id=doi:10.1631/FITEE.1800571,springer
Article,doi:10.1007/s40815-018-0550-z,Self-Organizing Recurrent Wavelet Fuzzy Neural Network-Based Control System Design for MIMO Uncertain Nonlinear Systems Using TOPSIS Method,International Journal of Fuzzy Systems,10.1007/s40815-018-0550-z,Springer,2019-03-06,2018-09-25,"The major objective of this study is to design an effective control algorithm for dealing with multiple-input–multiple-output uncertain nonlinear systems. Novelty advantages of the proposed method include: (1) The network has the maximum initial rules; it helps to increase the responsiveness of the system; (2) the network has two dynamic thresholds: One dynamic threshold is utilized to consider whether to retain or to delete the existing rules and the other is used for generating a new rule; (3) the fuzzy neural network-based system can automatically construct the network structure and adjust the parameters of the system; (4) the network uses multiple combination techniques, such as sliding mode control, adaptive control, recurrent unit, wavelet function, fuzzy logic, neural network, and technique for order of preference by similarity to ideal solution multi-criteria decision analysis method. Based on the advantages of the above techniques, a self-organizing recurrent wavelet fuzzy neural network control system is designed comprising a main controller and a robust compensator. The gradient descent method is used to online tune the parameters for the main controller, and a Lyapunov stability theorem is applied to guarantee the system’s stability. Finally, the proposed control system is applied to a nonlinear chaotic system, an inverted double-pendulum system, and an unmanned aerial vehicle motion control to verify the effectiveness of the proposed control scheme. The simulation results show that the proposed control scheme can achieve favorable control performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40815-018-0550-z,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-24308-1_23,Scenes Segmentation in Self-driving Car Navigation System Using Neural Network Models with Attention,Computational Science and Its Applications – ICCSA 2019,10.1007/978-3-030-24308-1_23,Springer,2019-01-01,2019-06-29,"The article describes the design process of a software module for the road signs recognition used for the self-driving car, developed at the Ulyanovsk State Technical University (UlSTU) at the Faculty of Information Systems and Technologies in cooperation with the Faculty of Mechanical Engineering. One of the main tasks to be solved when creating technical vision systems based on neural networks, including for self-driving cars, is to create a training dataset sufficient to train network models. At the same time, in the task of semantic segmentation of the scene, the preparation of a large train set may require considerable effort for manual labeling. The article describes a convolutional network model with a soft attention mechanism, which is trained for the classification task with the possibility of extracting an attention mask from the internal network state, which can be used for semantic image segmentation. This approach can significantly reduce the cost of data labeling.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-24308-1_23,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-00979-3_19,CAIAS Simulator: Self-driving Vehicle Simulator for AI Research,Intelligent Computing & Optimization,10.1007/978-3-030-00979-3_19,Springer,2019-01-01,2018-09-28,"This paper presents a simulation environment which includes virtual structures of a low-cost embedded designed car for the autonomous driving test, tracks, obstacles, and environments. A cross-platform game engine, Unity 3D, empowers the embedded designed car to check and trial new tracks, parameters and calculations in the 3D environment before the real-time test. The virtual environment fabricates the domain such like that it is the mimics of the activity of a genuine car and Unity 3D are utilized to incorporate the embedded designed car into the test situation while the car’s movements and steering angle can serve as an examination premise. Distinctive driving situations were utilized to analyze how the sensors respond when they are connected to genuine circumstances and are also utilized to confirm the impacts of other parameters on the scenes. Options are available to choose flexible sensors, monitor the output and implement any autonomous driving, steering prediction, deep learning and end-to-end learning algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-00979-3_19,springer
Chapter ConferencePaper,doi:10.1007/978-981-13-2490-1_44,Intelligent Unmanned Aerial Vehicles,Proceedings of International Conference on Intelligent Manufacturing and Automation,10.1007/978-981-13-2490-1_44,Springer,2019-01-01,2018-11-05,"Applications of unmanned aerial vehicles technology have shown a very big rise in the recent times. One of the main reasons is less cost, tropical deforestation and advancement in remote sensing technology. Artificial intelligence will become an integral part of unmanned aerial vehicles and can be used for various applications. Incorporation of such intelligence in a practical system is the need of hour. The aim of this paper is to embed artificial intelligence in drones using image processing. Intelligent drones are now the requirement of many fields right from courier delivery to defence, surveillance and rescue. Face-recognition system is proposed which is based on dataset creation, training and recognizer. Implementation of face-recognition system shows acceptable results. We have created an artificial intelligence which is capable of doing face recognition and incorporated it with an UAV.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-2490-1_44,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-01054-6_62,Application of Deep Learning Technique in UAV’s Search and Rescue Operations,Intelligent Systems and Applications,10.1007/978-3-030-01054-6_62,Springer,2019-01-01,2018-11-09,This paper is concerned with the application of Deep Learning techniques for analyzing image data for search and rescue operations of Unmanned Aerial Vehicle (UAV). It uses Keras and its Tensorflow backend to model a deep Convolutional Neural Network (CNN) Learning technique and train the model with MNIST digits dataset to predict the hand- written word from the image data received from the ground level. The paper explains the stages involved in the implementation of LeNet method of Deep Learning techniques for developing a classifier for long distance recognition of handwritten words.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-01054-6_62,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-10997-4_40,Best Practices to Train Deep Models on Imbalanced Datasets—A Case Study on Animal Detection in Aerial Imagery,Machine Learning and Knowledge Discovery in Databases,10.1007/978-3-030-10997-4_40,Springer,2019-01-01,2019-01-18,"We introduce recommendations to train a Convolutional Neural Network for grid-based detection on a dataset that has a substantial class imbalance. These include curriculum learning, hard negative mining, a special border class, and more. We evaluate the recommendations on the problem of animal detection in aerial images, where we obtain an increase in precision from 9% to 40% at high recalls, compared to state-of-the-art. Data related to this paper are available at: http://doi.org/10.5281/zenodo.609023 .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-10997-4_40,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-30241-2_47,A Reinforcement Learning Approach to Smart Lane Changes of Self-driving Cars,Progress in Artificial Intelligence,10.1007/978-3-030-30241-2_47,Springer,2019-01-01,2019-08-30,"Lane changes are a vital part of vehicle motions on roads, affecting surrounding vehicles locally and traffic flow collectively. In the context of connected and automated vehicles (CAVs), this paper is concerned with the impacts of smart lane changes of CAVs on their own travel performance as well as on the entire traffic flow with the increase of the market penetration rate (MPR). On the basis of intensive microscopic traffic simulation and reinforcement learning technique, a selfish lane-changing strategy was first developed in this work to enable foresighted lane changing decisions for CAVs to improve their travel efficiency. The overall impacts of such smart lane changes on traffic flow of both CAVs and human-driven vehicles were then examined on the same simulation platform. It was found that smart lane changes were beneficial for both CAVs and the entire traffic flow, if MPR was not more than 60%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30241-2_47,springer
Chapter ConferencePaper,doi:10.1007/978-981-13-7025-0_38,Research on 3D Reconstruction of Transmission Linesnd Identification of Hidden Dangers of Tree Barriers Based on Airborne Lidar Point Cloud,Geo-informatics in Sustainable Ecosystem and Society,10.1007/978-981-13-7025-0_38,Springer,2019-01-01,2019-02-27,"The inspection procedure of Chinese high voltage power grid is mainly based on human inspection for many years. This is not only time-consuming and difficult, but the inspection results are also not objective and complete. Aiming at these problems, this paper gives a research method based on UAV-borne laser scanning. By taking the orthophotos of the power line corridor area and using the overlapping feature points of the image, the orientation elements of each photo are inversely calculated. According to the principle of aerial triangulation, the pixel matching algorithm is used to calculate the dense point cloud data of the survey area, and the power line point in the point cloud is selected to simulate the complete power line. By calculating the Euclidean distance between the power line and the power line protection area, the calculated result is compared with the power line safety specification to obtain information such as a tree barrier point or an early warning point. It can effectively identify many important defects such as wire-vegetation, wire-building, wire-crossing, etc., and greatly improve the quality and efficiency of the inspection process of existing high-voltage transmission lines.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-7025-0_38,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-33709-4_17,AIBA: An AI Model for Behavior Arbitration in Autonomous Driving,Multi-disciplinary Trends in Artificial Intelligence,10.1007/978-3-030-33709-4_17,Springer,2019-01-01,2019-10-21,"Driving in dynamically changing traffic is a highly challenging task for autonomous vehicles, especially in crowded urban roadways. The Artificial Intelligence (AI) system of a driverless car must be able to arbitrate between different driving strategies in order to properly plan the car’s path, based on an understandable traffic scene model. In this paper, an AI behavior arbitration algorithm for Autonomous Driving (AD) is proposed. The method, coined AIBA (AI Behavior Arbitration), has been developed in two stages: (i) human driving scene description and understanding and (ii) formal modelling. The description of the scene is achieved by mimicking a human cognition model, while the modelling part is based on a formal representation which approximates the human driver understanding process. The advantage of the formal representation is that the functional safety of the system can be analytically inferred. The performance of the algorithm has been evaluated in Virtual Test Drive (VTD), a comprehensive traffic simulator, and in GridSim, a vehicle kinematics engine for prototypes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-33709-4_17,springer
Chapter ConferencePaper,doi:10.1007/978-981-13-6577-5_49,Self-Driving Car Using Artificial Intelligence,Advances in Interdisciplinary Engineering,10.1007/978-981-13-6577-5_49,Springer,2019-01-01,2019-06-01,"Self-driving autonomous vehicles are the solution for enhancing mobility intelligence related to driving. This project presents effective ways for implementation of a self-driving car. Proposed work is based on Artificial Intelligence, Computer Vision and Neural Networks. The proposed technology is implemented on a mini-robot car that was built from scratch, which uses Raspberry Pi and a camera as its core. The system built runs a script for complex task handling and sending appropriate commands to the vehicle. Image Processing techniques are also issued in the proposed system to identify various objects and traffic lights on the way. The system learns to autonomously navigate through reinforcement learning. Tensor Board is used to keep track of the working and efficiency of the trained Neural Network. The efficiency of the system is recorded at 96% as of now.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-6577-5_49,springer
Chapter,doi:10.1007/978-3-030-15191-1_8,Automation and Ethics,Moral Reasoning at Work,10.1007/978-3-030-15191-1_8,Springer,2019-01-01,2019-04-11,"Decision-makers in business can expect to face a range of new ethical challenges connected to automation and digitalization. One notable example is that of the programming of self-driving cars. It is likely that these cars can contribute to considerably safer traffic and fewer accidents, as these vehicles will be able to respond much faster and more reliably than fallible human drivers. However, they also raise ethical questions about how to prioritize human lives in situations where either people inside or outside the car will die. Here the reflections are similar to those we have encountered with regard to the trolley problem. Another set of ethical challenges arise in connection with automation and employment. Companies will be in a position to automate processes that have previously been handled by humans, with the aim of cutting costs and enhancing product quality. It will also make current employees redundant. This chapter introduces one conceptual distinction relevant to keep track of automation and ethics between proscriptive and prescriptive ethics, or between avoid-harm ethics and do-good ethics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-15191-1_8,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-01054-6_6,Convolution Neural Network Application for Road Asset Detection and Classification in LiDAR Point Cloud,Intelligent Systems and Applications,10.1007/978-3-030-01054-6_6,Springer,2019-01-01,2018-11-09,"Self-driving cars (or autonomous cars) can sense and navigate through an environment without any driver intervention. To achieve this task, they rely on vision sensors working in tandem with accurate algorithms to detect movable and non-movable objects around them. These vision sensors typically include cameras to identify static and non-static objects, Radio Detection and Ranging (RADAR) to detect the speed of the moving objects using Doppler effect and Light Detection and Ranging (LiDAR) to detect the distance to objects. In this paper, we explore a new usage of LiDAR data to classify static objects on the road. We present a pipeline to classify point cloud data grouped in volumetric pixels (voxels). We introduce a novel approach to point cloud data representation for processing within Convolution Neural Networks (CNN). Results show an accuracy exceeding 90% in the detection and classification of road edges, solid and broken lane markings, bike lanes, and lane center lines. Our data pipeline is capable of processing up to 20,000 points per 900ms on a server equipped with 2 Intel Xeon processors 8-core CPU with HyperThreading for a total of 32 threads and 2 NVIDIA Tesla K40 GPUs. Our model outperforms by 2% ResNet applied to camera images for the same road.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-01054-6_6,springer
Chapter,doi:10.1007/978-981-10-8797-4_41,Application of Swarm Intelligence in Autonomous Cars for Obstacle Avoidance,"Integrated Intelligent Computing, Communication and Security",10.1007/978-981-10-8797-4_41,Springer,2019-01-01,2018-09-15,"Obstacle detection is a major challenge which must be addressed for optimal implementation of self-driving cars. Various approaches have been postulated regarding the same. However, the acquisition of data by the various sensors in a car is shortsighted and constrained due the physical limitations in the scope of the sensors. In this chapter, we propose a model for obstacle avoidance in self-driving cars by integrating swarm intelligence with pre-existing conventional technologies. By establishing bi-directional communication of sensory data between the various cars which may form a network we can overcome the limitations faced by the receptors of a self-driving car.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-8797-4_41,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-01177-2_13,Deep Learning Based Classification System for Identifying Weeds Using High-Resolution UAV Imagery,Intelligent Computing,10.1007/978-3-030-01177-2_13,Springer,2019-01-01,2018-11-02,"In recent years, weeds is responsible for most of the agricultural yield losses. To deal with this problem Omega, farmers resort to spraying pesticides throughout the field. Such method not only requires huge quantities of herbicides but impact environment and humans health. In this paper, we propose a new vision-based classification system for identifying weeds in vegetable fields such as spinach, beet and bean by applying convolutional neural networks (CNNs) and crop lines information. In this study, we combine deep learning with line detection to enforce the classification procedure. The proposed method is applied to high-resolution Unmanned Aerial Vehicles (UAV) images of vegetables taken about 20 m above the soil. We have performed an extensive evaluation of the method with real data. The results showed that the proposed method of weeds detection was effective in different crop fields. The overall precision for the beet, spinach and bean is respectively of 93%, 81% and 69%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-01177-2_13,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-30619-9_24,Reinforcement Learning Based UAV Trajectory and Power Control Against Jamming,Machine Learning for Cyber Security,10.1007/978-3-030-30619-9_24,Springer,2019-01-01,2019-09-09,"Unmanned aerial vehicles (UAVs) are vulnerable to jamming attacks that aim to interrupt the communications between the UAVs and ground nodes and to prevent the UAVs from completing their sensing duties. In this paper, we design a reinforcement learning based UAV trajectory and power control scheme against jamming attacks without knowing the ground node and jammer locations, the UAV channel model and jamming model. By evaluating the UAV transmission quality obtained from the feedback channel and the UAV channel condition, this scheme uses reinforcement learning to choose the UAV trajectory and transmit power based on the UAV location, signal-to-interference-and-noise ratio of the previous sensing data signal received by the ground node, and the radio channel state. Simulation results show that this scheme improves the quality of service of the UAV sensing duty given the required UAV waypoints and saves the UAV energy consumption.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30619-9_24,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-29930-9_8,Training Deep Learning Models via Synthetic Data: Application in Unmanned Aerial Vehicles,Computer Analysis of Images and Patterns,10.1007/978-3-030-29930-9_8,Springer,2019-01-01,2019-08-23,"This paper describes preliminary work in the recent promising approach of generating synthetic training data for facilitating the learning procedure of deep learning (DL) models, with a focus on aerial photos produced by unmanned aerial vehicles (UAV) . The general concept and methodology are described, and preliminary results are presented, based on a classification problem of fire identification in forests as well as a counting problem of estimating number of houses in urban areas. The proposed technique constitutes a new possibility for the DL community, especially related to UAV-based imagery analysis, with much potential, promising results, and unexplored ground for further research .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-29930-9_8,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-29930-9_11,"An Integrated Precision Farming Application Based on 5G, UAV and Deep Learning Technologies",Computer Analysis of Images and Patterns,10.1007/978-3-030-29930-9_11,Springer,2019-01-01,2019-08-23,"Wireless communication technology has made tremendous progress over the last two decades providing extensive coverage, high data-rate and low-latency. The current major upgrade, the fifth generation (5G) wireless technology promises substantial improvement over 4G broadband cellular technology . However, even in many developed countries, rural areas are significantly under-connected with mobile wireless technology. Developing 5G testbeds in rural areas can provide an incentive for service providers to improve internet connectivity. 5G Rural Integrated Testbed (5GRIT) is a project commissioned to develop testbeds for 5G in rural areas in the United Kingdom (UK). The project aims to demonstrate the role 5G networks can play in empowering farming and tourism sectors using an integrated system of unmanned aerial vehicles (UAV) and artificial intelligence technologies. This paper reports some of the studies and findings of the 5GRIT project, specifically, the results of testbed implementation and the deep learning algorithms developed for precision farming applications .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-29930-9_11,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-23712-7_27,A Deep Reinforcement Learning Approach for Autonomous Car Racing,E-Learning and Games,10.1007/978-3-030-23712-7_27,Springer,2019-01-01,2019-07-17,"In this paper, we introduce a deep reinforcement learning approach for autonomous car racing based on the Deep Deterministic Policy Gradient (DDPG). We start by implementing the approach of DDPG, and then experimenting with various possible alterations to improve performance. In particular, we exploit two strategies: the action punishment and multiple exploration, to optimize actions in the car racing environment. We evaluate the performance of our approach on the Car Racing dataset, the experimental results demonstrate the effectiveness of the proposed approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-23712-7_27,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-11680-4_18,Car Monitoring System in Apartments’ Garages by Small Autonomous Car Using Deep Learning,Information Management and Big Data,10.1007/978-3-030-11680-4_18,Springer,2019-01-01,2019-02-08,"Currently in Peru, people prefer to live in apartment instead of houses but in some cases there are troubles with belongings between tenants who leave their stuffs in parking lots. For that, the use of an intelligent mobile mini-robot is proposed to implement a monitoring system of objects, such as cars in an underground garage inside a building using deep learning models in order to solve problems of theft of belongings. In addition, the small robot presents an indoor location system through the use of beacons that allow us to identify the position of the parking lot corresponding to each tenant of the building during the route of the robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-11680-4_18,springer
Chapter ConferencePaper,doi:10.1007/978-981-13-9917-6_36,Tiny Vehicle Detection from UAV Imagery,Image and Graphics Technologies and Applications,10.1007/978-981-13-9917-6_36,Springer,2019-01-01,2019-07-20,"In the past decade, great progress has been made in general object detection based on deep convolutional neural networks. However, object detection from Unmanned Aerial Vehicles (UAV) imagery received not so much concern. In this paper, a densely connected feature mining network is proposed for high accuracy detection. Specifically, multi-scale predictions are used to enhance the feature representation of the tiny vehicles. Furthermore, a streamlined one-stage detection network is used to achieve satisfactory trade-off between speed and accuracy. Finally, a improved distance metric function is integrated into the priors clustering process, which can lead to a better preliminary location before training. The proposed architecture is evaluated on the highly competitive UAV benchmark (UAVDT). The experimental results show that the proposed dense-darknet network has achieved a competitive performance of 42.03% mAP (mean Average Precision) and good generalization ability on the other UAV benchmarks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-9917-6_36,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-94120-2_28,Disturbances Based Adaptive Neuro-Control for UAVs: A First Approach,International Joint Conference SOCO’18-CISIS’18-ICEUTE’18,10.1007/978-3-319-94120-2_28,Springer,2019-01-01,2018-06-07,"In this work an adaptive neuro-control is proposed to cope with some external disturbances that can affect unmanned aerial vehicles (UAV) dynamics, specifically: the variation of the system mass during logistic tasks and the influence of the wind. An intelligent control strategy based on a feedforward neural networks is applied. In particular, a variant of the generalized learning algorithm has been used. Simulation results show how the on-line learning increases the robustness of the controller, reducing the effects of the changes in mass and the effects of wind on the UAV stabilization, thus improving the system response. It has been compared with a PID controller obtaining better results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-94120-2_28,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-99996-8_8,CNN Based Traffic Sign Recognition for Mini Autonomous Vehicles,Information Systems Architecture and Technology: Proceedings of 39th International Conference on Information Systems Architecture and Technology – ISAT 2018,10.1007/978-3-319-99996-8_8,Springer,2019-01-01,2018-08-28,"Advanced driving assistance systems (ADAS) could perform basic object detection and classification to alert drivers for road conditions, vehicle speed regulation, and etc. With the advances in the new hardware and software platforms, deep learning has been used in ADAS technologies. Traffic signs are an important part of road infrastructure. So, it is very important task to detect and classify traffic signs for autonomous vehicles. In this paper, we firstly create a traffic sign dataset from ZED stereo camera mounted on the top of Racecar mini autonomous vehicle and we use Tiny-YOLO real-time object detection and classification system to detect and classify traffic signs. Then, we test the model on our dataset in terms of accuracy, loss, precision and intersection over union performance metrics.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-99996-8_8,springer
Chapter,doi:10.1007/978-3-030-11479-4_4,Deep Learning for Driverless Vehicles,Handbook of Deep Learning Applications,10.1007/978-3-030-11479-4_4,Springer,2019-01-01,2019-02-26,"Automation is becoming a large component of many industries in the 21st century, in areas ranging from manufacturing, communications and transportation. Automation has offered promised returns of improvements in safety, productivity and reduced costs. Many industry leaders are specifically working on the application of autonomous technology in transportation to produce “driverless” or fully autonomous vehicles. A key technology that has the potential to drive the future development of these vehicles is deep learning. Deep learning has been an area of interest in machine learning for decades now but has only come into widespread application in recent years. While traditional analytical control systems and computer vision techniques have in the past been adequate for the fundamental proof of concept of autonomous vehicles, this review of current and emerging technologies demonstrates these short comings and the road map for overcoming them with deep learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-11479-4_4,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-20717-5_8,Development of Flexible Autonomous Car System Using Machine Learning and Blockchain,Proceedings of the 3rd International Symposium of Information and Internet Technology (SYMINTECH 2018),10.1007/978-3-030-20717-5_8,Springer,2019-01-01,2019-05-16,"Autonomous Driving car is an upcoming technology. In our project, we are taking a step towards this vision by developing a system using Raspberry Pi, image processing and machine learning and connect the system to any electric car. The proposed system provides an autonomous car feature to any existing electric car on the road that doesn’t have autonomous driving feature inbuilt within it. Most existing electric cars that are on roads don’t have this technology and this is mostly found in new and expensive cars. An alarming fact about autonomous cars is that many of them are being frequently hacked, indicating a problem related to security. The application of blockchain network, which seems to provide security and transparency in the usage of the network is employed to transfer data. Using the proposed system, such autonomous car feature can be installed separately at a cheaper expense in all existing electric cars. We aim to achieve the above by using image processing which is trained by using neural networks to create a model through which autonomous cars are achieved. With the usage of blockchain network, security and transparency of data transfer can be achieved. The hardware components used in this project are Raspberry PI 3 B microcomputer and camera module. This Raspberry Pi and camera unit forms a separate system which, when connected to the electronic control unit, helps the car to drive automatically.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-20717-5_8,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-35664-4_4,Autonomous Vehicle Control: End-to-End Learning in Simulated Urban Environments,Nordic Artificial Intelligence Research and Development,10.1007/978-3-030-35664-4_4,Springer,2019-01-01,2019-11-22,"In recent years, considerable progress has been made towards a vehicle’s ability to operate autonomously. An end-to-end approach attempts to achieve autonomous driving using a single, comprehensive software component. Recent breakthroughs in deep learning have significantly increased end-to-end systems’ capabilities, and such systems are now considered a possible alternative to the current state-of-the-art solutions. This paper examines end-to-end learning for autonomous vehicles in simulated urban environments containing other vehicles, traffic lights, and speed limits. Furthermore, the paper explores end-to-end systems’ ability to execute navigational commands and examines whether improved performance can be achieved by utilizing temporal dependencies between subsequent visual cues. Two end-to-end architectures are proposed: a traditional Convolutional Neural Network and an extended design combining a Convolutional Neural Network with a recurrent layer. The models are trained using expert driving data from a simulated urban setting, and are evaluated by their driving performance in an unseen simulated environment. The results of this paper indicate that end-to-end systems can operate autonomously in simple urban environments. Moreover, it is found that the exploitation of temporal information in subsequent images enhances a system’s ability to judge movement and distance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-35664-4_4,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-02686-8_21,Dynamic Evolution of Simulated Autonomous Cars in the Open World Through Tactics,Proceedings of the Future Technologies Conference (FTC) 2018,10.1007/978-3-030-02686-8_21,Springer,2019-01-01,2018-10-18,"There is an increasing level of interest in self-driving cars. In fact, it is predicted that fully autonomous cars will roam the streets by 2020. For an autonomous car to drive by itself, it needs to learn. A safe and economic way to teach a self-driving car to drive by itself is through simulation. However, current car simulators are based on closed world assumptions, where all possible events are already known as design time. Nevertheless, during the training of a self-driving car, it is impossible to account for all the possible events in the open world, where several unknown events may arise (i.e., events that were not considered at design time). Instead of carrying out particular adaptations for known context events in the closed world, the system architecture should evolve to safely reach a new state in the open world. In this research work, our contribution is to extend a car simulator trained by means of machine learning to evolve at runtime with tactics when the simulation faces unknown context events.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-02686-8_21,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-33617-2_17,Safe Deep Neural Network-Driven Autonomous Vehicles Using Software Safety Cages,Intelligent Data Engineering and Automated Learning – IDEAL 2019,10.1007/978-3-030-33617-2_17,Springer,2019-01-01,2019-10-18,"Deep learning is a promising class of techniques for controlling an autonomous vehicle. However, functional safety validation is seen as a critical issue for these systems due to the lack of transparency in deep neural networks and the safety-critical nature of autonomous vehicles. The black box nature of deep neural networks limits the effectiveness of traditional verification and validation methods. In this paper, we propose two software safety cages, which aim to limit the control action of the neural network to a safe operational envelope. The safety cages impose limits on the control action during critical scenarios, which if breached, change the control action to a more conservative value. This has the benefit that the behaviour of the safety cages is interpretable, and therefore traditional functional safety validation techniques can be applied. The work here presents a deep neural network trained for longitudinal vehicle control, with safety cages designed to prevent forward collisions. Simulated testing in critical scenarios shows the effectiveness of the safety cages in preventing forward collisions whilst under normal highway driving unnecessary interruptions are eliminated, and the deep learning control policy is able to perform unhindered. Interventions by the safety cages are also used to re-train the network, resulting in a more robust control policy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-33617-2_17,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-25540-4_25,VerifAI: A Toolkit for the Formal Design and Analysis of Artificial Intelligence-Based Systems,Computer Aided Verification,10.1007/978-3-030-25540-4_25,Springer,2019-01-01,2019-07-12,"We present VerifAI , a software toolkit for the formal design and analysis of systems that include artificial intelligence (AI) and machine learning (ML) components. VerifAI particularly addresses challenges with applying formal methods to ML components such as perception systems based on deep neural networks, as well as systems containing them, and to model and analyze system behavior in the presence of environment uncertainty. We describe the initial version of VerifAI , which centers on simulation-based verification and synthesis, guided by formal models and specifications. We give examples of several use cases, including temporal-logic falsification, model-based systematic fuzz testing, parameter synthesis, counterexample analysis, and data set augmentation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-25540-4_25,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-97885-7_3,Race from Pixels: Evolving Neural Network Controller for Vision-Based Car Driving,Recent Developments in Data Science and Intelligent Analysis of Information,10.1007/978-3-319-97885-7_3,Springer,2019-01-01,2018-08-05,"Modern robotics uses many advanced precise algorithms to control autonomous agents. Now arises tendency to apply machine learning in niches, where precise algorithms are hard to design or implement. With machine learning, for continuous control tasks, evolution strategies are used. We propose an enhancement to crossover operator, which diminishes probability of degraded offsprings compared to conventional crossover operators. Our experiments in TORCS environment show, that presented algorithm can evolve robust neural networks for non-trivial continuous control tasks such as driving a racing car in various tracks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-97885-7_3,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-31280-0_1,Learning a Behavior Model of Hybrid Systems Through Combining Model-Based Testing and Machine Learning,Testing Software and Systems,10.1007/978-3-030-31280-0_1,Springer,2019-01-01,2019-10-08,"Models play an essential role in the design process of cyber-physical systems. They form the basis for simulation and analysis and help in identifying design problems as early as possible. However, the construction of models that comprise physical and digital behavior is challenging. Therefore, there is considerable interest in learning such hybrid behavior by means of machine learning which requires sufficient and representative training data covering the behavior of the physical system adequately. In this work, we exploit a combination of automata learning and model-based testing to generate sufficient training data fully automatically. Experimental results on a platooning scenario show that recurrent neural networks learned with this data achieved significantly better results compared to models learned from randomly generated data. In particular, the classification error for crash detection is reduced by a factor of five and a similar F1-score is obtained with up to three orders of magnitude fewer training samples.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-31280-0_1,springer
Chapter ConferencePaper,doi:10.1007/978-981-10-8506-2_56,End-to-End Adaptive Cruise Control Based on Timing Network,Proceedings of the 19th Asia Pacific Automotive Engineering Conference & SAE-China Congress 2017: Selected Papers,10.1007/978-981-10-8506-2_56,Springer,2019-01-01,2018-10-07,"In recent years, driverless vehicle technology receives more attention because of its excellent performance on safety and efficiency. On the other hand, driverless vehicle calls for high-precision environmental perception and expert-like control strategies, which needs both lots of costly sensors and complex algorithms, and makes it difficult to achieve. Machine learning provides a new theoretical basis to solve this problem with big data, while most of data has not been calibrated yet. To solve these problems partly, a machine learning model based on a temporal neural network is described in this paper to achieve “end-to-end” self-driving from uncalibrated monocular images to control signals. The proposed approach is designed for adaptive cruise control situation. The approach is implemented in a simulation platform which has the control signal data from “expert.” According to the experiment in simulation platform, it shows that the proposed approach achieves “end-to-end” self-driving and has good performance on the prediction of desired acceleration.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-8506-2_56,springer
Chapter,doi:10.1007/978-3-319-98923-5_7,Sustainable Interdependent Networks from Smart Autonomous Vehicle to Intelligent Transportation Networks,Sustainable Interdependent Networks II,10.1007/978-3-319-98923-5_7,Springer,2019-01-01,2018-12-12,"The next step to the evolution of human transportation is the replacement of human driver by the artificial-intelligence-capable machine (i.e., autonomous vehicle). The prospect of improving aspects of lives including better utilization of cost, increased mobility, and independence as well as futuristic urban planning are some of the foreseen benefits. Regardless, the challenges remain especially to convince the consumers to trust the machines in exchange for their safety and ultimately their lives. This chapter seeks to highlight the ethical implications of the autonomous technology as a prerequisite to establishing trust between man and machine. Recent studies on the technology are cited in this chapter in order to give an overall outlook of the current discussion on the topic including on the issue of ethics. The objectives of the ethical consideration have to be grounded to the main objective of benefitting the society as a whole. As such, individual rights to access of information, system configuration, and education regarding autonomous technology should be upheld. In the end, it is important to integrate the autonomous systems into larger, interdependent transportation network systems in planning the future urban infrastructure and realize the full benefits of the technologies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-98923-5_7,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-01174-1_50,A Cognitive Framework for Object Recognition with Application to Autonomous Vehicles,Intelligent Computing,10.1007/978-3-030-01174-1_50,Springer,2019-01-01,2018-11-02,"Autonomous vehicles or self-driving cars are capable of sensing the surrounding environment so they can navigate roads without human input. Decisions are constantly made on sensing, mapping and driving policy using machine learning techniques. Deep Learning – massive neural networks that utilize the power of parallel processing – has become a popular choice for addressing the complexities of real time decision making. This method of machine learning has been shown to outperform alternative solutions in multiple domains, and has an architecture that can be adapted to new problems with relative ease. To harness the power of Deep Learning, it is necessary to have large amounts of training data that are representative of all possible situations the system will face. To successfully implement situational awareness in driverless vehicles, it is not possible to exhaust all possible training examples. An alternative method is to apply cognitive approaches to perception, for situations the autonomous vehicles will face. Cognitive approaches to perception work by mimicking the process of human intelligence – thereby permitting a machine to react to situations it has not previously experienced. This paper proposes a novel cognitive approach for object recognition. The proposed cognitive object recognition algorithm, referred to as Recognition by Components, is inspired by the psychological studies pertaining to early childhood development. The algorithm works by breaking down images into a series of primitive forms such as square, triangle, circle or rectangle and memory based aggregation to identify objects. Experimental results suggest that Recognition by Component algorithm performs significantly better than algorithms that require large amounts of training data.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-01174-1_50,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-23538-3_10,A Method to Automatic Measuring Riding Comfort of Autonomous Vehicles: Based on Passenger Subjective Rating and Vehicle Parameters,"Design, User Experience, and Usability. Application Domains",10.1007/978-3-030-23538-3_10,Springer,2019-01-01,2019-07-04,"As a milestone product of the AI era, the autonomous vehicle has attracted tremendous attention from the whole society. When autonomous vehicles (AV) provide transportation services as passenger vehicles in the future, a comfortable riding experience will be the fundamental element of usability. In such a case, it is necessary to establish an objective and sound evaluation system to evaluate the comfort level of autonomous vehicles. We hereby develop the comfort level model of autonomous vehicles with the following three steps: (a) Explore subjective evaluation indicators: Invite passengers to test autonomous vehicles and collect their ratings of the comfort level; (b) Establish the subjective comfort evaluation model: classify the evaluation indicators, continuously collect the evaluation data of the comfort level from the passengers during the testing process, and then use the structural modelling method to form a subjective evaluation model of the comfort level; (c) Develop the automatic scoring tool: collect subjective and objective data through data collection apps, form a calculation function with machine learning algorithm that fits the subjective and objective data, and develop an automatic scoring tool based on it. This precisely developed evaluation system and the empirical data-based scoring tool can be used to guide technological development, optimize algorithms, and improve strategies within the AV corporate. On the other hand, it can help to unify evaluation standard for AV industry, improving the experience of autonomous vehicle rides.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-23538-3_10,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-26250-1_34,The Moral Machine: Is It Moral?,"Computer Safety, Reliability, and Security",10.1007/978-3-030-26250-1_34,Springer,2019-01-01,2019-08-09,"Many recent studies have been proposing, discussing and investigating moral decisions in scenarios of imminent accident involving Autonomous Vehicles (AV). Those studies investigate people’s expectations about the best decisions the AVs should make when some life needs to be sacrificed to save other ones. A recent research found those preferences have strong ties to the respondents’ cultural traits. The present position paper questions the importance and the real value of those discussions. It also argues about their morality. Finally, an approach based on risk-oriented decision making is discussed as an alternative way to tackle those situations framed as “moral dilemmas” under the light of safety engineering.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-26250-1_34,springer
Article,doi:10.1186/s41018-018-0045-4,Search and rescue with autonomous flying robots through behavior-based cooperative intelligence,Journal of International Humanitarian Action,10.1186/s41018-018-0045-4,Springer,2018-12-05,2018-12-05,"A swarm of autonomous flying robots is implemented in simulation to cooperatively gather situational awareness data during the first few hours after a major natural disaster. In computer simulations, the swarm is successful in locating over 90% of survivors in less than an hour. The swarm is controlled by new sets of reactive behaviors which are presented and evaluated. The reactive behaviors integrate collision avoidance, battery recharge, formation control, altitude maintenance, and a variety of search methods to optimize the coverage area of camera and heart-beat locator sensors mounted on the robots. The behaviors are implemented in simulation on swarms of sizes from 1 to 20 robots. The simulation uses actual location data, including post-disaster satellite imagery, real locations of damaged and inundated buildings, and realistic victim locations based on personal interviews and accounts. The results demonstrate the value of using behavior-based swarming algorithms to control autonomous unmanned aerial vehicles for post-disaster search and assessment. Three examples of algorithms that have been effective in simulation are presented .",https://www.biomedcentral.com/openurl?doi=10.1186/s41018-018-0045-4,springer
Article,doi:10.1007/s42405-018-0091-6,Self-Tuning Proportional Double Derivative-Like Neural Network Controller for a Quadrotor,International Journal of Aeronautical and Space Sciences,10.1007/s42405-018-0091-6,Springer,2018-12-01,2018-11-01,"In this paper, a self-tuning proportional double derivative-like neural network nonlinear adaptive controller for attitude tracking control of an unmanned aerial vehicle (UAV) is presented. The proposed scheme consists of neural networks with two neural nodes in the hidden layer and includes activation feedback. The error between the desired angle set-point and the output as well as the change of error is selected as the controller input. The optimal initial weight parameters are obtained by employing an adaptive ant colony optimization. The proposed controller can online tune the weight parameters of the hidden layer with a stable learning rate based on the controller input. The effect of the learning rates on the stability of the neural network controller was analyzed. The designed controller was developed based on a nonlinear model of an UAV with quaternion representation in the presence of parametric uncertainties and external disturbances. Simulation results demonstrate the validity and effectiveness of the proposed algorithm with different reference attitude signals.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42405-018-0091-6,springer
Article,doi:10.1007/s40860-018-0070-5,A survey on verification strategies for intelligent transportation systems,Journal of Reliable Intelligent Environments,10.1007/s40860-018-0070-5,Springer,2018-12-01,2018-10-19,"As intelligent systems are increasingly entering everyday life, in domains such as transportation, resource distribution, health care, or retail, developing suitable verification mechanisms for such systems becomes vital. From a formal point of view, the employed intelligent sensor actuator systems (ISAS) constituting such intelligent systems combine three different technologies: control systems, distributed systems, and learning and reasoning. While each of the parent domains features tested and proven verification methods, simply combining the tasks unfortunately leads to a combinatorial explosion of complexity. This paper presents an overview and classification of currently employed techniques for handling ISAS in terms of: cyber-physical systems, intelligent autonomous robots, or intelligent agents. The article argues that each of the three classical perspectives misses one important characteristic of ISAS and proposes to combine the three for a full solution. The paper argues that in particular two mechanisms are promising: an intelligent environments perspective that verifies local safety and techniques for context-aware monitoring that allow a mobile system to leverage context-awareness to reduce complexity for self-monitoring tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40860-018-0070-5,springer
Article,doi:10.1007/s12559-018-9559-8,Distributed Drone Base Station Positioning for Emergency Cellular Networks Using Reinforcement Learning,Cognitive Computation,10.1007/s12559-018-9559-8,Springer,2018-10-01,2018-05-22,"Due to the unpredictability of natural disasters, whenever a catastrophe happens, it is vital that not only emergency rescue teams are prepared, but also that there is a functional communication network infrastructure. Hence, in order to prevent additional losses of human lives, it is crucial that network operators are able to deploy an emergency infrastructure as fast as possible. In this sense, the deployment of an intelligent, mobile, and adaptable network, through the usage of drones—unmanned aerial vehicles—is being considered as one possible alternative for emergency situations. In this paper, an intelligent solution based on reinforcement learning is proposed in order to find the best position of multiple drone small cells (DSCs) in an emergency scenario. The proposed solution’s main goal is to maximize the amount of users covered by the system, while drones are limited by both backhaul and radio access network constraints. Results show that the proposed Q -learning solution largely outperforms all other approaches with respect to all metrics considered. Hence, intelligent DSCs are considered a good alternative in order to enable the rapid and efficient deployment of an emergency communication network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12559-018-9559-8,springer
Article,doi:10.3103/S1068798X18100118,Smart Design of Driverless-Vehicle Routes in the Arctic and Far North,Russian Engineering Research,10.3103/S1068798X18100118,Springer,2018-10-01,2018-11-15,Abstract An approach to the design of routes for driverless vehicles in the Arctic and Far North is discussed. The proposed approach employs artificial intelligence and drones.,http://link.springer.com/openurl/fulltext?id=doi:10.3103/S1068798X18100118,springer
Article,doi:10.1007/s41650-018-0029-y,Reinforcement Learning-Based Control for Unmanned Aerial Vehicles,Journal of Communications and Information Networks,10.1007/s41650-018-0029-y,Springer,2018-09-01,2018-10-05,"Estates, especially those of public securityrelated companies and institutes, have to protect their privacy from adversary unmanned aerial vehicles (UAVs). In this paper, we propose a reinforcement learning-based control framework to prevent unauthorized UAVs from entering a target area in a dynamic game without being aware of the UAV attack model. This UAV control scheme enables a target estate to choose the optimal control policy, such as jamming the global positioning system signals, hacking, and laser shooting, to expel nearby UAVs. A deep reinforcement learning technique, called neural episodic control, is used to accelerate the learning speed to achieve the optimal UAV control policy, especially for estates with a large area, against complicated UAV attack policies. We analyze the computational complexity for the proposed UAV control scheme and provide its performance bound, including the risk level of the estate and its utility. Our simulation results show that the proposed scheme can reduce the risk level of the target estate and improve its utility against malicious UAVs compared with the selected benchmark scheme.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s41650-018-0029-y,springer
Article,doi:10.1007/s12524-018-0756-4,"Tree Crown Detection, Delineation and Counting in UAV Remote Sensed Images: A Neural Network Based Spectral–Spatial Method",Journal of the Indian Society of Remote Sensing,10.1007/s12524-018-0756-4,Springer,2018-06-01,2018-06-29,"UAVs are fast emerging as a remote sensing platform to complement satellite based remote sensing. Agriculture and ecology is one of the important applications of UAV remote sensing, also known as low altitude remote sensing (LARS). This work demonstrates the use and potential of LARS in agriculture, particularly small holder open field agriculture. Two UAVs are used for remote sensing. The first UAV is a fixed wing aircraft with a high spatial resolution visible spectrum also known as RGB camera as a payload. The second UAV is a quadrotor UAV with an RGB camera interfaced to an on-board single board computer as the payload. LARS was carried out to acquire aerial high spatial resolution RGB images of different farms. Spectral–spatial classification of high spatial resolution RGB images for detection, delineation and counting of tree crowns in the image is presented. Supervised classification is carried out using extreme learning machine (ELM), a single hidden layer feed forward network neural network classifier. ELM was modelled for RGB values as input feature vectors and binary (tree and non-tree pixels) output class. Due to similarities in spectral intensities, some of the non-tree pixels were classified as tree pixels and in order to remove them, spatial classification was performed on the image. Spatial classification was carried out using thresholded geometrical property filtering techniques. Threshold values chosen for carrying out spatial classification were analysed to obtain optimal values. Finally in the delineation and counting, the connected tree crowns were segmented using Watershed algorithm performed on the image after marking individual tree crowns using Distance Transform method. Five representative UAV images captured at different altitudes with different crowns of banana plant, mango trees and coconut trees were used to demonstrate the performance of the proposed method. The performance was compared with the traditional KMeans spectral–spatial method of clustering. Results and comparison of performance parameters of KMeans spectral–spatial and ELM spectral–spatial classification methods are presented. Results indicate that ELM performed better than KMeans.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12524-018-0756-4,springer
Article,doi:10.1007/s10677-018-9909-3,"Lin, P., Abney, K., & Jenkins, R. (Eds.): Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence",Ethical Theory and Moral Practice,10.1007/s10677-018-9909-3,Springer,2018-06-01,2018-07-31,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10677-018-9909-3,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-60591-3_3,Automated Situation Analysis as Next Level of Unmanned Aerial Vehicle Artificial Intelligence,Advances in Human Factors in Simulation and Modeling,10.1007/978-3-319-60591-3_3,Springer,2018-01-01,2017-06-15,"In this paper automated situation analysis is discussed together with already accessible advantages of artificial intelligence and control systems of unmanned aerial vehicle. Based on previous researches some new solutions are proposed to fulfill safety tasks in case of traffic, fire and criminal threats. Mostly connected with existing solutions, owing to artificial intelligence and hybrid systems they move to next level and provide better results and guideline for further development.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-60591-3_3,springer
Chapter,doi:10.1007/978-3-319-66379-1_11,A Drone-Based Building Inspection System Using Software-Agents,Intelligent Distributed Computing XI,10.1007/978-3-319-66379-1_11,Springer,2018-01-01,2017-10-05,"Regular building inspections are a key means of identifying defects before getting worse or causing a building failure. As a tool for building condition inspections, Unmanned Aerial Vehicles (UAVs) or drones offer considerable potential allowing especially high-rise buildings to be visually assessed with economic and risk-related benefits. One of the critical problems encountered in automating the system is that the whole process involves a very complicated and significant amount of computational tasks, such as UAV control, localisation, image acquisition and abnormality analysis using machine learning techniques. Distributed software agents interact and collaborate each other in complicated systems and improve the reliability, availability and scalability. This research introduces a ubiquitous concept of software-agents to a drone-based building inspection system that is applied to crack-detection on concrete surfaces. The architecture and new features of the proposed system will be discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-66379-1_11,springer
Chapter,doi:10.1007/978-3-319-98131-4_8,Explainable Deep Driving by Visualizing Causal Attention,Explainable and Interpretable Models in Computer Vision and Machine Learning,10.1007/978-3-319-98131-4_8,Springer,2018-01-01,2018-11-30,"Deep neural perception and control networks are likely to be a key component of self-driving vehicles. These models need to be explainable—they should provide easy-to-interpret rationales for their behavior—so that passengers, insurance companies, law enforcement, developers etc., can understand what triggered a particular behavior. Here, we explore the use of visual explanations. These explanations take the form of real-time highlighted regions of an image that causally influence the network’s output (steering control). Our approach is two-stage. In the first stage, we use a visual attention model to train a convolutional network end-to-end from images to steering angle. The attention model highlights image regions that potentially influence the network’s output. Some of these are true influences, but some are spurious. We then apply a causal filtering step to determine which input regions actually influence the output. This produces more succinct visual explanations and more accurately exposes the network’s behavior. We demonstrate the effectiveness of our model on three datasets totaling 16 h of driving. We first show that training with attention does not degrade the performance of the end-to-end network. Then we show that the network highlights interpretable features that are used by humans while driving, and causal filtering achieves a useful reduction in explanation complexity by removing features which do not significantly affect the output.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-98131-4_8,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-89656-4_44,Decision Assist for Self-driving Cars,Advances in Artificial Intelligence,10.1007/978-3-319-89656-4_44,Springer,2018-01-01,2018-04-06,"Research into self-driving cars has grown enormously in the last decade primarily due to the advances in the fields of machine intelligence and image processing. An under-appreciated aspect of self-driving cars is actively avoiding high traffic zones, low visibility zones, and routes with rough weather conditions by learning different conditions and making decisions based on trained experiences. This paper addresses this challenge by introducing a novel hierarchical structure for dynamic path planning and experiential learning for vehicles. A multistage system is proposed for detecting and compensating for weather, lighting, and traffic conditions as well as a novel adaptive path planning algorithm named Checked State A3C . This algorithm improves upon the existing A3C Reinforcement Learning (RL) algorithm by adding state memory which provides the ability to learn an adaptive model of the best decisions to take from experience.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-89656-4_44,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-00692-1_35,Embedded Vision System for Automated Drone Landing Site Detection,Computer Vision and Graphics,10.1007/978-3-030-00692-1_35,Springer,2018-01-01,2018-09-14,"This paper presents an embedded video subsystem used to classify the terrain, based on an image from a camera located under the drone, for the purpose of an automatic landing system. Colour and texture features, as well as decision trees and support vector machine classifiers were analysed and evaluated. The algorithm was supported with a shadow detection module. It was evaluated on 100 test cases and achieved over 80% performance. The designed video system was implemented on two embedded platforms – a Zynq SoC (System on Chip – Field Programmable Gate Array + ARM processor system) and a Jetson GPU (Graphic Processing Unit + ARM processor system). The performance achieved on both architectures is compared and discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-00692-1_35,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-96728-8_13,Extending Deep Neural Network Trail Navigation for Unmanned Aerial Vehicle Operation Within the Forest Canopy,Towards Autonomous Robotic Systems,10.1007/978-3-319-96728-8_13,Springer,2018-01-01,2018-07-21,"Autonomous flight within a forest canopy represents a key challenge for generalised scene understanding on-board a future Unmanned Aerial Vehicle (UAV) platforms. Here we present an approach for automatic trail navigation within such an unstructured environment that successfully generalises across differing image resolutions - allowing UAV with varying sensor payload capabilities to operate equally in such challenging environmental conditions. Specifically, this work presents an optimised deep neural network architecture, capable of state-of-the-art performance across varying resolution aerial UAV imagery, that improves forest trail detection for UAV guidance even when using significantly low resolution images that are representative of low-cost search and rescue capable UAV platforms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-96728-8_13,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-99229-7_42,Concerns on the Differences Between AI and System Safety Mindsets Impacting Autonomous Vehicles Safety,"Computer Safety, Reliability, and Security",10.1007/978-3-319-99229-7_42,Springer,2018-01-01,2018-08-21,"The inflection point in the development of some core technologies enabled the Autonomous Vehicles (AV). The unprecedented growth rate in Artificial Intelligence (AI) and Machine Learning (ML) capabilities, focusing only on AVs, is expected to shift the transportation paradigm and bring relevant benefits to the society, such as accidents reduction. However, recent AVs accidents resulted in life losses. This paper presents a viewpoint discussion based on findings from a preliminary exploratory literature review. It was identified an important misalignment between AI and Safety research communities regarding the impact of AI on the safety risks in AV. This paper promotes this discussion, raises concerns on the potential consequences and suggests research topics to reduce the differences between AI and system safety mindsets.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-99229-7_42,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-99229-7_41,Could We Issue Driving Licenses to Autonomous Vehicles?,"Computer Safety, Reliability, and Security",10.1007/978-3-319-99229-7_41,Springer,2018-01-01,2018-08-21,"Many companies are studying autonomous vehicles. One trend in the development of control algorithms for autonomous vehicles is the use of deep-learning approaches. The general idea is to simulate a human driver’s decision-making and behavior in various scenarios without necessarily knowing why the decision is made. In this position paper, we first argue that traditional safety analysis methods need to be extended to verify deep-learning-based autonomous vehicles. Then, we propose borrowing ideas from the process of issuing driving licenses to human drivers to verify autonomous vehicles. Verification of autonomous vehicles could focus on sufficient training as well as mental and physical health checks. Based on this position, we list several challenges that need to be addressed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-99229-7_41,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-74805-4_7,Robocopter,Satellite-Based Earth Observation,10.1007/978-3-319-74805-4_7,Springer,2018-01-01,2018-09-12,"In this paper about robocopters the author discusses the challenges of the integration of robotics, artificial intelligence, digitalisation, virtualisation and multicopter aviation technologies driven by the consumer market. After a linguistic decomposition of the word robocopter the robocopter will be defined as a “flying tool” or “flying robot” using, as a multicopter, the typical aviation technologies of a helicopter. A comparison shows the current differences between helicopters and typical unmanned multicopters. From an economic perspective, the quadcopter is most successful as a camera drone, driven by hobbyists like drone racers and photographers. With the use of first-person-view (FPV) glasses during a flight a philosophical dimension occurs, because, in our consciousness, the idea arises that “I am flying” instead of the drone. In Austria, a license from the Austro Control agency is necessary to legally store pictures and videos on a microchip on a drone; therefore, the legal regulations for drones are discussed in a short overview. Robocopters as flying tools with an extended level on autonomy are the next step in automation. But there is also a danger, especially in military applications discussed and shown in various video examples.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-74805-4_7,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-92537-0_78,Task Assignment Based on a Dual Neural Network,Advances in Neural Networks – ISNN 2018,10.1007/978-3-319-92537-0_78,Springer,2018-01-01,2018-05-26,"In this paper, task assignment, such as target assignment and parcel dispatching, for multi-agent systems is addressed. The problems are formulated as the linear assignment problem and its extensions. A dual neural network is used for solving them. Simulation results are reported on assigning multiple agents to multiple targets and dispatching parcels to given destinations using multiple agents.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-92537-0_78,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-94180-6_16,D2TFRS: An Object Recognition Method for Autonomous Vehicles Based on RGB and Spatial Values of Pixels,"Smart Societies, Infrastructure, Technologies and Applications",10.1007/978-3-319-94180-6_16,Springer,2018-01-01,2018-07-22,"Autonomous driving is now near future reality which will transform our world due to its numerous benefits. The foremost challenge to this task is to correctly identify the objects in the driving environment. In this work, we propose an object recognition method known as Decision Tree and Decision Fusion based Recognition System (D2TFRS) for autonomous driving. We combined two separate feature sets, which are RGB pixel values and spatial points X,Y of each pixel to form our dataset. The D2TFRS is based on our intuition that reclassification of pre-identified misclassified objects in a driving environment can give better prediction accuracy. Results showed that D2TFRS outperformed AdaBoost classifier and performed better than C5.0 classifier in terms of the classification accuracy and Kappa. In terms of speed, C5.0 outperforms both AdaBoost and D2TFRS. However, D2TFRS outperformed AdaBoost with respect to speed. We strongly believe that D2TFRS will have better parallelization performance compared to the other two methods and it will be investigated in our future work.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-94180-6_16,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-03769-7_23,Evaluating Perception Systems for Autonomous Vehicles Using Quality Temporal Logic,Runtime Verification,10.1007/978-3-030-03769-7_23,Springer,2018-01-01,2018-11-08,"For reliable situation awareness in autonomous vehicle applications, we need to develop robust and reliable image processing and machine learning algorithms. Currently, there is no general framework for reasoning about the performance of perception systems. This paper introduces Timed Quality Temporal Logic (TQTL) as a formal language for monitoring and testing the performance of object detection and situation awareness algorithms for autonomous vehicle applications. We demonstrate that it is possible to describe interesting properties as TQTL formulas and detect cases where the properties are violated.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-03769-7_23,springer
Chapter ConferencePaper,doi:10.1007/978-3-030-01258-8_25,End-to-End Deep Structured Models for Drawing Crosswalks,Computer Vision – ECCV 2018,10.1007/978-3-030-01258-8_25,Springer,2018-01-01,2018-10-06,"In this paper we address the problem of detecting crosswalks from LiDAR and camera imagery. Towards this goal, given multiple LiDAR sweeps and the corresponding imagery, we project both inputs onto the ground surface to produce a top down view of the scene. We then leverage convolutional neural networks to extract semantic cues about the location of the crosswalks. These are then used in combination with road centerlines from freely available maps (e.g., OpenStreetMaps) to solve a structured optimization problem which draws the final crosswalk boundaries. Our experiments over crosswalks in a large city area show that 96.6% automation can be achieved.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-01258-8_25,springer
Article,doi:10.1007/s10892-017-9252-2,Incorporating Ethics into Artificial Intelligence,The Journal of Ethics,10.1007/s10892-017-9252-2,Springer,2017-12-01,2017-03-07,"This article reviews the reasons scholars hold that driverless cars and many other AI equipped machines must be able to make ethical decisions, and the difficulties this approach faces. It then shows that cars have no moral agency, and that the term ‘autonomous’, commonly applied to these machines, is misleading, and leads to invalid conclusions about the ways these machines can be kept ethical. The article’s most important claim is that a significant part of the challenge posed by AI-equipped machines can be addressed by the kind of ethical choices made by human beings for millennia. Ergo, there is little need to teach machines ethics even if this could be done in the first place. Finally, the article points out that it is a grievous error to draw on extreme outlier scenarios—such as the Trolley narratives—as a basis for conceptualizing the ethical issues at hand.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10892-017-9252-2,springer
Article,doi:10.1007/s11042-016-4043-5,Vehicle detection from high-resolution aerial images using spatial pyramid pooling-based deep convolutional neural networks,Multimedia Tools and Applications,10.1007/s11042-016-4043-5,Springer,2017-10-01,2016-11-07,"In recent years, vehicle detection from aerial images obtained using unmanned aerial vehicles (UAVs) has become a research focus in image processing as remote sensing platforms on UAVs are rapidly popularised. This study proposes a detection algorithm using a deep convolutional neural network (DCNN) based on multi-scale spatial pyramid pooling (SPP). By using multi-scale SPP models to sample characteristic patterns with different sizes, feature vectors with a fixed length are generated. This avoids the stretching- or cropping-induced deformation of input images of different sizes, thus improving the detection effect. In addition, an imaging pre-processing algorithm based on maximum normed gradient (NG) with multiple thresholds is proposed. By using this algorithm, this research restores the edges of objects disturbed by clutter in the environment. Meanwhile, the raised candidate object extraction algorithm based on the maximum binarized NG entails fewer computations as it generates fewer candidate windows. Experimental results indicate that the multi-scale SPP based DCNN can better adapt to input images of different sizes to learn of the multi-scale characteristics of objects, thus further improving the detection effect.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11042-016-4043-5,springer
Article,doi:10.1007/s11948-016-9833-7,Who Should Decide How Machines Make Morally Laden Decisions?,Science and Engineering Ethics,10.1007/s11948-016-9833-7,Springer,2017-08-01,2016-11-30,"Who should decide how a machine will decide what to do when it is driving a car, performing a medical procedure, or, more generally, when it is facing any kind of morally laden decision? More and more, machines are making complex decisions with a considerable level of autonomy. We should be much more preoccupied by this problem than we currently are. After a series of preliminary remarks, this paper will go over four possible answers to the question raised above. First, we may claim that it is the maker of a machine that gets to decide how it will behave in morally laden scenarios. Second, we may claim that the users of a machine should decide. Third, that decision may have to be made collectively or, fourth, by other machines built for this special purpose. The paper argues that each of these approaches suffers from its own shortcomings, and it concludes by showing, among other things, which approaches should be emphasized for different types of machines, situations, and/or morally laden decisions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-016-9833-7,springer
Article,doi:10.1007/s11771-017-3551-4,Driving decision-making analysis of car-following for autonomous vehicle under complex urban environment,Journal of Central South University,10.1007/s11771-017-3551-4,Springer,2017-06-01,2017-07-09,"The decision-making under complex urban environment become one of the key issues that restricts the rapid development of the autonomous vehicles. The difficulty in making timely and accurate decisions like human beings under highly dynamic traffic environment is a major challenge for autonomous driving. Car-following has been regarded as the simplest but essential driving behavior among driving tasks and has received extensive attention from researchers around the world. This work addresses this problem and proposes a novel method RSAN (rough-set artificial neural network) to learn the decisions from excellent human drivers. A virtual urban traffic environment was built by PreScan and driving simulation was conducted to obtain a broad set of relevant data such as experienced drivers’ behavior data and surrounding vehicles’ motion data. Then, rough set was used to preprocess these data to extract the key influential factors on decision and reduce the impact of uncertain data and noise data. And the car-following decision was learned by neural network in which key factor was the input and acceleration was the output. The result shows the better convergence speed and the better decision accuracy of RSAN than ANN. Findings of this work contributes to the empirical understanding of driver’s decision-making process and it provides a theoretical basis for the study of car-following decision-making under complex and dynamic environment.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s11771-017-3551-4,springer
Article,doi:10.1007/s11629-016-3950-2,Cultivated land information extraction in UAV imagery based on deep convolutional neural network and transfer learning,Journal of Mountain Science,10.1007/s11629-016-3950-2,Springer,2017-04-01,2017-03-30,"The development of precision agriculture demands high accuracy and efficiency of cultivated land information extraction. As a new means of monitoring the ground in recent years, unmanned aerial vehicle (UAV) low-height remote sensing technique, which is flexible, efficient with low cost and with high resolution, is widely applied to investing various resources. Based on this, a novel extraction method for cultivated land information based on Deep Convolutional Neural Network and Transfer Learning (DTCLE) was proposed. First, linear features (roads and ridges etc.) were excluded based on Deep Convolutional Neural Network (DCNN). Next, feature extraction method learned from DCNN was used to cultivated land information extraction by introducing transfer learning mechanism. Last, cultivated land information extraction results were completed by the DTCLE and eCognition for cultivated land information extraction (ECLE). The location of the Pengzhou County and Guanghan County, Sichuan Province were selected for the experimental purpose. The experimental results showed that the overall precision for the experimental image 1, 2 and 3 (of extracting cultivated land) with the DTCLE method was 91.7%, 88.1% and 88.2% respectively, and the overall precision of ECLE is 90.7%, 90.5% and 87.0%, respectively. Accuracy of DTCLE was equivalent to that of ECLE, and also outperformed ECLE in terms of integrity and continuity.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s11629-016-3950-2,springer
Article,doi:10.1007/s11518-016-5325-1,The Sputnik of servgoods: Autonomous vehicles,Journal of Systems Science and Systems Engineering,10.1007/s11518-016-5325-1,Springer,2017-04-01,2017-01-24,"In an earlier paper (Tien 2015), the author defined the concept of a servgood, which can be thought of as a physical good or product enveloped by a services-oriented layer that makes the good smarter or more adaptable and customizable for a particular use. Adding another layer of physical sensors could then enhance its smartness and intelligence, especially if it were to be connected with each other or with other servgoods through the Internet of Things. Such sensed servgoods are becoming the products of the future. Indeed, autonomous vehicles can be considered the exemplar servgoods of the future; it is about decision informatics and embraces the advanced technologies of sensing (i.e., Big Data), processing (i.e., real-time analytics), reacting (i.e., real-time decision-making), and learning (i.e., deep learning). Since autonomous vehicles constitute a huge quality-of-life disruption, it is also critical to consider its policy impact on privacy and security, regulations and standards, and liability and insurance. Finally, just as the Soviet Union inaugurated the space age on October 4, 1957, with the launch of Sputnik, the first man-made object to orbit the Earth, the U. S. has inaugurated an age of automata or autonomous vehicles that can be considered to be the U. S. Sputnik of servgoods, with the full support of the U. S. government, the U. S. auto industry, the U. S. electronic industry, and the U.S. higher educational enterprise.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s11518-016-5325-1,springer
Article,doi:10.1007/s11071-016-3206-2,Adaptive neural-network sliding mode cascade architecture of longitudinal tracking control for unmanned vehicles,Nonlinear Dynamics,10.1007/s11071-016-3206-2,Springer,2017-03-01,2016-11-23,"Unmanned vehicles have drawn wide attention due to their intrinsic capacity of performing routine tasks for industry, conducting military missions and improving traffic safety. However, since the longitudinal dynamic system of unmanned vehicles inherently has the uncertain nonlinearities and time-varying behavior, longitudinal tracking control is reviewed as a challenging work in the exploitation of unmanned vehicles to deal with the features of uncertain nonlinearities and parametric time varying. In this paper, an adaptive nonlinear cascade control architecture is presented to design the longitudinal speed tracking control for unmanned vehicle, which is a nonholonomic system. Firstly, a upper-level model predictive control law is presented to produce a desired and smooth acceleration in real time, and the saturation characteristic is introduced to limit the accelerations within the range of given values. Then, a lower-level adaptive neuro-network sliding mode control (ANN-SMC) law is presented for dynamically tracking the desired acceleration, in which the uncertain term and the variable structure control term are adaptively adjusted by the neuro-networks, and the stability of proposed ANN-SMC control system is proved by the Lyapunov theory. Finally, simulation and experimental results demonstrate the feasibility and effectiveness of proposed control approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11071-016-3206-2,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-49073-1_11,A Novel Framework Based on Deep Learning and Unmanned Aerial Vehicles to Assess the Quality of Rice Fields,Advances in Information and Communication Technology,10.1007/978-3-319-49073-1_11,Springer,2017-01-01,2016-11-12,"In the past few decades, boosting crop yield has been extensively regarded in many agricultural countries, especially Vietnam. Due to food demands and impossibility of crop-field area increasing, precision farming is essential to improve agricultural production and productivity. In this paper, we propose a novel framework based on some advanced techniques including deep learning, unmanned aerial vehicles (UAVs) to assess the quality of Vietnamese rice fields. UAVs are responsible for taking images of the rice fields at low or very low altitudes. Then, these images with high resolution will be processed by the deep neural networks on high performance computing systems. The main task of deep neural networks is to classify the images into many classes corresponding to low and high qualities of the rice fields. To conduct experimental results, the rice fields located in Tay Ninh province are chosen as a case study. The experimental results indicate that this approach is quite appropriate for agricultural Vietnamese practice since its accuracy is approximately 0.72.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-49073-1_11,springer
Chapter ConferencePaper,doi:10.1007/978-981-10-7299-4_57,Traffic Sign Recognition Based on Deep Convolutional Neural Network,Computer Vision,10.1007/978-981-10-7299-4_57,Springer,2017-01-01,2017-11-30,"Traffic sign recognition (TSR) is an important component of automated driving system. It is a rather challenging task to design a high-performance classifier for the TSR system. In this paper, we proposed a new method for TSR system based on deep convolutional neural network. In order to enhance the expression of the network, a novel structure (dubbed block-layer below) which combines Network-in-Network and residual connection was designed. Our network has 10 layers with parameters (block-layer be seen as a single layer); the first seven are alternate convolutional layers and block-layers, and the remaining three are fully-connected layers. We trained our TSR network on the German Traffic Sign Recognition Benchmark (GTSRB) dataset. To reduce overfitting, we did data augmentation on the training images and employed a regularization method named dropout. We also employed a mechanism called Batch Normalization which has been proved to be efficient for accelerating the training of deep neural networks. To speed up the training, we used an efficient GPU to accelerate the convolutional operation. On the test dataset of GTSRB, we achieve the accuracy rate of 98.96%, exceeding the human average raters.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-7299-4_57,springer
Article,doi:10.1631/FITEE.1601650,Current trends in the development of intelligent unmanned autonomous systems,Frontiers of Information Technology & Electronic Engineering,10.1631/FITEE.1601650,Springer,2017-01-01,2017-02-04,"Intelligent unmanned autonomous systems are some of the most important applications of artificial intelligence (AI). The development of such systems can significantly promote innovation in AI technologies. This paper introduces the trends in the development of intelligent unmanned autonomous systems by summarizing the main achievements in each technological platform. Furthermore, we classify the relevant technologies into seven areas, including AI technologies, unmanned vehicles, unmanned aerial vehicles, service robots, space robots, marine robots, and unmanned workshops/intelligent plants. Current trends and developments in each area are introduced.",http://link.springer.com/openurl/fulltext?id=doi:10.1631/FITEE.1601650,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-64107-2_37,Drivers’ Manoeuvre Classification for Safe HRI,Towards Autonomous Robotic Systems,10.1007/978-3-319-64107-2_37,Springer,2017-01-01,2017-07-20,"Ever increasing autonomy of machines and the need to interact with them creates challenges to ensure safe operation. Recent technical and commercial interest in increasing autonomy of vehicles has led to the integration of more sensors and actuators inside the vehicle, making them more like robots. For interaction with semi-autonomous cars, the use of these sensors could help to create new safety mechanisms. This work explores the concept of using motion tracking (i.e. skeletal tracking) data gathered from the driver whilst driving to learn to classify the manoeuvre being performed. A kernel-based classifier is trained with empirically selected features based on data gathered from a Kinect V2 sensor in a controlled environment. This method shows that skeletal tracking data can be used in a driving scenario to classify manoeuvres and sets a background for further work.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-64107-2_37,springer
Article,doi:10.1007/s10846-015-0324-x,An Integrated System for UAV Control Using a Neural Network Implemented in a Prototyping Board,Journal of Intelligent & Robotic Systems,10.1007/s10846-015-0324-x,Springer,2016-12-01,2016-01-08,"Modern aerospace vehicles are expected to have non-conventional flight envelopes and then, in order to operate in uncertain environments, they must guarantee a high level of robustness and adaptability. A Neural Network (NN) controller, with real-time learning capability, can be used in applications with manned or unmanned aerial vehicles. In this paper a novel real-time control system, based on a NN model, in order to control the trajectories of a hexacopter is proposed. The proposed NN is optimized by the analytical calculation of the embedding parameters. The paper shows a performance evaluation, through a real experimental testbed, of the proposed approach in terms of error measures and computation of the angular velocities of the hexacopter.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-015-0324-x,springer
Article,doi:10.1007/s10676-016-9400-6,AI assisted ethics,Ethics and Information Technology,10.1007/s10676-016-9400-6,Springer,2016-06-01,2016-05-05,"The growing number of ‘smart’ instruments, those equipped with AI, has raised concerns because these instruments make autonomous decisions; that is, they act beyond the guidelines provided them by programmers. Hence, the question the makers and users of smart instrument (e.g., driver-less cars) face is how to ensure that these instruments will not engage in unethical conduct (not to be conflated with illegal conduct). The article suggests that to proceed we need a new kind of AI program—oversight programs—that will monitor, audit, and hold operational AI programs accountable.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10676-016-9400-6,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-34111-8_17,Neural Network-POMDP-Based Traffic Sign Classification Under Weather Conditions,Advances in Artificial Intelligence,10.1007/978-3-319-34111-8_17,Springer,2016-01-01,2016-05-13,"Despite their initial success in operating autonomously, self-driving cars are still unable to navigate under severe weather conditions. In the proposed system, a multi-layer perceptron (MLP) performs initial traffic sign classification. The classification is input as an observation into a partially observable Markov decision process (POMDP) in order to determine whether taking another picture of the sign, or accepting the classification determined by the MLP is the more optimal action. The synergistic combination of the MLP with the POMDP was shown to have a greater functionality than the sum of the MLP and POMDP operating in isolation. The results demonstrate the MLP-POMDP system is capable of training faster and more accurately classifying traffic sign images obscured by fog than a MLP. With further development of this model, one of the greatest shortcomings of autonomous driving may be overcome by accurately classifying signs despite obstruction by weather.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-34111-8_17,springer
Article,doi:10.1007/s10677-015-9563-y,"Autonomous Machines, Moral Judgment, and Acting for the Right Reasons",Ethical Theory and Moral Practice,10.1007/s10677-015-9563-y,Springer,2015-08-01,2015-01-30,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10677-015-9563-y,springer
Article,doi:10.1007/s10115-014-0754-y,Online data-driven anomaly detection in autonomous robots,Knowledge and Information Systems,10.1007/s10115-014-0754-y,Springer,2015-06-01,2014-05-21,"The use of autonomous robots is appealing for tasks, which are dangerous to humans. Autonomous robots might fail to perform their tasks since they are susceptible to varied sorts of faults such as point and contextual faults. Not all faults can be known in advance, and hence, anomaly detection is required. In this paper, we present an online data-driven anomaly detection approach ( ODDAD ) for autonomous robots. ODDAD is suitable for the dynamic nature of autonomous robots since it declares a fault based only on data collected online. In addition, it is unsupervised, model free and domain independent. ODDAD proceeds in three steps: data filtering, attributes grouping based on dependency between attributes and outliers detection for each group. Above a calculated threshold, an anomaly is declared. We empirically evaluate ODDAD in different domains: commercial unmanned aerial vehicles (UAVs), a vacuum-cleaning robot, a high-fidelity flight simulator and an electrical power system of a spacecraft. We show the significance and impact of each component of ODDAD . By comparing ODDAD to other state-of-the-art competing anomaly detection algorithms, we show its advantages.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10115-014-0754-y,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-19719-7_29,Adaptive Neural Control-Oriented Models of Unmanned Aerial Vehicles,10th International Conference on Soft Computing Models in Industrial and Environmental Applications,10.1007/978-3-319-19719-7_29,Springer,2015-01-01,2015-05-27,"From real input/output data, different models of an unmanned aerial vehicle are obtained by applying adaptive neural networks. These models are control-oriented; their main objective is to help us to design, implement and simulate different intelligent controllers and to test them on real systems. The influence of the selected training data on the final model is also discussed. They have been compared to off-line learning neural models with satisfactory results in terms of accuracy and computational cost.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-19719-7_29,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-24069-5_6,Combining Machine Learning and Multi-agent Approach for Controlling Traffic at Intersections,Computational Collective Intelligence,10.1007/978-3-319-24069-5_6,Springer,2015-01-01,2015-10-24,"Increasing volume of traffic in urban areas causes great costs and has negative effect on citizens’ life and health. The main cause of decreasing traffic fluency is intersections. Many methods for increasing bandwidth of junctions exist, but they are still insufficient. At the same time intelligent, autonomous cars are being created, what opens up new possibilities for controlling traffic at intersections. In this article a new approach for crossing an isolated junction is proposed - cars are given total autonomy and to avoid collisions they have to change speed. Several methods for adjusting speed based on machine learning (ML) are described, including new methods combining different ML algorithms (hybrid methods). The approach and methods were tested using a specially designed platform MABICS. Conducted experiments revealed some deficiencies of the methods - ideas for addressing them are proposed. Results of experiments made it possible to verify the proposed idea as promising.",http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-319-24069-5_6,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-20294-5_70,ROBOG Autonomously Navigating Outdoor Robo-Guide,"Swarm, Evolutionary, and Memetic Computing",10.1007/978-3-319-20294-5_70,Springer,2015-01-01,2015-07-16,ROBO G : The Robo-Guide is an autonomously navigating vehicle capable of learning the navigational directions of a locality by using Artificial Neural Networks. The main task of ROBO G is to guide people from one location to any other location in a trained region. The prime feature of ROBO G is its simplicity of implementation and working. The map information is learned by Artificial Neural Network using the proposed concept of branch and node. The Multi-Layered Perceptron is trained using the standard Error Back Propagation Algorithm. Road Detection & Tracking and Destination Identification are employed to achieve autonomous navigation. All the Image Processing techniques used are computationally inexpensive. The ROBO G is tested successfully in the outdoor environment for autonomous navigation and due to the simplicity in implementation it can be easily trained for any region.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-20294-5_70,springer
Article,doi:10.1007/s00521-012-1242-5,Intelligent control system design for UAV using a recurrent wavelet neural network,Neural Computing and Applications,10.1007/s00521-012-1242-5,Springer,2014-02-01,2012-11-07,"This paper aims to propose an efficient control algorithm for the unmanned aerial vehicle (UAV) motion control. An intelligent control system is proposed by using a recurrent wavelet neural network (RWNN). The developed RWNN is used to mimic an ideal controller. Moreover, based on sliding-mode approach, the adaptive tuning laws of RWNN can be derived. Then, the developed RWNN control system is applied to an UAV motion control for achieving desired trajectory tracking. From the simulation results, the control scheme has been shown to achieve favorable control performance for the UAV motion control even it is subjected to control effort deterioration and crosswind disturbance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-012-1242-5,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-07596-9_8,UAVs Applied to the Counting and Monitoring of Animals,Ambient Intelligence - Software and Applications,10.1007/978-3-319-07596-9_8,Springer,2014-01-01,,The advantages of intelligent approaches such as the conjunction of artificial vision and the use of Unmanned Aerial Vehicles (UAVs) have been recently emerging. This paper presents a focused on obtaining scans of large areas of livestock system. Counting and monitoring of animal species can be performed with video recordings taken from UAVs. Moreover the system keeps track of the number of animals detected by analyzing the images taken with the UAVs cameras. Several tests have been performed to evaluate this system and preliminary results and the conclusions are presented in this paper.,http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-319-07596-9_8,springer
Chapter ConferencePaper,doi:10.1007/978-3-319-08087-1_4,Design of Real-Time Transition from Driving Assistance to Automation Function: Bayesian Artificial Intelligence Approach,Advanced Microsystems for Automotive Applications 2014,10.1007/978-3-319-08087-1_4,Springer,2014-01-01,,"Forecasts of automation in driving suggest that wide spread market penetration of fully autonomous vehicles will be decades away and that before such vehicles will gain acceptance by all stake holders, there will be a need for driving assistance in key driving tasks, supplemented by automated active safety capability. This paper advances a Bayesian Artificial Intelligence model for the design of real time transition from assisted driving to automated driving under conditions of high probability of a collision if no action is taken to avoid the collision. Systems can be designed to feature collision warnings as well as automated active safety capabilities. In addition to the high level architecture of the Bayesian transition model, example scenarios illustrate the function of the real-time transition model.",http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-319-08087-1_4,springer
Article,doi:10.1186/2193-1801-2-188,Neuro-fuzzy controller to navigate an unmanned vehicle,SpringerPlus,10.1186/2193-1801-2-188,Springer,2013-04-27,2013-04-27,"A Neuro-fuzzy control method for an Unmanned Vehicle (UV) simulation is described. The objective is guiding an autonomous vehicle to a desired destination along a desired path in an environment characterized by a terrain and a set of distinct objects, such as obstacles like donkey traffic lights and cars circulating in the trajectory. The autonomous navigate ability and road following precision are mainly influenced by its control strategy and real-time control performance. Fuzzy Logic Controller can very well describe the desired system behavior with simple “if-then” relations owing the designer to derive “if-then” rules manually by trial and error. On the other hand, Neural Networks perform function approximation of a system but cannot interpret the solution obtained neither check if its solution is plausible. The two approaches are complementary. Combining them, Neural Networks will allow learning capability while Fuzzy-Logic will bring knowledge representation (Neuro-Fuzzy). In this paper, an artificial neural network fuzzy inference system (ANFIS) controller is described and implemented to navigate the autonomous vehicle. Results show several improvements in the control system adjusted by neuro-fuzzy techniques in comparison to the previous methods like Artificial Neural Network (ANN).",https://www.biomedcentral.com/openurl?doi=10.1186/2193-1801-2-188,springer
Article,doi:10.1007/s12239-013-0030-2,Neural-network multiple models filter (NMM)-based position estimation system for autonomous vehicles,International Journal of Automotive Technology,10.1007/s12239-013-0030-2,Springer,2013-04-01,2013-03-28,"A highly accurate and reliable vehicle position estimation system is an important component of an autonomous driving system. In generally, a global positioning system (GPS) receiver is employed for the vehicle position estimation of autonomous vehicles. However, a stand-alone GPS does not always provide accurate and reliable information of the vehicle position due to frequent GPS blockages and multipath errors. In order to overcome these problems, a sensor fusion scheme that combines the data from the GPS receiver and several on-board sensors has been studied. In previous researches, a single model filter-based sensor fusion algorithm was used to integrate information from the GPS and on-board sensors. However, an estimate obtained from a single model is difficult to cover the various driving environments, including urban areas, off-road areas, and highways. Thus, a multiple models filter (MMF) has been introduced to address this limitation by adapting multiple models to a wide range of driving conditions. An adaptation of the multiple model is achieved through the use of the model probability. The MMF combines several vehicle models using the model probabilities, which indicate the suitability of the current driving condition. In this paper, we propose a vehicle position estimation algorithm for an autonomous vehicle that is based on a neural network (NN)-based MMF. The model probabilities are determined through the NN. The proposed position estimation system was evaluated through simulations and experiments. The experimental results show that the proposed position estimation algorithm is suitable for application in an autonomous driving system over a wide range of driving conditions.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s12239-013-0030-2,springer
Chapter,doi:10.1007/978-3-642-22619-9_7,Neural Network Based Lane Change Trajectory Prediction in Autonomous Vehicles,Transactions on Computational Science XIII,10.1007/978-3-642-22619-9_7,Springer,2011-01-01,,"During a lane change, vehicle collision warning systems detect the likelihood of collision and time to collision to warn vehicles of an imminent collision. In autonomous systems, a vehicle utilizes data obtained by its own sensors to predict future state of traffic. The data from on board sensors are limited by line of sight, measurement noise and motion parameters of the vehicle which affect the accuracy of prediction. Alternatively, in cooperative driving, vehicles transmit their parameters continuously. This is also beset by communication delays and message loss. To avoid these limitations, a vehicle should estimate its future state and broadcast it to others vehicles in the neighborhood. This necessitates vehicles to predict their future trajectories based entirely on its past. Since, low cost global positioning systems are becoming an integral part of vehicles; a vehicle knows its own position. This can be utilized by the vehicle for prediction of its future trajectory. In this paper, the effectiveness of lane change trajectory prediction on the basis of past positions is studied. The lane change trajectory of a vehicle is modeled as a time series and back propagation neural network is trained using real field data and its efficacy for short range and long range prediction is benchmarked. Simulation results using NGSIM data indicate that future lane change trajectory cannot be predicted with sufficient accuracy. The most important reason seemed to be the influence of other neighboring vehicles on the trajectory on the lane changing vehicle in addition to noise and complex dependence of future on the past values. The results also indicate that a vehicle changes its motion parameters during the entire lane change process. This confirms the active intervention of the driver in adjusting the trajectory on the basis of his assessment of the future state of its surrounding vehicles and entails the consideration of the state of surrounding vehicle for accurate prediction.",http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-22619-9_7,springer
Article,doi:10.1007/s10846-008-9287-5,An Adaptable Oscillator-Based Controller for Autonomous Robots,Journal of Intelligent and Robotic Systems,10.1007/s10846-008-9287-5,Springer,2009-05-01,2008-10-07,"This paper proposes a unique oscillator-based robot controller with learning abilities to effectively guide a team of robots operating in uncertain environments. To verify this, we designed four separate controllers and compared their performance in a series of tests in several different environments. The experiments used a team of three robots to explore arenas with variable lighting and different obstacle patterns, with a goal of having the team as a whole absorb as much light as possible. The four controllers were: a reactive controller, an oscillator with fixed parameters, an oscillator whose parameters changed based on the pattern of sensor information received, and an oscillator-based controller that used reinforcement learning. Experiments confirmed that the proposed method outperforms the others in all environments tested.",http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-008-9287-5,springer
Chapter ConferencePaper,doi:10.1007/978-3-642-01507-6_101,Neural Network Algorithm for Installation Error Identification Based on Bearing-only Target Motion Analyses,Advances in Neural Networks – ISNN 2009,10.1007/978-3-642-01507-6_101,Springer,2009-01-01,,"It is quite strict with the degree of installation precision of photo-electricity device (PED) carried by unmanned aerial vehicle (UAV) when conducting bearing-only target motion analyses (BTMA), because of the existence of the installation error of PED, the precision of target location is bound to be affected. In order to solve this problem mentioned above, a neural network algorithm for installation error identification based on BTMA is put forward in this paper, consulting the target surveillance technology of PED to identify the installation error thought neural network algorithm, which is worthy to be put into practical applications.",http://link.springer.com/openurl/pdf?id=doi:10.1007/978-3-642-01507-6_101,springer
Article,doi:10.1007/s11633-007-0071-y,Neural network based feedback linearization control of an unmanned aerial vehicle,International Journal of Automation and Computing,10.1007/s11633-007-0071-y,Springer,2007-01-01,,This paper presents a flight control design for an unmanned aerial vehicle (UAV) using a nonlinear autoregressive moving average (NARMA-L2) neural network based feedback linearization and output redefinition technique. The UAV investigated is non-minimum phase. The output redefinition technique is used in such a way that the resulting system to be inverted is a minimum phase system. The NARMA-L2 neural network is trained off-line for forward dynamics of the UAV model with redefined output and is then inverted to force the real output to approximately track a command input. Simulation results show that the proposed approaches have good performance.,http://link.springer.com/openurl/pdf?id=doi:10.1007/s11633-007-0071-y,springer
Chapter ConferencePaper,doi:10.1007/11510888_40,Autonomous Vehicle Steering Based on Evaluative Feedback by Reinforcement Learning,Machine Learning and Data Mining in Pattern Recognition,10.1007/11510888_40,Springer,2005-01-01,,"Steering an autonomous vehicle requires the permanent adaptation of behavior in relation to the various situations the vehicle is in. This paper describes a research which implements such adaptation and optimization based on Reinforcement Learning (RL) which in detail purely learns from evaluative feedback in contrast to instructive feedback. Convergence of the learning process has been achieved at various experimental results revealing the impact of the different RL parameters. While using RL for autonomous steering is in itself already a novelty, additional attention has been given to new proposals for post-processing and interpreting the experimental data.",http://link.springer.com/openurl/pdf?id=doi:10.1007/11510888_40,springer
Article,doi:10.1023/A:1014394117908,Soft Computing Based Pattern Classifiers for the Obstacle Avoidance Behavior of Intelligent Autonomous Vehicles (IAV),Applied Intelligence,10.1023/A:1014394117908,Springer,2002-05-01,,"To ensure more autonomy and intelligence with real-time processing capabilities for the obstacle avoidance behavior of Intelligent Autonomous Vehicles (IAV), the use of soft computing is necessary to bring this behavior near to that of humans in the recognition, learning, adaptation, generalization, reasoning and decision-making, and action. In this paper, pattern classifiers of spatial obstacle avoidance situations using Neural Networks (NN), Fuzzy Logic (FL), Genetic Algorithms (GA) and Adaptive Resonance Theory (ART) individually or in combination are suggested. These classifiers are based on supervised learning and adaptation paradigms as Gradient Back-Propagation (GBP), FL, GA and Simplified Fuzzy ArtMap (SFAM) resulting in NN/GBP and FL as Intelligent Systems (IS) and in NN/GA, NN/GA-GBP, NN-FL/GBP and NN-FL-ART/SFAM as Hybrid Intelligent Systems (HIS). Afterwards, a synthesis of the suggested pattern classifiers is presented where their results and performances are discussed as well as the Field Programmable Gate Array (FPGA) architectures, characterized by their high flexibility and compactness, for their implementation.",http://link.springer.com/openurl/pdf?id=doi:10.1023/A:1014394117908,springer
Article,doi:10.1023/A:1008216400353,Neural Navigation Approach for Intelligent Autonomous Vehicles (IAV) in Partially Structured Environments,Applied Intelligence,10.1023/A:1008216400353,Springer,1998-05-01,,"The use of Neural Networks (NN) is necessary to bring the behavior of Intelligent Autonomous Vehicles (IAV) near the human one in recognition, learning, decision-making, and action. First, current navigation approaches based on NN are discussed. Indeed, these current approaches remedy insufficiencies of classical approaches related to real-time , autonomy , and intelligence . Second, a neural navigation approach essentially based on pattern classification to acquire target localization and obstacle avoidance behaviors is suggested. This approach must provide vehicles with capability, after supervised Gradient Backpropagation learning, to recognize both six (06) target location and thirty (30) obstacle avoidance situations using NN1 and NN2 classifiers , respectively. Afterwards, the decision-making and action consist of two association stages, carried out by reinforcement Trial and Error learning, and their coordination using a NN3. Then, NN3 allows to decide among five (05) actions (move towards 30°, move towards 60°, move towards 90°, move towards 120°, and move towards 150°). Third, simulation results which display the ability of the neural approach to provide IAV with capability to intelligently navigate in partially structured environments are presented. Finally, a discussion dealing with the suggested approach and how it relates to some other works is given.",http://link.springer.com/openurl/pdf?id=doi:10.1023/A:1008216400353,springer
Article,doi:10.1007/BF00426025,A reinforcement learning approach based on the fuzzy min-max neural network,Neural Processing Letters,10.1007/BF00426025,Springer,1996-12-01,,The fuzzy min-max neural network constitutes a neural architecture that is based on hyperbox fuzzy sets and can be incrementally trained by appropriately adjusting the number of hyperboxes and their corresponding volumes. Two versions have been proposed: for supervised and unsupervised learning. In this paper a modified approach is presented that is appropriate for reinforcement learning problems with discrete action space and is applied to the difficult task of autonomous vehicle navigation when no a priori knowledge of the enivronment is available. Experimental results indicate that the proposed reinforcement learning network exhibits superior learning behavior compared to conventional reinforcement schemes.,http://link.springer.com/openurl/pdf?id=doi:10.1007/BF00426025,springer
