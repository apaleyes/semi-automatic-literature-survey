doi,type,publication,publisher,publication_date,database,title,url,abstract,domain
10.1109/TITS.2019.2962338,filtered,IEEE Transactions on Intelligent Transportation Systems,IEEE,2021-02-01 00:00:00,ieeexplore,A Survey of Deep Learning Applications to Autonomous Vehicle Control,https://ieeexplore.ieee.org/document/8951131/,"Designing a controller for autonomous vehicles capable of providing adequate performance in all driving scenarios is challenging due to the highly complex environment and inability to test the system in the wide variety of scenarios which it may encounter after deployment. However, deep learning methods have shown great promise in not only providing excellent performance for complex and non-linear control problems, but also in generalising previously learned rules to new scenarios. For these reasons, the use of deep learning for vehicle control is becoming increasingly popular. Although important advancements have been achieved in this field, these works have not been fully summarised. This paper surveys a wide range of research works reported in the literature which aim to control a vehicle through deep learning methods. Although there exists overlap between control and perception, the focus of this paper is on vehicle control, rather than the wider perception problem which includes tasks such as semantic segmentation and object detection. The paper identifies the strengths and limitations of available deep learning methods through comparative analysis and discusses the research challenges in terms of computation, architecture selection, goal specification, generalisation, verification and validation, as well as safety. Overall, this survey brings timely and topical information to a rapidly evolving field relevant to intelligent transportation systems.",autonomous vehicle
10.1109/DSN-W.2018.00027,filtered,2018 48th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W),IEEE,2018-06-28 00:00:00,ieeexplore,AVFI: Fault Injection for Autonomous Vehicles,https://ieeexplore.ieee.org/document/8416212/,"Autonomous vehicle (AV) technology is rapidly becoming a reality on U.S. roads, offering the promise of improvements in traffic management, safety, and the comfort and efficiency of vehicular travel. With this increasing popularity and ubiquitous deployment, resilience has become a critical requirement for public acceptance and adoption. Recent studies into the resilience of AVs have shown that though the AV systems are improving over time, they have not reached human levels of automation. Prior work in this area has studied the safety and resilience of individual components of the AV system (e.g., testing of neural networks powering the perception function). However, methods for holistic end-to-end resilience assessment of AV systems are still non-existent.",autonomous vehicle
10.1109/GlobalSIP45357.2019.8969382,filtered,2019 IEEE Global Conference on Signal and Information Processing (GlobalSIP),IEEE,2019-11-14 00:00:00,ieeexplore,Machine Learning-Based Roadside Vehicular Traffic Localization via Opportunistic Wireless Sensing,https://ieeexplore.ieee.org/document/8969382/,"Comprehensive Situational Awareness (SA) in mixed traffic environments (i.e., both autonomous and human-operated platforms) is a critical requirement in addressing some of the challenges that hinder the deployment of autonomous vehicle (AV) systems onto roadways. In this paper, a novel framework that leverages machine learning techniques for utilizing Signals of Opportunity (SoO) for robust localization of all vehicles operating along a stretch of roadway is presented. By making use of ubiquitous wireless emissions from vehicles, the presented approach performs vehicle localization without any active participation/assistance from vehicles thus making it a suitable candidate for SA in mixed traffic environments. Our simulation results show that given the road shape and number of vehicles present, observed 2D localization estimates generated by an arbitrary algorithm whose error is described by a Gaussian bivariate distribution with 10 meters covariance yields unbiased vehicle centroid estimates with less than one meter mean squared error by eight Kalman Filter (KF) iterations. A set of KFs for each vehicle are used to leverage the filtering of multiple estimates per vehicle per filter step to reduce measurement noise by averaging, while a clustering algorithm performs the dual role of forming KF set priors and classifying location estimates to their correct vehicle.",autonomous vehicle
10.1109/ITSC.2019.8917085,filtered,2019 IEEE Intelligent Transportation Systems Conference (ITSC),IEEE,2019-10-30 00:00:00,ieeexplore,Machine learning method to ensure robust decision-making of AVs,https://ieeexplore.ieee.org/document/8917085/,"Replacing the human driver to perform the Dynamic Driving Task (DDT)[1] will require perception, complex analysis and assessment of traffic situation. The path leading to success the deployment of fully Autonomous Vehicle (AV) depends on the resolution of a lot of challenges. Both the safety and the security aspects of AV constitute the core of regulatory compliance and technical research. The Autonomous Driving System (ADS) should be designed to ensure a safe manoeuvre and a stable behaviour despite the technological limitations, the uncertainties and hazards which characterize the real traffic conditions. In fully Autonomous Driving situation, detecting all relevant objects and agents should be sufficient to generate a warning, however the ADS requires further complex data analysis steps to quantify and improve the safety of decision making. This paper aims to improve the robustness of decision-making in order to mimic human-like decision ability. The approach is based on machine learning to identify the criticality of the dynamic situation and enabling ADS to make appropriate decision and fulfil safe manoeuvre.",autonomous vehicle
10.1109/ITSC48978.2021.9564712,filtered,2021 IEEE International Intelligent Transportation Systems Conference (ITSC),IEEE,2021-09-22 00:00:00,ieeexplore,OdoViz: A 3D Odometry Visualization and Processing Tool,https://ieeexplore.ieee.org/document/9564712/,"OdoViz is a reactive web-based tool for 3D visualization and processing of autonomous vehicle datasets designed to support common tasks in visual place recognition research. The system includes functionality for loading, inspecting, visualizing, and processing GPS/INS poses, point clouds and camera images. It supports a number of commonly used driving datasets and can be adapted to load custom datasets with minimal effort. OdoViz's design consists of a slim server to serve the datasets coupled with a rich client frontend. This design supports multiple deployment configurations including single user stand-alone installations, research group installations serving datasets internally across a lab, or publicly accessible web-frontends for providing online interfaces for exploring and interacting with datasets. The tool allows viewing complete vehicle trajectories traversed at multiple different time periods simultaneously, facilitating tasks such as sub-sampling, comparing and finding pose correspondences both across and within sequences. This significantly reduces the effort required in creating subsets of data from existing datasets for machine learning tasks. Further to the above, the system also supports adding custom extensions and plugins to extend the capabilities of the software for other potential data management, visualization and processing tasks. The platform has been open-sourced to promote its use and encourage further contributions from the research community.",autonomous vehicle
10.1109/IROS45743.2020.9341738,filtered,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),IEEE,2021-01-24 00:00:00,ieeexplore,Probabilistic Semantic Mapping for Urban Autonomous Driving Applications,https://ieeexplore.ieee.org/document/9341738/,"Recent advancements in statistical learning and computational abilities have enabled autonomous vehicle technology to develop at a much faster rate. While many of the architectures previously introduced are capable of operating under highly dynamic environments, many of these are constrained to smaller-scale deployments, require constant maintenance due to the associated scalability cost with high-definition (HD) maps, and involve tedious manual labeling. As an attempt to tackle this problem, we propose to fuse image and pre-built point cloud map information to perform automatic and accurate labeling of static landmarks such as roads, sidewalks, crosswalks, and lanes. The method performs semantic segmentation on 2D images, associates the semantic labels with point cloud maps to accurately localize them in the world, and leverages the confusion matrix formulation to construct a probabilistic semantic map in bird's eye view from semantic point clouds. Experiments from data collected in an urban environment show that this model is able to predict most road features and can be extended for automatically incorporating road features into HD maps with potential future work directions.",autonomous vehicle
10.1109/CAC51589.2020.9326504,filtered,2020 Chinese Automation Congress (CAC),IEEE,2020-11-08 00:00:00,ieeexplore,The Multi-sensor Fusion Automatic Driving Test Scene Algorithm based on Cloud Platform,https://ieeexplore.ieee.org/document/9326504/,"The production of autonomous vehicles needs to accumulate a large amount of mileage experience while the researching, development and testing methods of the traditional vehicle terminals cannot meet the requirements. The industry generally adopts the new Cloud Platform to research and develop iterative mode, which collects massive road environment data through the test fleet, and conducts model and algorithm development and simulation verification, so as to meet the product safety standards. Based on collaboration capability of the Cloud, Pipe and Terminal, this paper supports to carry out data collection, storage, processing and analysis through high-performance basic platform, application platform and AI development platform and other methods. Through cloud training and deployment of the autonomous vehicle , it is completed for scenario development to improve model training speed and development efficiency.",autonomous vehicle
10.1109/IVS.1994.639471,filtered,Proceedings of the Intelligent Vehicles '94 Symposium,IEEE,1994-10-26 00:00:00,ieeexplore,The development of a fully autonomous ground vehicle (FAGV),https://ieeexplore.ieee.org/document/639471/,"As a first step toward the creation of a fully autonomous vehicle that operates in a real world environment, we are currently developing a prototype autonomous ground vehicle (AGV) for use in factories and other industrial/business sites based on behavior-based artificial intelligence (AI) control. This flexible and fully autonomous AGV (FAGV) is expected to operate efficiently in a normal industrial environment without any external guidance. The crucial technique employed is a non-Cartesian way of organizing software agents for the creation of a highly responsive control program. The resulting software is considerably reduced in size. Through numerous experiments using mobile robots we confirmed that these new control programs excel in functionality, efficiency, flexibility and robustness. The second key technique in the planning stage is evolutionary computation, of which genetic algorithms are a principal technique. An online, real-time evolution of the control program will be incorporated in later phases of the project to make FAGVs adaptable to any given operational environment after deployment. The first prototype FAGV has an active vision and behaviour-based control system.",autonomous vehicle
10.1109/CVPR42600.2020.01164,filtered,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),IEEE,2020-06-19 00:00:00,ieeexplore,nuScenes: A Multimodal Dataset for Autonomous Driving,https://ieeexplore.ieee.org/document/9156412/,"Robust detection and tracking of objects is crucial for the deployment of autonomous vehicle technology. Image based benchmark datasets have driven development in computer vision tasks such as object detection, tracking and segmentation of agents in the environment. Most autonomous vehicles, however, carry a combination of cameras and range sensors such as lidar and radar. As machine learning based methods for detection and tracking become more prevalent, there is a need to train and evaluate such methods on datasets containing range sensor data along with images. In this work we present nuTonomy scenes (nuScenes), the first dataset to carry the full autonomous vehicle sensor suite: 6 cameras, 5 radars and 1 lidar, all with full 360 degree field of view. nuScenes comprises 1000 scenes, each 20s long and fully annotated with 3D bounding boxes for 23 classes and 8 attributes. It has 7x as many annotations and 100x as many images as the pioneering KITTI dataset. We define novel 3D detection and tracking metrics. We also provide careful dataset analysis as well as baselines for lidar and image based detection and tracking. Data, development kit and more information are available online.",autonomous vehicle
10.1109/ISOCC50952.2020.9333071,filtered,2020 International SoC Design Conference (ISOCC),IEEE,2020-10-24 00:00:00,ieeexplore,A Distance-Aware Technique for Object Detection Used in Self-Driving Vehicles,https://ieeexplore.ieee.org/document/9333071/,"Object detection obtains huge improvement after adopting deep learning technique. However, deep learning technique requires extremely high computation complexity and heavy DRAM (Dynamic Random Access Memory) bandwidth requirements, which blocks the deployment over various kinds of platforms. This paper provides a distance-aware technique for object detection that can adjust the required computation complexity and DRAM access amount according to several different searching distances. According to our analysis, the perception system can save up to 34.2% and 21.5% of computation complexity and DRAM access amount, respectively, for detecting near field objects when compared to the full range detection, without sacrificing any detection accuracy.",autonomous vehicle
10.1109/AITEST52744.2021.00032,filtered,2021 IEEE International Conference on Artificial Intelligence Testing (AITest),IEEE,2021-08-26 00:00:00,ieeexplore,Critical and Challenging Scenario Generation based on Automatic Action Behavior Sequence Optimization: 2021 IEEE Autonomous Driving AI Test Challenge Group 108,https://ieeexplore.ieee.org/document/9564386/,"Assuring the safety of automated and autonomous driving functions is crucial for a safe deployment of self-driving vehicles on public roads. This includes the need for automated virtual testing methods and exhaustive search for critical scenarios that potentially reveal faults in the driving feature under test. In the past, researches have demonstrated the effectiveness of search-based testing to create situations that result in unintended behavior of the driving feature. In this paper, we contribute to this field of research by developing a method for automated generation of diverse critical scenarios based on a search algorithm that iterative optimizes behavior action sequences of the surrounding traffic participants towards critical situations. Utilizing the provided LG SVL Simulator pipeline, our method effectively generated both critical and challenging test scenarios that either revealed faulty behavior of the ego-vehicle (crash or near-crash) or showed extraordinary behavior of the surrounding traffic participants (e.g. approaching traffic on wrong lane).",autonomous vehicle
10.1109/DFT.2019.8875314,filtered,2019 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT),IEEE,2019-10-04 00:00:00,ieeexplore,Efficient Error-Tolerant Quantized Neural Network Accelerators,https://ieeexplore.ieee.org/document/8875314/,"Neural Networks are currently one of the most widely deployed machine learning algorithms. In particular, Convolutional Neural Networks (CNNs), are gaining popularity and are evaluated for deployment in safety critical applications such as self driving vehicles. Modern CNNs feature enormous memory bandwidth and high computational needs, challenging existing hardware platforms to meet throughput, latency and power requirements. Functional safety and error tolerance need to be considered as additional requirement in safety critical systems. In general, fault tolerant operation can be achieved by adding redundancy to the system, which is further exacerbating the computational demands. Furthermore, the question arises whether pruning and quantization methods for performance scaling turn out to be counterproductive with regards to fail safety requirements. In this work we present a methodology to evaluate the impact of permanent faults affecting Quantized Neural Networks (QNNs) and how to effectively decrease their effects in hardware accelerators. We use FPGA-based hardware accelerated error injection, in order to enable the fast evaluation. A detailed analysis is presented showing that QNNs containing convolutional layers are by far not as robust to faults as commonly believed and can lead to accuracy drops of up to 10%. To circumvent that, we propose two different methods to increase their robustness: 1) selective channel replication which adds significantly less redundancy than used by the common triple modular redundancy and 2) a fault-aware scheduling of processing elements for folded implementations.",autonomous vehicle
10.1109/MECO.2019.8760130,filtered,2019 8th Mediterranean Conference on Embedded Computing (MECO),IEEE,2019-06-14 00:00:00,ieeexplore,Facilitating Near Real Time Analytics on the Edge,https://ieeexplore.ieee.org/document/8760130/,"Internet of Things (IoT) is revolutionizing the way how information is processed and stored. Due to latency sensitive applications and huge amounts of data produced at the edge of the network, more and more data is processed where it is produced - namely on the edge. This development results in completely new network topologies where besides massive data centers we experience growing amount of so called micro data centers on the edge of the network. However, increasing complexity of multiple data centers necessary to execute an application represents a new challenge for the deployment and runtime operation of large scale applications like those in the area of smart cities, self-driving vehicles and tele medicine. The challenge thereby is to deploy application in a way to satisfy user requirements in form of different Quality of Service parameters (e.g., latency) but at the same time minimize energy consumption necessary to execute the application. In this talk we discuss several research challenges that arise when deploying near real time analytics on the edge of the network.",autonomous vehicle
10.1109/ICSE43902.2021.00044,filtered,2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE),IEEE,2021-05-30 00:00:00,ieeexplore,Self-Checking Deep Neural Networks in Deployment,https://ieeexplore.ieee.org/document/9402003/,"The widespread adoption of Deep Neural Networks (DNNs) in important domains raises questions about the trustworthiness of DNN outputs. Even a highly accurate DNN will make mistakes some of the time, and in settings like self-driving vehicles these mistakes must be quickly detected and properly dealt with in deployment. Just as our community has developed effective techniques and mechanisms to monitor and check programmed components, we believe it is now necessary to do the same for DNNs. In this paper we present DNN self-checking as a process by which internal DNN layer features are used to check DNN predictions. We detail SelfChecker, a self-checking system that monitors DNN outputs and triggers an alarm if the internal layer features of the model are inconsistent with the final prediction. SelfChecker also provides advice in the form of an alternative prediction. We evaluated SelfChecker on four popular image datasets and three DNN models and found that SelfChecker triggers correct alarms on 60.56% of wrong DNN predictions, and false alarms on 2.04% of correct DNN predictions. This is a substantial improvement over prior work (SelfOracle, Dissector, and ConfidNet). In experiments with self-driving car scenarios, SelfChecker triggers more correct alarms than SelfOracle for two DNN models (DAVE-2 and Chauffeur) with comparable false alarms. Our implementation is available as open source.",autonomous vehicle
10.1109/OJITS.2020.3027146,filtered,IEEE Open Journal of Intelligent Transportation Systems,IEEE,2020-01-01 00:00:00,ieeexplore,A Plausibility-Based Fault Detection Method for High-Level Fusion Perception Systems,https://ieeexplore.ieee.org/document/9207739/,"Trustworthy environment perception is the fundamental basis for the safe deployment of automated agents such as self-driving vehicles or intelligent robots. The problem remains that such trust is notoriously difficult to guarantee in the presence of systematic faults, e.g., non-traceable errors caused by machine learning functions. One way to tackle this issue without making rather specific assumptions about the perception process is plausibility checking. Similar to the reasoning of human intuition, the final outcome of a complex black-box procedure is verified against given expectations of an object's behavior. In this article, we apply and evaluate collaborative, sensor-generic plausibility checking as a mean to detect empirical perception faults from their statistical fingerprints. Our real use case is next-generation automated driving that uses a roadside sensor infrastructure for perception augmentation, represented here by test scenarios at a German highway and a city intersection. The plausibilization analysis is integrated naturally in the object fusion process, and helps to diagnose known and possibly yet unknown faults in distributed sensing systems.",autonomous vehicle
10.1145/3180155.3180220,filtered,2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE),IEEE,2018-06-03 00:00:00,ieeexplore,DeepTest: Automated Testing of Deep-Neural-Network-Driven Autonomous Cars,https://ieeexplore.ieee.org/document/8453089/,"Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can drive without any human intervention. Most major manufacturers including Tesla, GM, Ford, BMW, and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California, Texas, and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads. However, despite their spectacular progress, DNNs, just like traditional software, often demonstrate incorrect or unexpected corner-case behaviors that can lead to potentially fatal collisions. Several such real-world accidents involving autonomous cars have already happened including one which resulted in a fatality. Most existing testing techniques for DNN-driven vehicles are heavily dependent on the manual collection of test data under different driving conditions which become prohibitively expensive as the number of test conditions increases. In this paper, we design, implement, and evaluate DeepTest, a systematic testing tool for automatically detecting erroneous behaviors of DNN-driven vehicles that can potentially lead to fatal crashes. First, our tool is designed to automatically generated test cases leveraging real-world changes in driving conditions like rain, fog, lighting conditions, etc. DeepTest systematically explore different parts of the DNN logic by generating test inputs that maximize the numbers of activated neurons. DeepTest found thousands of erroneous behaviors under different realistic driving conditions (e.g., blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in three top performing DNNs in the Udacity self-driving car challenge.",autonomous vehicle
10.1109/ICSSE52999.2021.9537944,filtered,2021 International Conference on System Science and Engineering (ICSSE),IEEE,2021-08-28 00:00:00,ieeexplore,Enhancement of Robustness in Object Detection Module for Advanced Driver Assistance Systems,https://ieeexplore.ieee.org/document/9537944/,"A unified system integrating a compact object detector and a surrounding environmental condition classifier for enhancing the robustness of object detection scheme in advanced driver assistance systems (ADAS) is proposed in this paper. ADAS are invented to improve traffic safety and effectiveness in autonomous driving systems where object detection plays an extremely important role. However, modern object detectors integrated into ADAS are still unstable due to high latency and the variation of the environmental contexts in the deployment phase. Our system is proposed to address the aforementioned problems. The proposed system includes two main components: (1) a compact one-stage object detector which is expected to be able to perform at a comparable accuracy compared to state-of-the-art object detectors, and (2) an environmental condition detector that helps to send a warning signal to the cloud in case the self-driving car needs human actions due to the significance of the situation. The empirical results prove the reliability and the scalability of the proposed system to realistic scenarios.",autonomous vehicle
10.1109/ISQED.2018.8357325,filtered,2018 19th International Symposium on Quality Electronic Design (ISQED),IEEE,2018-03-14 00:00:00,ieeexplore,Low cost and power CNN/deep learning solution for automated driving,https://ieeexplore.ieee.org/document/8357325/,"Automated driving functions, like highway driving and parking assist, are increasingly getting deployed in high-end cars with the ultimate goal of realizing self-driving car using Deep learning techniques like convolution neural network (CNN). For mass-market deployment, the embedded solution is required to address the right cost and performance envelope along with security and safety. In the case of automated driving, one of the key functionality is “finding drivable free space”, which is addressed using deep learning techniques like CNN. These CNN networks pose huge computing requirements in terms of hundreds of GOPS/TOPS (Giga or Tera operations per second), which seems beyond the capability of today's embedded SoC. This paper covers various techniques consisting of fixed-point conversion, sparse multiplication, fusing of layers and network pruning, for tailoring on the embedded solution. These techniques are implemented on the device by means of optimized Deep learning library for inference. The paper concludes by demonstrating the results of a CNN network running in real time on TI's TDA2X embedded platform producing a high-quality drivable space output for automated driving.",autonomous vehicle
10.1109/ISMVL.2017.49,filtered,2017 IEEE 47th International Symposium on Multiple-Valued Logic (ISMVL),IEEE,2017-05-24 00:00:00,ieeexplore,Deep Learning for Autonomous Vehicles,https://ieeexplore.ieee.org/document/7964981/,"Summary form only given. In this talk we discuss the latest developments in the art and science of autonomous driving. Deep Learning Networks have become indispensable in design and implementation of such systems. We will present the latest software and hardware tools for development and deployment of ever more computationally demanding DLNs used in self-driving cars. From DGX-1 supercomputer for training DLNs, to Drive PX 2, a scalable AI car computer platform for inference, and looking into the future, to the recently announced Xavier, an AI supercomputer on a chip for future autonomous vehicles, tools are now available for every part of a DLN lifecycle. We illustrate how the tools are being used already by showing some of the most recent results of Nvidia's own, end-to-end DLN for autonomous driving.",autonomous vehicle
10.1109/ITSC.2017.8317901,filtered,2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC),IEEE,2017-10-19 00:00:00,ieeexplore,Deep fully convolutional networks with random data augmentation for enhanced generalization in road detection,https://ieeexplore.ieee.org/document/8317901/,"In this paper, a Deep Learning system for accurate road detection is proposed using the ResNet-101 network with a fully convolutional architecture and multiple upscaling steps for image interpolation. It is demonstrated that significant generalization gains in the learning process are attained by randomly generating augmented training data using several geometric transformations and pixelwise changes, such as affine and perspective transformations, mirroring, image cropping, distortions, blur, noise, and color changes. In addition, this paper shows that the use of a 4-step upscaling strategy provides optimal learning results as compared to other similar techniques that perform data upscaling based on shallow layers with scarce representation of the scene data. The complete system is trained and tested on data from the KITTI benchmark and besides it is also tested on images recorded on the Campus of the University of Alcala (Spain). The improvement attained after performing data augmentation and conducting a number of training variants is really encouraging, showing the path to follow for enhanced learning generalization of road detection systems with a view to real deployment in self-driving cars.",autonomous vehicle
10.1109/IEMTRONICS52119.2021.9422512,filtered,"2021 IEEE International IOT, Electronics and Mechatronics Conference (IEMTRONICS)",IEEE,2021-04-24 00:00:00,ieeexplore,Deployment of Compressed MobileNet V3 on iMX RT 1060,https://ieeexplore.ieee.org/document/9422512/,"Deep Neural Networks (DNN) are prominent in most applications today. From self-driving cars, sentiment analysis, surveillance systems, and robotics, they have been used extensively. Among DNNs, Convolutional Neural Networks (CNN) have achieved massive success in computer vision applications as the human visual system inspires their architecture. However, striving to achieve higher accuracies, CNN complexity, parameters, and layers were increased, which led to a drastic surge in their size, making their deployment challenging. Over the years, many researchers have proposed various techniques to alleviate this issue-one of them being Design Space Exploration (DSE) to minimize size and computation with little compromise to accuracy. MobileNet V3 is one such architecture designed to achieve good accuracy while being mindful of resources. It produces an accuracy of 88.93% on CIFAR-10 with a size of 15.3MB. This paper further reduces its size to 2.3MB while boosting its accuracy to 89.13% using DSE techniques. It is then deployed into NXP's i.MX RT1060 Advanced Driver Assistance System (ADAS) platform.",autonomous vehicle
10.1109/BigData.2018.8622371,filtered,2018 IEEE International Conference on Big Data (Big Data),IEEE,2018-12-13 00:00:00,ieeexplore,Robustness of Compressed Convolutional Neural Networks,https://ieeexplore.ieee.org/document/8622371/,"Advancements in deep neural networks have revolutionized the way how we conduct our day-to-day activities ranging from how we unlock our phones to self-driving cars. Convolutional Neural Networks (CNN) play the principal role in learning high level feature representations from visual inputs. It is crucial to know how reliable those neural networks are as human lives can be at stake. Recent experiments on the robustness of CNNs show that they are highly susceptible to small adversarial perturbations. Due to the increasing popularity of mobile devices, there is a significant demand for CNN models which are smaller enough to run on a mobile device without sacrificing the accuracy. Although recent researches have been successful at achieving smaller models with comparable accuracy on standard image datasets, their robustness to adversarial attacks has not been studied. However, massive deployment of smaller models on millions of mobile devices stresses importance of their robustness. In this work, we study how robust such models are with respect to state-of-the-art compression techniques such as quantization. Our contributions are summarized as follows: (1) insights to achieve smaller and robust models (2) a compression framework which is adversarial-aware. Our findings reveal that compressed models are naturally more robust than compact models. This provides an incentive to perform compression rather than designing compact models. Additionally, the latter provides benefits of increased accuracy and higher compression rate, up to 90×.",autonomous vehicle
10.1109/THS.2017.7943477,filtered,2017 IEEE International Symposium on Technologies for Homeland Security (HST),IEEE,2017-04-26 00:00:00,ieeexplore,Securing wireless communications of connected vehicles with artificial intelligence,https://ieeexplore.ieee.org/document/7943477/,"This work applies artificial intelligence (AI) to secure wireless communications of Connected Vehicles. Vehicular Ad-hoc Network (VANET) facilitates exchange of safety messages for collision avoidance, leading to self-driving cars. An AI system continuously learns to augment its ability in discerning and recognizing its surroundings. Such ability plays a vital role in evaluating the authenticity and integrity of safety messages for cars driven by computers. Falsification of meter readings, disablement of brake function, and other unauthorized controls by spoofed messages injected into VANET emerge as security threats. Countermeasures must be considered at design stage, as opposed to afterthought patches, effectively against cyber-attacks. However, current standards oversubscribe security measures by validating every message circulating among Connected Vehicles, making VANET subject to denial-of-service (DoS) Attacks. This interdisciplinary research shows promising results by searching the pivot point to balance between message authentication and DoS prevention, making security measures practical for the real-world deployment of Connected Vehicles. Message authentication adopts Context-Adaptive Signature Verification strategy, applying AI filters to reduce both communication and computation overhead. Combining OMNET++, a data network simulator, and SUMO, a road traffic simulator, with Veins, an open source framework for VANET simulation, the study evaluates AI filters comparatively under various attacking scenarios. The results lead to an effective design choice of securing wireless communications for Connected Vehicles.",autonomous vehicle
10.1109/ISSRE.2019.00049,filtered,2019 IEEE 30th International Symposium on Software Reliability Engineering (ISSRE),IEEE,2019-10-31 00:00:00,ieeexplore,TamperNN: Efficient Tampering Detection of Deployed Neural Nets,https://ieeexplore.ieee.org/document/8987572/,"Neural networks are powering the deployment of embedded devices and Internet of Things. Applications range from personal assistants to critical ones such as self-driving cars. It has been shown recently that models obtained from neural nets can be trojaned; an attacker can then trigger an arbitrary model behavior facing crafted inputs. This has a critical impact on the security and reliability of those deployed devices. We introduce novel algorithms to detect the tampering with deployed models, classifiers in particular. In the remote interaction setup we consider, the proposed strategy is to identify markers of the model input space that are likely to change class if the model is attacked, allowing a user to detect a possible tampering. This setup makes our proposal compatible with a wide range of scenarios, such as embedded models, or models exposed through prediction APIs. We experiment those tampering detection algorithms on the canonical MNIST dataset, over three different types of neural nets, and facing five different attacks (trojaning, quantization, fine-tuning, compression and watermarking). We then validate over five large models (VGG16, VGG19, ResNet, MobileNet, DenseNet) with a state of the art dataset (VGGFace2), and report results demonstrating the possibility of an efficient detection of model tampering.",autonomous vehicle
10.1109/SSCI47803.2020.9308364,filtered,2020 IEEE Symposium Series on Computational Intelligence (SSCI),IEEE,2020-12-04 00:00:00,ieeexplore,Vision-based Vehicle Detection and Distance Estimation,https://ieeexplore.ieee.org/document/9308364/,"Real-time vehicle detection is one of the most important topics under the Autonomous Vehicles (AVs) research paradigm and traffic surveillance. Detecting vehicles and estimating their distances are essential to ensure that the vehicles can keep a safe distance and run safely on the roads. The technology can also be utilized to determine traffic flow and estimate vehicle speed. In this paper, we apply two different deep learning models and compare their performances in detecting vehicles such as cars and trucks for deployment on the self-driving cars to ensure road safety. Our models are based on YOLOv4 and Faster R-CNN which are efficient and accurate in object detection within a given distance. We also propose a vision-based distance estimation algorithm to estimate other vehicles' distances. In detecting vehicles within 100 meters, the two variations of our models, YOLOv4 and Faster R-CNN, achieved 99.16% and 95.47% mean precision, and 79.36% and 85.54% Fl-measure respectively on a two-way road. The detection speed is 68 fps and 14 fps for YOLOv4 and Faster R-CNN respectively.",autonomous vehicle
10.1109/JIOT.2019.2930459,filtered,IEEE Internet of Things Journal,IEEE,2019-12-01 00:00:00,ieeexplore,"A <inline-formula> <tex-math notation=""LaTeX"">${Q}$ </tex-math></inline-formula>-Learning Based Framework for Congested Link Identification",https://ieeexplore.ieee.org/document/8769959/,"Network congestion will result in significant performance degradation or even failures of many bandwidth-hungry Internet of Things (IoT) applications. Accurate and efficient congested link identification has become a foundational issue to IoT applications like self-driving cars, digital health, smart city, and so on. However, directly monitoring the massive number of interior links often introduces high operation cost or even is infeasible in practice, giving rise to indirect monitoring techniques like network Boolean tomography. Nevertheless, in many networks, the number of their interior links is larger than their end-to-end paths, making it very challenging for network Boolean tomography to find a determined solution. To resolve this issue, most of current methods try to utilize some prerequisites, such as the link congestion probabilities. While these probabilities might be hard or even unable to be obtained accurately in dynamical networks, limiting the practical deployment. In this paper, we are motivated to design a framework of congested link identification without any prerequisite or assumption. We first novelly model the congested link identification procedures as a Markov decision processes (MDPs), and then employ a reinforcement learning technology, i.e., Q-learning, to solve this MDP. The simulation results show that our proposed scheme can autonomously and efficiently explore the unknown network environment, and is able to achieve better adaptivity and correctness, without any prior knowledge comparing to existing methods.",autonomous vehicle
10.1109/CRV.2018.00024,filtered,2018 15th Conference on Computer and Robot Vision (CRV),IEEE,2018-05-10 00:00:00,ieeexplore,A Hierarchical Deep Architecture and Mini-batch Selection Method for Joint Traffic Sign and Light Detection,https://ieeexplore.ieee.org/document/8575742/,"Traffic light and sign detectors on autonomous cars are integral for road scene perception. The literature is abundant with deep learning networks that detect either lights or signs, not both, which makes them unsuitable for real-life deployment due to the limited graphics processing unit (GPU) memory and power available on embedded systems. The root cause of this issue is that no public dataset contains both traffic light and sign labels, which leads to difficulties in developing a joint detection framework. We present a deep hierarchical architecture in conjunction with a mini-batch proposal selection mechanism that allows a network to detect both traffic lights and signs from training on separate traffic light and sign datasets. Our method solves the overlapping issue where instances from one dataset are not labelled in the other dataset. We are the first to present a network that performs joint detection on traffic lights and signs. We measure our network on the Tsinghua-Tencent 100K benchmark for traffic sign detection and the Bosch Small Traffic Lights benchmark for traffic light detection and show it outperforms the existing Bosch Small Traffic light state-of-the-art method. We focus on autonomous car deployment and show our network is more suitable than others because of its low memory footprint and real-time image processing time. Qualitative results can be viewed at https://youtu.be/ YmogPzBXOw.",autonomous vehicle
10.1109/AICAI.2019.8701414,filtered,2019 Amity International Conference on Artificial Intelligence (AICAI),IEEE,2019-02-06 00:00:00,ieeexplore,Modeling and Deployment of an Autonomous Cart Pickup and Delivery System,https://ieeexplore.ieee.org/document/8701414/,"Our research provides a novel hardware/software autonomous car model that can be effectively deployed to carry out intelligent pickup and delivery missions. We develop a model of a Cooperative Autonomous Reactive Taxi System (CARTS) that contributes to solving the unsustainable urban traffic gridlock in large cities. Our model formulation is inspired by general the pickup/delivery problem (GPDP). Given dynamic stochastic variables that include a set of cars, a set of customers, a set of stations (e.g., bus stop), and a set of transport missions, devise autonomous intelligent carts capable of effectively carrying out these missions to satisfy the quality of service requirements and any associated constraints. Our model integrates novel capabilities, such as decentralized architecture, cooperative decision-making, autonomy, and intelligent navigation, as well as a transport requests logistics model. Our deployment prototype is a laboratory experimental set-up using autonomous robots and relevant infrastructure that demonstrate the feasibility of our pickup and delivery model. Analysis of collected data from the simulation and the physical implementation demonstrates the effectiveness of our model.",autonomous vehicle
10.1109/EMPDP.2019.8671589,filtered,"2019 27th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)",IEEE,2019-02-15 00:00:00,ieeexplore,Catalina: In-Storage Processing Acceleration for Scalable Big Data Analytics,https://ieeexplore.ieee.org/document/8671589/,"Cloud applications are increasingly playing a crucial role in big data analytics. New use cases such as autonomous cars and edge computing call for novel approaches mixing heterogeneous computing and machine learning. These applications typically process petabyte-scale datasets, therefore, requiring low-power and scalable storage providing low-latency and high-throughput data access. While data centers have been focusing on migrating from legacy HDDs and SATA SSDs by deploying high-throughput and low-latency NVMe SSDs, the data bottlenecks appear as capacity scales. One approach to tackle this problem is to enable processing to happen within the storage device -in-storage processing (ISP)- eliminating the need to move the data. In this paper, we investigated the deployment of storage units with embedded low-power application processors along with FPGA-based reconfigurable hardware accelerators to address both performance and energy efficiency. To this purpose, we developed a high-capacity solid-state drive (SSD) named Catalina equipped with a quad-core ARM A53 processor running a Linux operating system along with a highly efficient FPGA accelerator for running applications in-place. We evaluated our proposed approach on a case study application for a similarity search library called Faiss.",autonomous vehicle
10.1109/FPL.2018.00056,filtered,2018 28th International Conference on Field Programmable Logic and Applications (FPL),IEEE,2018-08-31 00:00:00,ieeexplore,Reconfigurable Acceleration of 3D-CNNs for Human Action Recognition with Block Floating-Point Representation,https://ieeexplore.ieee.org/document/8533510/,"Human action recognition (HAR) has been widely employed in various applications such as autonomous cars and intelligent video surveillance. Among the algorithms proposed for HAR, the 3D-CNNs algorithm can achieve the best accuracy. However, its algorithmic complexity imposes a substantial overhead over the speed of these networks, which limits their deployment in real-life applications. This paper proposes a novel customizable architecture for 3D-CNNs based on block floating-point (BFP) arithmetic, where the utilization of BFP significantly reduces the bitwidth while eliminating the need to retrain the network. Optimizations such as locality exploration and block alignment with 3D blocking are performed to improve performance and accuracy. An analytical model and tool are developed to predict the optimized parameters for hardware customization based on user constraints such as FPGA resources or accuracy requirement. Experiments show that without retraining, a 15-bit mantissa design using single-precision accumulation on a Xilinx ZC706 device can be 8.2 times faster than an Intel i7-950 processor at 3.07 GHz with only 0.4% accuracy loss.",autonomous vehicle
10.1109/GCWkshps45667.2019.9024398,filtered,2019 IEEE Globecom Workshops (GC Wkshps),IEEE,2019-12-13 00:00:00,ieeexplore,Reconfigurable Intelligent Surface for Green Edge Inference in Machine Learning,https://ieeexplore.ieee.org/document/9024398/,"To provide energy-efficient machine learning services for high-stake applications, e.g., drones and autonomous cars, in this paper, we propose a reconfigurable intelligent surface (RIS)-empowered edge inference architecture by cooperatively executing tasks at multiple computing-enabled base stations. Specifically, an RIS with many reflecting elements is deployed in the network architecture to assist the controllable signal propagations via configuring the phase shifts of these elements, thereby enhancing the signal quality at receivers. To minimize the power consumption for RIS-empowered edge inference process, we shall propose a joint group sparse beamforming and phase shifts design approach for inference tasks allocation and signal propagations control, respectively. An alternating minimization method is further developed to decouple the optimization variables and split this intractable problem into two subproblems. The mixed ℓ<sub>1,2</sub>-norm and difference-of-convex-functions (DC) techniques are presented respectively for group sparsity inducing and phase shifts design. Simulation results demonstrate the admirable performance gains of the proposed algorithms and the effectiveness of the deployment of RIS.",autonomous vehicle
10.1109/ACCESS.2019.2942390,filtered,IEEE Access,IEEE,2019-01-01 00:00:00,ieeexplore,"Machine Learning for 5G/B5G Mobile and Wireless Communications: Potential, Limitations, and Future Directions",https://ieeexplore.ieee.org/document/8844682/,"Driven by the demand to accommodate today's growing mobile traffic, 5G is designed to be a key enabler and a leading infrastructure provider in the information and communication technology industry by supporting a variety of forthcoming services with diverse requirements. Considering the ever-increasing complexity of the network, and the emergence of novel use cases such as autonomous cars, industrial automation, virtual reality, e-health, and several intelligent applications, machine learning (ML) is expected to be essential to assist in making the 5G vision conceivable. This paper focuses on the potential solutions for 5G from an ML-perspective. First, we establish the fundamental concepts of supervised, unsupervised, and reinforcement learning, taking a look at what has been done so far in the adoption of ML in the context of mobile and wireless communication, organizing the literature in terms of the types of learning. We then discuss the promising approaches for how ML can contribute to supporting each target 5G network requirement, emphasizing its specific use cases and evaluating the impact and limitations they have on the operation of the network. Lastly, this paper investigates the potential features of Beyond 5G (B5G), providing future research directions for how ML can contribute to realizing B5G. This article is intended to stimulate discussion on the role that ML can play to overcome the limitations for a wide deployment of autonomous 5G/B5G mobile and wireless communications.",autonomous vehicle
10.1109/ICDE48307.2020.00010,filtered,2020 IEEE 36th International Conference on Data Engineering (ICDE),IEEE,2020-04-24 00:00:00,ieeexplore,Curiosity-Driven Energy-Efficient Worker Scheduling in Vehicular Crowdsourcing: A Deep Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/9101657/,"Spatial crowdsourcing (SC) utilizes the potential of a crowd to accomplish certain location based tasks. Although worker scheduling has been well studied recently, most existing works only focus on the static deployment of workers but ignore their temporal movement continuity. In this paper, we explicitly consider the use of unmanned vehicular workers, e.g., drones and driverless cars, which are more controllable and can be deployed in remote or dangerous areas to carry on long-term and hash tasks as a vehicular crowdsourcing (VC) campaign. We propose a novel deep reinforcement learning (DRL) approach for curiosity-driven energy-efficient worker scheduling, called ""DRL-CEWS"", to achieve an optimal trade-off between maximizing the collected amount of data and coverage fairness, and minimizing the overall energy consumption of workers. Specifically, we first utilize a chief-employee distributed computational architecture to stabilize and facilitate the training process. Then, we propose a spatial curiosity model with a sparse reward mechanism to help derive the optimal policy in large crowdsensing space with unevenly distributed data. Extensive simulation results show that DRL-CEWS outperforms the state-of-the-art methods and baselines, and we also visualize the benefits curiosity model brings and show the impact of two hyperparameters.",autonomous vehicle
10.1109/EuCNC/6GSummit51104.2021.9482459,filtered,2021 Joint European Conference on Networks and Communications & 6G Summit (EuCNC/6G Summit),IEEE,2021-06-11 00:00:00,ieeexplore,Enhanced Teleoperated Transport and Logistics: A 5G Cross-Border Use Case,https://ieeexplore.ieee.org/document/9482459/,"5G technologies promise to significantly improve the network connection with ultra-low latency communications and edge computing, enabling the delivery of groundbreaking solutions, such as autonomous vehicles and artificial intelligence (AI) based communications systems. As 5G mobile networks are still under deployment, the potential for 5G-connected AI-assisted driverless cars, drones, and vessels is still several years away. However, to realize fully connected and automated mobility (CAM), a crucial step needs to be addressed: 5G-based teleoperated transport. For this reason, the H2020 5G-Blueprint project is designing, testing, and validating a 5G-enabled teleoperated transport system and its enabling functions in both relevant and operational environments, realized through cross-border trials on the road/highways and waterways along 5G corridors that cross through Belgium and The Netherlands. The main outcome of the 5G-Blueprint project will result in a blueprint for the future cooperation between public, private, and semi-private parties (e.g., ports), empowered by 5G technologies and gaining new insights related to the architecture, governance, and relevant business models of CAM services.",autonomous vehicle
10.1109/ITSC.2016.7795536,filtered,2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC),IEEE,2016-11-04 00:00:00,ieeexplore,Multivariate modelling for autonomous vehicles: Research trends in perspective,https://ieeexplore.ieee.org/document/7795536/,"Over the last decade, the impressive technological advancement around artificial intelligence have encouraged and stimulated much research on driverless cars. Inevitability, such novelty casts huge speculation on its effective deployment in the urban reality. The viability issue of cybercars demands appropriate research so as to infer and validate upcoming impacts at different levels, especially the mobility level, and address new performance measures intrinsic to this novel transportation paradigm. Therefore, this paper presents a short overview perspective about the definitions around the so-called autonomous vehicles. Additionally, as long as multivariate modelling is concerned, this position paper contributes with insights that span some of the future problematics and research questions regarding the automated vehicles topic.",autonomous vehicle
10.1109/ISVLSI.2019.00107,filtered,2019 IEEE Computer Society Annual Symposium on VLSI (ISVLSI),IEEE,2019-07-17 00:00:00,ieeexplore,Towards Efficient On-Board Deployment of DNNs on Intelligent Autonomous Systems,https://ieeexplore.ieee.org/document/8839367/,"With their unprecedented performance in major AI tasks, deep neural networks (DNNs) have emerged as a primary building block in modern autonomous systems. Intelligent systems such as drones, mobile robots and driverless cars largely base their perception, planning and application-specific tasks on DNN models. Nevertheless, due to the nature of these applications, such systems require on-board local processing in order to retain their autonomy and meet latency and throughput constraints. In this respect, the large computational and memory demands of DNN workloads pose a significant barrier on their deployment on the resource-and power-constrained compute platforms that are available on-board. This paper presents an overview of recent methods and hardware architectures that address the system-level challenges of modern DNN-enabled autonomous systems at both the algorithmic and hardware design level. Spanning from latency-driven approximate computing techniques to high-throughput mixed-precision cascaded classifiers, the presented set of works paves the way for the on-board deployment of sophisticated DNN models on robots and autonomous systems.",autonomous vehicle
10.1109/ICRA.2014.6907553,filtered,2014 IEEE International Conference on Robotics and Automation (ICRA),IEEE,2014-06-07 00:00:00,ieeexplore,Physics-aware informative coverage planning for autonomous vehicles,https://ieeexplore.ieee.org/document/6907553/,"Unmanned vehicles are emerging as an attractive tool for persistent monitoring tasks of a given area, but need automated planning capabilities for effective unattended deployment. Such an automated planner needs to generate collision-free coverage paths by steering waypoints to locations that both minimize the path length and maximize the amount of information gathered along the path. The approach presented in this paper significantly extends prior work and handles motion uncertainty of an unmanned vehicle and the presence of obstacles by using a Markov Decision Process based approach to generate collision-free paths. Simulation results show that the proposed approach is robust to significant motion uncertainties and reduces the probability of collision with obstacles in the environment.",autonomous vehicle
10.1109/MODELS-C.2019.00017,filtered,2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C),IEEE,2019-09-20 00:00:00,ieeexplore,Coordinate Systems: Level Ascending Ontological Options,https://ieeexplore.ieee.org/document/8904729/,"A major challenge faced in the deployment of collaborating unmanned vehicles is enabling the semantic interoperability of sensor data. One aspect of this, where there is significant opportunity for improvement, is characterizing the coordinate systems for sensed position data. We are involved in a proof of concept project that addresses this challenge through a foundational conceptual model using a constructional approach based upon the BORO Foundational Ontology. The model reveals the characteristics as sets of options for configuring the coordinate systems. This paper examines how these options involve, ontologically, ascending levels. It identifies two types of levels, the well-known type levels and the less well-known tuple/relation levels.",autonomous vehicle
10.1109/TVT.2021.3069426,filtered,IEEE Transactions on Vehicular Technology,IEEE,2021-06-01 00:00:00,ieeexplore,An Adversarial Attack Based on Incremental Learning Techniques for Unmanned in 6G Scenes,https://ieeexplore.ieee.org/document/9390408/,"With the development of artificial intelligence(AI), unmanned vehicles can relieve traffic jamming and decrease the risk of traffic accidents, where deep neural networks (DNNs) play an important role and have become one of the most critical technologies. Nevertheless, DNNs are still susceptible to adversarial examples. Even worse, they also show severe performance degradation when the system needs DNNs to learn new knowledge without forgetting the old one. As unmanned vehicles travel on the road, they need to frequently learn new categories and different representations. Learning all data after the new sample arrives will expend a lot of time and space. As a result, it will affect the deployment of artificial intelligence in unmanned scenes. In recent years, it has been observed that incremental learning technology can solve the above challenges. However, previously reported works mainly focused on batch learning. It is not clear how much impact the adversarial attack will have on the deep learning model when performing incremental learning tasks. This issue exposes the hidden safety risks of unmanned driving and increases discuss opportunities. Therefore, we propose an adversarial attack based on incremental learning techniques for unmanned scenes in this paper. Specifically, it can retain information previously learned by the model. At the same time, it can renew the old model to learn new model, thereby continually adding small perturbation to legitimate examples. A couple of experiments on the Pascal VOC 2012 dataset has been conducted, and the experiment results show that the adversarial attack based on incremental learning techniques has a higher attack success rate. Further, it can improve the successful attack rate by 8.43%.",autonomous vehicle
10.1109/ITAIC.2011.6030219,filtered,2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference,IEEE,2011-08-22 00:00:00,ieeexplore,A redeployment strategy based on Unmanned Aerial Vehicle in wireless sensor network,https://ieeexplore.ieee.org/document/6030219/,"In reality, holes in large-scale sensor networks are exist due to various reasons, such as energy depletion and randomness deployment. These holes may degrade the detection performance of the entire sensor networks. Based on the probabilistic detection model with false alarm rate, this paper proposes a new redeployment method. A method of using an Unmanned Aerial Vehicle (UAV) was proposed for boundaries of holes detection. In particular, in this paper, the contour graph was used for redeploy the holes based on depth-first strategy. According to the simulation results, the proposed method can attain better coverage rate.",autonomous vehicle
10.1109/ICOIN48656.2020.9016459,filtered,2020 International Conference on Information Networking (ICOIN),IEEE,2020-01-10 00:00:00,ieeexplore,Unmanned Aerial Vehicle Allocation and Deep Learning based Content Caching in Wireless Network,https://ieeexplore.ieee.org/document/9016459/,"Data traffic is increasing with the increasing number of smart devices. Also, base stations in some regions are suddenly overloaded only for a certain period (i.e., an amusement park on holiday). Thus, to handle this issue, we need to deploy more base stations, small-cell base stations. But those are not economical solutions. Hence, in this paper, we utilized Unmanned Aerial Vehicles (UAVs) as temporary small-cell base-stations to solve the aforementioned problems. In this work, we proposed a cluster-based UAVs deployment scheme to reduce data traffic (such as video traffic) as well as service delays for the users and improve the coverage of base stations. First, we formed the user groups according to the distance of users with the help of the K-means clustering algorithm. Second, we find the optimal location to allocate the UAVs in each cluster. Third, we proposed a Long Short-Term Memory based caching scheme to cache popular contents on UAVs. Finally, the simulation results show that our proposed scheme outperforms than the other in terms of accessing delay and cache hit ratio.",autonomous vehicle
10.1109/IGARSS.2011.6049252,filtered,2011 IEEE International Geoscience and Remote Sensing Symposium,IEEE,2011-07-29 00:00:00,ieeexplore,Use of high-resolution multispectral imagery acquired with an autonomous unmanned aerial vehicle to quantify the spread of an invasive wetlands species,https://ieeexplore.ieee.org/document/6049252/,"Management of wetlands resources often requires assessment of changes in wetland vegetation over time. Accurate tracking of the expansion or retraction of invasive plant species is especially critical for natural resource managers who must make decisions on the deployment of effective control measures. Many available remote sensing strategies to quantify the location of invasive plant species are either too expensive to deploy on a regular basis or lack sufficient geographic or temporal resolution to be of use to resources managers. This paper presents the results of the use of a new unmanned aerial vehicle platform, called Aggie Air™, and a new classification algorithm to track the spread of an invasive grass species, Phragmites australis, in a large and important wet-land in northern Utah. The combination of high resolution multi-spectral images (in space and time) and the classification algorithm based on advances in statistical learning theory produce quantitative land cover descriptions that identify Phragmites locations with an accuracy of 95 percent. The combination of these two tools provides wetlands managers with new and potentially valuable methods to quantify the spread of Phragmites and to evaluate the efficacy of their attempts to control it.",autonomous vehicle
10.1109/TWC.2019.2946822,filtered,IEEE Transactions on Wireless Communications,IEEE,2020-01-01 00:00:00,ieeexplore,Energy-Aware 3D Unmanned Aerial Vehicle Deployment for Network Throughput Optimization,https://ieeexplore.ieee.org/document/8875002/,"Introducing mobile small cells to next generation cellular networks is nowadays a pervasive and cost-effective way to fulfill the ever-increasing mobile broadband traffic. Being agile and resilient, unmanned aerial vehicles (UAVs) mounting small cells are deemed emerging platforms for the provision of wireless services. As the residual battery capacity available to UAVs determines the lifetime of an airborne network, it is essential to account for the energy expenditure on various flying actions in a flight plan. The focus of this paper is therefore on studying the 3D deployment problem for a swarm of UAVs, with the goal of maximizing the total amount of data transmitted by UAVs. In particular, we address an interesting trade-off among flight altitude, energy expense and travel time. We formulate the problem as a non-convex non-linear optimization problem and propose an energy-aware 3D deployment algorithm to resolve it with the aid of Lagrangian dual relaxation, interior-point and subgradient projection methods. Afterwards, we prove the optimality of a special case derived from the convexification transformation. We then conduct a series of simulations to evaluate the performance of our proposed algorithm. Simulation results manifest that our proposed algorithm can benefit from the proper treatment of the trade-off.",autonomous vehicle
10.1109/ICCC49849.2020.9238795,filtered,2020 IEEE/CIC International Conference on Communications in China (ICCC),IEEE,2020-08-11 00:00:00,ieeexplore,3D Deployment with Machine Learning and System Performance Analysis of UAV-Enabled Networks,https://ieeexplore.ieee.org/document/9238795/,"Exploring the base station (BS) placement in both horizontal and vertical directions is beneficial but challenging for unmanned aerial vehicle (UAV)-enabled wireless network. In this paper, we propose a three dimensional (3D) deployment approach for UAVs and analyze the system performance of finite UAV-enabled networks in which UAVs are equipped with BS. By modeling UAVs as a deep reinforcement learning (DRL) agent, we propose a novel framework to deploy UAVs in 3D space to maximize the network utility. Then utilizing tools from stochastic geometry, we model the locations of UAVs as binomial point process (BPP) and derive exact expressions of coverage probability for directional antennas and omnidirectional antennas equipped UAVs. The expressions are functions of UAVs' altitudes and sector angles. The analysis is meaningful for setting UAVs' altitude and sector angle of directional antennas. Simulation results show that 3D deployment of UAVs achieves a remarkable system performance and the analysis provides useful performance trends.",autonomous vehicle
10.1109/ICC42927.2021.9500582,filtered,ICC 2021 - IEEE International Conference on Communications,IEEE,2021-06-23 00:00:00,ieeexplore,A Deep Learning-Based Approach to Resource Allocation in UAV-aided Wireless Powered MEC Networks,https://ieeexplore.ieee.org/document/9500582/,"Beamforming and non-orthogonal multiple access (NOMA) are two key techniques for achieving spectral efficient communication in the fifth generation and beyond wireless networks. In this paper, we jointly apply a hybrid beamforming and NOMA techniques to an unmanned aerial vehicle (UAV)-carried wireless-powered mobile edge computing (MEC) system, within which the UAV is mounted with a wireless power charger and the MEC platform delivers energy and computing services to Internet of Things (IoT) devices. We aim to maximize the sum computation rate at all IoT devices whilst satisfying the constraint of energy harvesting and coverage. The considered optimization problem is non-convex involving joint optimization of the UAV’s 3D placement and hybrid beamforming matrices as well as computation resource allocation in partial offloading pattern, and thus is quite difficult to tackle directly. By applying the polyhedral annexation method and the deep deterministic policy gradient (DDPG) algorithm, we propose an effective algorithm to derive the closed-form solution for the optimal 3D deployment of the UAV, and find the solution for the hybrid beamformer. A resource allocation algorithm for partial offloading pattern is thereby proposed. Simulation results demonstrate that our designed algorithm yields a significant computation performance enhancement as compared to the benchmark schemes.",autonomous vehicle
10.1109/GLOBECOM42002.2020.9322556,filtered,GLOBECOM 2020 - 2020 IEEE Global Communications Conference,IEEE,2020-12-11 00:00:00,ieeexplore,Caching Placement and Resource Allocation for AR Application in UAV NOMA Networks,https://ieeexplore.ieee.org/document/9322556/,"The cache-enabling unmanned aerial vehicle (UAV) cellular networks with massive access capability supported by non-orthogonal multiple access (NOMA) are investigated in this paper. The delivery of multi-media contents for the mixed augmented reality (AR) and normal multi-media application is assisted by multiple mobile UAV base stations, which cache popular contents for wireless backhaul link traffic offloading. To cope with the dynamic content requests and mobility of users in practical scenarios, the dynamic optimization problem for user association, caching placement of UAVs, real-time deployment of UAVs, and power allocation of NOMA is modeled as a stackelberg game to minimize the long-term content delivery delay. Specifically, the game is decomposed into a leader level problem and a number of follower level problems. A correction mechanism is added in deep reinforcement learning (DRL) to optimize the user association in leader level. A meta actor network is proposed in DRL to jointly optimize the UAVs caching placement, real-time UAVs deployment and power allocation of NOMA in follower level. Then, a dynamic caching placement and resource allocation algorithm based on multi-agent meta deep reinforcement learning is proposed to minimize the long-term content delivery delay. Finally, we demonstrate that the considerable gains are achieved by the proposed algorithm.",autonomous vehicle
10.1109/GLOBECOM42002.2020.9348040,filtered,GLOBECOM 2020 - 2020 IEEE Global Communications Conference,IEEE,2020-12-11 00:00:00,ieeexplore,Distributional Reinforcement Learning for mmWave Communications with Intelligent Reflectors on a UAV,https://ieeexplore.ieee.org/document/9348040/,"In this paper, a novel communication framework that uses an unmanned aerial vehicle (UAV)-carried intelligent reflector (IR) is proposed to enhance multi-user downlink transmissions over millimeter wave (mmWave) frequencies. In order to maximize the downlink sum-rate, the optimal precoding matrix (at the base station) and reflection coefficient (at the IR) are jointly derived. Next, to address the uncertainty of mmWave channels and maintain line-of-sight links in a realtime manner, a distributional reinforcement learning approach, based on quantile regression optimization, is proposed to learn the propagation environment of mmWave communications, and, then, optimize the location of the UAV-IR so as to maximize the long-term downlink communication capacity. Simulation results show that the proposed learning-based deployment of the UAV-IR yields a significant advantage, compared to a non-learning UAV-IR, a static IR, and a direct transmission schemes, in terms of the average data rate and the achievable line-of-sight probability of downlink mmWave communications.",autonomous vehicle
10.1109/ISAECT50560.2020.9523700,filtered,2020 International Symposium on Advanced Electrical and Communication Technologies (ISAECT),IEEE,2020-11-27 00:00:00,ieeexplore,Edge-Cloud Architectures Using UAVs Dedicated To Industrial IoT Monitoring And Control Applications,https://ieeexplore.ieee.org/document/9523700/,"The deployment of new technologies to ease the control and management of a massive data volume and its uncertainty is a very significant challenge in the industry. Under the name ""Smart Factory"", the Industrial Internet of Things (IoT) aims to send data from systems that monitor and control the physical world to data processing systems for which cloud computing has proven to be an important tool to meet processing needs. unmanned aerial vehicles (UAVs) are now being introduced as part of IIoT and can perform important tasks. UAVs are now considered one of the best remote sensing techniques for collecting data over large areas. In the field of fog and edge computing, the IoT gateway connects various objects and sensors to the Internet. It function as a common interface for different networks and support different communication protocols. Edge intelligence is expected to replace Deep Learning (DL) computing in the cloud, providing a variety of distributed, low-latency and reliable intelligent services. In this paper, An unmanned aerial vehicle is automatically integrated into an industrial control system through an IoT gateway platform. Rather than sending photos from the UAV to the cloud for processing, an AI cloud trained model is deployed in the IoT gateway and used to process the taken photos. This model is designed to overcome the latency channels of the cloud computing architecture. The results show that the monitoring and tracking process using advanced computing in the IoT gateway is significantly faster than in the cloud.",autonomous vehicle
10.1109/AIPR50011.2020.9425341,filtered,2020 IEEE Applied Imagery Pattern Recognition Workshop (AIPR),IEEE,2020-10-15 00:00:00,ieeexplore,Enhancing Network-edge Connectivity and Computation Security in Drone Video Analytics,https://ieeexplore.ieee.org/document/9425341/,"Unmanned Aerial Vehicle (UAV) systems with high-resolution video cameras are used for many operations such as aerial imaging, search and rescue, and precision agriculture. Multi-drone systems operating in Flying Ad Hoc Networks (FANETS) are inherently insecure and require efficient security schemes to defend against cyber-attacks such as e.g., Man-in-the-middle, Replay and Denial of Service attacks. In this paper, we propose a cloud-based, end-to-end security framework viz., ""DroneNet-Sec"" that provides secure network-edge connectivity, and computation security for drone video analytics to defend against common attack vectors in UAV systems. The DroneNet-Sec features a dynamic security scheme that uses machine learning to detect anomaly events and adopts countermeasures for computation security of containerized video analytics tasks. The security scheme comprises of a custom secure packet designed with MAVLink protocol for ensuring data privacy and integrity, without high degradation of the performance in a real-time FANET deployment. We evaluate DroneNet-Sec in a hybrid testbed that synergies simulation and emulation via an open-source network simulator (NS-3) and a research platform for mobile wireless networks (POWDER). Our performance evaluation experiments in our holistic hybrid-testbed show that DroneNet-Sec successfully detects learned anomaly events and effectively protects containerized tasks execution as well as communication in drones video analytics in a light-weight manner.",autonomous vehicle
10.1109/ICC.2019.8761117,filtered,ICC 2019 - 2019 IEEE International Conference on Communications (ICC),IEEE,2019-05-24 00:00:00,ieeexplore,Machine Learning for Position Prediction and Determination in Aerial Base Station System,https://ieeexplore.ieee.org/document/8761117/,"A novel framework for dynamic 3-D deployment of unmanned aerial vehicle (UAV) in the aerial base station system (ABSS) that based on the machine learning algorithms is proposed. In the framework, the UAV is deployed as an aerial base station to serve a group of ground users and is placed based on the prediction of the users' mobility. The joint problem of prediction of users' track and 3-D deployment of the UAV is formulated for maximizing the sum transmit rate. A two-step approach is proposed for predicting the movement of users and for determining the dynamic 3-D placement of the UAV. Firstly, an echo state network (ESN) based prediction algorithm is utilized for predicting the future positions of users based on the real-world datasets collected from Twitter. Secondly, an iterative K-Means based algorithm is proposed for obtaining the optimal placement of UAV at each time slot based on the output of ESN model. Numerical results are illustrated for showing the superiority of the proposed algorithm over the prevalent algorithm on prediction tasks. The accuracy and efficiency of the proposed framework are also investigated. Additionally, compared with static placement of the UAV, the advantage of dynamic 3-D deployment is demonstrated.",autonomous vehicle
10.23919/APNOMS50412.2020.9236987,filtered,2020 21st Asia-Pacific Network Operations and Management Symposium (APNOMS),IEEE,2020-09-25 00:00:00,ieeexplore,Optimized Deployment of Multi-UAV based on Machine Learning in UAV-HST Networking,https://ieeexplore.ieee.org/document/9236987/,"A new communications infrastructure is needed for users to experience the contents of 5G-based VR/AR in High-Speed Train (HST). Therefore, it is proposed that the Unmanned Aerial Vehicle (UAV) can be used as a communication equipment on behalf of the general Rail-side Units (RSUs) supporting the communication of the HST. To maintain reliable communications, initial deployment and trajectory considered altitude and direction of UAV are determined. Also, limited energy in UAV is an important constraint on trajectory optimization. Thus, this paper proposes initial deployment and trajectory optimization techniques for stable communication between HST and Multi-UAV with the energy constraints of UAV. This paper uses Soft Actor-Critic (SAC), one of the methods of reinforcement learning, as a way to optimize the UAV trajectory. It also uses the Support Vector Machine to carry out optimal initial deployment based on data on the maximum UAV communication distance according to the speed of HST and the energy of UAV, which is the result of trajectory optimization. As a result, this study quickly and accurately derives the optimal trajectory of Multi-Uav according to the speed of HST and the energy of UAV and also maintain stable communication by optimal initial deployment.",autonomous vehicle
10.23919/ICACT48636.2020.9061508,filtered,2020 22nd International Conference on Advanced Communication Technology (ICACT),IEEE,2020-02-19 00:00:00,ieeexplore,Proposing a Privacy Protection Model in Case of Civilian Drone,https://ieeexplore.ieee.org/document/9061508/,"Technology-based products are meant for improving the people's quality of life. Since drones or more precisely Unmanned Aerial Vehicle's UAVs were permitted to be used for civilian purposes and applications, many lucrative reasons such as low price, mobility and ease of deployment have captured the attention of commercial organizations. These reasons have motivated the commercial organizations to involve and adopt UAVs in their company's operational body structure which will be positively reflected on the services provided to their clients. UAVs have influential features that can be used to infringe on the privacy of individuals if they are deliberately misused, therefor the commercial organizations willingness and the precious services going to be offered to clients should not be at the cost of privacy. This research will present a privacy detection model to guarantee the success of UAV commercial adoption as well as securing the individual privacy. Proposed model will be implemented in near future to escort the privacy protection of civilian in case of commercial drone.",autonomous vehicle
10.1109/IWCMC.2019.8766458,filtered,2019 15th International Wireless Communications & Mobile Computing Conference (IWCMC),IEEE,2019-06-28 00:00:00,ieeexplore,RL-Based User Association and Resource Allocation for Multi-UAV enabled MEC,https://ieeexplore.ieee.org/document/8766458/,"In this paper, multi-unmanned aerial vehicle (UAV) enabled mobile edge computing (MEC), i.e., UAVE is studied, where several UAVs are deployed as flying MEC platform to provide computing resource to ground user equipments (UEs). Compared to the traditional fixed location MEC, UAV enabled MEC (i.e., UAVE) is particular useful in case of temporary events, emergency situations and on-demand services, due to its high flexibility, low cost and easy deployment features. However, operation of UAVE faces several challenges, two of which are how to achieve both 1) the association between multiple UEs and UAVs and 2) the resource allocation from UAVs to UEs, while minimizing the energy consumption for all the UEs. To address this, we formulate the above problem into a mixed integer nonlinear programming (MINLP), which is difficult to be solved in general, especially in the large-scale scenario. We then propose a Reinforcement Learning (RL)-based user Association and resource Allocation (RLAA) algorithm to tackle this problem efficiently and effectively. Numerical results show that the proposed RLAA can achieve the optimal performance with comparison to the exhaustive search in small scale, and have considerable performance gain over other typical algorithms in large-scale cases.",autonomous vehicle
10.1109/GLOBECOM38437.2019.9013626,filtered,2019 IEEE Global Communications Conference (GLOBECOM),IEEE,2019-12-13 00:00:00,ieeexplore,Reflections in the Sky: Millimeter Wave Communication with UAV-Carried Intelligent Reflectors,https://ieeexplore.ieee.org/document/9013626/,"In this paper, a novel approach that uses an unmanned aerial vehicle (UAV)-carried intelligent reflector (IR) is proposed to enhance the performance of millimeter wave (mmW) networks. In particular, the UAV-IR is used to intelligently reflect mmW beamforming signals from a base station towards a mobile outdoor user, while harvesting energy from mmW signals to power the IR. To maintain a line-of-sight (LOS) channel, a reinforcement learning (RL) approach, based on Q- learning and neural networks, is proposed to model the propagation environment, such that the location and reflection coefficient of the UAV-IR can be optimized to maximize the downlink transmission capacity. Simulation results show a significant advantage for using a UAV-IR over a static IR, in terms of the average data rate and the achievable downlink LOS probability. The results also show that the RL-based deployment of the UAV-IR further improves the network performance, relative to a scheme without learning.",autonomous vehicle
10.1109/ICRA48506.2021.9560756,filtered,2021 IEEE International Conference on Robotics and Automation (ICRA),IEEE,2021-06-05 00:00:00,ieeexplore,Siamese Anchor Proposal Network for High-Speed Aerial Tracking,https://ieeexplore.ieee.org/document/9560756/,"In the domain of visual tracking, most deep learning-based trackers highlight the accuracy but casting aside efficiency. Therefore, their real-world deployment on mobile platforms like the unmanned aerial vehicle (UAV) is impeded. In this work, a novel two-stage Siamese network-based method is proposed for aerial tracking, i.e., stage-1 for high-quality anchor proposal generation, stage-2 for refining the anchor proposal. Different from anchor-based methods with numerous pre-defined fixed-sized anchors, our no-prior method can 1) increase the robustness and generalization to different objects with various sizes, especially to small, occluded, and fast-moving objects, under complex scenarios in light of the adaptive anchor generation, 2) make calculation feasible due to the substantial decrease of anchor numbers. In addition, compared to anchor-free methods, our framework has better performance owing to refinement at stage-2. Comprehensive experiments on three benchmarks have proven the superior performance of our approach, with a speed of ∼200 frames/s.",autonomous vehicle
10.1109/GHTC.2018.8601597,filtered,2018 IEEE Global Humanitarian Technology Conference (GHTC),IEEE,2018-10-21 00:00:00,ieeexplore,The EDNA Public Safety Drone: Bullet-Stopping Lifesaving,https://ieeexplore.ieee.org/document/8601597/,"Urban gun violence in cities across the world is a serious issue for public safety agencies and disaster management organizations. This led us to the development of the EDNA drone, an aerial robotics solution designed to equip first responders in high-risk settings with lifesaving-edge tools for situational awareness and non-lethal conflict resolution. The EDNA is an unmanned aerial vehicle (UAV) that delivers the patent-pending “Predictive Probable Cause” technology. The EDNA drone is designed to provide automated real-time analysis to assist teams entering high-risk situations where gun violence may occur. By leveraging machine learning, biometric sensors, and advanced materials in the field and routing feedback to an intuitive augmented-reality interface, the EDNA will provide autonomous threat detection and bullet-stopping capabilities wherever those features are needed--to groups such as Police and Sheriff's Departments, Fire Departments, and EMT and emergency rescue teams. Data from the EDNA drone's sensors is fed to machine learning algorithms running on the drone in real-time. Through a neural network trained on past data, the EDNA is able to detect the presence and location of firearms and explosives, even through walls or other obstacles. Through the use of advanced metal foams and composite materials, the armored drone can even stop bullets-functionality which has obvious benefits for humanitarian deployment.",autonomous vehicle
10.1109/WCNC45663.2020.9120668,filtered,2020 IEEE Wireless Communications and Networking Conference (WCNC),IEEE,2020-05-28 00:00:00,ieeexplore,Trajectory Design and Generalization for UAV Enabled Networks:A Deep Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/9120668/,"In this paper, an unmanned aerial vehicle (UAV) flies as a base station (BS) to provide wireless communication service. We propose two algorithms for designing the trajectory of the UAV and analyze the impact of different training approaches on transferring to new environments. When the UAV is used to track users that move along some specific paths, we propose a proximal policy optimization (PPO) -based algorithm to maximize the instantaneous sum rate (MSR-PPO). The UAV is modeled as a deep reinforcement learning (DRL) agent to learn how to move by interacting with the environment. When the UAV serves users along unknown paths for emergencies, we propose a random training proximal policy optimization (RT-PPO) algorithm which can transfer the pre-trained model to new tasks to achieve quick deployment. Unlike classical DRL algorithms that the agent is trained on the same task to learn its actions, RT-PPO randomizes the features of tasks to get the ability to transfer to new tasks. Numerical results reveal that MSR-PPO achieves a remarkable improvement and RT-PPO shows an effective generalization performance.",autonomous vehicle
10.1109/WCSP49889.2020.9299862,filtered,2020 International Conference on Wireless Communications and Signal Processing (WCSP),IEEE,2020-10-23 00:00:00,ieeexplore,UAV-Enabled Mobile Radiation Source Tracking with Deep Reinforcement Learning,https://ieeexplore.ieee.org/document/9299862/,"Employing unmanned aerial vehicle (UAV) in localization and tracking system can bring many attractive advantages due to its high mobility, on-demand deployment and low cost. In this paper, we utilize the UAV as a mobile sensor to close up and track a mobile radiation source only based on the received signal strengths. We aim to maximize the sum of received signal strengths at the UAV receiver during a certain time interval, while taking the UAV's maximum speed and fly region constraints into account. However, it is very challenging since the positions of radiation source are unknown and dynamically changing. To address this issue, we propose a deep reinforcement learning (DRL) based framework. We first reformulate the original problem into a Markov decision process (MDP). Then, we apply the double deep Q-network (DDQN) with dueling network structure and accordingly develop a multi-step dueling-DDQN learning algorithm for radiation source tracking. The simulation results demonstrate the effectiveness of the proposed algorithm under various parameter settings.",autonomous vehicle
10.1109/VTC2020-Spring48590.2020.9128613,filtered,2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring),IEEE,2020-05-28 00:00:00,ieeexplore,UAV-assisted Online Video Downloading in Vehicular Networks: A Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/9128613/,"Online video becomes a significant service in daily life, and it usually adopts a caching and playing mechanism. Due to high mobility and changeable topology, challenges of video downloading still exist in vehicular networks, especially in areas where the roadside units (RSUs) are not fully covered. The flexible deployment of the unmanned aerial vehicle (UAVs) compensate for the lack of RSU coverage, and thus this paper considers that a cyclic flight UAV to assist RSUs in providing video download services for vehicles. With the help of UAV, seamless communication coverage and stable transmission links ensure better service quality for vehicles. In addition, we propose a model-free algorithm based on a deep Q network to find the optimal UAV decision policy to achieve the minimized stalling time. Finally, the simulation results are given to demonstrate that the proposed solution can effectively maintain a high-quality user experience.",autonomous vehicle
10.1109/DeSE.2016.34,filtered,2016 9th International Conference on Developments in eSystems Engineering (DeSE),IEEE,2016-09-02 00:00:00,ieeexplore,UAVs Deployment in Disaster Scenarios Based on Global and Local Search Optimization Algorithms,https://ieeexplore.ieee.org/document/7930647/,"The advancements in Unmanned Aerial Vehicle (UAV) related technologies and wireless communications pave the way for the deployment of wireless mesh networks in the air. These air mesh networks can be suitable for providing communication services in disaster scenarios to ground nodes such as victims and first responders. However, the optimal deployment of UAVs is not an easy as the number of possible scenarios to position the UAVs may reach a computationally challenging level. The combination of global and local search optimization algorithms can be considered as a powerful way for dealing with the massive number of possible solutions. We propose a deployment approach based on a global search algorithm such as the genetic algorithm and a local search algorithm namely the hill climbing algorithm. We show that the combination of both optimization techniques provides promising results for optimal positioning of UAVs in disaster scenarios based on simulation examples.",autonomous vehicle
10.1109/ACCESS.2021.3111318,filtered,IEEE Access,IEEE,2021-01-01 00:00:00,ieeexplore,A Novel Genetic Trajectory Planning Algorithm With Variable Population Size for Multi-UAV-Assisted Mobile Edge Computing System,https://ieeexplore.ieee.org/document/9531998/,"This paper presents a multi-unmanned aerial vehicle (UAV)-assisted mobile edge computing (MEC) system, where multiple UAVs (variable number of UAVs) are deployed to serve Internet of Things devices (IoTDs). We aim to minimize the sum of hovering and flying energies of UAVs by optimizing the trajectories of UAVs. The problem is very complicated as we have to consider the deployment of stop points (SPs), the association between UAVs and SPs, and the order of SPs for UAVs. To solve the problem, this paper proposed a novel genetic trajectory planning algorithm with variable population size (GTPA-VP), which consists of two phases. In the first phase, a genetic algorithm (GA) with a variable population size is used to update the deployment of SPs. Accordingly, a multi-chrome GA is adopted to find the association between UAVs and SPs, an optimal number of UAVs, and the optimal order of SPs for UAVs. The effectiveness of the proposed GTPA-VP is demonstrated through several experiments on a set of ten instances with up to 200 IoTDs. It is evident from the experimental results that the proposed GTPA-VP outperforms the benchmark algorithms in terms of the energy consumption of the system.",autonomous vehicle
10.1109/ACCESS.2019.2960314,filtered,IEEE Access,IEEE,2019-01-01 00:00:00,ieeexplore,Deployment Optimization of UAV Relays for Collecting Data From Sensors: A Potential Game Approach,https://ieeexplore.ieee.org/document/8935341/,"Due to the high maneuverability of unmanned aerial vehicle (UAV), a cluster of UAVs is considered used to collect sensing data from the sensors that distributed randomly in an area without the terrestrial infrastructure. The cluster members work as relays to forward the sensing data from sensors to the cluster head. For the reason that the relay deployment impacts the transmission rate and coverage area directly, we are going to optimize the deployment of the UAV relays, aiming to maximize the total capacity of the network. The problem of multi-relay deployment is intractable for two reasons. On one hand, because of the interactional and coupled relationship among the UAV relays, when the deployment of any given relay changes, the deployment optimization of other relays will be affected. On the other hand, on account of that the exact positions of the sensors are unknown, the deployment optimization of the UAV relays cannot be completed directly because of lacking parameters. In order to tackle the coupled relationship among the UAV relays, the problem of multi-relay deployment is modeled as a local interaction game. We prove that the multi-relay deployment game is an exact potential game that has at least one Nash equilibrium (NE) point. Then, the better reply-based relay deployment approach, which is an online learning approach that does not demand the information of the exact positions of sensors, is proposed to search the NE point. The simulation results show that the network capacity is significantly enhanced with the proposed relays deployment approach.",autonomous vehicle
10.1109/TVT.2021.3103153,filtered,IEEE Transactions on Vehicular Technology,IEEE,2021-10-01 00:00:00,ieeexplore,Gridless Compressed Sensing Based Channel Estimation for UAV Wideband Communications With Beam Squint,https://ieeexplore.ieee.org/document/9513592/,"Unmanned aerial vehicle (UAV) has become an appealing solution for a wide range of commercial and civilian applications thanks to its high mobility and flexible deployment. Due to the continuous UAV navigation, the channels between UAV based arial base station (BS) and the ground users are subject to the Doppler effect. Meanwhile, when UAV is equipped with massive number of antennas in high frequency band such as mmWave and Tera Hertz (THz), the non-negligible propagation delay across the array aperture would cause <italic>beam squint</italic> effect. In this paper, we first investigate the channel under both Doppler effect and beam squint effect for UAV communications with large antenna array and high frequency band. Then, we design a gridless compressed sensing (GCS) based channel tracking method, where the high dimension uplink channel can be derived by estimating a few physical parameters such as the direction of arrival (DOA), Doppler shift, and the complex gain information. Besides, with the Doppler shift reciprocity and angular reciprocity, the downlink channel can be derived by only one pilot symbol, which greatly decreases the downlink channel training overhead. Various simulation results are provided to verify the effectiveness of the proposed methods.",autonomous vehicle
10.1109/LWC.2021.3100388,filtered,IEEE Wireless Communications Letters,IEEE,2021-10-01 00:00:00,ieeexplore,Joint 3D Deployment and Power Allocation for UAV-BS: A Deep Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/9497328/,"Due to its high mobility and low cost, unmanned aerial vehicle mounted base station (UAV-BS) can be deployed in a fast and cost-efficient manner for providing wireless services in areas where traditional terrestrial infrastructures cannot be laid for technical and economic reasons. In this letter, we investigate the problem of joint three-dimensional (3D) deployment and power allocation for maximizing the system throughput in a UAV-BS system. To solve this non-convex problem, we propose a deep deterministic policy gradient (DDPG) based algorithm. The proposed algorithm allows the UAV-BS to explore in continuous state and action spaces to learn the optimal 3D hovering location and power allocation. Simulation results show that the proposed algorithm outperforms the traditional deep Q-learning-based method and genetic algorithm.",autonomous vehicle
10.1109/TVT.2020.2971001,filtered,IEEE Transactions on Vehicular Technology,IEEE,2020-03-01 00:00:00,ieeexplore,LightAMC: Lightweight Automatic Modulation Classification via Deep Learning and Compressive Sensing,https://ieeexplore.ieee.org/document/8978670/,"Automatic modulation classification (AMC) is an promising technology for non-cooperative communication systems in both military and civilian scenarios. Recently, deep learning (DL) based AMC methods have been proposed with outstanding performances. However, both high computing cost and large model sizes are the biggest hinders for deployment of the conventional DL based methods, particularly in the application of internet-of-things (IoT) networks and unmanned aerial vehicle (UAV)-aided systems. In this correspondence, a novel DL based lightweight AMC (LightAMC) method is proposed with smaller model sizes and faster computational speed. We first introduce a scaling factor for each neuron in convolutional neural network (CNN) and enforce scaling factors sparsity via compressive sensing. It can give an assist to screen out redundant neurons and then these neurons are pruned. Experimental results show that the proposed LightAMC method can effectively reduce model sizes and accelerate computation with the slight performance loss.",autonomous vehicle
10.1109/LWC.2020.2995226,filtered,IEEE Wireless Communications Letters,IEEE,2020-09-01 00:00:00,ieeexplore,Optimization of Energy Management for UAV-Enabled Cognitive Radio,https://ieeexplore.ieee.org/document/9094637/,"The deployment of unmanned aerial vehicle (UAV)-enabled cognitive radio system in the area covered by primary network is studied in this letter. The UAV shares the spectrum with primary user (PU) and aims to maximize the transmitted bits with limited battery capacity. When the UAV flies towards the primary transmitter, the sensing performance and throughput of the UAV system will be improved. However, the energy consumption increases linearly with the flying distance. The goal of this letter is to find the optimal position of the UAV and optimize the sensing performance as well as the power allocation such that the transmitted bits is maximized while the PU is sufficiently protected. An iterative optimization algorithm is proposed to obtain the system parameters. Simulation results show the efficiency of the proposed approach in terms of transmitted bits as compared to other schemes.",autonomous vehicle
10.1109/TCOMM.2020.3006908,filtered,IEEE Transactions on Communications,IEEE,2020-10-01 00:00:00,ieeexplore,Probabilistic Cache Placement in UAV-Assisted Networks With D2D Connections: Performance Analysis and Trajectory Optimization,https://ieeexplore.ieee.org/document/9133208/,"With the exponential growth of data traffic, caching is regarded as a promising solution to combine with unmanned aerial vehicle (UAV)-assisted networks, which can offload cellular traffic and improve the system performance. Moreover, the cache capacity at user side can be leveraged, e.g., through local data storage or device-to-device (D2D) sharing. In this paper, we focus on the performance analysis and trajectory optimization of cache-enabled UAV-assisted networks with underlaid D2D communications. We consider both static and dynamic UAV deployments. For static UAV deployment, we first formulate an optimization problem to design the cache placement in order to maximize the cache hit probability. Then, the successful transfer probability (STP) and sum-rate are analyzed by using stochastic geometry, and their closed-form expressions are derived. For dynamic UAV deployment, the UAV moves over the cell and stops at several path points to serve users. To shorten the time required for the UAV to cover all users, a spiral algorithm is proposed to optimize the UAV trajectory, aiming at minimizing the number of UAV path points. Moreover, since at different locations, the UAV communication will incur different interference on D2D users, we derive the outage probability for the D2D users. Simulation results show the significant performance gain of our proposed probabilistic cache placement over existing strategies. For a given user density, we show that the optimal values for the UAV height which lead to the maximum UAV-STP and sum-rate exist.",autonomous vehicle
10.1109/ACCESS.2021.3050522,filtered,IEEE Access,IEEE,2021-01-01 00:00:00,ieeexplore,Spectrum-Sharing UAV-Assisted Mission-Critical Communication: Learning-Aided Real-Time Optimisation,https://ieeexplore.ieee.org/document/9319135/,"We propose an unmanned aerial vehicle (UAV) communications scheme with spectrum-sharing mechanism to provide mission-critical services such as disaster recovery and public safety. Specifically, the UAVs can serve as flying base stations to provide extended network coverage for the affected area under spectrum-sharing cognitive radio networks (CRNs). To cope with the effects of network destruction in a disaster, we propose a real-time optimisation framework for resource allocation (e.g., power and number of UAVs) for CRNs assisted by UAV relays. The proposed optimisation scheme aims at optimising the network throughput of primary and secondary networks under the stringent constraint of maximum tolerable interference impinged on the primary users. We also propose a deep neural network (DNN) model to significantly reduce the execution time under real-time solution of mixed-integer UAV deployment problems. For both primary and secondary networks, our real-time optimisation algorithms impose low computational complexity, hence, have a low execution time in solving throughput optimisation problems, which demonstrates the benefit of our approached proposed for spectrum-sharing UAV-assisted mission-critical services.",autonomous vehicle
10.1109/ACCESS.2020.3025409,filtered,IEEE Access,IEEE,2020-01-01 00:00:00,ieeexplore,Swarm Intelligence Application to UAV Aided IoT Data Acquisition Deployment Optimization,https://ieeexplore.ieee.org/document/9201288/,"It is feasible and safe to use unmanned aerial vehicle (UAV) as the data collection platform of the Internet of things (IoT). In order to save the energy loss of the platform and make the UAV perform the collection work effectively, it is necessary to optimize the deployment of UAV. The objective problem is to minimize the sum of the lost energy of UAV and the loss of data transmission of Internet of things devices. The key to solving the problem is to calculate the location of the docking points and the number of docking points when the UAV is working to collect data. This paper proposes a coding scheme based on swarm intelligence optimization, which encapsulates the docking position of UAV into a dimension, so the number of docking points to be calculated is the dimension number of optimization objective. This problem is considered as a dynamic dimension optimization problem. Each individual in swarm intelligence algorithm is a solution. When adjusting the dimension, the best individual is added or deleted to achieve dynamic search in the evolutionary process. Collaborative search among multiple individuals can improve the local optimal limit of search to a certain extent. Finally, the validity of the swarm intelligence-based coding approach is verified by simulation under seven IoT device distribution scenarios. The swarm intelligence algorithms we used are flower pollination algorithm (FPA), salp swarm algorithm (SSA), sine cosine algorithm (SCA). FPA and SCA perform most efficiently in three and four scenarios among the seven IoT device scenarios, respectively.",autonomous vehicle
10.1109/JIOT.2018.2876695,filtered,IEEE Internet of Things Journal,IEEE,2019-04-01 00:00:00,ieeexplore,UAV-Enabled Spatial Data Sampling in Large-Scale IoT Systems Using Denoising Autoencoder Neural Network,https://ieeexplore.ieee.org/document/8496746/,"Internet of Things (IoT) technology has been pervasively applied to environmental monitoring, due to the advantages of low cost and flexible deployment of IoT enabled systems. In many large-scale IoT systems, accurate and efficient data sampling and reconstruction is among the most critical requirements, since this can relieve the data rate of trunk link for data uploading while ensure data accuracy. To address the related challenges, we have proposed an unmanned aerial vehicle (UAV) enabled spatial data sampling scheme in this paper using denoising autoencoder (DAE) neural network. More specifically, a UAV-enabled edge-cloud collaborative IoT system architecture is first developed for data processing in large-scale IoT monitoring systems, where UAV is utilized as mobile edge computing device. Based on this system architecture, the UAV-enabled spatial data sampling scheme is further proposed, where the wireless sensor nodes of large-scale IoT systems are clustered by a newly developed bounded-size K-means clustering algorithm. A neural network model, i.e., DAE, is applied to each cluster for data sampling and reconstruction, by exploitation of both linear and nonlinear spatial correlation among data samples. Simulations have been conducted and the results indicate that the proposed scheme has improved data reconstruction accuracy under the sampling ratio without introducing extra complexity, as compared to the compressive sensing-based method.",autonomous vehicle
10.1109/ECAI46879.2019.9042120,filtered,"2019 11th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)",IEEE,2019-06-29 00:00:00,ieeexplore,Automatic Analysis of Potential Hazard Events Using Unmanned Aerial Vehicles,https://ieeexplore.ieee.org/document/9042120/,"This paper is motivated by the possibility of developing a wide variety of applications and domains in which Unmanned Aerial Vehicles (UAVs) can be used globally for various purposes. UAVs are currently used by public administrations and security forces such as police, fire brigades, civil protection, research institutions, construction, and agriculture entities. The purpose of this paper is to facilitate the handling of UAVs to retrieve various data from the environment. The drone (UAV) visits some points to collect data (image and/or video input) from sensors like GPS, camera, gyroscope, and accelerometer. GPS sensor coordinates are used to compare the data taken with subsequent results through processing with specialized software. The drone is used as an access gate with built-in sensors. Certain hazard events (fires, floods, avalanches, landslides) are not limited to narrow geographical areas, but can impact the environment by triggering negative chain events. 3D modeling offers a wide range of possibilities to prevent potential hazard events, or, if such an event has occurred, makes it possible to monitor the affected area and assess the damage by comparing the area in the pre-event configuration with the after-event one. After image processing and data acquisition, a report is generated that includes the map and the 3D model of the analyzed object. A hazard is an agent that has the potential to cause damage to a particular target. Terms such as risk or danger can be used in similar contexts. TensorFlow is an open source software library in high-performance computing. Flexible architecture allows easy deployment of computing on a variety of platforms (CPU, GPU, TPU), from desktop to server or mobile devices. We used the learning transfer: at first we used a model that was already prepared for another problem, and then we re-qualified it on a similar problem. Deep learning from scratch can take several days, but learning transfer can be done shortly. We applied Python along with TensorFlow to train an image classifier and classify images with it. We formed a consistent set of training pictures, using three labels: fire, flood (detectable hazards) and nature (non-hazard images). We then re-qualified an efficient, small-sized neural network by (re)training the image set in order to get the best results in the hazards prediction selection process with a progressive higher accuracy as (re) training evolves at optimal rating. With Python and OpenCV technologies, we used four decision algorithms to generate prediction of hazard: Support Vector Machine, Naive Bayes, Logistic Regression, and Decision Tree Classifier. Each generated report includes precision, recall, f1-score, and support indices, depending on the class and intervals used. We also used the confusion matrix as an alternative method to evaluate the classification accuracy. Analyzing the 4 algorithms we noticed that they behave differently. Training using TensorFlow generated better results than the other methods. For the main classes tested hazard is recognized up to 99%.",autonomous vehicle
10.1109/COMST.2019.2919613,filtered,IEEE Communications Surveys & Tutorials,IEEE,2019-12-01 00:00:00,ieeexplore,A Survey of Game Theory in Unmanned Aerial Vehicles Communications,https://ieeexplore.ieee.org/document/8723552/,"Unmanned aerial vehicles (UAVs) can be deployed as wireless relays or aerial base stations to improve network connectivity and coverage in cellular networks. UAVs can also be used to significantly enhance the performance of mobile ad-hoc networks and wireless sensor networks. In the future, UAVs are expected to become an integral part of the fifth generation wireless networks as well as key enablers of the coming massive Internet of Things. However, there are still many challenging issues in designing architectures and deployment of UAV-based networks. To address the issues, game theory has recently been adopted as an effective tool for modeling and analyzing problems in UAV-aided networks. In this paper, we survey the applications of game theory in solving various UAV-assisted networks challenges. We first provide a brief introduction to wireless communications with UAVs and then introduce basic game theory concepts and their relation to wireless networks. We further present the classification and brief introduction to the games applied to solve problems in UAV-aided networks. We then provide a comprehensive literature review on game-theoretic techniques utilized in dealing with challenges in the UAV-based wireless networks. Finally, we introduce advanced distributed schemes for interference management in large UAV-assisted communication networks. This paper aims to provide readers with an understanding of UAV-aided networks in terms of their architecture, benefits, challenges, and various game theoretical solutions applied to these communications networks.",autonomous vehicle
10.1109/JSAC.2017.2680898,filtered,IEEE Journal on Selected Areas in Communications,IEEE,2017-05-01 00:00:00,ieeexplore,Caching in the Sky: Proactive Deployment of Cache-Enabled Unmanned Aerial Vehicles for Optimized Quality-of-Experience,https://ieeexplore.ieee.org/document/7875131/,"In this paper, the problem of proactive deployment of cache-enabled unmanned aerial vehicles (UAVs) for optimizing the quality-of-experience (QoE) of wireless devices in a cloud radio access network is studied. In the considered model, the network can leverage human-centric information, such as users' visited locations, requested contents, gender, job, and device type to predict the content request distribution, and mobility pattern of each user. Then, given these behavior predictions, the proposed approach seeks to find the user-UAV associations, the optimal UAVs' locations, and the contents to cache at UAVs. This problem is formulated as an optimization problem whose goal is to maximize the users' QoE while minimizing the transmit power used by the UAVs. To solve this problem, a novel algorithm based on the machine learning framework of conceptor-based echo state networks (ESNs) is proposed. Using ESNs, the network can effectively predict each user's content request distribution and its mobility pattern when limited information on the states of users and the network is available. Based on the predictions of the users' content request distribution and their mobility patterns, we derive the optimal locations of UAVs as well as the content to cache at UAVs. Simulation results using real pedestrian mobility patterns from BUPT and actual content transmission data from Youku show that the proposed algorithm can yield 33.3% and 59.6% gains, respectively, in terms of the average transmit power and the percentage of the users with satisfied QoE compared with a benchmark algorithm without caching and a benchmark solution without UAVs.",autonomous vehicle
10.1109/TSG.2020.2970156,filtered,IEEE Transactions on Smart Grid,IEEE,2020-07-01 00:00:00,ieeexplore,Intelligent Damage Classification and Estimation in Power Distribution Poles Using Unmanned Aerial Vehicles and Convolutional Neural Networks,https://ieeexplore.ieee.org/document/8972612/,"Damage estimation is part of daily operation of power utilities, often requiring a manual process of crew deployment and damage report to quantify and locate damages. Advancement in unmanned aerial vehicles (UAVs) as well as real-time communication and learning technologies could be harnessed towards efficient and accurate automation of this process. This paper develops a model to automate the process of estimating and localizing damages in power distribution poles, which utilizes the images taken by UAVs transferred in real-time to an intelligent damage classification and estimation (IDCE) unit. The IDCE unit integrates four convolutional neural networks to learn the states of poles from images, extract the image characteristics, and train an automated intelligent tool to replace manual fault location and damage estimation. The proposed model first determines the type of pole damages, including falling and burning, and then estimates the percentage of damage in each type. The IDCE unit also localizes damages in the poles by locating possible burning or arcing parts. A data set of 1615 images is utilized to train, validate and test the proposed model, which demonstrates high accuracy of the model in classifying and estimating damages in distribution poles.",autonomous vehicle
10.1109/ICCC47050.2019.9064450,filtered,2019 IEEE 5th International Conference on Computer and Communications (ICCC),IEEE,2019-12-09 00:00:00,ieeexplore,3D Deployment of Multi-UAV for Energy-Saving: A Game-Based Learning Approach,https://ieeexplore.ieee.org/document/9064450/,"In this paper, we investigate the problem of three-dimensional (3D) coverage deployment of unmanned aerial vehicles (UAVs). The downlink scenario of air-to-ground communication networks is considered, where UAVs are supposed to maximize the coverage utility of mission area with minimal transmission power. We decompose the problem into two sub-problems, which are UAV deployment and power allocation, respectively. In the first sub-problem, we adjust the 3D locations of UAVs to maximize the coverage utility. In the second sub-problem, we adjust the transmission power to maximize the energy efficiency. By constructing marginal utility function, we prove that these two problems are exact potential games (EPG) and exist Nash equilibrium (NE) points. After that, an algorithm based on binary log-linear learning is proposed to achieve the NE point. The simulation results verify the efficiency of the algorithm and the stability of the model.",autonomous vehicle
10.1109/PIMRC48278.2020.9217205,filtered,"2020 IEEE 31st Annual International Symposium on Personal, Indoor and Mobile Radio Communications",IEEE,2020-09-03 00:00:00,ieeexplore,A Fast Deployment Strategy for UAV Enabled Network Based on Deep Learning,https://ieeexplore.ieee.org/document/9217205/,"In this paper, a fast deployment strategy of unmanned aerial vehicles (UAVs) served as base stations (BSs) in an object region is investigated. To be specific, it solves a problem of how to find proper BSs position for multi-UAV as quickly as possible, and it also achieves the goal of maximizing the sum of downlink rates in a communication network. For this purpose, we design a geographical position information learning (GPI-Learning) algorithm to learn the GPI relationship between users and UAVs. This approach consumes less time by avoiding calculation of exact channels and fills a gap existed in the scenario of setting multi-UAV rapidly to serve multi-user. Without loss of generality, we apply GPI-Learning in different scenarios, such as changes in user number or area size. As for different area size, simulation reveals that a proper size is adequate to any smaller size on condition that the smaller size is included in training set. Numerical results witness the good performance of our proposed algorithm.",autonomous vehicle
10.1109/VTCFall.2019.8891286,filtered,2019 IEEE 90th Vehicular Technology Conference (VTC2019-Fall),IEEE,2019-09-25 00:00:00,ieeexplore,A Game Approach for Distributed Channel Selection in UAV Communication Networks,https://ieeexplore.ieee.org/document/8891286/,"Due to the low cost, easy deployment and high flexibility, unmanned aerial vehicles (UAVs) have attracted much attention for civil and military applications. In this paper, we investigate the problem of channel selection for multiple UAV clusters where UAVs work cooperatively to accomplish tasks in a large area. Firstly, the problem is formulated as a game model to minimize the aggregate interference and decrease channel switching cost. Secondly, we prove the game is an exact potential game which ensures the existence of Nash equilibrium (NE). Thirdly, we solve the game using a distributed way and propose two learning methods with different update rules. Finally, we verify the optimality of proposed algorithms. Comparing with the traditional baseline scheme, we demonstrate the effectiveness of proposed algorithms.",autonomous vehicle
10.1109/ICCWorkshops50388.2021.9473768,filtered,2021 IEEE International Conference on Communications Workshops (ICC Workshops),IEEE,2021-06-23 00:00:00,ieeexplore,A Reinforcement Learning Algorithm for Data Collection in UAV-aided IoT Networks with Uncertain Time Windows,https://ieeexplore.ieee.org/document/9473768/,"Unmanned aerial vehicles (UAVs) have been considered as an efficient solution to collect data from ground sensor nodes in Internet-of-Things (IoT) networks due to their several advantages such as flexibility, quick deployment and maneuverability. Studies on this subject have been mainly focused on problems where limited UAV battery is introduced as a tight constraint that shortens the mission time in the models, which significantly undervalues the UAV potential. Moreover, the sensors in the network are typically assumed to have deterministic working times during which the data is uploaded. In this study, we revisit the UAV trajectory planning problem with a different approach and revise the battery constraint by allowing UAVs to swap their batteries at fixed stations and continue their data collection task, hence, the planning horizon can be extended. In particular, we develop a discrete time Markov process (DTMP) in which the UAV trajectory and battery swapping times are jointly determined to minimize the total data loss in the network, where the sensors have uncertain time windows for uploading. Due to the so-called curse-of-dimensionality, we propose a reinforcement learning (RL) algorithm in which the UAV is trained as an agent to explore the network. The computational study shows that our proposed algorithm outperforms two benchmark approaches and achieves significant reduction in data loss.",autonomous vehicle
10.1109/ATNAC.2018.8615400,filtered,2018 28th International Telecommunication Networks and Applications Conference (ITNAC),IEEE,2018-11-23 00:00:00,ieeexplore,A Reinforcement Learning Based User Association Algorithm for UAV Networks,https://ieeexplore.ieee.org/document/8615400/,"There have been increasing interests in employing unmanned aerial vehicles (UAVs) such as drones for telecommunication purpose. In such networks, UAVs act as base stations and provide downloading service to users. Compared with conventional terrestrial base stations, such UAV-BSs can dynamically adjust their locations to improve network performance. However, there exists two important issues in UAV networks, handoff overhead and UAV deployment. The handoff overhead issue is particularly important for UAVs because UAV BSs are connected to cellular BSs via wireless backhaul links, which are costly in terms of spectrum usage and energy consumption. Hence, it is highly desirable to eliminate any unnecessary handoff to minimise the waste of wireless backhaul. The UAV deployment, on the other hand, introduces a new tool for radio resource management, since BS positions are open for network optimisation. In this paper, a smart user association algorithm, named reinforcement learning handoff (RLH), is devised to reduce redundant handoffs in UAV networks and two methods of UAV mobility control are designed to co-operate with the proposed RLH algorithm to optimise the system throughput. In the RLH algorithm, users perform handoffs according to the reward of a reinforcement learning process. In UAV deployment two UAV mobility control methods are proposed respectively base on the SNR estimation and based on the K-Means approach. According to our simulation results, the RLH algorithm can reduce the number of handoffs by 75%.",autonomous vehicle
10.1109/VTC2020-Fall49728.2020.9348512,filtered,2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall),IEEE,2020-12-16 00:00:00,ieeexplore,Adaptive Deployment of UAV-Aided Networks Based on Hybrid Deep Reinforcement Learning,https://ieeexplore.ieee.org/document/9348512/,"Unmanned aerial vehicles (UAVs) can be used as air base stations to provide fast wireless connections for ground users. Due to their constraints on both mobility and energy consumption, a key problem is how to deploy UAVs adaptively in a geographic area with changing traffic demand of mobile users, while meeting the aforemetioned constraints. In this paper, we propose an adaptive deployment strategy for UAV-aided networks based on hybrid deep reinforcement learning, where a UAV can adjust its movement direction and distance to serve users who move randomly in the target area. Through hybrid deep reinforcement learning, UAVs can be trained offline to obtain the global state information and learn a completely distributed control strategy, with which each UAV only needs to take actions based on its observed state in the real deployment to be fully adaptive. Moreover, in order to improve the speed and effect of learning, we improve hybrid reinforcement learning, by adding genetic algorithms and TD-error-based resampling optimization mechanism. Simulation results show that the hybrid deep reinforcement learning algorithm has better efficiency and robustness in multi-UAV control, and has better performance in terms of coverage, energy consumption and average throughput, by which average throughput can be increased by 20% to 60%.",autonomous vehicle
10.1109/ECMR50962.2021.9568788,filtered,2021 European Conference on Mobile Robots (ECMR),IEEE,2021-09-03 00:00:00,ieeexplore,Adaptive Path Planning for UAV-based Multi-Resolution Semantic Segmentation,https://ieeexplore.ieee.org/document/9568788/,"In this paper, we address the problem of adaptive path planning for accurate semantic segmentation of terrain using unmanned aerial vehicles (UAVs). The usage of UAVs for terrain monitoring and remote sensing is rapidly gaining momentum due to their high mobility, low cost, and flexible deployment. However, a key challenge is planning missions to maximize the value of acquired data in large environments given flight time limitations. To address this, we propose an online planning algorithm which adapts the UAV paths to obtain high-resolution semantic segmentations necessary in areas on the terrain with fine details as they are detected in incoming images. This enables us to perform close inspections at low altitudes only where required, without wasting energy on exhaustive mapping at maximum resolution. A key feature of our approach is a new accuracy model for deep learning-based architectures that captures the relationship between UAV altitude and semantic segmentation accuracy. We evaluate our approach on the application of crop/weed segmentation in precision agriculture using real-world field data.",autonomous vehicle
10.1109/ATNAC.2017.8215356,filtered,2017 27th International Telecommunication Networks and Applications Conference (ITNAC),IEEE,2017-11-24 00:00:00,ieeexplore,Adaptive data transfer methods via policy evolution for UAV swarms,https://ieeexplore.ieee.org/document/8215356/,"This paper presents an adaptive robotic swarm of Unmanned Aerial Vehicles (UAVs) enabling communications between separated non-swarm devices. The swarm nodes utilise machine learning and hyper-heuristic policy evolution to provide agility within the swarm, enabling each swarm member to select the most appropriate mobility policy for the environment given the swarm's abilities. The swarm evolution process of this study is found to successfully create different data transfer methods depending on the separation of non-swarm devices and the communication range of the swarm members. These methods are either human-designed, which the swarm adopts when most appropriate, or are novel hybridisations that the swarm creates for the problem. This paper also tests the swarm with individuals being removed during deployment. It is found that the swarm is immune to most alterations, though removal of specialised members of the heterogeneous swarm leads to temporary failure. The swarm evolution can then correct this failure by adjusting the swarm behaviour.",autonomous vehicle
10.1109/ICC40277.2020.9148788,filtered,ICC 2020 - 2020 IEEE International Conference on Communications (ICC),IEEE,2020-06-11 00:00:00,ieeexplore,An Actor-Critic-Based UAV-BSs Deployment Method for Dynamic Environments,https://ieeexplore.ieee.org/document/9148788/,"In this paper, the real-time deployment of unmanned aerial vehicles (UAVs) as flying base stations (BSs) for optimizing the throughput of mobile users is investigated for UAV networks. This problem is formulated as a time-varying mixed-integer non-convex programming (MINP) problem, which is challenging to find an optimal solution in a short time with conventional optimization techniques. Hence, we propose an actor-critic-based (AC-based) deep reinforcement learning (DRL) method to find near-optimal UAV positions at every moment. In the proposed method, the process searching for the solution iteratively at a particular moment is modeled as a Markov decision process (MDP). To handle infinite state and action spaces and improve the robustness of the decision process, two powerful neural networks (NNs) are configured to evaluate the UAV position adjustments and make decisions, respectively. Compared with heuristic algorithm, sequential least-squares programming and fixed UAVs methods, simulation results have shown that the proposed method outperforms these three benchmarks in terms of the throughput at every moment in UAV networks.",autonomous vehicle
10.15439/2021F001,filtered,2021 16th Conference on Computer Science and Intelligence Systems (FedCSIS),IEEE,2021-09-05 00:00:00,ieeexplore,An Efficient Connected Swarm Deployment via Deep Learning,https://ieeexplore.ieee.org/document/9555749/,"In this paper, an unmanned aerial vehicles (UAVs) deployment framework based on machine learning is studied. It aims to maximize the sum of the weights of the ground users covered by UAVs while UAVs forming a connected communication graph. We focus on the case where the number of UAVs is not necessarily enough to cover all ground users.We develop an UAV Deployment Deep Neural network (UD-DNNet) as a UAV’s deployment deep network method. Simulation results demonstrate that UDDNNet can serve as a computationally inexpensive replacement for traditionally expensive optimization algorithms in real-time tasks and outperform the state-of-the-art traditional algorithms.",autonomous vehicle
10.1109/WCNC.2019.8885648,filtered,2019 IEEE Wireless Communications and Networking Conference (WCNC),IEEE,2019-04-18 00:00:00,ieeexplore,An Intelligent UAV Deployment Scheme for Load Balance in Small Cell Networks Using Machine Learning,https://ieeexplore.ieee.org/document/8885648/,"In wireless networks, network load can be highly unbalanced due to the mobility of user equipments (UEs). Unmanned Aerial Vehicles (UAVs) supported base station with the advantage of flexible deployment, ubiquitous wireless coverage and high speed data rate, is a promising approach to handle with the foregoing problem. However, how to achieve cost-effective UAV deployment in an autonomous and dynamic manner is a significant challenge. Facing this problem, we propose a novel UAV base station intelligent deployment scheme based on machine learning and evaluate its performance on a realworld dataset. First, we conduct data preprocessing to process, clean, and transform raw data into formatted data. Missing values are filled by Conditional Mean Imputation (CMI) method and outliers are corrected by pauta criterion. Then, we use hybrid approach which contains ARIMA model and XGBoost model. Linear predictions are carried out by ARIMA model and later nonlinear model XGBoost are applied on residue of ARIMA. Resultant prediction is obtained by adding linear and nonlinear prediction, hybrid model is estimated by Root Mean Square Error (RMSE) and R2 score. Finally, according to predicted results, UAV base stations can be deployed to cater for dynamically changing demands in the hotspot areas and achieve cost-effective deployment. Simulation results show that the propose scheme is superior to other benchmark schemes in load balancing.",autonomous vehicle
10.1109/DCOSS.2019.00111,filtered,2019 15th International Conference on Distributed Computing in Sensor Systems (DCOSS),IEEE,2019-05-31 00:00:00,ieeexplore,An Open Source and Open Hardware Deep Learning-Powered Visual Navigation Engine for Autonomous Nano-UAVs,https://ieeexplore.ieee.org/document/8804776/,"Nano-size unmanned aerial vehicles (UAVs), with few centimeters of diameter and sub-10 Watts of total power budget, have so far been considered incapable of running sophisticated visual-based autonomous navigation software without external aid from base-stations, ad-hoc local positioning infrastructure, and powerful external computation servers. In this work, we present what is, to the best of our knowledge, the first 27g nano-UAV system able to run aboard an end-to-end, closed-loop visual pipeline for autonomous navigation based on a state-of-the-art deep-learning algorithm, built upon the open-source CrazyFlie 2.0 nano-quadrotor. Our visual navigation engine is enabled by the combination of an ultra-low power computing device (the GAP8 system-on-chip) with a novel methodology for the deployment of deep convolutional neural networks (CNNs). We enable onboard real-time execution of a state-of-the-art deep CNN at up to 18Hz. Field experiments demonstrate that the system's high responsiveness prevents collisions with unexpected dynamic obstacles up to a flight speed of 1.5m/s. In addition, we also demonstrate the capability of our visual navigation engine of fully autonomous indoor navigation on a 113m previously unseen path. To share our key findings with the embedded and robotics communities and foster further developments in autonomous nano-UAVs, we publicly release all our code, datasets, and trained networks.",autonomous vehicle
10.1109/ICTC49870.2020.9289536,filtered,2020 International Conference on Information and Communication Technology Convergence (ICTC),IEEE,2020-10-23 00:00:00,ieeexplore,Applications and Challenges in Video Surveillance via Drone: A Brief Survey,https://ieeexplore.ieee.org/document/9289536/,"Our society is moving quickly towards smart homes and smart cities, requiring more and more deployment of Internet of Things (IoT) devices. To achieve smart urbanization, continuous surveillance is necessary. Research about video surveillance via Closed-Circuit Television (CCTV) cameras is in play for decades but poses different problems, i.e., limited area coverage, no location sharing, and tracking capabilities. On the other hand, vision sensors mounted on drones are more scalable and flexible with more comprehensive surveillance coverage. But at the same time, drones also encounter several challenges, such as limited processing and power resources, trembling camera effects in the video feed, disturbance in transmission signals, etc. Drones surveillance lacks the researcher's attentiveness, and therefore, we collect the related literature and confer their practical viewpoint broadly. This article focuses on video surveillance using drones in object detection and tracking, video summarization, persistent monitoring of the target, search and rescue operation in a hostile environment, traffic management in smart cities, and disaster management in an apocalyptic situation. This brief survey sheds light on the research gaps and profound insights of the methods used in the mentioned articles by opening up future research tracks for the Computer Vision (CV) enthusiasts using Unmanned Aerial Vehicles (UAV).",autonomous vehicle
10.1109/VTC2020-Fall49728.2020.9348719,filtered,2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall),IEEE,2020-12-16 00:00:00,ieeexplore,BLOCK-ML: Blockchain and Machine Learning for UAV-BSs Deployment,https://ieeexplore.ieee.org/document/9348719/,"Unmanned aerial vehicles (UAVs) are expected to be extensively used as an integral part in the future generations of communication networks, to provide ubiquitous connectivity. The mobile nature of UAVs make them a tempting candidate to provide seamless connectivity in environments where the installation of conventional terrestrial base stations (BS) is not feasible. Nonetheless, there are major deployment issues related to optimal placement of UAV-mounted base stations (UAV-BSs) due to limited number of UAV-BSs, limited energy availability and trade-off between coverage area and its altitude. In this paper, we address UAV-BSs placement issues by proposing a novel Machine learning (ML) based intelligent deployment mechanism. More specifically, for intelligent deployment of UAV-BSs based on energy, computational power, nature of available data and criticality of the scenario, we use two different approaches: Support Vector Machine (SVM) and Deep Learning (DL), which is composed of sequential time series learning process. Moreover, to address the security and privacy challenges emanating from the wireless connectivity and untrusted broadcast nature of UAV-BSs, we propose a Blockchain-based novel information-sharing scheme. To evaluate the performance of our combined secure and intelligent proposed approach, we have improved energy consumption by almost twice in contrast with the normal deployment of UAV-BSs.",autonomous vehicle
10.1109/ICCES51350.2021.9488948,filtered,2021 6th International Conference on Communication and Electronics Systems (ICCES),IEEE,2021-07-10 00:00:00,ieeexplore,Block Chain-based access control and intrusion detection system in IoD,https://ieeexplore.ieee.org/document/9488948/,"The Internet of Drones (IoD), a layered network, has attracted more attention among the research community due to its wide range of applications, such as packet transmission, rescue operations, traffic surveillance, and so on. Various drones known as Unmanned Aerial Vehicles (UAVs) are deployed in various flying zones to transmit important information to the Ground station server (GSS). Hence, secure transmission is the major challenging aspect of IoD. Hence, this paper introduces a novel technique for secure transmission in IoD by effective blockchain-assisted access control and intrusion detection approach using the newly devised Deep Neuro-Fuzzy Network system. Typically, Blockchain-based access control consists of mainly four phases, like pre-deployment, registration, authentication, and access control phase for transferring the crucial information in the IoD environment. Besides, intrusion in IoD is detected using the proposed Deep Neuro-Fuzzy Network. However, the proposed approach achieved a minimum delay of 1.253, a maximum precision rate of 88.375, and a maximum recall measure of 89.263 while considering the Neptune attack.",autonomous vehicle
10.1109/AECT47998.2020.9194188,filtered,2019 International Conference on Advances in the Emerging Computing Technologies (AECT),IEEE,2020-02-10 00:00:00,ieeexplore,Clustering Based UAV Base Station Positioning for Enhanced Network Capacity,https://ieeexplore.ieee.org/document/9194188/,"Unmanned aerial vehicles (UAVs) are expected to be deployed in a variety of applications in future mobile networks due to several advantages they bring over the deployment of ground base stations. However, despite the recent interest in UAVs in mobile networks, some issues still remain, such as determining the placement of multiple UAVs in different scenarios. In this paper we propose a solution to determine the optimal 3D position of multiple UAVs in a capacity enhancement use-case, or in other words, when the ground network cannot cope with the user traffic demand. For this scenario, real data from the city of Milan, provided by Telecom Italia is utilized to simulate an event. Based on that, a solution based on k-means, a machine learning technique, to position multiple UAVs is proposed and it is compared with two other baseline methods. Results demonstrate that the proposed solution is able to significantly outperform other methods in terms of users covered and quality of service.",autonomous vehicle
10.1109/DASC43569.2019.9081802,filtered,2019 IEEE/AIAA 38th Digital Avionics Systems Conference (DASC),IEEE,2019-09-12 00:00:00,ieeexplore,Cost-Effective NLOS Detection for Privacy Invasion Attacks by Consumer Drones,https://ieeexplore.ieee.org/document/9081802/,"The pervasive operation of customer drones, or small-scale unmanned aerial vehicles (UAVs), has raised serious concerns about their privacy threats to the public. In recent years, privacy invasion events caused by customer drones have been frequently reported. Given such a fact, timely detection of invading drones has become an emerging task. Existing solutions using active radar, video or acoustic sensors are usually too costly (especially for individuals) or exhibit various constraints (e.g., requiring visual line of sight). Recent research on drone detection with passive RF signals provides an opportunity for low-cost deployment of drone detectors on commodity wireless devices. However, the state of the arts in this direction rely on line-of-sight (LOS) RF signals, which makes them only work under very constrained conditions. The support of more common scenarios, i.e., non-line-of-sight (NLOS), is still missing for low-cost solutions. In this paper, we propose a novel detection system for privacy invasion caused by customer drone. Our system is featured with accurate NLOS detection with low-cost hardware (under $50). By exploring and validating the relationship between drone motions and RF signal under the NLOS condition, we find that RF signatures of drones are somewhat “amplified” by multipaths in NLOS. Based on this observation, we design a two-step solution which first classifies received RSS measurements into LOS and NLOS categories; deep learning is then used to extract the signatures and ultimately detect the drones. Our experimental results show that LOS and NLOS signals can be identified at accuracy rates of 98.4% and 96% respectively. Our drone detection rate for NLOS condition is above 97% with a system implemented using Raspberry PI 3 B+.",autonomous vehicle
10.1109/ISC2.2018.8656971,filtered,2018 IEEE International Smart Cities Conference (ISC2),IEEE,2018-09-19 00:00:00,ieeexplore,Coupling Deep Learning and UAV for Infrastructure Condition Assessment Automation,https://ieeexplore.ieee.org/document/8656971/,"We propose coupling the state-of-the-art computer technology deep learning and unmanned aerial vehicles (UAV) to automatically detect and assess the health condition of civil infrastructure such as bridges and pavements. UAV carrying high resolution camera and infrared thermography camera to collect a large amount of image data from the target infrastructure, which serves as inputs of trained deep neural networks for damage classification and condition assessment. Details of the framework that may guide the automation process are explained. We demonstrated preliminary application of using UAV and deep neural network in concrete crack and asphalt pavement distress classification. Challenges and needs for deployment of UAV and deep learning are briefly discussed in the end.",autonomous vehicle
10.1109/CISCE52179.2021.9445927,filtered,"2021 International Conference on Communications, Information System and Computer Engineering (CISCE)",IEEE,2021-05-16 00:00:00,ieeexplore,Deep Learning Based Robust Beamforming for UAV Communication System,https://ieeexplore.ieee.org/document/9445927/,"Unmanned aerial vehicles (UAVs) have shown its application potentiality in communication system because of its inherent mobility and ease of organization. In this paper, we develop a robust beamforming method for an UAV communication system by deep learning (DL), in which a eavesdropping UAV attempts to wiretap the confidential transmission. Specifically, by modeling the legitimate channel and eavesdropping channel undergo Rician fading, a robust beamforming neural network (RBNN) is trained to maximize the average secrecy rate. Both perfect and imperfect channel state information (CSI) are used to train the RBNN in the off-line train stage, then all weights are fixed for on-line deployment stage with only imperfect CSI. Simulation results verify that the proposed DL based beamforming method outperforms benchmark beamforming methods with imperfect legitimate CSI and eavesdropper CSI, and generalization ability of the trained RBNN is shown. Last but not least, the proposed beamforming method is still effective while the eavesdropper CSI is completely unknown.",autonomous vehicle
10.1109/WCSP.2019.8928091,filtered,2019 11th International Conference on Wireless Communications and Signal Processing (WCSP),IEEE,2019-10-25 00:00:00,ieeexplore,Deep RL-based Trajectory Planning for AoI Minimization in UAV-assisted IoT,https://ieeexplore.ieee.org/document/8928091/,"Due to the flexibility and low deployment cost, unmanned aerial vehicles (UAVs) have been widely used to assist cellular networks in providing extended coverage for Internet of Things (IoT) networks. Existing throughput or delay-based UAV trajectory planning methods cannot meet the requirement of collecting fresh information from IoT devices. In this paper, by taking age-of-information (AoI) as a measure of information freshness, we investigate AoI-based UAV trajectory planning for fresh data collection. To model the complicated association and interaction pattern between UAV and IoT devices, the UAV trajectory planning problem is formulated as a Markov decision process (MDP) to capture the dynamics of UAV locations. As network topology and traffic generation pattern are unknown ahead, we propose an AoI-based trajectory planning (A-TP) algorithm using deep reinforcement learning (RL) technique. To accelerate the learning process during online decision making, the off-line pre-training of deep neural networks is performed. Extensive simulation results demonstrate that the proposed algorithm can significantly reduce the AoI of collected IoT data, as compared to other benchmark approaches.",autonomous vehicle
10.1109/GLOBECOM38437.2019.9013924,filtered,2019 IEEE Global Communications Conference (GLOBECOM),IEEE,2019-12-13 00:00:00,ieeexplore,Deep Reinforcement Learning for Minimizing Age-of-Information in UAV-Assisted Networks,https://ieeexplore.ieee.org/document/9013924/,"Unmanned aerial vehicles (UAVs) are expected to be a key component of the next-generation wireless systems. Due to their deployment flexibility, UAVs are being considered as an efficient solution for collecting information data from ground nodes and transmitting it wirelessly to the network. In this paper, a UAV-assisted wireless network is studied, in which energy-constrained ground nodes are deployed to observe different physical processes. In this network, a UAV that has a time constraint for its operation due to its limited battery, moves towards the ground nodes to receive status update packets about their observed processes. The flight trajectory of the UAV and scheduling of status update packets are jointly optimized with the objective of achieving the minimum weighted sum for the age- of-information (AoI) values of different processes at the UAV, referred to as weighted sum-AoI. The problem is modeled as a finite- horizon Markov decision process (MDP) with finite state and action spaces. Since the state space is extremely large, a deep reinforcement learning (RL) algorithm is proposed to obtain the optimal policy that minimizes the weighted sum-AoI, referred to as the age-optimal policy. Several simulation scenarios are considered to showcase the convergence of the proposed deep RL algorithm. Moreover, the results also demonstrate that the proposed deep RL approach can significantly improve the achievable sum- AoI per process compared to the baseline policies, such as the distance-based and random walk policies. The impact of various system design parameters on the optimal achievable sum-AoI per process is also shown through extensive simulations.",autonomous vehicle
10.1109/GLOCOMW.2018.8644345,filtered,2018 IEEE Globecom Workshops (GC Wkshps),IEEE,2018-12-13 00:00:00,ieeexplore,Deployment and Movement for Multiple Aerial Base Stations by Reinforcement Learning,https://ieeexplore.ieee.org/document/8644345/,"A novel framework for Quality of experience (QoE)-driven deployment and movement of multiple unmanned aerial vehicles (UAVs) is proposed. The problem of joint non-concave 3D deployment and dynamic movement for maximizing the sum mean opinion score (MOS) of users is formulated, which is proved to be NP-hard. In an effort to solve this problem, we proposed a three-step approach to obtain 3D deployment and dynamic movement of multiple UAVs. More specifically, in the first step, GAK-means algorithm is invoked to obtain the cell partitioning of ground users. Secondly, Q-learning based deployment algorithm is proposed, in which each UAV is considered as an agent, making its own decision to obtain 3D position. In contrast to conventional genetic algorithm based learning algorithms, the proposed algorithm is capable of training the policy of making decision offline. Thirdly, Q-learning algorithm is invoked when the ground users roam. Unlike the other trajectory obtaining algorithms, the proposed approach enables each UAV learn its movement gradually through trials and errors, and updates the direction selection strategy until it reaches convergence. Numerical results reveal that the proposed 3D deployment scheme outperforms K-means algorithm and IGK algorithm with low complexity. Additionally, with the aid of proposed approach, 3D real-time dynamic movement of UAVs is obtained.",autonomous vehicle
10.1109/ETFA.2015.7301549,filtered,2015 IEEE 20th Conference on Emerging Technologies & Factory Automation (ETFA),IEEE,2015-09-11 00:00:00,ieeexplore,Design and implementation for multiple-robot deployment in intelligent space,https://ieeexplore.ieee.org/document/7301549/,"This paper presents the problem of robot deployment for a number of scattered tasks. We aim to minimize the duration it takes for all robots to reach their assigned task locations. In previous work, we have proposed a team composed of one carrier robot (CR) and several servant robots to accomplish the mission. Then we have suggested an algorithm that determines a path of the CR for an efficient deployment under a few constraints, which is verified by simulations. Assuming that the servant robots are unmanned aerial vehicles (UAVs), the present paper extends the discussion to a real robot experiment. We design and implement a deployment system in intelligent space. The feasibility of the study is demonstrated through an experiment.",autonomous vehicle
10.23919/DATE.2018.8342149,filtered,"2018 Design, Automation & Test in Europe Conference & Exhibition (DATE)",IEEE,2018-03-23 00:00:00,ieeexplore,DroNet: Efficient convolutional neural network detector for real-time UAV applications,https://ieeexplore.ieee.org/document/8342149/,"Unmanned Aerial Vehicles (drones) are emerging as a promising technology for both environmental and infrastructure monitoring, with broad use in a plethora of applications. Many such applications require the use of computer vision algorithms in order to analyse the information captured from an on-board camera. Such applications include detecting vehicles for emergency response and traffic monitoring. This paper therefore, explores the trade-offs involved in the development of a single-shot object detector based on deep convolutional neural networks (CNNs) that can enable UAVs to perform vehicle detection under a resource constrained environment such as in a UAV. The paper presents a holistic approach for designing such systems; the data collection and training stages, the CNN architecture, and the optimizations necessary to efficiently map such a CNN on a lightweight embedded processing platform suitable for deployment on UAVs. Through the analysis we propose a CNN architecture that is capable of detecting vehicles from aerial UAV images and can operate between 5-18 frames-per-second for a variety of platforms with an overall accuracy of ~ 95%. Overall, the proposed architecture is suitable for UAV applications, utilizing low-power embedded processors that can be deployed on commercial UAVs.",autonomous vehicle
10.1109/AICAS48895.2020.9073885,filtered,2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS),IEEE,2020-09-02 00:00:00,ieeexplore,Efficient Embedded Deep Neural-Network-based Object Detection Via Joint Quantization and Tiling,https://ieeexplore.ieee.org/document/9073885/,"Embedded visual AI is a growing trend in applications requiring low latency, real-time decision support, increased robustness and security. Visual object detection, a key task in visual data analytics, has enjoyed significant improvements in terms of capabilities and accuracy due to the emergence of Convolutional Neural Networks (CNNs). However, such complex paradigms require heavy computational resources that prevent their deployment on resource-constrained devices, and in particular, impose significant constraints in possible hardware accelerators geared towards such applications. In this work therefore, we investigate how a combination of techniques can lead to efficient visual AI pipelines for resource-constrained object detection. In particular we leverage an efficient search strategy based on a combination of pre-processing mechanisms, that reduce the processing demands of deep network as a counter measure for potential accuracy reduction caused by quantization. The proposed approach enables the detection of objects in higher resolution frames using quantized models, while maintaining the accuracy of full-precision CNN-based object detectors. We illustrate the impact on the accuracy and average processing time using quantization techniques and different tiling approaches on efficient object detection architectures; as a case study, we focus on Unmanned-Aerial- Vehicles (UAVs). Through the proposed methodology, hardware accelerator demands are thereby reduced, leading to both performance benefits and associated power savings.",autonomous vehicle
10.1109/VTCSpring.2018.8417735,filtered,2018 IEEE 87th Vehicular Technology Conference (VTC Spring),IEEE,2018-06-06 00:00:00,ieeexplore,Energy-Aware 3D Aerial Small-Cell Deployment over Next Generation Cellular Networks,https://ieeexplore.ieee.org/document/8417735/,"One viable and cost-effective method to fulfill the ever-increasing mobile broadband traffic and to achieve coverage and capacity improvement is the employment of mobile small cells in next generation cellular networks. Being agile and resilient, aerial small cells (ASCs), which are small cells mounted on unmanned aerial vehicles (UAVs), are deemed promising platforms for the provision of wireless services. Since the lifetime of an airborne network highly depends on the residual battery capacity available to each ASC, it is essential to account for the energy expenditure on various flying actions in a flight plan. Therefore, the focus of this paper is to study the 3D deployment problem for a swarm of ASCs, in which a trade-off among flight altitudes, energy expenses and available lifetimes is observed. The objective is to maximize the total throughput of all users. We formulate the problem as a non-convex non-linear optimization problem and propose an energy-aware 3D deployment algorithm to resolve it with the aid of Lagrangian dual relaxation, interior-point and subgradient projection methods. We then conduct a series of simulations to evaluate the performance of our proposed algorithm. Simulation results manifest that our proposed algorithm can bring tremendous increase in the total throughput for all users by properly coping with the trade-off, compared to the two user-aware approaches with random and minimum altitude assignments.",autonomous vehicle
10.1109/GLOBECOM42002.2020.9322292,filtered,GLOBECOM 2020 - 2020 IEEE Global Communications Conference,IEEE,2020-12-11 00:00:00,ieeexplore,Energy-Efficient UAV Deployment and IoT Device Association in Fixed-Wing Multi-UAV Networks,https://ieeexplore.ieee.org/document/9322292/,"This work examines the deployment of multiple fixed-wing unmanned aerial vehicles (UAVs) for data-gathering from ground IoT devices, and the corresponding device association policy. Each UAV is assumed to hover above its associated devices following a circular trajectory. The device association and the UAVs' trajectory centers and radii are jointly optimized to maximize the energy-savings relative to a constant transmission power scheme. Given the trajectory centers and radii, the device association problem is modeled as a multiple 0-1 knapsack problem, taking into consideration the load demands of different devices as well as UAVs' service capacities. A two-stage maximum energy-saving device association policy is proposed, where each UAV first solves a single knapsack problem based on all connectable devices, and then resolves conflict with others by a maximum profit assignment. Moreover, given the device association, the UAVs' trajectory centers and radii are optimized by an iterative load-balancing algorithm, where the trajectory centers are chosen as a load-dependent weighted sum of the associated devices' locations. The device association and the UAV deployment are optimized in turn until convergence. Simulation results show that our proposed schemes outperform candidate algorithms in terms of the total energy-savings of IoT devices.",autonomous vehicle
10.1109/ICSensT.2015.7438508,filtered,2015 9th International Conference on Sensing Technology (ICST),IEEE,2015-12-10 00:00:00,ieeexplore,Estimation of UAV position using LiDAR images for autonomous navigation over the ocean,https://ieeexplore.ieee.org/document/7438508/,"The use of autonomous navigation in Unmanned Aerial Vehicles is growing every day, in many areas, due to the low cost of its deployment and also does not require a pilot in a ground station. The most applied technique for autonomous navigation of Unmanned Aerial Vehicles is the joint use of Global Navigation Satellite System with Inertial Navigation System, an alternative for this technique is the autonomous navigation through image processing. To perform the autonomous navigation of Unmanned Aerial Vehicles through image processing are used usually images that has landmarks in the ground to guide the trajectory. But, still is a challenge perform the autonomous navigation of Unmanned Aerial Vehicles through image processing, without Global Navigation Satellite System combined with Inertial Navigation System, over regions without landmarks, such as the ocean. Therefore, this research presents a methodology to perform the estimation of Unmanned Aerial Vehicles position in LiDAR images to allow that it performs the autonomous navigation over the ocean.",autonomous vehicle
10.1109/ICCWorkshops49005.2020.9145090,filtered,2020 IEEE International Conference on Communications Workshops (ICC Workshops),IEEE,2020-06-11 00:00:00,ieeexplore,Federated Convolutional Auto-Encoder for Optimal Deployment of UAVs with Visible Light Communications,https://ieeexplore.ieee.org/document/9145090/,"In this paper, the problem of unmanned aerial vehicles (UAV) deployment is investigated for visible light communication (VLC)-enabled UAV networks. Here, UAVs can simul-taneously provide communications and illumination services to ground users. In this model, ambient illumination distribution of the service area must be considered since it can cause interference over the VLC link and affects the illumination requirements of users. This problem is formulated as an optimization problem, which jointly considers UAV deployment, user association, power efficiency, and predictions of the illumination distribution. To solve this problem, we first need to predict illumination distribution to proactively determine the UAV deployment and user association so as to minimize total transmission power of UAVs. To predict the illumination distribution of the entire service area, a federated learning framework based on the machine learning algorithm of convolutional auto-encoder (CAE) is proposed. Compared to the centralized machine learning algorithms that requires complete illumination data for centralized training, the proposed algorithm enables the UAVs to train their local CAE with partial illumination data and cooperatively build a global CAE model that can predict the entire illumination distribution. Using these predictions, the optimal UAV deployment and user association policy that minimizes the total transmission power of UAVs is determined. Simulation results demonstrate that the proposed approach reduces the transmission power of UAVs up to 14.8% and 25.1%, respectively, compared to the local CAE prediction models and the conventional optimal algorithm without illumination distribution predictions.",autonomous vehicle
10.1109/GLOBECOM38437.2019.9014310,filtered,2019 IEEE Global Communications Conference (GLOBECOM),IEEE,2019-12-13 00:00:00,ieeexplore,Gated Recurrent Units Learning for Optimal Deployment of Visible Light Communications Enabled UAVs,https://ieeexplore.ieee.org/document/9014310/,"In this paper, the problem of optimizing the deployment of unmanned aerial vehicles (UAVs) equipped with visible light communication (VLC) capabilities is studied. In the studied model, the UAVs can simultaneously provide communications and illumination to service ground users. Ambient illumination increases the interference over VLC links while reducing the illumination threshold of the UAVs. Therefore, it is necessary to consider the illumination distribution of the target area for UAV deployment optimization. This problem is formulated as an optimization problem whose goal is to minimize the total transmit power while meeting the illumination and communication requirements of users. To solve this problem, an algorithm based on the machine learning framework of gated recurrent units (GRUs) is proposed. Using GRUs, the UAVs can model the longterm historical illumination distribution and predict the future illumination distribution. In order to reduce the complexity of the prediction algorithm while accurately predicting the illumination distribution, a Gaussian mixture model (GMM) is used to fit the illumination distribution of the target area at each time slot. Based on the predicted illumination distribution, the optimization problem is proved to be a convex optimization problem that can be solved by using duality. Simulations using real data from the Earth observations group (EOG) at NOAA/NCEI show that the proposed approach can achieve up to 22.1% reduction in transmit power compared to a conventional optimal UAV deployment that does not consider the illumination distribution. The results also show that UAVs must hover at areas having strong illumination, thus providing useful guidelines on the deployment of VLCenabled UAVs.",autonomous vehicle
10.1109/IROS40897.2019.8967722,filtered,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),IEEE,2019-11-08 00:00:00,ieeexplore,Informed Region Selection for Efficient UAV-based Object Detectors: Altitude-aware Vehicle Detection with CyCAR Dataset,https://ieeexplore.ieee.org/document/8967722/,"Deep Learning-based object detectors enhance the capabilities of remote sensing platforms, such as Unmanned Aerial Vehicles (UAVs), in a wide spectrum of machine vision applications. However, the integration of deep learning introduces heavy computational requirements, preventing the deployment of such algorithms in scenarios that impose low-latency constraints during inference, in order to make mission-critical decisions in real-time. In this paper, we address the challenge of efficient deployment of region-based object detectors in aerial imagery, by introducing an informed methodology for extracting candidate detection regions (proposals). Our approach considers information from the UAV on-board sensors, such as flying altitude and light-weight computer vision filters, along with prior domain knowledge to intelligently decrease the number of region proposals by eliminating false-positives at an early stage of the computation, reducing significantly the computational workload while sustaining the detection accuracy. We apply and evaluate the proposed approach on the task of vehicle detection. Our experiments demonstrate that state-of-the-art detection models can achieve up to 2.6x faster inference by employing our altitude-aware data-driven methodology. Alongside, we introduce and provide to the community a novel vehicle-annotated and altitude-stamped dataset of real UAV imagery, captured at numerous flying heights under a wide span of traffic scenarios.",autonomous vehicle
10.1109/VLSI-SoC.2017.8203456,filtered,2017 IFIP/IEEE International Conference on Very Large Scale Integration (VLSI-SoC),IEEE,2017-10-25 00:00:00,ieeexplore,Intelligent embedded and real-time ANN-based motor control for multi-rotor unmanned aircraft systems,https://ieeexplore.ieee.org/document/8203456/,"Constant technological advancements in commercial multirotor unmanned aerial vehicles (drones) resulted in their deployment in more and more applications, ranging from entertainment to disaster management and many more domains. However, in contrast to their powerful and diverse entrance into our lifestyle and society, they do not yet provide sufficient intrinsic fail-safe mechanisms to prevent accidents that may occur due to technical problems or unforeseen flight incidents such as turbulent winds, inexperienced pilots, and so on. Therefore, in the current study, we propose the use of an integrated intelligent motor controller, which is trained to recognize incidents directly from the on-board sensors (barometer, gyroscope, compass and accelerometer) and react in real-time, adjusting the drone's motors. The goal is to provide a small, intelligent, low-power, real-time, built-in controller for multirotor UAVs that will be able to understand a dangerous scenario right before it happens, start taking counter measures to keep the drone safe, and provide the pilot with a bigger reaction-time window. We propose the use of an artificial neural network, implemented in a lightweight embedded processing board, that is able to recognize and react in real-time to various turbulent situations. Experimental results suggest that our controller is able to respond properly and timely to wind changes (turbulence) allowing the drone to maintain its expected state and path.",autonomous vehicle
10.1109/ICCWorkshops49005.2020.9145105,filtered,2020 IEEE International Conference on Communications Workshops (ICC Workshops),IEEE,2020-06-11 00:00:00,ieeexplore,Joint Trajectory and Power Optimization in Multi-Type UAVs Network with Mean Field Q-Learning,https://ieeexplore.ieee.org/document/9145105/,"Unmanned aerial vehicles (UAVs) are expected to meet the requirements of diverse and efficient communication in the future, which act as aerial base stations (ABSs) with a better line-of-sight communication channels in air-to-ground communication networks. However, resource allocation, interference management and path planning of UAV ABSs have become a series of challenging problems. In this paper, trajectory design and downlink power control of multi-type UAV ABSs are jointly investigated. In order to meet the signal to interference plus noise ratio (SINR) requirements of users, each UAV ABS needs to adjust its position and transmission power. We propose a non-cooperative mean-field-type game (MFTG) model to jointly optimize the trajectory and transmission power of UAV ABS based on the interactions among multiple communication links. In order to simplify the problem, we cluster the users in the given area to get the initial deployment of the UAV ABSs. Furthermore, the discrete MFTG problem is solved by the proposed mean field Q (MFQ)-learning algorithm. Simulation results show that the proposed approach can converge to the equilibrium solution, and reduce the energy cost of each UAV ABS effectively with satisfying the SINR.",autonomous vehicle
10.1109/PIMRC48278.2020.9217381,filtered,"2020 IEEE 31st Annual International Symposium on Personal, Indoor and Mobile Radio Communications",IEEE,2020-09-03 00:00:00,ieeexplore,Learning in the Sky: Towards Efficient 3D Placement of UAVs,https://ieeexplore.ieee.org/document/9217381/,"Deployment of unmanned aerial vehicles (UAVs) as aerial base stations to support cellular networks can deliver a fast and flexible solution for serving high and varying traffic demand. In order to adequately leverage the benefit of UAVs deployment, their efficient placement is of utmost importance, and requires to intelligently adapt to the environment changes. In this paper, we propose novel learning-based mechanisms for the three-dimensional deployment of UAVs assisting terrestrial networks in the downlink for overloaded situations. The problem is modeled as a game among UAVs. To solve the game, we utilize tools from reinforcement learning, and develop low complexity algorithms based on the multi-armed bandit and satisfaction methods to learn UAVs' locations. Simulation results reveal that the proposed satisfaction based UAV placement algorithm can yield significant performance gains up to about 50% and 41% in terms of throughput and the number of outage users, respectively, compared to a learning based benchmark algorithm.",autonomous vehicle
10.1109/IROS.2018.8594204,filtered,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),IEEE,2018-10-05 00:00:00,ieeexplore,Learning to Fly by MySelf: A Self-Supervised CNN-Based Approach for Autonomous Navigation,https://ieeexplore.ieee.org/document/8594204/,"Nowadays, Unmanned Aerial Vehicles (UAVs)are becoming increasingly popular facilitated by their extensive availability. Autonomous navigation methods can act as an enabler for the safe deployment of drones on a wide range of real-world civilian applications. In this work, we introduce a self-supervised CNN-based approach for indoor robot navigation. Our method addresses the problem of real-time obstacle avoidance, by employing a regression CNN that predicts the agent's distance-to-collision in view of the raw visual input of its on-board monocular camera. The proposed CNN is trained on our custom indoor-flight dataset which is collected and annotated with real-distance labels, in a self-supervised manner using external sensors mounted on an UAV. By simultaneously processing the current and previous input frame, the proposed CNN extracts spatio-temporal features that encapsulate both static appearance and motion information to estimate the robot's distance to its closest obstacle towards multiple directions. These predictions are used to modulate the yaw and linear velocity of the UAV, in order to navigate autonomously and avoid collisions. Experimental evaluation demonstrates that the proposed approach learns a navigation policy that achieves high accuracy on real-world indoor flights, outperforming previously proposed methods from the literature.",autonomous vehicle
10.1109/GCWkshps50303.2020.9367523,filtered,2020 IEEE Globecom Workshops (GC Wkshps,IEEE,2020-12-11 00:00:00,ieeexplore,Machine Learning for Predictive Deployment of UAVs with Rate Splitting Multiple Access,https://ieeexplore.ieee.org/document/9367523/,"In this paper, an unmanned aerial vehicles (UAVs) deployment framework based on machine learning is studied. UAVs are deployed as flying base stations (BSs) to offload heavy traffic from ground BSs. A method of backpropagation neuron network (BP) algorithm is used to predict the future cellular traffic. According to the cellular traffic spatial distribution, a KEG algorithm, which is a joint K-means and expectation maximization (EM) algorithm based on Gaussian mixture model (GMM), is proposed for determining each UAV's service area. The UAV locations are optimized to minimize transmit power in their service area. Three multi-access techniques are compared to minimize the total uplink transmit power. Simulation results show that the proposed method can reduce up to 24% of the total power consumption compared to the conventional method without traffic prediction. Besides, rate splitting multiple access (RSMA) has the lower required transmit power compared to frequency domain multiple access (FDMA) and time domain multiple access (TDMA).",autonomous vehicle
10.1109/GLOCOM.2018.8647209,filtered,2018 IEEE Global Communications Conference (GLOBECOM),IEEE,2018-12-13 00:00:00,ieeexplore,Machine Learning for Predictive On-Demand Deployment of Uavs for Wireless Communications,https://ieeexplore.ieee.org/document/8647209/,"In this paper, a novel machine learning (ML) framework is proposed for enabling a predictive, efficient deployment of unmanned aerial vehicles (UAVs), acting as aerial base stations (BSs), to provide on-demand wireless service to cellular users. In order to have a comprehensive analysis of cellular traffic, an ML framework based on a Gaussian mixture model and a weighted expectation maximization algorithm is introduced to predict the potential network congestion. Then, the optimal deployment of UAVs is studied with the objective of minimizing the power needed for UAV transmission and mobility, given the predicted traffic. To this end, first, the optimal partition of service areas of each UAV is derived, based on a fairness principle. Next, the optimal location of each UAV that minimizes the total power consumption is derived. Simulation results show that the proposed ML approach can reduce power needed for downlink transmission and mobility by over 20% and 80%, respectively, compared with an optimal deployment of UAVs with no ML prediction.",autonomous vehicle
10.1109/VTC2020-Fall49728.2020.9348605,filtered,2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall),IEEE,2020-12-16 00:00:00,ieeexplore,"Machine Learning-Assisted UAV Operations with the UTM: Requirements, Challenges, and Solutions",https://ieeexplore.ieee.org/document/9348605/,"Unmanned aerial vehicles (UAVs) are emerging in commercial spaces and will support many applications, such as smart agriculture, dynamic network deployment, network coverage extension, surveillance and security. The unmanned aircraft system (UAS) traffic management (UTM) provides a framework for safe UAV operation by integrating UAV controllers and central data bases through a communications network. This paper discusses the challenges and opportunities for machine learning (ML) for effectively providing critical UTM services. We introduce the four pillars of UTM-operation planning, situational awareness, failure detection and recovery, and remote identification-and discuss the main services, specific opportunities for ML and the ongoing research. We conclude that the multi-faceted operating environment and operational parameters will benefit from collected data and data-driven algorithms, as well as online learning to support new UAV operation situations.",autonomous vehicle
10.1109/ICCWorkshops49005.2020.9145089,filtered,2020 IEEE International Conference on Communications Workshops (ICC Workshops),IEEE,2020-06-11 00:00:00,ieeexplore,Mobility Management for Cellular-Connected UAVs: A Learning-Based Approach,https://ieeexplore.ieee.org/document/9145089/,"The pervasiveness of the wireless cellular network can be a key enabler for the deployment of autonomous unmanned aerial vehicles (UAVs) in beyond visual line of sight scenarios without human control. However, traditional cellular networks are optimized for ground user equipment (GUE) such as smartphones which makes providing connectivity to flying UAVs very challenging. Moreover, ensuring better connectivity to a moving cellular-connected UAV is notoriously difficult due to the complex air-to-ground path loss model. In this paper, a novel mechanism is proposed to ensure robust wireless connectivity and mobility support for cellular-connected UAVs by tuning the downtilt (DT) angles of all the ground base stations (GBSs). By leveraging tools from reinforcement learning (RL), DT angles are dynamically adjusted by using a model-free RL algorithm. The goal is to provide efficient mobility support in the sky by maximizing the received signal quality at the UAV while also maintaining good throughput performance of the ground users. Simulation results show that the proposed RL-based mobility management (MM) technique can reduce the number of handovers while maintaining the performance goals, compared to the baseline MM scheme in which the network always keeps the DT angle fixed.",autonomous vehicle
10.1109/IWCMC51323.2021.9498892,filtered,2021 International Wireless Communications and Mobile Computing (IWCMC),IEEE,2021-07-02 00:00:00,ieeexplore,Mobility Prediction For Aerial Base Stations for a Coverage Extension in 5G Networks,https://ieeexplore.ieee.org/document/9498892/,"A promising potential of Unmanned Aerial Vehicles (UAV) in 5G networks is to act as Aerial Base Stations (ABSs) that dynamically extend terrestrial base stations coverage without overloading the infrastructure. However, coverage extension faces crucial challenges such as user mobility and determining the best coordinates for new base station deployment. In this paper, we address this problem based on the prediction of users' spatial distribution that allows Aerial base stations (ABS) to adjust their position accordingly. We first analyze the performance of two machine learning schemes (Long Short Term Memory (LSTM)-based encoder-decoder and self-attention-based Transformer) for user mobility prediction based on a real DataSet. Then, we use these schemes to enhance the ABS deployment algorithm. Numerical results reveal significant gains when applying the proposed mobility prediction models over traditional deployment algorithms. In four hours of the day, both the Transformer and LSTM based models show, respectively, more than 31% and 22% gain in coverage rates compared to regular deployment schemes.",autonomous vehicle
10.1109/PIMRC48278.2020.9217347,filtered,"2020 IEEE 31st Annual International Symposium on Personal, Indoor and Mobile Radio Communications",IEEE,2020-09-03 00:00:00,ieeexplore,Optimal Transmission Control and Learning-Based Trajectory Design for UAV-Assisted Detection and Communication,https://ieeexplore.ieee.org/document/9217347/,"Due to their high mobility, flexible deployment and stable maneuverability, unmanned aerial vehicles (UAVs) have been deemed as a promising and indispensable role for various emerging applications (e.g., dangerous area detection, dynamic target tracking, and map remote sensing). Compared to the static monitoring equipments, UAV-mounted high-definition camera and signal transceiver can be used cost-effectively as an on-demand aerial platform to detect the unknown region and send the real-time data back at the same time. However, these highlighted limitations of battery capacity and communication resource extremely affect the UAV's performance such as flight endurance and data transmission. Motivated by the above conflicts, this paper aims to minimize the total energy consumed by the UAV during the region detection mission through jointly optimizing the collected data size, transmission time, and flying trajectory. Toward this end, we derive the optimal data collection and transmission time in closed forms via convex optimization, and propose a model-free reinforcement learning-based algorithm for training the UAV to plan its trajectory without knowing the environment information in advance. Simulation results validate the performance of our designs in terms of convergence, energy consumption, and energy efficiency.",autonomous vehicle
10.1109/ICCE.2018.8326145,filtered,2018 IEEE International Conference on Consumer Electronics (ICCE),IEEE,2018-01-14 00:00:00,ieeexplore,Optimized vision-directed deployment of UAVs for rapid traffic monitoring,https://ieeexplore.ieee.org/document/8326145/,"The flexibility and cost efficiency of traffic monitoring using Unmanned Aerial Vehicles (UAVs) has made such a proposition an attractive topic of research. To date, the main focus was placed on the types of sensors used to capture the data, and the alternative data processing options to achieve good monitoring performance. In this work we move a step further, and explore the deployment strategies that can be realized for rapid traffic monitoring over particular regions of the transportation network by considering a monitoring scheme that captures data from a visual sensor on-board the UAV, and subsequently analyzes it through a specific vision processing pipeline to extract network state information. These innovative deployment strategies can be used in real-time to assess traffic conditions, while for longer periods, to validate the underlying mobility models that characterise traffic patterns.",autonomous vehicle
10.1109/GCWkshps45667.2019.9024648,filtered,2019 IEEE Globecom Workshops (GC Wkshps),IEEE,2019-12-13 00:00:00,ieeexplore,Optimum Aerial Base Station Deployment for UAV Networks: A Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/9024648/,"The boom of unmanned aerial vehicles (UAVs) is projected to fundamentally shift paradigms of transportations, logistics, agricultures, and public safety as a dominating unmanned application in following decades. To optimally process assigned tasks, each UAV requires prompt and ubiquitous information provisioning regarding the varying operation conditions, which renders exploiting base stations (BSs) of existing wireless infrastructures a tractable solution. To receive services from a BS, a UAV should stay within the coverage area of a BS, which however limits the operation range of a UAV. This obstacle thus drives the deployment of a special sort of UAV, known as an aerial base station (ABS), to relay signals between a BS and a UAV. Based on different flight paths of UAVs, an ABS should autonomously decide its own flight trajectory so as to maximize the number of UAVs which can receive wireless services. However, the inherently non-stationary environment renders the optimum autonomous deployment of an ABS a challenging issue. Inspired by the merit of interacting with the environment, we consequently propose a reinforcement learning scheme to optimize the flight trajectory of an ABS. To eliminate the engineering concern in the conventional Q-learning scheme that most state-action pairs may not be fully visited in the deployment of an ABS, in this paper, a state-amount-reduction (SAR) k-step Q-learning scheme is proposed to avoid the issue in the conventional Q-learning, so as to maximize the number of UAVs receiving services from an ABS. Through providing analytical foundations and simulation studies, outstanding performance of the proposed schemes is demonstrated as compared with that of the conventional reinforcement learning based ABS deployment.",autonomous vehicle
10.1109/MSN48538.2019.00046,filtered,2019 15th International Conference on Mobile Ad-Hoc and Sensor Networks (MSN),IEEE,2019-12-13 00:00:00,ieeexplore,RF Aerially Charging Scheduling for UAV Fleet : A Q-Learning Approach,https://ieeexplore.ieee.org/document/9066043/,"In recent years, unmanned aerial vehicles (UAVs) have attracted extensive interests from both academia and industry due to the potential wide applications with universal applicable nature of the deployment. However, currently the bottleneck for UAVs is the limited carried energy resources (e.g. oil box, battery), especially for electric-driven UAVs. For a system consisting of multiple UAVs using batteries, its stability depends on each UAV. Therefore, the lifetime of each UAV is expected to be extended. In this paper, we propose the concept of RF charging aerially for the UAV fleet. Specifically, in order to ensure the stability of the system, wireless charging is considered for enhancing the lifetime of each UAV. However, it may be unbalanced. Accordingly, the issue of charging scheduling arises. The problem is formulated as a Q-Learning problem in this paper. Agent constantly explores and optimizes its scheduling policy. Finally, it can adapt to different UAV distribution situations. We take the energy levels of UAVs as input, which is easy for implementation. We have compared with two other algorithms (RSA and LESA) and compared with the case of no-charging. The results show that comparing with no-charging, the stability of the system can be improved by up to 78%. Compared with RSA and LESA, system stability is increased by up to 30%-40%. In addition, our method is more flexible and applicable to fleet than other ways (such as return to base station, landing to power line, ground laser, etc) to supplement energy.",autonomous vehicle
10.1109/ICACITE51222.2021.9404629,filtered,2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE),IEEE,2021-03-05 00:00:00,ieeexplore,RF Controlled Solar Based Robotic Drone,https://ieeexplore.ieee.org/document/9404629/,"In this paper, we present the recent research in the development of AL drones by using an algorithm of deep learning (A subset of machine learning algorithms) and computer vision (CV) based on a drone camera, the study explores the potential use of drones not only in searching the victim person, animals, important properties during natural calamities like flood, volcanoes eruption, forest fire, cyclones, and earthquake, etc. but also it insights into much useful information to collect to ensure the future safety by using a machine learning algorithm. Preparing for and responding to disasters is a major logistical challenge. ""Actionable Data"" is the next powerful approach and reliable to the Al drones. As we know that drones often generate a huge amount of data - sometimes it produces a large amount of data that we can't handle at a time. Unmanned Aerial Vehicles (UAVs) are the only possible approach that can add value to our AI-based drone without putting any additional efforts to make UAVs more frequent automation. During search and rescue operations, UAVs played a crucial role over humans. As we know that UAVs can be sent to any desired location without any prior knowledge about the exact conditions in the target area. In this paper, we worked to reduce the number of factors that cause hindrance to the effective deployment of UAVs and increasing the duration of flight duration for the rescue operation. We also use the first Indian microprocessor Shakti class c which is installed in the board Artix-7.",autonomous vehicle
10.1109/ICC42927.2021.9500978,filtered,ICC 2021 - IEEE International Conference on Communications,IEEE,2021-06-23 00:00:00,ieeexplore,Re-envisioning Space-Air-Ground Integrated Networks: Reinforcement Learning for Link Optimization,https://ieeexplore.ieee.org/document/9500978/,"To provide ubiquitous connectivity and achieve high reliability in the under-served and under-connected areas, the integration of aerial and space communication infrastructures into terrestrial networks is envisioned as a promising solution. In this regard, unmanned aerial vehicles (UAVs), in the role of aerial base stations (BSs), have been recommended to solve the coverage problem. In order to effectively leverage the advantages of UAVs deployment, UAV trajectory and resource management are required to effectively adapt to the network conditions. However, providing backhaul connectivity for terrestrial and aerial BSs deployed in these areas is another tremendous challenge. In this paper, we aim at jointly optimizing backhaul link and access link in a space-air-ground integrated network. We consider low Earth orbit (LEO) satellites as an effective backhaul solution. For access links, we manage the radio resource among UAVs and small cell BSs, and optimize the trajectories of UAVs in the network. To solve the problem in a distributed manner, we utilize the tools of reinforcement learning, and propose two approaches based on the multi-armed bandit and satisfaction algorithms. Simulation results show that the proposed approaches yield significant performance compared to the benchmark algorithms.",autonomous vehicle
10.1109/ICTC49870.2020.9289086,filtered,2020 International Conference on Information and Communication Technology Convergence (ICTC),IEEE,2020-10-23 00:00:00,ieeexplore,Reinforcement Learning based Real Time Aerial BS Positioning for Dense Urban 5G Mobile Network,https://ieeexplore.ieee.org/document/9289086/,"Due to the recent surge in mobile users and traffic, next-generation mobile communication aims to increase network capacity through large bandwidth and small cell deployment. To respond to this situation, there have been lots of researches on aerial base stations (BSs) using unmanned aerial vehicles (UAVs) for the mobile user. Aerial BS has the advantage of providing flexible communication range by avoiding obstacles such as buildings in urban areas through 3D positioning. However, finding an optimal point for aerial BS considering the variance of user's requirements, movement, and obstacles in real time is difficult problem to solve. Therefore, it is necessary to find an approximate optimal point for applying to the real-time flight path control of aerial BS. This paper aims to find optimal behavior in real time interacting with a given environment, through reinforcement learning. We propose the algorithm based on Q-learning with a new concept called Coarse Search to reduce convergence speed. We evaluate the performance of the algorithm by comparing it with that of other heuristic algorithms.",autonomous vehicle
10.1109/ICCWorkshops49005.2020.9145423,filtered,2020 IEEE International Conference on Communications Workshops (ICC Workshops),IEEE,2020-06-11 00:00:00,ieeexplore,Reinforcement Learning for Improved UAV-Based Integrated Access and Backhaul Operation,https://ieeexplore.ieee.org/document/9145423/,"There is a strong interest in utilizing commercial cellular networks to support unmanned aerial vehicles (UAVs) to send control commands and communicate heavy traffic. Cellular networks are well suited for offering reliable and secure connections to the UAVs as well as facilitating traffic management systems to enhance safe operation. However, for the full-scale integration of UAVs that perform critical and high-risk tasks, more advanced solutions are required to improve wireless connectivity in mobile networks. In this context, integrated access and backhaul (IAB) is an attractive approach for the UAVs to enhance connectivity and traffic forwarding. In this paper, we study a novel approach to dynamic associations based on reinforcement learning at the edge of the network and compare it to alternative association algorithms. Considering the average data rate, our results indicate that the reinforcement learning methods improve the achievable data rate. The optimal parameters of the introduced algorithm are highly sensitive to the donor next generation node base (DgNB) and UAV IAB node densities, and need to be identified beforehand or estimated via a stateful search. However, its performance nearly converges to that of the ideal scheme with a full knowledge of the data rates in dense deployments of DgNBs.",autonomous vehicle
10.1109/ICC40277.2020.9148694,filtered,ICC 2020 - 2020 IEEE International Conference on Communications (ICC),IEEE,2020-06-11 00:00:00,ieeexplore,Resource Allocation for Energy Efficient NOMA UAV Network under Imperfect CSI,https://ieeexplore.ieee.org/document/9148694/,"Unmanned aerial vehicles (UAVs) are developing rapidly owing to flexible deployment and access services as air base stations. However, the energy efficiency of the UAVs cells using non-orthogonal multiple access (NOMA) with imperfect channel state information (CSI) hasnt been well studied yet. Therefore, we maximize energy efficiency in the downlink NOMA UAV network considering imperfect CSI between the UAV and users. Resource allocation schemes including user scheduling as well as power allocation are designed for system energy efficiency optimization. Because of the non-convexity of optimization function with an probability constraint for imperfect CSI, the original problem is converted into a nonprobability problem and then decoupled into two convex subproblems by successive convex approximation method. First, a user scheduling method is applied in the two-side matching of users and subchannels by the difference of convex programming. Then based on user scheduling, the energy efficiency in UAV cells is optimized through a suboptimal power allocation algorithm. The simulation results prove that our proposed algorithm is more effective compared with existing resource allocation schemes.",autonomous vehicle
10.1109/GLOBECOM42002.2020.9322583,filtered,GLOBECOM 2020 - 2020 IEEE Global Communications Conference,IEEE,2020-12-11 00:00:00,ieeexplore,Self-Learning Bayesian Generative Models for Jammer Detection in Cognitive-UAV-Radios,https://ieeexplore.ieee.org/document/9322583/,"Unmanned Aerial Vehicles (UAVs) attracted both industry and research community owing to their fascinating features like mobility, deployment flexibility and strong Line of Sight (LoS) links. The integration of Cognitive Radio (CR) can greatly help UAVs to overcome several issues especially spectrum scarcity. However, the dynamic radio environment in CR and the strong dependence of safe communications from LoS channels integrity in UAV communications make the Cognitive- UAV-Radio vulnerable to jamming attacks. This work aims to study the integration of CR and UAVs introducing a Self- Awareness (SA) framework from the physical layer security perspective. Under the SA framework, a Dynamic Bayesian Network (DBN) model is proposed as a representation of the radio environment and a modified Markov Jump Particle Filter (MJPF) is employed for prediction and state estimation purposes. A novel jammer detection framework is proposed that allows the UAV to perform abnormality evaluation at different hierarchical levels. The jammer is shown to be located effectively in both time and frequency domains. Experimental results show the effectiveness of the proposed framework in terms of detection probability and accuracy.",autonomous vehicle
10.1109/CVPRW.2019.00177,filtered,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),IEEE,2019-06-17 00:00:00,ieeexplore,The Attack Generator: A Systematic Approach Towards Constructing Adversarial Attacks,https://ieeexplore.ieee.org/document/9025529/,"Most state-of-the-art machine learning (ML) classification systems are vulnerable to adversarial perturbations. As a consequence, adversarial robustness poses a significant challenge for the deployment of ML-based systems in safety-and security-critical environments like autonomous driving, disease detection or unmanned aerial vehicles. In the past years we have seen an impressive amount of publications presenting more and more new adversarial attacks. However, the attack research seems to be rather unstructured and new attacks often appear to be random selections from the unlimited set of possible adversarial attacks. With this publication, we present a structured analysis of the adversarial attack creation process. By detecting different building blocks of adversarial attacks, we outline the road to new sets of adversarial attacks. We call this the ""attack generator"". In the pursuit of this objective, we summarize and extend existing adversarial perturbation taxonomies. The resulting taxonomy is then linked to the application context of computer vision systems for autonomous vehicles, i.e. semantic segmentation and object detection. Finally, in order to prove the usefulness of the attack generator, we investigate existing semantic segmentation attacks with respect to the detected defining components of adversarial attacks.",autonomous vehicle
10.1109/RO-MAN46459.2019.8956420,filtered,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),IEEE,2019-10-18 00:00:00,ieeexplore,Trust Repair in Human-Swarm Teams+,https://ieeexplore.ieee.org/document/8956420/,"Swarm robots are coordinated via simple control laws to generate emergent behaviors such as flocking, rendezvous, and deployment. Human-swarm teaming has been widely proposed for scenarios, such as human-supervised teams of unmanned aerial vehicles (UAV) for disaster rescue, UAV and ground vehicle cooperation for building security, and soldier-UAV teaming in combat. Effective cooperation requires an appropriate level of trust, between a human and a swarm. When an UAV swarm is deployed in a real-world environment, its performance is subject to real-world factors, such as system reliability and wind disturbances. Degraded performance of a robot can cause undesired swarm behaviors, decreasing human trust. This loss of trust, in turn, can trigger human intervention in UAVs' task executions, decreasing cooperation effectiveness if inappropriate. Therefore, to promote effective cooperation we propose and test a trust-repairing method (Trust-repair) restoring performance and human trust in the swarm to an appropriate level by correcting undesired swarm behaviors. Faulty swarms caused by both external and internal factors were simulated to evaluate the performance of the Trust-repair algorithm in repairing swarm performance and restoring human trust. Results show that Trust-repair is effective in restoring trust to a level intermediate between normal and faulty conditions.",autonomous vehicle
10.1109/SoutheastCon44009.2020.9368285,filtered,2020 SoutheastCon,IEEE,2020-03-29 00:00:00,ieeexplore,UAV Aided Search and Rescue Operation Using Reinforcement Learning,https://ieeexplore.ieee.org/document/9368285/,"Owing to the enhanced flexibility in deployment and decreasing costs of manufacturing, the demand for unmanned aerial vehicles (UAVs) is expected to soar in the upcoming years. In this paper, we explore a UAV aided search and rescue (SAR) operation in indoor environments, where the GPS signals might not be reliable. We consider a SAR scenario where the UAV tries to locate a victim trapped in an indoor environment by sensing the RF signals emitted from a smart device owned by the victim. To locate the victim as fast as possible, we leverage tools from reinforcement learning (RL). Received signal strength (RSS) at the UAV depends on the distance from the source, indoor shadowing and fading parameters, and antenna radiation pattern of the receiver mounted on the UAV. To make our analysis more realistic, we model two indoor scenarios with different dimensions using a commercial ray tracing software. Then, the corresponding RSS values at each possible discrete UAV location are extracted and used in a Q-learning framework. Unlike the traditional location-based navigation approach that exploits GPS coordinates, our method uses the RSS to define the states and rewards of the RL algorithm. We compare the performance of the proposed method where directional and omnidirectional antennas are used. The results reveal that the use of directional antennas provides faster convergence rates than the omnidirectional antennas.",autonomous vehicle
10.1109/IRC.2019.00103,filtered,2019 Third IEEE International Conference on Robotic Computing (IRC),IEEE,2019-02-27 00:00:00,ieeexplore,UAV Detection System with Multiple Acoustic Nodes Using Machine Learning Models,https://ieeexplore.ieee.org/document/8675566/,"Class 1 unmanned aerial vehicles (UAVs), known as drones, have become popular and accessible, which makes them tools for malicious purposes. As a result, there is an increasing demand for an effective defense system that can detect UAVs. In this paper, a UAV detection system with multiple acoustic nodes using machine learning models is proposed along with an empirically optimized configuration of the nodes for deployment. Features including Mel-frequency cepstral coefficients (MFCC) and short-time Fourier transform (STFT) were used for training. Support vector machines (SVM) and convolutional neural networks (CNN) were trained with the data collected in person. Experiments were done to evaluate models' ability to find the path of the UAV that was flying. Sensing nodes were placed in four different configurations and the best of test set was chosen which maximizes the detection range without blind spots. STFT-SVM model showed the best performance and a semi-circle formation with 75 meters distance between a node and the protected area is found to be the optimized configuration.",autonomous vehicle
10.1109/GLOBECOM42002.2020.9322234,filtered,GLOBECOM 2020 - 2020 IEEE Global Communications Conference,IEEE,2020-12-11 00:00:00,ieeexplore,UAV Path Planning for Wireless Data Harvesting: A Deep Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/9322234/,"Autonomous deployment of unmanned aerial vehicles (UAVs) supporting next-generation communication networks requires efficient trajectory planning methods. We propose a new end-to-end reinforcement learning (RL) approach to UAV-enabled data collection from Internet of Things (IoT) devices in an urban environment. An autonomous drone is tasked with gathering data from distributed sensor nodes subject to limited flying time and obstacle avoidance. While previous approaches, learning and non-learning based, must perform expensive recomputations or relearn a behavior when important scenario parameters such as the number of sensors, sensor positions, or maximum flying time, change, we train a double deep Q-network (DDQN) with combined experience replay to learn a UAV control policy that generalizes over changing scenario parameters. By exploiting a multi-layer map of the environment fed through convolutional network layers to the agent, we show that our proposed network architecture enables the agent to make movement decisions for a variety of scenario parameters that balance the data collection goal with flight time efficiency and safety constraints. Considerable advantages in learning efficiency from using a map centered on the UAV's position over a non-centered map are also illustrated.",autonomous vehicle
10.1109/ACCESS.2020.3032929,filtered,IEEE Access,IEEE,2020-01-01 00:00:00,ieeexplore,A Dynamic Artificial Potential Field (D-APF) UAV Path Planning Technique for Following Ground Moving Targets,https://ieeexplore.ieee.org/document/9234396/,"Path planning is a vital and challenging component in the support of Unmanned Aerial Vehicles (UAVs) and their deployment in autonomous missions, such as following ground moving target. Few attempts are reported in the literature on multirotor UAV path planning techniques for following ground moving targets despite the great improvement in their control dynamics, flying behaviors and hardware specifications. These attempts suffer several drawbacks including their hardware dependency, high computational requirements, inability to handle obstacles and dynamic environments in addition to their low performance regarding the moving target speed variations. In this paper, a novel dynamic Artificial Potential Field (D-APF) path planning technique is developed for multirotor UAVs for following ground moving targets. The UAV produced path is a smooth and flyable path suitable to dynamic environments with obstacles and can handle different motion profiles for the ground moving target including change in speed and direction. Additionally, the proposed path planning technique effectively supports UAVs following ground moving targets while maneuvering ahead and at a standoff distance from the target. It is hardware-independent where it can be used on most types of multirotor UAVs with an autopilot flight controller and basic sensors for distance measurements. The developed path planning technique is tested and validated against existing general potential field techniques for different simulation scenarios in ROS and gazebo-supported PX4-SITL. Simulation results show that the proposed D-APF is better suited for UAV path planning for following moving ground targets compared to existing general APFs. In addition, it outperforms the general APFs as it is more suitable for UAVs flying in environments with dynamic and unknown obstacles.",autonomous vehicle
10.1109/COMST.2019.2902862,filtered,IEEE Communications Surveys & Tutorials,IEEE,2019-09-01 00:00:00,ieeexplore,"A Tutorial on UAVs for Wireless Networks: Applications, Challenges, and Open Problems",https://ieeexplore.ieee.org/document/8660516/,"The use of flying platforms such as unmanned aerial vehicles (UAVs), popularly known as drones, is rapidly growing. In particular, with their inherent attributes such as mobility, flexibility, and adaptive altitude, UAVs admit several key potential applications in wireless systems. On the one hand, UAVs can be used as aerial base stations to enhance coverage, capacity, reliability, and energy efficiency of wireless networks. On the other hand, UAVs can operate as flying mobile terminals within a cellular network. Such cellular-connected UAVs can enable several applications ranging from real-time video streaming to item delivery. In this paper, a comprehensive tutorial on the potential benefits and applications of UAVs in wireless communications is presented. Moreover, the important challenges and the fundamental tradeoffs in UAV-enabled wireless networks are thoroughly investigated. In particular, the key UAV challenges such as 3D deployment, performance analysis, channel modeling, and energy efficiency are explored along with representative results. Then, open problems and potential research directions pertaining to UAV communications are introduced. Finally, various analytical frameworks and mathematical tools, such as optimization theory, machine learning, stochastic geometry, transport theory, and game theory are described. The use of such tools for addressing unique UAV problems is also presented. In a nutshell, this tutorial provides key guidelines on how to analyze, optimize, and design UAV-based wireless communication systems.",autonomous vehicle
10.1109/ACCESS.2019.2947546,filtered,IEEE Access,IEEE,2019-01-01 00:00:00,ieeexplore,A Two-Step Environment-Learning-Based Method for Optimal UAV Deployment,https://ieeexplore.ieee.org/document/8869876/,"Unmanned aerial vehicles (UAVs) can be used as low-altitude flight base stations to satisfy the coverage requirements of wireless users in various scenarios. In practical applications, since the transmitted power and energy resources of the UAVs are limited and the propagation environments are complicated and time-variant, it is challenging to control a group of UAVs to ensure coverage performance while preserving the connectivity and safety of the UAV networks. To this end, a two-step environment-learning-based method is proposed for the intelligent deployment of the UAVs. First, a machine learning algorithm is used to establish an accurate prediction model of the link qualities from the UAVs to the users under a specific scenario for the next step. Then, a modified deep deterministic policy gradient (DDPG) algorithm is employed to control the movements of the UAVs according to the predicted link qualities and to maximize the proportion of covered users. The prioritized experience replay mechanism is introduced to the standard DDPG algorithm to accelerate the deployment procedure. The coverage performance is analyzed in both the interference-free situation and the situation with co-channel interference. Simulation results have shown that the proposed method has a higher convergence speed than the standard DDPG method. Additionally, the proposed deployment method can achieve higher coverage performance and better adaptability to the dynamic environment than three commonly used methods, the random method, the K-means-based method, and the statistical-channel-model-based method.",autonomous vehicle
10.1109/ACCESS.2020.3008168,filtered,IEEE Access,IEEE,2020-01-01 00:00:00,ieeexplore,Air-Ground Integrated Mobile Edge Networks: A Survey,https://ieeexplore.ieee.org/document/9137644/,"With proliferation of smart devices and wireless applications, the recent few years have witnessed data surge. These massive data needs to be stored, transmitted, and processed in time to exploit their value for decision making. Conventional cloud computing requires transmission of massive amount of data in and out of core network, which can lead to longer service latency and potential traffic congestion. As a new platform, mobile edge computing (MEC) moves computation and storage resources to edge network in proximity to the data source. With MEC, data can be processed locally, and thus mitigate issues of latency and congestion. However, it is very challenging to reap the benefits of MEC everywhere due to geographic constraints, expensive deployment cost, and immoveable base stations. Because of easy deployment and high mobility of unmanned aerial vehicles (UAVs), air-ground integrated mobile edge networks (AGMEN) is proposed, where UAVs are employed to assist the MEC network. Such an AGMEN expects to provide MEC services ubiquitously and reliably. In this article, we first introduce the characteristics and components of UAV. Then, we will review the applications, key challenges, and current research technologies of AGMEN, from perspectives of communication, computation, and caching, respectively. Finally, we will discuss some essential research directions for AGMEN.",autonomous vehicle
10.1109/TCOMM.2020.3013599,filtered,IEEE Transactions on Communications,IEEE,2020-11-01 00:00:00,ieeexplore,Cooperative Internet of UAVs: Distributed Trajectory Design by Multi-Agent Deep Reinforcement Learning,https://ieeexplore.ieee.org/document/9154432/,"Due to the advantages of flexible deployment and extensive coverage, unmanned aerial vehicles (UAVs) have significant potential for sensing applications in the next generation of cellular networks, which will give rise to a cellular Internet of UAVs. In this article, we consider a cellular Internet of UAVs, where the UAVs execute sensing tasks through cooperative sensing and transmission to minimize the age of information (AoI). However, the cooperative sensing and transmission is tightly coupled with the UAVs' trajectories, which makes the trajectory design challenging. To tackle this challenge, we propose a distributed sense-and-send protocol, where the UAVs determine the trajectories by selecting from a discrete set of tasks and a continuous set of locations for sensing and transmission. Based on this protocol, we formulate the trajectory design problem for AoI minimization and propose a compound-action actor-critic (CA2C) algorithm to solve it based on deep reinforcement learning. The CA2C algorithm can learn the optimal policies for actions involving both continuous and discrete variables and is suited for the trajectory design. Our simulation results show that the CA2C algorithm outperforms four baseline algorithms. Also, we show that by dividing the tasks, cooperative UAVs can achieve a lower AoI compared to non-cooperative UAVs.",autonomous vehicle
10.1109/TWC.2020.3007804,filtered,IEEE Transactions on Wireless Communications,IEEE,2020-11-01 00:00:00,ieeexplore,Deep Learning for Optimal Deployment of UAVs With Visible Light Communications,https://ieeexplore.ieee.org/document/9140367/,"In this paper, the problem of dynamical deployment of unmanned aerial vehicles (UAVs) equipped with visible light communication (VLC) capabilities for optimizing the energy efficiency of UAV-enabled networks is studied. In the studied model, the UAVs can simultaneously provide communications and illumination to service ground users. Since ambient illumination increases the interference over VLC links while reducing the illumination threshold of the UAVs, it is necessary to consider the illumination distribution of the target area for UAV deployment optimization. This problem is formulated as an optimization problem which jointly optimizes UAV deployment, user association, and power efficiency while meeting the illumination and communication requirements of users. To solve this problem, an algorithm that combines the machine learning framework of gated recurrent units (GRUs) with convolutional neural networks (CNNs) is proposed. Using GRUs and CNNs, the UAVs can model the long-term historical illumination distribution and predict the future illumination distribution. Given the prediction of illumination distribution, the original nonconvex optimization problem can be divided into two sub-problems and is then solved using a low-complexity, iterative algorithm. Then, the proposed algorithm enables UAVs to determine the their deployment and user association to minimize the total transmit power. Simulation results using real data from the Earth observations group (EOG) at NOAA/NCEI show that the proposed approach can achieve up to 68.9% reduction in total transmit power compared to a conventional optimal UAV deployment that does not consider the illumination distribution and user association.",autonomous vehicle
10.1109/TVT.2019.2947078,filtered,IEEE Transactions on Vehicular Technology,IEEE,2019-12-01 00:00:00,ieeexplore,Deployment Optimization of UAV Relay for Malfunctioning Base Station: Model-Free Approaches,https://ieeexplore.ieee.org/document/8867956/,"Due to the advantages of high mobility, high maneuverability and high probability of line of sight (LoS) transmission, unmanned aerial vehicles (UAVs) have attracted much interest in assisting wireless communication systems. This paper considers a set of ground users cannot receive service from the base station because of a sudden base station malfunction, a UAV is deployed in the air to work as a relay to establish communication links between uncovered users and the neighboring base station. We are going to optimize the UAV relay deployment, aiming to maximize the capacity of the relay network. Considering the channel model and exact positions of ground users are priori unknown, the problem of deployment optimization can't be solved directly because of lacking parameters. Thus, considering multiple detecting UAVs are available and only one is available, model-free online deployment approaches are respectively proposed to solve this challenging problem. The optimal relay deployment is acquired via online learning and iteration without the knowledge of channel model and exact positions of the users but with the real-time measurement of relay capacity, thus the proposed model-free deployment approaches can be adaptive to the practical communication environment compared to the model-based optimization. Simulation results show that with the proposed model-free deployment approaches, relay network capacities are close to the optimum.",autonomous vehicle
10.1109/COMST.2019.2924143,filtered,IEEE Communications Surveys & Tutorials,IEEE,2019-12-01 00:00:00,ieeexplore,Design Challenges of Multi-UAV Systems in Cyber-Physical Applications: A Comprehensive Survey and Future Directions,https://ieeexplore.ieee.org/document/8742658/,"Unmanned aerial vehicles (UAVs) have recently rapidly grown to facilitate a wide range of innovative applications that can fundamentally change the way cyber-physical systems (CPSs) are designed. CPSs are a modern generation of systems with synergic cooperation between computational and physical potentials that can interact with humans through several new mechanisms. The main advantages of using UAVs in CPS application is their exceptional features, including their mobility, dynamism, effortless deployment, adaptive altitude, agility, adjustability, and effective appraisal of real-world functions anytime and anywhere. Furthermore, from the technology perspective, UAVs are predicted to be a vital element of the development of advanced CPSs. Therefore, in this survey, we aim to pinpoint the most fundamental and important design challenges of multi-UAV systems for CPS applications. We highlight key and versatile aspects that span the coverage and tracking of targets and infrastructure objects, energy-efficient navigation, and image analysis using machine learning for fine-grained CPS applications. Key prototypes and testbeds are also investigated to show how these practical technologies can facilitate CPS applications. We present and propose state-of-the-art algorithms to address design challenges with both quantitative and qualitative methods and map these challenges with important CPS applications to draw insightful conclusions on the challenges of each application. Finally, we summarize potential new directions and ideas that could shape future research in these areas.",autonomous vehicle
10.1109/TVT.2020.3043851,filtered,IEEE Transactions on Vehicular Technology,IEEE,2020-12-01 00:00:00,ieeexplore,Downlink Transmit Power Control in Ultra-Dense UAV Network Based on Mean Field Game and Deep Reinforcement Learning,https://ieeexplore.ieee.org/document/9290094/,"As an emerging technology in 5G, ultra-dense unmanned aerial vehicles (UAVs) network can significantly improve the system capacity and networks coverage. However, it is still a challenge to reduce interference and improve energy efficiency (EE) of UAVs. In this paper, we investigate a downlink power control problem to maximize the EE in an ultra-dense UAV network. Firstly, the power control problem is formulated as a discrete mean field game (MFG) to imitate the interactions among a large number of UAVs, and then the MFG framework is transformed into a Markov decision process (MDP) to obtain the equilibrium solution of the MFG due to the dense deployment of UAVs. Specifically, a deep reinforcement learning-based MFG (DRL-MFG) algorithm is proposed to suppress the interference and maximize the EE by using deep neural networks (DNN) to explore the optimal power strategy for UAVs. The numerical results show that the UAVs can effectively interact with the environment to obtain the optimal power control strategy. Compared with the benchmarks algorithms, the DRL-MFG algorithm converges faster to the solution of MFG and improves the EE of UAVs. Moreover, the impact of the transmit power on EE under the different heights of the UAVs is also analyzed.",autonomous vehicle
10.1109/JSTARS.2020.2969809,filtered,IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,IEEE,2020-01-01 00:00:00,ieeexplore,EmergencyNet: Efficient Aerial Image Classification for Drone-Based Emergency Monitoring Using Atrous Convolutional Feature Fusion,https://ieeexplore.ieee.org/document/9050881/,"Deep learning-based algorithms can provide state-of-the-art accuracy for remote sensing technologies such as unmanned aerial vehicles (UAVs)/drones, potentially enhancing their remote sensing capabilities for many emergency response and disaster management applications. In particular, UAVs equipped with camera sensors can operating in remote and difficult to access disaster-stricken areas, analyze the image and alert in the presence of various calamities such as collapsed buildings, flood, or fire in order to faster mitigate their effects on the environment and on human population. However, the integration of deep learning introduces heavy computational requirements, preventing the deployment of such deep neural networks in many scenarios that impose low-latency constraints on inference, in order to make mission-critical decisions in real time. To this end, this article focuses on the efficient aerial image classification from on-board a UAV for emergency response/monitoring applications. Specifically, a dedicated Aerial Image Database for Emergency Response applications is introduced and a comparative analysis of existing approaches is performed. Through this analysis a lightweight convolutional neural network architecture is proposed, referred to as EmergencyNet, based on atrous convolutions to process multiresolution features and capable of running efficiently on low-power embedded platforms achieving upto 20× higher performance compared to existing models with minimal memory requirements with less than 1% accuracy drop compared to state-of-the-art models.",autonomous vehicle
10.1109/JSAC.2020.3005489,filtered,IEEE Journal on Selected Areas in Communications,IEEE,2020-12-01 00:00:00,ieeexplore,Energy Efficiency Optimization for NOMA UAV Network With Imperfect CSI,https://ieeexplore.ieee.org/document/9127472/,"Unmanned aerial vehicles (UAVs) are developing rapidly owing to flexible deployment and access services as air base stations. However, the channel errors of low-altitude communication links formed by mobile deployment of UAVs cannot be ignored. And the energy efficiency of the UAVs communication with imperfect channel state information (CSI) hasnt been well studied yet. Therefore, we focus on system performance optimization in non-orthogonal multiple access (NOMA) UAV network considering imperfect CSI between the UAV and users. A suboptimal resource allocation scheme including user scheduling and power allocation is designed for maximizing energy efficiency. Because of the nonconvexity of optimization function with an probability constraint for imperfect CSI, the original problem is converted into a non-probability problem and then decoupled into two convex subproblems. First, a user scheduling method is applied in the two-side matching of users and subchannels by the difference of convex programming. Then based on user scheduling, the energy efficiency in UAV cells is optimized through a suboptimal power allocation algorithm by successive convex approximation method. The simulation results prove that the proposed algorithm is effective compared with existing resource allocation schemes.",autonomous vehicle
10.1109/LCOMM.2021.3052230,filtered,IEEE Communications Letters,IEEE,2021-05-01 00:00:00,ieeexplore,Energy-Efficient Multi-UAVs Deployment and Movement for Emergency Response,https://ieeexplore.ieee.org/document/9328210/,"Unmanned aerial vehicles (UAVs) can be utilized to provide communication services for the areas where the communication is unavailable due to the high mobility, agility and low cost. In this letter, we investigate the energy efficient UAVs deployment and the movement for emergency response in the multi-UAVs enabled wireless communication system. The positions of the UAVs, the users association and the transmit power of the ground users are jointly optimized to maximize the energy efficiency of all ground users. And when one UAV leaves because of the breakdown or the drained battery, how the other UAVs move with the minimum energy cost is also studied. An alternating algorithm based on successive convex approximation (SCA) technique is proposed to solve the formulated optimization problems. Numerical results show the proposed multi-UAVs deployment and movement outperform the benchmarks.",autonomous vehicle
10.1109/ACCESS.2021.3121905,filtered,IEEE Access,IEEE,2021-01-01 00:00:00,ieeexplore,Evolutionary Coverage Optimization for a Self-Organizing UAV-Based Wireless Communication System,https://ieeexplore.ieee.org/document/9583254/,"Self-organized wireless networks based on unmanned aerial vehicles (UAVs) are receiving increasing attention due to their flexible deployment opportunities. Typically, UAVs are used as supplementary access points to existing ground infrastructure to extend network coverage and capacity. Therefore, finding the optimal position for each UAV is a crucial task that can be resolved by multiobjective optimization. In this paper, a self-organizing UAV swarm model is introduced as an evolutionary type of heuristic that can be adjusted in real time based on the network’s key performance indicators (KPIs). The exogenous dynamics of the wireless communication system are reflected by an end-user mobility model based on Ornstein-Uhlenbeck processes. To achieve versatility in the positioning of UAVs, a model of virtual forces is adopted to enable control of the movement of each UAV via a collection of persistent and mutable parameters of the system. Evolution is controlled by eleven strategic versions of parametric mutations, including a neutral benchmark process. The simulation results reveal that the suggested solution allows for a substantial increase in the KPI efficiency metrics relative to those of the nonmutated system. The results also addressed the presence of the Pareto front, where it is not possible to improve the selected KPIs without negatively affecting others. While existing research that focuses on evolutionary methods usually considers offline approaches, this work uses an online evolutionary approach that is able to solve the presented problem by taking the dynamic nature of the environment into account.",autonomous vehicle
10.1109/TNET.2020.2970744,filtered,IEEE/ACM Transactions on Networking,IEEE,2020-04-01 00:00:00,ieeexplore,"Joint Optimization of Relay Deployment, Channel Allocation, and Relay Assignment for UAVs-Aided D2D Networks",https://ieeexplore.ieee.org/document/9003500/,"Unmanned aerial vehicles (UAVs) can be deployed in the air to provide high probabilities of line of sight (LoS) transmission, thus UAVs bring much gain for wireless communication systems. In this paper, we study a UAVs-aided self-organized device-to-device (D2D) network. Relay deployment, channel allocation and relay assignment are jointly optimized, aiming to maximize the capacity of the relay network. On account of the coupled relationship between the three optimization variables, an alternating optimization approach is proposed to solve this problem. The original problem is divided into two sub-problems. The first one is that of optimizing the channel allocation and relay assignment with fixed relay deployment. Considering without central controller, a reinforcement learning algorithm is proposed to solve this sub-problem. The second sub-problem is that of optimizing the relay deployment with fixed channel allocation and relay assignment. Assuming no knowledge of channel model and exact positions of the communication nodes, an online learning algorithm based on real-time capacity is proposed to solve this sub-problem. By solving the two sub-problems alternately and iteratively, the original problem is finally solved. Simulation results show that the UAVs-aided D2D network can achieve a high capacity via the joint optimization of relay deployment, channel allocation, and relay assignment.",autonomous vehicle
10.1109/ACCESS.2021.3049360,filtered,IEEE Access,IEEE,2021-01-01 00:00:00,ieeexplore,Joint Optimization of Sensors Association and UAVs Placement in IoT Applications With Practical Network Constraints,https://ieeexplore.ieee.org/document/9313991/,"This paper considers the problem of efficient network design for data collection from various sensors in smart environments using flying base stations, which are realized using unmanned aerial vehicles (UAVs), or drones. The system efficiency is enhanced by maximizing the number of served sensors using the minimum number of UAVs while satisfying particular network constraints. Towards this end, a joint optimization problem is formulated for UAVs placement and sensors assignment in smart environments with massive sensor deployment. Due to the complexity of the optimal solution, a probabilistic learning approach is utilized to find a near-optimal solution. Further, a non-death penalty constraint handling approach is used to deal with difficult and conflicting constraints. Monte Carlo simulation is performed to evaluate the performance of the proposed algorithm in various scenarios, and compare it with the optimal solution to validate the efficiency of the proposed solution. The presented numerical results show that the solutions obtained using the proposed algorithm are generally close or equal to the optimal solution for several scenarios, but with significant complexity reduction, which confirms the efficiency of the proposed algorithm. Moreover, the proposed solution shows significant performance improvement when compared with an efficient greedy algorithm.",autonomous vehicle
10.1109/JSYST.2020.3041706,filtered,IEEE Systems Journal,IEEE,2021-09-01 00:00:00,ieeexplore,Joint UAV Position Optimization and Resource Scheduling in Space-Air-Ground Integrated Networks With Mixed Cloud-Edge Computing,https://ieeexplore.ieee.org/document/9307224/,"Space-aerial-assisted computation offloading has been recognized as a promising technique to provide ubiquitous computing services for remote Internet of Things (IoT) applications, such as forest fire monitoring and disaster rescue. This article considers a space-aerial-assisted mixed cloud-edge computing framework, where the flying unmanned aerial vehicles (UAVs) provide IoT devices with low-delay edge computing service and satellites provide ubiquitous access to cloud computing. We aim to minimize the maximum computation delay among IoT devices with the joint scheduling for association control, computation task allocation, transmission power and bandwidth allocation, UAV computation resource, and deployment position optimization. Through exploiting block coordinate descent and successive convex approximation, we develop an alternating optimization algorithm with guaranteed convergence, to solve the formulated problem. Extensive simulation results are provided to demonstrate the remarkable delay reduction of the proposed scheme than existing benchmark methods.",autonomous vehicle
10.1109/LWC.2021.3073014,filtered,IEEE Wireless Communications Letters,IEEE,2021-07-01 00:00:00,ieeexplore,Latency-Sensitive Service Delivery With UAV-Assisted 5G Networks,https://ieeexplore.ieee.org/document/9403402/,"In this letter, a novel framework to deliver critical spread out URLLC services deploying unmanned aerial vehicles (UAVs) in an out-of-coverage area is developed. To this end, the resource optimization problem, i.e., resource blocks (RBs) and power allocation, and optimal UAV deployment strategy are studied for UAV-assisted 5G networks to jointly maximize the average sum-rate and minimize the transmit power of UAV while satisfying the URLLC requirements. To cope with the sporadic URLLC traffic problem, an efficient online URLLC traffic prediction model based on Gaussian Process Regression (GPR) is proposed which derives optimal URLLC scheduling and transmit power strategy. The formulated problem is revealed as a mixed-integer nonlinear programming (MINLP), which is solved following the introduced successive minimization algorithm. Finally, simulation results are provided to show our proposed solution approach's efficiency.",autonomous vehicle
10.1109/TWC.2021.3068206,filtered,IEEE Transactions on Wireless Communications,IEEE,2021-08-01 00:00:00,ieeexplore,Machine-Learning Beam Tracking and Weight Optimization for mmWave Multi-UAV Links,https://ieeexplore.ieee.org/document/9390407/,"Millimeter-wave (mmWave) hybrid analog-digital beamforming is a promising approach to satisfy the low-latency constraint in multiple unmanned aerial vehicles (UAVs) systems, which serve as network infrastructure for flexible deployment. However, in highly dynamic multi-UAV environments, analog beam tracking becomes a critical challenge. The overhead of additional pilot transmission at the price of spectral efficiency is shown necessary to achieve high resilience in operation. An efficient method to deal with high dynamics of UAVs applies machine learning, particularly Q-learning, to analog beam tracking. The proposed Q-learning-based beam tracking scheme uses current/past observations to design rewards from environments to facilitate prediction, which significantly increases the efficiency of data transmission and beam switching. Given the selected analog beams, the goal of digital beamforming is to maximize the SINR. The received pilot signals are utilized to approximate the desired signal and interference power values, which yield the SINR measurements as well as the optimal digital weights. Since the selected analog beams based on the received power do not guarantee the hybrid beamforming achieving the maximization SINR, we therefore reserve additional analog beams as candidates during the beam tracking. When the candidates include the ideal beams, the combination of analog beams with their digital weights achieving the maximum SINR consequently provides the optimal solution to the hybrid beamforming.",autonomous vehicle
10.1109/TVT.2021.3094273,filtered,IEEE Transactions on Vehicular Technology,IEEE,2021-08-01 00:00:00,ieeexplore,Multi-Agent Reinforcement Learning Based 3D Trajectory Design in Aerial-Terrestrial Wireless Caching Networks,https://ieeexplore.ieee.org/document/9473012/,"This paper investigates a dynamic 3D trajectory design of multiple cache-enabled unmanned aerial vehicles (UAVs) in a wireless device-to-device (D2D) caching network with the goal of maximizing the long-term network throughput. By storing popular content at the nearby mobile user devices, D2D caching is an efficient method to improve network throughput and alleviate backhaul burden. With the attractive features of high mobility and flexible deployment, UAVs have recently attracted significant attention as cache-enabled flying base stations. The use of cache-enabled UAVs opens up the possibility of tracking the mobility pattern of the corresponding users and serving them under limited cache storage capacity. However, it is challenging to determine the optimal UAV trajectory due to the dynamic environment with frequently changing network topology and the coexistence of aerial and terrestrial caching nodes. In response, we propose a novel multi-agent reinforcement learning based framework to determine the optimal 3D trajectory of each UAV in a distributed manner without a central coordinator. In the proposed method, multiple UAVs can cooperatively make flight decisions by sharing the gained experiences within a certain proximity to each other. Simulation results reveal that our algorithm outperforms the traditional single- and multi-agent Q-learning algorithms. This work confirms the feasibility and effectiveness of cache-enabled UAVs which serve as an important complement to terrestrial D2D caching nodes.",autonomous vehicle
10.1109/ACCESS.2021.3107674,filtered,IEEE Access,IEEE,2021-01-01 00:00:00,ieeexplore,Multi-Tier Variable Height UAV Networks: User Coverage and Throughput Optimization,https://ieeexplore.ieee.org/document/9521913/,"Unmanned aerial vehicles (UAVs) are increasingly considered to act as base stations (BSs) for the future wireless networks. Some of the crucial UAV-assisted network design challenges are the network coverage, throughput, and energy efficiency. Therefore, fast, low-complexity, and efficient UAV placement and resource allocation strategies are imperative. This paper presents a novel variable height multi-UAV deployment strategy to exploit the 3D flexibility of UAVs as BSs. We propose a multi-tier variable height UAV-based network deployment and compare its performance with the state-of-the-art equal height deployment. Height optimization is performed to deliver energy efficiency and throughput maximization for each cell. The results show that our proposed method is more energy-efficient in a multi-cell UAV network than the most widely used height optimization method in the literature. In UAV networks, users at the cell edges can receive very poor signal-to-interference-plus-noise ratio (SINR) levels due to interfering UAVs. To cope with this problem, we adopt a fractional frequency reuse (FFR) scheme to compensate low SINR levels. We optimize the SINR threshold corresponding to each cell to maximize their spectral efficiency (SE), thereby improving the network’s area spectral efficiency (ASE). The numerical results show that the proposed deployments provide significant gains in coverage density, SINR coverage probability, rate coverage, and ASE compared to equal height benchmark scheme. As the number of UAVs increases, the number of tiers need to increase to preserve the rate coverage of the network. Moreover, the performance of the proposed variable height model is expected to converge to that of equal height cellular design for a large number of UAVs.",autonomous vehicle
10.1109/JIOT.2020.2971645,filtered,IEEE Internet of Things Journal,IEEE,2020-08-01 00:00:00,ieeexplore,Multi-UAV-Enabled Load-Balance Mobile-Edge Computing for IoT Networks,https://ieeexplore.ieee.org/document/8981986/,"Unmanned aerial vehicles (UAVs) have been widely used to provide enhanced information coverage as well as relay services for ground Internet-of-Things (IoT) networks. Considering the substantially limited processing capability, the IoT devices may not be able to tackle with heavy computing tasks. In this article, a multi-UAV-aided mobile-edge computing (MEC) system is constructed, where multiple UAVs act as MEC nodes in order to provide computing offloading services for ground IoT nodes which have limited local computing capabilities. For the sake of balancing the load for UAVs, the differential evolution (DE)-based multi-UAV deployment mechanism is proposed, where we model the access problem as a generalized assignment problem (GAP), which is then solved by a near-optimal solution algorithm. Based on this, we are capable of achieving the load balance of these drones while guaranteeing the coverage constraint and satisfying the quality of service (QoS) of IoT nodes. Furthermore, a deep reinforcement learning (DRL) algorithm is conceived for the task scheduling in a certain UAV, which improves the efficiency of the task execution in each UAV. Finally, sufficient simulation results show the feasibility and superiority of our proposed load-balance-oriented UAV deployment scheme as well as the task scheduling algorithm.",autonomous vehicle
10.1109/TCCN.2019.2948324,filtered,IEEE Transactions on Cognitive Communications and Networking,IEEE,2019-12-01 00:00:00,ieeexplore,Optimal UAV Base Station Trajectories Using Flow-Level Models for Reinforcement Learning,https://ieeexplore.ieee.org/document/8876694/,"Cellular base stations (BS) and remote radio heads can be mounted on unmanned aerial vehicles (UAV) for flexible, traffic-aware deployment. These UAV base station networks (UAVBSN) promise an unprecendented degree of freedom that can be exploited for spectral efficiency gains as well as optimal network utilization. However, the current literature lacks realistic radio and traffic models for UAVBSN deployment planning and for performance evaluation. In this paper, we propose flowlevel models (FLM) for realistically characterizing the UAVBSN performance in terms of a broad range of flow- and system-level metrics. Further, we propose a deep reinforcement learning (DRL) approach that relies on the UAVBSN FLM for learning the optimal traffic-aware UAV trajectories. For a given user traffic density and starting UAV locations, our RL approach learns the optimal UAV trajectories offline that maximizes a cumulative performance metric. We then execute the learned UAV trajectories in a discrete event simulator to evaluate online UAVBSN performance. For M = 9 UAVs deployed in a simulated Downtown San Francisco model, where the UAV trajectories are defined by N = 20 discrete actions, our approach achieves approximately a three-fold increase in the average user throughput compared to the initial UAV placement, while simultaneously balancing traffic loads across the BSs.",autonomous vehicle
10.1109/ACCESS.2018.2812896,filtered,IEEE Access,IEEE,2018-01-01 00:00:00,ieeexplore,Optimal UAV Path Planning: Sensing Data Acquisition Over IoT Sensor Networks Using Multi-Objective Bio-Inspired Algorithms,https://ieeexplore.ieee.org/document/8314824/,"The use of unmanned aerial vehicles (UAVs) has been considered to be an efficient platform for monitoring critical infrastructures spanning over geographical areas. UAVs have also demonstrated exceptional feasibility when collecting data due to the wide wireless sensor networks in which they operate. Based on environmental information such as prohibited airspace, geo-locational conditions, flight risk, and sensor deployment statistics, we developed an optimal flight path planning mechanism by using multiobjective bio-inspired algorithms. In this paper, we first acquire data sensing points from the entire sensor field, in which UAV communicates with sensors to obtain sensor data, then we determine the best flight path between neighboring acquisition points. Using the proposed joint genetic algorithm and ant colony optimization from possible UAV flight paths, an optimal one is selected in accordance with sensing, energy, time, and risk utilities. The simulation results show that our method can obtain dynamic environmental adaptivity and high utility in various practical situations.",autonomous vehicle
10.1109/TWC.2020.3027624,filtered,IEEE Transactions on Wireless Communications,IEEE,2021-01-01 00:00:00,ieeexplore,Predictive Deployment of UAV Base Stations in Wireless Networks: Machine Learning Meets Contract Theory,https://ieeexplore.ieee.org/document/9220821/,"In this paper, a novel framework is proposed to enable a predictive deployment of unmanned aerial vehicles (UAVs) as temporary base stations (BSs) to complement ground cellular systems in face of downlink traffic overload. First, a novel learning approach, based on the weighted expectation maximization (WEM) algorithm, is proposed to estimate the user distribution and the downlink traffic demand. Next, to guarantee a truthful information exchange between the BS and UAVs, using the framework of contract theory, an offload contract is developed, and the sufficient and necessary conditions for having a feasible contract are analytically derived. Subsequently, an optimization problem is formulated to deploy an optimal UAV onto the hotspot area in a way that the utility of the overloaded BS is maximized. Simulation results show that the proposed WEM approach yields a prediction error of around 10%. Compared with the expectation maximization and k-mean approaches, the WEM method shows a significant advantage on the prediction accuracy, as the traffic load in the cellular system becomes spatially uneven. Furthermore, compared with two event-driven deployment schemes based on the closest-distance and maximal-energy metrics, the proposed predictive approach enables UAV operators to provide efficient communication service for hotspot users in terms of the downlink capacity, energy consumption and service delay. Simulation results also show that the proposed method significantly improves the revenues of both the BS and UAV networks, compared with two baseline schemes.",autonomous vehicle
10.1109/TVT.2019.2922849,filtered,IEEE Transactions on Vehicular Technology,IEEE,2019-08-01 00:00:00,ieeexplore,Reinforcement Learning in Multiple-UAV Networks: Deployment and Movement Design,https://ieeexplore.ieee.org/document/8736350/,"A novel framework is proposed for quality of experience driven deployment and dynamic movement of multiple unmanned aerial vehicles (UAVs). The problem of joint non-convex three-dimensional (3-D) deployment and dynamic movement of the UAVs is formulated for maximizing the sum mean opinion score of ground users, which is proved to be NP-hard. In the aim of solving this pertinent problem, a three-step approach is proposed for attaining 3-D deployment and dynamic movement of multiple UAVs. First, a genetic algorithm based K-means (GAK-means) algorithm is utilized for obtaining the cell partition of the users. Second, Q-learning based deployment algorithm is proposed, in which each UAV acts as an agent, making their own decision for attaining 3-D position by learning from trial and mistake. In contrast to the conventional genetic algorithm based learning algorithms, the proposed algorithm is capable of training the direction selection strategy offline. Third, Q-learning based movement algorithm is proposed in the scenario that the users are roaming. The proposed algorithm is capable of converging to an optimal state. Numerical results reveal that the proposed algorithms show a fast convergence rate after a small number of iterations. Additionally, the proposed Q-learning based deployment algorithm outperforms K-means algorithms and Iterative-GAKmean algorithms with low complexity.",autonomous vehicle
10.1109/ACCESS.2019.2928012,filtered,IEEE Access,IEEE,2019-01-01 00:00:00,ieeexplore,Trajectory Planning for Reconnaissance Mission Based on Fair-Energy UAVs Cooperation,https://ieeexplore.ieee.org/document/8759855/,"Unmanned aerial vehicles (UAVs) have recently received growing popularity in reconnaissance missions due to their many advantages, such as high mobility, flexible deployment, and low operational costs. In this paper, we investigate how the UAVs should optimally exploit its mobility via trajectory planning to achieve the fairness of energy consumption with communication, hovering, and motion energy consumption in consideration. Most of the current works only consider motion energy consumption; however, communication and hovering energy consumption cannot be ignored. We first formulate this problem as a min-max tour cover problem that has been proved to be NP-hard. Then, a heuristic algorithm is proposed to minimize the maximum energy consumption of the reconnaissance UAVs by planning the trajectories. Next, to guarantee the fairness of energy consumption under scenarios with strict and firm energy requirements, we propose an approximation algorithm that can achieve an approximation ratio of 2.5. Finally, the extensive simulations are conducted under different settings to evaluate the performance of our proposed algorithms. The results show that the algorithms can improve the fairness of energy consumption and reduce the maximum energy consumption compared with other algorithms.",autonomous vehicle
10.1109/TCOMM.2018.2857461,filtered,IEEE Transactions on Communications,IEEE,2018-11-01 00:00:00,ieeexplore,When Mobile Crowd Sensing Meets UAV: Energy-Efficient Task Assignment and Route Planning,https://ieeexplore.ieee.org/document/8413129/,"With the increasing popularity of unmanned aerial vehicles (UAVs), it is foreseen that they will play an important role in broadening the horizon of mobile crowd sensing (MCS). Specifically, UAV-aided MCS allows autonomous data collection anytime and anywhere due to the capability of fast deployment and controllable mobility. However, the on-board battery capacity of UAVs imposes a limitation on their endurance capability and performance. In this paper, we consider the fixed-wing UAV-aided MCS system and investigate the corresponding joint route planning and task assignment problem from an energy efficiency perspective. The formulated joint optimization problem is transformed into a two-sided two-stage matching problem, in which the route planning problem is solved in the first stage based on either dynamic programming or genetic algorithms, and the task assignment problem is addressed in the second stage by exploring the Gale-Shapley algorithm. We provide a comprehensive theoretical analysis, and elaborate the procedures of practical implementation. Numerical results demonstrate that significant performance improvement can be achieved by the proposed scheme.",autonomous vehicle
10.1007/978-3-030-79766-9_1,filtered,Secure Communication for 5G and IoT Networks,Springer,2022-01-01 00:00:00,springer,Security Challenges in 5G and IoT Networks: A Review,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-79766-9_1,"5G networks are poised to satisfy the anticipated growth in Internet of Technology (IoT) devices and their related systems. The invasion of 5G networks brings along with it an accelerated need for security and privacy. The need for tailor-made security solutions has become the need of the hour to ensure data integrity, confidentiality, and authentication in 5G-based IoT networks. Since IoT initiates sensors and actuators in a totally smart environment, IoT security will involve protecting the total deployment architecture of IoT from internal and external attacks. Integration of cryptographical algorithms and quantum cryptography has been used effectively to secure data in 5G networks. Privacy and identity management has been a mandatory requirement in networks carrying delicate data involved in retail shops, traffic services, and health monitoring systems. Securing data in 5G and IoT networks and detection of trustworthy and rogue nodes, proper monitoring, logging, and broadcasting are the vital necessities of any security system. The exhaustive survey on the security issues in the 5G-IoT scenario, highlights the application of the latest technologies, incorporation of hybrid methodologies in securing them, and also emphasizes on the open issues yet to be addressed and research challenges that are to be explored.",autonomous vehicle
10.1007/978-981-16-4016-2_65,filtered,Smart Trends in Computing and Communications,Springer,2022-01-01 00:00:00,springer,The Mythical or Realistic Implementation of AI-powered Driverless Cars in Africa: A Review of Challenges and Risks,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-4016-2_65,"In recent times, African nations have been mostly absent in discussions concerning artificial intelligence (AI)-powered driverless cars. Additionally, it was also discovered that several global surveys and other studies on driverless car acceptance, popularity and confidence excluded Africa. This is in the light of its immense benefits which include the reduction of road accidents, an effectual car-sharing and transport structure and accurate navigation with less consideration of distractions. Therefore, we examined the challenges and risks attendant to the deployment of self-driving cars in a developing region such as Africa. Several challenges were identified, and they include lack of needed infrastructure, absence of law and order, cost, absence of image detection and recognition projects, absence of practical artificial intelligence courseware, need for an advanced AI-based algorithm, weak legal framework and other ethical issues, criminalization, security and privacy and high tendency to cause more unemployment. The paper highlights several risks attendant to such forms of advancement in Africa.",autonomous vehicle
10.1007/s11276-021-02789-7,filtered,Wireless Networks,Springer,2021-10-12 00:00:00,springer,Energy-efficient UAV-enabled computation offloading for industrial internet of things: a deep reinforcement learning approach,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11276-021-02789-7,"Industrial Internet of Things (IIoT) has been envisioned as a killer application of 5G and beyond. However, due to the shortness of computation ablility and batery capacity, it is challenging for IIoT devices to process latency-sensitive and resource-sensitive tasks. Moblie Edge Computing (MEC), as a promising paradigm for handling tasks with high quality of service (QoS) requirement and for energy-constrained IIoT devices, allows IIoT devices to offload their tasks to MEC servers, which can significantly reduce the task process delay and energy consumptions. However, the deployment of the MEC servers rely heavily on communication infrastructure, which greatly reduce the flexibility. Toward this end, in this paper, we consider multiple Unmanned Aerial Vehicles (UAV) eqqipped with transceivers as aerial MEC servers to provide IIoT devices computation offloading opportunities due to their high controbility. IIoT devices can choose to offload the tasks to UAVs through air-ground links, or to offload the tasks to the remote cloud center through ground cellular network, or to process the tasks locally. We formulate the multi-UAV-Enabled computation offloading problem as a mixed integer non-linear programming (MINLP) problem and prove its NP-hardness. To obtain the energy-efficient and low complexity solution, we propose an intelligent computation offloading algorithm called multi-agent deep Q-learning with stochastic prioritized replay (MDSPR). Numerical results show that the proposed MDSPR converges fast and outperforms the benchmark algorithms, including random method, deep Q-learning method and double deep Q-learning method in terms of energy efficiency and task successful rate.",autonomous vehicle
10.1631/FITEE.1900637,filtered,Frontiers of Information Technology & Electronic Engineering,Springer,2021-05-01 00:00:00,springer,Pre-training with asynchronous supervised learning for reinforcement learning based autonomous driving,http://link.springer.com/openurl/pdf?id=doi:10.1631/FITEE.1900637,"基于人定规则所设计的自动驾驶系统可能会因大规模相互耦合的规则而变得越来越复杂, 因此许多研究人员致力于探索基于学习的解决方案. 强化学习 (reinforcement learning, RL) 因其在各种顺序控制问题上的出色表现而被应用于自动驾驶系统设计. 然而, 基于RL的自动驾驶系统落地应用所面临的主要挑战是其初始性能不佳. 强化学习训练需要大量训练数据, 然后模型才能达到合理的性能要求, 这使得基于强化学习的模型不适用于现实环境, 尤其在数据昂贵的情况下. 本文为基于强化学习的端到端自动驾驶模型提出一种异步监督学习 (asynchronous supervised learning, ASL) 方法, 以解决在实际环境中训练基于强化学习模型时初始性能差的问题. 具体而言, 通过在多个驾驶演示数据集上并行且异步执行多个监督学习过程, 在异步监督学习预训练阶段引入先验知识。经过预训练后, 模型将被部署到真实车辆上进一步开展强化学习训练, 以适应实际环境并不断突破性能极限. 本文在赛车模拟器TORCS (The Open Racing Car Simulator) 上对所提出的预训练方法进行评估, 以验证该方法在改善强化学习训练阶段端到端自动驾驶模型的初始性能和收敛速度方面足够可靠. 此外, 建立一个实车验证系统, 以验证所提预训练方法在实车部署中的可行性. 仿真结果表明, 在有监督的预训练阶段使用一些演示, 可以显著提高强化学习训练阶段的初始性能和收敛速度. Rule-based autonomous driving systems may suffer from increased complexity with large-scale intercoupled rules, so many researchers are exploring learning-based approaches. Reinforcement learning (RL) has been applied in designing autonomous driving systems because of its outstanding performance on a wide variety of sequential control problems. However, poor initial performance is a major challenge to the practical implementation of an RL-based autonomous driving system. RL training requires extensive training data before the model achieves reasonable performance, making an RL-based model inapplicable in a real-world setting, particularly when data are expensive. We propose an asynchronous supervised learning (ASL) method for the RL-based end-to-end autonomous driving model to address the problem of poor initial performance before training this RL-based model in real-world settings. Specifically, prior knowledge is introduced in the ASL pre-training stage by asynchronously executing multiple supervised learning processes in parallel, on multiple driving demonstration data sets. After pre-training, the model is deployed on a real vehicle to be further trained by RL to adapt to the real environment and continuously break the performance limit. The presented pre-training method is evaluated on the race car simulator, TORCS (The Open Racing Car Simulator), to verify that it can be sufficiently reliable in improving the initial performance and convergence speed of an end-to-end autonomous driving model in the RL training stage. In addition, a real-vehicle verification system is built to verify the feasibility of the proposed pre-training method in a real-vehicle deployment. Simulations results show that using some demonstrations during a supervised pre-training stage allows significant improvements in initial performance and convergence speed in the RL training stage.",autonomous vehicle
10.1007/s12524-020-01231-3,filtered,Journal of the Indian Society of Remote Sensing,Springer,2021-03-01 00:00:00,springer,Deep Learning Based Supervised Image Classification Using UAV Images for Forest Areas Classification,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12524-020-01231-3,"Applications of unmanned aerial vehicles (UAVs) based remote sensing is increasing rapidly due to their advanced accessibility, capability for fast and easy deployment, capability for miniaturization of sensors and efficient collection of remotely-sensed data from relatively low altitudes. Recently, UAV data sets have been found to be quite useful for forest feature identification due to their relatively high spatial resolution. Several machine learning algorithms have been broadly used for remotely-sensed image classification. In remote sensing image classification, deep learning based methods can be considered quite effective techniques as they have achieved promising results. In this study, we have used deep learning based supervised image classification algorithm and images collected using UAV for classification of forest areas. The deep learning algorithm stacked Auto-encoder has been found to have tremendous potential regarding image classification and the assessment of forest coverage area. Our experimental results show that deep learning method provides better accuracy compared to other machine learning algorithms. Cross-validation showed that the overall accuracy of the deep learning method is about 93%. This study highlights the essential role that UAV observations and deep learning could play in the planning and management of forest areas which are often under the threat of deforestation and forest encroachment.",autonomous vehicle
10.1007/978-3-030-69066-3_22,filtered,Artificial Intelligence for Communications and Networks,Springer,2021-01-01 00:00:00,springer,Delay Minimization in Multi-UAV Assisted Wireless Networks: A Reinforcement Learning Approach,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-69066-3_22,"Unmanned Aerial Vehicles (UAVs) assisted communications are promising technology for meeting the demand of unprecedented demands for wireless services. In this paper, we propose a novel framework for delay minimization driven deployment of multiple UAVs. The problem of joint non-convex three dimensional (3D) deployment for minimizing average delay is formulated and solved by Deep Q network (DQN), which is a reinforcement learning based algorithm. Firstly, we obtain the cell partition by K-means algorithm. Then, we find the optimal 3D position for each UAV in each cluster to provide low delay service. Finally, when users are roaming, the UAVs are still able to track the real-time users. Numerical results show that the proposed DQN-based delay algorithm shows a fast convergence after a small number of iterations. Additionally, the proposed deployment algorithm outperforms several benchmarks in terms of average delay.",autonomous vehicle
10.1007/978-3-030-66042-0_12,filtered,Towards Connected and Autonomous Vehicle Highways,Springer,2021-01-01 00:00:00,springer,The Deep Learning Method for Image Segmentation to Improve the Efficiency of Data Processing Without Compromising the Accuracy of an Autonomous Driving Country-Road Pilot System After Image Classification,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-66042-0_12,"Autonomous driving requires object recognition for vehicles to automatically generate a path according to their recognised environment, the conditions of which have different dims of light, from daylight to night. High-resolution images require high amounts of expensive storage as automated driving moves from urban to rural areas, where driving at night and recognising traffic signs and lights are necessary for all light conditions. Therefore, a reliable source of input, allowing for the intended performance of an autonomous driving system such as the country or rural road pilot, is necessary for adequate deployment of its functionality in its target environment. For quality criteria such as intended performance, functional reliability, safety, and correct driving behaviour are to be ensured; accuracy metrics can be a substantial contribution to the product quality criteria. Furthermore, since autonomous technology faces the challenge of being costly, thus any new innovative methods for saving costs, without comprising quality, would help to develop and enhance the chance of this developing technology being installed into more advanced automated or autonomous driving vehicles once the product safety as quality criteria can be validated on target roads. Part of this work’s limitation was that only a simulation environment was used for testing the image processing and autonomous driving accuracy models. Through research, certain algorithms were found that may be used in storage size minimisation for taking a high-resolution image; its size had to be reduced for use without compromising accuracy in the classification process. Further research in their validation may be necessary.",autonomous vehicle
10.1007/978-3-030-59897-6_11,filtered,Automotive Embedded Systems,Springer,2021-01-01 00:00:00,springer,Internet of Things and Artificial Intelligence-Enabled Secure Autonomous Vehicles for Smart Cities,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-59897-6_11,"The ever-increasing count of vehicles wrecks several cities in the global scenario. Smart cities have evolved as a winning strategy that helps to cope up with this issue and overcome the urban problems such as pollution, traffic, waste management, optimization of energy consumption, and so on. Technologies such as machine learning (ML), Internet of Things (IoT), artificial intelligence (AI), big data analytics, cloud computing, and smart sensors serve as tools that provide enormous possibilities in the smart revolution. Several researchers are working on developing a complete system that performs information gathering, alternate identification, smart predictions, review of choices, decision-making, and taking suitable actions. These systems impose various challenges in terms of governance, economy, mobility, environment, people, and living. This chapter provides an in-depth analysis of these challenges in smart cities with respect to autonomous vehicles and also offers real-time solutions to overcome these challenges. A comparative analysis of the existing algorithms is done, and the optimal algorithms that can help in implementation of the system with a user-friendly approach and linguistic flexibility are proposed. Factors such as use of unmanned aerial vehicles (UAV), vehicle-to-vehicle and vehicle-to-infrastructure communication, deployment of location and path planning, data routing, dynamic coordination, data transmission, privacy, and cybersecurity are also considered while designing the system.",autonomous vehicle
10.1007/978-981-15-5113-0_40,filtered,International Conference on Innovative Computing and Communications,Springer,2021-01-01 00:00:00,springer,Tweets About Self-Driving Cars: Deep Sentiment Analysis Using Long Short-Term Memory Network (LSTM),http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-5113-0_40,"Due to the extensive growth of social media usage, sentiment analysis using social media data such as Twitter is an important task. The current study presents an empirical investigation of consumer sentiment toward self-driving cars or autonomous vehicles (AVs) based on the acquired self-driving car-related tweets. Information retrieval in social media is a complex task that requires technical insights. We used a hierarchical attention-based long short-term memory network (LSTM), a popular deep learning tool, to classify sentiment-specific document representations. The findings show that favorable attitudes toward AVs are associated with technological advantages and safety improvements, while more negative attitudes are associated with self-driving car-related crashes, media coverage, and deployment uncertainty. The results show that the estimated accuracy of LSTM is 85%. Our study indicates the necessity of examining big social media data in understanding the perceptions of end-users toward autonomous vehicles.",autonomous vehicle
10.1007/978-981-15-9255-3_1,filtered,Autonomous Vehicles,Springer,2021-01-01 00:00:00,springer,Challenges for and with Autonomous Vehicles: An Introduction,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-9255-3_1,"The deployment of autonomous vehicles has been announced for years. Yet, full autonomous vehicles are not on public roads. Elon Musk Elon Musk , speaking at an event during the first half of 2020, stated that his firm will be able to present a fully autonomous vehicle technology by the end of the year. This statement is met with skepticism, especially because several of the challenges that existed have not been solved. Road traffic laws have not been adjusted to face the reality of driving by an autonomous machine. The only way that full autonomous vehicles can hit public roads is through test procedures. There also exists quite some uncertainty on who should be liable for accidents with autonomous vehicles. Accidents may occur, and this is something that adversarial machine learning Adversarial machine learning is showing. Even with the best set of sensors, the interpretation of the sensed environment may be misinterpreted. Connectivity Connectivity is being suggested as a possible solution to several of the problems autonomous vehicles are facing. Deploying autonomous vehicles will also challenge business organization, as car manufacturers Manufacturer may turn their business vehicles into mobility service providers. This may require a different type of organization within the firm.",autonomous vehicle
10.1007/s00521-019-04653-4,filtered,Neural Computing and Applications,Springer,2020-08-01 00:00:00,springer,An unmanned aerial vehicle-aided node localization using an efficient multilayer perceptron neural network in wireless sensor networks,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-019-04653-4,"Localization of sensor node is decisive for many localization-based scenarios of wireless sensor networks (WSNs). Node localization using fixed terrestrial anchor nodes (ANs) equipped with global positioning system (GPS) modules suffers from high deployment cost and poor localization accuracy, because the terrestrial AN propagates signals to the unknown nodes (UNs) through unreliable ground-to-ground channel. However, the ANs deployed in unmanned aerial vehicles (UAVs) with a single GPS module communicate over reliable air-to-ground channel, where almost clear line-of-sight path exists. Thus, the localization accuracy and deployment cost are better with aerial anchors than terrestrial anchors. However, still the nonlinear distortions imposed in propagation channel limit the performance of classical RSSI and least square localization schemes. So, the neural network (NN) models can become good alternative for node localization under such nonlinear conditions as they can do complex nonlinear mapping between input and output. Since the multilayer perceptron (MLP) is a robust tool in the assembly of NNs, MLP-based localization scheme is proposed for UN localization in UAV-aided WSNs. The detailed simulation analysis provided in this paper prefers the MLP localization scheme as they exhibit improved localization accuracy and deployment cost.",autonomous vehicle
10.1007/978-3-030-60239-0_18,filtered,Algorithms and Architectures for Parallel Processing,Springer,2020-01-01 00:00:00,springer,Fast Segmentation-Based Object Tracking Model for Autonomous Vehicles,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60239-0_18,"On-road object tracking is a critical module for both Advanced Driving Assistant System (ADAS) and autonomous vehicles. Commonly, this function can be achieved through single vehicle sensors, such as a camera or LiDAR. Consider the low cost and wide application of optical cameras, a simple image segmentation-based on-road object tracking model is proposed. Different from the detection-based tracking with bounding box, our model improves tracking performance from the following three aspects: 1) the Positional Normalization (PONO) feature is used to enhance the target outline with common convolutional layers. 2) The inter-frame correlation of each target used for tracking relies on mask, this helps the model reducing the influences caused by the background around the targets. 3) By using a bidirectional LSTM module capable of capturing timing correlation information, the forward and reverse matching of the targets in consecutive frames is performed. We also evaluate the presented model on the KITTI MOTS (Multi-Object and Segmentation) task which collected from out door environment for autonomous vehicle. Results show that our model is three times faster than Track RCNN with slightly drop on sMOTSA, and is more suitable for deployment on vehicular low-power edge computing equipment.",autonomous vehicle
10.1007/s12559-018-9559-8,filtered,Cognitive Computation,Springer,2018-10-01 00:00:00,springer,Distributed Drone Base Station Positioning for Emergency Cellular Networks Using Reinforcement Learning,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12559-018-9559-8,"Due to the unpredictability of natural disasters, whenever a catastrophe happens, it is vital that not only emergency rescue teams are prepared, but also that there is a functional communication network infrastructure. Hence, in order to prevent additional losses of human lives, it is crucial that network operators are able to deploy an emergency infrastructure as fast as possible. In this sense, the deployment of an intelligent, mobile, and adaptable network, through the usage of drones—unmanned aerial vehicles—is being considered as one possible alternative for emergency situations. In this paper, an intelligent solution based on reinforcement learning is proposed in order to find the best position of multiple drone small cells (DSCs) in an emergency scenario. The proposed solution’s main goal is to maximize the amount of users covered by the system, while drones are limited by both backhaul and radio access network constraints. Results show that the proposed Q -learning solution largely outperforms all other approaches with respect to all metrics considered. Hence, intelligent DSCs are considered a good alternative in order to enable the rapid and efficient deployment of an emergency communication network.",autonomous vehicle
http://arxiv.org/abs/1906.05015v10,filtered,arxiv,arxiv,2019-06-12 09:12:50+00:00,arxiv,"Deep Reinforcement Learning for Unmanned Aerial Vehicle-Assisted
  Vehicular Networks",http://arxiv.org/abs/1906.05015v10,"Unmanned aerial vehicles (UAVs) are envisioned to complement the 5G
communication infrastructure in future smart cities. Hot spots easily appear in
road intersections, where effective communication among vehicles is
challenging. UAVs may serve as relays with the advantages of low price, easy
deployment, line-of-sight links, and flexible mobility. In this paper, we study
a UAV-assisted vehicular network where the UAV jointly adjusts its transmission
control (power and channel) and 3D flight to maximize the total throughput.
First, we formulate a Markov decision process (MDP) problem by modeling the
mobility of the UAV/vehicles and the state transitions. Secondly, we solve the
target problem using a deep reinforcement learning method under unknown or
unmeasurable environment variables especially in 5G, namely, the deep
deterministic policy gradient (DDPG), and propose three solutions with
different control objectives. Environment variables are unknown and
unmeasurable, therefore, we use a deep reinforcement learning method. Moreover,
considering the energy consumption of 3D flight, we extend the proposed
solutions to maximize the total throughput per energy unit by encouraging or
discouraging the UAV's mobility. To achieve this goal, the DDPG framework is
modified. Thirdly, in a simplified model with small state space and action
space, we verify the optimality of proposed algorithms. Comparing with two
baseline schemes, we demonstrate the effectiveness of proposed algorithms in a
realistic model.",autonomous vehicle
http://arxiv.org/abs/1708.08559v2,filtered,arxiv,arxiv,2017-08-28 23:26:14+00:00,arxiv,"DeepTest: Automated Testing of Deep-Neural-Network-driven Autonomous
  Cars",http://arxiv.org/abs/1708.08559v2,"Recent advances in Deep Neural Networks (DNNs) have led to the development of
DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can
drive without any human intervention. Most major manufacturers including Tesla,
GM, Ford, BMW, and Waymo/Google are working on building and testing different
types of autonomous vehicles. The lawmakers of several US states including
California, Texas, and New York have passed new legislation to fast-track the
process of testing and deployment of autonomous vehicles on their roads.
  However, despite their spectacular progress, DNNs, just like traditional
software, often demonstrate incorrect or unexpected corner case behaviors that
can lead to potentially fatal collisions. Several such real-world accidents
involving autonomous cars have already happened including one which resulted in
a fatality. Most existing testing techniques for DNN-driven vehicles are
heavily dependent on the manual collection of test data under different driving
conditions which become prohibitively expensive as the number of test
conditions increases.
  In this paper, we design, implement and evaluate DeepTest, a systematic
testing tool for automatically detecting erroneous behaviors of DNN-driven
vehicles that can potentially lead to fatal crashes. First, our tool is
designed to automatically generated test cases leveraging real-world changes in
driving conditions like rain, fog, lighting conditions, etc. DeepTest
systematically explores different parts of the DNN logic by generating test
inputs that maximize the numbers of activated neurons. DeepTest found thousands
of erroneous behaviors under different realistic driving conditions (e.g.,
blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in
three top performing DNNs in the Udacity self-driving car challenge.",autonomous vehicle
http://arxiv.org/abs/2007.05156v1,filtered,arxiv,arxiv,2020-07-10 04:27:39+00:00,arxiv,"A Survey on Autonomous Vehicle Control in the Era of Mixed-Autonomy:
  From Physics-Based to AI-Guided Driving Policy Learning",http://arxiv.org/abs/2007.05156v1,"This paper serves as an introduction and overview of the potentially useful
models and methodologies from artificial intelligence (AI) into the field of
transportation engineering for autonomous vehicle (AV) control in the era of
mixed autonomy. We will discuss state-of-the-art applications of AI-guided
methods, identify opportunities and obstacles, raise open questions, and help
suggest the building blocks and areas where AI could play a role in mixed
autonomy. We divide the stage of autonomous vehicle (AV) deployment into four
phases: the pure HVs, the HV-dominated, the AVdominated, and the pure AVs. This
paper is primarily focused on the latter three phases. It is the
first-of-its-kind survey paper to comprehensively review literature in both
transportation engineering and AI for mixed traffic modeling. Models used for
each phase are summarized, encompassing game theory, deep (reinforcement)
learning, and imitation learning. While reviewing the methodologies, we
primarily focus on the following research questions: (1) What scalable driving
policies are to control a large number of AVs in mixed traffic comprised of
human drivers and uncontrollable AVs? (2) How do we estimate human driver
behaviors? (3) How should the driving behavior of uncontrollable AVs be modeled
in the environment? (4) How are the interactions between human drivers and
autonomous vehicles characterized? Hopefully this paper will not only inspire
our transportation community to rethink the conventional models that are
developed in the data-shortage era, but also reach out to other disciplines, in
particular robotics and machine learning, to join forces towards creating a
safe and efficient mixed traffic ecosystem.",autonomous vehicle
http://arxiv.org/abs/2102.01740v1,filtered,arxiv,arxiv,2021-02-02 20:25:23+00:00,arxiv,"Reliability Analysis of Artificial Intelligence Systems Using Recurrent
  Events Data from Autonomous Vehicles",http://arxiv.org/abs/2102.01740v1,"Artificial intelligence (AI) systems have become increasingly common and the
trend will continue. Examples of AI systems include autonomous vehicles (AV),
computer vision, natural language processing, and AI medical experts. To allow
for safe and effective deployment of AI systems, the reliability of such
systems needs to be assessed. Traditionally, reliability assessment is based on
reliability test data and the subsequent statistical modeling and analysis. The
availability of reliability data for AI systems, however, is limited because
such data are typically sensitive and proprietary. The California Department of
Motor Vehicles (DMV) oversees and regulates an AV testing program, in which
many AV manufacturers are conducting AV road tests. Manufacturers participating
in the program are required to report recurrent disengagement events to
California DMV. This information is being made available to the public. In this
paper, we use recurrent disengagement events as a representation of the
reliability of the AI system in AV, and propose a statistical framework for
modeling and analyzing the recurrent events data from AV driving tests. We use
traditional parametric models in software reliability and propose a new
nonparametric model based on monotonic splines to describe the event process.
We develop inference procedures for selecting the best models, quantifying
uncertainty, and testing heterogeneity in the event process. We then analyze
the recurrent events data from four AV manufacturers, and make inferences on
the reliability of the AI systems in AV. We also describe how the proposed
analysis can be applied to assess the reliability of other AI systems.",autonomous vehicle
http://arxiv.org/abs/2009.11722v1,filtered,arxiv,arxiv,2020-09-23 09:23:29+00:00,arxiv,"Cloud2Edge Elastic AI Framework for Prototyping and Deployment of AI
  Inference Engines in Autonomous Vehicles",http://arxiv.org/abs/2009.11722v1,"Self-driving cars and autonomous vehicles are revolutionizing the automotive
sector, shaping the future of mobility altogether. Although the integration of
novel technologies such as Artificial Intelligence (AI) and Cloud/Edge
computing provides golden opportunities to improve autonomous driving
applications, there is the need to modernize accordingly the whole prototyping
and deployment cycle of AI components. This paper proposes a novel framework
for developing so-called AI Inference Engines for autonomous driving
applications based on deep learning modules, where training tasks are deployed
elastically over both Cloud and Edge resources, with the purpose of reducing
the required network bandwidth, as well as mitigating privacy issues. Based on
our proposed data driven V-Model, we introduce a simple yet elegant solution
for the AI components development cycle, where prototyping takes place in the
cloud according to the Software-in-the-Loop (SiL) paradigm, while deployment
and evaluation on the target ECUs (Electronic Control Units) is performed as
Hardware-in-the-Loop (HiL) testing. The effectiveness of the proposed framework
is demonstrated using two real-world use-cases of AI inference engines for
autonomous vehicles, that is environment perception and most probable path
prediction.",autonomous vehicle
http://arxiv.org/abs/2011.07699v1,filtered,arxiv,arxiv,2020-11-16 02:56:13+00:00,arxiv,"Efficient falsification approach for autonomous vehicle validation using
  a parameter optimisation technique based on reinforcement learning",http://arxiv.org/abs/2011.07699v1,"The widescale deployment of Autonomous Vehicles (AV) appears to be imminent
despite many safety challenges that are yet to be resolved. It is well-known
that there are no universally agreed Verification and Validation (VV)
methodologies guarantee absolute safety, which is crucial for the acceptance of
this technology. The uncertainties in the behaviour of the traffic participants
and the dynamic world cause stochastic reactions in advanced autonomous
systems. The addition of ML algorithms and probabilistic techniques adds
significant complexity to the process for real-world testing when compared to
traditional methods. Most research in this area focuses on generating
challenging concrete scenarios or test cases to evaluate the system performance
by looking at the frequency distribution of extracted parameters as collected
from the real-world data. These approaches generally employ Monte-Carlo
simulation and importance sampling to generate critical cases. This paper
presents an efficient falsification method to evaluate the System Under Test.
The approach is based on a parameter optimisation problem to search for
challenging scenarios. The optimisation process aims at finding the challenging
case that has maximum return. The method applies policy-gradient reinforcement
learning algorithm to enable the learning. The riskiness of the scenario is
measured by the well established RSS safety metric, euclidean distance, and
instance of a collision. We demonstrate that by using the proposed method, we
can more efficiently search for challenging scenarios which could cause the
system to fail in order to satisfy the safety requirements.",autonomous vehicle
http://arxiv.org/abs/1912.10773v1,filtered,arxiv,arxiv,2019-12-23 12:50:32+00:00,arxiv,A Survey of Deep Learning Applications to Autonomous Vehicle Control,http://arxiv.org/abs/1912.10773v1,"Designing a controller for autonomous vehicles capable of providing adequate
performance in all driving scenarios is challenging due to the highly complex
environment and inability to test the system in the wide variety of scenarios
which it may encounter after deployment. However, deep learning methods have
shown great promise in not only providing excellent performance for complex and
non-linear control problems, but also in generalising previously learned rules
to new scenarios. For these reasons, the use of deep learning for vehicle
control is becoming increasingly popular. Although important advancements have
been achieved in this field, these works have not been fully summarised. This
paper surveys a wide range of research works reported in the literature which
aim to control a vehicle through deep learning methods. Although there exists
overlap between control and perception, the focus of this paper is on vehicle
control, rather than the wider perception problem which includes tasks such as
semantic segmentation and object detection. The paper identifies the strengths
and limitations of available deep learning methods through comparative analysis
and discusses the research challenges in terms of computation, architecture
selection, goal specification, generalisation, verification and validation, as
well as safety. Overall, this survey brings timely and topical information to a
rapidly evolving field relevant to intelligent transportation systems.",autonomous vehicle
http://arxiv.org/abs/1906.07077v1,filtered,arxiv,arxiv,2019-06-17 15:06:47+00:00,arxiv,"The Attack Generator: A Systematic Approach Towards Constructing
  Adversarial Attacks",http://arxiv.org/abs/1906.07077v1,"Most state-of-the-art machine learning (ML) classification systems are
vulnerable to adversarial perturbations. As a consequence, adversarial
robustness poses a significant challenge for the deployment of ML-based systems
in safety- and security-critical environments like autonomous driving, disease
detection or unmanned aerial vehicles. In the past years we have seen an
impressive amount of publications presenting more and more new adversarial
attacks. However, the attack research seems to be rather unstructured and new
attacks often appear to be random selections from the unlimited set of possible
adversarial attacks. With this publication, we present a structured analysis of
the adversarial attack creation process. By detecting different building blocks
of adversarial attacks, we outline the road to new sets of adversarial attacks.
We call this the ""attack generator"". In the pursuit of this objective, we
summarize and extend existing adversarial perturbation taxonomies. The
resulting taxonomy is then linked to the application context of computer vision
systems for autonomous vehicles, i.e. semantic segmentation and object
detection. Finally, in order to prove the usefulness of the attack generator,
we investigate existing semantic segmentation attacks with respect to the
detected defining components of adversarial attacks.",autonomous vehicle
http://arxiv.org/abs/1908.03271v2,filtered,arxiv,arxiv,2019-08-08 21:44:26+00:00,arxiv,"Reflections in the Sky: Millimeter Wave Communication with UAV-Carried
  Intelligent Reflectors",http://arxiv.org/abs/1908.03271v2,"In this paper, a novel approach that uses an unmanned aerial vehicle
(UAV)-carried intelligent reflector (IR) is proposed to enhance the performance
of millimeter wave (mmW) networks. In particular, the UAV-IR is used to
intelligently reflect mmW beamforming signals from a base station towards a
mobile outdoor user, while harvesting energy from mmW signals to power the IR.
To maintain a line-of-sight (LOS) channel, a reinforcement learning (RL)
approach, based on Q-learning and neural networks, is proposed to model the
propagation environment, such that the location and reflection coefficient of
the UAV-IR can be optimized to maximize the downlink transmission capacity.
Simulation results show a significant advantage for using a UAV-IR over a
static IR, in terms of the average data rate and the achievable downlink LOS
probability. The results also show that the RL-based deployment of the UAV-IR
further improves the network performance, relative to a scheme without
learning.",autonomous vehicle
http://arxiv.org/abs/2004.08008v1,filtered,arxiv,arxiv,2020-04-17 00:41:35+00:00,arxiv,"DepthNet Nano: A Highly Compact Self-Normalizing Neural Network for
  Monocular Depth Estimation",http://arxiv.org/abs/2004.08008v1,"Depth estimation is an active area of research in the field of computer
vision, and has garnered significant interest due to its rising demand in a
large number of applications ranging from robotics and unmanned aerial vehicles
to autonomous vehicles. A particularly challenging problem in this area is
monocular depth estimation, where the goal is to infer depth from a single
image. An effective strategy that has shown considerable promise in recent
years for tackling this problem is the utilization of deep convolutional neural
networks. Despite these successes, the memory and computational requirements of
such networks have made widespread deployment in embedded scenarios very
challenging. In this study, we introduce DepthNet Nano, a highly compact self
normalizing network for monocular depth estimation designed using a human
machine collaborative design strategy, where principled network design
prototyping based on encoder-decoder design principles are coupled with
machine-driven design exploration. The result is a compact deep neural network
with highly customized macroarchitecture and microarchitecture designs, as well
as self-normalizing characteristics, that are highly tailored for the task of
embedded depth estimation. The proposed DepthNet Nano possesses a highly
efficient network architecture (e.g., 24X smaller and 42X fewer MAC operations
than Alhashim et al. on KITTI), while still achieving comparable performance
with state-of-the-art networks on the NYU-Depth V2 and KITTI datasets.
Furthermore, experiments on inference speed and energy efficiency on a Jetson
AGX Xavier embedded module further illustrate the efficacy of DepthNet Nano at
different resolutions and power budgets (e.g., ~14 FPS and >0.46
images/sec/watt at 384 X 1280 at a 30W power budget on KITTI).",autonomous vehicle
http://arxiv.org/abs/2006.14544v1,filtered,arxiv,arxiv,2020-06-24 07:39:47+00:00,arxiv,"Machine Learning-Assisted UAV Operations with UTM: Requirements,
  Challenges, and Solutions",http://arxiv.org/abs/2006.14544v1,"Unmanned aerial vehicles (UAVs) are emerging in commercial spaces and will
support many applications and services, such as smart agriculture, dynamic
network deployment, and network coverage extension, surveillance and security.
The unmanned aircraft system (UAS) traffic management (UTM) provides a
framework for safe UAV operation integrating UAV controllers and central data
bases via a communications network. This paper discusses the challenges and
opportunities for machine learning (ML) for effectively providing critical UTM
services. We introduce the four pillars of UTM---operation planning,
situational awareness, status and advisors and security---and discuss the main
services, specific opportunities for ML and the ongoing research. We conclude
that the multi-faceted operating environment and operational parameters will
benefit from collected data and data-driven algorithms, as well as online
learning to face new UAV operation situations.",autonomous vehicle
http://arxiv.org/abs/2110.06775v1,filtered,arxiv,arxiv,2021-10-11 19:38:24+00:00,arxiv,"Using UAVs for vehicle tracking and collision risk assessment at
  intersections",http://arxiv.org/abs/2110.06775v1,"Assessing collision risk is a critical challenge to effective traffic safety
management. The deployment of unmanned aerial vehicles (UAVs) to address this
issue has shown much promise, given their wide visual field and movement
flexibility. This research demonstrates the application of UAVs and V2X
connectivity to track the movement of road users and assess potential
collisions at intersections. The study uses videos captured by UAVs. The
proposed method combines deep-learning based tracking algorithms and
time-to-collision tasks. The results not only provide beneficial information
for vehicle's recognition of potential crashes and motion planning but also
provided a valuable tool for urban road agencies and safety management
engineers.",autonomous vehicle
http://arxiv.org/abs/2007.15286v1,filtered,arxiv,arxiv,2020-07-30 08:00:32+00:00,arxiv,Design Guidelines for Blockchain-Assisted 5G-UAV Networks,http://arxiv.org/abs/2007.15286v1,"Fifth Generation (5G) wireless networks are designed to meet various end-user
Quality of Service (QoS) requirements through high data rates (typically of
Gbps order) and low latencies. Coupled with Fog and Mobile Edge Computing
(MEC), 5G can achieve high data rates, enabling complex autonomous smart city
services such as the large deployment of self-driving vehicles and large-scale
Artificial Intelligence (AI)-enabled industrial manufacturing. However, to meet
the exponentially growing number of connected IoT devices and irregular data
and service requests in both low and highly dense locations, the process of
enacting traditional cells supported through fixed and costly base stations
requires rethought to enable on-demand mobile access points in the form of
Unmanned Aerial Vehicles (UAV) for diversified smart city scenarios. This
article envisions a 5G network environment that is supported by
blockchain-enabled UAVs to meet dynamic user demands with network access
supply. The solution enables decentralized service delivery (Drones as a
Service) and routing to and from end-users in a reliable and secure manner.
Both public and private blockchains are deployed within the UAVs, supported by
fog and cloud computing devices and data centers to provide wide range of
complex authenticated service and data availability. Particular attention is
paid tocomparing data delivery success rates and message exchange in the
proposed solution against traditional UAV-supported cellular networks.
Challenges and future research are also discussed with highlights on emerging
technologies such as Federated Learning.",autonomous vehicle
http://arxiv.org/abs/2104.14006v1,filtered,arxiv,arxiv,2021-04-28 20:24:10+00:00,arxiv,"EmergencyNet: Efficient Aerial Image Classification for Drone-Based
  Emergency Monitoring Using Atrous Convolutional Feature Fusion",http://arxiv.org/abs/2104.14006v1,"Deep learning-based algorithms can provide state-of-the-art accuracy for
remote sensing technologies such as unmanned aerial vehicles (UAVs)/drones,
potentially enhancing their remote sensing capabilities for many emergency
response and disaster management applications. In particular, UAVs equipped
with camera sensors can operating in remote and difficult to access
disaster-stricken areas, analyze the image and alert in the presence of various
calamities such as collapsed buildings, flood, or fire in order to faster
mitigate their effects on the environment and on human population. However, the
integration of deep learning introduces heavy computational requirements,
preventing the deployment of such deep neural networks in many scenarios that
impose low-latency constraints on inference, in order to make mission-critical
decisions in real time. To this end, this article focuses on the efficient
aerial image classification from on-board a UAV for emergency
response/monitoring applications. Specifically, a dedicated Aerial Image
Database for Emergency Response applications is introduced and a comparative
analysis of existing approaches is performed. Through this analysis a
lightweight convolutional neural network architecture is proposed, referred to
as EmergencyNet, based on atrous convolutions to process multiresolution
features and capable of running efficiently on low-power embedded platforms
achieving upto 20x higher performance compared to existing models with minimal
memory requirements with less than 1% accuracy drop compared to
state-of-the-art models.",autonomous vehicle
http://arxiv.org/abs/1805.00061v1,filtered,arxiv,arxiv,2018-04-30 19:08:53+00:00,arxiv,"Machine Learning for Predictive On-Demand Deployment of UAVs for
  Wireless Communications",http://arxiv.org/abs/1805.00061v1,"In this paper, a novel machine learning (ML) framework is proposed for
enabling a predictive, efficient deployment of unmanned aerial vehicles (UAVs),
acting as aerial base stations (BSs), to provide on-demand wireless service to
cellular users. In order to have a comprehensive analysis of cellular traffic,
an ML framework based on a Gaussian mixture model (GMM) and a weighted
expectation maximization (WEM) algorithm is introduced to predict the potential
network congestion. Then, the optimal deployment of UAVs is studied to minimize
the transmit power needed to satisfy the communication demand of users in the
downlink, while also minimizing the power needed for UAV mobility, based on the
predicted cellular traffic. To this end, first, the optimal partition of
service areas of each UAV is derived, based on a fairness principle. Next, the
optimal location of each UAV that minimizes the total power consumption is
derived. Simulation results show that the proposed ML approach can reduce the
required downlink transmit power and improve the power efficiency by over 20%,
compared with an optimal deployment of UAVs with no ML prediction.",autonomous vehicle
http://arxiv.org/abs/2108.10748v1,filtered,arxiv,arxiv,2021-08-23 16:10:14+00:00,arxiv,"Federated Learning for UAV Swarms Under Class Imbalance and Power
  Consumption Constraints",http://arxiv.org/abs/2108.10748v1,"The usage of unmanned aerial vehicles (UAVs) in civil and military
applications continues to increase due to the numerous advantages that they
provide over conventional approaches. Despite the abundance of such advantages,
it is imperative to investigate the performance of UAV utilization while
considering their design limitations. This paper investigates the deployment of
UAV swarms when each UAV carries a machine learning classification task. To
avoid data exchange with ground-based processing nodes, a federated learning
approach is adopted between a UAV leader and the swarm members to improve the
local learning model while avoiding excessive air-to-ground and ground-to-air
communications. Moreover, the proposed deployment framework considers the
stringent energy constraints of UAVs and the problem of class imbalance, where
we show that considering these design parameters significantly improves the
performances of the UAV swarm in terms of classification accuracy, energy
consumption and availability of UAVs when compared with several baseline
algorithms.",autonomous vehicle
http://arxiv.org/abs/2012.06058v1,filtered,arxiv,arxiv,2020-12-11 00:50:09+00:00,arxiv,"Next Wave Artificial Intelligence: Robust, Explainable, Adaptable,
  Ethical, and Accountable",http://arxiv.org/abs/2012.06058v1,"The history of AI has included several ""waves"" of ideas. The first wave, from
the mid-1950s to the 1980s, focused on logic and symbolic hand-encoded
representations of knowledge, the foundations of so-called ""expert systems"".
The second wave, starting in the 1990s, focused on statistics and machine
learning, in which, instead of hand-programming rules for behavior, programmers
constructed ""statistical learning algorithms"" that could be trained on large
datasets. In the most recent wave research in AI has largely focused on deep
(i.e., many-layered) neural networks, which are loosely inspired by the brain
and trained by ""deep learning"" methods. However, while deep neural networks
have led to many successes and new capabilities in computer vision, speech
recognition, language processing, game-playing, and robotics, their potential
for broad application remains limited by several factors.
  A concerning limitation is that even the most successful of today's AI
systems suffer from brittleness-they can fail in unexpected ways when faced
with situations that differ sufficiently from ones they have been trained on.
This lack of robustness also appears in the vulnerability of AI systems to
adversarial attacks, in which an adversary can subtly manipulate data in a way
to guarantee a specific wrong answer or action from an AI system. AI systems
also can absorb biases-based on gender, race, or other factors-from their
training data and further magnify these biases in their subsequent
decision-making. Taken together, these various limitations have prevented AI
systems such as automatic medical diagnosis or autonomous vehicles from being
sufficiently trustworthy for wide deployment. The massive proliferation of AI
across society will require radically new ideas to yield technology that will
not sacrifice our productivity, our quality of life, or our values.",autonomous vehicle
http://arxiv.org/abs/2012.10706v4,filtered,arxiv,arxiv,2020-12-19 14:53:56+00:00,arxiv,Siamese Anchor Proposal Network for High-Speed Aerial Tracking,http://arxiv.org/abs/2012.10706v4,"In the domain of visual tracking, most deep learning-based trackers highlight
the accuracy but casting aside efficiency. Therefore, their real-world
deployment on mobile platforms like the unmanned aerial vehicle (UAV) is
impeded. In this work, a novel two-stage Siamese network-based method is
proposed for aerial tracking, \textit{i.e.}, stage-1 for high-quality anchor
proposal generation, stage-2 for refining the anchor proposal. Different from
anchor-based methods with numerous pre-defined fixed-sized anchors, our
no-prior method can 1) increase the robustness and generalization to different
objects with various sizes, especially to small, occluded, and fast-moving
objects, under complex scenarios in light of the adaptive anchor generation, 2)
make calculation feasible due to the substantial decrease of anchor numbers. In
addition, compared to anchor-free methods, our framework has better performance
owing to refinement at stage-2. Comprehensive experiments on three benchmarks
have proven the superior performance of our approach, with a speed of around
200 frames/s.",autonomous vehicle
http://arxiv.org/abs/1708.05884v4,filtered,arxiv,arxiv,2017-08-19 18:13:23+00:00,arxiv,"Teaching UAVs to Race: End-to-End Regression of Agile Controls in
  Simulation",http://arxiv.org/abs/1708.05884v4,"Automating the navigation of unmanned aerial vehicles (UAVs) in diverse
scenarios has gained much attention in recent years. However, teaching UAVs to
fly in challenging environments remains an unsolved problem, mainly due to the
lack of training data. In this paper, we train a deep neural network to predict
UAV controls from raw image data for the task of autonomous UAV racing in a
photo-realistic simulation. Training is done through imitation learning with
data augmentation to allow for the correction of navigation mistakes. Extensive
experiments demonstrate that our trained network (when sufficient data
augmentation is used) outperforms state-of-the-art methods and flies more
consistently than many human pilots. Additionally, we show that our optimized
network architecture can run in real-time on embedded hardware, allowing for
efficient on-board processing critical for real-world deployment. From a
broader perspective, our results underline the importance of extensive data
augmentation techniques to improve robustness in end-to-end learning setups.",autonomous vehicle
http://arxiv.org/abs/2002.00831v1,filtered,arxiv,arxiv,2020-02-03 15:39:56+00:00,arxiv,An Actor-Critic-Based UAV-BSs Deployment Method for Dynamic Environments,http://arxiv.org/abs/2002.00831v1,"In this paper, the real-time deployment of unmanned aerial vehicles (UAVs) as
flying base stations (BSs) for optimizing the throughput of mobile users is
investigated for UAV networks. This problem is formulated as a time-varying
mixed-integer non-convex programming (MINP) problem, which is challenging to
find an optimal solution in a short time with conventional optimization
techniques. Hence, we propose an actor-critic-based (AC-based) deep
reinforcement learning (DRL) method to find near-optimal UAV positions at every
moment. In the proposed method, the process searching for the solution
iteratively at a particular moment is modeled as a Markov decision process
(MDP). To handle infinite state and action spaces and improve the robustness of
the decision process, two powerful neural networks (NNs) are configured to
evaluate the UAV position adjustments and make decisions, respectively.
Compared with the heuristic algorithm, sequential least-squares programming and
fixed UAVs methods, simulation results have shown that the proposed method
outperforms these three benchmarks in terms of the throughput at every moment
in UAV networks.",autonomous vehicle
http://arxiv.org/abs/2107.13869v2,filtered,arxiv,arxiv,2021-07-29 10:11:36+00:00,arxiv,"Autonomous UAV Base Stations for Next Generation Wireless Networks: A
  Deep Learning Approach",http://arxiv.org/abs/2107.13869v2,"To address the ever-growing connectivity demands of wireless communications,
the adoption of ingenious solutions, such as Unmanned Aerial Vehicles (UAVs) as
mobile Base Stations (BSs), is imperative. In general, the location of a UAV
Base Station (UAV-BS) is determined by optimization algorithms, which have high
computationally complexities and place heavy demands on UAV resources. In this
paper, we show that a Convolutional Neural Network (CNN) model can be trained
to infer the location of a UAV-BS in real time. In so doing, we create a
framework to determine the UAV locations that considers the deployment of
Mobile Users (MUs) to generate labels by using the data obtained from an
optimization algorithm. Performance evaluations reveal that once the CNN model
is trained with the given labels and locations of MUs, the proposed approach is
capable of approximating the results given by the adopted optimization
algorithm with high fidelity, outperforming Reinforcement Learning (RL)-based
approaches. We also explore future research challenges and highlight key
issues.",autonomous vehicle
http://arxiv.org/abs/2103.17162v2,filtered,arxiv,arxiv,2021-03-31 15:25:36+00:00,arxiv,RIS-Assisted UAV for Timely Data Collection in IoT Networks,http://arxiv.org/abs/2103.17162v2,"Intelligent Transportation Systems are thriving thanks to a wide range of
technological advances, namely 5G communications, Internet of Things,
artificial intelligence and edge computing. Central to this is the wide
deployment of smart sensing devices and accordingly the large amount of
harvested information to be processed for timely decision making. Robust
network access is, hence, essential for offloading the collected data before a
set deadline, beyond which the data loses its value. In environments where
direct communication can be impaired by, for instance, blockages such as in
urban cities, unmanned aerial vehicles (UAVs) can be considered as an
alternative for providing and enhancing connectivity, particularly when IoT
devices (IoTD) are constrained with their resources. Also, to conserve energy,
IoTDs are assumed to alternate between their active and passive modes. This
paper, therefore, considers a time-constrained data gathering problem from a
network of sensing devices and with assistance from a UAV. A Reconfigurable
Intelligent Surface (RIS) is deployed to further improve both the connectivity
and energy efficiency of the UAV, particularly when multiple devices are served
concurrently and experience different channel impairments. This integrated
problem brings challenges related to the configuration of the phase shift
elements of the RIS, the scheduling of IoTDs transmissions as well as the
trajectory of the UAV. First, the problem is formulated with the objective of
maximizing the total number of served devices each during its activation
period. Owing to its complexity and the incomplete knowledge about the
environment, we leverage deep reinforcement learning in our solution; the UAV
trajectory planning is modeled as a Markov Decision Process, and Proximal
Policy Optimization is invoked to solve it. Next, the RIS configuration is then
handled via Block Coordinate Descent.",autonomous vehicle
http://arxiv.org/abs/1912.00752v3,filtered,arxiv,arxiv,2019-11-28 03:03:24+00:00,arxiv,"Deep Learning for Optimal Deployment of UAVs with Visible Light
  Communications",http://arxiv.org/abs/1912.00752v3,"In this paper, the problem of dynamical deployment of unmanned aerial
vehicles (UAVs) equipped with visible light communication (VLC) capabilities
for optimizing the energy efficiency of UAV-enabled networks is studied. In the
studied model, the UAVs can simultaneously provide communications and
illumination to service ground users. Since ambient illumination increases the
interference over VLC links while reducing the illumination threshold of the
UAVs, it is necessary to consider the illumination distribution of the target
area for UAV deployment optimization. This problem is formulated as an
optimization problem which jointly optimizes UAV deployment, user association,
and power efficiency while meeting the illumination and communication
requirements of users. To solve this problem, an algorithm that combines the
machine learning framework of gated recurrent units (GRUs) with convolutional
neural networks (CNNs) is proposed. Using GRUs and CNNs, the UAVs can model the
long-term historical illumination distribution and predict the future
illumination distribution. Given the prediction of illumination distribution,
the original nonconvex optimization problem can be divided into two
sub-problems and is then solved using a low-complexity, iterative algorithm.
Then, the proposed algorithm enables UAVs to determine the their deployment and
user association to minimize the total transmit power. Simulation results using
real data from the Earth observations group (EOG) at NOAA/NCEI show that the
proposed approach can achieve up to 68.9% reduction in total transmit power
compared to a conventional optimal UAV deployment that does not consider the
illumination distribution and user association.",autonomous vehicle
http://arxiv.org/abs/1905.04166v1,filtered,arxiv,arxiv,2019-05-10 13:34:18+00:00,arxiv,"An Open Source and Open Hardware Deep Learning-powered Visual Navigation
  Engine for Autonomous Nano-UAVs",http://arxiv.org/abs/1905.04166v1,"Nano-size unmanned aerial vehicles (UAVs), with few centimeters of diameter
and sub-10 Watts of total power budget, have so far been considered incapable
of running sophisticated visual-based autonomous navigation software without
external aid from base-stations, ad-hoc local positioning infrastructure, and
powerful external computation servers. In this work, we present what is, to the
best of our knowledge, the first 27g nano-UAV system able to run aboard an
end-to-end, closed-loop visual pipeline for autonomous navigation based on a
state-of-the-art deep-learning algorithm, built upon the open-source CrazyFlie
2.0 nano-quadrotor. Our visual navigation engine is enabled by the combination
of an ultra-low power computing device (the GAP8 system-on-chip) with a novel
methodology for the deployment of deep convolutional neural networks (CNNs). We
enable onboard real-time execution of a state-of-the-art deep CNN at up to
18Hz. Field experiments demonstrate that the system's high responsiveness
prevents collisions with unexpected dynamic obstacles up to a flight speed of
1.5m/s. In addition, we also demonstrate the capability of our visual
navigation engine of fully autonomous indoor navigation on a 113m previously
unseen path. To share our key findings with the embedded and robotics
communities and foster further developments in autonomous nano-UAVs, we
publicly release all our code, datasets, and trained networks.",autonomous vehicle
http://arxiv.org/abs/1907.12650v2,filtered,arxiv,arxiv,2019-07-30 15:41:01+00:00,arxiv,"Beyond Safety Drivers: Staffing a Teleoperations System for Autonomous
  Vehicles",http://arxiv.org/abs/1907.12650v2,"Driverless vehicles promise a host of societal benefits including
dramatically improved safety, increased accessibility, greater productivity,
and higher quality of life. As this new technology approaches widespread
deployment, both industry and government are making provisions for
teleoperations systems, in which remote human agents provide assistance to
driverless vehicles. This assistance can involve real-time remote operation and
even ahead-of-time input via human-in-the-loop artificial intelligence systems.
In this paper, we address the problem of staffing such a remote support center.
Our analysis focuses on the tradeoffs between the total number of remote
agents, the reliability of the remote support system, and the resulting safety
of the driverless vehicles. By establishing a novel connection between queues
with large batch arrivals and storage processes, we determine the probability
of the system exceeding its service capacity. This connection drives our
staffing methodology. We also develop a numerical method to compute the exact
staffing level needed to achieve various performance measures. This moment
generating function based technique may be of independent interest, and our
overall staffing analysis may be of use in other applications that combine
human expertise and automated systems.",autonomous vehicle
http://arxiv.org/abs/2103.10873v1,filtered,arxiv,arxiv,2021-03-19 15:56:58+00:00,arxiv,"Fully Onboard AI-powered Human-Drone Pose Estimation on Ultra-low Power
  Autonomous Flying Nano-UAVs",http://arxiv.org/abs/2103.10873v1,"Artificial intelligence-powered pocket-sized air robots have the potential to
revolutionize the Internet-of-Things ecosystem, acting as autonomous,
unobtrusive, and ubiquitous smart sensors. With a few cm$^{2}$ form-factor,
nano-sized unmanned aerial vehicles (UAVs) are the natural befit for indoor
human-drone interaction missions, as the pose estimation task we address in
this work. However, this scenario is challenged by the nano-UAVs' limited
payload and computational power that severely relegates the onboard brain to
the sub-100 mW microcontroller unit-class. Our work stands at the intersection
of the novel parallel ultra-low-power (PULP) architectural paradigm and our
general development methodology for deep neural network (DNN) visual pipelines,
i.e., covering from perception to control. Addressing the DNN model design,
from training and dataset augmentation to 8-bit quantization and deployment, we
demonstrate how a PULP-based processor, aboard a nano-UAV, is sufficient for
the real-time execution (up to 135 frame/s) of our novel DNN, called
PULP-Frontnet. We showcase how, scaling our model's memory and computational
requirement, we can significantly improve the onboard inference (top energy
efficiency of 0.43 mJ/frame) with no compromise in the quality-of-result vs. a
resource-unconstrained baseline (i.e., full-precision DNN). Field experiments
demonstrate a closed-loop top-notch autonomous navigation capability, with a
heavily resource-constrained 27-gram Crazyflie 2.1 nano-quadrotor. Compared
against the control performance achieved using an ideal sensing setup, onboard
relative pose inference yields excellent drone behavior in terms of median
absolute errors, such as positional (onboard: 41 cm, ideal: 26 cm) and angular
(onboard: 3.7$^{\circ}$, ideal: 4.1$^{\circ}$).",autonomous vehicle
http://arxiv.org/abs/1807.02009v1,filtered,arxiv,arxiv,2018-07-05 13:56:58+00:00,arxiv,"On-Demand Deployment of Multiple Aerial Base Stations for Traffic
  Offloading and Network Recovery",http://arxiv.org/abs/1807.02009v1,"Unmanned aerial vehicles (UAVs) are being utilized for a wide spectrum of
applications in wireless networks leading to attractive business opportunities.
In the case of abrupt disruption to existing cellular network operation or
infrastructure, e.g., due to an unexpected surge in user demand or a natural
disaster, UAVs can be deployed to provide instant recovery via temporary
wireless coverage in designated areas. A major challenge is to determine
efficiently how many UAVs are needed and where to position them in a relatively
large 3D search space. To this end, we formulate the problem of 3D deployment
of a fleet of UAVs as a mixed integer linear program, and present a greedy
approach that mimics the optimal behavior assuming a grid composed of a finite
set of possible UAV locations. In addition, we propose and evaluate a novel low
complexity algorithm for multiple UAV deployment in a continuous 3D space,
based on an unsupervised learning technique that relies on the notion of
electrostatics with repulsion and attraction forces. We present performance
results for the proposed algorithm as a function of various system parameters
and demonstrate its effectiveness compared to the close-to-optimal greedy
approach and its superiority compared to recent related work from the
literature.",autonomous vehicle
http://arxiv.org/abs/1904.07961v1,filtered,arxiv,arxiv,2019-04-08 20:15:39+00:00,arxiv,"RL-Based User Association and Resource Allocation for Multi-UAV enabled
  MEC",http://arxiv.org/abs/1904.07961v1,"In this paper, multi-unmanned aerial vehicle (UAV) enabled mobile edge
computing (MEC), i.e., UAVE is studied, where several UAVs are deployed as
flying MEC platform to provide computing resource to ground user equipments
(UEs). Compared to the traditional fixed location MEC, UAV enabled MEC (i.e.,
UAVE) is particular useful in case of temporary events, emergency situations
and on-demand services, due to its high flexibility, low cost and easy
deployment features. However, operation of UAVE faces several challenges, two
of which are how to achieve both 1) the association between multiple UEs and
UAVs and 2) the resource allocation from UAVs to UEs, while minimizing the
energy consumption for all the UEs. To address this, we formulate the above
problem into a mixed integer nonlinear programming (MINLP), which is difficult
to be solved in general, especially in the large-scale scenario. We then
propose a Reinforcement Learning (RL)-based user Association and resource
Allocation (RLAA) algorithm to tackle this problem efficiently and effectively.
Numerical results show that the proposed RLAA can achieve the optimal
performance with comparison to the exhaustive search in small scale, and have
considerable performance gain over other typical algorithms in large-scale
cases.",autonomous vehicle
http://arxiv.org/abs/2002.01546v2,filtered,arxiv,arxiv,2020-02-04 21:27:16+00:00,arxiv,"Mobility Management for Cellular-Connected UAVs: A Learning-Based
  Approach",http://arxiv.org/abs/2002.01546v2,"The pervasiveness of the wireless cellular network can be a key enabler for
the deployment of autonomous unmanned aerial vehicles (UAVs) in beyond visual
line of sight scenarios without human control. However, traditional cellular
networks are optimized for ground user equipment (GUE) such as smartphones
which makes providing connectivity to flying UAVs very challenging. Moreover,
ensuring better connectivity to a moving cellular-connected UAV is notoriously
difficult due to the complex air-to-ground path loss model. In this paper, a
novel mechanism is proposed to ensure robust wireless connectivity and mobility
support for cellular-connected UAVs by tuning the downtilt (DT) angles of all
the GBSs. By leveraging tools from reinforcement learning (RL), DT angles are
dynamically adjusted by using a model-free RL algorithm. The goal is to provide
efficient mobility support in the sky by maximizing the received signal quality
at the UAV while also maintaining good throughput performance of the ground
users. Simulation results show that the proposed RL-based mobility management
(MM) technique can reduce the number of handovers while maintaining the
performance goals, compared to the baseline MM scheme in which the network
always keeps the DT angle fixed.",autonomous vehicle
http://arxiv.org/abs/2002.08415v1,filtered,arxiv,arxiv,2020-02-19 20:09:46+00:00,arxiv,UAV Aided Search and Rescue Operation Using Reinforcement Learning,http://arxiv.org/abs/2002.08415v1,"Owing to the enhanced flexibility in deployment and decreasing costs of
manufacturing, the demand for unmanned aerial vehicles (UAVs) is expected to
soar in the upcoming years. In this paper, we explore a UAV aided search and
rescue~(SAR) operation in indoor environments, where the GPS signals might not
be reliable. We consider a SAR scenario where the UAV tries to locate a victim
trapped in an indoor environment by sensing the RF signals emitted from a smart
device owned by the victim. To locate the victim as fast as possible, we
leverage tools from reinforcement learning~(RL). Received signal strength~(RSS)
at the UAV depends on the distance from the source, indoor shadowing, and
fading parameters, and antenna radiation pattern of the receiver mounted on the
UAV. To make our analysis more realistic, we model two indoor scenarios with
different dimensions using commercial ray-tracing software. Then, the
corresponding RSS values at each possible discrete UAV location are extracted
and used in a Q-learning framework. Unlike the traditional location-based
navigation approach that exploits GPS coordinates, our method uses the RSS to
define the states and rewards of the RL algorithm. We compare the performance
of the proposed method where directional and omnidirectional antennas are used.
The results reveal that the use of directional antennas provides faster
convergence rates than the omnidirectional antennas.",autonomous vehicle
http://arxiv.org/abs/2007.00544v2,filtered,arxiv,arxiv,2020-07-01 15:14:16+00:00,arxiv,"UAV Path Planning for Wireless Data Harvesting: A Deep Reinforcement
  Learning Approach",http://arxiv.org/abs/2007.00544v2,"Autonomous deployment of unmanned aerial vehicles (UAVs) supporting
next-generation communication networks requires efficient trajectory planning
methods. We propose a new end-to-end reinforcement learning (RL) approach to
UAV-enabled data collection from Internet of Things (IoT) devices in an urban
environment. An autonomous drone is tasked with gathering data from distributed
sensor nodes subject to limited flying time and obstacle avoidance. While
previous approaches, learning and non-learning based, must perform expensive
recomputations or relearn a behavior when important scenario parameters such as
the number of sensors, sensor positions, or maximum flying time, change, we
train a double deep Q-network (DDQN) with combined experience replay to learn a
UAV control policy that generalizes over changing scenario parameters. By
exploiting a multi-layer map of the environment fed through convolutional
network layers to the agent, we show that our proposed network architecture
enables the agent to make movement decisions for a variety of scenario
parameters that balance the data collection goal with flight time efficiency
and safety constraints. Considerable advantages in learning efficiency from
using a map centered on the UAV's position over a non-centered map are also
illustrated.",autonomous vehicle
http://arxiv.org/abs/2007.14297v1,filtered,arxiv,arxiv,2020-07-28 15:13:06+00:00,arxiv,"Cooperative Internet of UAVs: Distributed Trajectory Design by
  Multi-agent Deep Reinforcement Learning",http://arxiv.org/abs/2007.14297v1,"Due to the advantages of flexible deployment and extensive coverage, unmanned
aerial vehicles (UAVs) have great potential for sensing applications in the
next generation of cellular networks, which will give rise to a cellular
Internet of UAVs. In this paper, we consider a cellular Internet of UAVs, where
the UAVs execute sensing tasks through cooperative sensing and transmission to
minimize the age of information (AoI). However, the cooperative sensing and
transmission is tightly coupled with the UAVs' trajectories, which makes the
trajectory design challenging. To tackle this challenge, we propose a
distributed sense-and-send protocol, where the UAVs determine the trajectories
by selecting from a discrete set of tasks and a continuous set of locations for
sensing and transmission. Based on this protocol, we formulate the trajectory
design problem for AoI minimization and propose a compound-action actor-critic
(CA2C) algorithm to solve it based on deep reinforcement learning. The CA2C
algorithm can learn the optimal policies for actions involving both continuous
and discrete variables and is suited for the trajectory design. {Our simulation
results show that the CA2C algorithm outperforms four baseline algorithms}.
Also, we show that by dividing the tasks, cooperative UAVs can achieve a lower
AoI compared to non-cooperative UAVs.",autonomous vehicle
http://arxiv.org/abs/2011.01840v1,filtered,arxiv,arxiv,2020-11-03 16:50:37+00:00,arxiv,"Distributional Reinforcement Learning for mmWave Communications with
  Intelligent Reflectors on a UAV",http://arxiv.org/abs/2011.01840v1,"In this paper, a novel communication framework that uses an unmanned aerial
vehicle (UAV)-carried intelligent reflector (IR) is proposed to enhance
multi-user downlink transmissions over millimeter wave (mmWave) frequencies. In
order to maximize the downlink sum-rate, the optimal precoding matrix (at the
base station) and reflection coefficient (at the IR) are jointly derived. Next,
to address the uncertainty of mmWave channels and maintain line-of-sight links
in a real-time manner, a distributional reinforcement learning approach, based
on quantile regression optimization, is proposed to learn the propagation
environment of mmWave communications, and, then, optimize the location of the
UAV-IR so as to maximize the long-term downlink communication capacity.
Simulation results show that the proposed learning-based deployment of the
UAV-IR yields a significant advantage, compared to a non-learning UAV-IR, a
static IR, and a direct transmission schemes, in terms of the average data rate
and the achievable line-of-sight probability of downlink mmWave communications.",autonomous vehicle
http://arxiv.org/abs/1803.00680v2,filtered,arxiv,arxiv,2018-03-02 01:34:06+00:00,arxiv,"A Tutorial on UAVs for Wireless Networks: Applications, Challenges, and
  Open Problems",http://arxiv.org/abs/1803.00680v2,"The use of flying platforms such as unmanned aerial vehicles (UAVs),
popularly known as drones, is rapidly growing. In particular, with their
inherent attributes such as mobility, flexibility, and adaptive altitude, UAVs
admit several key potential applications in wireless systems. On the one hand,
UAVs can be used as aerial base stations to enhance coverage, capacity,
reliability, and energy efficiency of wireless networks. On the other hand,
UAVs can operate as flying mobile terminals within a cellular network. Such
cellular-connected UAVs can enable several applications ranging from real-time
video streaming to item delivery. In this paper, a comprehensive tutorial on
the potential benefits and applications of UAVs in wireless communications is
presented. Moreover, the important challenges and the fundamental tradeoffs in
UAV-enabled wireless networks are thoroughly investigated. In particular, the
key UAV challenges such as three-dimensional deployment, performance analysis,
channel modeling, and energy efficiency are explored along with representative
results. Then, open problems and potential research directions pertaining to
UAV communications are introduced. Finally, various analytical frameworks and
mathematical tools such as optimization theory, machine learning, stochastic
geometry, transport theory, and game theory are described. The use of such
tools for addressing unique UAV problems is also presented. In a nutshell, this
tutorial provides key guidelines on how to analyze, optimize, and design
UAV-based wireless communication systems.",autonomous vehicle
http://arxiv.org/abs/1810.09729v1,filtered,arxiv,arxiv,2018-10-23 08:51:54+00:00,arxiv,"Design Challenges of Multi-UAV Systems in Cyber-Physical Applications: A
  Comprehensive Survey, and Future Directions",http://arxiv.org/abs/1810.09729v1,"Unmanned Aerial Vehicles (UAVs) have recently rapidly grown to facilitate a
wide range of innovative applications that can fundamentally change the way
cyber-physical systems (CPSs) are designed. CPSs are a modern generation of
systems with synergic cooperation between computational and physical potentials
that can interact with humans through several new mechanisms. The main
advantages of using UAVs in CPS application is their exceptional features,
including their mobility, dynamism, effortless deployment, adaptive altitude,
agility, adjustability, and effective appraisal of real-world functions anytime
and anywhere. Furthermore, from the technology perspective, UAVs are predicted
to be a vital element of the development of advanced CPSs. Therefore, in this
survey, we aim to pinpoint the most fundamental and important design challenges
of multi-UAV systems for CPS applications. We highlight key and versatile
aspects that span the coverage and tracking of targets and infrastructure
objects, energy-efficient navigation, and image analysis using machine learning
for fine-grained CPS applications. Key prototypes and testbeds are also
investigated to show how these practical technologies can facilitate CPS
applications. We present and propose state-of-the-art algorithms to address
design challenges with both quantitative and qualitative methods and map these
challenges with important CPS applications to draw insightful conclusions on
the challenges of each application. Finally, we summarize potential new
directions and ideas that could shape future research in these areas.",autonomous vehicle
http://arxiv.org/abs/1910.13538v1,filtered,arxiv,arxiv,2019-10-29 21:16:50+00:00,arxiv,"Machine-Learning Beam Tracking and Weight Optimization for mmWave
  Multi-UAV Links",http://arxiv.org/abs/1910.13538v1,"Millimeter-wave (mmWave) hybrid analog-digital beamforming is a promising
approach to satisfy the low-latency constraint in multiple unmanned aerial
vehicles (UAVs) systems, which serve as network infrastructure for flexible
deployment. However, in highly dynamic multi-UAV environments, analog beam
tracking becomes a critical challenge. The overhead of additional pilot
transmission at the price of spectral efficiency is shown necessary to achieve
high resilience in operation. An efficient method to deal with high dynamics of
UAVs applies machine learning, particularly Q-learning, to analog beam
tracking. The proposed Q-learning-based beam tracking scheme uses current/past
observations to design rewards from environments to facilitate prediction,
which significantly increases the efficiency of data transmission and beam
switching. Given the selected analog beams, the goal of digital beamforming is
to maximize the SINR. The received pilot signals are utilized to approximate
the desired signal and interference power, which yield the SINR measurements as
well as the optimal digital weights. Since the selected analog beams based on
the received power do not guarantee the hybrid beamforming achieving the
maximization SINR, we therefore reserve additional analog beams as candidates
during the beam tracking. The combination of analog beams with their digital
weights achieving the maximum SINR consequently provides the optimal solution
to the hybrid beamforming.",autonomous vehicle
http://arxiv.org/abs/2001.11610v1,filtered,arxiv,arxiv,2020-01-30 23:49:15+00:00,arxiv,"UAV Autonomous Localization using Macro-Features Matching with a CAD
  Model",http://arxiv.org/abs/2001.11610v1,"Research in the field of autonomous Unmanned Aerial Vehicles (UAVs) has
significantly advanced in recent years, mainly due to their relevance in a
large variety of commercial, industrial, and military applications. However,
UAV navigation in GPS-denied environments continues to be a challenging problem
that has been tackled in recent research through sensor-based approaches. This
paper presents a novel offline, portable, real-time in-door UAV localization
technique that relies on macro-feature detection and matching. The proposed
system leverages the support of machine learning, traditional computer vision
techniques, and pre-existing knowledge of the environment. The main
contribution of this work is the real-time creation of a macro-feature
description vector from the UAV captured images which are simultaneously
matched with an offline pre-existing vector from a Computer-Aided Design (CAD)
model. This results in a quick UAV localization within the CAD model. The
effectiveness and accuracy of the proposed system were evaluated through
simulations and experimental prototype implementation. Final results reveal the
algorithm's low computational burden as well as its ease of deployment in
GPS-denied environments.",autonomous vehicle
http://arxiv.org/abs/2003.02631v2,filtered,arxiv,arxiv,2020-03-02 00:15:09+00:00,arxiv,Machine Learning for Predictive Deployment of UAVs with Multiple Access,http://arxiv.org/abs/2003.02631v2,"In this paper, a machine learning based deployment framework of unmanned
aerial vehicles (UAVs) is studied. In the considered model, UAVs are deployed
as flying base stations (BS) to offload heavy traffic from ground BSs. Due to
time-varying traffic distribution, a long short-term memory (LSTM) based
prediction algorithm is introduced to predict the future cellular traffic. To
predict the user service distribution, a KEG algorithm, which is a joint
K-means and expectation maximization (EM) algorithm based on Gaussian mixture
model (GMM), is proposed for determining the service area of each UAV. Based on
the predicted traffic, the optimal UAV positions are derived and three
multi-access techniques are compared so as to minimize the total transmit
power. Simulation results show that the proposed method can reduce up to 24\%
of the total power consumption compared to the conventional method without
traffic prediction. Besides, rate splitting multiple access (RSMA) has the
lower required transmit power compared to frequency domain multiple access
(FDMA) and time domain multiple access (TDMA).",autonomous vehicle
http://arxiv.org/abs/2103.01143v4,filtered,arxiv,arxiv,2021-03-01 17:28:16+00:00,arxiv,Towards 6G with Connected Sky: UAVs and Beyond,http://arxiv.org/abs/2103.01143v4,"The large-scale and ever-growing use of unmanned aerial vehicles (UAVs) in a
wide range of applications is foreseen to be a major part of beyond 5G and 6G
wireless networks in the next decade. The effective support of such massive
deployment of UAVs requires offering reliable, secure, and cost-effective
wireless connectivity. In this regard, cellular networks play essential roles
in serving UAVs acting as flying user equipments. While the cellular networks
provide promising connectivity solutions for UAVs, enabling robust UAV
operations faces several challenges. In this paper, an overview of key barriers
and design considerations of widespread commercial use of flying UAVs are
presented along with their potential solutions. In addition, we discuss how
cellular networks can support UAVs by relying on their advanced features,
network intelligence, key enabling technologies for beyond 5G and 6G, and
exploiting new tools from machine learning. Finally, we shed light on offering
wireless services to high altitudes and the integration of non-terrestrial
networks with terrestrial networks towards limitless connectivity in 6G.",autonomous vehicle
http://arxiv.org/abs/2106.07314v1,filtered,arxiv,arxiv,2021-06-14 11:38:13+00:00,arxiv,"Computer Vision Tool for Detection, Mapping and Fault Classification of
  PV Modules in Aerial IR Videos",http://arxiv.org/abs/2106.07314v1,"Increasing deployment of photovoltaics (PV) plants demands for cheap and fast
inspection. A viable tool for this task is thermographic imaging by unmanned
aerial vehicles (UAV). In this work, we develop a computer vision tool for the
semi-automatic extraction of PV modules from thermographic UAV videos. We use
it to curate a dataset containing 4.3 million IR images of 107842 PV modules
from thermographic videos of seven different PV plants. To demonstrate its use
for automated PV plant inspection, we train a ResNet-50 to classify ten common
module anomalies with more than 90 % test accuracy. Experiments show that our
tool generalizes well to different PV plants. It successfully extracts PV
modules from 512 out of 561 plant rows. Failures are mostly due to an
inappropriate UAV trajectory and erroneous module segmentation. Including all
manual steps our tool enables inspection of 3.5 MW p to 9 MW p of PV
installations per day, potentially scaling to multi-gigawatt plants due to its
parallel nature. While we present an effective method for automated PV plant
inspection, we are also confident that our approach helps to meet the growing
demand for large thermographic datasets for machine learning tasks, such as
power prediction or unsupervised defect identification.",autonomous vehicle
http://arxiv.org/abs/2108.01884v1,filtered,arxiv,arxiv,2021-08-04 07:30:04+00:00,arxiv,"Adaptive Path Planning for UAV-based Multi-Resolution Semantic
  Segmentation",http://arxiv.org/abs/2108.01884v1,"In this paper, we address the problem of adaptive path planning for accurate
semantic segmentation of terrain using unmanned aerial vehicles (UAVs). The
usage of UAVs for terrain monitoring and remote sensing is rapidly gaining
momentum due to their high mobility, low cost, and flexible deployment.
However, a key challenge is planning missions to maximize the value of acquired
data in large environments given flight time limitations. To address this, we
propose an online planning algorithm which adapts the UAV paths to obtain
high-resolution semantic segmentations necessary in areas on the terrain with
fine details as they are detected in incoming images. This enables us to
perform close inspections at low altitudes only where required, without wasting
energy on exhaustive mapping at maximum resolution. A key feature of our
approach is a new accuracy model for deep learning-based architectures that
captures the relationship between UAV altitude and semantic segmentation
accuracy. We evaluate our approach on the application of crop/weed segmentation
in precision agriculture using real-world field data.",autonomous vehicle
http://arxiv.org/abs/1804.00294v1,filtered,arxiv,arxiv,2018-04-01 13:05:05+00:00,arxiv,QoS-Aware Routing in Wireless Networks Using Aerial Vehicles,http://arxiv.org/abs/1804.00294v1,"The next generation wireless networks need efficient mechanisms for data
dissemination that should support users with better Quality of Service (QoS).
Nevertheless, the existing solutions are unable to handle this demand and
require either network redeployment or replanning. Moreover, this upsurges the
overall operational cost and complexity of the network. This problem can be
addressed by deploying Unmanned Aerial Vehicles (UAVs), which can act as
on-demand relays in next generation wireless networks. In this work, a novel
strategy comprising a series of algorithms based on neural networks is devised,
which resolves the issues related to data dissemination, QoS, capacity, and
coverage. When compared with the existing methods, the proposed approach
demonstrates better outcomes for various parameters, namely, throughput,
message disseminations, service dissemination rate, UAV allocation time, route
acquisition delay, link utilization and signal to noise ratio for end users.
The experimental results exhibit the fact that the proposed approach utilizes
39.6%, 41.6%, 43.5%, 44.4%, and 46.9% lesser iterations than the EEDD, A-Star,
OCD, GPCR, and GyTAR, respectively. Therefore, it is evident that the proposed
approach surpasses the existing methods by means of superior performance and
augmented efficiency.",autonomous vehicle
http://arxiv.org/abs/1807.06789v1,filtered,arxiv,arxiv,2018-07-18 06:30:54+00:00,arxiv,"DroNet: Efficient convolutional neural network detector for real-time
  UAV applications",http://arxiv.org/abs/1807.06789v1,"Unmanned Aerial Vehicles (drones) are emerging as a promising technology for
both environmental and infrastructure monitoring, with broad use in a plethora
of applications. Many such applications require the use of computer vision
algorithms in order to analyse the information captured from an on-board
camera. Such applications include detecting vehicles for emergency response and
traffic monitoring. This paper therefore, explores the trade-offs involved in
the development of a single-shot object detector based on deep convolutional
neural networks (CNNs) that can enable UAVs to perform vehicle detection under
a resource constrained environment such as in a UAV. The paper presents a
holistic approach for designing such systems; the data collection and training
stages, the CNN architecture, and the optimizations necessary to efficiently
map such a CNN on a lightweight embedded processing platform suitable for
deployment on UAVs. Through the analysis we propose a CNN architecture that is
capable of detecting vehicles from aerial UAV images and can operate between
5-18 frames-per-second for a variety of platforms with an overall accuracy of
~95%. Overall, the proposed architecture is suitable for UAV applications,
utilizing low-power embedded processors that can be deployed on commercial
UAVs.",autonomous vehicle
http://arxiv.org/abs/2102.13253v1,filtered,arxiv,arxiv,2021-02-26 01:31:28+00:00,arxiv,"On the Visual-based Safe Landing of UAVs in Populated Areas: a Crucial
  Aspect for Urban Deployment",http://arxiv.org/abs/2102.13253v1,"Autonomous landing of Unmanned Aerial Vehicles (UAVs) in crowded scenarios is
crucial for successful deployment of UAVs in populated areas, particularly in
emergency landing situations where the highest priority is to avoid hurting
people. In this work, a new visual-based algorithm for identifying Safe Landing
Zones (SLZ) in crowded scenarios is proposed, considering a camera mounted on
an UAV, where the people in the scene move with unknown dynamics. To do so, a
density map is generated for each image frame using a Deep Neural Network, from
where a binary occupancy map is obtained aiming to overestimate the people's
location for security reasons. Then, the occupancy map is projected to the
head's plane, and the SLZ candidates are obtained as circular regions in the
head's plane with a minimum security radius. Finally, to keep track of the SLZ
candidates, a multiple instance tracking algorithm is implemented using Kalman
Filters along with the Hungarian algorithm for data association. Several
scenarios were studied to prove the validity of the proposed strategy,
including public datasets and real uncontrolled scenarios with people moving in
public squares, taken from an UAV in flight. The study showed promising results
in the search of preventing the UAV from hurting people during emergency
landing.",autonomous vehicle
http://arxiv.org/abs/2004.13351v1,filtered,arxiv,arxiv,2020-04-28 08:04:06+00:00,arxiv,Communication-Efficient Edge AI Inference Over Wireless Networks,http://arxiv.org/abs/2004.13351v1,"Given the fast growth of intelligent devices, it is expected that a large
number of high-stake artificial intelligence (AI) applications, e.g., drones,
autonomous cars, tactile robots, will be deployed at the edge of wireless
networks in the near future. As such, the intelligent communication networks
will be designed to leverage advanced wireless techniques and edge computing
technologies to support AI-enabled applications at various end devices with
limited communication, computation, hardware and energy resources. In this
article, we shall present the principles of efficient deployment of model
inference at network edge to provide low-latency and energy-efficient AI
services. This includes the wireless distributed computing framework for
low-latency device distributed model inference as well as the wireless
cooperative transmission strategy for energy-efficient edge cooperative model
inference. The communication efficiency of edge inference systems is further
improved by building up a smart radio propagation environment via intelligent
reflecting surface.",autonomous vehicle
http://arxiv.org/abs/1812.03216v1,filtered,arxiv,arxiv,2018-12-07 21:05:22+00:00,arxiv,"Zero-shot Deep Reinforcement Learning Driving Policy Transfer for
  Autonomous Vehicles based on Robust Control",http://arxiv.org/abs/1812.03216v1,"Although deep reinforcement learning (deep RL) methods have lots of strengths
that are favorable if applied to autonomous driving, real deep RL applications
in autonomous driving have been slowed down by the modeling gap between the
source (training) domain and the target (deployment) domain. Unlike current
policy transfer approaches, which generally limit to the usage of
uninterpretable neural network representations as the transferred features, we
propose to transfer concrete kinematic quantities in autonomous driving. The
proposed robust-control-based (RC) generic transfer architecture, which we call
RL-RC, incorporates a transferable hierarchical RL trajectory planner and a
robust tracking controller based on disturbance observer (DOB). The deep RL
policies trained with known nominal dynamics model are transfered directly to
the target domain, DOB-based robust tracking control is applied to tackle the
modeling gap including the vehicle dynamics errors and the external
disturbances such as side forces. We provide simulations validating the
capability of the proposed method to achieve zero-shot transfer across multiple
driving scenarios such as lane keeping, lane changing and obstacle avoidance.",autonomous vehicle
http://arxiv.org/abs/1905.02993v2,filtered,arxiv,arxiv,2019-05-08 10:14:37+00:00,arxiv,"Deep Reinforcement Learning for Minimizing Age-of-Information in
  UAV-assisted Networks",http://arxiv.org/abs/1905.02993v2,"Unmanned aerial vehicles (UAVs) are expected to be a key component of the
next-generation wireless systems. Due to their deployment flexibility, UAVs are
being considered as an efficient solution for collecting information data from
ground nodes and transmitting it wirelessly to the network. In this paper, a
UAV-assisted wireless network is studied, in which energy-constrained ground
nodes are deployed to observe different physical processes. In this network, a
UAV that has a time constraint for its operation due to its limited battery,
moves towards the ground nodes to receive status update packets about their
observed processes. The flight trajectory of the UAV and scheduling of status
update packets are jointly optimized with the objective of achieving the
minimum weighted sum for the age-of-information (AoI) values of different
processes at the UAV, referred to as weighted sum-AoI. The problem is modeled
as a finite-horizon Markov decision process (MDP) with finite state and action
spaces. Since the state space is extremely large, a deep reinforcement learning
(RL) algorithm is proposed to obtain the optimal policy that minimizes the
weighted sum-AoI, referred to as the age-optimal policy. Several simulation
scenarios are considered to showcase the convergence of the proposed deep RL
algorithm. Moreover, the results also demonstrate that the proposed deep RL
approach can significantly improve the achievable sum-AoI per process compared
to the baseline policies, such as the distance-based and random walk policies.
The impact of various system design parameters on the optimal achievable
sum-AoI per process is also shown through extensive simulations.",autonomous vehicle
http://arxiv.org/abs/1610.01585v1,filtered,arxiv,arxiv,2016-10-05 19:41:12+00:00,arxiv,"Caching in the Sky: Proactive Deployment of Cache-Enabled Unmanned
  Aerial Vehicles for Optimized Quality-of-Experience",http://arxiv.org/abs/1610.01585v1,"In this paper, the problem of proactive deployment of cache-enabled unmanned
aerial vehicles (UAVs) for optimizing the quality-of-experience (QoE) of
wireless devices in a cloud radio access network (CRAN) is studied. In the
considered model, the network can leverage human-centric information such as
users' visited locations, requested contents, gender, job, and device type to
predict the content request distribution and mobility pattern of each user.
Then, given these behavior predictions, the proposed approach seeks to find the
user-UAV associations, the optimal UAVs' locations, and the contents to cache
at UAVs. This problem is formulated as an optimization problem whose goal is to
maximize the users' QoE while minimizing the transmit power used by the UAVs.
To solve this problem, a novel algorithm based on the machine learning
framework of conceptor-based echo state networks (ESNs) is proposed. Using
ESNs, the network can effectively predict each user's content request
distribution and its mobility pattern when limited information on the states of
users and the network is available. Based on the predictions of the users'
content request distribution and their mobility patterns, we derive the optimal
user-UAV association, optimal locations of the UAVs as well as the content to
cache at UAVs. Simulation results using real pedestrian mobility patterns from
BUPT and actual content transmission data from Youku show that the proposed
algorithm can yield 40% and 61% gains, respectively, in terms of the average
transmit power and the percentage of the users with satisfied QoE compared to a
benchmark algorithm without caching and a benchmark solution without UAVs.",autonomous vehicle
http://arxiv.org/abs/1909.07554v1,filtered,arxiv,arxiv,2019-09-17 02:22:09+00:00,arxiv,"Gated Recurrent Units Learning for Optimal Deployment of Visible Light
  Communications Enabled UAVs",http://arxiv.org/abs/1909.07554v1,"In this paper, the problem of optimizing the deployment of unmanned aerial
vehicles (UAVs) equipped with visible light communication (VLC) capabilities is
studied. In the studied model, the UAVs can simultaneously provide
communications and illumination to service ground users. Ambient illumination
increases the interference over VLC links while reducing the illumination
threshold of the UAVs. Therefore, it is necessary to consider the illumination
distribution of the target area for UAV deployment optimization. This problem
is formulated as an optimization problem whose goal is to minimize the total
transmit power while meeting the illumination and communication requirements of
users. To solve this problem, an algorithm based on the machine learning
framework of gated recurrent units (GRUs) is proposed. Using GRUs, the UAVs can
model the long-term historical illumination distribution and predict the future
illumination distribution. In order to reduce the complexity of the prediction
algorithm while accurately predicting the illumination distribution, a Gaussian
mixture model (GMM) is used to fit the illumination distribution of the target
area at each time slot. Based on the predicted illumination distribution, the
optimization problem is proved to be a convex optimization problem that can be
solved by using duality. Simulations using real data from the Earth
observations group (EOG) at NOAA/NCEI show that the proposed approach can
achieve up to 22.1% reduction in transmit power compared to a conventional
optimal UAV deployment that does not consider the illumination distribution.
The results also show that UAVs must hover at areas having strong illumination,
thus providing useful guidelines on the deployment of VLC-enabled UAVs.",autonomous vehicle
http://arxiv.org/abs/2008.07371v1,filtered,arxiv,arxiv,2020-07-20 22:23:50+00:00,arxiv,Artificial Intelligence is stupid and causal reasoning won't fix it,http://arxiv.org/abs/2008.07371v1,"Artificial Neural Networks have reached Grandmaster and even super-human
performance across a variety of games: from those involving perfect-information
(such as Go) to those involving imperfect-information (such as Starcraft). Such
technological developments from AI-labs have ushered concomitant applications
across the world of business - where an AI brand tag is fast becoming
ubiquitous. A corollary of such widespread commercial deployment is that when
AI gets things wrong - an autonomous vehicle crashes; a chatbot exhibits racist
behaviour; automated credit scoring processes discriminate on gender etc. -
there are often significant financial, legal and brand consequences and the
incident becomes major news. As Judea Pearl sees it, the underlying reason for
such mistakes is that, 'all the impressive achievements of deep learning amount
to just curve fitting'. The key, Judea Pearl suggests, is to replace reasoning
by association with causal-reasoning - the ability to infer causes from
observed phenomena. It is a point that was echoed by Gary Marcus and Ernest
Davis in a recent piece for the New York Times: 'we need to stop building
computer systems that merely get better and better at detecting statistical
patterns in data sets - often using an approach known as Deep Learning - and
start building computer systems that from the moment of their assembly innately
grasp three basic concepts: time, space and causality'. In this paper,
foregrounding what in 1949 Gilbert Ryle termed a category mistake, I will offer
an alternative explanation for AI errors: it is not so much that AI machinery
cannot grasp causality, but that AI machinery - qua computation - cannot
understand anything at all.",autonomous vehicle
http://arxiv.org/abs/1711.05934v1,filtered,arxiv,arxiv,2017-11-16 05:37:14+00:00,arxiv,Enhanced Attacks on Defensively Distilled Deep Neural Networks,http://arxiv.org/abs/1711.05934v1,"Deep neural networks (DNNs) have achieved tremendous success in many tasks of
machine learning, such as the image classification. Unfortunately, researchers
have shown that DNNs are easily attacked by adversarial examples, slightly
perturbed images which can mislead DNNs to give incorrect classification
results. Such attack has seriously hampered the deployment of DNN systems in
areas where security or safety requirements are strict, such as autonomous
cars, face recognition, malware detection. Defensive distillation is a
mechanism aimed at training a robust DNN which significantly reduces the
effectiveness of adversarial examples generation. However, the state-of-the-art
attack can be successful on distilled networks with 100% probability. But it is
a white-box attack which needs to know the inner information of DNN. Whereas,
the black-box scenario is more general. In this paper, we first propose the
epsilon-neighborhood attack, which can fool the defensively distilled networks
with 100% success rate in the white-box setting, and it is fast to generate
adversarial examples with good visual quality. On the basis of this attack, we
further propose the region-based attack against defensively distilled DNNs in
the black-box setting. And we also perform the bypass attack to indirectly
break the distillation defense as a complementary method. The experimental
results show that our black-box attacks have a considerable success rate on
defensively distilled networks.",autonomous vehicle
http://arxiv.org/abs/2106.04823v1,filtered,arxiv,arxiv,2021-06-09 05:56:42+00:00,arxiv,Practical Machine Learning Safety: A Survey and Primer,http://arxiv.org/abs/2106.04823v1,"The open-world deployment of Machine Learning (ML) algorithms in
safety-critical applications such as autonomous vehicles needs to address a
variety of ML vulnerabilities such as interpretability, verifiability, and
performance limitations. Research explores different approaches to improve ML
dependability by proposing new models and training techniques to reduce
generalization error, achieve domain adaptation, and detect outlier examples
and adversarial attacks. In this paper, we review and organize practical ML
techniques that can improve the safety and dependability of ML algorithms and
therefore ML-based software. Our organization maps state-of-the-art ML
techniques to safety strategies in order to enhance the dependability of the ML
algorithm from different aspects, and discuss research gaps as well as
promising solutions.",autonomous vehicle
http://arxiv.org/abs/1806.07987v2,filtered,arxiv,arxiv,2018-06-20 21:12:43+00:00,arxiv,"A Hierarchical Deep Architecture and Mini-Batch Selection Method For
  Joint Traffic Sign and Light Detection",http://arxiv.org/abs/1806.07987v2,"Traffic light and sign detectors on autonomous cars are integral for road
scene perception. The literature is abundant with deep learning networks that
detect either lights or signs, not both, which makes them unsuitable for
real-life deployment due to the limited graphics processing unit (GPU) memory
and power available on embedded systems. The root cause of this issue is that
no public dataset contains both traffic light and sign labels, which leads to
difficulties in developing a joint detection framework. We present a deep
hierarchical architecture in conjunction with a mini-batch proposal selection
mechanism that allows a network to detect both traffic lights and signs from
training on separate traffic light and sign datasets. Our method solves the
overlapping issue where instances from one dataset are not labelled in the
other dataset. We are the first to present a network that performs joint
detection on traffic lights and signs. We measure our network on the
Tsinghua-Tencent 100K benchmark for traffic sign detection and the Bosch Small
Traffic Lights benchmark for traffic light detection and show it outperforms
the existing Bosch Small Traffic light state-of-the-art method. We focus on
autonomous car deployment and show our network is more suitable than others
because of its low memory footprint and real-time image processing time.
Qualitative results can be viewed at https://youtu.be/_YmogPzBXOw",autonomous vehicle
http://arxiv.org/abs/2005.02979v3,filtered,arxiv,arxiv,2020-05-06 17:31:51+00:00,arxiv,"A Survey of Algorithms for Black-Box Safety Validation of Cyber-Physical
  Systems",http://arxiv.org/abs/2005.02979v3,"Autonomous cyber-physical systems (CPS) can improve safety and efficiency for
safety-critical applications, but require rigorous testing before deployment.
The complexity of these systems often precludes the use of formal verification
and real-world testing can be too dangerous during development. Therefore,
simulation-based techniques have been developed that treat the system under
test as a black box operating in a simulated environment. Safety validation
tasks include finding disturbances in the environment that cause the system to
fail (falsification), finding the most-likely failure, and estimating the
probability that the system fails. Motivated by the prevalence of
safety-critical artificial intelligence, this work provides a survey of
state-of-the-art safety validation techniques for CPS with a focus on applied
algorithms and their modifications for the safety validation problem. We
present and discuss algorithms in the domains of optimization, path planning,
reinforcement learning, and importance sampling. Problem decomposition
techniques are presented to help scale algorithms to large state spaces, which
are common for CPS. A brief overview of safety-critical applications is given,
including autonomous vehicles and aircraft collision avoidance systems.
Finally, we present a survey of existing academic and commercially available
safety validation tools.",autonomous vehicle
http://arxiv.org/abs/2010.00972v1,filtered,arxiv,arxiv,2020-10-02 13:04:58+00:00,arxiv,6G Cellular Networks and Connected Autonomous Vehicles,http://arxiv.org/abs/2010.00972v1,"With 5G mobile communication systems been commercially rolled out, research
discussions on next generation mobile systems, i.e., 6G, have started. On the
other hand, vehicular technologies are also evolving rapidly, from connected
vehicles as coined by V2X (vehicle to everything) to autonomous vehicles to the
combination of the two, i.e., the networks of connected autonomous vehicles
(CAV). How fast the evolution of these two areas will go head-in-head is of
great importance, which is the focus of this paper. Based on a brief overview
on the technological evolution of V2X to CAV and 6G key technologies, this
paper explores two complementary research directions, namely, 6G for CAVs
versus CAVs for 6G. The former investigates how various 6G key enablers, such
as THz, cell free communication and artificial intelligence (AI), can be
utilized to provide CAV mission-critical services. The latter discusses how
CAVs can facilitate effective deployment and operation of 6G systems. This
paper attempts to investigate the interactions between the two technologies to
spark more research efforts in these areas.",autonomous vehicle
http://arxiv.org/abs/2003.01886v1,filtered,arxiv,arxiv,2020-03-04 04:35:22+00:00,arxiv,"Efficient statistical validation with edge cases to evaluate Highly
  Automated Vehicles",http://arxiv.org/abs/2003.01886v1,"The widescale deployment of Autonomous Vehicles (AV) seems to be imminent
despite many safety challenges that are yet to be resolved. It is well known
that there are no universally agreed Verification and Validation (VV)
methodologies to guarantee absolute safety, which is crucial for the acceptance
of this technology. Existing standards focus on deterministic processes where
the validation requires only a set of test cases that cover the requirements.
Modern autonomous vehicles will undoubtedly include machine learning and
probabilistic techniques that require a much more comprehensive testing regime
due to the non-deterministic nature of the operating design domain. A rigourous
statistical validation process is an essential component required to address
this challenge. Most research in this area focuses on evaluating system
performance in large scale real-world data gathering exercises (number of miles
travelled), or randomised test scenarios in simulation.
  This paper presents a new approach to compute the statistical characteristics
of a system's behaviour by biasing automatically generated test cases towards
the worst case scenarios, identifying potential unsafe edge cases.We use
reinforcement learning (RL) to learn the behaviours of simulated actors that
cause unsafe behaviour measured by the well established RSS safety metric. We
demonstrate that by using the method we can more efficiently validate a system
using a smaller number of test cases by focusing the simulation towards the
worst case scenario, generating edge cases that correspond to unsafe
situations.",autonomous vehicle
http://arxiv.org/abs/2110.01232v1,filtered,arxiv,arxiv,2021-10-04 07:52:23+00:00,arxiv,Benchmarking Safety Monitors for Image Classifiers with Machine Learning,http://arxiv.org/abs/2110.01232v1,"High-accurate machine learning (ML) image classifiers cannot guarantee that
they will not fail at operation. Thus, their deployment in safety-critical
applications such as autonomous vehicles is still an open issue. The use of
fault tolerance mechanisms such as safety monitors is a promising direction to
keep the system in a safe state despite errors of the ML classifier. As the
prediction from the ML is the core information directly impacting safety, many
works are focusing on monitoring the ML model itself. Checking the efficiency
of such monitors in the context of safety-critical applications is thus a
significant challenge. Therefore, this paper aims at establishing a baseline
framework for benchmarking monitors for ML image classifiers. Furthermore, we
propose a framework covering the entire pipeline, from data generation to
evaluation. Our approach measures monitor performance with a broader set of
metrics than usually proposed in the literature. Moreover, we benchmark three
different monitor approaches in 79 benchmark datasets containing five
categories of out-of-distribution data for image classifiers: class novelty,
noise, anomalies, distributional shifts, and adversarial attacks. Our results
indicate that these monitors are no more accurate than a random monitor. We
also release the code of all experiments for reproducibility.",autonomous vehicle
http://arxiv.org/abs/2006.04734v3,filtered,arxiv,arxiv,2020-06-08 16:40:12+00:00,arxiv,Reinforcement Learning Under Moral Uncertainty,http://arxiv.org/abs/2006.04734v3,"An ambitious goal for machine learning is to create agents that behave
ethically: The capacity to abide by human moral norms would greatly expand the
context in which autonomous agents could be practically and safely deployed,
e.g. fully autonomous vehicles will encounter charged moral decisions that
complicate their deployment. While ethical agents could be trained by rewarding
correct behavior under a specific moral theory (e.g. utilitarianism), there
remains widespread disagreement about the nature of morality. Acknowledging
such disagreement, recent work in moral philosophy proposes that ethical
behavior requires acting under moral uncertainty, i.e. to take into account
when acting that one's credence is split across several plausible ethical
theories. This paper translates such insights to the field of reinforcement
learning, proposes two training methods that realize different points among
competing desiderata, and trains agents in simple environments to act under
moral uncertainty. The results illustrate (1) how such uncertainty can help
curb extreme behavior from commitment to single theories and (2) several
technical complications arising from attempting to ground moral philosophy in
RL (e.g. how can a principled trade-off between two competing but incomparable
reward functions be reached). The aim is to catalyze progress towards
morally-competent agents and highlight the potential of RL to contribute
towards the computational grounding of moral philosophy.",autonomous vehicle
http://arxiv.org/abs/1708.04485v1,filtered,arxiv,arxiv,2017-05-23 22:11:11+00:00,arxiv,SCNN: An Accelerator for Compressed-sparse Convolutional Neural Networks,http://arxiv.org/abs/1708.04485v1,"Convolutional Neural Networks (CNNs) have emerged as a fundamental technology
for machine learning. High performance and extreme energy efficiency are
critical for deployments of CNNs in a wide range of situations, especially
mobile platforms such as autonomous vehicles, cameras, and electronic personal
assistants. This paper introduces the Sparse CNN (SCNN) accelerator
architecture, which improves performance and energy efficiency by exploiting
the zero-valued weights that stem from network pruning during training and
zero-valued activations that arise from the common ReLU operator applied during
inference. Specifically, SCNN employs a novel dataflow that enables maintaining
the sparse weights and activations in a compressed encoding, which eliminates
unnecessary data transfers and reduces storage requirements. Furthermore, the
SCNN dataflow facilitates efficient delivery of those weights and activations
to the multiplier array, where they are extensively reused. In addition, the
accumulation of multiplication products are performed in a novel accumulator
array. Our results show that on contemporary neural networks, SCNN can improve
both performance and energy by a factor of 2.7x and 2.3x, respectively, over a
comparably provisioned dense CNN accelerator.",autonomous vehicle
http://arxiv.org/abs/2004.13866v1,filtered,arxiv,arxiv,2020-04-28 21:56:10+00:00,arxiv,Deflating Dataset Bias Using Synthetic Data Augmentation,http://arxiv.org/abs/2004.13866v1,"Deep Learning has seen an unprecedented increase in vision applications since
the publication of large-scale object recognition datasets and introduction of
scalable compute hardware. State-of-the-art methods for most vision tasks for
Autonomous Vehicles (AVs) rely on supervised learning and often fail to
generalize to domain shifts and/or outliers. Dataset diversity is thus key to
successful real-world deployment. No matter how big the size of the dataset,
capturing long tails of the distribution pertaining to task-specific
environmental factors is impractical. The goal of this paper is to investigate
the use of targeted synthetic data augmentation - combining the benefits of
gaming engine simulations and sim2real style transfer techniques - for filling
gaps in real datasets for vision tasks. Empirical studies on three different
computer vision tasks of practical use to AVs - parking slot detection, lane
detection and monocular depth estimation - consistently show that having
synthetic data in the training mix provides a significant boost in
cross-dataset generalization performance as compared to training on real data
only, for the same size of the training set.",autonomous vehicle
http://arxiv.org/abs/2105.00203v2,filtered,arxiv,arxiv,2021-05-01 09:55:17+00:00,arxiv,"Adversarial Example Detection for DNN Models: A Review and Experimental
  Comparison",http://arxiv.org/abs/2105.00203v2,"Deep learning (DL) has shown great success in many human-related tasks, which
has led to its adoption in many computer vision based applications, such as
security surveillance systems, autonomous vehicles and healthcare. Such
safety-critical applications have to draw their path to success deployment once
they have the capability to overcome safety-critical challenges. Among these
challenges are the defense against or/and the detection of the adversarial
examples (AEs). Adversaries can carefully craft small, often imperceptible,
noise called perturbations to be added to the clean image to generate the AE.
The aim of AE is to fool the DL model which makes it a potential risk for DL
applications. Many test-time evasion attacks and countermeasures,i.e., defense
or detection methods, are proposed in the literature. Moreover, few reviews and
surveys were published and theoretically showed the taxonomy of the threats and
the countermeasure methods with little focus in AE detection methods. In this
paper, we focus on image classification tasks and attempt to provide a survey
for detection methods of test-time evasion attacks on neural network
classifiers. A detailed discussion for such methods is provided with
experimental results for eight state-of-the-art detectors under different
scenarios on four datasets. We also provide potential challenges and future
perspectives for this research direction.",autonomous vehicle
http://arxiv.org/abs/1704.02696v1,filtered,arxiv,arxiv,2017-04-10 03:46:00+00:00,arxiv,Implementing a Cloud Platform for Autonomous Driving,http://arxiv.org/abs/1704.02696v1,"Autonomous driving clouds provide essential services to support autonomous
vehicles. Today these services include but not limited to distributed
simulation tests for new algorithm deployment, offline deep learning model
training, and High-Definition (HD) map generation. These services require
infrastructure support including distributed computing, distributed storage, as
well as heterogeneous computing. In this paper, we present the details of how
we implement a unified autonomous driving cloud infrastructure, and how we
support these services on top of this infrastructure.",autonomous vehicle
http://arxiv.org/abs/1311.6981v1,filtered,arxiv,arxiv,2013-11-13 04:46:57+00:00,arxiv,"A customized flocking algorithm for swarms of sensors tracking a swarm
  of targets",http://arxiv.org/abs/1311.6981v1,"Wireless mobile sensor networks (WMSNs) are groups of mobile sensing agents
with multi-modal sensing capabilities that communicate over wireless networks.
WMSNs have more flexibility in terms of deployment and exploration abilities
over static sensor networks. Sensor networks have a wide range of applications
in security and surveillance systems, environmental monitoring, data gathering
for network-centric healthcare systems, monitoring seismic activities and
atmospheric events, tracking traffic congestion and air pollution levels,
localization of autonomous vehicles in intelligent transportation systems, and
detecting failures of sensing, storage, and switching components of smart
grids. The above applications require target tracking for processes and events
of interest occurring in an environment. Various methods and approaches have
been proposed in order to track one or more targets in a pre-defined area.
Usually, this turns out to be a complicated job involving higher order
mathematics coupled with artificial intelligence due to the dynamic nature of
the targets. To optimize the resources we need to have an approach that works
in a more straightforward manner while resulting in fairly satisfactory data.
In this paper we have discussed the various cases that might arise while
flocking a group of sensors to track targets in a given environment. The
approach has been developed from scratch although some basic assumptions have
been made keeping in mind some previous theories. This paper outlines a
customized approach for feasibly tracking swarms of targets in a specific area
so as to minimize the resources and optimize tracking efficiency.",autonomous vehicle
http://arxiv.org/abs/1905.00689v2,filtered,arxiv,arxiv,2019-05-02 12:09:59+00:00,arxiv,"Approximate LSTMs for Time-Constrained Inference: Enabling Fast Reaction
  in Self-Driving Cars",http://arxiv.org/abs/1905.00689v2,"The need to recognise long-term dependencies in sequential data such as video
streams has made Long Short-Term Memory (LSTM) networks a prominent Artificial
Intelligence model for many emerging applications. However, the high
computational and memory demands of LSTMs introduce challenges in their
deployment on latency-critical systems such as self-driving cars which are
equipped with limited computational resources on-board. In this paper, we
introduce a progressive inference computing scheme that combines model pruning
and computation restructuring leading to the best possible approximation of the
result given the available latency budget of the target application. The
proposed methodology enables mission-critical systems to make informed
decisions even in early stages of the computation, based on approximate LSTM
inference, meeting their specifications on safety and robustness. Our
experiments on a state-of-the-art driving model for autonomous vehicle
navigation demonstrate that the proposed approach can yield outputs with
similar quality of result compared to a faithful LSTM baseline, up to 415x
faster (198x on average, 76x geo. mean).",autonomous vehicle
http://arxiv.org/abs/1903.11027v5,filtered,arxiv,arxiv,2019-03-26 17:19:56+00:00,arxiv,nuScenes: A multimodal dataset for autonomous driving,http://arxiv.org/abs/1903.11027v5,"Robust detection and tracking of objects is crucial for the deployment of
autonomous vehicle technology. Image based benchmark datasets have driven
development in computer vision tasks such as object detection, tracking and
segmentation of agents in the environment. Most autonomous vehicles, however,
carry a combination of cameras and range sensors such as lidar and radar. As
machine learning based methods for detection and tracking become more
prevalent, there is a need to train and evaluate such methods on datasets
containing range sensor data along with images. In this work we present
nuTonomy scenes (nuScenes), the first dataset to carry the full autonomous
vehicle sensor suite: 6 cameras, 5 radars and 1 lidar, all with full 360 degree
field of view. nuScenes comprises 1000 scenes, each 20s long and fully
annotated with 3D bounding boxes for 23 classes and 8 attributes. It has 7x as
many annotations and 100x as many images as the pioneering KITTI dataset. We
define novel 3D detection and tracking metrics. We also provide careful dataset
analysis as well as baselines for lidar and image based detection and tracking.
Data, development kit and more information are available online.",autonomous vehicle
http://arxiv.org/abs/2009.14349v3,filtered,arxiv,arxiv,2020-09-30 00:01:54+00:00,arxiv,"Computing Systems for Autonomous Driving: State-of-the-Art and
  Challenges",http://arxiv.org/abs/2009.14349v3,"The recent proliferation of computing technologies (e.g., sensors, computer
vision, machine learning, and hardware acceleration), and the broad deployment
of communication mechanisms (e.g., DSRC, C-V2X, 5G) have pushed the horizon of
autonomous driving, which automates the decision and control of vehicles by
leveraging the perception results based on multiple sensors. The key to the
success of these autonomous systems is making a reliable decision in real-time
fashion. However, accidents and fatalities caused by early deployed autonomous
vehicles arise from time to time. The real traffic environment is too
complicated for current autonomous driving computing systems to understand and
handle. In this paper, we present state-of-the-art computing systems for
autonomous driving, including seven performance metrics and nine key
technologies, followed by twelve challenges to realize autonomous driving. We
hope this paper will gain attention from both the computing and automotive
communities and inspire more research in this direction.",autonomous vehicle
http://arxiv.org/abs/2006.00644v1,filtered,arxiv,arxiv,2020-06-01 00:02:45+00:00,arxiv,Automatic Building and Labeling of HD Maps with Deep Learning,http://arxiv.org/abs/2006.00644v1,"In a world where autonomous driving cars are becoming increasingly more
common, creating an adequate infrastructure for this new technology is
essential. This includes building and labeling high-definition (HD) maps
accurately and efficiently. Today, the process of creating HD maps requires a
lot of human input, which takes time and is prone to errors. In this paper, we
propose a novel method capable of generating labelled HD maps from raw sensor
data. We implemented and tested our methods on several urban scenarios using
data collected from our test vehicle. The results show that the pro-posed deep
learning based method can produce highly accurate HD maps. This approach speeds
up the process of building and labeling HD maps, which can make meaningful
contribution to the deployment of autonomous vehicle.",autonomous vehicle
http://arxiv.org/abs/1712.02294v4,filtered,arxiv,arxiv,2017-12-06 17:20:21+00:00,arxiv,Joint 3D Proposal Generation and Object Detection from View Aggregation,http://arxiv.org/abs/1712.02294v4,"We present AVOD, an Aggregate View Object Detection network for autonomous
driving scenarios. The proposed neural network architecture uses LIDAR point
clouds and RGB images to generate features that are shared by two subnetworks:
a region proposal network (RPN) and a second stage detector network. The
proposed RPN uses a novel architecture capable of performing multimodal feature
fusion on high resolution feature maps to generate reliable 3D object proposals
for multiple object classes in road scenes. Using these proposals, the second
stage detection network performs accurate oriented 3D bounding box regression
and category classification to predict the extents, orientation, and
classification of objects in 3D space. Our proposed architecture is shown to
produce state of the art results on the KITTI 3D object detection benchmark
while running in real time with a low memory footprint, making it a suitable
candidate for deployment on autonomous vehicles. Code is at:
https://github.com/kujason/avod",autonomous vehicle
http://arxiv.org/abs/1803.06077v2,filtered,arxiv,arxiv,2018-03-16 05:29:12+00:00,arxiv,"Real-time Detection, Tracking, and Classification of Moving and
  Stationary Objects using Multiple Fisheye Images",http://arxiv.org/abs/1803.06077v2,"The ability to detect pedestrians and other moving objects is crucial for an
autonomous vehicle. This must be done in real-time with minimum system
overhead. This paper discusses the implementation of a surround view system to
identify moving as well as static objects that are close to the ego vehicle.
The algorithm works on 4 views captured by fisheye cameras which are merged
into a single frame. The moving object detection and tracking solution uses
minimal system overhead to isolate regions of interest (ROIs) containing moving
objects. These ROIs are then analyzed using a deep neural network (DNN) to
categorize the moving object. With deployment and testing on a real car in
urban environments, we have demonstrated the practical feasibility of the
solution. The video demos of our algorithm have been uploaded to Youtube:
https://youtu.be/vpoCfC724iA, https://youtu.be/2X4aqH2bMBs",autonomous vehicle
http://arxiv.org/abs/1907.01038v1,filtered,arxiv,arxiv,2019-07-01 19:42:37+00:00,arxiv,AVFI: Fault Injection for Autonomous Vehicles,http://arxiv.org/abs/1907.01038v1,"Autonomous vehicle (AV) technology is rapidly becoming a reality on U.S.
roads, offering the promise of improvements in traffic management, safety, and
the comfort and efficiency of vehicular travel. With this increasing popularity
and ubiquitous deployment, resilience has become a critical requirement for
public acceptance and adoption. Recent studies into the resilience of AVs have
shown that though the AV systems are improving over time, they have not reached
human levels of automation. Prior work in this area has studied the safety and
resilience of individual components of the AV system (e.g., testing of neural
networks powering the perception function). However, methods for holistic
end-to-end resilience assessment of AV systems are still non-existent.",autonomous vehicle
http://arxiv.org/abs/2102.12967v1,filtered,arxiv,arxiv,2021-02-25 16:14:47+00:00,arxiv,"Statistical Testing for Efficient Out of Distribution Detection in Deep
  Neural Networks",http://arxiv.org/abs/2102.12967v1,"Commonly, Deep Neural Networks (DNNs) generalize well on samples drawn from a
distribution similar to that of the training set. However, DNNs' predictions
are brittle and unreliable when the test samples are drawn from a dissimilar
distribution. This presents a major concern for deployment in real-world
applications, where such behavior may come at a great cost -- as in the case of
autonomous vehicles or healthcare applications.
  This paper frames the Out Of Distribution (OOD) detection problem in DNN as a
statistical hypothesis testing problem. Unlike previous OOD detection
heuristics, our framework is guaranteed to maintain the false positive rate
(detecting OOD as in-distribution) for test data. We build on this framework to
suggest a novel OOD procedure based on low-order statistics. Our method
achieves comparable or better than state-of-the-art results on well-accepted
OOD benchmarks without retraining the network parameters -- and at a fraction
of the computational cost.",autonomous vehicle
http://arxiv.org/abs/2109.02529v2,filtered,arxiv,arxiv,2021-09-06 15:12:17+00:00,arxiv,"ViSTA: a Framework for Virtual Scenario-based Testing of Autonomous
  Vehicles",http://arxiv.org/abs/2109.02529v2,"In this paper, we present ViSTA, a framework for Virtual Scenario-based
Testing of Autonomous Vehicles (AV), developed as part of the 2021 IEEE
Autonomous Test Driving AI Test Challenge. Scenario-based virtual testing aims
to construct specific challenges posed for the AV to overcome, albeit in
virtual test environments that may not necessarily resemble the real world.
This approach is aimed at identifying specific issues that arise safety
concerns before an actual deployment of the AV on the road. In this paper, we
describe a comprehensive test case generation approach that facilitates the
design of special-purpose scenarios with meaningful parameters to form test
cases, both in automated and manual ways, leveraging the strength and
weaknesses of either. Furthermore, we describe how to automate the execution of
test cases, and analyze the performance of the AV under these test cases.",autonomous vehicle
http://arxiv.org/abs/2001.00048v1,filtered,arxiv,arxiv,2019-12-31 19:41:59+00:00,arxiv,"MIR-Vehicle: Cost-Effective Research Platform for Autonomous Vehicle
  Applications",http://arxiv.org/abs/2001.00048v1,"This paper illustrates the MIR (Mobile Intelligent Robotics) Vehicle: a
feasible option of transforming an electric ride-on-car into a modular Graphics
Processing Unit (GPU) powered autonomous platform equipped with the capability
that supports test and deployment of various intelligent autonomous vehicles
algorithms. To use a platform for research, two components must be provided:
perception and control. The sensors such as incremental encoders, an Inertial
Measurement Unit (IMU), a camera, and a LIght Detection And Ranging (LIDAR)
must be able to be installed on the platform to add the capability of
environmental perception. A microcontroller-powered control box is designed to
properly respond to the environmental changes by regulating drive and steering
motors. This drive-by-wire capability is controlled by a GPU powered laptop
computer where high-level perception algorithms are processed and complex
actions are generated by various methods including behavior cloning using deep
neural networks. The main goal of this paper is to provide an adequate and
comprehensive approach for fabricating a cost-effective platform that would
contribute to the research quality from the wider community. The proposed
platform is to use a modular and hierarchical software architecture where the
lower and simpler motor controls are taken care of by microcontroller programs,
and the higher and complex algorithms are processed by a GPU powered laptop
computer. The platform uses the Robot Operating System (ROS) as middleware to
maintain the modularity of the perceptions and decision-making modules. It is
expected that the level three and above autonomous vehicle systems and Advanced
Driver Assistance Systems (ADAS) can be tested on and deployed to the platform
with a decent real-time system behavior due to the capabilities and
affordability of the proposed platform.",autonomous vehicle
http://arxiv.org/abs/1607.08289v4,filtered,arxiv,arxiv,2016-07-28 01:22:26+00:00,arxiv,Mammalian Value Systems,http://arxiv.org/abs/1607.08289v4,"Characterizing human values is a topic deeply interwoven with the sciences,
humanities, art, and many other human endeavors. In recent years, a number of
thinkers have argued that accelerating trends in computer science, cognitive
science, and related disciplines foreshadow the creation of intelligent
machines which meet and ultimately surpass the cognitive abilities of human
beings, thereby entangling an understanding of human values with future
technological development. Contemporary research accomplishments suggest
sophisticated AI systems becoming widespread and responsible for managing many
aspects of the modern world, from preemptively planning users' travel schedules
and logistics, to fully autonomous vehicles, to domestic robots assisting in
daily living. The extrapolation of these trends has been most forcefully
described in the context of a hypothetical ""intelligence explosion,"" in which
the capabilities of an intelligent software agent would rapidly increase due to
the presence of feedback loops unavailable to biological organisms. The
possibility of superintelligent agents, or simply the widespread deployment of
sophisticated, autonomous AI systems, highlights an important theoretical
problem: the need to separate the cognitive and rational capacities of an agent
from the fundamental goal structure, or value system, which constrains and
guides the agent's actions. The ""value alignment problem"" is to specify a goal
structure for autonomous agents compatible with human values. In this brief
article, we suggest that recent ideas from affective neuroscience and related
disciplines aimed at characterizing neurological and behavioral universals in
the mammalian class provide important conceptual foundations relevant to
describing human values. We argue that the notion of ""mammalian value systems""
points to a potential avenue for fundamental research in AI safety and AI
ethics.",autonomous vehicle
http://arxiv.org/abs/2107.07557v1,filtered,arxiv,arxiv,2021-07-15 18:37:19+00:00,arxiv,OdoViz: A 3D Odometry Visualization and Processing Tool,http://arxiv.org/abs/2107.07557v1,"OdoViz is a reactive web-based tool for 3D visualization and processing of
autonomous vehicle datasets designed to support common tasks in visual place
recognition research. The system includes functionality for loading,
inspecting, visualizing, and processing GPS/INS poses, point clouds and camera
images. It supports a number of commonly used driving datasets and can be
adapted to load custom datasets with minimal effort. OdoViz's design consists
of a slim server to serve the datasets coupled with a rich client frontend.
This design supports multiple deployment configurations including single user
stand-alone installations, research group installations serving datasets
internally across a lab, or publicly accessible web-frontends for providing
online interfaces for exploring and interacting with datasets. The tool allows
viewing complete vehicle trajectories traversed at multiple different time
periods simultaneously, facilitating tasks such as sub-sampling, comparing and
finding pose correspondences both across and within sequences. This
significantly reduces the effort required in creating subsets of data from
existing datasets for machine learning tasks. Further to the above, the system
also supports adding custom extensions and plugins to extend the capabilities
of the software for other potential data management, visualization and
processing tasks. The platform has been open-sourced to promote its use and
encourage further contributions from the research community.",autonomous vehicle
http://arxiv.org/abs/1804.10829v3,filtered,arxiv,arxiv,2018-04-28 16:37:01+00:00,arxiv,Formal Security Analysis of Neural Networks using Symbolic Intervals,http://arxiv.org/abs/1804.10829v3,"Due to the increasing deployment of Deep Neural Networks (DNNs) in real-world
security-critical domains including autonomous vehicles and collision avoidance
systems, formally checking security properties of DNNs, especially under
different attacker capabilities, is becoming crucial. Most existing security
testing techniques for DNNs try to find adversarial examples without providing
any formal security guarantees about the non-existence of such adversarial
examples. Recently, several projects have used different types of
Satisfiability Modulo Theory (SMT) solvers to formally check security
properties of DNNs. However, all of these approaches are limited by the high
overhead caused by the solver.
  In this paper, we present a new direction for formally checking security
properties of DNNs without using SMT solvers. Instead, we leverage interval
arithmetic to compute rigorous bounds on the DNN outputs. Our approach, unlike
existing solver-based approaches, is easily parallelizable. We further present
symbolic interval analysis along with several other optimizations to minimize
overestimations of output bounds.
  We design, implement, and evaluate our approach as part of ReluVal, a system
for formally checking security properties of Relu-based DNNs. Our extensive
empirical results show that ReluVal outperforms Reluplex, a state-of-the-art
solver-based system, by 200 times on average. On a single 8-core machine
without GPUs, within 4 hours, ReluVal is able to verify a security property
that Reluplex deemed inconclusive due to timeout after running for more than 5
days. Our experiments demonstrate that symbolic interval analysis is a
promising new direction towards rigorously analyzing different security
properties of DNNs.",autonomous vehicle
http://arxiv.org/abs/2008.04379v1,filtered,arxiv,arxiv,2020-08-10 19:35:51+00:00,arxiv,"A Survey and Insights on Deployments of the Connected and Autonomous
  Vehicles in US",http://arxiv.org/abs/2008.04379v1,"CV/ITS (Connected Vehicle, Intelligent Transportation System) and AV/ADS
(Autonomous Vehicle, Automated Driving System) have been emerging for the sake
of saving people lives, improving traffic efficiency and helping the
environment for decades. There are separate efforts led respectively by USDOT
with state DOTs for CV, and private sectors through market driven approach from
start-ups and technology companies for AV. By CV/ITS effort there are 97
deployments of V2X communications utilizing the 5.9 GHz band, 18,877 vehicles
with aftermarket V2X communications devices, and 8,098 infrastructure V2X
devices installed at the roadsides. However, CV/ITS still cannot be massively
deployed in US markets due to lack of regulations, dedicated wireless spectrum
bands, sustainable financial & business models with mature supply chain, etc.
In the other side, technology-driven AV market has been much slower than
expected mainly because of immaturity of AI technology to handle different
complex driving scenarios in a cost effective way. In this paper, we first
present these two parallel journeys focusing on the deployments including
operating models, scenarios and applications, evaluations and lessons learning.
Then, come up with recommendations to a cooperative CAV approach driving a more
feasible, safer, affordable and cost effective transportation, but require a
great industry collaboration from Automotive, Transportation. ICT and Cloud.",autonomous vehicle
http://arxiv.org/abs/1806.03243v1,filtered,arxiv,arxiv,2018-05-28 17:46:54+00:00,arxiv,"In-vehicle data recording, storage and access management in autonomous
  vehicles",http://arxiv.org/abs/1806.03243v1,"Transport sector is in the process of being rapidly and fundamentally
reshaped by autonomous and collaborative driving technologies. This reshaping
promises huge economic and social benefits as well as challenges in terms of
developing and deploying secure and safe transportations systems, their smooth
integration to social fabric. We have employed Policy Scan and Technology
Strategy Design methodology in order to identify concrete societal expectations
and problems and map them with mitigating technological availabilities in the
domain of autonomous driving and smart mobility.
  Event Data Recorder for Autonomous Driving (EDR/AD) is an envisioned
subsystem of a vehicular Controller Area Network which ensures the
confidentiality, integrity and availability of data related to operation of a
vehicle in order to permit recovery of exact situation following the occurrence
of an event or on demand. The exact technical and regulatory requirements for
the device are still in the development internationally, but it is clear that
it will be included into vehicle type-approval requirements at UNECE level. We
present an analysis of the context of the usage of the EDR/AD in collaborative
intelligent transport systems, related security, data provenance and privacy,
other regulatory and technical issues considering many interest groups and
stakeholders involved. We present a concrete proposal for developing a EDR/AD
proof of the concept prototype with clear market deployment potential and urge
security researchers, vehicle manufacturers, and component suppliers to form a
collaboration towards implementing important technology for making future
autonomous vehicles more socially acceptable and legally compliant.
Furthermore, EDR/AD technology, apart from its immediate use in autonomous
driving and smart mobility domain has a potential to be extended to general
autonomous robot and AI applications.",autonomous vehicle
10.1016/j.knosys.2020.106685,filtered,Knowledge-Based Systems,sciencedirect,2021-02-28,sciencedirect,Explainability in deep reinforcement learning,https://api.elsevier.com/content/article/pii/S0950705120308145,"
                  A large set of the explainable Artificial Intelligence (XAI) literature is emerging on feature relevance techniques to explain a deep neural network (DNN) output or explaining models that ingest image source data. However, assessing how XAI techniques can help understand models beyond classification tasks, e.g. for reinforcement learning (RL), has not been extensively studied. We review recent works in the direction to attain Explainable Reinforcement Learning (XRL), a relatively new subfield of Explainable Artificial Intelligence, intended to be used in general public applications, with diverse audiences, requiring ethical, responsible and trustable algorithms. In critical situations where it is essential to justify and explain the agent’s behaviour, better explainability and interpretability of RL models could help gain scientific insight on the inner workings of what is still considered a black box. We evaluate mainly studies directly linking explainability to RL, and split these into two categories according to the way the explanations are generated: transparent algorithms and post-hoc explainability. We also review the most prominent XAI works from the lenses of how they could potentially enlighten the further deployment of the latest advances in RL, in the demanding present and future of everyday problems.
               ",autonomous vehicle
10.1016/j.comnet.2021.108004,filtered,Computer Networks,sciencedirect,2021-05-22,sciencedirect,Deep reinforcement learning for blockchain in industrial IoT: A survey,https://api.elsevier.com/content/article/pii/S1389128621001213,"
                  With the ambitious plans of renewal and expansion of industrialization in many countries, the efficiency, agility and cost savings potentially resulting from the application of industrial Internet of Things (IIoT) are drawing attentions. Although blockchain and machine learning technologies (especially deep learning and deep reinforcement learning) may provide the next promising use case for IIoT, they are working in an adversarial way to some extent. While blockchain facilitates the data collection that is critical for machine learning under the premise of data regulation rules like privacy protection, it may suffer from privacy leakage due to big data analytics with the help of machine learning. To make machine learning and blockchain useful and practical for diversified services in industrial sectors, it is of paramount importance to have a comprehensive understanding of the development of both technologies in the context of IIoT. To this end, in this paper we summarize and analyze the applications of blockchain and machine learning in IIoT from three important aspects, i.e., consensus mechanism, storage and communication. This survey provides a deeper understanding on the security and privacy risks of the key components of a blockchain from the perspective of machine learning, which is useful in the design of practical blockchain solutions for IIoT. In addition, we provide useful guidance for future research in the area by identifying interesting open problems that need to be addressed before large-scale deployments of IIoT applications are practicable.
               ",autonomous vehicle
10.1016/B978-0-12-823817-2.00011-5,filtered,Mobile Edge Artificial Intelligence,sciencedirect,2022-12-31,sciencedirect,Chapter Two: Primer on artificial intelligence,https://api.elsevier.com/content/article/pii/B9780128238172000115,"
               
                  Artificial intelligence (AI) has induced considerable achievements in various fields such as computer vision, natural language processing, autonomous vehicles, and so on. The AI models refer to the technology presenting human intelligence through computer programs, which could efficiently address the complex optimization problems in the wireless network to enhance the communication quality. On the other hand, the wireless network could also assist the data collection for model training and simplify the deployment of inference models. In this chapter, we shall present the basic concept of various AI models, which contributes to comprehend the following chapters. The machine learning (ML) models are specified by presenting supervised learning, unsupervised learning, and reinforcement learning. Moreover, we particularly present various models of deep learning (DL), which exhibit complex structure and excellent performance.
            ",autonomous vehicle
10.1016/j.adhoc.2021.102667,filtered,Ad Hoc Networks,sciencedirect,2021-12-01,sciencedirect,"Machine learning for 5G security: Architecture, recent advances, and challenges",https://api.elsevier.com/content/article/pii/S1570870521001785,"
                  The granularization of crucial network functions implementation using software-centric, and virtualized approaches in 5G networks have brought forth unprecedented security challenges in general and privacy concerns. Moreover, these software components’ premature deployment and compromised supply chain put the individual network components at risk and have a ripple effect for the rest of the network. Some of the novel threats to 5G assets include tampering in identity and access management, supply-chain poisoning, masquerade and bot attacks, loop-holes in source codes. Machine learning (ML) in this context can help to provide heavily dynamic and robust security mechanisms for the software-centric architecture of 5G Networks. ML models’ development and implementation also rely on programmable environments; hence, they can play a vital role in designing, modelling, and automating efficient security protocols. This article presents the threat landscape across 5G networks and discusses the feasibility and architecture of different ML-based models to counter these threats. Also, we present the architecture for automated threat intelligence using cooperative and coordinated ML to secure 5G assets and infrastructure. We also present the summary of closely related existing works along with future research challenges.
               ",autonomous vehicle
10.1016/j.ifacol.2020.12.712,filtered,IFAC-PapersOnLine,sciencedirect,2020-12-31,sciencedirect,Deep Learning in Mining and Mineral Processing Operations: A Review,https://api.elsevier.com/content/article/pii/S2405896320310296,"
                  In this paper, the application of deep learning in the mining and processing of ores is reviewed. Deep learning is strongly impacting the development of sensor systems, particularly computer vision systems used in mining and mineral processing automation, where it is filling a gap not currently achievable by traditional approaches. To a lesser extent, deep learning is also being considered in the automation of decision support systems. There is significant scope for the application of deep learning to improve operations, but access to industrial data and big data infrastructure in operational environments are critical bottlenecks to the development and deployment of the technology.
               ",autonomous vehicle
10.1016/j.egyai.2021.100049,filtered,Energy and AI,sciencedirect,2021-03-31,sciencedirect,Machine learning for advanced energy materials,https://api.elsevier.com/content/article/pii/S2666546821000033,"The screening of advanced materials coupled with the modeling of their quantitative structural-activity relationships has recently become one of the hot and trending topics in energy materials due to the diverse challenges, including low success probabilities, high time consumption, and high computational cost associated with the traditional methods of developing energy materials. Following this, new research concepts and technologies to promote the research and development of energy materials become necessary. The latest advancements in artificial intelligence and machine learning have therefore increased the expectation that data-driven materials science would revolutionize scientific discoveries towards providing new paradigms for the development of energy materials. Furthermore, the current advances in data-driven materials engineering also demonstrate that the application of machine learning technology would not only significantly facilitate the design and development of advanced energy materials but also enhance their discovery and deployment. In this article, the importance and necessity of developing new energy materials towards contributing to the global carbon neutrality are presented. A comprehensive introduction to the fundamentals of machine learning is also provided, including open-source databases, feature engineering, machine learning algorithms, and analysis of machine learning model. Afterwards, the latest progress in data-driven materials science and engineering, including alkaline ion battery materials, photovoltaic materials, catalytic materials, and carbon dioxide capture materials, is discussed. Finally, relevant clues to the successful applications of machine learning and the remaining challenges towards the development of advanced energy materials are highlighted.",autonomous vehicle
10.1016/j.comnet.2020.107478,filtered,Computer Networks,sciencedirect,2020-12-09,sciencedirect,UAVs joint optimization problems and machine learning to improve the 5G and Beyond communication,https://api.elsevier.com/content/article/pii/S1389128620311518,"
                  Recently, unmanned aerial vehicles (UAVs) have gained notable interest in various applications such as wireless coverage, aerial surveillance, precision agriculture, construction, power lines monitoring and blood delivery, etc. The UAVs implicit attributes e.g., rapid deployment, quick mobility, increase in flight duration, improvements in payload capacities, etc. , place it as an effective candidate for many applications in 5G and Beyond communications. The UAVs-assisted next-generation communications are determined to be highly influenced by various techniques and technologies like artificial intelligence (AI), machine learning (ML), deep reinforcement learning (DRL), mobile edge computing (MEC), and software-defined networks (SDN). In this article, we develop a review to investigate the UAVs joint optimization problems to enhance system efficiency. We classify the joint optimization problems based on the number of parameters used in proposed optimization problems. Moreover, we explore the impact of AI, ML, DRL, MEC, and SDN over UAVs joint optimization problems and present future research challenges and directions.
               ",autonomous vehicle
10.1016/B978-0-12-822226-3.00003-9,filtered,Trends in Deep Learning Methodologies,sciencedirect,2021-12-31,sciencedirect,"Chapter 3: An overview of deep learning in big data, image, and signal processing in the modern digital age",https://api.elsevier.com/content/article/pii/B9780128222263000039,"
               Nowadays, data is generated all the time on the internet. Faced with this scenario, technologies have emerged to take advantage of this feature, so that in addition to just being able to measure and understand where they come from, it is possible for them to be collected, quantified, decoded, and analyzed, allowing the understanding of behaviors and trends, the definition of strategies, and the process of insight generation. Big data leverages resources that organize and catalog this information, increasing the availability of relevant data for informed decision making. Machine learning is an aspect of artificial intelligence that competently performs automation in the process of building analytical models that allow machines to adapt independently to new scenarios, enabling software to successfully predict and react to the deployment of scenarios based on past results. Deep learning has this nomenclature because it deals with neural networks having multiple (deep) layers that allow learning; therefore it is a subset of machine learning, which considers algorithms inspired by the human brain, the artificial neural networks, which learn from large amounts of data. Deep learning techniques are especially useful for analyzing complex, rich, and multidimensional data such as voice, images, and videos. In short, all deep learning is machine learning, but not all machine learning is deep learning. This chapter examines the technology of deep learning and machine learning in big data by addressing its evolution and fundamental concepts and its integration into new technologies, by approaching its success, and by categorizing and synthesizing the potential of both technologies.
            ",autonomous vehicle
10.1016/j.apsb.2021.02.007,filtered,Acta Pharmaceutica Sinica B,sciencedirect,2021-02-11,sciencedirect,Applying artificial intelligence for cancer immunotherapy,https://api.elsevier.com/content/article/pii/S2211383521000459,"Artificial intelligence (AI) is a general term that refers to the use of a machine to imitate intelligent behavior for performing complex tasks with minimal human intervention, such as machine learning; this technology is revolutionizing and reshaping medicine. AI has considerable potential to perfect health-care systems in areas such as diagnostics, risk analysis, health information administration, lifestyle supervision, and virtual health assistance. In terms of immunotherapy, AI has been applied to the prediction of immunotherapy responses based on immune signatures, medical imaging and histological analysis. These features could also be highly useful in the management of cancer immunotherapy given their ever-increasing performance in improving diagnostic accuracy, optimizing treatment planning, predicting outcomes of care and reducing human resource costs. In this review, we present the details of AI and the current progression and state of the art in employing AI for cancer immunotherapy. Furthermore, we discuss the challenges, opportunities and corresponding strategies in applying the technology for widespread clinical deployment. Finally, we summarize the impact of AI on cancer immunotherapy and provide our perspectives about underlying applications of AI in the future.",autonomous vehicle
10.1016/j.drudis.2020.12.003,filtered,Drug Discovery Today,sciencedirect,2021-03-31,sciencedirect,Advanced machine-learning techniques in drug discovery,https://api.elsevier.com/content/article/pii/S1359644620305213,"The popularity of machine learning (ML) across drug discovery continues to grow, yielding impressive results. As their use increases, so do their limitations become apparent. Such limitations include their need for big data, sparsity in data, and their lack of interpretability. It has also become apparent that the techniques are not truly autonomous, requiring retraining even post deployment. In this review, we detail the use of advanced techniques to circumvent these challenges, with examples drawn from drug discovery and allied disciplines. In addition, we present emerging techniques and their potential role in drug discovery. The techniques presented herein are anticipated to expand the applicability of ML in drug discovery.",autonomous vehicle
10.1016/j.procir.2020.04.039,filtered,Procedia CIRP,sciencedirect,2020-12-31,sciencedirect,Automated machine learning for predictive quality in production,https://api.elsevier.com/content/article/pii/S2212827120306016,"Applications that leverage the benefits of applying machine learning (ML) in production have been successfully realized. A fundamental hurdle to scale ML-based projects is the necessity of expertise from manufacturing and data science. One possible solution lies in automating the ML pipeline: integration, preparation, modeling and model deployment. This paper shows the possibilities and limits of applying AutoML in production, including a benchmarking of available systems. Furthermore, AutoML is compared to manual implementation in a predictive quality use case: AutoML still requires programming knowledge and is outperformed by manual implementation - but sufficient results are available in a shorter timespan.",autonomous vehicle
10.1016/j.dcan.2021.10.007,filtered,Digital Communications and Networks,sciencedirect,2021-10-28,sciencedirect,Machine learning in vehicular networking: an overview,https://api.elsevier.com/content/article/pii/S2352864821000870,"As vehicle complexity and road congestion increase, combined with the emergence of electric vehicles, the need for intelligent transportation systems to improve on-road safety and transportation efficiency using vehicular networks has become essential. The evolution of high mobility wireless networks will provide improved support for connected vehicles through highly dynamic heterogeneous networks. Particularly, 5G deployment introduces new features and technologies that enable operators to capitalize on emerging infrastructure capabilities. Machine Learning (ML), a powerful methodology for adaptive and predictive system development, has emerged in both vehicular and conventional wireless networks. Adopting data-centric methods enables ML to address highly dynamic vehicular network issues faced by conventional solutions, such as traditional control loop design and optimization techniques. This article provides a short survey of ML applications in vehicular networks from the networking aspect. Research topics covered in this article include network control containing handover management and routing decision making, resource management, and energy efficiency in vehicular networks. The findings of this paper suggest more attention should be paid to network forming/deforming decision making. ML applications in vehicular networks should focus on researching multi-agent cooperated oriented methods and overall complexity reduction while utilizing enabling technologies, such as mobile edge computing for real-world deployment. Research datasets, simulation environment standardization, and method interpretability also require more research attention.",autonomous vehicle
10.1016/j.jnca.2021.103084,filtered,Journal of Network and Computer Applications,sciencedirect,2021-08-15,sciencedirect,A Systematic Review of Quality of Service in Wireless Sensor Networks using Machine Learning: Recent Trend and Future Vision,https://api.elsevier.com/content/article/pii/S1084804521001065,"
                  Wireless Sensor Network (WSN) is used in different research areas such as military, industry, healthcare, agriculture, Internet of Things (IoT), transportation, and smart cities. The reason behind this increased usage is the rapid development of smart sensors. There is a challenging need to satisfy the Quality of Service (QoS) requirements in different applications due to the dynamic network condition, heterogeneous traffic flows and resource-constrained behaviour of sensor nodes. Optimizing the QoS in terms of performance, privacy and security levels is an open issue in the WSN. It has limited resources and is deployed in hostile environment where achieving high performance is difficult. This performance level is categorized into four subcategories: deployment phase, layered architecture, measurability, network and application specific parameter. Privacy and security levels are divided into four parameters: security, confidentiality, integrity and safety. A systematic review is presented in this paper based on QoS parameters in the light of Machine Learning (ML) techniques. It also provides a methodological framework for the performance parameters. This study presents a statistical analysis of the past ten years ranging from 2011 to 2021 on various ML techniques used for the QoS parameters. Finally, the author's vision is highlighted with some discussion on the open issues which forms the baseline for the future research directions.
               ",autonomous vehicle
10.1016/j.enbuild.2020.109807,filtered,Energy and Buildings,sciencedirect,2020-03-15,sciencedirect,The use of artificial intelligence (AI) methods in the prediction of thermal comfort in buildings: energy implications of AI-based thermal comfort controls,https://api.elsevier.com/content/article/pii/S0378778819336527,"
                  Buildings consume about 40 % of globally-produced energy. A notable amount of this energy is used to provide sufficient comfort levels to the building occupants. Moreover, given recent increases in global temperatures as a result of climate change and the associated decrease in comfort levels, providing adequate comfort levels in indoor spaces has become increasingly important. However, striking a balance between reducing building energy use and providing adequate comfort levels is a significant challenge. Conventional control methods for indoor spaces, such as on/off, proportional-integral (PI), and proportional-integral-derivative (PID) controllers, display significant instabilities and frequently overshoot thermostats, resulting in unnecessary energy use. Additionally, conventional building control methods rarely include comfort regulatory schemes. Consequently, recent research efforts have focused on the use of advanced artificial intelligence (AI) methods to optimize building energy usage while maintaining occupant thermal comfort. We present a review of the current AI-based methodologies being used to enhance thermal comfort in indoor spaces. we focus on thermal comfort predictive models using diverse machine learning (ML) algorithms and their deployment in building control systems for energy saving purposes. We then discuss gaps in the existing literature and highlight potential future research directions.
               ",autonomous vehicle
10.1016/j.inffus.2019.12.012,filtered,Information Fusion,sciencedirect,2020-06-30,sciencedirect,"Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI",https://api.elsevier.com/content/article/pii/S1566253519308103,"
                  In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.
               ",autonomous vehicle
10.1016/j.aei.2020.101101,filtered,Advanced Engineering Informatics,sciencedirect,2020-08-31,sciencedirect,Predictive model-based quality inspection using Machine Learning and Edge Cloud Computing,https://api.elsevier.com/content/article/pii/S1474034620300707,"The supply of defect-free, high-quality products is an important success factor for the long-term competitiveness of manufacturing companies. Despite the increasing challenges of rising product variety and complexity and the necessity of economic manufacturing, a comprehensive and reliable quality inspection is often indispensable. In consequence, high inspection volumes turn inspection processes into manufacturing bottlenecks. In this contribution, we investigate a new integrated solution of predictive model-based quality inspection in industrial manufacturing by utilizing Machine Learning techniques and Edge Cloud Computing technology. In contrast to state-of-the-art contributions, we propose a holistic approach comprising the target-oriented data acquisition and processing, modelling and model deployment as well as the technological implementation in the existing IT plant infrastructure. A real industrial use case in SMT manufacturing is presented to underline the procedure and benefits of the proposed method. The results show that by employing the proposed method, inspection volumes can be reduced significantly and thus economic advantages can be generated.",autonomous vehicle
10.1016/j.jksuci.2021.07.020,filtered,Journal of King Saud University - Computer and Information Sciences,sciencedirect,2021-07-30,sciencedirect,Intelligent transportation systems: A survey on modern hardware devices for the era of machine learning,https://api.elsevier.com/content/article/pii/S1319157821001877,"The increasing complexity of Intelligent Transportation Systems (ITS), that comprise a wide variety of applications and services, has imposed a necessity for high-performance Modern Hardware Devices (MHDs). The performance challenge has become more noticeable with the integration of Machine Learning (ML) techniques deployed in large-scale settings. ML has effectively supported the field of ITS by providing efficient and optimized solutions to problems that were otherwise tackled using traditional statistical and analytical approaches. Addressing the hardware deployment needs of ITS in the era of ML is a challenging problem that involves temporal, spatial, environmental, and economical factors. This survey reviews the recent literature of ML-driven ITS, in which MHDs were utilized, with a focus on performance indicators. A taxonomy is then synthesized, giving a complete representation of what the current capabilities of the surveyed ITS rely on in terms of ML techniques and technological infrastructure. To alleviate the difficulties faced in the non-trivial task of selecting suitable ML techniques and MHDs for an ITS with a specific complexity level, a performance evaluation framework is proposed. The presented survey sets the basis for developing suitable hardware, facilitating the integration of ML within ITS, and bridging the gap between research and real-world deployments.",autonomous vehicle
10.1016/j.future.2021.05.030,filtered,Future Generation Computer Systems,sciencedirect,2021-11-30,sciencedirect,Asymmetric cryptographic functions based on generative adversarial neural networks for Internet of Things,https://api.elsevier.com/content/article/pii/S0167739X21001801,"
                  Increasingly, one should assume that the (digital) environment, e.g., Internet-of-Things (IoT) systems, we operate in is untrusted. In other words, this is a zero trust environment, in the sense that all devices and systems can be compromised and hence, untrusted. However, information sharing in a zero trust environment is more challenging, in comparison to an environment where we can rely on some trusted third-party. To address this challenge, we propose a blockchain-enabled zero trust information sharing protocol that is able to support the filtering of fabricated information and protect participant privacy during information sharing. We then prove the security of our protocol in the universally composable secure framework, and also evaluate its performance using a series of experiments. The evaluation results show that the average execution times of the three key steps in our protocol are 0.059 s, 0.060 s and 0.032 s, which demonstrates its potential for deployment in a real-world setting.
               ",autonomous vehicle
10.1016/j.procs.2019.06.016,filtered,Procedia Computer Science,sciencedirect,2019-12-31,sciencedirect,Deep Learning-Based Power Usage Forecast Modeling and Evaluation,https://api.elsevier.com/content/article/pii/S1877050919307859,"The growing Internet of Things (IoT) provides significant resources to be integrated with critical infrastructures to enable cyber-physical systems. More specifically, the deployment of smart meters for electricity usage monitoring in the smart grid can provide granular and detailed information from which power load forecasting can be carried out. However, the accurate prediction of long-term power usage remains a challenging issue. In light of many recent advances, deep learning has the potential to significantly improve the ability to assess data and make predictions, and is already rapidly changing the world we live in. As such, in this paper, we consider the use of deep learning, via Recursive Neural Network (RNN) and Long Short-Term Memory layers, for the long-term prediction of localized power consumption. In particular, we consider the optimization of both data feature sets and neural network models, developing three model-feature combinations to maximize prediction accuracy and minimize error. Through detailed experimental evaluation, our results demonstrate the ability to achieve highly accurate predictions over periods as large as 21 days through the integration of correlated features.",autonomous vehicle
10.1016/j.kint.2021.01.015,filtered,Kidney International,sciencedirect,2021-06-30,sciencedirect,AI applications in renal pathology,https://api.elsevier.com/content/article/pii/S0085253821001812,"
                  The explosive growth of artificial intelligence (AI) technologies, especially deep learning methods, has been translated at revolutionary speed to efforts in AI-assisted healthcare. New applications of AI to renal pathology have recently become available, driven by the successful AI deployments in digital pathology. However, synergetic developments of renal pathology and AI require close interdisciplinary collaborations between computer scientists and renal pathologists. Computer scientists should understand that not every AI innovation is translatable to renal pathology, while renal pathologists should capture high-level principles of the relevant AI technologies. Herein, we provide an integrated review on current and possible future applications in AI-assisted renal pathology, by including perspectives from computer scientists and renal pathologists. First, the standard stages, from data collection to analysis, in full-stack AI-assisted renal pathology studies are reviewed. Second, representative renal pathology-optimized AI techniques are introduced. Last, we review current clinical AI applications, as well as promising future applications with the recent advances in AI.
               ",autonomous vehicle
10.1016/j.dcan.2021.11.002,filtered,Digital Communications and Networks,sciencedirect,2021-11-15,sciencedirect,Reconfigurable intelligent surface: Design the channel – A new opportunity for future wireless networks,https://api.elsevier.com/content/article/pii/S2352864821000912,"In this paper, we survey state-of-the-art research outcomes in the burgeoning field of Reconfigurable Intelligent Surface (RIS) given its potential for significant performance enhancement of next-generation wireless communication networks by means of adapting a propagation environment. Emphasis has been placed on several aspects gating the commercially viability of a future network deployment. Comprehensive summaries are provided for practical hardware design considerations and broad implications of artificial intelligence techniques, as are in-depth outlooks on the salient aspects of system models, use cases, and physical layer optimization techniques.",autonomous vehicle
10.1016/j.engappai.2013.04.010,filtered,Engineering Applications of Artificial Intelligence,sciencedirect,2013-10-31,sciencedirect,An appraisal and design of a multi-agent system based cooperative wireless intrusion detection computational intelligence technique,https://api.elsevier.com/content/article/pii/S0952197613000766,"
                  The deployment of wireless sensor networks and mobile ad-hoc networks in applications such as emergency services, warfare and health monitoring poses the threat of various cyber hazards, intrusions and attacks as a consequence of these networks’ openness. Among the most significant research difficulties in such networks safety is intrusion detection, whose target is to distinguish between misuse and abnormal behavior so as to ensure secure, reliable network operations and services. Intrusion detection is best delivered by multi-agent system technologies and advanced computing techniques. To date, diverse soft computing and machine learning techniques in terms of computational intelligence have been utilized to create Intrusion Detection and Prevention Systems (IDPS), yet the literature does not report any state-of-the-art reviews investigating the performance and consequences of such techniques solving wireless environment intrusion recognition issues as they gain entry into cloud computing. The principal contribution of this paper is a review and categorization of existing IDPS schemes in terms of traditional artificial computational intelligence with a multi-agent support. The significance of the techniques and methodologies and their performance and limitations are additionally analyzed in this study, and the limitations are addressed as challenges to obtain a set of requirements for IDPS in establishing a collaborative-based wireless IDPS (Co-WIDPS) architectural design. It amalgamates a fuzzy reinforcement learning knowledge management by creating a far superior technological platform that is far more accurate in detecting attacks. In conclusion, we elaborate on several key future research topics with the potential to accelerate the progress and deployment of computational intelligence based Co-WIDPSs.
               ",autonomous vehicle
10.1016/j.arcontrol.2021.04.001,filtered,Annual Reviews in Control,sciencedirect,2021-12-31,sciencedirect,Robustness of AI-based prognostic and systems health management,https://api.elsevier.com/content/article/pii/S1367578821000195,"
                  Prognostic and systems Health Management (PHM) is an integral part of a system. It is used for solving reliability problems that often manifest due to complexities in design, manufacturing, operating environment and system maintenance. For safety-critical applications, using a model-based development process for complex systems might not always be ideal but it is equally important to establish the robustness of the solution. The information revolution has allowed data-driven methods to diffuse within this field to construct the requisite process (or system models) to cope with the so-called big data phenomenon. This is supported by large datasets that help machine-learning models achieve impressive accuracy. AI technologies are now being integrated into many PHM related applications including aerospace, automotive, medical robots and even autonomous weapon systems. However, with such rapid growth in complexity and connectivity, a systems’ behaviour is influenced in unforeseen ways by cyberattacks, human errors, working with incorrect or incomplete models and even adversarial phenomena. Many of these models depend on the training data and how well the data represents the test data. These issues require fine-tuning and even retraining the models when there is even a small change in operating conditions or equipment. Yet, there is still ambiguity associated with their implementation, even if the learning algorithms classify accordingly. Uncertainties can lie in any part of the AI-based PHM model, including in the requirements, assumptions, or even in the data used for training and validation. These factors lead to sub-optimal solutions with an open interpretation as to why the requirements have not been met. This warrants the need for achieving a level of robustness in the implemented PHM, which is a challenging task in a machine learning solution.
                  This article aims to present a framework for testing the robustness of AI-based PHM. It reviews some key milestones achieved in the AI research community to deal with three particular issues relevant for AI-based PHM in safety-critical applications: robustness to model errors, robustness to unknown phenomena and empirical evaluation of robustness during deployment. To deal with model errors, many techniques from probabilistic inference and robust optimisation are often used to provide some robustness guarantee metric. In the case of unknown phenomena, techniques include anomaly detection methods, using causal models, the construction of ensembles and reinforcement learning. It elicits from the authors’ work on fault diagnostics and robust optimisation via machine learning techniques to offer guidelines to the PHM research community. Finally, challenges and future directions are also examined; on how to better cope with any uncertainties as they appear during the operating life of an asset.
               ",autonomous vehicle
10.1016/j.patcog.2020.107677,filtered,Pattern Recognition,sciencedirect,2021-03-31,sciencedirect,Exploring global diverse attention via pairwise temporal relation for video summarization,https://api.elsevier.com/content/article/pii/S0031320320304805,"
                  Video summarization is an effective way to facilitate video searching and browsing. Most of existing systems employ encoder-decoder based recurrent neural networks, which fail to explicitly diversify the system-generated summary frames while requiring intensive computations. In this paper, we propose an efficient convolutional neural network architecture for video SUMmarization via Global Diverse Attention called SUM-GDA, which adapts attention mechanism in a global perspective to consider pairwise temporal relations of video frames. Particularly, the GDA module has two advantages: (1) it models the relations within paired frames as well as the relations among all pairs, thus capturing the global attention across all frames of one video; (2) it reflects the importance of each frame to the whole video, leading to diverse attention on these frames. Thus, SUM-GDA is beneficial for generating diverse frames to form satisfactory video summary. Extensive experiments on three data sets, i.e., SumMe, TVSum, and VTW, have demonstrated that SUM-GDA and its extension outperform other competing state-of-the-art methods with remarkable improvements. In addition, the proposed models can be run in parallel with significantly less computational costs, which helps the deployment in highly demanding applications.
               ",autonomous vehicle
10.1016/j.jnca.2021.103244,filtered,Journal of Network and Computer Applications,sciencedirect,2021-12-15,sciencedirect,Towards development of IoT-ML driven healthcare systems: A survey,https://api.elsevier.com/content/article/pii/S1084804521002423,"
                  The impact of IoT-ML in the healthcare sector is very significant and it has helped us to change our view at the traditional treatment methods. In IoT-ML-based healthcare applications, the sensing layer is responsible for collecting information from humans and transferring it to the storage layer through communication technology. ML is implemented to make intelligent decisions for healthcare applications. This survey shows all the fields starting from the IoT sensor devices to the deployment of ML in the healthcare sector. We have conducted a comprehensive survey of the existing literature covering IoT and ML strategies from a healthcare perspective. We also provide insights into the different types of network storage and computing strategies used for other health-based applications. We believe that the presented work is innovative as no other survey is furnished in such manner. From this survey, researchers can get an overview of IoT-ML and cloud-based healthcare applications under the single system. We have proposed a unique taxonomy from an IoT-ML-based healthcare perspective where we have highlighted key steps in developing healthcare systems. We have culminated the most striking technologies in IoT, communications, network storage and computing, and ML for healthcare systems. Another contribution of our survey is that we have collected and discussed surveys and scientific literature based on the proposed taxonomy and their sub-taxonomy throughout this paper. Besides that we have reviewed several types of popularly used sensors, development boards in healthcare with various examples. We also show the mapping of communication technology with the protocols used by IoT sensors. In the ML section, we have shown an ML pipeline centering on healthcare application and discussed every step of it. Finally, we have identified a number of research challenges including exploration of Deep Learning based models, proper data acquisition and handling of data, privacy and ethics, security issues in WBAN, etc. These research challenges will provide the researchers the necessary future research directions while developing IoT-ML-based healthcare applications.
               ",autonomous vehicle
10.1016/j.neucom.2019.08.003,filtered,Neurocomputing,sciencedirect,2019-11-20,sciencedirect,Complete vector quantization of feedforward neural networks,https://api.elsevier.com/content/article/pii/S0925231219311129,"
                  Deep neural networks are widely used to solve several difficult machine learning tasks due to their impressive performance on standard benchmarking datasets. Most of the state of the art neural architectures contain a staggering amount of parameters and have many layers. Thus, they are computationally intensive and memory demanding models. This fact prohibits their deployment in devices with limited computational resources such as smartphones and unmanned vehicles. Recently, a growing interest in developing methods that can compress and accelerate these networks emerged. In this paper, we propose the use of complete vector quantization for neural model compression and acceleration. More specifically, we show that it is possible to use product quantization with common subdictionaries to quantize both the parameters and the activations of the neural network without compromising significantly the network accuracy. The proposed method removes the need for multiplications in order to compute the neural preactivations and provides opportunities for acceleration using lookup tables.
               ",autonomous vehicle
10.1016/j.bdr.2018.04.002,filtered,Big Data Research,sciencedirect,2018-12-31,sciencedirect,A Dynamic Neural Network Architecture with Immunology Inspired Optimization for Weather Data Forecasting,https://api.elsevier.com/content/article/pii/S2214579617303696,"
                  Recurrent neural networks are dynamical systems that provide for memory capabilities to recall past behaviour, which is necessary in the prediction of time series. In this paper, a novel neural network architecture inspired by the immune algorithm is presented and used in the forecasting of naturally occurring signals, including weather big data signals. Big Data Analysis is a major research frontier, which attracts extensive attention from academia, industry and government, particularly in the context of handling issues related to complex dynamics due to changing weather conditions. Recently, extensive deployment of IoT, sensors, and ambient intelligence systems led to an exponential growth of data in the climate domain. In this study, we concentrate on the analysis of big weather data by using the Dynamic Self Organized Neural Network Inspired by the Immune Algorithm. The learning strategy of the network focuses on the local properties of the signal using a self-organised hidden layer inspired by the immune algorithm, while the recurrent links of the network aim at recalling previously observed signal patterns. The proposed network exhibits improved performance when compared to the feedforward multilayer neural network and state-of-the-art recurrent networks, e.g., the Elman and the Jordan networks. Three non-linear and non-stationary weather signals are used in our experiments. Firstly, the signals are transformed into stationary, followed by 5-steps ahead prediction. Improvements in the prediction results are observed with respect to the mean value of the error (RMS) and the signal to noise ratio (SNR), however to the expense of additional computational complexity, due to presence of recurrent links.
               ",autonomous vehicle
10.1016/j.ecoinf.2021.101212,filtered,Ecological Informatics,sciencedirect,2021-03-31,sciencedirect,Advances in image acquisition and processing technologies transforming animal ecological studies,https://api.elsevier.com/content/article/pii/S1574954121000030,"
                  Images and videos have become pervasive in ecological research and the ease of acquiring image data and its subsequent processing can provide answers in research areas such as species recognition, animal behaviour, and population studies which are critical for animal conservation and biodiversity. Technological advances in imaging are enabling data collection from new areas such as from underwater, new modalities such as thermal and new ways of processing such as deep learning. These advances are accelerating due to ease of data collection, better storage and processing technologies with associated lowering costs. The advancements in state-of-the-art machine learning for image and video classification and analysis can directly be applied in ecology. Ecological applications are generally conducted in remote and harsh deployment environments, and therefore present formidable challenges that require appreciation of the limitations of such technologies. The ecological field is poised to make use of images acquired through drones, robotics, and satellites through machine learning for rapid advancements in critical research areas. Timely insights from such data help to understand and protect the species and environment. This paper provides a review of the advancements in image acquisition and processing technologies used in animal ecological studies. We also discuss concepts and technologies that would help foster future ecological research methodologies potentially opening new insights and quickening growth to an already rich and data-intensive field.
               ",autonomous vehicle
10.1016/j.aei.2021.101404,filtered,Advanced Engineering Informatics,sciencedirect,2021-10-31,sciencedirect,A survey of modeling for prognosis and health management of industrial equipment,https://api.elsevier.com/content/article/pii/S1474034621001567,"
                  Prognosis and health management plays an important role in the control of costs associated with operating large industrial equipment, such as wind turbines and aircraft. It is only fair that engineers and scientists have vastly researched modeling approaches to support decision making. Motivated by the growing availability of data and computational power as well as the advances in algorithms and methods, modeling frameworks often merge elements of physics, machine learning, and statistical learning. In this paper, we present a review on modeling in support of prognosis and health management of industrial equipment. This survey complements the existing prognosis and health management literature by discussing how modeling strategies are influenced by industry-specific aspects such as maintenance approaches (e.g., reactive, proactive, and predictive), implementation factors (e.g., industry, business model, purpose, development, and deployment), as well as supporting technologies (sensing, repair, and modeling itself). We use the onshore wind energy and civil aviation industries to illustrate how these aforementioned aspects can influence modeling and implementation of prognosis and health management. The literature review is broad and covers contributions over the past 40 years. We close the paper with few topics that can motive research going forward.
               ",autonomous vehicle
10.1016/j.techfore.2018.03.024,filtered,Technological Forecasting and Social Change,sciencedirect,2020-04-30,sciencedirect,Big data analytics: Computational intelligence techniques and application areas,https://api.elsevier.com/content/article/pii/S0040162517318498,"
                  Big Data has significant impact in developing functional smart cities and supporting modern societies. In this paper, we investigate the importance of Big Data in modern life and economy, and discuss challenges arising from Big Data utilization. Different computational intelligence techniques have been considered as tools for Big Data analytics. We also explore the powerful combination of Big Data and Computational Intelligence (CI) and identify a number of areas, where novel applications in real world smart city problems can be developed by utilizing these powerful tools and techniques. We present a case study for intelligent transportation in the context of a smart city, and a novel data modelling methodology based on a biologically inspired universal generative modelling approach called Hierarchical Spatial-Temporal State Machine (HSTSM). We further discuss various implications of policy, protection, valuation and commercialization related to Big Data, its applications and deployment.
               ",autonomous vehicle
10.1016/j.jpdc.2020.07.008,filtered,Journal of Parallel and Distributed Computing,sciencedirect,2020-12-31,sciencedirect,"Intelligently modeling, detecting, and scheduling elephant flows in software defined energy cloud: A survey",https://api.elsevier.com/content/article/pii/S0743731520303373,"
                  Elephant flows (elephants) refer to the sequences of packets that contribute only 10% of the total volume but consume over 90% of the network bandwidth. They often cause network congestion and should be efficiently managed. Present cloud data centers often involve host- and switch-based approaches to detect and schedule elephants, but suffer (1) each host and switch in the network needs to be customized, and (2) dynamic models and advanced policies are difficult to be applied. Software Defined Cloud (SDC) addresses these issues by enabling controller-based approaches. With the aid of Machine Learning (ML) technologies, SDC can achieve learning-based models, flexible deployment, and early detection and schedule of elephants for the optimization of network performance and energy usage in a dynamic and intelligent manner. On this purpose, this article emphases the significance of models describing elephants, surveys the mechanisms that may apply to model, detect, and schedule elephants for SDC to optimize the network performance and energy usage. To the best of our knowledge, this work is the first effort that reviews the techniques in all these related subtopics simultaneously in the context of energy cloud.
               ",autonomous vehicle
10.1016/j.future.2020.07.025,filtered,Future Generation Computer Systems,sciencedirect,2020-12-31,sciencedirect,A novel multi-view pedestrian detection database for collaborative Intelligent Transportation Systems,https://api.elsevier.com/content/article/pii/S0167739X20300340,"
                  Recent advances in machine-learning, especially in deep neural networks have significantly accelerated the development and deployment of transport-oriented intelligent designs with increasingly high efficiency. While these technologies are exceptionally promising toward revolutionizing our current mobility and reducing the number of road accidents, the way to safe Intelligent Transportation Systems (ITS) remains long. Since pedestrians are the most vulnerable road users, designing accurate pedestrian detection methods is a priority task. However, traditional monocular pedestrian detection methods are limited, especially in occlusion handling. Hence, a collaborative perception scheme in which vehicles no longer restrict their input data to their immediate embedded sensors and rather exploit data from remote sensors is necessary to achieve a more comprehensive environment perception. In this work, we propose a novel public dataset: Infrastructure to Vehicle Multi-View Pedestrian Detection Database (I2V-MVPD) that combines synchronized images from both a mobile camera embedded in a car and a static camera in the road infrastructure. We also propose a new multi-view pedestrian detection framework based on collaborative intelligence between vehicles and infrastructure. Our results show a significant improvement in detection performance over monocular detection.
               ",autonomous vehicle
10.1016/j.actaastro.2021.03.029,filtered,Acta Astronautica,sciencedirect,2021-07-31,sciencedirect,"On the guidance, navigation and control of in-orbit space robotic missions: A survey and prospective vision",https://api.elsevier.com/content/article/pii/S0094576521001429,"
                  In the first part, this article presents an overview of Guidance, Navigation and Control (GNC) methodologies developed for space manipulators to perform in-orbit robotic missions, including but not limited to, on-orbit servicing, satellite/station assembly, probing extra-terrestrial objects and space debris mitigation. Some space mission concepts are briefly mentioned, for which space robotics is discussed to be among the most practical and universal solutions. Common phases of an in-orbit robotic mission are identified as: close-range rendezvous, attitude synchronization, target identification, manipulator deployment, capture, and if needed, post-capture maneuvers. Prominent GNC methodologies that are either proposed for or applicable to each phase are extensively reviewed. In the current article, the emphasis is placed on the study of GNC methodologies utilized in attitude synchronization, manipulator deployment, and capture phases, specially the ones reported for use in the two free-floating and free-flying operating regimes of space manipulators. Kinematics and dynamics of space manipulator systems are formulated to help unifying the presentation of the main ideas behind different GNC methodologies. Using a unified notation, comparison tables and discussions provided in this paper, researchers can compare various GNC approaches and contribute to the next-generation GNC systems for space robots. In addition, this survey aids technology users to learn about in-orbit robotic missions and choose appropriate GNC technologies for specific applications. In the second part of this paper, two families of emerging control schemes based upon reinforcement learning and geometric mechanics are introduced as promising research directions in the GNC of space robotic systems. The benefits of implementing these techniques to the GNC of in-orbit robotic missions are discussed. An exclusive study of environmental disturbances affecting space manipulators and their threat to long-term autonomy concludes this article.
               ",autonomous vehicle
10.1016/j.neucom.2020.02.035,filtered,Neurocomputing,sciencedirect,2020-07-20,sciencedirect,Sparse low rank factorization for deep neural network compression,https://api.elsevier.com/content/article/pii/S0925231220302253,"
                  Storing and processing millions of parameters in deep neural networks is highly challenging during the deployment of model in real-time application on resource constrained devices. Popular low-rank approximation approach singular value decomposition (SVD) is generally applied to the weights of fully connected layers where compact storage is achieved by keeping only the most prominent components of the decomposed matrices. Years of research on pruning-based neural network model compression revealed that the relative importance or contribution of each neuron in a layer highly vary among each other. Recently, synapses pruning has also demonstrated that having sparse matrices in network architecture achieve lower space and faster computation during inference time. We extend these arguments by proposing that the low-rank decomposition of weight matrices should also consider significance of both input as well as output neurons of a layer. Combining the ideas of sparsity and existence of unequal contributions of neurons towards achieving the target, we propose sparse low rank (SLR) method which sparsifies SVD matrices to achieve better compression rate by keeping lower rank for unimportant neurons. We demonstrate the effectiveness of our method in compressing famous convolutional neural networks based image recognition frameworks which are trained on popular datasets. Experimental results show that the proposed approach SLR outperforms vanilla truncated SVD and a pruning baseline, achieving better compression rates with minimal or no loss in the accuracy. Code of the proposed approach is avaialble at https://github.com/sridarah/slr.
               ",autonomous vehicle
10.1016/j.csl.2010.04.002,filtered,Computer Speech & Language,sciencedirect,2011-04-30,sciencedirect,A prototype for a conversational companion for reminiscing about images,https://api.elsevier.com/content/article/pii/S0885230810000331,"
                  This paper describes an initial prototype of the Companions project (www.companions-project.org): the Senior Companion (SC), designed to be a platform to display novel approaches to:
                        
                           (1)
                           The use of Information Extraction (IE) techniques to extract the content of incoming dialogue utterances after an ASR phase.
                        
                        
                           (2)
                           The conversion of the input to RDF form to allow the generation of new facts from existing ones, under the control of a Dialogue Manager (DM), that also has access to stored knowledge and knowledge accessed in real time from the web, all in RDF form.
                        
                        
                           (3)
                           A DM expressed as a stack and network virtual machine that models mixed initiative in dialogue control.
                        
                        
                           (4)
                           A tuned dialogue act detector based on corpus evidence.
                        
                     
                  
                  The prototype platform was evaluated, and we describe this; it is also designed to support more extensive forms of emotion detection carried by both speech and lexical content, as well as extended forms of machine learning. We describe preliminary studies and results for these, in particular a novel approach to enabling reinforcement learning for open dialogue systems through the detection of emotion in the speech signal and its deployment as a form of a learned DM, at a higher level than the DM virtual machine and able to direct the SC's responses to a more emotionally appropriate part of its repertoire.
               ",autonomous vehicle
10.1016/B978-0-12-819710-3.00008-9,filtered,From Smart Grid to Internet of Energy,sciencedirect,2019-12-31,sciencedirect,"Chapter 8: Big data, privacy and security in smart grids",https://api.elsevier.com/content/article/pii/B9780128197103000089,"
               The smart grid applications are related with monitoring and control operations of conventional power grid. The integration of information and communication technologies (ICT) to existing power network has leveraged interaction of different generators, controllers, monitoring and measurement devices, and intelligent loads. The two-way communication infrastructure is comprised by numerous sensor networks that increased deployment of massive data from measurement nodes to monitoring centers. Big data is a widespread concept which become a trend for massive data streams that are transferred and processed in an ecosystem. The enormous amount of data are generated, transferred and stored to improve operating and management quality of smart grid. The big data analytics are performed to improve quality of service in terms of grid operators and consumers. The big data acquisition, processing, storing, and clustering stages are widely researched by a wide variety of specialist. In this chapter, the all these stages, big data acquisition technologies, machine learning methods used in big data analytics, privacy and security of big data infrastructure are introduced in detail. The privacy preserving methods, big data processing technologies and firmware infrastructures are presented in the context of this chapter.
            ",autonomous vehicle
10.1016/j.compind.2018.03.025,filtered,Computers in Industry,sciencedirect,2018-08-31,sciencedirect,A novel Big Data analytics and intelligent technique to predict driver's intent,https://api.elsevier.com/content/article/pii/S0166361517303640,"
                  Modern age offers a great potential for automatically predicting the driver's intent through the increasing miniaturization of computing technologies, rapid advancements in communication technologies and continuous connectivity of heterogeneous smart objects. Inside the cabin and engine of modern cars, dedicated computer systems need to possess the ability to exploit the wealth of information generated by heterogeneous data sources with different contextual and conceptual representations. Processing and utilizing this diverse and voluminous data, involves many challenges concerning the design of the computational technique used to perform this task. In this paper, we investigate the various data sources available in the car and the surrounding environment, which can be utilized as inputs in order to predict driver's intent and behavior. As part of investigating these potential data sources, we conducted experiments on e-calendars for a large number of employees, and have reviewed a number of available geo referencing systems. Through the results of a statistical analysis and by computing location recognition accuracy results, we explored in detail the potential utilization of calendar location data to detect the driver's intentions. In order to exploit the numerous diverse data inputs available in modern vehicles, we investigate the suitability of different Computational Intelligence (CI) techniques, and propose a novel fuzzy computational modelling methodology. Finally, we outline the impact of applying advanced CI and Big Data analytics techniques in modern vehicles on the driver and society in general, and discuss ethical and legal issues arising from the deployment of intelligent self-learning cars.
               ",autonomous vehicle
10.1016/j.eswa.2009.05.059,filtered,Expert Systems with Applications,sciencedirect,2010-01-31,sciencedirect,A data driven ensemble classifier for credit scoring analysis,https://api.elsevier.com/content/article/pii/S0957417409004771,"
                  This study focuses on predicting whether a credit applicant can be categorized as good, bad or borderline from information initially supplied. This is essentially a classification task for credit scoring. Given its importance, many researchers have recently worked on an ensemble of classifiers. However, to the best of our knowledge, unrepresentative samples drastically reduce the accuracy of the deployment classifier. Few have attempted to preprocess the input samples into more homogeneous cluster groups and then fit the ensemble classifier accordingly. For this reason, we introduce the concept of class-wise classification as a preprocessing step in order to obtain an efficient ensemble classifier. This strategy would work better than a direct ensemble of classifiers without the preprocessing step. The proposed ensemble classifier is constructed by incorporating several data mining techniques, mainly involving optimal associate binning to discretize continuous values; neural network, support vector machine, and Bayesian network are used to augment the ensemble classifier. In particular, the Markov blanket concept of Bayesian network allows for a natural form of feature selection, which provides a basis for mining association rules. The learned knowledge is represented in multiple forms, including causal diagram and constrained association rules. The data driven nature of the proposed system distinguishes it from existing hybrid/ensemble credit scoring systems.
               ",autonomous vehicle
10.1016/j.engappai.2016.11.001,filtered,Engineering Applications of Artificial Intelligence,sciencedirect,2017-02-28,sciencedirect,Improving relevance in a content pipeline via syntactic generalization,https://api.elsevier.com/content/article/pii/S0952197616302032,"
                  This is a report from the field on a linguistic-based relevance technology based on learning of parse trees for processing, classification and delivery of a stream of texts. We describe the content pipeline for eBay entertainment domain which employs this technology, and show that text processing relevance is the main bottleneck for its performance. A number of components of the content pipeline such as content mining, aggregation, deduplication, opinion mining, integrity enforcing need to rely on domain-independent efficient text classification, entity extraction and relevance assessment operations.
                  Text relevance assessment is based on the operation of syntactic generalization (SG) which finds a maximum common sub-tree for a pair of parse trees for sentences. Relevance of two portions of texts is then defined as a cardinality of this sub-tree. SG is intended to substitute keyword-based analysis for more accurate assessment of relevance which takes phrase-level and sentence-level information into account. In the partial case where short expression are commonly used terms such as Facebook likes, SG ascends to the level of categories and a reasoning technique is required to map these categories in the course of relevance assessment.
                  A number of content pipeline components employ web mining which needs SG to compare web search results. We describe how SG works in a number of components in the content pipeline including personalization and recommendation, and provide the evaluation results for eBay deployment. Content pipeline support is implemented as an open source contribution OpenNLP.Similarity and is available at https://github.com/bgalitsky/relevance-based-on-pars-trees.
               ",autonomous vehicle
10.1016/j.comcom.2020.06.030,filtered,Computer Communications,sciencedirect,2020-07-01,sciencedirect,Towards trustworthy Internet of Things: A survey on Trust Management applications and schemes,https://api.elsevier.com/content/article/pii/S0140366419319073,"
                  Advancement in technology with the proliferation of new wireless communication protocols gave rise to the new era of ubiquitous computing, called Internet of Things (IoT). IoT facilitates connectivity between various heterogeneous physical devices through the internet to advantage users with intelligent and more advanced services. Effective utilization of these services demands a secure system where one can rely on the source of the information together with the received information. Trust Management (TM) is a crucial aspect of security that aims to maintain reliability in a system by ensuring the secure exchange of information. Using the concept of local and global perception about the reputation, TM measures the degree of trust on the system’s entities and endeavors to reduce risk and uncertainty in the system. For IoT, TM paves the way to accomplish various decision-making tasks, like reliable service composition, secure routing, device authentication, access control, etc. However, design and deployment of TM for IoT are hindered by the inherent characteristics of IoT systems that demand to be addressed.
                  In this paper, we identified various applications of TM and examined issues in the design and deployment of TM for IoT. A clear vision towards TM system, explaining the different phases involved in the process of managing the trust, is presented. Furthermore, an exhaustive survey on various TM schemes developed for IoT with their applicability and addressing issues is provided. The survey is conducted considering direct observations and indirect recommendations based distributed, semi-distributed, and centralized schemes along with the review on blockchain technology-based schemes for trust management in IoT. In addition to that, a comparative study of the existing schemes based on the various system measures like computation model, input attributes, evaluation tool, and performance metrics examining their strengths and weaknesses is given. Finally, the paper highlights open research challenges investigated by the survey to present future direction for the researchers.
               ",autonomous vehicle
10.1016/j.comcom.2016.07.012,filtered,Computer Communications,sciencedirect,2016-11-15,sciencedirect,Cognitive radio for M2M and Internet of Things: A survey,https://api.elsevier.com/content/article/pii/S0140366416302699,"
                  Internet of things (IoT) paradigm poses new challenges to the communication technology as numerous heterogeneous objects will need to be connected. To address these issues new radio technologies and network architectures need to be designed to cater to several future devices having connectivity demands. For radio communications, the frequency spectrum allocation will have to be adapted for efficient spectrum utilization considering new bandwidth and application requirements. Novel research directions based on the use of opportunistic radio resource utilization such as those based on cognitive radio (CR) technology will have to be pursued for efficiency as well as reliability.
                  Cognitive Radio is a promising enabler communication technology for IoT. Its opportunistic communication paradigm is suited to communicating objects having event driven nature, that generate bursty traffic. Cognitive Radio can help overcome the problems of collision and excessive contention in the wireless access network that will arise due to the deployment of several objects connected to infrastructure through radio links. However, there are several issues that need to be addressed before cognitive radio technology can be used for Internet of things.
                  This paper surveys novel approaches and discusses research challenges related to the use of cognitive radio technology for Internet of things. In addition, the paper presents a general background on cognitive radio and Internet of Things with some potential applications. Our survey is different from existing surveys in that we focus on recent advances and ongoing research directions in cognitive radio in the context of Machine to Machine and Internet of Things. We review CR solutions that address generic problems of IoT including emerging challenges of autonomicity, scalability, energy efficiency, heterogeneity in terms of user equipment capabilities, complexity and environments, etc. The solutions are supported by our taxonomy of different CR approaches that are classified into two categories, flexible and efficient networking, and tackling heterogeneity. This paper intends to help new researchers entering the domain of CR and IoT by providing a comprehensive survey on recent advances.
               ",autonomous vehicle
10.1016/j.aei.2015.01.008,filtered,Advanced Engineering Informatics,sciencedirect,2015-04-30,sciencedirect,A review on computer vision based defect detection and condition assessment of concrete and asphalt civil infrastructure,https://api.elsevier.com/content/article/pii/S1474034615000208,"
                  To ensure the safety and the serviceability of civil infrastructure it is essential to visually inspect and assess its physical and functional condition. This review paper presents the current state of practice of assessing the visual condition of vertical and horizontal civil infrastructure; in particular of reinforced concrete bridges, precast concrete tunnels, underground concrete pipes, and asphalt pavements. Since the rate of creation and deployment of computer vision methods for civil engineering applications has been exponentially increasing, the main part of the paper presents a comprehensive synthesis of the state of the art in computer vision based defect detection and condition assessment related to concrete and asphalt civil infrastructure. Finally, the current achievements and limitations of existing methods as well as open research challenges are outlined to assist both the civil engineering and the computer science research community in setting an agenda for future research.
               ",autonomous vehicle
10.1016/j.autcon.2003.12.002,filtered,Automation in Construction,sciencedirect,2004-05-31,sciencedirect,Multi-agent systems in construction–state of the art and prospects,https://api.elsevier.com/content/article/pii/S0926580503001262,"
                  This paper provides an overview of the research and development of multi-agent systems (MAS) in construction. It identifies the key issues in the development and deployment of agent-based systems, and indicates how these issues should be addressed in the construction domain. To do so, this paper first reviews the notions of MAS; discusses agent collaboration mechanisms, and highlights the advantages that MAS could provide to collaborative engineering activities. It then discusses the MAS models developed for different construction problems where agents interact in various ways to solve construction problems. Finally, a number of important issues in the application of agent-based approaches in construction (e.g., potential application areas, development method, and difficulties) are outlined and further analysed.
               ",autonomous vehicle
10.1016/B978-0-12-820028-5.00010-2,filtered,Smart Manufacturing,sciencedirect,2020-12-31,sciencedirect,Chapter 10: Smart manufacturing in industrial gas production: A digital transformation,https://api.elsevier.com/content/article/pii/B9780128200285000102,"
               This chapter shows, from the experience of Air Liquide in its digital transformation through the development and implementation of its Smart Innovative Operations (SIO) program, that enterprise-wide industrial deployment of smart manufacturing solutions requires strong methodology, organization, and communication to provide the expected benefits in operational excellence (e.g., efficiency and reliability). This is true whether the smart manufacturing solution is fully internally developed, completely commercial-off-the-shelf (COTS), or a hybrid, as is the case for both SIO.Predict (anomaly detection) and SIO.Optim (mathematical programming optimization) as discussed in this chapter. Both SIO.Predict and SIO.Optim implement COTS software as a platform to both enable and be enabled by a strong internal organization within Air Liquide, including a variety of backgrounds, roles, and expertise. Such software platforms enable further innovation, including the implementation of the latest mathematical algorithms developed and demonstrated by industrial and academic researchers.
            ",autonomous vehicle
10.1016/B978-0-12-814435-0.00017-1,filtered,Internet of Things,sciencedirect,2019-12-31,sciencedirect,Chapter 5: Technology Fundamentals,https://api.elsevier.com/content/article/pii/B9780128144350000171,"
               This chapter presents an overview of technology fundamentals – the building blocks upon which the IoT rests. Here, we cover devices and gateways, personal, local and Wide Area Networking, Data Management, business processes, and cloud and analytics technologies. Devices form the physical basis of the Internet of Things and provide functions for sensing and actuating in the physical world. Local and Wide Area Networks provide these with the necessary infrastructure to connect to cloud services and associated applications. Data Management handles essential functions such as data acquisition, validation, and storage and makes sure that critical information is available at the right point, in a timely manner, and in the right form. Business processes refers to the series of steps to perform management, operational, and supporting activities for achieving specific mission objectives. XaaS is used as a general term to describe the functions provided as a service by cloud infrastructures, such as computational capacity, software, networking, and storage. Analytics are used to extract additional value from data generated by devices and enable new opportunities by using data from devices for multiple purposes, many of which may not have been imagined at the time of deployment. Knowledge Management Frameworks provide the ability to understand data-generated information and may leverage existing experiences within certain decision making contexts.
            ",autonomous vehicle
10.1016/j.neucom.2021.09.008,filtered,Neurocomputing,scopus,2021-11-20,scopus,Fast intent prediction of multi-cyclists in 3D point cloud data using deep neural networks,https://api.elsevier.com/content/abstract/scopus_id/85115024624,"
                  Inferring the intended actions of road-sharing users with autonomous ground vehicles in particularly vulnerable ones like cyclists is considered one of the tough tasks facing the wide-spread deployment of autonomous ground vehicles. One of the main reasons for that is the scarcity of the available datasets for that task due to the difficulty in obtaining those datasets in real environments. In this work, we first propose a pipeline that can synthetically produce 3D LiDAR data of cyclists hand-signalling a set of intended actions that are commonly done in real environments. Given the synthetically-produced labelled 3D LiDAR data sequences, we trained a framework that can simultaneously detect, track and give predictions about the intended actions of multi-cyclists in the scene on time. The proposed framework was evaluated using both synthetic and real data from a physical 3D LiDAR sensor. Our proposed framework has scored competitive and robust results in both synthetic and real environments with 88% in 
                        
                           
                              
                                 F
                              
                              
                                 1
                              
                           
                        
                      measure with higher frame per second rate (12.9 FPS) than the 3D LiDAR sensor frame rate (10 Hz).
               ",autonomous vehicle
10.1016/j.oceaneng.2021.109531,filtered,Ocean Engineering,scopus,2021-09-15,scopus,A remote anomaly detection system for Slocum underwater gliders,https://api.elsevier.com/content/abstract/scopus_id/85109609494,"
                  Marine Autonomous Systems (MAS) operating at sea beyond visual line of sight need to be self-reliant, as any malfunction could lead to loss or pose a risk to other sea users. In the absence of fully automated on-board control and fault detection tools, MAS are piloted and monitored by experts, resulting in high operational costs and limiting the scale of observational fleets that can be deployed simultaneously. Hence, an effective anomaly detection system is fundamental to increase fleet capacity and reliability. In this study, an on-line, remote fault detection system is developed for underwater gliders. Two alternative methods are analysed using time series data: feedforward deep neural networks estimating the glider’s vertical velocity and an autoencoder. The systems are trained using field data from four baseline deployments of Slocum gliders and tested on six deployments of vehicles suffering from adverse behaviour. The methods are able to successfully detect a range of anomalies in the near real time data streams, whilst being able to generalise to different glider configurations. The autoencoder’s error in reconstructing the original signals is the clearest indicator of anomalies. Thus, the autoencoder is a prime candidate to be included into an all-encompassing condition monitoring system for MAS.
               ",autonomous vehicle
10.1016/j.comcom.2021.06.005,filtered,Computer Communications,scopus,2021-09-01,scopus,A cost-effective trilateration-based radio localization algorithm using machine learning and sequential least-square programming optimization,https://api.elsevier.com/content/abstract/scopus_id/85107813332,"
                  Wireless communication systems play an essential role in everyday life situations and enable a wide range of location-based services to their users. The imminent adoption of 5G networks worldwide and the future establishment of next-generation wireless networks will allow various applications, such as autonomous vehicles, connected robotics, and most recently, crowd monitoring for fighting infectious diseases, such as COVID-19. In this context, radio localization techniques have become an essential tool to provide solid performance for mobile positioning systems, through increased accuracy or less computational time. With this in mind, we propose a trilateration-based approach using machine learning (ML) and sequential least-square programming (SLSQP) optimization to estimate the outdoor position of mobile terminals in cellular networks. The ML technique employed is the 
                        k
                     -nearest neighbors (
                        k
                     -NN). The optimization methods analyzed are Nelder–Mead (NM), genetic algorithms (GA), and SLSQP. Different environments (noise-free and noisy) and network scenarios (different numbers of base stations) are considered to evaluate the approaches. Numerical results indicate that the 
                        k
                     -NN/SLSQP technique has similar accuracy compared to the 
                        k
                     -NN/GA with eight generations. Both perform better than 
                        k
                     -NN/NM in all scenarios and environments. When comparing computational times, our proposal is considerably more time-efficient. Aside from that, SLSQP computational time is less affected by network scenarios with more base stations in comparison with GA. That feature is significant considering the ultra-dense base station deployment forecasted for the next-generation cellular networks.
               ",autonomous vehicle
10.1016/j.apor.2021.102590,filtered,Applied Ocean Research,scopus,2021-05-01,scopus,Adaptive and extendable control of unmanned surface vehicle formations using distributed deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85102065211,"
                  Future ocean exploration will be dominated by a large-scale deployment of marine robots such as unmanned surface vehicles (USVs). Without the involvement of human operators, USVs exploit oceans, especially the complex marine environments, in an unprecedented way with an increased mission efficiency. However, current autonomy level of USVs is still limited, and the majority of vessels are being remotely controlled. To address such an issue, artificial intelligence (AI) such as reinforcement learning can effectively equip USVs with high-level intelligence and consequently achieve full autonomous operation. Also, by adopting the concept of multi-agent intelligence, future trend of USV operations is to use them as a formation fleet. Current researches in USV formation control are largely based upon classical control theories such as PID, backstepping and model predictive control methods with the impact by using advanced AI technologies unclear. This paper, therefore, paves the way in this area by proposing a distributed deep reinforcement learning algorithm for USV formations. More importantly, using the proposed algorithm USV formations can learn two critical abilities, i.e. adaptability and extendibility that enable formations to arbitrarily increase the number of USVs or change formation shapes. The effectiveness of algorithms has been verified and validated through a number of computer-based simulations.
               ",autonomous vehicle
10.1016/j.trc.2021.103008,filtered,Transportation Research Part C: Emerging Technologies,scopus,2021-04-01,scopus,A survey on autonomous vehicle control in the era of mixed-autonomy: From physics-based to AI-guided driving policy learning,https://api.elsevier.com/content/abstract/scopus_id/85102260094,"
                  This paper serves as an introduction and overview of the potentially useful models and methodologies from artificial intelligence (AI) into the field of transportation engineering for autonomous vehicle (AV) control in the era of mixed autonomy when AVs drive alongside human-driven vehicles (HV). It is the first-of-its-kind survey paper to comprehensively review literature in both transportation engineering and AI for mixed traffic modeling. We will discuss state-of-the-art applications of AI-guided methods, identify opportunities and obstacles, and raise open questions. We divide the stage of AV deployment into four phases: the pure HVs, the HV-dominated, the AV-dominated, and the pure AVs. This paper is primarily focused on the latter three phases. Models used for each phase are summarized, encompassing game theory, deep (reinforcement) learning, and imitation learning. While reviewing the methodologies, we primarily focus on the following research questions: (1) What scalable driving policies are to control a large number of AVs in mixed traffic comprised of human drivers and uncontrollable AVs? (2) How do we estimate human driver behaviors? (3) How should the driving behavior of uncontrollable AVs be modeled in the environment? (4) How are the interactions between human drivers and autonomous vehicles characterized? We also provide a list of public datasets and simulation software related to AVs. Hopefully this paper will not only inspire our transportation community to rethink the conventional models that are developed in the data-shortage era, but also start conversations with other disciplines, in particular robotics and machine learning, to join forces towards creating a safe and efficient mixed traffic ecosystem.
               ",autonomous vehicle
10.1016/j.vehcom.2020.100314,filtered,Vehicular Communications,scopus,2021-04-01,scopus,Deep learning-based code indexed modulation for autonomous underwater vehicles systems,https://api.elsevier.com/content/abstract/scopus_id/85096481945,"
                  The Multiuser Direct Sequence Spread Spectrum (DSSS) has been proposed for the autonomous underwater vehicles (AUV) communication systems in a long transmission distance to transmit multiple users over the same channel bandwidth. Unfortunately, the DSSS data rate is limited by four users as a maximum due to the extensive multipath arrivals. This paper proposes a new scheme for the AUV communication systems called, deep learning coded index modulation-spread spectrum (DL-CIM-SS), to overcome the increasing data rate restriction of limited users number. The proposed DL-CIM-SS transmits the majority of information bits via the index of spreading code instead of transmitting all information bits physical. That doesn't only harvest more energy efficiency as the majority of information bits are not transmitted physically anymore, but also provide almost perfect detection at the receiver end. To further save the AUV energy, a pre-processing stage is added before feeding the received signal into the DL-based detector; the DL-based detector becomes environment-independent and no more training will be required during the online deployment. The proposed DL-CIM-SS performance is evaluated in this paper over simulation and measured underwater acoustic channels. The simulation results show the ability of the proposed scheme to increase the underwater acoustic data rate with significant energy efficiency improvement and low system bit and symbol error rate.
               ",autonomous vehicle
10.1016/j.ocecoaman.2020.105478,filtered,Ocean and Coastal Management,scopus,2021-02-01,scopus,Autonomous litter surveying and human activity monitoring for governance intelligence in coastal eco-cyber-physical systems,https://api.elsevier.com/content/abstract/scopus_id/85097580928,"
                  The human impact on the coastal ecosystems is a global environmental concern. Due to the growing urbanization, industrialization, and transportation, this impact on the living and non-living components of the coastal area is expected to further increase in the coming years. Artificial intelligence based automation of the coastal monitoring, including data collection, analysis and decision making, provides real-time insights and opportunities for large-scale coastal management and governance. In this paper, a framework for autonomous litter surveying and human activity monitoring for governance intelligence in coastal eco-cyber-physical systems (ecoCystem) is presented. A large dataset of more than 20,000 images focused on smart coastal management is collected to model the real world scenarios. A combination of various artificial intelligence based methods are used for automatic detection and classification of various litter in the coastal environment. Furthermore, the proposed framework is capable of autonomous monitoring of humans activities and detection of illegal entry of vehicles and boats to the beach area. The accuracy of the proposed autonomous system is 87% for correct classification of fully visible litter and 95% for fully visible vehicles. The experimental results show that the application of computer vision and machine learning for autonomous litter classification shows promising results for increasing the speed and scale of litter surveying in the coastal area. Further training of the artificial intelligence models is necessary for increasing the accuracy of the proposed framework and real-world deployment in the coastal environment. The proposed human activity monitoring system can be used for autonomous coastal law enforcement and real-time and active protection of the coastal zones.
               ",autonomous vehicle
10.1016/j.future.2020.09.001,filtered,Future Generation Computer Systems,scopus,2021-02-01,scopus,Formal approach to thwart against drone discovery attacks: A taxonomy of novel 3D obfuscation mechanisms,https://api.elsevier.com/content/abstract/scopus_id/85091758369,"
                  The pervasive capabilities and myriad of mission performance abilities of Unmanned (Combat) Aerial Vehicles (UAVs/UCAVs) have exponentially grown their deployment possibilities in the recent past. Advancements in artificial intelligence, sensing technologies and autonomous guidance, navigation and control capabilities have further fueled wide-scale deployments of UAVs, both for military and commercial applications, ranging from autonomous air taxis and cargo deliveries to intelligence surveillance, reconnaissance, and combat missions. Most of these applications consume Global Navigation Satellite System (GNSS) based location information for their services, which is also shared in real-time with ground control stations and centralized service operators, often using insecure communication channels. This limitation has significantly raised the location privacy concerns of aerial vehicles, deployed to conduct user-centric, safety-critical and localization-sensitive operations. A compromise of location privacy of a UAV can pose serious threats, including stalking, theft or damage of UAV/payload or even use of GNSS-guided munitions. These emerging threats call for robust and trust-worthy solutions for preserving the location privacy of aerial vehicles.
                  This paper proposes a novel obfuscation-based mechanism to safeguard location information against privacy attacks. Our proposed solution conceals actual information by transmitting modified location parameters, either after diluting their accuracy or by fabricating deceptive trajectories for a known eavesdropper. Based on these two broad categories, defined as Attenuation and Deception-based obfuscation techniques respectively, we also present a novel taxonomy of 3D obfuscation mechanisms, supported by formal descriptions of underlying operators. The operators can be used independently or in conjunction to satisfy diverse mission-specific obfuscation profiles. The proposed operators have been practically implemented and evaluated using a customizable obfuscator deployed over a Global Positioning System (GPS) guided UAV. The field experiments validate the efficacy, security and deployability of the proposed solution against location-privacy threats.
               ",autonomous vehicle
10.1016/j.vehcom.2021.100399,filtered,Vehicular Communications,scopus,2021-01-01,scopus,"Vehicular intelligence in 6G: Networking, communications, and computing",https://api.elsevier.com/content/abstract/scopus_id/85114394668,"
                  With the deployment of 5G, researchers and experts begin to look forward to 6G. They predict that 6G will be the key driving force for information interaction and social life after 2030. With the help of artificial intelligence (AI), 6G will be a highly autonomous closed-loop network, and will make up for 5G's shortcomings in communications, computing and global coverage, achieving “AI of things (AIoT)”. In 6G life, vehicles may become another indispensable devices for people besides smartphones, and non-polluting, highly safe as well as full-autonomous vehicles will be the goal of vehicular development. In order to ensure the safe driving of future vehicles and meet the entertainment needs of passengers, it is necessary to investigate future 6G vehicular intelligence. In this paper, we will discuss its networking, communications, computing and intelligence, look into future technological developments and applications, and identify forthcoming challenges and research directions.
               ",autonomous vehicle
10.1016/j.image.2020.115969,filtered,Signal Processing: Image Communication,scopus,2020-10-01,scopus,Re-identification framework for long term visual object tracking based on object detection and classification,https://api.elsevier.com/content/abstract/scopus_id/85089267326,"
                  In this paper, we address the problem of long-term visual object tracking and we present an efficient real-time single object tracking system suitable for integration in autonomous platforms that need to encompass intelligent capabilities. We propose a novel long-term tracking framework for classification based re-detection and tracking, that incorporates state estimation, object re-identification and automated management of tracking and detection results. Our method integrates a novel object re-identification technique which efficiently filters a number of detection candidates and systematically corrects the tracking results. Through extensive experimental validation on the UAV123, UAV20L and TLP datasets, we demonstrate the effectiveness of the proposed system and its advantage over several state-of-the art trackers. The results furthermore highlight the proposed tracker’s ability to handle challenges arising from real-world and long-term scenarios, such as variations in pose, scale, occlusions and out-of-view situations. Furthermore, we propose a variant that is suitable for deployment on autonomous robots, such as Unmanned Aerial Vehicles.
               ",autonomous vehicle
10.1016/j.sysarc.2020.101835,filtered,Journal of Systems Architecture,scopus,2020-10-01,scopus,MBBNet: An edge IoT computing-based traffic light detection solution for autonomous bus,https://api.elsevier.com/content/abstract/scopus_id/85087859478,"
                  Traffic light detection is a key module in the autonomous driving system to enhance the interactions between drivers and unmanned vehicles. In recent studies, deep neural networks are widely used for traffic light detection and resource/power consumption is a major concern for model deployment in vehicular edge devices. This paper proposes a novel light-weight deep CNN model that integrates the multi-backbone of state-of-the-art architectures for the self-driving traffic light detection. The MBBNet (Multi-BackBone Network) consists of three common convolutional backbones, i.e., the normal, residual and highway (DenseNet) convolutional modules. Simple ensemble of those backbones may incur high computational load. Therefore, channel compression is adopted to control the model parameters, while guaranteeing the accuracy for mobile and embedded hardware. Evaluation of a dataset collected from real road conditions demonstrate the robustness of our detection system, and it achieves higher accuracy (accuracy > 0.94 and 
                        
                           A
                           v
                           e
                           r
                           a
                           g
                           e
                           _
                           I
                           O
                           U
                           >
                           74.05
                           %
                        
                     ) for self-driving buses. In terms of resource consumption, the trained model size is 1.35 MB, and can process high-resolution images (1280 × 960) at 14 FPS (frames per second) on low-power edge devices.
               ",autonomous vehicle
10.1016/j.engappai.2020.103799,filtered,Engineering Applications of Artificial Intelligence,scopus,2020-09-01,scopus,Trajectory based lateral control: A Reinforcement Learning case study,https://api.elsevier.com/content/abstract/scopus_id/85087950678,"
                  Reinforcement Learning (RL) has been employed in many applications of robotics and has steadily been gaining traction in the field of Autonomous Driving (AD). This paper proposes a Deep Reinforcement Learning based approach for lateral Vehicle Motion Control (VMC), and explores the generalization capabilities of the approach. The proposed methodology uses a sequence of waypoints generated from a planning module of an AD stack as the input. The network has been trained to predict accurate steering commands to follow the given trajectory. In this paper we detail our implementation and share our learning experience on real-vehicle deployment of the RL based controller. Our experiments yield promising results with an agent trained on less than 4 h of simulated driving experience without any real-world data. The trained agent is able to successfully complete unseen and more complex tracks using different unseen vehicle models. The agent safely reached up to 150km/h in simulation and up to 60km/h in a real-life Sport Utility Vehicle (SUV) weighing more than 2000kg.
               ",autonomous vehicle
10.1016/j.comcom.2020.02.065,filtered,Computer Communications,scopus,2020-03-15,scopus,Amateur Drones Detection: A machine learning approach utilizing the acoustic signals in the presence of strong interference,https://api.elsevier.com/content/abstract/scopus_id/85080874387,"
                  Owing to small size, sensing capabilities and autonomous nature, the Unmanned Air Vehicles (UAVs) have enormous applications in various areas e.g., remote sensing, navigation, archaeology, journalism, environmental science, and agriculture. However, the un-monitored deployment of UAVs called the amateur drones (AmDr) can lead to serious security threats and risk to human life and infrastructure. Therefore, timely detection of the AmDr is essential for the protection and security of sensitive organizations, human life and other vital infrastructure. AmDrs can be detected using different techniques based on sound, video, thermal, and radio frequencies. However, the performance of these techniques is limited in sever atmospheric conditions. In this paper, we propose an efficient un-supervise machine learning approach of independent component analysis (ICA) to detect various acoustic signals i.e., sounds of bird, airplanes, thunderstorm, rain, wind and the UAVs in practical scenario. After unmixing the signals, the features like Mel Frequency Cepstral Coefficients (MFCC), the power spectral density (PSD) and the Root Mean Square Value (RMS) of the PSD are extracted by using ICA. The PSD and the RMS of PSD signals are extracted by first passing the signals from octave band filter banks. Based on the above features the signals are classified using Support Vector Machines (SVM)and K Nearest Neighbour (KNN)to detect the presence or absence of AmDr. Unique feature of the proposed technique is the detection of a single or multiple AmDrs at a time in the presence of multiple acoustic interfering signals. The proposed technique is verified through extensive simulations and it is observed that the RMS values of PSD with KNN performs better than the MFCC with KNN and SVM.
               ",autonomous vehicle
10.1016/j.imavis.2020.103889,filtered,Image and Vision Computing,scopus,2020-03-01,scopus,Unsupervised domain adaptation for mobile semantic segmentation based on cycle consistency and feature alignment,https://api.elsevier.com/content/abstract/scopus_id/85079673578,"
                  The supervised training of deep networks for semantic segmentation requires a huge amount of labeled real world data. To solve this issue, a commonly exploited workaround is to use synthetic data for training, but deep networks show a critical performance drop when analyzing data with slightly different statistical properties with respect to the training set. In this work, we propose a novel Unsupervised Domain Adaptation (UDA) strategy to address the domain shift issue between real world and synthetic representations. An adversarial model, based on the cycle consistency framework, performs the mapping between the synthetic and real domain. The data is then fed to a MobileNet-v2 architecture that performs the semantic segmentation task. An additional couple of discriminators, working at the feature level of the MobileNet-v2, allows to better align the features of the two domain distributions and to further improve the performance. Finally, the consistency of the semantic maps is exploited. After an initial supervised training on synthetic data, the whole UDA architecture is trained end-to-end considering all its components at once. Experimental results show how the proposed strategy is able to obtain impressive performance in adapting a segmentation network trained on synthetic data to real world scenarios. The usage of the lightweight MobileNet-v2 architecture allows its deployment on devices with limited computational resources as the ones employed in autonomous vehicles.
               ",autonomous vehicle
10.1016/j.jsr.2019.12.025,filtered,Journal of Safety Research,scopus,2020-02-01,scopus,Are parents ready to use autonomous vehicles to transport children? Concerns and safety features,https://api.elsevier.com/content/abstract/scopus_id/85078852184,"
                  
                     Introduction: This study addressed a gap in the literature – the potential of using autonomous vehicles (AV) to enhance children’s mobility. Prior studies documented the perceived benefits and concerns about this prospect, but did not examine the features in AV and support mechanisms that are desired by potential users. Method: An on-line survey was used to collect public opinions within the United States. In the survey, willingness to use AVs for this use case was asked twice to assess if participants changed their mind after being asked about concerns related to this prospect and importance of car features. A combination of statistical and machine-learning methods were used to profile individuals with high versus low post-willingness and to identify variables that differentiated the two groups. Results: Results indicated that respondents who were lower on their post-willingness to use AVs to transport children were more concerned about how AVs would protect children, how someone could harm the children inside, and whether there would be someone at the destination. In addition, they were less in favor of technology, older in age, and rated car features such as having a designated adult waiting at destination, a camera, and a microphone as relatively required (as opposed to optional). These results highlight potential users’ needs and requirements as they think about AVs in the context of parent–children mobility practices. Practical Applications: Relevant stakeholders should develop deployment and implementation plans while taking into account ridership contexts and vulnerable road users who can benefit from enhanced mobility.
               ",autonomous vehicle
10.1016/j.dsr.2019.103136,filtered,Deep-Sea Research Part I: Oceanographic Research Papers,scopus,2019-11-01,scopus,"DEEPi: A miniaturized, robust, and economical camera and computer system for deep-sea exploration: A miniaturized deep-sea camera system",https://api.elsevier.com/content/abstract/scopus_id/85074531989,"
                  Cameras are essential components to almost every underwater vehicle including ROV's, AUV's, manned submersibles, ocean observatories, and baited remote underwater video systems (BRUVs). Deep-sea cameras are traditionally expensive components, and are almost exclusively fabricated as 1-atm pressure housings made of aluminum, stainless steel or titanium, combined with custom-made optical viewports. In autonomous recording systems such as BRUVs and biologging animal tags, camera size and form factor directly influences the physical design of the entire system and limits the operational endurance. In this paper, we describe a novel design for DEEPi, a deep-sea imaging and control system based on the Raspberry Pi family of single-board computers. The DEEPi camera is an extremely compact remote head unit (~16 ml volume), can operate to depths of at least 5500 m, and uses a photopolymer 3D-printed shell partially filled with epoxy as a pressure housing. A flat polished borosilicate glass disc serves as the optical viewport, and protects the lens assembly from pressure and water intrusion. The control computer is completely potted in epoxy, and is accessible through a wifi connection. The DEEPi system is described in detail, along with example imagery from deep-sea deployments to depths of up to 1096 m.
               ",autonomous vehicle
10.1016/j.aap.2019.04.006,filtered,Accident Analysis and Prevention,scopus,2019-07-01,scopus,Development and validation of a questionnaire to assess public receptivity toward autonomous vehicles and its relation with the traffic safety climate in China,https://api.elsevier.com/content/abstract/scopus_id/85064150442,"
                  The advent of autonomous vehicles (AVs) has gained increasing attention in China. Although auto manufacturers and innovators have attempted to confirm that AVs are safe and have introduced them on public roads, it is vital to understand end-users’ acceptance of AVs. A total of 1453 participants voluntarily and validly completed a series of questionnaires. The questionnaires included the Autonomous Vehicle Acceptability Scale (AVAS), the Traffic Climate Scale (TCS), and sociodemographic variables. The satisfactory internal consistency reliability and construct validity revealed that the newly developed Chinese version of the AVAS is a suitable tool to measure public acceptance of AVs. Moreover, exploratory factor analysis and confirmatory factor analysis conformed to the four factors of AVAS, including benefits in usefulness (BIU), benefits in situations (BIS), concern scenarios (CS) and system concern (SC). Scores higher on benefits and lower on concerns represent more acceptance of AVs. In addition, we found that the public’s perceived local traffic safety climate affected the attitude toward AVs. More specifically, external affective demands (EAD) were found to be a significant predictor of SC, internal requirements (IR) were shown to have an effect on BIS and CS, and functionality was found to be a significant predictor of BIU and SC. Furthermore, the differences between drivers and non-drivers revealed that drivers were concerned significantly less about AVs and regarded AVs as more useful than non-drivers did. To gain more customers for the purchase of AVs, it is necessary for automotive vehicle manufacturers and retailers to introduce and advertise the functions and usability of autonomous driving systems to the public. Gaining acceptance from end users and understanding the factors that affect acceptability will be critical to the widespread deployment of AVs.
               ",autonomous vehicle
10.23919/ACC50511.2021.9482827,filtered,2021 American Control Conference (ACC),IEEE,2021-05-28 00:00:00,ieeexplore,A Learning-Based Automatic Parameters Tuning Framework for Autonomous Vehicle Control in Large Scale System Deployment,https://ieeexplore.ieee.org/document/9482827/,"This paper presents the design of an automatic (human-out-of-the-loop) control parameters tuning framework, aiming at accelerating large scale autonomous driving system deployed on various vehicles and driving environments. The framework consists of three machine-learning-based procedures, which jointly automate the control parameter tuning for autonomous driving, including: a learning-based dynamic modeling procedure, to enable the control-in-the-loop simulation with highly accurate vehicle dynamics for parameter tuning; a learning-based open-loop mapping procedure, to solve the feedforward control parameters tuning; and more significantly, a Bayesian-optimization-based closed-loop parameter tuning procedure, to automatically tune feedback control (PID, LQR, MRAC, MPC, etc.) parameters in simulation environment. The paper shows an improvement in control performance with a significant increase in parameter tuning efficiency, in both simulation and road tests. This framework has been validated on different vehicles in US and China.",autonomous vehicle
10.1109/B-HTC50970.2020.9297995,filtered,2020 IEEE Bangalore Humanitarian Technology Conference (B-HTC),IEEE,2020-10-10 00:00:00,ieeexplore,AI-NAAV: An AI enabled Neurocognition Aware Autonomous Vehicle,https://ieeexplore.ieee.org/document/9297995/,"Smart cars or Autonomous Vehicles (AV), capable of replicating human cognitive behaviour supported with a digital autopilot, shall make better drivers than humans in the near future. Driving in a complex and competitive environment is a challenging task. Driver health monitoring serves to be a pivotal contributor to autonomous driving. The human factors, including cognitive, psychomotor and physiological abilities, should be continuously monitored in an autonomous vehicle. On the road, neurocognitive impairments are very often reported, where the driver suffers a stroke or heart attack or unconsciousness and is incapacitated from driving. In this paper, we present AI-NAAV (AI enabled Neurocognition Aware Autonomous Vehicle), a deep learning assisted AI-empowered autonomous vehicle, which has the combined capabilities of a) detecting impaired driving capabilities in the driver b) shift to autopilot mode and hence enabling a safe drive. AI-NAAV is simulated on CARLA platform. The exteroceptive sensor combinations used for surround view, blind spot detection, rear collision warning and parking assistance, are used in a complementary mode for a safe drive on autopilot. The paper discusses the sensors deployed, methodologies and the results from simulations that perform an accurate transition of autonomy from Level 0 to Level 5, as defined in SAE (Society of Automotive Engineers).",autonomous vehicle
10.1109/TITS.2020.3009223,filtered,IEEE Transactions on Intelligent Transportation Systems,IEEE,2021-07-01 00:00:00,ieeexplore,Deep Learning Based Autonomous Vehicle Super Resolution DOA Estimation for Safety Driving,https://ieeexplore.ieee.org/document/9173575/,"In this paper, a novel system architecture including a massive multi-input multi-output (MIMO) or a reconfigurable intelligent surface (RIS) and multiple autonomous vehicles is considered in vehicle location systems. The location parameters of autonomous vehicles can be estimated based on the deep unfolding technique, which is a recent advance of deep learning. Traditional vehicle location methods such as the global position system (GPS) can only locate the target vehicles with relatively low accuracy. The super resolution cannot be achieved when two vehicles are too close, which means that the safety incidents exist when autonomous vehicles are deployed in future intelligent transportation systems (ITS). Different from the existing massive MIMO or RIS equipped with a regular array such as uniform rectangular array (URA) and uniform circular array (UCA), we exploit a massive MIMO or a RIS equipped with a conformal array extended from traditional regular array. First, the rotation from the global coordinate system to the local coordinate system is achieved based on geometric algebra. Second, 2D-DOA estimation of autonomous vehicles is modeled as a novel block sparse recovery problem. Third, the deep network architecture SBLNet is implemented to learn the nonlinear characteristic from the DOAs of autonomous vehicles and the data received by massive MIMOs or RISs. The 2D-DOA and polarization parameters can be estimated based on SBLNet with relatively low computational complexity. Simulation results demonstrate that SBLNet performs better than the state-of-the-art methods in terms of estimation accuracy and successful probability. The SBLNet is also suitable for the practical scenario considering fast moving autonomous vehicles, while, the traditional block sparse recovery methods fail in this complex scenario.",autonomous vehicle
10.1109/ICVES.2019.8906442,filtered,2019 IEEE International Conference on Vehicular Electronics and Safety (ICVES),IEEE,2019-09-06 00:00:00,ieeexplore,Autonomous Embedded System Enabled 3-D Object Detector: (with Point Cloud and Camera),https://ieeexplore.ieee.org/document/8906442/,"An Autonomous vehicle or present day smart vehicle is equipped with several ADAS safety features such as Blind Spot Detection, Forward Collision Warning, Lane Departure and Parking Assistance, Surround View System, Vehicular communication System. Recent research utilize deep learning algorithms as a counterfeit for these traditional methods, using optimal sensors. This paper discusses the perception tasks related to autonomous vehicle, specifically the computer-vision approach of 3D object detection and thus proposes a model compatible with embedded system using the RTMaps framework. The proposed model is based on the sensors: camera and Lidar connected to an autonomous embedded system, providing the sensed inputs to the deep learning classifier which on the basis of theses inputs estimates the position and predicts a 3-d bounding box on the physical objects. The Frustum PointNet a contemporary architecture for 3-D object detection is used as base model and is implemented with extended functionality. The architecture is trained and tested on the KITTI dataset and is discussed with the competitive validation precision and accuracy. The Presented model is deployed on the Bluebox 2.0 platform with the RTMaps Embedded framework.",autonomous vehicle
10.1109/ITSC48978.2021.9564566,filtered,2021 IEEE International Intelligent Transportation Systems Conference (ITSC),IEEE,2021-09-22 00:00:00,ieeexplore,Continual Unsupervised Domain Adaptation for Semantic Segmentation by Online Frequency Domain Style Transfer,https://ieeexplore.ieee.org/document/9564566/,"When deep neural networks are deployed in a highly automated vehicle for environment perception tasks in an unseen (target) domain that differs from the training (source) domain, the mismatch will result in decreased performance. Domain adaptation methods aim at overcoming this mismatch. Many recently investigated methods for unsupervised domain adaptation train a model using labeled source data and unlabeled target data at the same time. These methods assume that data from the target domain is available during the source domain training, which is not always the case in real applications. In this paper we present a way to perform an online style transfer for continual domain adaptation which improves performance on (multiple) unseen target domains using a given perception model. The approach is based on an image style transfer in the frequency domain and requires neither an adjustment of the given source-trained model parameters to the target domain, nor does it require any considerable amount of memory for storing its frequency domain representation of the source domain style, which is particularly important considering the hardware limitations in an autonomous vehicle.",autonomous vehicle
10.1109/CVPRW.2018.00196,filtered,2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),IEEE,2018-06-22 00:00:00,ieeexplore,Convolutional Social Pooling for Vehicle Trajectory Prediction,https://ieeexplore.ieee.org/document/8575356/,"Forecasting the motion of surrounding vehicles is a critical ability for an autonomous vehicle deployed in complex traffic. Motion of all vehicles in a scene is governed by the traffic context, i.e., the motion and relative spatial configuration of neighboring vehicles. In this paper we propose an LSTM encoder-decoder model that uses convolutional social pooling as an improvement to social pooling layers for robustly learning interdependencies in vehicle motion. Additionally, our model outputs a multi-modal predictive distribution over future trajectories based on maneuver classes. We evaluate our model using the publicly available NGSIM US-101 and I-80 datasets. Our results show improvement over the state of the art in terms of RMS values of prediction error and negative log-likelihoods of true future trajectories under the model's predictive distribution. We also present a qualitative analysis of the model's predicted distributions for various traffic scenarios.",autonomous vehicle
10.1109/CCWC.2019.8666562,filtered,2019 IEEE 9th Annual Computing and Communication Workshop and Conference (CCWC),IEEE,2019-01-09 00:00:00,ieeexplore,Embedded System Enabled Vehicle Collision Detection: An ANN Classifier,https://ieeexplore.ieee.org/document/8666562/,"An Autonomous vehicle depends on the combination of latest technology or ADAS safety features such as Adaptive cruise control (ACC), Autonomous Emergency Braking (AEB), Automatic Parking, Blind Spot Monitor, Forward Collision Warning /Avoidance (FCW or FCA). The current trend follows incorporation of these technologies using the Artificial neural network or Deep neural network, as an imitation of the traditionally used algorithms. The concept behind a FCW algorithm is the measure of a distance or warning range which results in an alert to notify or inform the driver regarding the possible collision. The objective of this paper is to propose a collision warning model using the RTMaps framework. The proposed model is based on the forward facing automotive radar providing the sensed input values such as acceleration, velocity, and separation distance to a neural network based classifier algorithm which on the basis of supervised learning alerts the driver of a possible collision. The implementation, precision and accuracy of the classifier and regression algorithm is discussed and compared. The presented model is deployed on the Bluebox 2.0 platform with the RTMaps Embedded framework.",autonomous vehicle
10.1109/ICMLANT50963.2020.9355992,filtered,2020 IEEE International Conference on Machine Learning and Applied Network Technologies (ICMLANT),IEEE,2020-12-21 00:00:00,ieeexplore,Estimation of Collision Priority on Traffic Videos using Deep Learning,https://ieeexplore.ieee.org/document/9355992/,"With the advancement in technology, autonomous vehicles will have a great impact on the near future and share the road space with human beings. For ensuring safer navigation, a robust collision mitigation system becomes mandatory which in general is deployed with multi-modal approaches. In this paper, a novel heuristic unimodal approach based on the vision system is presented to estimate the collision priority of vehicles on road. The priorities are estimated from the perspective of an ego vehicle that may be equipped with a vision based driver-assist system or a fully autonomous vehicle. Crowd-sourced videos from YouTube involving vehicular collisions captured by the dashboard camera of vehicles are considered. To detect the moving vehicles in the video, a deep learning-based pre-trained object detection model and a tracking algorithm are used. From the bounding box output, an estimate of collision priority of detected vehicles concerning the ego vehicle is obtained using an empirical heuristic-based approach. A simpler collision warning and navigation suggestion is also incorporated as a credible advanced driver assistance system element. The proposed qualitative approach performs well for input videos and a more robust estimate can be achieved by combining with other quantitative semantics of traffic parameters.",autonomous vehicle
10.1109/IROS.2018.8593725,filtered,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),IEEE,2018-10-05 00:00:00,ieeexplore,Game-Theoretic Cooperative Lane Changing Using Data-Driven Models,https://ieeexplore.ieee.org/document/8593725/,"Self-driving vehicles are being increasingly deployed in the wild. One of the most important next hurdles for autonomous driving is how such vehicles will optimally interact with one another and with their surroundings. In this paper, we consider the lane changing problem that is fundamental to road-bound multi-vehicle systems, and approach it through a combination of deep reinforcement learning (DRL) and game theory. We introduce a proactive-passive lane changing framework and formulate the lane changing problem as a Markov game between the proactive and passive vehicles. Based on different approaches to carry out DRL to solve the Markov game, we propose an asynchronous lane changing scheme as in a single-agent RL setting and a synchronous cooperative lane changing scheme that takes into consideration the adaptive behavior of the other vehicle in a vehicle's decision. Experimental results show that the synchronous scheme can effectively create and find proper merging moment after sufficient training. The framework and solution developed here demonstrate the potential of using reinforcement learning to solve multi-agent autonomous vehicle tasks such as the lane changing as they are formulated as Markov games.",autonomous vehicle
10.1109/CEC.2014.6900345,filtered,2014 IEEE Congress on Evolutionary Computation (CEC),IEEE,2014-07-11 00:00:00,ieeexplore,Online generation of trajectories for autonomous vehicles using a multi-agent system,https://ieeexplore.ieee.org/document/6900345/,"Autonomous vehicles are frequently deployed in environments where only certain trajectories are feasible. Classical trajectory generation methods attempt to find a feasible trajectory that satisfies a set of constraints. In some cases the optimal trajectory may be known, but it is hidden from the autonomous vehicle. Under such circumstance the vehicle must discover a feasible trajectory. This paper describes a multi-agent system that uses a combination of reinforcement learning and differential evolution to generate a trajectory that is ε-close to a target trajectory that is hidden.",autonomous vehicle
10.1109/NAECON46414.2019.9057988,filtered,2019 IEEE National Aerospace and Electronics Conference (NAECON),IEEE,2019-07-19 00:00:00,ieeexplore,Real-Time 3-D Segmentation on An Autonomous Embedded System: using Point Cloud and Camera,https://ieeexplore.ieee.org/document/9057988/,"Present day autonomous vehicle relies on several sensor technologies for it's autonomous functionality. The sensors based on their type and mounted-location on the vehicle, can be categorized as: line of sight and non-line of sight sensors and are responsible for the different level of autonomy. These line of sight sensors are used for the execution of actions related to localization, object detection and the complete environment understanding. The surrounding or environment understanding for an autonomous vehicle can be achieved by segmentation. Several traditional and deep learning related techniques providing semantic segmentation for an input from camera is already available, however with the advancement in the computing processor, the progression is on developing the deep learning application replacing traditional methods. This paper presents an approach to combine the input of camera and lidar for semantic segmentation purpose. The proposed model for outdoor scene segmentation is based on the frustum pointnet, and ResNet which utilizes the 3d point cloud and camera input for the 3d bounding box prediction across the moving and non-moving object and thus finally recognizing and understanding the scenario at the point-cloud or pixel level. For real time application the model is deployed on the RTMaps framework with Bluebox (an embedded platform for autonomous vehicle). The proposed architecture is trained with the CITYScpaes and the KITTI dataset.",autonomous vehicle
10.1109/ICEECCOT46775.2019.9114762,filtered,"2019 4th International Conference on Electrical, Electronics, Communication, Computer Technologies and Optimization Techniques (ICEECCOT)",IEEE,2019-12-14 00:00:00,ieeexplore,UNISol- Unmanned Network-based Intelligent Soldier,https://ieeexplore.ieee.org/document/9114762/,"In the constant effort to protect our country against enemy attacks, the human lives are always at stake. To make this a thing of the past, autonomous systems are gaining a name to perform `human-like' tasks. UNISol (Unmanned Network based Intelligent Solider) is an autonomous vehicle that can be deployed into war fields where it can replace the soldier's life to perform operations. The proposed system can identify and track a threat and take the necessary precautions as supervised by military personnel. UNISol uses Deep learning techniques for object detection and tracking, the identified threats are also reported back to the personnel using a secure wireless connection. The system can also be controlled and managed by the personnel and they can send the commands from the UI.",autonomous vehicle
10.1109/WACV45572.2020.9093332,filtered,2020 IEEE Winter Conference on Applications of Computer Vision (WACV),IEEE,2020-03-05 00:00:00,ieeexplore,Uncertainty-aware Short-term Motion Prediction of Traffic Actors for Autonomous Driving,https://ieeexplore.ieee.org/document/9093332/,"We address one of the crucial aspects necessary for safe and efficient operations of autonomous vehicles, namely predicting future state of traffic actors in the autonomous vehicle's surroundings. We introduce a deep learning-based approach that takes into account a current world state and produces raster images of each actor's vicinity. The rasters are then used as inputs to deep convolutional models to infer future movement of actors while also accounting for and capturing inherent uncertainty of the prediction task. Extensive experiments on real-world data strongly suggest benefits of the proposed approach. Moreover, following successful tests the system was deployed to a fleet of autonomous vehicles.",autonomous vehicle
10.1109/IWCMC51323.2021.9498581,filtered,2021 International Wireless Communications and Mobile Computing (IWCMC),IEEE,2021-07-02 00:00:00,ieeexplore,Integration of Motion Prediction with End-to-end Latent RL for Self-Driving Vehicles,https://ieeexplore.ieee.org/document/9498581/,"The field of self-driving vehicles (SDVs) is going viral among researchers from a broad spectrum of specialties. SDVs are expected to have profound impacts on the world once fully developed and deployed on roads. Hence, researchers are working assiduously together to accomplish this project. In this paper, we propose integrating motion prediction with sequential latent maximum entropy reinforcement learning, end-to-end, to train an agent to navigate autonomously in a simulated urban environment. The fusion of motion prediction for surrounding vehicles enhances traffic efficiency and safety. A novel network specialized in joint perception and motion prediction, named MotionNet, is selected in our paper to supply us with motion predictions. Our proposed system demonstrates that adding motion prediction enhances performance even further. Furthermore, our system relies merely on LIDAR sensor. CARLA simulator is used to conduct our experiments and extract outcomes.",autonomous vehicle
10.1109/IV47402.2020.9304778,filtered,2020 IEEE Intelligent Vehicles Symposium (IV),IEEE,2020-11-13 00:00:00,ieeexplore,"Autonomous Driving Vehicle Control Auto-Calibration System: An Industry-Level, Data-Driven and Learning-based Vehicle Longitudinal Dynamic Calibrating Algorithm",https://ieeexplore.ieee.org/document/9304778/,"The control module is a crucial part for autonomous driving systems, a typical control algorithm often requires vehicle dynamics (such as longitudinal dynamics) as inputs, which, unfortunately are difficult to calibrate in real time. Further, it is also a challenge to reflect instantaneous changes in longitudinal dynamics (e.g. load changes) using a calibration table. As a result, control performance may deteriorate when load changes considerably (especially for small cargoes). In this paper, we will show how we build a data-driven longitudinal calibration procedure using machine learning techniques to adapt load changes in real time. We first generated offline calibration tables from human driving data. The offline table serves as an initial guess for later uses, and it only requires twenty minutes of data collection and processing. We then used an online learning algorithm to appropriately update the initial table (the offline table) based on real-time performance analysis. Experiments indicated (a) offline auto-calibration leads to a better control accuracy, compared with manual calibration; (b) online auto-calibration is capable to handle load changes and significantly reduce real time control error. This system has been deployed to more than one hundred Baidu self-driving vehicles (both hybrid and electronic vehicles) since April 2018. By January 2019, the system had been tested for more than 2,000 hours and over 10,000 kilometers (6,213 miles) and was still proven to be effective.",autonomous vehicle
10.1109/CDC40024.2019.9029916,filtered,2019 IEEE 58th Conference on Decision and Control (CDC),IEEE,2019-12-13 00:00:00,ieeexplore,From self-tuning regulators to reinforcement learning and back again,https://ieeexplore.ieee.org/document/9029916/,"Machine and reinforcement learning (RL) are increasingly being applied to plan and control the behavior of autonomous systems interacting with the physical world. Examples include self-driving vehicles, distributed sensor networks, and agile robots. However, when machine learning is to be applied in these new settings, the algorithms had better come with the same type of reliability, robustness, and safety bounds that are hallmarks of control theory, or failures could be catastrophic. Thus, as learning algorithms are increasingly and more aggressively deployed in safety critical settings, it is imperative that control theorists join the conversation. The goal of this tutorial paper is to provide a starting point for control theorists wishing to work on learning related problems, by covering recent advances bridging learning and control theory, and by placing these results within an appropriate historical context of system identification and adaptive control.",autonomous vehicle
10.1109/ICSSE52999.2021.9538460,filtered,2021 International Conference on System Science and Engineering (ICSSE),IEEE,2021-08-28 00:00:00,ieeexplore,Steering Angle Estimation for Self-driving Car Based on Enhanced Semantic Segmentation,https://ieeexplore.ieee.org/document/9538460/,"Common approaches for semantic segmentation using Convolutional Neural Networks (CNN) based around conventional U-shapes architectures were widely used. However, failures to retrieve global context information and memory issues made such models unable to compete against modern architectures considering accuracy and real-time capability. In this paper, an efficient method maintaining equivalent accuracy of a previous segmentation network and skillfully making a model more light-weighted for real-time inference was proposed. More concretely, we managed to alleviate five out of 17 million trainable parameters, which effectively reduce the amount of computation of the original PSPNet by 30% using the backbone of CSPNet. Our proposed network implementation achieved 73 mIoU scores on our custom dataset and reached 15 fps regarding real-time inference. We deployed the trained model on the multifunctional hardware and then connected it to a golf car to jointly navigate the natural environment and traffic sign detection task. Accordingly, the STM32 board and servo motor were used for controlling the steering wheel through a track-and-wheel drive system. As for the traffic sign detection task, we employed a small-size Yolov5 trained on the TT100K dataset running around 60fps and attained real-time performance with sufficient accuracy.",autonomous vehicle
10.1109/ICCE-Berlin.2018.8576190,filtered,2018 IEEE 8th International Conference on Consumer Electronics - Berlin (ICCE-Berlin),IEEE,2018-09-05 00:00:00,ieeexplore,End to End Learning based Self-Driving using JacintoNet,https://ieeexplore.ieee.org/document/8576190/,"Automated driving functions, like highway driving and parking assist, are getting increasing deployed in high-end cars with the trend moving towards the self-driving car. With the advent of deep learning, many traditional computer vision techniques have been replaced by deep convolutional neural networks (CNN). End to end learning is one of the paradigm for self-driving, in which user provides a input images from the front facing camera to the given neural network and the network outputs the car control signals such as throttle, steering and braking. The paper proposes an embedded friendly convolutional neural network, `Jacintonet', to demonstrate self-driving using end to end learning paradigm in a virtual simulation environment. Paper discusses key learning during the training methodology and presents the results on embedded platform. Texas Instruments (TI) TDA2x System on Chip (SoC) is used as embedded platform for running `Jacintonet', real-time to demonstrate self-driving car in the virtual simulator.",autonomous vehicle
10.1109/IVS.2019.8813870,filtered,2019 IEEE Intelligent Vehicles Symposium (IV),IEEE,2019-06-12 00:00:00,ieeexplore,A Cloud-Based AI Framework for Machine Learning Orchestration: A “Driving or Not-Driving” Case-Study for Self-Driving Cars,https://ieeexplore.ieee.org/document/8813870/,"Self-driving cars rely on a plethora of algorithms in order to perform safe driving manoeuvres. Training those models is expensive (e.g. hardware cost, storage, energy) and requires continuous updates. This paper proposes a cloud-based framework for continuous training of self-driving AI models. In addition to training standalone models, the framework is capable of leveraging pre-trained models in expediting the training on environment changes (e.g. new driver or new car model). As use-case, this paper focuses on a driver's behaviour while the vehicle's control is being transferred between the driver and the self-driving AI. A human driver can hand over the control of a vehicle's driving tasks to an automated system, when that system's confidence level is high enough. Reciprocally, there are situations where that control has to be handed back to the human driver. This paper proposes a novel real-time system for Driving Not-Driving (DND) detection, which is able to capture the ability of the driver to re-take control of a vehicle when the automated driving system transitions from a higher to a lower level of automation (e.g. L3 to L2 vehicle automation). We are using a computer vision-based Driver Monitoring System (DMS) that captures in real-time head and eye movements. These are captured in the car and transferred to the cloud where a DND model is trained for a specific driver. The DND classification model is deployed in the vehicle and predicts if the driver is ready or not to resume control at a given time. The cloud-based framework proposed in this paper shows an end-to-end cycle of collecting, training and deploying self-driving AI technology, with the additional features of continuous and transfer learning.",autonomous vehicle
10.1109/IROS45743.2020.9341122,filtered,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),IEEE,2021-01-24 00:00:00,ieeexplore,ReachFlow: An Online Safety Assurance Framework for Waypoint-Following of Self-driving Cars,https://ieeexplore.ieee.org/document/9341122/,"Learning-enabled components have been widely deployed in autonomous systems. However, due to the weak interpretability and the prohibitively high complexity of large-scale machine learning models such as neural networks, reliability has been a crucial concern for safety-critical autonomous systems. This work proposes an online monitor called Reach-Flow for fault prevention of waypoint-following tasks for self-driving cars. It mainly consists of two components: (a) an online verification tool which conservatively checks the safety of the system behavior in the near future, and (b) a fallback controller which steers the system back to a desired state when the system is potentially unsafe. We implement ReachFlow in a self-driving racing car governed by a reinforcement learning-based controller. We demonstrate the effectiveness by rigorously verifying a safe waypoint-following control and providing a fallback control for an unsafe situation in which a large deviation from the planned path is predicted.",autonomous vehicle
10.1109/DDECS52668.2021.9417059,filtered,2021 24th International Symposium on Design and Diagnostics of Electronic Circuits & Systems (DDECS),IEEE,2021-04-09 00:00:00,ieeexplore,A Model-Based Framework to Assess the Reliability of Safety-Critical Applications,https://ieeexplore.ieee.org/document/9417059/,"Solutions based on artificial intelligence and brain-inspired computations like Artificial Neural Networks (ANNs) are suited to deal with the growing computational complexity required by state-of-the-art electronic devices. Many applications that are being deployed using these computational models are considered safety-critical (e.g., self-driving cars), producing a pressing need to evaluate their reliability. Besides, state-of-theart ANNs require significant memory resources to store their parameters (e.g., weights, activation values), which goes outside the possibility of many resource-constrained embedded systems. In this light, Approximate Computing (AxC) has become a significant field of research to improve memory footprint, speed, and energy consumption in embedded and high-performance systems. The use of AxC can significantly reduce the cost of ANN implementations, but it may also reduce the inherent resiliency of this kind of application. On this scope, reliability assessments are carried out by performing fault injection test campaigns. The intent of the paper is to propose a framework that, relying on the results of radiation tests in Commercial-Off-The-Shelf (COTS) devices, is able to assess the reliability of a given application. To this end, a set of different radiation-induced errors in COTS memories is presented. Upon these, specific fault models are extracted to drive emulation-based fault injections.",autonomous vehicle
10.1109/IOLTS52814.2021.9486704,filtered,2021 IEEE 27th International Symposium on On-Line Testing and Robust System Design (IOLTS),IEEE,2021-06-30 00:00:00,ieeexplore,A Suitability Analysis of Software Based Testing Strategies for the On-line Testing of Artificial Neural Networks Applications in Embedded Devices,https://ieeexplore.ieee.org/document/9486704/,"Electronic devices based on artificial intelligence solutions are pervading our everyday life. Nowadays, human decision processes are supported by real-time data gathered from intelligent systems. Artificial Neural Networks (ANNs) are one of the most used deep learning predictive models due to their outstanding computational capabilities. However, assessing their reliability is still an open issue faced by both the academic and industrial worlds, especially when ANNs are deployed on safety-critical systems, such as self-driving cars in the automotive world. In these systems, a strategy for identifying hardware faults is required by industry standards (e.g., ISO26262 for automotive, and DO254 for avionics). Among the existing in-field test strategies, the periodic scheduling of on-line Software Test Library (STL) is a wide strategy adopted; STL allows to reach an acceptable fault coverage without the need for additional hardware. However, when dealing with ANN-based applications, the execution of on-line tests interleaving the ANN inferences may jeopardise the strive for performance maximization. The paper presents a comprehensive analysis of six possible scenarios concerning the execution of on-line self-test programs in embedded devices running ANN-based applications. In the proposed scenarios, the impact of the STL execution on the ANN performance is analyzed; in particular, the execution times of an inference and the Fault Detection Time (FDT) of the STL are discussed and compared. Experimental analyses are provided by relying on: an open-source RISC-V platform running two different convolutional neural networks; a STL for RISC-V cores with a maximum achievable fault coverage of 90%.",autonomous vehicle
10.1109/TENCON50793.2020.9293767,filtered,2020 IEEE REGION 10 CONFERENCE (TENCON),IEEE,2020-11-19 00:00:00,ieeexplore,Convolutional Neural Network based Traffic-Sign Classifier Optimized for Edge Inference,https://ieeexplore.ieee.org/document/9293767/,"Traffic-Sign Classification is a major task in self-driving cars as well as modern driving assisting systems can be deployed as an inference engine on the Field Programmable Gate Array (FPGA) combined with host processor-based edge device like Zynq Platform considering the property of dynamic reconfigurability of FPGA adoptable to architectural innovation. Hence this paper proposes an optimized Convolutional Neural Network (CNN) architecture based on VGGNet combined with image-preprocessing techniques. The proposed methodology utilizes pruning combined with post-training quantization-based optimization and obtains an accuracy loss of less than 1%. The architecture is trained, tested and validated using German Traffic Sign Detection Benchmark (GTSDB) with Google's TensorFlow framework obtaining a validation accuracy of 99.2% and test accuracy of 100% for novel input inference. The experimental results show the reduction in memory footprint of CNN model readily implementable on FPGA.",autonomous vehicle
10.1109/DICTA.2018.8615819,filtered,2018 Digital Image Computing: Techniques and Applications (DICTA),IEEE,2018-12-13 00:00:00,ieeexplore,Crack-pot: Autonomous Road Crack and Pothole Detection,https://ieeexplore.ieee.org/document/8615819/,"With the advent of self-driving cars and autonomous robots, it is imperative to detect road impairments like cracks and potholes and to perform necessary evading maneuvers to ensure fluid journey for on-board passengers or equipment. We propose a fully autonomous robust real-time road crack and pothole detection algorithm which can be deployed on any GPU based conventional processing boards with an associated camera. The approach is based on a deep neural net architecture which detects cracks and potholes using texture and spatial features. We also propose pre-processing methods which ensure real-time performance. The novelty of the approach lies in using texture-based features to differentiate between crack surfaces and sound roads. The approach performs well in large viewpoint changes, background noise, shadows, and occlusion. The efficacy of the system is shown on standard road crack datasets.",autonomous vehicle
10.1109/CVPRW50498.2020.00172,filtered,2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),IEEE,2020-06-19 00:00:00,ieeexplore,Detection and Retrieval of Out-of-Distribution Objects in Semantic Segmentation,https://ieeexplore.ieee.org/document/9150788/,"When deploying deep learning technology in self-driving cars, deep neural networks are constantly exposed to domain shifts. These include, e.g., changes in weather conditions, time of day, and long-term temporal shift. In this work we utilize a deep neural network trained on the Cityscapes dataset containing urban street scenes and infer images from a different dataset, the A2D2 dataset, containing also countryside and highway images. We present a novel pipeline for semantic segmenation that detects out-of-distribution (OOD) segments by means of the deep neural network's prediction and performs image retrieval after feature extraction and dimensionality reduction on image patches. In our experiments we demonstrate that the deployed OOD approach is suitable for detecting out-of-distribution concepts. Furthermore, we evaluate the image patch retrieval qualitatively as well as quantitatively by means of the semi-compatible A2D2 ground truth and obtain mAP values of up to 52.2%.",autonomous vehicle
10.1109/MICRO50266.2020.00033,filtered,2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO),IEEE,2020-10-21 00:00:00,ieeexplore,FIdelity: Efficient Resilience Analysis Framework for Deep Learning Accelerators,https://ieeexplore.ieee.org/document/9251852/,"We present a resilience analysis framework, called FIdelity, to accurately and quickly analyze the behavior of hardware errors in deep learning accelerators. Our framework enables resilience analysis starting from the very beginning of the design process to ensure that the reliability requirements are met, so that these accelerators can be safely deployed for a wide range of applications, including safety-critical applications such as self-driving cars. Existing resilience analysis techniques suffer from the following limitations: 1. general-purpose hardware techniques can achieve accurate results, but they require access to RTL to perform time-consuming RTL simulations, which is not feasible for early design exploration; 2. general-purpose software techniques can produce results quickly, but they are highly inaccurate; 3. techniques targeting deep learning accelerators only focus on memory errors. Our FIdelity framework overcomes these limitations. FIdelity only requires a minimal amount of high-level design information that can be obtained from architectural descriptions/block diagrams, or estimated and varied for sensitivity analysis. By leveraging unique architectural properties of deep learning accelerators, we are able to systematically model a major class of hardware errors - transient errors in logic components - in software with high fidelity. Therefore, FIdelity is both quick and accurate, and does not require access to RTL. We thoroughly validate our FIdelity framework using Nvidia's open-source accelerator called NVDLA, which shows that the results are highly accurate - out of 60K fault injection experiments, the software fault models derived using FIdelity closely match the behaviors observed from RTL simulations. Using the validated FIdelity framework, we perform a large-scale resilience study on NVDLA, which consists of 46M fault injection experiments running various representative deep neural network applications. We report the key findings and architectural insights, which can be used to guide the design of future accelerators.",autonomous vehicle
10.1109/MWSCAS47672.2021.9531833,filtered,2021 IEEE International Midwest Symposium on Circuits and Systems (MWSCAS),IEEE,2021-08-11 00:00:00,ieeexplore,Security Analysis of Capsule Network Inference using Horizontal Collaboration,https://ieeexplore.ieee.org/document/9531833/,"The traditional convolution neural networks (CNN) have several drawbacks like the ""Picasso effect"" and the loss of information by the pooling layer. The Capsule network (CapsNet) was proposed to address these challenges because its architecture can encode and preserve the spatial orientation of input images. Similar to traditional CNNs, CapsNet is also vulnerable to several malicious attacks, as studied by several researchers in the literature. However, most of these studies focus on single-device-based inference, but horizontally collaborative inference in state-of-the-art systems, like intelligent edge services in self-driving cars, voice controllable systems, and drones, nullify most of these analyses. Horizontal collaboration implies partitioning the trained CNN models or CNN tasks to multiple end devices or edge nodes. Therefore, it is imperative to examine the robustness of the CapsNet against malicious attacks when deployed in horizontally collaborative environments. Towards this, we examine the robustness of the CapsNet when subjected to noise-based inference attacks in a horizontal collaborative environment. In this analysis, we perturbed the feature maps of the different layers of four DNN models, i.e., CapsNet, mini-VGGNet, LeNet, and an in-house designed CNN (ConvNet) with the same number of parameters as CapsNet, using two types of noised-based attacks, i.e., Gaussian Noise Attack and FGSM noise attack. The experimental results show that similar to the traditional CNNs, depending upon the attacker’s access to the DNN layer, the classification accuracy of the CapsNet drops significantly. For example, when Gaussian Noise Attack classification is performed at the Digit-cap layer of the CapsNet, the maximum classification accuracy drop is approximately 97%. Similarly, the maximum classification accuracy drop is 90.1% when an FGSM noise attack is performed at the Conv layer of the CapsNet.",autonomous vehicle
10.1109/DeepTest52559.2021.00010,filtered,2021 IEEE/ACM Third International Workshop on Deep Learning for Testing and Testing for Deep Learning (DeepTest),IEEE,2021-06-01 00:00:00,ieeexplore,TF-DM: Tool for Studying ML Model Resilience to Data Faults,https://ieeexplore.ieee.org/document/9476897/,"Machine learning (ML) is widely deployed in safety-critical systems (e.g. self-driving cars). Failures can have disastrous consequences in these systems, and hence ensuring the reliability of its operations is important. Mutation testing is a popular method for assessing the dependability of applications and tools have recently been developed for ML frameworks. However, the focus has been on improving the quality of test data. We present an open source data mutation tool, TensorFlow Data Mutator (TF-DM), which targets different kinds of data faults for any ML program written in TensorFlow 2. TF-DM supports different types of data mutators so users can study model resilience to data faults. We explain how different fault models are mapped to mutators in TF-DM, and present a detailed evaluation and resiliency analysis of 6 ML models and 3 datasets.",autonomous vehicle
10.1109/ICCD46524.2019.00076,filtered,2019 IEEE 37th International Conference on Computer Design (ICCD),IEEE,2019-11-20 00:00:00,ieeexplore,When Deep Learning Meets the Edge: Auto-Masking Deep Neural Networks for Efficient Machine Learning on Edge Devices,https://ieeexplore.ieee.org/document/8988678/,"Deep neural network (DNN) has demonstrated promising performance in various machine learning tasks. Due to the privacy issue and the unpredictable transmission latency, inferring DNN models directly on edge devices trends the development of intelligent systems, like self-driving cars, smart Internet-of-Things (IoTs) and autonomous robotics. The on-device DNN model is obtained by expensive training via vast volumes of high-quality training data in the cloud datacenter, and then deployed into these devices, expecting it to work effectively at the edge. However, edge device always deals with low-quality images caused by compression or environmental noise pollutions. The well-trained model, though could work perfectly on the cloud, cannot adapt to these edge-specific conditions without remarkable accuracy drop. In this paper, we propose an automated strategy, called ""AutoMask"", to embrace effective machine learning and accelerate DNN inference on edge devices. AutoMask comprises end-to-end trainable software strategies and cost-effective hardware accelerator architecture to improve the adaptability of the device without compromising the constrained computation and storage resources. Extensive experiments, over ImageNet dataset and various state-of-the-art DNNs, show that AutoMask achieves significant inference acceleration and storage reduction while maintains comparable accuracy level on embedded Xilinx Z7020 FPGA, as well as NVIDIA Jetson TX2.",autonomous vehicle
10.1109/ICSPC51351.2021.9451761,filtered,2021 3rd International Conference on Signal Processing and Communication (ICPSC),IEEE,2021-05-14 00:00:00,ieeexplore,YOLOv4 for Multi-class Artefact Detection in Endoscopic Images,https://ieeexplore.ieee.org/document/9451761/,"State of the art deep learning-based object detectors are deployed in various fields of computer vision such as face recognition, object tracking, self-driving cars and so on. Most of the object detectors are trained on common objects such as person, car, train, truck etc. but not on medical images. Considering specific applications like detecting multi-class artefacts in endoscopic images, a cutting-edge object detector like YOLOv4 which out-performed well in terms of speed and accuracy in general purpose dataset (like MS COCO dataset), is chosen. The aim of the paper is to carefully handpick techniques from Bag of Freebies of YOLOv4 and retrain the detector for detecting commonly occurring artefacts in endoscopic images using EAD2019 dataset. The experimental results proved a good mAP score of 49.82 % with the inference time of 76 milliseconds.",autonomous vehicle
10.1109/TMC.2019.2946538,filtered,IEEE Transactions on Mobile Computing,IEEE,2021-02-01 00:00:00,ieeexplore,Augur: Modeling the Resource Requirements of ConvNets on Mobile Devices,https://ieeexplore.ieee.org/document/8863962/,"Convolutional Neural Networks (ConvNets/CNNs) have revolutionized the research in computer vision, due to their ability to capture complex patterns, resulting in high inference accuracies. However, the increasingly complex nature of these neural networks means that they are particularly suited for server computers with powerful GPUs. We envision that deep learning applications will be eventually widely deployed on mobile devices, e.g., smartphones, self-driving cars, and drones. Therefore, in this paper, we aim to understand the resource requirements of CNNs on mobile devices in terms of compute time, memory, and power. First, by deploying several popular CNNs on different mobile CPUs and GPUs, we measure and analyze the performance and resource usage for the CNNs on a layerwise granularity. Our findings point out the potential ways of optimizing the CNN pipelines on mobile devices. Second, we model resource requirements of core computations of CNNs. Finally, based on the measurement and modeling, we build and evaluate our modeling tool, Augur, which takes a CNN configuration (descriptor) as the input and estimates the compute time, memory, and power requirements of the CNN, to give insights about whether and how efficiently a CNN can be run on a given mobile platform.",autonomous vehicle
10.1109/JSAC.2020.3020677,filtered,IEEE Journal on Selected Areas in Communications,IEEE,2021-02-01 00:00:00,ieeexplore,Exploiting Transfer Learning for Emotion Recognition Under Cloud-Edge-Client Collaborations,https://ieeexplore.ieee.org/document/9187207/,"Emerging virtual reality/augmented reality games and self-driving cars necessitate accurate/responsive/private emotion recognition. Usually, traditional emotion recognition models are deployed at central servers, which results in the lack of abilities in generalization and covering the individual variation of clients. This paper proposes a responsive, localized, and private transfer learning based emotion recognition framework under the cloud-edge-client collaborations. Additionally, a 3-dimensional channel mapping method is designed to aggregate features extracted from electroencephalogram (EEG) signals for the generic emotion recognition model, which is further localized and personalized using transfer learning. Simulation results validate the performance of the proposed TLER framework in reducing model training time and improving emotion recognition accuracy.",autonomous vehicle
10.1109/LARS/SBR/WRE.2018.00048,filtered,"2018 Latin American Robotic Symposium, 2018 Brazilian Symposium on Robotics (SBR) and 2018 Workshop on Robotics in Education (WRE)",IEEE,2018-11-10 00:00:00,ieeexplore,Verisimilar Percept Sequences Tests for Autonomous Driving Intelligent Agent Assessment,https://ieeexplore.ieee.org/document/8588554/,The autonomous car technology promises to replace human drivers with safer driving systems. But although autonomous cars can become safer than human drivers this is a long process that is going to be refined over time. Before these vehicles are deployed on urban roads a minimum safety level must be assured. Since the autonomous car technology is still under development there is no standard methodology to evaluate such systems. It is important to completely understand the technology that is being developed to design efficient means to evaluate it. In this paper we assume safety-critical systems reliability as a safety measure. We model an autonomous road vehicle as an intelligent agent and we approach its evaluation from an artificial intelligence perspective. Our focus is the evaluation of perception and decision-making systems and also to propose a systematic method to evaluate their integration in the vehicle. We identify critical aspects of the data dependency from the artificial intelligence state of the art models and we also propose procedures to evaluate them.,autonomous vehicle
10.1109/IJCNN52387.2021.9533738,filtered,2021 International Joint Conference on Neural Networks (IJCNN),IEEE,2021-07-22 00:00:00,ieeexplore,CarSNN: An Efficient Spiking Neural Network for Event-Based Autonomous Cars on the Loihi Neuromorphic Research Processor,https://ieeexplore.ieee.org/document/9533738/,"Autonomous Driving (AD) related features provide new forms of mobility that are also beneficial for other kind of intelligent and autonomous systems like robots, smart transportation, and smart industries. For these applications, the decisions need to be made fast and in real-time. Moreover, in the quest for electric mobility, this task must follow low power policy, without affecting much the autonomy of the mean of transport or the robot. These two challenges can be tackled using the emerging Spiking Neural Networks (SNNs). When deployed on a specialized neuromorphic hardware, SNNs can achieve high performance with low latency and low power consumption. In this paper, we use an SNN connected to an event-based camera for facing one of the key problems for AD, i.e., the classification between cars and other objects. To consume less power than traditional frame-based cameras, we use a Dynamic Vision Sensor (DVS) [1]. The experiments are made following an offline supervised learning rule, followed by mapping the learnt SNN model on the Intel Loihi Neuromorphic Research Chip [2]. Our best experiment achieves an accuracy on offline implementation of 86%, that drops to 83% when it is ported onto the Loihi Chip. The Neuromorphic Hardware implementation has maximum 0.72 ms of latency for every sample, and consumes only 310 mW. To the best of our knowledge, this work is the first implementation of an event-based car classifier on a Neuromorphic Chip.",autonomous vehicle
10.1109/ACDT47198.2019.9072792,filtered,2019 IEEE 6th Asian Conference on Defence Technology (ACDT),IEEE,2019-11-15 00:00:00,ieeexplore,Cognitive Networks and Systems to Improve Coalition Operations Effectiveness,https://ieeexplore.ieee.org/document/9072792/,"Successful coalition operations depend on the accuracy and timeliness of the tactical information shared by participating units where sensor and communications delays are among the many factors affecting the pertinence of the information shared. Advanced cognitive networks (CNs) are a subset of cognitive dynamic systems (CDS) or distributed intelligent systems. CDS accelerate the production of accurate information and its timely sharing among participating agents which in turn improve decision making and likelihood of desired outcomes of course of actions. CDS are enabled by learning software run on advance specialized hardware, and they are used in distributed cognitive sensing and decision making to control effectors or inform users. If developed successfully, showing endurance at low cost, they are likely to provide significant advantages to their early adopters. Although CDS are progressing fast for applications such as autonomous cars and Fifth Generation (5G) services, no military CDS seem to have been deployed so far besides incomplete demonstrations.",autonomous vehicle
10.1109/ISSPIT.2018.8705101,filtered,2018 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT),IEEE,2018-12-08 00:00:00,ieeexplore,Collision warning system: embedded enabled (RTMaps with NXP BLBX2),https://ieeexplore.ieee.org/document/8705101/,"Forward Collision Warning (FCW) also referred as the Forward Collision Avoidance (FCA) system has become an essential part of the Autonomous cars or smart vehicles. The FCW System has found its position as one of the foremost automobile safety features included in the present smart vehicles. This paper proposes a Forward collision warning system which includes its subsystem as Forward-looking automotive radar model and a Classifier algorithm developed and designed in the Intempora RTMaps Embedded with NXP Bluebox 2.0. The classifier and regression algorithm work on the principle of supervised learning, the proposed model predicts the collision or no-collision occurrence based on the radar sensed inputs. The implementation, precision and accuracy of the classifier and regression algorithm is presented. The proposed model is deployed on the Bluebox 2.0 platform with the RTMaps Embedded framework.",autonomous vehicle
10.1109/ITAIC.2019.8785543,filtered,2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC),IEEE,2019-05-26 00:00:00,ieeexplore,Improving Adversarial Images Using Activation Maps,https://ieeexplore.ieee.org/document/8785543/,"Deep Neural Networks are currently gaining a lot of attention for their near human-level performances in tasks such as image classification, object detection, etc. As a result, they are also being deployed in security critical and real time systems such as face recognition and autonomous cars. This requires models to be robust to changes to the input. However, recent literature has showed that they are easily fooled when human imperceptible noise, also known as adversarial noise, is added to the input. By exploiting this adversarial nature, various adversarial attacks and defences against these attacks have been introduced so far. In this paper, we propose a new approach which can be used alongside any existing adversarial attack to further reduce the L2 distance between the generated adversarial image and the original image. Our approach can also be thought of as a new adversarial attack built on top of an existing attack. We evaluated our approach on the ImageNet dataset. Using our approach, we were able to reduce the L2 distance for around 60-70% of the images sampled from the ImageNet dataset.",autonomous vehicle
10.1109/LRA.2020.2967296,filtered,IEEE Robotics and Automation Letters,IEEE,2020-04-01 00:00:00,ieeexplore,Aerial Single-View Depth Completion With Image-Guided Uncertainty Estimation,https://ieeexplore.ieee.org/document/8962227/,"On the pursuit of autonomous flying robots, the scientific community has been developing onboard real-time algorithms for localisation, mapping and planning. Despite recent progress, the available solutions still lack accuracy and robustness in many aspects. While mapping for autonomous cars had a substantive boost using deep-learning techniques to enhance LIDAR measurements using image-based depth completion, the large viewpoint variations experienced by aerial vehicles are still posing major challenges for learning-based mapping approaches. In this letter, we propose a depth completion and uncertainty estimation approach that better handles the challenges of aerial platforms, such as large viewpoint and depth variations, and limited computing resources. The core of our method is a novel compact network that performs both depth completion and confidence estimation using an image-guided approach. Real-time performance onboard a GPU suitable for small flying robots is achieved by sharing deep features between both tasks. Experiments demonstrate that our network outperforms the state-of-the-art in depth completion and uncertainty estimation for single-view methods on mobile GPUs. We further present a new photorealistic aerial depth completion dataset that exhibits more challenging depth completion scenarios than the established indoor and car driving datasets. The dataset includes an open-source, visual-inertial UAV simulator for photo-realistic data generation. Our results show that our network trained on this dataset can be directly deployed on real-world outdoor aerial public datasets without fine-tuning or style transfer.",autonomous vehicle
10.1109/TMC.2019.2947893,filtered,IEEE Transactions on Mobile Computing,IEEE,2021-02-01 00:00:00,ieeexplore,JointDNN: An Efficient Training and Inference Engine for Intelligent Mobile Cloud Computing Services,https://ieeexplore.ieee.org/document/8871124/,"Deep learning models are being deployed in many mobile intelligent applications. End-side services, such as intelligent personal assistants, autonomous cars, and smart home services often employ either simple local models on the mobile or complex remote models on the cloud. However, recent studies have shown that partitioning the DNN computations between the mobile and cloud can increase the latency and energy efficiencies. In this paper, we propose an efficient, adaptive, and practical engine, JointDNN, for collaborative computation between a mobile device and cloud for DNNs in both inference and training phase. JointDNN not only provides an energy and performance efficient method of querying DNNs for the mobile side but also benefits the cloud server by reducing the amount of its workload and communications compared to the cloud-only approach. Given the DNN architecture, we investigate the efficiency of processing some layers on the mobile device and some layers on the cloud server. We provide optimization formulations at layer granularity for forward- and backward-propagations in DNNs, which can adapt to mobile battery limitations and cloud server load constraints and quality of service. JointDNN achieves up to 18 and 32 times reductions on the latency and mobile energy consumption of querying DNNs compared to the status-quo approaches, respectively.",autonomous vehicle
10.1109/INFOCOM42981.2021.9488791,filtered,IEEE INFOCOM 2021 - IEEE Conference on Computer Communications,IEEE,2021-05-13 00:00:00,ieeexplore,Mobile Crowdsensing for Data Freshness: A Deep Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/9488791/,"Data collection by mobile crowdsensing (MCS) is emerging as data sources for smart city applications, however how to ensure data freshness has sparse research exposure but quite important in practice. In this paper, we consider to use a group of mobile agents (MAs) like UAVs and driverless cars which are equipped with multiple antennas to move around in the task area to collect data from deployed sensor nodes (SNs). Our goal is to minimize the age of information (AoI) of all SNs and energy consumption of MAs during movement and data upload. To this end, we propose a centralized deep reinforcement learning (DRL)-based solution called ""DRL-freshMCS"" for controlling MA trajectory planning and SN scheduling. We further utilize implicit quantile networks to maintain the accurate value estimation and steady policies for MAs. Then, we design an exploration and exploitation mechanism by dynamic distributed prioritized experience replay. We also derive the theoretical lower bound for episodic AoI. Extensive simulation results show that DRL-freshMCS significantly reduces the episodic AoI per remaining energy, compared to five baselines when varying different number of antennas and data upload thresholds, and number of SNs. We also visualize their trajectories and AoI update process for clear illustrations.",autonomous vehicle
10.1109/IV47402.2020.9304624,filtered,2020 IEEE Intelligent Vehicles Symposium (IV),IEEE,2020-11-13 00:00:00,ieeexplore,Autonomous Driving: Framework for Pedestrian Intention Estimation in a Real World Scenario,https://ieeexplore.ieee.org/document/9304624/,"Rapid advancements in driver assistance technology will lead to the integration of fully autonomous vehicles on our roads that will interact with other road users. To address the problem that driverless vehicles make interaction through eye contact impossible, we describe a framework for estimating the crossing intentions of pedestrians in order to reduce the uncertainty that the lack of eye contact between road users creates. The framework was deployed in a real vehicle and tested with three experimental cases that showed a variety of communication messages to pedestrians in a shared space scenario. Results from the performed field tests showed the feasibility of the presented approach.",autonomous vehicle
10.1109/ACCESS.2020.3001277,filtered,IEEE Access,IEEE,2020-01-01 00:00:00,ieeexplore,"A Survey of Multi-Access Edge Computing in 5G and Beyond: Fundamentals, Technology Integration, and State-of-the-Art",https://ieeexplore.ieee.org/document/9113305/,"Driven by the emergence of new compute-intensive applications and the vision of the Internet of Things (IoT), it is foreseen that the emerging 5G network will face an unprecedented increase in traffic volume and computation demands. However, end users mostly have limited storage capacities and finite processing capabilities, thus how to run compute-intensive applications on resource-constrained users has recently become a natural concern. Mobile edge computing (MEC), a key technology in the emerging fifth generation (5G) network, can optimize mobile resources by hosting compute-intensive applications, process large data before sending to the cloud, provide the cloud-computing capabilities within the radio access network (RAN) in close proximity to mobile users, and offer context-aware services with the help of RAN information. Therefore, MEC enables a wide variety of applications, where the real-time response is strictly required, e.g., driverless vehicles, augmented reality, robotics, and immerse media. Indeed, the paradigm shift from 4G to 5G could become a reality with the advent of new technological concepts. The successful realization of MEC in the 5G network is still in its infancy and demands for constant efforts from both academic and industry communities. In this survey, we first provide a holistic overview of MEC technology and its potential use cases and applications. Then, we outline up-to-date researches on the integration of MEC with the new technologies that will be deployed in 5G and beyond. We also summarize testbeds and experimental evaluations, and open source activities, for edge computing. We further summarize lessons learned from state-of-the-art research works as well as discuss challenges and potential future directions for MEC research.",autonomous vehicle
10.1109/ComPE49325.2020.9200107,filtered,2020 International Conference on Computational Performance Evaluation (ComPE),IEEE,2020-07-04 00:00:00,ieeexplore,Inspection of Concrete Structures by a Computer Vision Technique and an Unmanned Aerial Vehicle,https://ieeexplore.ieee.org/document/9200107/,"We have proposed a visual inspection technique for concrete structures using deep learning and a hardware ecosystem, an Unmanned Aerial Vehicle (UAV). The UAV is a quadcopter that can fly to unreachable sections of a site which consists of a camera that captures images of the concrete surfaces via a mobile device and feed the real time images in the CNN model. The images taken from such remote locations may contain different types of surfaces, shadowed regions and surfaces with holes. The cracks are properly detected by the CNN `AlexNet' algorithm and masking with sliding window technique in such conditions due to variation in the image data set. The experimental results were simulated on a standard online data set of 40,000 images of Mendeley Data which is freely available and 3000 images have been chosen from the entire data set for this method. The classes have been divided into 2 categories of `crack' and `no crack' for the proposed method's data set. There are 1050 training images and 450 testing images for each category. Experimental results were achieved on Google Colab cloud service using Python Tensorflow API (Application Programming Interface). The proposed `AlexNet' CNN algorithm achieves 98.4 % accuracy and the model is deployed to a masking technique with sliding window to detect cracks in a 3008×2000 pixel resolution image by breaking the image into 227×227 pixel resolution image patches. The experimental results have proved that the proposed method handles noisy background such as cracks with shadows and stains, cracks on rusty and rough surfaces and minor dimension cracks with good efficiency.",autonomous vehicle
10.1109/ECAI.2018.8679047,filtered,"2018 10th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)",IEEE,2018-06-30 00:00:00,ieeexplore,Trajectory influence on data collection in Wireless Sensor Networks using an Unmanned Aerial Vehicle,https://ieeexplore.ieee.org/document/8679047/,"Data collection is one of the most important parts in the communication process of wireless sensors. Without a proper mechanism to gather data, any further action is inefficient. Data aggregation, processing and decision making are only possible after data is collected. For this reason, this paper studies the impact of trajectories on data collection in an environment where a mobile unmanned aerial vehicle is deployed to gather information from ground sensors. Different mobility patterns have been taken into consideration to observe how collection efficiency is affected. Simulations were deployed in Network Simulator 2, version 2.34 and results are revealed in Section IV.",autonomous vehicle
10.1109/ICUAS.2018.8453315,filtered,2018 International Conference on Unmanned Aircraft Systems (ICUAS),IEEE,2018-06-15 00:00:00,ieeexplore,Vision-Based Autonomous Landing of a Multi-Copter Unmanned Aerial Vehicle using Reinforcement Learning,https://ieeexplore.ieee.org/document/8453315/,"This paper presents vision-based landing guidance of multi-copter Unmanned Aerial Vehicle (UAV) using reinforcement learning. In this approach, the guidance method is not designed or proposed by a human, but deployed by a neural network trained in simulated environments; which contains a quad-copter UAV model with Proportional-Integral-Derivative (PID) Controller, ground looking camera model that gives pixel deviation of targeting landing location from the center of an image frame, and laser rangefinder that gives altitude above ground level. Since we aimed for various types of multi-copter UAVs to track targeting ground location, reinforcement learning method has been used to generate proper roll and pitch attitude commands in multiple situations. Series of flight experiments show that a multi-copter UAV equipped with a proper attitude controller and trained artificial intelligence pilot can guide a multi-copter UAV to a ground target position.",autonomous vehicle
10.1109/ACCESS.2019.2892716,filtered,IEEE Access,IEEE,2019-01-01 00:00:00,ieeexplore,Analysis and Optimization of Unmanned Aerial Vehicle Swarms in Logistics: An Intelligent Delivery Platform,https://ieeexplore.ieee.org/document/8611082/,"Deploying unmanned aerial vehicle (UAV) swarms in delivery systems are still in its infancy with regard to the technology, safety, and aviation rules and regulations. Optimal use of UAVs in dynamic environments is important in many aspects, e.g., increasing efficacy and reducing the air traffic, resulting in a safer environment, and it requires new techniques and robust approaches based on the capabilities of UAVs and constraints. This paper analyzes several delivery schemes within a platform, such as delivery with and without using air highways and delivery using a hybrid scheme along with several delivery methods (i.e., optimal, premium, and first-in first-out) to explore the use of UAV swarms as part of the logistics operations. In this platform, a dimension reduction technique, “dynamic multiple assignments in multi-dimensional space,” and several other new techniques along with Hungarian and cross-entropy Monte Carlo techniques are forged together to assign tasks and plan 3D routes dynamically. This particular approach is performed in such a way that UAV swarms in several warehouses are deployed optimally given the delivery scheme, method, and constraints. Several scenarios are tested on the simulator using small and big data sets. The results show that the distribution and the characteristics of data sets and constraints affect the decision on choosing the optimal delivery scheme and the method. The findings are expected to guide the aviation authorities in their decisions before dictating rules and regulations regarding effective, efficient, and safe use of UAVs. Furthermore, the companies that produce UAVs are going to take the demonstrated results into account for their functional design of UAVs along with other companies that aim to deliver their products using UAVs. Additionally, private industries, logistics operators, and municipalities are expected to benefit from the potential adoption of the simulator in strategic decisions before embarking on the practical implementation of UAV delivery systems.",autonomous vehicle
10.1109/WPMC.2017.8301842,filtered,2017 20th International Symposium on Wireless Personal Multimedia Communications (WPMC),IEEE,2017-12-20 00:00:00,ieeexplore,A deep learning based handover mechanism for UAV networks,https://ieeexplore.ieee.org/document/8301842/,"The attractive feature of conveniently deployed as an aerial access point (AP) to provide coverage and improve network performance, has made the Unmanned Aerial Vehicle (UAV) networks a research hotspot. In this paper, an UAV handover mechanism in the three-dimensional space is proposed. We build and train user trajectory prediction model based on neural network. Then we described the handover mechanism under the condition of predicted trajectory and the constructed signal transmission model in UAV networks. Simulation results show that compared to the traditional handover algorithm, our scheme nearly 10% higher in handover success rate.",autonomous vehicle
10.1109/GLOBECOM42002.2020.9322632,filtered,GLOBECOM 2020 - 2020 IEEE Global Communications Conference,IEEE,2020-12-11 00:00:00,ieeexplore,Age of Information-Aware Resource Management in UAV-Assisted Mobile-Edge Computing Systems,https://ieeexplore.ieee.org/document/9322632/,"This paper investigates the problem of age of information (AoI)-aware resource awareness in an unmanned aerial vehicle (UAV)-assisted mobile-edge computing (MEC) system, which is deployed by an infrastructure provider (InP). A service provider leases resources from the InP to serve the mobile users (MUs) with sporadic computation requests. Due to the limited number of channels and the finite shared I/O resource of the UAV, the MUs compete to schedule local and remote task computations in accordance with the observations of system dynamics. The aim of each MU is to selfishly maximize the expected long-term computation performance. We formulate the non-cooperative interactions among the MUs as a stochastic game. To approach the Nash equilibrium solutions, we propose a novel online deep reinforcement learning (DRL) scheme, which enables each MU to behave using its local conjectures only. The DRL scheme employs two separate deep Q-networks to approximate the Q-factor and the post-decision Q-factor for each MU. Numerical experiments show the potentials of the online DRL scheme in balancing the tradeoff between AoI and energy consumption.",autonomous vehicle
10.1109/VTC2020-Fall49728.2020.9348616,filtered,2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall),IEEE,2020-12-16 00:00:00,ieeexplore,Deep Q-Network Based Dynamic Movement Strategy in a UAV-Assisted Network,https://ieeexplore.ieee.org/document/9348616/,"Unmanned aerial vehicle (UAV)-assisted communications is a promising solution to improve the performance of future wireless networks, where UAVs are deployed as base stations for enhancing the quality of service (QoS) provided to ground users when traditional terrestrial base stations are unavailable or not sufficient. An effective framework is proposed in this paper to manage the dynamic movement of multiple unmanned aerial vehicles (UAVs) in response to ground user mobility, with the objective to maximize the sum data rate of the ground users. First, we discuss the relationship between the air-to-ground (A2G) path loss (PL) and the location of UAVs. Then a deep Q-network (DQN) based method is proposed to adjust the locations of UAVs to maximize the sum data rate of the user equipment (UE). Finally, simulation results show that the proposed method is capable of adjusting UAV locations in a real-time condition to improve the QoS of the entire network.",autonomous vehicle
10.1109/WCNC49053.2021.9417292,filtered,2021 IEEE Wireless Communications and Networking Conference (WCNC),IEEE,2021-04-01 00:00:00,ieeexplore,Deep Reinforcement Learning based Path Planning for UAV-assisted Edge Computing Networks,https://ieeexplore.ieee.org/document/9417292/,"Mobile edge computing (MEC) harvests the computation capability at the network edge to perform the computation intensive tasks for diverse IoT applications. Meanwhile, the unmanned aerial vehicle (UAV) has a great potential to flexibly enlarge the coverage, and enhance the network performance. Accordingly, it has been a promising paradigm to use the UAV to provide the edge computing service for massive IoT devices. This paper studies the path planning problem of a UAV-assisted edge computing network, where an UAV is deployed with an edge server to execute the computing tasks offloaded from multiple devices. We consider the mobility of devices, where a GaussMarkov random movement model is adopted. By taking the energy consumed for the dynamic flying and executing the tasks at the UAV into account, we formulate a path planning problem that aims to maximize the amount of offloaded data bits by the devices while minimizing the energy consumption of the UAV. To deal with the dynamic change of the complex environment, we apply the deep reinforcement learning (DRL) method to develop an online path planning algorithm based on double deep Q-learning network (DDQN). Extensive simulation results validate the effectiveness of the proposed DRL-based path planning algorithm in terms of the convergence speed and the system reward.",autonomous vehicle
10.1109/WCSP49889.2020.9299784,filtered,2020 International Conference on Wireless Communications and Signal Processing (WCSP),IEEE,2020-10-23 00:00:00,ieeexplore,Deep Reinforcement Learning for Caching Placement and Content Delivery in UAV NOMA Networks,https://ieeexplore.ieee.org/document/9299784/,"The cache-enabling unmanned aerial vehicle (UAV) cellular network is investigated in this article, where the massive access capability is enhanced by applying non-orthogonal multiple access (NOMA). More particularly, a mobile UAV base station, which caches the popular contents to release the pressure on wireless backhaul links, is deployed to assist the delivery of large volume multimedia contents for ground users. The dynamic UAV cellular network with the dynamic UAV locations and content requests in practical scenario is considered in this paper. A long-term caching placement and content delivery joint optimization problem for content delivery delay minimization is formulated as a Markov decision process (MDP) to cope with the dynamic environment. A deep reinforcement learning (DRL) based caching placement and content delivery algorithm is proposed to tackle the MDP with large action space. Finally, it is demonstrated by the numerical results that: 1) a low content delivery delay is achieved by the studied cache-enabling UAV NOMA networks; 2) a good performance is provided by the proposed algorithm.",autonomous vehicle
10.1109/ICCWorkshops49005.2020.9145249,filtered,2020 IEEE International Conference on Communications Workshops (ICC Workshops),IEEE,2020-06-11 00:00:00,ieeexplore,Deep Reinforcement Learning for Efficient Data Collection in UAV-Aided Internet of Things,https://ieeexplore.ieee.org/document/9145249/,"In the Internet of Things (IoTs), unmanned aerial vehicle (UAV) has been considered as an efficient solution to collect information from ground sensor nodes (SNs) due to its controllable mobility and high maneuverability. In this paper, we study a UAV-aided efficient data collection problem for IoTs, where SNs sample information with fixed or random rates and cache the sampled update packets under a sample-and-replace policy. An energy-constrained UAV is deployed to collect data from each SN when it flies over this SN. The UAV's flight trajectory is optimized to minimize the SNs' average age-ofinformation (AoI) while preserving their packet drop rate as low as possible. Toward this end, we model the UAV-aided data collection problem as a finite-horizon Markov decision process (MDP) with finite state and action spaces. Then, we develop a deep reinforcement learning algorithm to find an asymptotically optimal policy. Simulation results demonstrate that the proposed learning algorithm can significantly reduce the AoI and packet drop rate, compared to the baseline greedy algorithms.",autonomous vehicle
10.1109/IAICT50021.2020.9172031,filtered,"2020 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)",IEEE,2020-07-08 00:00:00,ieeexplore,Human Target Search and Detection using Autonomous UAV and Deep learning,https://ieeexplore.ieee.org/document/9172031/,"An Unmanned Aerial Vehicle (UAV) is an airborne system or pilotless aircraft which is remotely controlled by a human operator on ground or by an onboard computer such that the vehicle moves autonomously. The range of applications in which UAVs are used is very large. This paper describes the application of developing an autonomous surveillance system using an UAV to identify a given target and/or objects of interest in the terrain over which it flies. Such a system can be used in rescue operations, especially in remote areas where physical access is difficult. It can also be used for military operations, farming or any field where surveillance of a given land area is required. The UAV developed in this work is capable of object detection. A mounted camera is used to give visual feedback, and an onboard processing unit runs image recognition software to identify the target in real time. Optimal algorithms are used to search and find the target from the given search area. After recognition of the target, the UAV can either be used to hold its position so as to have a video feed of the target, or return to its base station once the coordinates have been estimated using GPS modules or relay the GPS location to the base station. This paper describes the implementation of the hardware and software components that lead to the realization of the UAV and the application of object detection. The details of a new search algorithm and an example of object detection is presented . The work presented in this paper is the first part in the attempt to develop a cluster of UAVs meant to work in collaboration to be deployed for search and rescue operations.",autonomous vehicle
10.1109/CyberPELS49534.2020.9311545,filtered,2020 IEEE CyberPELS (CyberPELS),IEEE,2020-10-13 00:00:00,ieeexplore,Intrusion Detection Systems-Enabled Power Electronics for Unmanned Aerial Vehicles,https://ieeexplore.ieee.org/document/9311545/,"Compromised power electronics, due to firmware attacks and hardware Trojans, in a flight computer can jeopardize the safety and security of an Unmanned Aerial Vehicle (UAV). They can maliciously alter sensor measurements or control commands to make a UAV to take disastrous moves. Unfortunately, most of these attacks are difficult to detect before deploying components in the system. Therefore, detecting compromised behavior run-time is important, while it is challenging at the same time. In this work, we propose to build machine learning-based intrusion detection systems (IDSs) to be deployed at the power electronics/microcontorller level such that it can deal with malicious data/control commands initiated due to hardware attacks.",autonomous vehicle
10.1109/SECON52354.2021.9491604,filtered,"2021 18th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON)",IEEE,2021-07-09 00:00:00,ieeexplore,Joint Communication-Motion Planning for UAV Relaying in Urban Areas,https://ieeexplore.ieee.org/document/9491604/,"In this paper, we consider a challenging surveillance scenario where there could exist line-of-sight (LOS) propagations and non-line-of-sight (NLOS) propagations in air-to-ground (ATG) channel and air-to-air (ATA) channel due to obstacles in urban areas, and a ground mobile robot is deployed to survey this area and transmit collected data to a remote base station via an unmanned aerial vehicle (UAV) relay. In this scenario, we aim to plan the optimal transmit power and trajectory of the UAV relay to minimize energy consumption while maintaining the communication quality. Existing works typically rely on the free-space path loss model and the statistical channel model, thus neglect the positions and shapes of obstacles and may fail in practical NLOS scenarios. In this paper, we first exploit the end-to-end packet error rate (PER)-based communication model, which captures the LOS propagation and NLOS propagation. Then, taken the information of obstacles in environment into consideration, we propose an UAV relay-assisted joint communication-motion planning (UAV-JCMP) method for minimizing the total energy consumption in urban areas. By decomposing the concave problem into two subproblems and dividing its domain into several convex subdomains according to LOS conditions, we further get the optimal solution. At last, numerical results demonstrate that substantial energy-efficient improvements can be achieved over methods that only optimize communication energy consumption and methods using statistical channel model. We further discuss the robustness of UAV-JCMP method towards terrain measurement error.",autonomous vehicle
10.1109/GLOBECOM42002.2020.9322190,filtered,GLOBECOM 2020 - 2020 IEEE Global Communications Conference,IEEE,2020-12-11 00:00:00,ieeexplore,Learning for Path Planning and Coverage Mapping in UAV-Assisted Emergency Communications,https://ieeexplore.ieee.org/document/9322190/,"We consider a setting in which a rotary-wing unmanned aerial vehicle (UAV) acts as an aerial base station to provide emergency communication service to an area of unknown and inhomogeneous user distribution. The UAV has communication with a ground node deployed to the area, which acts as a charging station. We are interested in two important problems in this setting, namely the path planning and coverage mapping problems. In the path planning problem, the UAV must plan its path starting and ending at the charging station, visiting a series of waypoints over which it hovers to provide coverage to surrounding users. On the other hand, the coverage mapping problem focuses on learning the distribution of user coverage over the area. We highlight the importance of learning this distribution to collect valuable data in an emergency situation. We then propose an online algorithm that simultaneously solves the path planning and coverage mapping problems using a deep learning model. We highlight the interplay and conflicting goals of path planning and coverage mapping, but show through Monte Carlo simulation that, under the correct parameters, the algorithm is able to achieve success on both problems.",autonomous vehicle
10.1109/ICC42927.2021.9500646,filtered,ICC 2021 - IEEE International Conference on Communications,IEEE,2021-06-23 00:00:00,ieeexplore,Lifelong Learning for Minimizing Age of Information in Internet of Things Networks,https://ieeexplore.ieee.org/document/9500646/,"In this paper, a lifelong learning problem is studied for an Internet of Things (IoT) system. In the considered model, each IoT device aims to balance its information freshness and energy consumption tradeoff by controlling its computational resource allocation at each time slot under dynamic environments. An unmanned aerial vehicle (UAV) is deployed as a flying base station so as to enable the IoT devices to adapt to novel environments. To this end, a new lifelong reinforcement learning algorithm, used by the UAV, is proposed in order to adapt the operation of the devices at each visit by the UAV. By using the experience from previously visited devices and environments, the UAV can help devices adapt faster to future states of their environment. To do so, a knowledge base shared by all devices is maintained at the UAV. Simulation results show that the proposed algorithm can converge 25% to 50% faster than a policy gradient baseline algorithm that optimizes each device’s decision making problem in isolation.",autonomous vehicle
10.1109/WCSP49889.2020.9299676,filtered,2020 International Conference on Wireless Communications and Signal Processing (WCSP),IEEE,2020-10-23 00:00:00,ieeexplore,Mobility-Aware Trajectory Design for Aerial Base Station Using Deep Reinforcement Learning,https://ieeexplore.ieee.org/document/9299676/,"In this paper, an unmanned aerial vehicle (UAV) assisted wireless network is investigated, where an aerial base station (ABS) is deployed for serving both ground and aerial users. The objective is to maximize the uplink sum-rate of all users by designing the trajectory of the ABS, while considering the mobility of users. Specifically, it is assumed that all aerial UAVs move individually with the random waypoint mobility model (RWM). Meanwhile, some ground users move with the reference point group mobility model, while others follow the RWM as well. Due to the mobility of both ground and aerial users, conventional reinforcement learning (such as Q-learning) is very likely to fail for the curse of dimensionality. Therefore, it is non-trivial to solve the trajectory design problem in the large-scale highly dynamic environment. By approximating the value functions with neural networks, a deep reinforcement learning-based algorithm is proposed for the ABS to autonomously provide network services in the rapidly changing environment. Simulation results demonstrate that our designed double deep Q-network (DDQN) can learn the environment information very well with our elaborate rewards. Compared to the conventional DDQN with fully connected network, our proposed DDQN converges faster and has better stability.",autonomous vehicle
10.1109/ICAIIC51459.2021.9415264,filtered,2021 International Conference on Artificial Intelligence in Information and Communication (ICAIIC),IEEE,2021-04-16 00:00:00,ieeexplore,Prioritized-MAC Model for Intelligent UAV-to-BS Communication in Industrial-WSN Systems,https://ieeexplore.ieee.org/document/9415264/,"In this paper, a prioritized-MAC protocol model for unmanned aerial vehicle (UAV) data collection and processing in an industrial wireless sensor network system (IWSN) is proposed. The model encapsulates the existing legacy IEEE 802.11 carrier-sense multiple access collision avoidance (CSMA/CA) MAC protocol, where nodes are kept active when in UAV's coverage area. A level-sided access channel approach is then deployed to distinguish the priority allotment to each ground node using the distributed coordinated function inter-frame spacing (DCFIS) approach. Consequently, nodes located at the highest priority level-sided frame have shorter time-length with more DCFIS values than those of lower priority level-sided frames. On simulation, our proposed protocol not only improves fairness, but enhances network fairness with reduced delay time.",autonomous vehicle
10.1109/SMARTCOMP52413.2021.00041,filtered,2021 IEEE International Conference on Smart Computing (SMARTCOMP),IEEE,2021-08-27 00:00:00,ieeexplore,REPlanner: Efficient UAV Trajectory-Planning using Economic Reinforcement Learning,https://ieeexplore.ieee.org/document/9556271/,"Advances in the unmanned aerial vehicle (UAV) design and capability, as well as decreases in the manufacturing cost, have opened up applications of UAVs in various fields, including surveillance, firefighting, cellular networks, and delivery purposes. The uniqueness of UAVs in systems creates a novel set of trajectory or path planning and coordination problems. Environments include many more points of interest (POIs) than UAVs, with obstacles and no-fly zones. We introduce REPlanner, a novel multi-agent reinforcement learning algorithm inspired by economic transactions to distribute tasks among UAVs. This system revolves around an economic theory, in particular an auction mechanism where UAVs trade assigned POIs. We formulate the path planning problem as a multi-agent economic game, where agents can cooperate and compete for resources. We then translate the problem into a partially observable Markov decision process (POMDP), which is solved using a reinforcement learning (RL) model deployed on each agent. As the system computes task distributions via UAV cooperation, it is highly resilient to any change in the swarm size. Our proposed network and economic game architecture can effectively coordinate the swarm as an emergent phenomenon while maintaining the swarm’s operation. Evaluation results prove that REPlanner efficiently outperforms conventional RL-based trajectory search.",autonomous vehicle
10.1109/PIMRC50174.2021.9569434,filtered,"2021 IEEE 32nd Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)",IEEE,2021-09-16 00:00:00,ieeexplore,Reinforcement Learning Based Green Rate-Constrained UAV Trajectory and User Association Design for IoT Networks,https://ieeexplore.ieee.org/document/9569434/,"In this paper, we have proposed an energy-efficient unmanned aerial vehicle (UAV) assisted Internet of things (IoT) network where a low altitude UAV is employed as a mobile data collector. We develop a novel optimization framework that minimizes the total energy consumption of all devices by jointly optimizing the UAV’s trajectory, device association and respective transmit power allocation at every time slot while ensuring that every device should achieve a given transmission rate constraint. As this joint optimization problem is nonconvex and combinatorial, we adopt reinforcement learning (RL) based solution methodology that effectively decouples it into three individual optimization problems. The formulated problem is transformed as a Markov decision process (MDP) where UAV learns its trajectory according to its current state and corresponding action aiming to maximize the reward under the current policy. Finally, we conceive state-action-reward-state-action (SARSA), a low complexity iterative algorithm for updating the current policy in the case of randomly deployed IoT devices which achieves good computational complexity-optimality tradeoff via numerical results. We find that the proposed methodology reduces the total energy consumption of all devices by 9.23%, 14.06%, and 15.87% in the case of 80, 100, and 120 available time slots of UAV respectively.",autonomous vehicle
10.1109/IROS45743.2020.9341802,filtered,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),IEEE,2021-01-24 00:00:00,ieeexplore,Towards Deep Learning Assisted Autonomous UAVs for Manipulation Tasks in GPS-Denied Environments,https://ieeexplore.ieee.org/document/9341802/,"In this work, we present a pragmatic approach to enable unmanned aerial vehicle (UAVs) to autonomously perform highly complicated tasks of object pick and place. This paper is largely inspired by challenge-2 of MBZIRC 2020 and is primarily focused on the task of assembling large 3D structures in outdoors and GPS-denied environments. Primary contributions of this system are: (i) a novel computationally efficient deep learning based unified multi-task visual perception system for target localization, part segmentation, and tracking, (ii) a novel deep learning based grasp state estimation, (iii) a retracting electromagnetic gripper design, (iv) a remote computing approach which exploits state-of-the-art MIMO based high speed (5000Mb/s) wireless links to allow the UAVs to execute compute intensive tasks on remote high end compute servers, and (v) system integration in which several system components are weaved together in order to develop an optimized software stack. We use DJI Matrice-600 Pro, a hexrotor UAV and interface it with the custom designed gripper. Our framework is deployed on the specified UAV in order to report the performance analysis of the individual modules. Apart from the manipulation system, we also highlight several hidden challenges associated with the UAVs in this context.",autonomous vehicle
10.1109/ECICE50847.2020.9301968,filtered,"2020 IEEE Eurasia Conference on IOT, Communication and Engineering (ECICE)",IEEE,2020-10-25 00:00:00,ieeexplore,UAV Landmark Detection Based on Convolutional Neural Network,https://ieeexplore.ieee.org/document/9301968/,"The extensive use application of visual perception technology in Unmanned Aerial Vehicle (UAV) has brought great changes to the application of UAV in various fields. It is challenge to detect in landmark images for UAV. During UAV flight in different environments, the performance of landmark detection to deteriorate seriously have been caused by the uncertainty of landmark orientation, the diversity of landmark types and the similarities. This paper presents landmark detection of UAV based on Convolutional Neural Network (CNN). Theoretical analysis and experimental results demonstrate landmark recognition with an accuracy of at least 96% to match deployed in UAV, and the proposed CNN can make a correct classification.",autonomous vehicle
10.1109/Confluence51648.2021.9377082,filtered,"2021 11th International Conference on Cloud Computing, Data Science & Engineering (Confluence)",IEEE,2021-01-29 00:00:00,ieeexplore,Water Quality Estimation using Computer Vision in UAV,https://ieeexplore.ieee.org/document/9377082/,"The color change of water in a water body is often a tell - tale sign of its health. To counter the sources of water pollution an Unmanned Aerial Vehicle is deployed over a water body which reports back any discrepancies by channeling the feed through Computer Vision based model. This allows for rapid steps to be taken by the Concerned Authorities to mitigate the current situation. Algae formation, floating impurities and color change of the water body are the scope of the project and each of these are detected with an independent Machine Learning Models. The UAV communicates and sends results based on the accuracy of these models.",autonomous vehicle
10.1109/MetroAgriFor50201.2020.9277542,filtered,2020 IEEE International Workshop on Metrology for Agriculture and Forestry (MetroAgriFor),IEEE,2020-11-06 00:00:00,ieeexplore,Water spray detection for smart irrigation systems with Mask R-CNN and UAV footage,https://ieeexplore.ieee.org/document/9277542/,"While the world's population rises, demand for food grows accordingly. Smart agriculture emerges as a viable solution to increase the quality and efficiency of crops. Irrigation plays an essential role in the grade and productivity of harvests, while also being a crucial factor in the cost-effectiveness of food production. Smart irrigation uses technology to improve watering, such as the Internet of Things (IoT) applications and Machine Learning algorithms. The correct functioning of irrigation nozzles is critical to ensure that the hydration plan is deployed correctly to the crop field. This paper presents a Machine Learning algorithm that can automatically recognize water from aerial footage of irrigation systems. This automatic recognition can help in the irrigation system inspection, potentially reducing time and cost in system maintenance. Initial results show that it is possible to identify water on image frames captured by an Unmanned Aerial Vehicle (UAV) using the Mask R-CNN Neural Network. The goal is to identify malfunctioning irrigation systems that can lead to under or overwatering, compromising the irrigation plan's correct implementation.",autonomous vehicle
10.1109/JSAC.2018.2872429,filtered,IEEE Journal on Selected Areas in Communications,IEEE,2019-02-01 00:00:00,ieeexplore,A Prediction-Based Charging Policy and Interference Mitigation Approach in the Wireless Powered Internet of Things,https://ieeexplore.ieee.org/document/8474384/,"The Internet of Things (IoT) technology has recently drawn more attention due to its ability to achieve the interconnections of massive physic devices. However, how to provide a reliable power supply to energy-constrained devices and improve the energy efficiency in the wireless powered IoT (WP-IoT) is a twofold challenge. In this paper, we develop a novel wireless power transmission (WPT) system, where an unmanned aerial vehicle (UAV) equipped with radio frequency energy transmitter charges the IoT devices. A machine learning framework of echo state networks together with an improved k -means clustering algorithm is used to predict the energy consumption and cluster all the sensor nodes at the next period, thus automatically determining the charging strategy. The energy obtained from the UAV by WPT supports the IoT devices to communicate with each other. In order to improve the energy efficiency of the WP-IoT system, the interference mitigation problem is modeled as a mean field game, where an optimal power control policy is presented to adapt and analyze the large number of sensor nodes randomly deployed in WP-IoT. The numerical results verify that our proposed dynamic charging policy effectively reduces the data packet loss rate, and that the optimal power control policy greatly mitigates the interference, and improve the energy efficiency of the whole network.",autonomous vehicle
10.1109/TVT.2018.2886961,filtered,IEEE Transactions on Vehicular Technology,IEEE,2019-02-01 00:00:00,ieeexplore,An Empirical Air-to-Ground Channel Model Based on Passive Measurements in LTE,https://ieeexplore.ieee.org/document/8576578/,"In this paper, a recently conducted measurement campaign for unmanned-aerial-vehicle channels is introduced. The downlink signals of an in-service long-time-evolution network, which is deployed in a suburban scenario were acquired. Five horizontal and five vertical flight routes were considered. The channel impulse responses (CIRs) are extracted from the received data by exploiting the cell-specific signals, and the underlying physical propagation mechanisms are interpreted by exploiting the propagation graph modeling approach. Based on the CIRs, the parameters of multipath components are estimated by using a high-resolution algorithm derived according to the space-alternating generalized expectation-maximization (SAGE) principle. Based on the SAGE results, channel characteristics including the path loss, shadow fading, fast fading, delay spread, and Doppler frequency spread are thoroughly investigated for different heights and horizontal distances, which constitute a stochastic model.",autonomous vehicle
10.1109/TBC.2020.2983298,filtered,IEEE Transactions on Broadcasting,IEEE,2021-03-01 00:00:00,ieeexplore,An Innovative Machine-Learning-Based Scheduling Solution for Improving Live UHD Video Streaming Quality in Highly Dynamic Network Environments,https://ieeexplore.ieee.org/document/9068423/,"The latest advances in terms of network technologies open up new opportunities for high-end applications, including using the next generation video streaming technologies. As mobile devices become more affordable and powerful, an increasing range of rich media applications could offer a highly realistic and immersive experience to mobile users. However, this comes at the cost of very stringent Quality of Service (QoS) requirements, putting significant pressure on the underlying networks. In order to accommodate these new rich media applications and overcome their associated challenges, this paper proposes an innovative Machine Learning-based scheduling solution which supports increased quality for live omnidirectional (360°) video streaming. The proposed solution is deployed in a highly dynamic Unmanned Aerial Vehicle (UAV)-based environment to support immersive live omnidirectional video streaming to mobile users. The effectiveness of the proposed method is demonstrated through simulations and compared against three state-of-the-art scheduling solutions, such as: static Prioritization (SP), Required Activity Detection Scheduler (RADS) and Frame Level Scheduler (FLS). The results show that the proposed solution outperforms the other schemes involved in terms of PSNR, throughput and packet loss rate.",autonomous vehicle
10.23919/JCIN.2020.9306013,filtered,Journal of Communications and Information Networks,PTP,2020-12-01 00:00:00,ieeexplore,Deep Q-Network Based Dynamic Trajectory Design for UAV-Aided Emergency Communications,https://ieeexplore.ieee.org/document/9306013/,"In this paper, an unmanned aerial vehicle (UAV)-aided wireless emergence communication system is studied, where a UAV is deployed to support ground user equipments (UEs) for emergence communications. We aim to maximize the number of the UEs served, the fairness, and the overall uplink data rate via optimizing the trajectory of UAV and the transmission power of UEs. We propose a deep Q-network (DQN) based algorithm, which involves the well-known deep neural network (DNN) and Q-learning, to solve the UAV trajectory problem. Then, based on the optimized UAV trajectory, we further propose a successive convex approximation (SCA) based algorithm to tackle the power control problem for each UE. Numerical simulations demonstrate that the proposed DQN based algorithm can achieve considerable performance gain over the existing benchmark algorithms in terms of fairness, the number of UEs served and overall uplink data rate via optimizing UAV's trajectory and power optimization.",autonomous vehicle
10.1109/LNET.2021.3065943,filtered,IEEE Networking Letters,IEEE,2021-06-01 00:00:00,ieeexplore,"Joint Placement, Power Control, and Spectrum Allocation for UAV Wireless Backhaul Networks",https://ieeexplore.ieee.org/document/9378782/,"Unmanned aerial vehicle (UAV) communication is a promising technology to yield great benefits for 5G wireless networks and beyond. In this paper, we investigate the downlink transmission in wireless backhaul networks when a UAV is deployed as the flying base station. A joint optimization problem of UAV's placement, spectrum allocation, and power control is formulated, which is an NP-hard problem. To solve the above-mentioned problem efficiently, we propose decomposing the underlying problem into two subproblems, which are then solved alternatively in an iterative manner. Simulation results under various settings are provided to demonstrate the performance improvement of the proposed algorithm over baseline schemes.",autonomous vehicle
10.1109/TII.2020.3024170,filtered,IEEE Transactions on Industrial Informatics,IEEE,2021-07-01 00:00:00,ieeexplore,Learning-Based Resource Allocation Strategy for Industrial IoT in UAV-Enabled MEC Systems,https://ieeexplore.ieee.org/document/9197688/,"Forest fire monitoring plays an important role in forest resource protection. Although satellite remote sensing is an effective way for forest fire monitoring, satellite-based methods can only monitor large-scale forest areas, and they are weak in predicting the specific areas of forest fires. In this article, we first propose an unmanned aerial vehicle (UAV)-enabled system architecture consisting of multiple industrial Internet of Things (IIoTs), in which the data collected by sensors in IIoTs can be delivered to UAVs for processing directly. As the sensors of IIoTs are deployed to monitor different indexes of forest fires, fully considering the priority constraints among sensors can guarantee a quick response of forest fire monitoring. Thus, the priority constraints among the sensors are taken into consideration in this system architecture, and the objective is to minimize the maximum response time of forest fire monitoring. To search for the optimal UAV resource allocation strategy, a learning-based cooperative particle swarm optimization (LCPSO) algorithm with a Markov random field (MRF)-based decomposition strategy is proposed. The solution space of UAV resource allocation is decomposed into subsolution spaces according to the decomposed decision variables by the MRF network structure, and the optimal resource allocation strategy is searched by LCPSO in multiple subsolution spaces cooperatively. Three simulation experiments on two datasets are designed, and the simulation results compared with the state-of-the-art methods verify the validity of LCPSO, which are reflected by the quickest response time of forest fire monitoring.",autonomous vehicle
10.1109/JSAC.2020.3041401,filtered,IEEE Journal on Selected Areas in Communications,IEEE,2021-07-01 00:00:00,ieeexplore,Machine Learning Empowered Trajectory and Passive Beamforming Design in UAV-RIS Wireless Networks,https://ieeexplore.ieee.org/document/9277627/,"A novel framework is proposed for integrating reconfigurable intelligent surfaces (RIS) in unmanned aerial vehicle (UAV) enabled wireless networks, where an RIS is deployed for enhancing the service quality of the UAV. Non-orthogonal multiple access (NOMA) technique is invoked to further improve the spectrum efficiency of the network, while mobile users (MUs) are considered as roaming continuously. The energy consumption minimizing problem is formulated by jointly designing the movement of the UAV, phase shifts of the RIS, power allocation policy from the UAV to MUs, as well as determining the dynamic decoding order. A decaying deep Q-network (D-DQN) based algorithm is proposed for tackling this pertinent problem. In the proposed D-DQN based algorithm, the central controller is selected as an agent for periodically observing the state of UAV-enabled wireless network and for carrying out actions to adapt to the dynamic environment. In contrast to the conventional DQN algorithm, the decaying learning rate is leveraged in the proposed D-DQN based algorithm for attaining a tradeoff between accelerating training speed and converging to the local optimal. Numerical results demonstrate that: 1) In contrast to the conventional Q-learning algorithm, which cannot converge when being adopted for solving the formulated problem, the proposed D-DQN based algorithm is capable of converging with minor constraints; 2) The energy dissipation of the UAV can be significantly reduced by integrating RISs in UAV-enabled wireless networks; 3) By designing the dynamic decoding order and power allocation policy, the RIS-NOMA case consumes 11.7% less energy than the RIS-OMA case.",autonomous vehicle
10.1109/ACCESS.2020.3046499,filtered,IEEE Access,IEEE,2021-01-01 00:00:00,ieeexplore,Real-Time Energy Harvesting Aided Scheduling in UAV-Assisted D2D Networks Relying on Deep Reinforcement Learning,https://ieeexplore.ieee.org/document/9303363/,"Unmanned aerial vehicle (UAV)-assisted device-to-device (D2D) communications can be deployed flexibly thanks to UAVs' agility. By exploiting the direct D2D interaction supported by UAVs, both the user experience and network performance can be substantially enhanced at public events. However, the continuous moving of D2D users, limited energy and flying time of UAVs are impediments to their applications in real-time. To tackle this issue, we propose a novel model based on deep reinforcement learning in order to find the optimal solution for the energy-harvesting time scheduling in UAV-assisted D2D communications. To make the system model more realistic, we assume that the UAV flies around a central point, the D2D users move continuously with random walk model and the channel state information encountered during each time slot is randomly time-variant. Our numerical results demonstrate that the proposed schemes outperform the existing solutions. The associated energy efficiency game can be solved in less than one millisecond by an off-the-shelf processor using trained neural networks. Hence our deep reinforcement learning techniques are capable of solving real-time resource allocation problems in UAV-assisted wireless networks.",autonomous vehicle
10.1109/TIM.2020.3001659,filtered,IEEE Transactions on Instrumentation and Measurement,IEEE,2020-12-01 00:00:00,ieeexplore,Real-Time Fault Detection for UAV Based on Model Acceleration Engine,https://ieeexplore.ieee.org/document/9115090/,"With the wide applications of the unmanned aerial vehicle (UAV) in the civilian and military fields, its operational safety has drawn much attention. A series of fault detection methods are studied to avoid disasters. Due to the capabilities of strong feature extraction and massive flight data processing, the deep learning-based methods have received extensive attention. However, restricted by UAV airborne size, weight, and power consumption, a significant challenge is posed to deploy these complicated detection methods in the airborne application, which requires to run in real time. In this article, a fault detection model acceleration engine (FDMAE) for UAV real-time fault detection is realized under the airborne constraint. First, a high-performance detection model is designed based on stacked long short-term memory networks, and fault detection is achieved by a statistical threshold in this method. Second, a model pruning method based on principal component analysis is proposed to improve computing efficiency. Finally, the pruned fault detection method is optimized and integrated as a flexible acceleration engine through high-level synthesis and deployed on an airborne embedded computing platform based on a field-programmable gate array. Real UAV flight data are used to verify the proposed FDMAE. By comparing accuracy, the area under the receiver operating characteristic curve, speed, and power consumption, the effectiveness of the FDMAE is proven.",autonomous vehicle
10.1109/ACCESS.2021.3070908,filtered,IEEE Access,IEEE,2021-01-01 00:00:00,ieeexplore,Task Offloading and Trajectory Control for UAV-Assisted Mobile Edge Computing Using Deep Reinforcement Learning,https://ieeexplore.ieee.org/document/9395130/,"Mobile Edge Computing (MEC) has been widely employed to support various Internet of Things (IoT) and mobile applications. By leveraging the advantages of easily deployed and flexibility of Unmanned Aerial Vehicle (UAV), one of MEC primary functions is employing UAVs equipped with MEC servers to provide computation supports for the offloaded tasks by mobile users in temporally hotspot areas or some emergent scenarios, such as sports game areas or destroyed by natural disaster areas. Despite the numerous advantages of UAV carried with a MEC server, it is restricted by its limited computation resources and sensitive energy consumption. Moreover, due to the complexity of UAV-assisted MEC system, its computational resource optimization and energy consumption optimization cannot be achieved well in traditional optimization methods. Furthermore, the computational cost of the MEC system optimization is often exponentially growing with the increase of the MEC servers and mobile users. Therefore, it is considerably challenging to control the UAV positions and schedule the task offloading ratio. In this paper, we proposed a novel Deep Reinforcement Learning (DRL) method to optimize UAV trajectory controlling and users' offloaded task ratio scheduling and improve the performance of the UAV-assisted MEC system. We maximized the system stability and minimized the energy consumption and computation latency of UAV-assisted the MEC system. The simulation results show that the proposed method outperforms existing work and has better scalability.",autonomous vehicle
10.1109/JIOT.2019.2954825,filtered,IEEE Internet of Things Journal,IEEE,2020-07-01 00:00:00,ieeexplore,Toward Big Data Processing in IoT: Path Planning and Resource Management of UAV Base Stations in Mobile-Edge Computing System,https://ieeexplore.ieee.org/document/8908690/,"Heavy data load and wide cover range have always been crucial problems for big data processing in Internet of Things (IoT). Recently, mobile-edge computing (MEC) and unmanned aerial vehicle base stations (UAV-BSs) have emerged as promising techniques in IoT. In this article, we propose a three-layer online data processing network based on the MEC technique. On the bottom layer, raw data are generated by distributed sensors with local information. Upon them, UAV-BSs are deployed as moving MEC servers, which collect data and conduct initial steps of data processing. On top of them, a center cloud receives processed results and conducts further evaluation. For online processing requirements, the edge nodes should stabilize delay to ensure data freshness. Furthermore, limited onboard energy poses constraints to edge processing capability. In this article, we propose an online edge processing scheduling algorithm based on Lyapunov optimization. In cases of low data rate, it tends to reduce edge processor frequency for saving energy. In the presence of a high data rate, it will smartly allocate bandwidth for edge data offloading. Meanwhile, hovering UAV-BSs bring a large and flexible service coverage, which results in a path planning issue. In this article, we also consider this problem and apply deep reinforcement learning to develop an online path planning algorithm. Taking observations of around environment as an input, a CNN network is trained to predict action rewards. By simulations, we validate its effectiveness in enhancing service coverage. The result will contribute to big data processing in future IoT.",autonomous vehicle
10.1109/ACCESS.2020.2987851,filtered,IEEE Access,IEEE,2020-01-01 00:00:00,ieeexplore,UAV-Mounted Mobile Base Station Placement via Sparse Recovery,https://ieeexplore.ieee.org/document/9066938/,"In order to deploy minimum number of unmanned aerial vehicle (UAV)-mounted mobile base stations (MBSs) to service all given ground terminals, this paper proposes an MBS placement based on sparse recovery (MBS-PBSR) algorithm. By exploiting the sparsity inherent in the differences between any two dedicated MBSs, the problem of UAV-mounted MBS placement could be formulated as an ℓ<sub>0</sub>-norm constrained optimization problem, which is then be solved by the reweighted ℓ<sub>1</sub>-norm method. Subsequently, the resulted solutions to the MBS placement are adjusted by the iterative redundant circle deletion algorithm, eventually leading to the redundant MBSs removal as much as possible. Simulation results demonstrate that our proposed MBS-PBSR algorithm works well with affordable computational complexity, and is nearly optimum in the sense of the number of deployed UAV-mounted MBSs.",autonomous vehicle
10.1109/ICUAS.2014.6842349,filtered,2014 International Conference on Unmanned Aircraft Systems (ICUAS),IEEE,2014-05-30 00:00:00,ieeexplore,Formal intent based Flight Management System design for unmanned aerial vehicles,https://ieeexplore.ieee.org/document/6842349/,"This paper presents a formal intent based Flight Management System (FMS) hardware and functional structure utilising multi-level autonomy modes. The novel advanced capabilities added to the UAV autopilots are envisioned to meet the requirements of the future flight operations of the UAVs integrated into national airspace. The proposed FMS structure integrates new functionalities such as a) formal intent based information exchange and collaborative tactical planning utilising air-to-air and air-to-ground data links and, b) decentralised immediate sense-and-avoid. The collaborative nominal operation mode enables the ground operator to build “shared intelligence” with the UAV through the intent sharing. In this mode, the intent sharing process benefits from the advantages of formal intent languages at different levels of abstraction and data-links. The air-to-ground data link allows the ground operator to update/modify/re-plan the flight intent (FI) of the UAV(s) in any phase of the operation according to evolving situations through ground station. The air-to-air intent sharing also continues between the surrounding aircraft through the aircraft intent (AI) (“machine-to-machine” level) communication which makes unmanned systems to be visible. The sense-and-avoid mode, the FMS recursively computes and observes the probabilities of potential immediate collisions with the other aircraft and terrain. Whenever the immediate response needs, the FMS executes the generated 3D avoidance maneuver. For technology demonstration purposes, an experimental FMS hardware has been deployed in a quadrotor UAV, and a ground operator station with GUI has been designed enabling envisioned operational experiments.",autonomous vehicle
10.1109/TVT.2020.3042128,filtered,IEEE Transactions on Vehicular Technology,IEEE,2020-12-01 00:00:00,ieeexplore,RF Fingerprinting Unmanned Aerial Vehicles With Non-Standard Transmitter Waveforms,https://ieeexplore.ieee.org/document/9277909/,"The universal availability of unmanned aerial vehicles (UAVs) has resulted in many applications where the same make/model can be deployed by multiple parties. Thus, identifying a specific UAV in a given swarm, in a manner that cannot be spoofed by software methods, becomes important. We propose RF fingerprinting for this purpose, where a neural network learns subtle imperfections present in the transmitted waveform. For UAVs, the constant hovering motion raises a key challenge, which remains a fundamental problem in previous works on RF fingerprinting: Since the wireless channel changes constantly, the network trained with a previously collected dataset performs poorly on the test data. The main contribution of this paper is to address this problem by: (i) proposing a multi-classifier scheme with a two-step score-based aggregation method, (ii) using RF data augmentation to increase neural network robustness to hovering-induced variations, and (iii) extending the multi-classifier scheme for detecting a new UAV, not seen earlier during training. Importantly, our approach permits RF fingerprinting on manufacturer-proprietary waveforms that cannot be decoded or altered by the end-user. Results reveal a near two-fold accuracy in UAV classification through our multi-classifier method over the single-classifier case, with an overall accuracy of 95% when tested with data under unseen channel. Our multi-classifier scheme also improves new UAV detection accuracy to a near perfect 99%, up from 68% for a single neural network approach.",autonomous vehicle
10.1109/DASC.2016.7778103,filtered,2016 IEEE/AIAA 35th Digital Avionics Systems Conference (DASC),IEEE,2016-09-29 00:00:00,ieeexplore,A reliable system design for nondeterministic adaptive controllers in small UAV autopilots,https://ieeexplore.ieee.org/document/7778103/,"Despite the tremendous attention Unmanned Aerial Vehicles (UAVs) have received in recent years for applications in transportation, surveillance, agriculture, and search and rescue, as well as their possible enormous economic impact, UAVs are still banned from fully autonomous commercial flights. One of the main reasons for this is the safety of the flight. Traditionally, pilots control the aircraft when complex situations emerge that even advanced autopilots are not able to manage. Artificial Intelligence based methods and Adaptive Controllers have proven themselves to be efficient in scenarios with uncertainties; however, they also introduce another concern: nondeterminism. This research endeavors to find a solution on how such algorithms can be utilized with higher reliability. Our method is based on using an adaptive model to verify the performance of a control parameter - proposed by a nondeterministic adaptive controller or AI-based optimizer - before it is deployed on the physical platform. Furthermore, a backup mechanism is engaged to recover the drone in case of failure. A Neural Network is employed to model the aircraft, and a Genetic Algorithm is utilized to optimize the PID controller of a quadcopter. The initial experimental results from test flights indicate the feasibility of this method.",autonomous vehicle
10.1109/GCWkshps45667.2019.9024679,filtered,2019 IEEE Globecom Workshops (GC Wkshps),IEEE,2019-12-13 00:00:00,ieeexplore,Communications and Networking Technologies for Intelligent Drone Cruisers,https://ieeexplore.ieee.org/document/9024679/,"Future mobile communication networks require an Aerial Base Station (ABS) with fast mobility and long-term hovering capabilities. At present, unmanned aerial vehicles (UAV) or drones do not have long flight times and are mainly used for monitoring, surveillance, and image post-processing. On the other hand, the traditional airship is too large and not easy to take off and land. Therefore, we propose to develop an ""Artificial Intelligence (AI) Drone-Cruiser"" base station that can help 5G mobile communication systems and beyond quickly recover the network after a disaster and handle the instant communications by the flash crowd. The drone-cruiser base station can overcome the communications problem for three types of flash crowds, such as in stadiums, parades, and large plaza so that an appropriate number of aerial base stations can be accurately deployed to meet large and dynamic traffic demands. Artificial intelligence can solve these problems by analyzing the collected data, and then adjust the system parameters in the framework of Self-Organizing Network (SON) to achieve the goals of self-configuration, self- optimization, and self-healing. With the help of AI technologies, 5G networks can become more intelligent. This paper aims to provide a new type of service, On-Demand Aerial Base Station as a Service. This work needs to overcome the following five technical challenges: innovative design of drone-cruisers for the long-time hovering, crowd estimation and prediction, rapid 3D wireless channel learning and modeling, 3D placement of aerial base stations and the integration of WiFi front-haul and millimeter wave/WiGig back-haul networks.",autonomous vehicle
10.1109/PIMRC50174.2021.9569295,filtered,"2021 IEEE 32nd Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)",IEEE,2021-09-16 00:00:00,ieeexplore,Data Collection in UAV-Assisted Wireless Sensor Networks Powered by Harvested Energy,https://ieeexplore.ieee.org/document/9569295/,"Unmanned aerial vehicles (UAV) assisted-data collection is a new and promising application in many practical scenarios and is gathering a lot of interest. UAVs have the advantage of flexibility as they can be deployed in difficult terrains and hence can be employed for data collection in wireless sensor networks (WSNs). However UAV assisted-data collection in WSN faces many challenges due especially to energy limitations at both the UAV and the sensors. Hence, in this paper, we adress the data collection problem, by considering wireless power transfer (WPT) from the UAV to the sensor nodes (SNs). Our objective is to minimize the UAV total mission time that is defined as the amount of time needed by the UAV to collect all the data available at the SNs and to replenish their energies. To solve this NP-hard problem, which is formulated as an integer linear program, we propose two heuristics, namely the nearest neighbor algorithm (NNA) and the genetic algorithm (GA). In addition to the optimal solution, we also propose two other simple algorithms as benchmarks, in order to demonstrate the efficiency of the proposed algorithms by means of simulations.",autonomous vehicle
10.1109/ICCWorkshops49005.2020.9145456,filtered,2020 IEEE International Conference on Communications Workshops (ICC Workshops),IEEE,2020-06-11 00:00:00,ieeexplore,Deep Reinforcement Learning Based Strategy for Quadrotor UAV Pursuer and Evader Problem,https://ieeexplore.ieee.org/document/9145456/,"In recent years, there have occurred many incidents that unmanned aerial vehicles (UAVs) in the field of national security. While in some situations, UAVs may be deployed simultaneously by different parties with opposite purposes, easily resulting in direct competitions against each other. In this case, how to use UAVs to pursue UAVs has become a hot spot. In order to analyze the behavior of UAV, building a realistic mathematical dynamic model is necessary. In this paper, we propose a Takagi-Sugeno (T-S) fuzzy control system based UAV dynamic model, which is exactly the same UAV control method in practice. To address the competition conundrum between UAVs, we formulate this problem into a pursuer-evader problem and leverage the reinforcement learning based machine learning method to solve this. The proposed deep Q network is based on traditional Q learning but able to address some deficiencies. Basically, deep Q network has three vital improvements: using neural network to describe the Q function, the architecture of double networks, and the experience replay. The simulation results show the correctness of our analysis and effectiveness of our proposed method.",autonomous vehicle
10.1109/ICUAS51884.2021.9476756,filtered,2021 International Conference on Unmanned Aircraft Systems (ICUAS),IEEE,2021-06-18 00:00:00,ieeexplore,Deep Reinforcement Learning for Adaptive Exploration of Unknown Environments,https://ieeexplore.ieee.org/document/9476756/,"Autonomous exploration is an essential task for unmanned aerial vehicles (UAVs) operating in unknown environments. Often, UAVs on these missions must first build a map of the environment via pure exploration and subsequently use (i.e. exploit) the generated map for downstream navigation tasks. Accomplishing these navigation tasks in two separate steps is not always possible and can potentially be disadvantageous for UAVs deployed in outdoor and dynamically changing environments. Current exploration approaches typically use a priori human-generated maps or heuristics such as frontier-based exploration. Other approaches use learning but focus only on learning policies for specific tasks and use sample inefficient random exploration or make impractical assumptions about full map availability. In this paper, we develop an adaptive exploration approach that allows for a trade off between exploration and exploitation in a single step using Deep Reinforcement Learning (DRL). We specifically focus on UAVs searching for areas of interest (AoIs) in an unknown environment. The proposed approach uses a map segmentation technique to decompose the environment map into smaller, tractable maps. DDQN and A2C algorithms are extended with a stack of LSTM layers and trained to generate optimal policies for the exploration and exploitation tasks, respectively. Then, an information gain function is repeatedly computed to determine the optimal trade-off between them. We tested our approach in 3 different tasks against 4 baselines. The results demonstrate that our proposed approach is capable of navigating through randomly generated environments and covering more AoI in less time compared to the baselines.",autonomous vehicle
10.1109/EAIS.2018.8397177,filtered,2018 IEEE Conference on Evolving and Adaptive Intelligent Systems (EAIS),IEEE,2018-05-27 00:00:00,ieeexplore,Deep reinforcement learning for frontal view person shooting using drones,https://ieeexplore.ieee.org/document/8397177/,"Unmanned Aerial Vehicles (UAVs), also known as drones, are increasingly used for a wide variety of novel tasks, including drone-based cinematography. However, flying drones in such setting requires the coordination of several people, increasing the cost of using drones for aerial cinematography and limiting the shooting flexibility by putting a significant cognitive load on the director and drone/camera operators. To overcome some of these limitation, this paper proposes a deep reinforcement learning (RL) method for performing autonomous frontal view shooting. To this end, a realistic simulation environment is developed, which ensures that the learned agent can be directly deployed on a drone. Then, a deep RL algorithm, tailored to the needs of the specific application, is derived building upon the well known deep Q-learning approach. The effectiveness of the proposed technique is experimentally demonstrated using several quantitative and qualitative experiments.",autonomous vehicle
10.1109/MELECON48756.2020.9140588,filtered,2020 IEEE 20th Mediterranean Electrotechnical Conference ( MELECON),IEEE,2020-06-18 00:00:00,ieeexplore,Drones for Sheep Livestock Monitoring,https://ieeexplore.ieee.org/document/9140588/,"Nowadays, Unmanned Aerial Vehicles (UAV) have been included in many more applications such as package delivery, traffic monitoring, etc; and one of its potential applications is agriculture. This work demonstrates the research and design of a new application for the drones, which is monitoring sheep livestock. We describe the set-up process for the drone and what are the equipment used for it, how the system for the monitoring is designed, what are the system limitations and how the constraints are satisfied within the system design of the system. Image processing and Machine Learning are heavily used along the setup, and therefore, the system is trained and tested in a real field that served the purpose of this paper. Different setups that match a wide spectrum of applications are deployed and their results thoroughly discussed.",autonomous vehicle
10.1109/INFOCOM41043.2020.9155535,filtered,IEEE INFOCOM 2020 - IEEE Conference on Computer Communications,IEEE,2020-07-09 00:00:00,ieeexplore,Energy-Efficient UAV Crowdsensing with Multiple Charging Stations by Deep Learning,https://ieeexplore.ieee.org/document/9155535/,"Different from using human-centric mobile devices like smartphones, unmanned aerial vehicles (UAVs) can be utilized to form a new UAV crowdsensing paradigm, where UAVs are equipped with build-in high-precision sensors, to provide data collection services especially for emergency situations like earthquakes or flooding. In this paper, we aim to propose a new deep learning based framework to tackle the problem that a group of UAVs energy-efficiently and cooperatively collect data from low-level sensors, while charging the battery from multiple randomly deployed charging stations. Specifically, we propose a new deep model called ""j-PPO+ConvNTM"" which contains a novel spatiotemporal module ""Convolution Neural Turing Machine"" (ConvNTM) to better model long-sequence spatiotemporal data, and a deep reinforcement learning (DRL) model called ""j-PPO"", where it has the capability to make continuous (i.e., route planing) and discrete (i.e., either to collect data or go for charging) action decisions simultaneously for all UAVs. Finally, we perform extensive simulation to show its illustrative movement trajectories, hyperparameter tuning, ablation study, and compare with four other baselines.",autonomous vehicle
10.1109/HPCC-SmartCity-DSS50907.2020.00074,filtered,2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems (HPCC/SmartCity/DSS),IEEE,2020-12-16 00:00:00,ieeexplore,High-Performance Object Detection for Optical Remote Sensing Images with Lightweight Convolutional Neural Networks,https://ieeexplore.ieee.org/document/9407897/,"Convolutional neural network (CNN)-based object detection for optical remote sensing images has achieved higher accuracy compared with traditional detection methods with handcrafted features. However, the deep and large CNNs make it hard to be deployed in real-time scenarios with limited computation, storage, power and bandwidth resources, for example, data processing onboard airborne, satellites and unmanned aerial vehicles for search and rescue. Therefore, in this paper we present a high-performance object detection approach for optical remote sensing images. Based on the widely used Faster R-CNN framework, we integrate state-of-the-art lightweight CNNs as backbone to extract features, slim the heavy-head architecture of two-stage detector by reducing dimensions of features, and fine-tune our models with NWPU VHR-10 optical remote sensing dataset. Besides, the multi-threading for CPU and detection in batches for GPU are deployed to enhance the throughput of detectors and utilization of multi-core CPU and many-core GPU. Experiments show that our presented detection approach can significantly reduce the model size, computation complexity and detection time, while maintaining competitive accuracy. Specifically, the one with ShuffleNet-v2 and slimmed features has achieved a highest mean average precision of 94.39%, a lowest computational complexity of 18.97 Giga floating point operations, a highest detection speed of 90.10 frames per second (fps) for GPU and 3.07 fps for CPU, corresponding to speedups of 6.94X and 13.26X compared with the baseline on the benchmarked system, with a model size of 13.6 MB. Moreover, it further improves the efficiency and achieves 4.98 fps on CPU with 4 threads, and 200.24 fps on GPU with a batch size of 32.",autonomous vehicle
10.1109/INFOCOMWKSHPS47286.2019.9093759,filtered,IEEE INFOCOM 2019 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS),IEEE,2019-05-02 00:00:00,ieeexplore,Intelli-Eye: An UAV Tracking System with Optimized Machine Learning Tasks Offloading,https://ieeexplore.ieee.org/document/9093759/,"The unmanned aerial vehicles (UAVs) have been extensively used in providing intelligence such as target tracking. In our field experiments, a pre-trained deep neural network (DNN) is deployed on the UAV to identify a target from the captured video frames and enable UAV to keep tracking. However, tracking in real time by the DNN requires a lot of computational resources. This motivates us to consider offloading this type of machine learning (ML) tasks to a mobile edge computing (MEC) server. Specifically, we propose a novel hierarchical ML tasks distribution framework for the UAV tracking system, where the UAV is embedded with lower layers of the pre-trained convolutional neural network (CNN) model due to its limited computing capability, while the MEC server with rich computing resources will handle the higher layers of the CNN model. An optimization problem is formulated to minimize the CNN inference delay while taking into account the communications delay, computing time, and ML error. Insights are provided to understand the tradeoff between communications and ML computing in offloading decisions. Numerical results demonstrate the effectiveness of the proposed ML tasks distribution framework with the optimized offloading strategy.",autonomous vehicle
10.1109/ARIS50834.2020.9205793,filtered,2020 International Conference on Advanced Robotics and Intelligent Systems (ARIS),IEEE,2020-08-21 00:00:00,ieeexplore,Landing Area Recognition using Deep Learning for Unammaned Aerial Vehicles,https://ieeexplore.ieee.org/document/9205793/,The lack of an automated Unmanned Aerial Vehicles (UAV) landing site detection system has been identified as one of the main impediments to allow UAV flight over populated areas in civilian airspace to develop tasks in the logistical transport scenario. This research proposes landing area localization and obstruction detection for UAVs that are based on deep learning faster R-CNN and feature matching algorithm. Which output decides if the landing area is safe or not. The final result has been deployed on the Aerial Mobile Robot Platform and was successfully performed effectively.,autonomous vehicle
10.1109/DASC50938.2020.9256456,filtered,2020 AIAA/IEEE 39th Digital Avionics Systems Conference (DASC),IEEE,2020-10-15 00:00:00,ieeexplore,Mask R-CNN Powerline Detector: A Deep Learning approach with applications to a UAV,https://ieeexplore.ieee.org/document/9256456/,"This paper explores the use of a UAV for power-line inspection using a Deep Learning algorithm for detection. Unmanned Aerial Vehicles (UAVs) are versatile with the potential to revolutionize multiple business domains, with benefits being discovered both inside and outside the world of utility and energy industries. They can reduce operational costs, improve worker safety, asset reliability, and decision making, also having semiautonomous flight capability. Utility and Energy companies have successfully deployed UAVs in inspections. Power-line companies usually perform regular visual inspections to check the status of their transmission lines mainly using helicopters equipped with external gimbals housing infrared and an ultraviolet camera to detect hot spots and corona discharges. This solution is quite expensive and dangerous for the crew. To resolve this, a powerline-detection segmentation algorithm based on transfer learning and an improved mask regional convolutional neural network (Mask RCNN), Mask RCNN Powerline Detector is proposed and is deployed on an UAV. For this Draganfly XP-4 was used as the UAV platform. The power-line detection system used a Deep Learning Resnet50 architecture as the backbone network, combined with the Feature Pyramid Network (FPN) architecture for feature extraction. The Region Proposal Network (RPN) was trained end-to-end to create region proposals for each feature map. This paper will present the development of the MRPD system, integration, and testing of the UAV.",autonomous vehicle
10.1109/INFOCOMWKSHPS51825.2021.9484496,filtered,IEEE INFOCOM 2021 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS),IEEE,2021-05-13 00:00:00,ieeexplore,Multi-UAV-enabled AoI-aware WPCN: A Multi-agent Reinforcement Learning Strategy,https://ieeexplore.ieee.org/document/9484496/,"Unmanned Aerial Vehicles (UAVs) have been deployed in virtually all tasks of enabling wireless powered communication networks (WPCNs). To ensure sustainable energy support and timely coverage of terrestrial Internet of Things (IoT) devices, a UAV needs to continuously hover and transmit wireless energy signals to charge these devices in the downlink. Then, the devices send their independent information to the UAV in the uplink. However, it was noted that the majority of existing schemes related to UAV-enabled WPCN are mainly based on a single UAV and cannot meet the requirements of a large-scale WPCN. In this paper, we design a separated UAV-assisted WPCN system, where two UAVs are deployed to behave as a UAV data collector (UAV-DC) and UAV energy transmitter (UAV-ET), respectively. Thus, the collection of fresh information and energy transfer are treated separately at the level of the two corresponding UAVs. These two tasks could be enhanced by optimizing the UAVs' trajectories. For this purpose, we leverage a multi-agent deep Q-network (MADQN) strategy to provide appropriate UAVs' trajectories that jointly minimize the expected age of information (AoI), enhance the energy transfer to devices, and minimize the energy consumption of UAVs. Simulation results show that our system enhances the performance of our strategy significantly in terms of AoI and energy transfer compared with baseline methods.",autonomous vehicle
10.1109/DSAA.2017.72,filtered,2017 IEEE International Conference on Data Science and Advanced Analytics (DSAA),IEEE,2017-10-21 00:00:00,ieeexplore,Nazr-CNN: Fine-Grained Classification of UAV Imagery for Damage Assessment,https://ieeexplore.ieee.org/document/8259763/,"We propose Nazr-CNN1, a deep learning pipeline for object detection and fine-grained classification in images acquired from Unmanned Aerial Vehicles (UAVs) for damage assessment and monitoring. Nazr-CNN consists of two components. The function of the first component is to localize objects (e.g. houses or infrastructure) in an image by carrying out a pixel-level classification. In the second component, a hidden layer of a Convolutional Neural Network (CNN) is used to encode Fisher Vectors (FV) of the segments generated from the first component in order to help discriminate between different levels of damage. To showcase our approach we use data from UAVs that were deployed to assess the level of damage in the aftermath of a devastating cyclone that hit the island of Vanuatu in 2015. The collected images were labeled by a crowdsourcing effort and the labeling categories consisted of fine-grained levels of damage to built structures. Since our data set is relatively small, a pre-trained network for pixel-level classification and FV encoding was used. Nazr-CNN attains promising results both for object detection and damage assessment suggesting that the integrated pipeline is robust in the face of small data sets and labeling errors by annotators. While the focus of Nazr-CNN is on assessment of UAV images in a post-disaster scenario, our solution is general and can be applied in many diverse settings. We show one such case of transfer learning to assess the level of damage in aerial images collected after a typhoon in Philippines.",autonomous vehicle
10.1109/ICPHYS.2019.8780266,filtered,2019 IEEE International Conference on Industrial Cyber Physical Systems (ICPS),IEEE,2019-05-09 00:00:00,ieeexplore,Real-Time SLFN-Based Node Localization Using UAV,https://ieeexplore.ieee.org/document/8780266/,"In this paper, a novel real-time single hidden layer feedforward neural network (SLFN)-based node localization technique in the wireless sensor network (WSN) is proposed. The localization is performed using mobile unmanned aerial vehicles (UAVs) as the anchor nodes to send the beacon signals every period of time, thus every unknown node can estimate it's current position based on the RSSI values of the received beacon signals by training the SLFN using extreme learning machine (ELM) technique. There are no deployed ground anchor node and require fewer anchor nodes compared to traditional RSSI-based localization technique to yield better accuracy. Simulation results show that this technique is capable of performing real-time unknown nodes localization with less localization error by using ELM compared to other traditional machine learning algorithms.",autonomous vehicle
10.1109/ICIP.2019.8803262,filtered,2019 IEEE International Conference on Image Processing (ICIP),IEEE,2019-09-25 00:00:00,ieeexplore,SSSDET: Simple Short and Shallow Network for Resource Efficient Vehicle Detection in Aerial Scenes,https://ieeexplore.ieee.org/document/8803262/,"Detection of small-sized targets is of paramount importance in many aerial vision-based applications. The commonly deployed low cost unmanned aerial vehicles (UAVs) for aerial scene analysis are highly resource constrained in nature. In this paper we propose a simple short and shallow network (SSSDet) to robustly detect and classify small-sized vehicles in aerial scenes. The proposed SSSDet is up to 4× faster, requires 4.4× less FLOPs, has 30× less parameters, requires 31× less memory space and provides better accuracy in comparison to existing state-of-the-art detectors. Thus, it is more suitable for hardware implementation in real-time applications. We also created a new airborne image dataset (ABD) by annotating 1396 new objects in 79 aerial images for our experiments. The effectiveness of the proposed method is validated on the existing VEDAI, DLR-3K, DOTA and Combined dataset. The SSSDet outperforms state-of-the-art detectors in term of accuracy, speed, compute and memory efficiency.",autonomous vehicle
10.1109/IWCMC51323.2021.9498879,filtered,2021 International Wireless Communications and Mobile Computing (IWCMC),IEEE,2021-07-02 00:00:00,ieeexplore,Securing Unmanned Aerial Systems Using Mobile Agents and Artificial Neural Networks,https://ieeexplore.ieee.org/document/9498879/,"Advances in wireless networks and the rapid development of electronic components have actively contributed to the emergence of new communication and surveillance systems known as Unmanned Aerial Systems (UASs). In such systems, unmanned aerial vehicles (UAVs) can be used as a wireless ad hoc network and thus provide a communications infrastructure for diverse military or civil applications. For more efficiency, a swarm of drones can be deployed in an area of interest (e.g. disaster areas, battlefields) by forming a flying ad hoc network (FANET) capable of communicating wirelessly with a ground control station (GCS) in a more secure manner. In this work, we particularly focus on the detection of False Data Injection (FDI) attacks in Unmanned Aerial Systems. We propose a new approach based on mobile agents to collect data and an artificial neural network model to identify injected false data. Our approach is validated using realistic datasets, provided by the University of Minnesota UAS Laboratories, and our results show that our proposal outperforms the compared approach by demonstrating higher detection rates (&gt;94%) and lower false positive rates (&lt;; 2.2%).",autonomous vehicle
10.1109/URTC.2015.7563746,filtered,2015 IEEE MIT Undergraduate Research Technology Conference (URTC),IEEE,2015-11-08 00:00:00,ieeexplore,Spectral anomaly detection with machine learning for wilderness search and rescue,https://ieeexplore.ieee.org/document/7563746/,"In wilderness search and rescue missions, unmanned aerial vehicles (UAVs) may be deployed to collect high-resolution imagery which is later reviewed by a first responder. The volume of images and the altitude from which they are taken makes manually identifying potential items of interest, like clothing or other man-made material, a difficult task. For this reason, we created a program that automatically detects unusually-colored objects in aerial imagery in order to assist responders in locating signs of missing persons. The program uses the Reed-Xiaoli (RX) spectral anomaly detection algorithm to determine which pixels in an image are anomalous and then generates an ""anomaly map"" where brighter pixels signify greater abnormality. While the RX algorithm has previously been proposed for search and rescue missions, up until now it has not been evaluated in a high-fidelity setting with real responders and real equipment. We tested the program on 150 aerial images taken over the Blanco River area in Hays County, Texas after the May 2015 flooding and demonstrated the results at a workshop on flooding hosted by Texas A&amp;M's Center for Emergency Informatics. Early feedback from responders suggests that RX spectral anomaly detection is a valuable tool for quickly locating atypically-colored objects in images taken with UAVs for wilderness search and rescue.",autonomous vehicle
10.1109/ETFA.2016.7733537,filtered,2016 IEEE 21st International Conference on Emerging Technologies and Factory Automation (ETFA),IEEE,2016-09-09 00:00:00,ieeexplore,UAV degradation identification for pilot notification using machine learning techniques,https://ieeexplore.ieee.org/document/7733537/,"Unmanned Aerial Vehicles are currently investigated as an important sub-domain of robotics, a fast growing and truly multidisciplinary research field. UAVs are increasingly deployed in real-world settings for missions in dangerous environments or in environments which are challenging to access. Combined with autonomous flying capabilities, many new possibilities, but also challenges, open up. To overcome the challenge of early identification of degradation, machine learning based on flight features is a promising direction. Existing approaches build classifiers that consider their features to be correlated. This prevents a fine-grained detection of degradation for the different hardware components. This work presents an approach where the data is considered uncorrelated and, using machine learning techniques, allows the precise identification of UAV's damages.",autonomous vehicle
10.1109/OJCOMS.2020.3010270,filtered,IEEE Open Journal of the Communications Society,IEEE,2020-01-01 00:00:00,ieeexplore,"6G Wireless Communication Systems: Applications, Requirements, Technologies, Challenges, and Research Directions",https://ieeexplore.ieee.org/document/9144301/,"The demand for wireless connectivity has grown exponentially over the last few decades. Fifth-generation (5G) communications, with far more features than fourth-generation communications, will soon be deployed worldwide. A new paradigm of wireless communication, the sixth-generation (6G) system, with the full support of artificial intelligence, is expected to be implemented between 2027 and 2030. Beyond 5G, some fundamental issues that need to be addressed are higher system capacity, higher data rate, lower latency, higher security, and improved quality of service (QoS) compared to the 5G system. This paper presents the vision of future 6G wireless communication and its network architecture. This article describes emerging technologies such as artificial intelligence, terahertz communications, wireless optical technology, free-space optical network, blockchain, three-dimensional networking, quantum communications, unmanned aerial vehicles, cell-free communications, integration of wireless information and energy transfer, integrated sensing and communication, integrated access-backhaul networks, dynamic network slicing, holographic beamforming, backscatter communication, intelligent reflecting surface, proactive caching, and big data analytics that can assist the 6G architecture development in guaranteeing the QoS. Besides, expected applications with 6G communication requirements and possible technologies are presented. We also describe potential challenges and research directions for achieving this goal.",autonomous vehicle
10.1109/JIOT.2019.2917066,filtered,IEEE Internet of Things Journal,IEEE,2019-10-01 00:00:00,ieeexplore,A 64-mW DNN-Based Visual Navigation Engine for Autonomous Nano-Drones,https://ieeexplore.ieee.org/document/8715489/,"Fully miniaturized robots (e.g., drones), with artificial intelligence (AI)-based visual navigation capabilities, are extremely challenging drivers of Internet-of-Things edge intelligence capabilities. Visual navigation based on AI approaches, such as deep neural networks (DNNs) are becoming pervasive for standard-size drones, but are considered out of reach for nano-drones with a size of a few cm<sup>2</sup>. In this paper, we present the first (to the best of our knowledge) demonstration of a navigation engine for autonomous nano-drones capable of closed-loop end-to-end DNN-based visual navigation. To achieve this goal we developed a complete methodology for parallel execution of complex DNNs directly on board resource-constrained milliwatt-scale nodes. Our system is based on GAP8, a novel parallel ultralow-power computing platform, and a 27-g commercial, open-source Crazyflie 2.0 nano-quadrotor. As part of our general methodology, we discuss the software mapping techniques that enable the DroNet state-of-the-art deep convolutional neural network to be fully executed aboard within a strict 6 frame-per-second real-time constraint with no compromise in terms of flight results, while all processing is done with only 64 mW on average. Our navigation engine is flexible and can be used to span a wide performance range: at its peak performance corner, it achieves 18 frames/s while still consuming on average just 3.5% of the power envelope of the deployed nano-aircraft. To share our key findings with the embedded and robotics communities and foster further developments in autonomous nano-unmanned aerial vehicles (UAVs), we publicly release all our code, datasets, and trained networks.",autonomous vehicle
10.1109/OJVT.2020.2971594,filtered,IEEE Open Journal of Vehicular Technology,IEEE,2020-01-01 00:00:00,ieeexplore,A Reinforcement Learning Approach for Fair User Coverage Using UAV Mounted Base Stations Under Energy Constraints,https://ieeexplore.ieee.org/document/8982070/,"Unmanned Aerial Vehicles (UAVs) are gaining popularity in many aspects of wireless communication systems. UAV-mounted mobile base stations (UAV-BSs) are an effective and cost-efficient solution for providing wireless connectivity where fixed infrastructure is not available or destroyed. However, UAV-BSs have their limitations and complications, for instance, limited available energy. In addition, when several UAV-BSs are deployed to provide coverage to a specific area, the possibility of inter-UAV collisions and the interference to ground users increase. We propose Reinforcement Learning (RL) and Deep Reinforcement Learning (DRL) based methods to deploy UAV-BSs under energy constraints to provide efficient and fair coverage to the ground users, while minimising inter-UAV collisions and interference to ground users. The proposed methods outperform the baseline methods by an average increase of 38.94% in system fairness, 42.54% in individual user coverage, and 15.04% in total system coverage, in comparison with the baseline methods.",autonomous vehicle
10.1109/TVT.2020.3023861,filtered,IEEE Transactions on Vehicular Technology,IEEE,2020-11-01 00:00:00,ieeexplore,Age of Information Aware Trajectory Planning of UAVs in Intelligent Transportation Systems: A Deep Learning Approach,https://ieeexplore.ieee.org/document/9195789/,"Unmanned aerial vehicles (UAVs) are envisioned to play a key role in intelligent transportation systems to complement the communication infrastructure in future smart cities. UAV-assisted vehicular networking research typically adopts throughput and latency as the main performance metrics. These conventional metrics, however, are not adequate to reflect the freshness of the information, an attribute that has been recently identified as a critical requirement to enable services such as autonomous driving and accident prevention. In this paper, we consider a UAV-assisted single-hop vehicular network, wherein sensors (e.g., LiDARs and cameras) on vehicles generate time sensitive data streams, and UAVs are used to collect and process this data while maintaining a minimum age of information (AoI). We aim to jointly optimize the trajectories of UAVs and find scheduling policies to keep the information fresh under minimum throughput constraints. The formulated optimization problem is shown to be mixed integer non-linear program (MINLP) and generally hard to be solved. Motivated by the success of machine learning (ML) techniques particularly deep learning in solving complex problems with low complexity, we reformulate the trajectories and scheduling policies problem as a Markov decision process (MDP) where the system state space considers the vehicular network dynamics. Then, we develop deep reinforcement learning (DRL) to learn the vehicular environment and its dynamics in order to handle UAVs' trajectory and scheduling policy. In particular, we leverage Deep Deterministic Policy Gradient (DDPG) for learning the trajectories of the deployed UAVs to efficiently minimize the Expected Weighted Sum AoI (EWSA). Simulations results demonstrate the effectiveness of the proposed design and show the deployed UAVs adapt their velocities during the data collection mission in order to minimize the AoI.",autonomous vehicle
10.1109/TVT.2021.3081049,filtered,IEEE Transactions on Vehicular Technology,IEEE,2021-07-01 00:00:00,ieeexplore,Classifying UAVs With Proprietary Waveforms via Preamble Feature Extraction and Federated Learning,https://ieeexplore.ieee.org/document/9432739/,"Small unmanned aerial vehicles (UAVs) are deployed in a number of different emerging market segments as well as for recreational hobby flying. Driven by their ubiquitous availability, a large number of manufacturers offer UAV models in different form factors, control and load carrying capacities. This paper proposes a deep learning method to detect the type/model of the UAV using the transmitted RF signals, even when these signals follow proprietary medium access protocols whose headers cannot be decoded. The main contributions are as follows: (i) We show how the preamble portion of the packet is better suited for learning subtle protocol-specific differences, instead of randomly selecting any subset of the transmitted packet, (ii) we propose a pre-processing scheme that generates cross-correlation feature maps to enhance the classification accuracy, (iii) we develop a deep convolutional neural architecture that can be trained in data collected from static scenarios and then tested in practical hovering conditions with 98.2% accuracy of UAV model classification, demonstrating robustness to channel variations, and (iv) we extend this model towards a federated learning paradigm where sensors send individually trained models back to a central controller that combines them, without any appreciable loss of accuracy. Our evaluations are performed on an 8.9 GB dataset collected from static and flying UAVs, which we also release as part of the technical contributions of the work.",autonomous vehicle
10.1109/JIOT.2021.3063188,filtered,IEEE Internet of Things Journal,IEEE,2001-08-01 20:21:00,ieeexplore,Collaborative Computation Offloading and Resource Allocation in Multi-UAV-Assisted IoT Networks: A Deep Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/9366889/,"In the fifth-generation (5G) wireless networks, Edge-Internet-of-Things (EIoT) devices are envisioned to generate huge amounts of data. Due to the limitation of computation capacity and battery life of devices, all tasks cannot be processed by these devices. However, mobile-edge computing (MEC) is a very promising solution enabling offloading of tasks to nearby MEC servers to improve quality of service. Also, during emergency situations in areas where network failure exists, unmanned aerial vehicles (UAVs) can be deployed to restore the network by acting as Aerial Base Stations and computational nodes for the edge network. In this article, we consider a central network controller who trains observations and broadcasts the trained data to a multi-UAV cluster network. Each UAV cluster head acts as an agent and autonomously allocates resources to EIoT devices in a decentralized fashion. We propose model-free deep reinforcement learning (DRL)-based collaborative computation offloading and resource allocation (CCORA-DRL) scheme in an aerial to ground (A2G) network for emergency situations, which can control the continuous action space. Each agent learns efficient computation offloading policies independently in the network and checks the statuses of the UAVs through Jain's Fairness index. The objective is minimizing task execution delay and energy consumption and acquiring an efficient solution by adaptive learning from the dynamic A2G network. Simulation results reveal that our scheme through deep deterministic policy gradient, effectively learns the optimal policy, outperforming A3C, deep Q-network and greedy-based offloading for local computation in stochastic dynamic environments.",autonomous vehicle
10.1109/TITS.2020.3039617,filtered,IEEE Transactions on Intelligent Transportation Systems,IEEE,2021-09-01 00:00:00,ieeexplore,Data Freshness and Energy-Efficient UAV Navigation Optimization: A Deep Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/9285214/,"In this paper, we design a navigation policy for multiple unmanned aerial vehicles (UAVs) where mobile base stations (BSs) are deployed to improve the data freshness and connectivity to the Internet of Things (IoT) devices. First, we formulate an energy-efficient trajectory optimization problem in which the objective is to maximize the energy efficiency by optimizing the UAV-BS trajectory policy. We also incorporate different contextual information such as energy and age of information (AoI) constraints to ensure the data freshness at the ground BS. Second, we propose an agile deep reinforcement learning with experience replay model to solve the formulated problem concerning the contextual constraints for the UAV-BS navigation. Moreover, the proposed approach is well-suited for solving the problem, since the state space of the problem is extremely large and finding the best trajectory policy with useful contextual features is too complex for the UAV-BSs. By applying the proposed trained model, an effective real-time trajectory policy for the UAV-BSs captures the observable network states over time. Finally, the simulation results illustrate the proposed approach is 3.6% and 3.13% more energy efficient than those of the greedy and baseline deep Q Network (DQN) approaches.",autonomous vehicle
10.1109/JSAC.2020.3005495,filtered,IEEE Journal on Selected Areas in Communications,IEEE,2020-12-01 00:00:00,ieeexplore,Deep Reinforcement Learning for Dynamic Uplink/Downlink Resource Allocation in High Mobility 5G HetNet,https://ieeexplore.ieee.org/document/9127428/,"Recently, the 5G is widely deployed for supporting communications of high mobility nodes including train, vehicular and unmanned aerial vehicles (UAVs) largely emerged as the main components for constructing the wireless heterogeneous network (HetNet). To further improve the radio utilization, the Time Division Duplex (TDD) is considered to be the potential full-duplex communication technology in the high mobility 5G network. However, the high mobility of users leads to the high dynamic network traffic and unpredicted link state change. A new method to predict the dynamic traffic and channel condition and schedule the TDD configuration in real-time is essential for the high mobility environment. In this paper, we investigate the channel model in the high mobility and heterogeneous network and proposed a novel deep reinforcement learning based intelligent TDD configuration algorithm to dynamically allocate radio resources in an online manner. In the proposal, the deep neural network is employed to extract the features of the complex network information, and the dynamic Q-value iteration based reinforcement learning with experience replay memory mechanism is proposed to adaptively change TDD Up/Down-link ratio by evaluated rewards. The simulation results show that the proposal achieves significant network performance improvement in terms of both network throughput and packet loss rate, comparing with conventional TDD resource allocation algorithms.",autonomous vehicle
10.1109/ACCESS.2020.2981403,filtered,IEEE Access,IEEE,2020-01-01 00:00:00,ieeexplore,Energy Efficient 3-D UAV Control for Persistent Communication Service and Fairness: A Deep Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/9039640/,"Recently, unmanned aerial vehicles (UAVs) as flying wireless communication platform have attracted much attention. Benefiting from the mobility, UAV aerial base stations can be deployed quickly and flexibly, and can effectively establish Line-of-Sight communication links. However, there are many challenges in UAV communication system. The first challenge is energy constraint, where the UAV battery lifetime is in the order of fraction of an hour. The second challenge is that the coverage area of UAV aerial base station is limited and the commercial UAV is usually expensive. Thus, covering a large target region all the time with sufficient UAVs is quite challenging. To solve above challenges, in this paper, we propose energy efficient and fair 3-D UAV scheduling with energy replenishment, where UAVs move around to serve users and recharge timely to replenish energy. Inspired by the success of deep reinforcement learning, we propose a UAV Control policy based on Deep Deterministic Policy Gradient (UC-DDPG) to address the combination problem of 3-D mobility of multiple UAVs and energy replenishment scheduling, which ensures energy efficient and fair coverage of each user in a large region and maintains the persistent service. Simulation results reveal that UC-DDPG shows a good convergence and outperforms other scheduling algorithms in terms of data volume, energy efficiency and fairness.",autonomous vehicle
10.1109/LCOMM.2020.3026033,filtered,IEEE Communications Letters,IEEE,2021-01-01 00:00:00,ieeexplore,Energy-Efficient Resource Management in UAV-Assisted Mobile Edge Computing,https://ieeexplore.ieee.org/document/9204738/,"Unmanned aerial vehicles (UAVs) have been deployed to enhance the network capacity and provide services to mobile users with or without infrastructure coverage. At the same time, we have observed the exponential growth in Internet of Things (IoTs) devices and applications. However, as IoT devices have limited computation capacity and battery lifetime, it is challenging to process data locally on the devices. To this end, in this letter, a UAV-aided mobile edge computing system is proposed. The problem to jointly minimize the energy consumption at the IoT devices and the UAVs during task execution is studied by optimizing the task offloading decision, resource allocation mechanism and UAV's trajectory while considering the communication and computation latency requirements. A non-convex structure of the formulated problem is revealed and shown to be challenging to solve. To address this challenge, a block successive upper-bound minimization (BSUM) algorithm is introduced. Finally, simulation results are provided to show the efficiency of our proposed algorithm.",autonomous vehicle
10.1109/JIOT.2019.2923702,filtered,IEEE Internet of Things Journal,IEEE,2019-10-01 00:00:00,ieeexplore,Hierarchical Game-Theoretic and Reinforcement Learning Framework for Computational Offloading in UAV-Enabled Mobile Edge Computing Networks With Multiple Service Providers,https://ieeexplore.ieee.org/document/8740949/,"We present a novel game-theoretic (GT) and reinforcement learning (RL) framework for computational offloading in the mobile edge computing (MEC) network operated by multiple service providers (SPs). The network is formed by MEC servers installed at stationary base stations (BSs) and unmanned aerial vehicles (UAVs) deployed as quasi-stationary BSs. Since computing powers of MEC servers are limited, the BSs in proximity can form coalitions with shared data processing resources to serve their users more efficiently. However, as BSs can be privately owned or controlled by different SPs, in any coalition, the BSs: 1) take only the actions that maximize their long-term payoffs and 2) do not coordinate their actions with other BSs in the coalition. That is, inside each coalition, BSs act in an independent and self-interested manner. Therefore, the interactions among BSs cannot be described by conventional coalitional games. Instead, the network operation is modeled by a two-level hierarchical model. The upper level is a cooperative game that defines the process of coalition formation. The lower level comprises the set of noncooperative subgames to represent a self-interested and independent behavior of BSs in coalitions. To enable each BS to select a coalition and decide on its action maximizing its long-term payoff, we propose two algorithms that combine coalition formation with RL and prove that these algorithms converge to the states where the coalitional structure is strongly stable and the strategies of BSs are in the mixed-strategy Nash equilibrium (NE).",autonomous vehicle
10.1109/JIOT.2021.3058236,filtered,IEEE Internet of Things Journal,IEEE,2021-04-01 00:00:00,ieeexplore,Learning-Based Queue-Aware Task Offloading and Resource Allocation for Space–Air–Ground-Integrated Power IoT,https://ieeexplore.ieee.org/document/9351533/,"Space-air-ground-integrated power Internet of Things (SAG-PIoT) can provide ubiquitous communication and computing services for PIoT devices deployed in remote areas. In SAG-PIoT, the tasks can be either processed locally by PIoT devices, offloaded to edge servers through unmanned aerial vehicles (UAVs), or offloaded to cloud servers through satellites. However, the joint optimization of task offloading and computational resource allocation faces several challenges, such as incomplete information, dimensionality curse, and coupling between long-term constraints of queuing delay and short-term decision making. In this article, we propose a learning-based queue-aware task offloading and resource allocation algorithm (QUARTER). Specifically, the joint optimization problem is decomposed into three deterministic subproblems: 1) device-side task splitting and resource allocation; 2) task offloading; and 3) server-side resource allocation. The first subproblem is solved by the Lagrange dual decomposition. For the second subproblem, we propose a queue-aware actor-critic-based task offloading algorithm to cope with dimensionality curse. A greedy-based low-complexity algorithm is developed to solve the third subproblem. Compared with existing algorithms, simulation results demonstrate that QUARTER has superior performances in energy consumption, queuing delay, and convergence.",autonomous vehicle
10.1109/TMC.2020.2991326,filtered,IEEE Transactions on Mobile Computing,IEEE,2021-09-01 00:00:00,ieeexplore,Leveraging UAVs for Coverage in Cell-Free Vehicular Networks: A Deep Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/9082162/,"The success in transitioning towards smart cities relies on the availability of information and communication technologies that meet the demands of this transformation. The terrestrial infrastructure presents itself as a preeminent component in this change. Unmanned aerial vehicles (UAVs) empowered with artificial intelligence (AI) are expected to become an integral component of future smart cities that provide seamless coverage for vehicles on highways with poor cellular infrastructure. Motivated by the above, in this paper, we introduce UAVs cell-free network for providing coverage to vehicles entering a highway that is not covered by other infrastructure. However, UAVs have limited energy resources and cannot serve the entire highway all the time. Furthermore, the deployed UAVs have insufficient knowledge about the environment (e.g., the vehicles' instantaneous location). Therefore, it is challenging to control a swarm of UAVs to achieve efficient communication coverage. To address these challenges, we formulate the trajectories decisions making as a Markov decision process (MDP) where the system state space considers the vehicular network dynamics. Then, we leverage deep reinforcement learning (DRL) to propose an approach for learning the optimal trajectories of the deployed UAVs to efficiently maximize the vehicular coverage, where we adopt Actor-Critic algorithm to learn the vehicular environment and its dynamics to handle the complex continuous action space. Finally, simulations results are provided to verify our findings and demonstrate the effectiveness of the proposed design and show that during the mission time, the deployed UAVs adapt their velocities in order to cover the vehicles.",autonomous vehicle
10.1109/OJCOMS.2021.3081996,filtered,IEEE Open Journal of the Communications Society,IEEE,2021-01-01 00:00:00,ieeexplore,Multi-UAV Path Planning for Wireless Data Harvesting With Deep Reinforcement Learning,https://ieeexplore.ieee.org/document/9437338/,"Harvesting data from distributed Internet of Things (IoT) devices with multiple autonomous unmanned aerial vehicles (UAVs) is a challenging problem requiring flexible path planning methods. We propose a multi-agent reinforcement learning (MARL) approach that, in contrast to previous work, can adapt to profound changes in the scenario parameters defining the data harvesting mission, such as the number of deployed UAVs, number, position and data amount of IoT devices, or the maximum flying time, without the need to perform expensive recomputations or relearn control policies. We formulate the path planning problem for a cooperative, non-communicating, and homogeneous team of UAVs tasked with maximizing collected data from distributed IoT sensor nodes subject to flying time and collision avoidance constraints. The path planning problem is translated into a decentralized partially observable Markov decision process (Dec-POMDP), which we solve through a deep reinforcement learning (DRL) approach, approximating the optimal UAV control policy without prior knowledge of the challenging wireless channel characteristics in dense urban environments. By exploiting a combination of centered global and local map representations of the environment that are fed into convolutional layers of the agents, we show that our proposed network architecture enables the agents to cooperate effectively by carefully dividing the data collection task among themselves, adapt to large complex environments and state spaces, and make movement decisions that balance data collection goals, flight-time efficiency, and navigation constraints. Finally, learning a control policy that generalizes over the scenario parameter space enables us to analyze the influence of individual parameters on collection performance and provide some intuition about system-level benefits.",autonomous vehicle
10.1109/JSAC.2021.3088694,filtered,IEEE Journal on Selected Areas in Communications,IEEE,2021-10-01 00:00:00,ieeexplore,Multi-UAV Trajectory and Power Optimization for Cached UAV Wireless Networks With Energy and Content Recharging-Demand Driven Deep Learning Approach,https://ieeexplore.ieee.org/document/9454157/,"In this paper, we propose a novel joint trajectory and communication scheduling scheme for multiple unmanned aerial vehicles (UAVs) enabled wireless caching networks. To exploit the favorable propagation of air-to-ground channels, we consider an ultra dense UAVs enabled content-centric wireless transmission network, where massive UAVs are deployed to transmit cached contents to a group of random distributed ground users. We formulate the problem as an infinite horizon ergodic stochastic differential game (SDG) for optimizing the users’ quality-of-experience (QoE). In particular, stochastic dynamics of channel states, UAVs’ mobility, energy queues and content request queues are modeled in this game. To deal with the state coupling between the UAVs, we consider a limiting problem for large number of UAV based on mean field analysis. A reduced-complexity decentralized solution can be obtained through mean-field equilibrium analysis. To further reduce the solution complexity on each UAV, we propose a model-specific deep neural network (DNN) to learn the optimal control solution in an online manner. The DNN is not arbitrarily generated but tailored to the structural properties of the value function and stationary distribution based on the homotopy perturbation method analysis. Finally, simulation results are provided to show that the proposed solution can achieve significant gain over the existing baselines.",autonomous vehicle
10.1109/JIOT.2020.3016694,filtered,IEEE Internet of Things Journal,IEEE,2021-06-15 00:00:00,ieeexplore,Offloading Optimization in Edge Computing for Deep-Learning-Enabled Target Tracking by Internet of UAVs,https://ieeexplore.ieee.org/document/9167249/,"The empowering unmanned aerial vehicles (UAVs) have been extensively used in providing intelligence such as target tracking. In our field experiments, a pretrained convolutional neural network (CNN) is deployed at UAV to identify a target (a vehicle) from the captured video frames and enable the UAV to keep tracking. However, this kind of visual target tracking demands a lot of computational resources due to the desired high inference accuracy and stringent delay requirement. This motivates us to consider offloading this type of deep learning (DL) tasks to a mobile-edge computing (MEC) server due to the limited computational resource and energy budget of the UAV and further improve the inference accuracy. Specifically, we propose a novel hierarchical DL tasks distribution framework, where the UAV is embedded with lower layers of the pretrained CNN model while the MEC server (MES) with rich computing resources will handle the higher layers of the CNN model. An optimization problem is formulated to minimize the weighted-sum cost, including the tracking delay and energy consumption introduced by communication and computing of UAVs while taking into account the quality of data (e.g., video frames) input to the DL model and the inference errors. Analytical results are obtained and insights are provided to understand the tradeoff between the weighted-sum cost and inference error rate in the proposed framework. Numerical results demonstrate the effectiveness of the proposed offloading framework.",autonomous vehicle
10.1109/ACCESS.2021.3111964,filtered,IEEE Access,IEEE,2021-01-01 00:00:00,ieeexplore,Proactive Power Control and Position Deployment for Drone Small Cells: Joint Supervised and Unsupervised Learning,https://ieeexplore.ieee.org/document/9535513/,"Since unmanned aerial vehicles (UAV) are easily deployed, highly mobile, and hover capability, they are utilized for many commercial applications. In particular, small cells mounted on UAVs, also known as drone small cells (DSC), may provide temporary relief or ancillary programs for the wireless network. In this paper, we design a prediction-based proactive drone management (P<sup>2</sup>DM) framework to reduce network interference and improve energy efficiency in the multiple DSCs scenario. The P<sup>2</sup>DM framework can be divided into offline and online phases. In the offline phase, supervised learning is used to build a highly accurate mobility prediction model according to the historical data. The prediction model is launched in the online phase to predict the user position only using a small sample set. The system proactively determines whether a DSC should be awake or asleep at the next timeslot due to the predicted user positions. Since DSC has more longer awake time in the deep sleeping mode, it is previously awoken to avoid data propagation delay. To further overcome the difficulty of obtaining the key performance indicator data (i.e., labeled data) in the online phase, an unsupervised learning technique is employed for DSC repositioning and power control to improve energy efficiency. Our simulation results show that the P<sup>2</sup>DM framework can demonstrate the advantage in terms of execution time and energy efficiency compared to the existing method based on genetic algorithm (i.e., a heuristic algorithm).",autonomous vehicle
10.1109/TVT.2021.3074304,filtered,IEEE Transactions on Vehicular Technology,IEEE,2021-05-01 00:00:00,ieeexplore,Sustainable Task Offloading in UAV Networks via Multi-Agent Reinforcement Learning,https://ieeexplore.ieee.org/document/9409695/,"The recent growth of IoT devices, along with edge computing, has revealed many opportunities for novel applications. Among them, Unmanned Aerial Vehicles (UAVs), which are deployed for surveillance and environmental monitoring, are attracting increasing attention. In this context, typical solutions must deal with events that may change the state of the network, providing a service that continuously maintains a high level of performance. In this paper, we address this problem by proposing a distributed architecture that leverages a Multi-Agent Reinforcement Learning (MARL) technique to dynamically offload tasks from UAVs to the edge cloud. Nodes of the system co-operate to jointly minimize the overall latency perceived by the user and the energy usage on UAVs by continuously learning from the environment the best action, which entails the decision of offloading and, in this case, the best transmission technology, i.e., Wi-Fi or cellular. Results validate our distributed architecture and show the effectiveness of the approach in reaching the above targets.",autonomous vehicle
10.1109/LNET.2020.2966976,filtered,IEEE Networking Letters,IEEE,2020-03-01 00:00:00,ieeexplore,Trajectory Planning of Multiple Dronecells in Vehicular Networks: A Reinforcement Learning Approach,https://ieeexplore.ieee.org/document/8960481/,"The agility of unmanned aerial vehicles (UAVs) have been recently harnessed in developing potential solutions that provide seamless coverage for vehicles in areas with poor cellular infrastructure. In this letter, multiple UAVs are deployed to provide the needed cellular coverage to vehicles traveling with random speeds over a given highway segment. This letter minimizes the number of deployed UAVs and optimizes their trajectories to offer prevalent communication coverage to all vehicles crossing the highway segment while saving energy consumption of the UAVs. Due to varying traffic conditions on the highway, a reinforcement learning approach is utilized to govern the number of needed UAVs and their trajectories to serve the existing and newly arriving vehicles. Numerical results demonstrate the effectiveness of the proposed design and show that during the mission time, a minimum number of UAVs adapt their velocities in order to cover the vehicles.",autonomous vehicle
10.1007/s10664-021-09982-4,filtered,Empirical Software Engineering,Springer,2021-07-05 00:00:00,springer,Can Offline Testing of Deep Neural Networks Replace Their Online Testing?,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10664-021-09982-4,"We distinguish two general modes of testing for Deep Neural Networks (DNNs): Offline testing where DNNs are tested as individual units based on test datasets obtained without involving the DNNs under test, and online testing where DNNs are embedded into a specific application environment and tested in a closed-loop mode in interaction with the application environment. Typically, DNNs are subjected to both types of testing during their development life cycle where offline testing is applied immediately after DNN training and online testing follows after offline testing and once a DNN is deployed within a specific application environment. In this paper, we study the relationship between offline and online testing. Our goal is to determine how offline testing and online testing differ or complement one another and if offline testing results can be used to help reduce the cost of online testing? Though these questions are generally relevant to all autonomous systems, we study them in the context of automated driving systems where, as study subjects, we use DNNs automating end-to-end controls of steering functions of self-driving vehicles. Our results show that offline testing is less effective than online testing as many safety violations identified by online testing could not be identified by offline testing, while large prediction errors generated by offline testing always led to severe safety violations detectable by online testing. Further, we cannot exploit offline testing results to reduce the cost of online testing in practice since we are not able to identify specific situations where offline testing could be as accurate as online testing in identifying safety requirement violations.",autonomous vehicle
10.1007/978-3-030-72065-0_18,filtered,Machine Intelligence and Data Analytics for Sustainable Future Smart Cities,Springer,2021-01-01 00:00:00,springer,Artificial Intelligence Techniques in Smart Cities Surveillance Using UAVs: A Survey,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-72065-0_18,"The security and urbanization challenge is expected to rise to 90% by 2050, and to leverage existing resources, technology is the solitary means to cope with this anticipated raise in entail. The Smart City is focused on the smooth convergence of Information and Communication Technology with the most technological innovations like well-connected home and equipment. Smart city augments the lifestyle of its residents by providing efficacious infrastructure and enhanced security. Surveillance is a recurring and monotonous assignment that descends the performance of human guards when continued for a longer period of time. Unmanned Aerial Vehicles (UAVs) or Drones can be deployed as security cameras to augment human guards. It can be deployed to track intruders, monitor unusual activities such as theft, violence and unprecedented corona-virus pandemic scenarios. UAV based visual surveillance in Smart cities, produces a huge amount of multimedia data. The need to process and analyze the data automatically in real-time is critical. Artificial Intelligence and Deep learning imitates human intelligence and provides excellent analytical capabilities to learn about complex data obtained in real environments. The integrated solution of Deep learning technology with the UAVs an electronic eye-in-the-sky has leveraged the capability of detection, recognition and deterrence in a scalable surveillance system. A comprehensive review on the potential benefits of UAVs and its applications for surveillance in smart cities has been presented. This chapter elaborates seamless integration of UAVs and Deep Learning technologies solutions for smart city surveillance. The paper concludes with a description of main challenges for the application of UAVs in deep learning solutions.",autonomous vehicle
http://arxiv.org/abs/2107.00401v1,filtered,arxiv,arxiv,2021-07-01 12:20:48+00:00,arxiv,"CarSNN: An Efficient Spiking Neural Network for Event-Based Autonomous
  Cars on the Loihi Neuromorphic Research Processor",http://arxiv.org/abs/2107.00401v1,"Autonomous Driving (AD) related features provide new forms of mobility that
are also beneficial for other kind of intelligent and autonomous systems like
robots, smart transportation, and smart industries. For these applications, the
decisions need to be made fast and in real-time. Moreover, in the quest for
electric mobility, this task must follow low power policy, without affecting
much the autonomy of the mean of transport or the robot. These two challenges
can be tackled using the emerging Spiking Neural Networks (SNNs). When deployed
on a specialized neuromorphic hardware, SNNs can achieve high performance with
low latency and low power consumption. In this paper, we use an SNN connected
to an event-based camera for facing one of the key problems for AD, i.e., the
classification between cars and other objects. To consume less power than
traditional frame-based cameras, we use a Dynamic Vision Sensor (DVS). The
experiments are made following an offline supervised learning rule, followed by
mapping the learnt SNN model on the Intel Loihi Neuromorphic Research Chip. Our
best experiment achieves an accuracy on offline implementation of 86%, that
drops to 83% when it is ported onto the Loihi Chip. The Neuromorphic Hardware
implementation has maximum 0.72 ms of latency for every sample, and consumes
only 310 mW. To the best of our knowledge, this work is the first
implementation of an event-based car classifier on a Neuromorphic Chip.",autonomous vehicle
http://arxiv.org/abs/1707.02589v1,filtered,arxiv,arxiv,2017-07-09 14:50:02+00:00,arxiv,"Exploiting the Tradeoff between Program Accuracy and Soft-error
  Resiliency Overhead for Machine Learning Workloads",http://arxiv.org/abs/1707.02589v1,"To protect multicores from soft-error perturbations, resiliency schemes have
been developed with high coverage but high power and performance overheads.
Emerging safety-critical machine learning applications are increasingly being
deployed on these platforms. Moreover, these systems are exposed to harsh
environments, such as unmanned aerial vehicles (UAVs) and self-driving cars.
Due to the unique structure and computational behavior of such applications,
research has been done on relaxing their accuracy for performance benefits. We
observe that not all transient errors affect program correctness, some errors
only affect program accuracy, i.e., the program completes with certain
acceptable deviations from error free outcome. This paper illustrates the idea
of cross-layer soft-error resilience using machine learning workloads, where
program accuracy is introduced as a tradeoff to deliver resilient yet efficient
execution on futuristic large-scale multicores.",autonomous vehicle
http://arxiv.org/abs/1910.05309v1,filtered,arxiv,arxiv,2019-09-25 16:22:29+00:00,arxiv,"Communications and Networking Technologies for Intelligent Drone
  Cruisers",http://arxiv.org/abs/1910.05309v1,"Future mobile communication networks require an Aerial Base Station (ABS)
with fast mobility and long-term hovering capabilities. At present, unmanned
aerial vehicles (UAV) or drones do not have long flight times and are mainly
used for monitoring, surveillance, and image post-processing. On the other
hand, the traditional airship is too large and not easy to take off and land.
Therefore, we propose to develop an ""Artificial Intelligence (AI)
Drone-Cruiser"" base station that can help 5G mobile communication systems and
beyond quickly recover the network after a disaster and handle the instant
communications by the flash crowd. The drone-cruiser base station can overcome
the communications problem for three types of flash crowds, such as in
stadiums, parades, and large plaza so that an appropriate number of aerial base
stations can be accurately deployed to meet large and dynamic traffic demands.
Artificial intelligence can solve these problems by analyzing the collected
data, and then adjust the system parameters in the framework of Self-Organizing
Network (SON) to achieve the goals of self-configuration, self-optimization,
and self-healing. With the help of AI technologies, 5G networks can become more
intelligent. This paper aims to provide a new type of service, On-Demand Aerial
Base Station as a Service. This work needs to overcome the following five
technical challenges: innovative design of drone-cruisers for the long-time
hovering, crowd estimation and prediction, rapid 3D wireless channel learning
and modeling, 3D placement of aerial base stations and the integration of WiFi
front-haul and millimeter wave/WiGig back-haul networks.",autonomous vehicle
http://arxiv.org/abs/1906.05023v1,filtered,arxiv,arxiv,2019-06-12 09:21:41+00:00,arxiv,"Towards Big data processing in IoT: Path Planning and Resource
  Management of UAV Base Stations in Mobile-Edge Computing System",http://arxiv.org/abs/1906.05023v1,"Heavy data load and wide cover range have always been crucial problems for
online data processing in internet of things (IoT). Recently, mobile-edge
computing (MEC) and unmanned aerial vehicle base stations (UAV-BSs) have
emerged as promising techniques in IoT. In this paper, we propose a three-layer
online data processing network based on MEC technique. On the bottom layer, raw
data are generated by widely distributed sensors, which reflects local
information. Upon them, unmanned aerial vehicle base stations (UAV-BSs) are
deployed as moving MEC servers, which collect data and conduct initial steps of
data processing. On top of them, a center cloud receives processed results and
conducts further evaluation. As this is an online data processing system, the
edge nodes should stabilize delay to ensure data freshness. Furthermore,
limited onboard energy poses constraints to edge processing capability. To
smartly manage network resources for saving energy and stabilizing delay, we
develop an online determination policy based on Lyapunov Optimization. In cases
of low data rate, it tends to reduce edge processor frequency for saving
energy. In the presence of high data rate, it will smartly allocate bandwidth
for edge data offloading. Meanwhile, hovering UAV-BSs bring a large and
flexible service coverage, which results in the problem of effective path
planning. In this paper, we apply deep reinforcement learning and develop an
online path planning algorithm. Taking observations of around environment as
input, a CNN network is trained to predict the reward of each action. By
simulations, we validate its effectiveness in enhancing service coverage. The
result will contribute to big data processing in future IoT.",autonomous vehicle
http://arxiv.org/abs/1611.06474v2,filtered,arxiv,arxiv,2016-11-20 05:54:06+00:00,arxiv,"Nazr-CNN: Fine-Grained Classification of UAV Imagery for Damage
  Assessment",http://arxiv.org/abs/1611.06474v2,"We propose Nazr-CNN1, a deep learning pipeline for object detection and
fine-grained classification in images acquired from Unmanned Aerial Vehicles
(UAVs) for damage assessment and monitoring. Nazr-CNN consists of two
components. The function of the first component is to localize objects (e.g.
houses or infrastructure) in an image by carrying out a pixel-level
classification. In the second component, a hidden layer of a Convolutional
Neural Network (CNN) is used to encode Fisher Vectors (FV) of the segments
generated from the first component in order to help discriminate between
different levels of damage. To showcase our approach we use data from UAVs that
were deployed to assess the level of damage in the aftermath of a devastating
cyclone that hit the island of Vanuatu in 2015. The collected images were
labeled by a crowdsourcing effort and the labeling categories consisted of
fine-grained levels of damage to built structures. Since our data set is
relatively small, a pre- trained network for pixel-level classification and FV
encoding was used. Nazr-CNN attains promising results both for object detection
and damage assessment suggesting that the integrated pipeline is robust in the
face of small data sets and labeling errors by annotators. While the focus of
Nazr-CNN is on assessment of UAV images in a post-disaster scenario, our
solution is general and can be applied in many diverse settings. We show one
such case of transfer learning to assess the level of damage in aerial images
collected after a typhoon in Philippines.",autonomous vehicle
http://arxiv.org/abs/2008.08001v1,filtered,arxiv,arxiv,2020-08-18 16:00:36+00:00,arxiv,"Offloading Optimization in Edge Computing for Deep Learning Enabled
  Target Tracking by Internet-of-UAVs",http://arxiv.org/abs/2008.08001v1,"The empowering unmanned aerial vehicles (UAVs) have been extensively used in
providing intelligence such as target tracking. In our field experiments, a
pre-trained convolutional neural network (CNN) is deployed at the UAV to
identify a target (a vehicle) from the captured video frames and enable the UAV
to keep tracking. However, this kind of visual target tracking demands a lot of
computational resources due to the desired high inference accuracy and
stringent delay requirement. This motivates us to consider offloading this type
of deep learning (DL) tasks to a mobile edge computing (MEC) server due to
limited computational resource and energy budget of the UAV, and further
improve the inference accuracy. Specifically, we propose a novel hierarchical
DL tasks distribution framework, where the UAV is embedded with lower layers of
the pre-trained CNN model, while the MEC server with rich computing resources
will handle the higher layers of the CNN model. An optimization problem is
formulated to minimize the weighted-sum cost including the tracking delay and
energy consumption introduced by communication and computing of the UAVs, while
taking into account the quality of data (e.g., video frames) input to the DL
model and the inference errors. Analytical results are obtained and insights
are provided to understand the tradeoff between the weighted-sum cost and
inference error rate in the proposed framework. Numerical results demonstrate
the effectiveness of the proposed offloading framework.",autonomous vehicle
http://arxiv.org/abs/1909.11315v1,filtered,arxiv,arxiv,2019-09-25 07:27:18+00:00,arxiv,"6G Wireless Communication Systems: Applications, Requirements,
  Technologies, Challenges, and Research Directions",http://arxiv.org/abs/1909.11315v1,"Fifth-generation (5G) communication, which has many more features than
fourth-generation communication, will be officially launched very soon. A new
paradigm of wireless communication, the sixth-generation (6G) system, with the
full support of artificial intelligence is expected to be deployed between 2027
and 2030. In beyond 5G, there are some fundamental issues, which need to be
addressed are higher system capacity, higher data rate, lower latency, and
improved quality of service (QoS) compared to 5G system. This paper presents
the vision of future 6G wireless communication and its network architecture. We
discuss the emerging technologies such as artificial intelligence, terahertz
communications, optical wireless technology, free space optic network,
blockchain, three-dimensional networking, quantum communications, unmanned
aerial vehicle, cell-free communications, integration of wireless information
and energy transfer, integration of sensing and communication, integration of
access-backhaul networks, dynamic network slicing, holographic beamforming, and
big data analytics that can assist the 6G architecture development in
guaranteeing the QoS. We present the expected applications with the
requirements and the possible technologies for 6G communication. We also
outline the possible challenges and research directions to reach this goal.",autonomous vehicle
http://arxiv.org/abs/2103.02676v1,filtered,arxiv,arxiv,2021-03-03 20:54:19+00:00,arxiv,Efficient UAV Trajectory-Planning using Economic Reinforcement Learning,http://arxiv.org/abs/2103.02676v1,"Advances in unmanned aerial vehicle (UAV) design have opened up applications
as varied as surveillance, firefighting, cellular networks, and delivery
applications. Additionally, due to decreases in cost, systems employing fleets
of UAVs have become popular. The uniqueness of UAVs in systems creates a novel
set of trajectory or path planning and coordination problems. Environments
include many more points of interest (POIs) than UAVs, with obstacles and
no-fly zones. We introduce REPlanner, a novel multi-agent reinforcement
learning algorithm inspired by economic transactions to distribute tasks
between UAVs. This system revolves around an economic theory, in particular an
auction mechanism where UAVs trade assigned POIs. We formulate the path
planning problem as a multi-agent economic game, where agents can cooperate and
compete for resources. We then translate the problem into a Partially
Observable Markov decision process (POMDP), which is solved using a
reinforcement learning (RL) model deployed on each agent. As the system
computes task distributions via UAV cooperation, it is highly resilient to any
change in the swarm size. Our proposed network and economic game architecture
can effectively coordinate the swarm as an emergent phenomenon while
maintaining the swarm's operation. Evaluation results prove that REPlanner
efficiently outperforms conventional RL-based trajectory search.",autonomous vehicle
http://arxiv.org/abs/2003.04816v1,filtered,arxiv,arxiv,2020-02-21 07:29:15+00:00,arxiv,"Data Freshness and Energy-Efficient UAV Navigation Optimization: A Deep
  Reinforcement Learning Approach",http://arxiv.org/abs/2003.04816v1,"In this paper, we design a navigation policy for multiple unmanned aerial
vehicles (UAVs) where mobile base stations (BSs) are deployed to improve the
data freshness and connectivity to the Internet of Things (IoT) devices. First,
we formulate an energy-efficient trajectory optimization problem in which the
objective is to maximize the energy efficiency by optimizing the UAV-BS
trajectory policy. We also incorporate different contextual information such as
energy and age of information (AoI) constraints to ensure the data freshness at
the ground BS. Second, we propose an agile deep reinforcement learning with
experience replay model to solve the formulated problem concerning the
contextual constraints for the UAV-BS navigation. Moreover, the proposed
approach is well-suited for solving the problem, since the state space of the
problem is extremely large and finding the best trajectory policy with useful
contextual features is too complex for the UAV-BSs. By applying the proposed
trained model, an effective real-time trajectory policy for the UAV-BSs
captures the observable network states over time. Finally, the simulation
results illustrate the proposed approach is 3.6% and 3.13% more energy
efficient than those of the greedy and baseline deep Q Network (DQN)
approaches.",autonomous vehicle
http://arxiv.org/abs/2103.15374v1,filtered,arxiv,arxiv,2021-03-29 07:02:36+00:00,arxiv,"Lifelong Learning for Minimizing Age of Information in Internet of
  Things Networks",http://arxiv.org/abs/2103.15374v1,"In this paper, a lifelong learning problem is studied for an Internet of
Things (IoT) system. In the considered model, each IoT device aims to balance
its information freshness and energy consumption tradeoff by controlling its
computational resource allocation at each time slot under dynamic environments.
An unmanned aerial vehicle (UAV) is deployed as a flying base station so as to
enable the IoT devices to adapt to novel environments. To this end, a new
lifelong reinforcement learning algorithm, used by the UAV, is proposed in
order to adapt the operation of the devices at each visit by the UAV. By using
the experience from previously visited devices and environments, the UAV can
help devices adapt faster to future states of their environment. To do so, a
knowledge base shared by all devices is maintained at the UAV. Simulation
results show that the proposed algorithm can converge $25\%$ to $50\%$ faster
than a policy gradient baseline algorithm that optimizes each device's decision
making problem in isolation.",autonomous vehicle
http://arxiv.org/abs/2105.01606v1,filtered,arxiv,arxiv,2021-05-04 16:29:44+00:00,arxiv,"Deep Reinforcement Learning for Adaptive Exploration of Unknown
  Environments",http://arxiv.org/abs/2105.01606v1,"Performing autonomous exploration is essential for unmanned aerial vehicles
(UAVs) operating in unknown environments. Often, these missions start with
building a map for the environment via pure exploration and subsequently using
(i.e. exploiting) the generated map for downstream navigation tasks.
Accomplishing these navigation tasks in two separate steps is not always
possible or even disadvantageous for UAVs deployed in outdoor and dynamically
changing environments. Current exploration approaches either use a priori
human-generated maps or use heuristics such as frontier-based exploration.
Other approaches use learning but focus only on learning policies for specific
tasks by either using sample inefficient random exploration or by making
impractical assumptions about full map availability. In this paper, we develop
an adaptive exploration approach to trade off between exploration and
exploitation in one single step for UAVs searching for areas of interest (AoIs)
in unknown environments using Deep Reinforcement Learning (DRL). The proposed
approach uses a map segmentation technique to decompose the environment map
into smaller, tractable maps. Then, a simple information gain function is
repeatedly computed to determine the best target region to search during each
iteration of the process. DDQN and A2C algorithms are extended with a stack of
LSTM layers and trained to generate optimal policies for the exploration and
exploitation, respectively. We tested our approach in 3 different tasks against
4 baselines. The results demonstrate that our proposed approach is capable of
navigating through randomly generated environments and covering more AoI in
less time steps compared to the baselines.",autonomous vehicle
http://arxiv.org/abs/2106.00845v1,filtered,arxiv,arxiv,2021-06-01 22:49:42+00:00,arxiv,"Energy-aware placement optimization of UAV base stations via
  decentralized multi-agent Q-learning",http://arxiv.org/abs/2106.00845v1,"Unmanned aerial vehicles serving as aerial base stations (UAV-BSs) can be
deployed to provide wireless connectivity to ground devices in events of
increased network demand, points-of-failure in existing infrastructure, or
disasters. However, it is challenging to conserve the energy of UAVs during
prolonged coverage tasks, considering their limited on-board battery capacity.
Reinforcement learning-based (RL) approaches have been previously used to
improve energy utilization of multiple UAVs, however, a central cloud
controller is assumed to have complete knowledge of the end-devices' locations,
i.e., the controller periodically scans and sends updates for UAV
decision-making. This assumption is impractical in dynamic network environments
with mobile ground devices. To address this problem, we propose a decentralized
Q-learning approach, where each UAV-BS is equipped with an autonomous agent
that maximizes the connectivity to ground devices while improving its energy
utilization. Experimental results show that the proposed design significantly
outperforms the centralized approaches in jointly maximizing the number of
connected ground devices and the energy utilization of the UAV-BSs.",autonomous vehicle
http://arxiv.org/abs/2106.03129v1,filtered,arxiv,arxiv,2021-06-06 14:08:41+00:00,arxiv,"3D UAV Trajectory and Data Collection Optimisation via Deep
  Reinforcement Learning",http://arxiv.org/abs/2106.03129v1,"Unmanned aerial vehicles (UAVs) are now beginning to be deployed for
enhancing the network performance and coverage in wireless communication.
However, due to the limitation of their on-board power and flight time, it is
challenging to obtain an optimal resource allocation scheme for the
UAV-assisted Internet of Things (IoT). In this paper, we design a new
UAV-assisted IoT systems relying on the shortest flight path of the UAVs while
maximising the amount of data collected from IoT devices. Then, a deep
reinforcement learning-based technique is conceived for finding the optimal
trajectory and throughput in a specific coverage area. After training, the UAV
has the ability to autonomously collect all the data from user nodes at a
significant total sum-rate improvement while minimising the associated
resources used. Numerical results are provided to highlight how our techniques
strike a balance between the throughput attained, trajectory, and the time
spent. More explicitly, we characterise the attainable performance in terms of
the UAV trajectory, the expected reward and the total sum-rate.",autonomous vehicle
http://arxiv.org/abs/2101.06414v1,filtered,arxiv,arxiv,2021-01-16 09:20:46+00:00,arxiv,"Towards Deep Learning Assisted Autonomous UAVs for Manipulation Tasks in
  GPS-Denied Environments",http://arxiv.org/abs/2101.06414v1,"In this work, we present a pragmatic approach to enable unmanned aerial
vehicle (UAVs) to autonomously perform highly complicated tasks of object pick
and place. This paper is largely inspired by challenge-2 of MBZIRC 2020 and is
primarily focused on the task of assembling large 3D structures in outdoors and
GPS-denied environments. Primary contributions of this system are: (i) a novel
computationally efficient deep learning based unified multi-task visual
perception system for target localization, part segmentation, and tracking,
(ii) a novel deep learning based grasp state estimation, (iii) a retracting
electromagnetic gripper design, (iv) a remote computing approach which exploits
state-of-the-art MIMO based high speed (5000Mb/s) wireless links to allow the
UAVs to execute compute intensive tasks on remote high end compute servers, and
(v) system integration in which several system components are weaved together
in order to develop an optimized software stack. We use DJI Matrice-600 Pro, a
hex-rotor UAV and interface it with the custom designed gripper. Our framework
is deployed on the specified UAV in order to report the performance analysis of
the individual modules. Apart from the manipulation system, we also highlight
several hidden challenges associated with the UAVs in this context.",autonomous vehicle
http://arxiv.org/abs/1703.10049v4,filtered,arxiv,arxiv,2017-03-29 14:12:42+00:00,arxiv,"Autonomous Recharging and Flight Mission Planning for Battery-operated
  Autonomous Drones",http://arxiv.org/abs/1703.10049v4,"Unmanned aerial vehicles (UAVs), commonly known as drones, are being
increasingly deployed throughout the globe as a means to streamline logistic
and monitoring routines. When dispatched on autonomous missions, drones require
an intelligent decision-making system for trajectory planning and tour
optimization. Given the limited capacity of their onboard batteries, a key
design challenge is ensuring the underlying algorithms can efficiently optimize
the mission objectives along with recharging operations during long-haul
flights. Against this backdrop, the present work undertakes a comprehensive
study on automated management systems for battery-constrained drones: (1) We
construct a machine learning model to estimate the energy expenditure of
drones, considering diverse real-world factors and flight scenarios. (2)
Leveraging this model, the joint problem of flight mission planning and
recharging optimization is formulated as a multi-criteria combinatorial program
aimed at completing a tour mission for a set of target sites in the shortest
time while minimizing recharging duration. (3) We devise an efficient
approximation algorithm, with provable near-optimal performance guarantees, and
implement it in a drone management system, which supports real-time flight path
tracking and re-computation in dynamic environments. (4) We validate the
effectiveness and practicality of the proposed approach through extensive
numerical simulations as well as real-world experiments.",autonomous vehicle
http://arxiv.org/abs/2010.09094v1,filtered,arxiv,arxiv,2020-10-18 20:22:05+00:00,arxiv,"Multi-Agent Reinforcement Learning in NOMA-aided UAV Networks for
  Cellular Offloading",http://arxiv.org/abs/2010.09094v1,"A novel framework is proposed for cellular offloading with the aid of
multiple unmanned aerial vehicles (UAVs), while the non-orthogonal multiple
access (NOMA) technique is employed at each UAV to further improve the spectrum
efficiency of the wireless network. The optimization problem of joint
three-dimensional (3D) trajectory design and power allocation is formulated for
maximizing the throughput. Since ground mobile users are considered as roaming
continuously, the UAVs need to be re-deployed timely based on the movement of
users. In an effort to solve this pertinent dynamic problem, a K-means based
clustering algorithm is first adopted for periodically partitioning users.
Afterward, a mutual deep Q-network (MDQN) algorithm is proposed to jointly
determine the optimal 3D trajectory and power allocation of UAVs. In contrast
to the conventional DQN algorithm, the MDQN algorithm enables the experience of
multi-agent to be input into a shared neural network to shorten the training
time with the assistance of state abstraction. Numerical results demonstrate
that: 1) the proposed MDQN algorithm is capable of converging under minor
constraints and has a faster convergence rate than the conventional DQN
algorithm in the multi-agent case; 2) The achievable sum rate of the NOMA
enhanced UAV network is 23% superior to the case of orthogonal multiple access
(OMA); 3) By designing the optimal 3D trajectory of UAVs with the aid of the
MDON algorithm, the sum rate of the network enjoys 142% and 56% gains than that
of invoking the circular trajectory and the 2D trajectory, respectively.",autonomous vehicle
http://arxiv.org/abs/2010.12461v3,filtered,arxiv,arxiv,2020-10-23 14:59:30+00:00,arxiv,"Multi-UAV Path Planning for Wireless Data Harvesting with Deep
  Reinforcement Learning",http://arxiv.org/abs/2010.12461v3,"Harvesting data from distributed Internet of Things (IoT) devices with
multiple autonomous unmanned aerial vehicles (UAVs) is a challenging problem
requiring flexible path planning methods. We propose a multi-agent
reinforcement learning (MARL) approach that, in contrast to previous work, can
adapt to profound changes in the scenario parameters defining the data
harvesting mission, such as the number of deployed UAVs, number, position and
data amount of IoT devices, or the maximum flying time, without the need to
perform expensive recomputations or relearn control policies. We formulate the
path planning problem for a cooperative, non-communicating, and homogeneous
team of UAVs tasked with maximizing collected data from distributed IoT sensor
nodes subject to flying time and collision avoidance constraints. The path
planning problem is translated into a decentralized partially observable Markov
decision process (Dec-POMDP), which we solve through a deep reinforcement
learning (DRL) approach, approximating the optimal UAV control policy without
prior knowledge of the challenging wireless channel characteristics in dense
urban environments. By exploiting a combination of centered global and local
map representations of the environment that are fed into convolutional layers
of the agents, we show that our proposed network architecture enables the
agents to cooperate effectively by carefully dividing the data collection task
among themselves, adapt to large complex environments and state spaces, and
make movement decisions that balance data collection goals, flight-time
efficiency, and navigation constraints. Finally, learning a control policy that
generalizes over the scenario parameter space enables us to analyze the
influence of individual parameters on collection performance and provide some
intuition about system-level benefits.",autonomous vehicle
http://arxiv.org/abs/1804.06760v4,filtered,arxiv,arxiv,2018-04-18 14:32:35+00:00,arxiv,"Simulation-based Adversarial Test Generation for Autonomous Vehicles
  with Machine Learning Components",http://arxiv.org/abs/1804.06760v4,"Many organizations are developing autonomous driving systems, which are
expected to be deployed at a large scale in the near future. Despite this,
there is a lack of agreement on appropriate methods to test, debug, and certify
the performance of these systems. One of the main challenges is that many
autonomous driving systems have machine learning components, such as deep
neural networks, for which formal properties are difficult to characterize. We
present a testing framework that is compatible with test case generation and
automatic falsification methods, which are used to evaluate cyber-physical
systems. We demonstrate how the framework can be used to evaluate closed-loop
properties of an autonomous driving system model that includes the ML
components, all within a virtual environment. We demonstrate how to use test
case generation methods, such as covering arrays, as well as requirement
falsification methods to automatically identify problematic test scenarios. The
resulting framework can be used to increase the reliability of autonomous
driving systems.",autonomous vehicle
http://arxiv.org/abs/2004.11070v1,filtered,arxiv,arxiv,2020-04-23 11:00:05+00:00,arxiv,"Millimeter-Wave Full-Duplex UAV Relay: Joint Positioning, Beamforming,
  and Power Control",http://arxiv.org/abs/2004.11070v1,"In this paper, a full-duplex unmanned aerial vehicle (FD-UAV) relay is
employed to increase the communication capacity of millimeter-wave (mmWave)
networks. Large antenna arrays are equipped at the source node (SN),
destination node (DN), and FD-UAV relay to overcome the high path loss of
mmWave channels and to help mitigate the self-interference at the FD-UAV relay.
Specifically, we formulate a problem for maximization of the achievable rate
from the SN to the DN, where the UAV position, analog beamforming, and power
control are jointly optimized. Since the problem is highly non-convex and
involves high-dimensional, highly coupled variable vectors, we first obtain the
conditional optimal position of the FD-UAV relay for maximization of an
approximate upper bound on the achievable rate in closed form, under the
assumption of a line-of-sight (LoS) environment and ideal beamforming. Then,
the UAV is deployed to the position which is closest to the conditional optimal
position and yields LoS paths for both air-to-ground links. Subsequently, we
propose an alternating interference suppression (AIS) algorithm for the joint
design of the beamforming vectors and the power control variables. In each
iteration, the beamforming vectors are optimized for maximization of the
beamforming gains of the target signals and the successive reduction of the
interference, where the optimal power control variables are obtained in closed
form. Our simulation results confirm the superiority of the proposed
positioning, beamforming, and power control method compared to three benchmark
schemes. Furthermore, our results show that the proposed solution closely
approaches a performance upper bound for mmWave FD-UAV systems.",autonomous vehicle
http://arxiv.org/abs/2010.10270v2,filtered,arxiv,arxiv,2020-10-20 13:42:31+00:00,arxiv,Pedestrian Intention Prediction: A Multi-task Perspective,http://arxiv.org/abs/2010.10270v2,"In order to be globally deployed, autonomous cars must guarantee the safety
of pedestrians. This is the reason why forecasting pedestrians' intentions
sufficiently in advance is one of the most critical and challenging tasks for
autonomous vehicles. This work tries to solve this problem by jointly
predicting the intention and visual states of pedestrians. In terms of visual
states, whereas previous work focused on x-y coordinates, we will also predict
the size and indeed the whole bounding box of the pedestrian. The method is a
recurrent neural network in a multi-task learning approach. It has one head
that predicts the intention of the pedestrian for each one of its future
position and another one predicting the visual states of the pedestrian.
Experiments on the JAAD dataset show the superiority of the performance of our
method compared to previous works for intention prediction. Also, although its
simple architecture (more than 2 times faster), the performance of the bounding
box prediction is comparable to the ones yielded by much more complex
architectures. Our code is available online.",autonomous vehicle
http://arxiv.org/abs/1805.02754v1,filtered,arxiv,arxiv,2018-05-07 21:32:56+00:00,arxiv,"Verisimilar Percept Sequences Tests for Autonomous Driving Intelligent
  Agent Assessment",http://arxiv.org/abs/1805.02754v1,"The autonomous car technology promises to replace human drivers with safer
driving systems. But although autonomous cars can become safer than human
drivers this is a long process that is going to be refined over time. Before
these vehicles are deployed on urban roads a minimum safety level must be
assured. Since the autonomous car technology is still under development there
is no standard methodology to evaluate such systems. It is important to
completely understand the technology that is being developed to design
efficient means to evaluate it. In this paper we assume safety-critical systems
reliability as a safety measure. We model an autonomous road vehicle as an
intelligent agent and we approach its evaluation from an artificial
intelligence perspective. Our focus is the evaluation of perception and
decision making systems and also to propose a systematic method to evaluate
their integration in the vehicle. We identify critical aspects of the data
dependency from the artificial intelligence state of the art models and we also
propose procedures to reproduce them.",autonomous vehicle
http://arxiv.org/abs/2101.07337v1,filtered,arxiv,arxiv,2021-01-18 21:45:35+00:00,arxiv,Dissonance Between Human and Machine Understanding,http://arxiv.org/abs/2101.07337v1,"Complex machine learning models are deployed in several critical domains
including healthcare and autonomous vehicles nowadays, albeit as functional
black boxes. Consequently, there has been a recent surge in interpreting
decisions of such complex models in order to explain their actions to humans.
Models that correspond to human interpretation of a task are more desirable in
certain contexts and can help attribute liability, build trust, expose biases
and in turn build better models. It is, therefore, crucial to understand how
and which models conform to human understanding of tasks. In this paper, we
present a large-scale crowdsourcing study that reveals and quantifies the
dissonance between human and machine understanding, through the lens of an
image classification task. In particular, we seek to answer the following
questions: Which (well-performing) complex ML models are closer to humans in
their use of features to make accurate predictions? How does task difficulty
affect the feature selection capability of machines in comparison to humans?
Are humans consistently better at selecting features that make image
recognition more accurate? Our findings have important implications on
human-machine collaboration, considering that a long term goal in the field of
artificial intelligence is to make machines capable of learning and reasoning
like humans.",autonomous vehicle
http://arxiv.org/abs/2012.06992v1,filtered,arxiv,arxiv,2020-12-13 07:28:18+00:00,arxiv,"Edge Intelligence for Autonomous Driving in 6G Wireless System: Design
  Challenges and Solutions",http://arxiv.org/abs/2012.06992v1,"In a level-5 autonomous driving system, the autonomous driving vehicles (AVs)
are expected to sense the surroundings via analyzing a large amount of data
captured by a variety of onboard sensors in near-real-time. As a result,
enormous computing costs will be introduced to the AVs for processing the tasks
with the deployed machine learning (ML) model, while the inference accuracy may
not be guaranteed. In this context, the advent of edge intelligence (EI) and
sixth-generation (6G) wireless networking are expected to pave the way to more
reliable and safer autonomous driving by providing multi-access edge computing
(MEC) together with ML to AVs in close proximity. To realize this goal, we
propose a two-tier EI-empowered autonomous driving framework. In the
autonomous-vehicles tier, the autonomous vehicles are deployed with the shallow
layers by splitting the trained deep neural network model. In the
edge-intelligence tier, an edge server is implemented with the remaining layers
(also deep layers) and an appropriately trained multi-task learning (MTL)
model. In particular, obtaining the optimal offloading strategy (including the
binary offloading decision and the computational resources allocation) can be
formulated as a mixed-integer nonlinear programming (MINLP) problem, which is
solved via MTL in near-real-time with high accuracy. On another note, an
edge-vehicle joint inference is proposed through neural network segmentation to
achieve efficient online inference with data privacy-preserving and less
communication delay. Experiments demonstrate the effectiveness of the proposed
framework, and open research topics are finally listed.",autonomous vehicle
http://arxiv.org/abs/1906.10044v2,filtered,arxiv,arxiv,2019-06-24 16:07:52+00:00,arxiv,"Complex Signal Denoising and Interference Mitigation for Automotive
  Radar Using Convolutional Neural Networks",http://arxiv.org/abs/1906.10044v2,"Driver assistance systems as well as autonomous cars have to rely on sensors
to perceive their environment. A heterogeneous set of sensors is used to
perform this task robustly. Among them, radar sensors are indispensable because
of their range resolution and the possibility to directly measure velocity.
Since more and more radar sensors are deployed on the streets, mutual
interference must be dealt with. In the so far unregulated automotive radar
frequency band, a sensor must be capable of detecting, or even mitigating the
harmful effects of interference, which include a decreased detection
sensitivity. In this paper, we address this issue with Convolutional Neural
Networks (CNNs), which are state-of-the-art machine learning tools. We show
that the ability of CNNs to find structured information in data while
preserving local information enables superior denoising performance. To achieve
this, CNN parameters are found using training with simulated data and
integrated into the automotive radar signal processing chain. The presented
method is compared with the state of the art, highlighting its promising
performance. Hence, CNNs can be employed for interference mitigation as an
alternative to conventional signal processing methods. Code and pre-trained
models are available at https://github.com/johanna-rock/imRICnn.",autonomous vehicle
http://arxiv.org/abs/2106.05997v2,filtered,arxiv,arxiv,2021-06-10 18:27:45+00:00,arxiv,Verifying Quantized Neural Networks using SMT-Based Model Checking,http://arxiv.org/abs/2106.05997v2,"Artificial Neural Networks (ANNs) are being deployed for an increasing number
of safety-critical applications, including autonomous cars and medical
diagnosis. However, concerns about their reliability have been raised due to
their black-box nature and apparent fragility to adversarial attacks. These
concerns are amplified when ANNs are deployed on restricted system, which limit
the precision of mathematical operations and thus introduce additional
quantization errors. Here, we develop and evaluate a novel symbolic
verification framework using software model checking (SMC) and satisfiability
modulo theories (SMT) to check for vulnerabilities in ANNs. More specifically,
we propose several ANN-related optimizations for SMC, including invariant
inference via interval analysis, slicing, expression simplifications, and
discretization of non-linear activation functions. With this verification
framework, we can provide formal guarantees on the safe behavior of ANNs
implemented both in floating- and fixed-point arithmetic. In this regard, our
verification approach was able to verify and produce adversarial examples for
$52$ test cases spanning image classification and general machine learning
applications. Furthermore, for small- to medium-sized ANN, our approach
completes most of its verification runs in minutes. Moreover, in contrast to
most state-of-the-art methods, our approach is not restricted to specific
choices regarding activation functions and non-quantized representations. Our
experiments show that our approach can analyze larger ANN implementations and
substantially reduce the verification time compared to state-of-the-art
techniques that use SMT solving.",autonomous vehicle
http://arxiv.org/abs/2101.09750v1,filtered,arxiv,arxiv,2021-01-24 16:54:53+00:00,arxiv,"Deployable, Data-Driven Unmanned Vehicle Navigation System in
  GPS-Denied, Feature-Deficient Environments",http://arxiv.org/abs/2101.09750v1,"This paper presents a novel data-driven navigation system to navigate an
Unmanned Vehicle (UV) in GPS-denied, feature-deficient environments such as
tunnels, or mines. The method utilizes Radio Frequency Identification (RFID)
tags, also referred to as landmarks, as range sensors that are carried by the
vehicle and are deployed in the environment to enable localization as the
vehicle traverses its pre-defined path through the tunnel. A key question that
arises in such scenario is to estimate and reduce the number of landmarks
required for localization before the start of the mission, given some
information about the environment. The main constraint of the problem is to
keep the maximum uncertainty in the position estimate near a desired value. In
this article, we combine techniques from estimation, machine learning, and
mixed-integer convex optimization to develop a systematic method to perform
localization and navigate the UV through the environment while ensuring minimum
number of landmarks are used and all the mission constraints are satisfied.",autonomous vehicle
http://arxiv.org/abs/1712.04248v2,filtered,arxiv,arxiv,2017-12-12 11:36:26+00:00,arxiv,"Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box
  Machine Learning Models",http://arxiv.org/abs/1712.04248v2,"Many machine learning algorithms are vulnerable to almost imperceptible
perturbations of their inputs. So far it was unclear how much risk adversarial
perturbations carry for the safety of real-world machine learning applications
because most methods used to generate such perturbations rely either on
detailed model information (gradient-based attacks) or on confidence scores
such as class probabilities (score-based attacks), neither of which are
available in most real-world scenarios. In many such cases one currently needs
to retreat to transfer-based attacks which rely on cumbersome substitute
models, need access to the training data and can be defended against. Here we
emphasise the importance of attacks which solely rely on the final model
decision. Such decision-based attacks are (1) applicable to real-world
black-box models such as autonomous cars, (2) need less knowledge and are
easier to apply than transfer-based attacks and (3) are more robust to simple
defences than gradient- or score-based attacks. Previous attacks in this
category were limited to simple models or simple datasets. Here we introduce
the Boundary Attack, a decision-based attack that starts from a large
adversarial perturbation and then seeks to reduce the perturbation while
staying adversarial. The attack is conceptually simple, requires close to no
hyperparameter tuning, does not rely on substitute models and is competitive
with the best gradient-based attacks in standard computer vision tasks like
ImageNet. We apply the attack on two black-box algorithms from Clarifai.com.
The Boundary Attack in particular and the class of decision-based attacks in
general open new avenues to study the robustness of machine learning models and
raise new questions regarding the safety of deployed machine learning systems.
An implementation of the attack is available as part of Foolbox at
https://github.com/bethgelab/foolbox .",autonomous vehicle
http://arxiv.org/abs/2005.07474v1,filtered,arxiv,arxiv,2020-05-15 11:31:54+00:00,arxiv,Robot Accident Investigation: a case study in Responsible Robotics,http://arxiv.org/abs/2005.07474v1,"Robot accidents are inevitable. Although rare, they have been happening since
assembly-line robots were first introduced in the 1960s. But a new generation
of social robots are now becoming commonplace. Often with sophisticated
embedded artificial intelligence (AI) social robots might be deployed as care
robots to assist elderly or disabled people to live independently. Smart robot
toys offer a compelling interactive play experience for children and
increasingly capable autonomous vehicles (AVs) the promise of hands-free
personal transport and fully autonomous taxis. Unlike industrial robots which
are deployed in safety cages, social robots are designed to operate in human
environments and interact closely with humans; the likelihood of robot
accidents is therefore much greater for social robots than industrial robots.
This paper sets out a draft framework for social robot accident investigation;
a framework which proposes both the technology and processes that would allow
social robot accidents to be investigated with no less rigour than we expect of
air or rail accident investigations. The paper also places accident
investigation within the practice of responsible robotics, and makes the case
that social robotics without accident investigation would be no less
irresponsible than aviation without air accident investigation.",autonomous vehicle
http://arxiv.org/abs/1801.08618v2,filtered,arxiv,arxiv,2018-01-25 22:20:11+00:00,arxiv,"JointDNN: An Efficient Training and Inference Engine for Intelligent
  Mobile Cloud Computing Services",http://arxiv.org/abs/1801.08618v2,"Deep learning models are being deployed in many mobile intelligent
applications. End-side services, such as intelligent personal assistants,
autonomous cars, and smart home services often employ either simple local
models on the mobile or complex remote models on the cloud. However, recent
studies have shown that partitioning the DNN computations between the mobile
and cloud can increase the latency and energy efficiencies. In this paper, we
propose an efficient, adaptive, and practical engine, JointDNN, for
collaborative computation between a mobile device and cloud for DNNs in both
inference and training phase. JointDNN not only provides an energy and
performance efficient method of querying DNNs for the mobile side but also
benefits the cloud server by reducing the amount of its workload and
communications compared to the cloud-only approach. Given the DNN architecture,
we investigate the efficiency of processing some layers on the mobile device
and some layers on the cloud server. We provide optimization formulations at
layer granularity for forward- and backward-propagations in DNNs, which can
adapt to mobile battery limitations and cloud server load constraints and
quality of service. JointDNN achieves up to 18 and 32 times reductions on the
latency and mobile energy consumption of querying DNNs compared to the
status-quo approaches, respectively.",autonomous vehicle
http://arxiv.org/abs/1906.07946v1,filtered,arxiv,arxiv,2019-06-19 07:15:51+00:00,arxiv,"Ethically Aligned Design of Autonomous Systems: Industry viewpoint and
  an empirical study",http://arxiv.org/abs/1906.07946v1,"Progress in the field of artificial intelligence has been accelerating
rapidly in the past two decades. Various autonomous systems from purely digital
ones to autonomous vehicles are being developed and deployed out on the field.
As these systems exert a growing impact on society, ethics in relation to
artificial intelligence and autonomous systems have recently seen growing
attention among the academia. However, the current literature on the topic has
focused almost exclusively on theory and more specifically on conceptualization
in the area. To widen the body of knowledge in the area, we conduct an
empirical study on the current state of practice in artificial intelligence
ethics. We do so by means of a multiple case study of five case companies, the
results of which indicate a gap between research and practice in the area.
Based on our findings we propose ways to tackle the gap.",autonomous vehicle
http://arxiv.org/abs/2010.05437v1,filtered,arxiv,arxiv,2020-10-12 03:53:58+00:00,arxiv,"A DRL-based Multiagent Cooperative Control Framework for CAV Networks: a
  Graphic Convolution Q Network",http://arxiv.org/abs/2010.05437v1,"Connected Autonomous Vehicle (CAV) Network can be defined as a collection of
CAVs operating at different locations on a multilane corridor, which provides a
platform to facilitate the dissemination of operational information as well as
control instructions. Cooperation is crucial in CAV operating systems since it
can greatly enhance operation in terms of safety and mobility, and high-level
cooperation between CAVs can be expected by jointly plan and control within CAV
network. However, due to the highly dynamic and combinatory nature such as
dynamic number of agents (CAVs) and exponentially growing joint action space in
a multiagent driving task, achieving cooperative control is NP hard and cannot
be governed by any simple rule-based methods. In addition, existing literature
contains abundant information on autonomous driving's sensing technology and
control logic but relatively little guidance on how to fuse the information
acquired from collaborative sensing and build decision processor on top of
fused information. In this paper, a novel Deep Reinforcement Learning (DRL)
based approach combining Graphic Convolution Neural Network (GCN) and Deep Q
Network (DQN), namely Graphic Convolution Q network (GCQ) is proposed as the
information fusion module and decision processor. The proposed model can
aggregate the information acquired from collaborative sensing and output safe
and cooperative lane changing decisions for multiple CAVs so that individual
intention can be satisfied even under a highly dynamic and partially observed
mixed traffic. The proposed algorithm can be deployed on centralized control
infrastructures such as road-side units (RSU) or cloud platforms to improve the
CAV operation.",autonomous vehicle
http://arxiv.org/abs/2110.05556v1,filtered,arxiv,arxiv,2021-10-11 18:54:05+00:00,arxiv,"Addressing crash-imminent situations caused by human driven vehicle
  errors in a mixed traffic stream: a model-based reinforcement learning
  approach for CAV",http://arxiv.org/abs/2110.05556v1,"It is anticipated that the era of fully autonomous vehicle operations will be
preceded by a lengthy ""Transition Period"" where the traffic stream will be
mixed, that is, consisting of connected autonomous vehicles (CAVs),
human-driven vehicles (HDVs) and connected human-driven vehicles (CHDVs). In
recognition of the fact that public acceptance of CAVs will hinge on safety
performance of automated driving systems, and that there will likely be safety
challenges in the early part of the transition period, significant research
efforts have been expended in the development of safety-conscious automated
driving systems. Yet still, there appears to be a lacuna in the literature
regarding the handling of the crash-imminent situations that are caused by
errant human driven vehicles (HDVs) in the vicinity of the CAV during
operations on the roadway. In this paper, we develop a simple model-based
Reinforcement Learning (RL) based system that can be deployed in the CAV to
generate trajectories that anticipate and avoid potential collisions caused by
drivers of the HDVs. The model involves an end-to-end data-driven approach that
contains a motion prediction model based on deep learning, and a fast
trajectory planning algorithm based on model predictive control (MPC). The
proposed system requires no prior knowledge or assumption about the physical
environment including the vehicle dynamics, and therefore represents a general
approach that can be deployed on any type of vehicle (e.g., truck, buse,
motorcycle, etc.). The framework is trained and tested in the CARLA simulator
with multiple collision imminent scenarios, and the results indicate the
proposed model can avoid the collision at high successful rate (>85%) even in
highly compact and dangerous situations.",autonomous vehicle
http://arxiv.org/abs/2101.02780v1,filtered,arxiv,arxiv,2021-01-07 22:01:30+00:00,arxiv,"SHARKS: Smart Hacking Approaches for RisK Scanning in Internet-of-Things
  and Cyber-Physical Systems based on Machine Learning",http://arxiv.org/abs/2101.02780v1,"Cyber-physical systems (CPS) and Internet-of-Things (IoT) devices are
increasingly being deployed across multiple functionalities, ranging from
healthcare devices and wearables to critical infrastructures, e.g., nuclear
power plants, autonomous vehicles, smart cities, and smart homes. These devices
are inherently not secure across their comprehensive software, hardware, and
network stacks, thus presenting a large attack surface that can be exploited by
hackers. In this article, we present an innovative technique for detecting
unknown system vulnerabilities, managing these vulnerabilities, and improving
incident response when such vulnerabilities are exploited. The novelty of this
approach lies in extracting intelligence from known real-world CPS/IoT attacks,
representing them in the form of regular expressions, and employing machine
learning (ML) techniques on this ensemble of regular expressions to generate
new attack vectors and security vulnerabilities. Our results show that 10 new
attack vectors and 122 new vulnerability exploits can be successfully generated
that have the potential to exploit a CPS or an IoT ecosystem. The ML
methodology achieves an accuracy of 97.4% and enables us to predict these
attacks efficiently with an 87.2% reduction in the search space. We demonstrate
the application of our method to the hacking of the in-vehicle network of a
connected car. To defend against the known attacks and possible novel exploits,
we discuss a defense-in-depth mechanism for various classes of attacks and the
classification of data targeted by such attacks. This defense mechanism
optimizes the cost of security measures based on the sensitivity of the
protected resource, thus incentivizing its adoption in real-world CPS/IoT by
cybersecurity practitioners.",autonomous vehicle
http://arxiv.org/abs/2004.06531v2,filtered,arxiv,arxiv,2020-04-14 14:12:17+00:00,arxiv,Adversarial Evaluation of Autonomous Vehicles in Lane-Change Scenarios,http://arxiv.org/abs/2004.06531v2,"Autonomous vehicles must be comprehensively evaluated before deployed in
cities and highways. However, most existing evaluation approaches for
autonomous vehicles are static and lack adaptability, so they are usually
inefficient in generating challenging scenarios for tested vehicles. In this
paper, we propose an adaptive evaluation framework to efficiently evaluate
autonomous vehicles in adversarial environments generated by deep reinforcement
learning. Considering the multimodal nature of dangerous scenarios, we use
ensemble models to represent different local optimums for diversity. We then
utilize a nonparametric Bayesian method to cluster the adversarial policies.
The proposed method is validated in a typical lane-change scenario that
involves frequent interactions between the ego vehicle and the surrounding
vehicles. Results show that the adversarial scenarios generated by our method
significantly degrade the performance of the tested vehicles. We also
illustrate different patterns of generated adversarial environments, which can
be used to infer the weaknesses of the tested vehicles.",autonomous vehicle
http://arxiv.org/abs/2101.05970v1,filtered,arxiv,arxiv,2021-01-15 05:21:25+00:00,arxiv,Affordance-based Reinforcement Learning for Urban Driving,http://arxiv.org/abs/2101.05970v1,"Traditional autonomous vehicle pipelines that follow a modular approach have
been very successful in the past both in academia and industry, which has led
to autonomy deployed on road. Though this approach provides ease of
interpretation, its generalizability to unseen environments is limited and
hand-engineering of numerous parameters is required, especially in the
prediction and planning systems. Recently, deep reinforcement learning has been
shown to learn complex strategic games and perform challenging robotic tasks,
which provides an appealing framework for learning to drive. In this work, we
propose a deep reinforcement learning framework to learn optimal control policy
using waypoints and low-dimensional visual representations, also known as
affordances. We demonstrate that our agents when trained from scratch learn the
tasks of lane-following, driving around inter-sections as well as stopping in
front of other actors or traffic lights even in the dense traffic setting. We
note that our method achieves comparable or better performance than the
baseline methods on the original and NoCrash benchmarks on the CARLA simulator.",autonomous vehicle
http://arxiv.org/abs/2109.10557v1,filtered,arxiv,arxiv,2021-09-22 07:38:23+00:00,arxiv,"A Reinforcement Learning Benchmark for Autonomous Driving in
  Intersection Scenarios",http://arxiv.org/abs/2109.10557v1,"In recent years, control under urban intersection scenarios becomes an
emerging research topic. In such scenarios, the autonomous vehicle confronts
complicated situations since it must deal with the interaction with social
vehicles timely while obeying the traffic rules. Generally, the autonomous
vehicle is supposed to avoid collisions while pursuing better efficiency. The
existing work fails to provide a framework that emphasizes the integrity of the
scenarios while being able to deploy and test reinforcement learning(RL)
methods. Specifically, we propose a benchmark for training and testing RL-based
autonomous driving agents in complex intersection scenarios, which is called
RL-CIS. Then, a set of baselines are deployed consists of various algorithms.
The test benchmark and baselines are to provide a fair and comprehensive
training and testing platform for the study of RL for autonomous driving in the
intersection scenario, advancing the progress of RL-based methods for
intersection autonomous driving control. The code of our proposed framework can
be found at https://github.com/liuyuqi123/ComplexUrbanScenarios.",autonomous vehicle
http://arxiv.org/abs/2005.07460v1,filtered,arxiv,arxiv,2020-05-15 10:34:51+00:00,arxiv,"Collective Risk Minimization via a Bayesian Model for Statistical
  Software Testing",http://arxiv.org/abs/2005.07460v1,"In the last four years, the number of distinct autonomous vehicles platforms
deployed in the streets of California increased 6-fold, while the reported
accidents increased 12-fold. This can become a trend with no signs of subsiding
as it is fueled by a constant stream of innovations in hardware sensors and
machine learning software. Meanwhile, if we expect the public and regulators to
trust the autonomous vehicle platforms, we need to find better ways to solve
the problem of adding technological complexity without increasing the risk of
accidents. We studied this problem from the perspective of reliability
engineering in which a given risk of an accident has severity and probability
of occurring. Timely information on accidents is important for engineers to
anticipate and reuse previous failures to approximate the risk of accidents in
a new city. However, this is challenging in the context of autonomous vehicles
because of the sparse nature of data on the operational scenarios (driving
trajectories in a new city). Our approach was to mitigate data sparsity by
reducing the state space through monitoring of multiple-vehicles operations. We
then minimized the risk of accidents by determining proper allocation of tests
for each equivalence class. Our contributions comprise (1) a set of strategies
to monitor the operational data of multiple autonomous vehicles, (2) a Bayesian
model that estimates changes in the risk of accidents, and (3) a feedback
control-loop that minimizes these risks by reallocating test effort. Our
results are promising in the sense that we were able to measure and control
risk for a diversity of changes in the operational scenarios. We evaluated our
models with data from two real cities with distinct traffic patterns and made
the data available for the community.",autonomous vehicle
http://arxiv.org/abs/2103.03150v1,filtered,arxiv,arxiv,2021-03-04 16:42:49+00:00,arxiv,"SSTN: Self-Supervised Domain Adaptation Thermal Object Detection for
  Autonomous Driving",http://arxiv.org/abs/2103.03150v1,"The sensibility and sensitivity of the environment play a decisive role in
the safe and secure operation of autonomous vehicles. This perception of the
surrounding is way similar to human visual representation. The human's brain
perceives the environment by utilizing different sensory channels and develop a
view-invariant representation model. Keeping in this context, different
exteroceptive sensors are deployed on the autonomous vehicle for perceiving the
environment. The most common exteroceptive sensors are camera, Lidar and radar
for autonomous vehicle's perception. Despite being these sensors have
illustrated their benefit in the visible spectrum domain yet in the adverse
weather conditions, for instance, at night, they have limited operation
capability, which may lead to fatal accidents. In this work, we explore thermal
object detection to model a view-invariant model representation by employing
the self-supervised contrastive learning approach. For this purpose, we have
proposed a deep neural network Self Supervised Thermal Network (SSTN) for
learning the feature embedding to maximize the information between visible and
infrared spectrum domain by contrastive learning, and later employing these
learned feature representation for the thermal object detection using
multi-scale encoder-decoder transformer network. The proposed method is
extensively evaluated on the two publicly available datasets: the FLIR-ADAS
dataset and the KAIST Multi-Spectral dataset. The experimental results
illustrate the efficacy of the proposed method.",autonomous vehicle
http://arxiv.org/abs/1808.10134v1,filtered,arxiv,arxiv,2018-08-30 06:29:10+00:00,arxiv,"Baidu Apollo Auto-Calibration System - An Industry-Level Data-Driven and
  Learning based Vehicle Longitude Dynamic Calibrating Algorithm",http://arxiv.org/abs/1808.10134v1,"For any autonomous driving vehicle, control module determines its road
performance and safety, i.e. its precision and stability should stay within a
carefully-designed range. Nonetheless, control algorithms require vehicle
dynamics (such as longitudinal dynamics) as inputs, which, unfortunately, are
obscure to calibrate in real time. As a result, to achieve reasonable
performance, most, if not all, research-oriented autonomous vehicles do manual
calibrations in a one-by-one fashion. Since manual calibration is not
sustainable once entering into mass production stage for industrial purposes,
we here introduce a machine-learning based auto-calibration system for
autonomous driving vehicles. In this paper, we will show how we build a
data-driven longitudinal calibration procedure using machine learning
techniques. We first generated offline calibration tables from human driving
data. The offline table serves as an initial guess for later uses and it only
needs twenty-minutes data collection and process. We then used an
online-learning algorithm to appropriately update the initial table (the
offline table) based on real-time performance analysis. This longitudinal
auto-calibration system has been deployed to more than one hundred Baidu Apollo
self-driving vehicles (including hybrid family vehicles and electronic
delivery-only vehicles) since April 2018. By August 27, 2018, it had been
tested for more than two thousands hours, ten thousands kilometers (6,213
miles) and yet proven to be effective.",autonomous vehicle
http://arxiv.org/abs/1902.05974v1,filtered,arxiv,arxiv,2019-02-15 19:42:45+00:00,arxiv,DeepFault: Fault Localization for Deep Neural Networks,http://arxiv.org/abs/1902.05974v1,"Deep Neural Networks (DNNs) are increasingly deployed in safety-critical
applications including autonomous vehicles and medical diagnostics. To reduce
the residual risk for unexpected DNN behaviour and provide evidence for their
trustworthy operation, DNNs should be thoroughly tested. The DeepFault whitebox
DNN testing approach presented in our paper addresses this challenge by
employing suspiciousness measures inspired by fault localization to establish
the hit spectrum of neurons and identify suspicious neurons whose weights have
not been calibrated correctly and thus are considered responsible for
inadequate DNN performance. DeepFault also uses a suspiciousness-guided
algorithm to synthesize new inputs, from correctly classified inputs, that
increase the activation values of suspicious neurons. Our empirical evaluation
on several DNN instances trained on MNIST and CIFAR-10 datasets shows that
DeepFault is effective in identifying suspicious neurons. Also, the inputs
synthesized by DeepFault closely resemble the original inputs, exercise the
identified suspicious neurons and are highly adversarial.",autonomous vehicle
http://arxiv.org/abs/2006.01250v6,filtered,arxiv,arxiv,2020-05-09 09:41:46+00:00,arxiv,RUHSNet: 3D Object Detection Using Lidar Data in Real Time,http://arxiv.org/abs/2006.01250v6,"In this work, we address the problem of 3D object detection from point cloud
data in real time. For autonomous vehicles to work, it is very important for
the perception component to detect the real world objects with both high
accuracy and fast inference. We propose a novel neural network architecture
along with the training and optimization details for detecting 3D objects in
point cloud data. We compare the results with different backbone architectures
including the standard ones like VGG, ResNet, Inception with our backbone. Also
we present the optimization and ablation studies including designing an
efficient anchor. We use the Kitti 3D Birds Eye View dataset for benchmarking
and validating our results. Our work surpasses the state of the art in this
domain both in terms of average precision and speed running at > 30 FPS. This
makes it a feasible option to be deployed in real time applications including
self driving cars.",autonomous vehicle
http://arxiv.org/abs/2009.12975v1,filtered,arxiv,arxiv,2020-09-27 22:39:00+00:00,arxiv,"VATLD: A Visual Analytics System to Assess, Understand and Improve
  Traffic Light Detection",http://arxiv.org/abs/2009.12975v1,"Traffic light detection is crucial for environment perception and
decision-making in autonomous driving. State-of-the-art detectors are built
upon deep Convolutional Neural Networks (CNNs) and have exhibited promising
performance. However, one looming concern with CNN based detectors is how to
thoroughly evaluate the performance of accuracy and robustness before they can
be deployed to autonomous vehicles. In this work, we propose a visual analytics
system, VATLD, equipped with a disentangled representation learning and
semantic adversarial learning, to assess, understand, and improve the accuracy
and robustness of traffic light detectors in autonomous driving applications.
The disentangled representation learning extracts data semantics to augment
human cognition with human-friendly visual summarization, and the semantic
adversarial learning efficiently exposes interpretable robustness risks and
enables minimal human interaction for actionable insights. We also demonstrate
the effectiveness of various performance improvement strategies derived from
actionable insights with our visual analytics system, VATLD, and illustrate
some practical implications for safety-critical applications in autonomous
driving.",autonomous vehicle
http://arxiv.org/abs/2109.11661v1,filtered,arxiv,arxiv,2021-09-23 21:55:12+00:00,arxiv,Learning-Based Path Planning for Long-Range Autonomous Valet Parking,http://arxiv.org/abs/2109.11661v1,"In this paper, to reduce the congestion rate at the city center and increase
the quality of experience (QoE) of each user, the framework of long-range
autonomous valet parking (LAVP) is presented, where an Electric Autonomous
Vehicle (EAV) is deployed in the city, which can pick up, drop off users at
their required spots, and then drive to the car park out of city center
autonomously. In this framework, we aim to minimize the overall distance of the
EAV, while guarantee all users are served, i.e., picking up, and dropping off
users at their required spots through optimizing the path planning of the EAV
and number of serving time slots. To this end, we first propose a learning
based algorithm, which is named as Double-Layer Ant Colony Optimization
(DL-ACO) algorithm to solve the above problem in an iterative way. Then, to
make the real-time decision, while consider the dynamic environment (i.e., the
EAV may pick up and drop off users from different locations), we further
present a deep reinforcement learning (DRL) based algorithm, which is known as
deep Q network (DQN). The experimental results show that the DL-ACO and
DQN-based algorithms both achieve the considerable performance.",autonomous vehicle
http://arxiv.org/abs/2110.07742v1,filtered,arxiv,arxiv,2021-10-14 21:53:03+00:00,arxiv,"Beyond Classification: Directly Training Spiking Neural Networks for
  Semantic Segmentation",http://arxiv.org/abs/2110.07742v1,"Spiking Neural Networks (SNNs) have recently emerged as the low-power
alternative to Artificial Neural Networks (ANNs) because of their sparse,
asynchronous, and binary event-driven processing. Due to their energy
efficiency, SNNs have a high possibility of being deployed for real-world,
resource-constrained systems such as autonomous vehicles and drones. However,
owing to their non-differentiable and complex neuronal dynamics, most previous
SNN optimization methods have been limited to image recognition. In this paper,
we explore the SNN applications beyond classification and present semantic
segmentation networks configured with spiking neurons. Specifically, we first
investigate two representative SNN optimization techniques for recognition
tasks (i.e., ANN-SNN conversion and surrogate gradient learning) on semantic
segmentation datasets. We observe that, when converted from ANNs, SNNs suffer
from high latency and low performance due to the spatial variance of features.
Therefore, we directly train networks with surrogate gradient learning,
resulting in lower latency and higher performance than ANN-SNN conversion.
Moreover, we redesign two fundamental ANN segmentation architectures (i.e.,
Fully Convolutional Networks and DeepLab) for the SNN domain. We conduct
experiments on two public semantic segmentation benchmarks including the PASCAL
VOC2012 dataset and the DDD17 event-based dataset. In addition to showing the
feasibility of SNNs for semantic segmentation, we show that SNNs can be more
robust and energy-efficient compared to their ANN counterparts in this domain.",autonomous vehicle
http://arxiv.org/abs/2007.05828v1,filtered,arxiv,arxiv,2020-07-11 18:41:47+00:00,arxiv,Understanding Object Detection Through An Adversarial Lens,http://arxiv.org/abs/2007.05828v1,"Deep neural networks based object detection models have revolutionized
computer vision and fueled the development of a wide range of visual
recognition applications. However, recent studies have revealed that deep
object detectors can be compromised under adversarial attacks, causing a victim
detector to detect no object, fake objects, or mislabeled objects. With object
detection being used pervasively in many security-critical applications, such
as autonomous vehicles and smart cities, we argue that a holistic approach for
an in-depth understanding of adversarial attacks and vulnerabilities of deep
object detection systems is of utmost importance for the research community to
develop robust defense mechanisms. This paper presents a framework for
analyzing and evaluating vulnerabilities of the state-of-the-art object
detectors under an adversarial lens, aiming to analyze and demystify the attack
strategies, adverse effects, and costs, as well as the cross-model and
cross-resolution transferability of attacks. Using a set of quantitative
metrics, extensive experiments are performed on six representative deep object
detectors from three popular families (YOLOv3, SSD, and Faster R-CNN) with two
benchmark datasets (PASCAL VOC and MS COCO). We demonstrate that the proposed
framework can serve as a methodical benchmark for analyzing adversarial
behaviors and risks in real-time object detection systems. We conjecture that
this framework can also serve as a tool to assess the security risks and the
adversarial robustness of deep object detectors to be deployed in real-world
applications.",autonomous vehicle
http://arxiv.org/abs/2101.04319v1,filtered,arxiv,arxiv,2021-01-12 06:42:45+00:00,arxiv,"DeepiSign: Invisible Fragile Watermark to Protect the Integrityand
  Authenticity of CNN",http://arxiv.org/abs/2101.04319v1,"Convolutional Neural Networks (CNNs) deployed in real-life applications such
as autonomous vehicles have shown to be vulnerable to manipulation attacks,
such as poisoning attacks and fine-tuning. Hence, it is essential to ensure the
integrity and authenticity of CNNs because compromised models can produce
incorrect outputs and behave maliciously. In this paper, we propose a
self-contained tamper-proofing method, called DeepiSign, to ensure the
integrity and authenticity of CNN models against such manipulation attacks.
DeepiSign applies the idea of fragile invisible watermarking to securely embed
a secret and its hash value into a CNN model. To verify the integrity and
authenticity of the model, we retrieve the secret from the model, compute the
hash value of the secret, and compare it with the embedded hash value. To
minimize the effects of the embedded secret on the CNN model, we use a
wavelet-based technique to transform weights into the frequency domain and
embed the secret into less significant coefficients. Our theoretical analysis
shows that DeepiSign can hide up to 1KB secret in each layer with minimal loss
of the model's accuracy. To evaluate the security and performance of DeepiSign,
we performed experiments on four pre-trained models (ResNet18, VGG16, AlexNet,
and MobileNet) using three datasets (MNIST, CIFAR-10, and Imagenet) against
three types of manipulation attacks (targeted input poisoning, output
poisoning, and fine-tuning). The results demonstrate that DeepiSign is
verifiable without degrading the classification accuracy, and robust against
representative CNN manipulation attacks.",autonomous vehicle
http://arxiv.org/abs/2101.06409v1,filtered,arxiv,arxiv,2021-01-16 09:00:34+00:00,arxiv,Shape Back-Projection In 3D Scenes,http://arxiv.org/abs/2101.06409v1,"In this work, we propose a novel framework shape back-projection for
computationally efficient point cloud processing in a probabilistic manner. The
primary component of the technique is shape histogram and a back-projection
procedure. The technique measures similarity between 3D surfaces, by analyzing
their geometrical properties. It is analogous to color back-projection which
measures similarity between images, simply by looking at their color
distributions. In the overall process, first, shape histogram of a sample
surface (e.g. planar) is computed, which captures the profile of surface
normals around a point in form of a probability distribution. Later, the
histogram is back-projected onto a test surface and a likelihood score is
obtained. The score depicts that how likely a point in the test surface behaves
similar to the sample surface, geometrically. Shape back-projection finds its
application in binary surface classification, high curvature edge detection in
unorganized point cloud, automated point cloud labeling for 3D-CNNs
(convolutional neural network) etc. The algorithm can also be used for
real-time robotic operations such as autonomous object picking in warehouse
automation, ground plane extraction for autonomous vehicles and can be deployed
easily on computationally limited platforms (UAVs).",autonomous vehicle
http://arxiv.org/abs/2107.12137v2,filtered,arxiv,arxiv,2021-07-26 12:18:23+00:00,arxiv,AA3DNet: Attention Augmented Real Time 3D Object Detection,http://arxiv.org/abs/2107.12137v2,"In this work, we address the problem of 3D object detection from point cloud
data in real time. For autonomous vehicles to work, it is very important for
the perception component to detect the real world objects with both high
accuracy and fast inference. We propose a novel neural network architecture
along with the training and optimization details for detecting 3D objects using
point cloud data. We present anchor design along with custom loss functions
used in this work. A combination of spatial and channel wise attention module
is used in this work. We use the Kitti 3D Birds Eye View dataset for
benchmarking and validating our results. Our method surpasses previous state of
the art in this domain both in terms of average precision and speed running at
> 30 FPS. Finally, we present the ablation study to demonstrate that the
performance of our network is generalizable. This makes it a feasible option to
be deployed in real time applications like self driving cars.",autonomous vehicle
10.1016/j.robot.2021.103731,filtered,Robotics and Autonomous Systems,sciencedirect,2021-04-30,sciencedirect,Two-stage visual navigation by deep neural networks and multi-goal reinforcement learning,https://api.elsevier.com/content/article/pii/S0921889021000166,"
                  In this paper, we propose a two-stage learning framework for visual navigation in which the experience of the agent during exploration of one goal is shared to learn to navigate to other goals. We train a deep neural network for estimating the robot’s position in the environment using ground truth information provided by a classical localization and mapping approach. The second simpler multi-goal Q-function learns to traverse the environment by using the provided discretized map. Transfer learning is applied to the multi-goal Q-function from a maze structure to a 2D simulator and is finally deployed in a 3D simulator where the robot uses the estimated locations from the position estimator deep network. In the experiments, we first compare different architectures to select the best deep network for location estimation, and then compare the effects of the multi-goal reinforcement learning method to traditional reinforcement learning. The results show a significant improvement when multi-goal reinforcement learning is used. Furthermore, the results of the location estimator show that a deep network can learn and generalize in different environments using camera images with high accuracy in both position and orientation.
               ",autonomous vehicle
10.1016/j.ejmp.2021.04.016,filtered,Physica Medica,sciencedirect,2021-03-31,sciencedirect,Artificial intelligence and machine learning for medical imaging: A technology review,https://api.elsevier.com/content/article/pii/S1120179721001733,"
                  Artificial intelligence (AI) has recently become a very popular buzzword, as a consequence of disruptive technical advances and impressive experimental results, notably in the field of image analysis and processing. In medicine, specialties where images are central, like radiology, pathology or oncology, have seized the opportunity and considerable efforts in research and development have been deployed to transfer the potential of AI to clinical applications. With AI becoming a more mainstream tool for typical medical imaging analysis tasks, such as diagnosis, segmentation, or classification, the key for a safe and efficient use of clinical AI applications relies, in part, on informed practitioners. The aim of this review is to present the basic technological pillars of AI, together with the state-of-the-art machine learning methods and their application to medical imaging. In addition, we discuss the new trends and future research directions. This will help the reader to understand how AI methods are now becoming an ubiquitous tool in any medical image analysis workflow and pave the way for the clinical implementation of AI-based solutions.
               ",autonomous vehicle
10.1016/j.adhoc.2021.102685,filtered,Ad Hoc Networks,sciencedirect,2021-12-01,sciencedirect,Role of machine learning and deep learning in securing 5G-driven industrial IoT applications,https://api.elsevier.com/content/article/pii/S1570870521001906,"
                  The Internet of Things (IoT) connects millions of computing devices and has set a stage for future technology where industrial use cases like smart cities and smart houses will operate with minimal human intervention. IoT’s cross-domain amalgamations with emergent technologies like 5G and blockchain affects human life. Hence, increase in reliance over IoT necessitates focus on its privacy and security concerns. Implementing security through encryption, authentication, access control and communication security is the need of the hour. These needs can be best catered with the use of machine learning (ML) and deep learning (DL) that can help in realizing secure intelligent systems. In this work, the authors present a comprehensive review for securing Industrial-IoT (I-IoT) devices to contribute to the development of security methods for I-IoT deployed over 5G and blockchain. The survey provides a general analysis of the state-of-the-art security implementation and further assesses the product life cycle of IoT devices. The authors present numerous virtues as well as faults in the machine learning and deep learning algorithms deployed over the fog architecture in context with the security solutions. The potential security algorithms can help overcome many challenges in the IoT security and pave way for implementation with emerging technologies like 5G, blockchain, edge computing, fog computing and their use cases for creating smart environments.
               ",autonomous vehicle
10.1016/j.rser.2021.111459,filtered,Renewable and Sustainable Energy Reviews,sciencedirect,2021-10-31,sciencedirect,Artificial intelligence techniques for enabling Big Data services in distribution networks: A review,https://api.elsevier.com/content/article/pii/S1364032121007413,"Artificial intelligence techniques lead to data-driven energy services in distribution power systems by extracting value from the data generated by the deployed metering and sensing devices. This paper performs a holistic analysis of artificial intelligence applications to distribution networks, ranging from operation, monitoring and maintenance to planning. The potential artificial intelligence techniques for power system applications and needed data sources are identified and classified. The following data-driven services for distribution networks are analyzed: topology estimation, observability, fraud detection, predictive maintenance, non-technical losses detection, forecasting, energy management systems, aggregated flexibility services and trading. A review of the artificial intelligence methods implemented in each of these services is conducted. Their interdependencies are mapped, proving that multiple services can be offered as a single clustered service to different stakeholders. Furthermore, the dependencies between the AI techniques with each energy service are identified. In recent years there has been a significant rise of deep learning applications for time series prediction tasks. Another finding is that unsupervised learning methods are mainly being applied to customer segmentation, buildings efficiency clustering and consumption profile grouping for non-technical losses detection. Reinforcement learning is being widely applied to energy management systems design, although more testing in real environments is needed. Distribution network sensorization should be enhanced and increased in order to obtain larger amounts of valuable data, enabling better service outcomes. Finally, the future opportunities and challenges for applying artificial intelligence in distribution grids are discussed.",autonomous vehicle
10.1016/j.compeleceng.2021.107574,filtered,Computers & Electrical Engineering,sciencedirect,2021-11-04,sciencedirect,Analysis of machine learning based LEACH robust routing in the Edge Computing systems,https://api.elsevier.com/content/article/pii/S0045790621005139,"
                  Wireless sensor networks (WSN) are used to detect real-time changes in the deployed environment. This dynamic behaviour is either triggered by the deployed environment or by the user from outside. Because of their ability to monitor complex scenarios that change rapidly over time, wireless sensor networks are critical components of most advanced computing systems. These complex activities are influenced by different methods or even by the designers of their networks. Machine learning encourages many real solutions that optimise resource use and increase the network's lifespan in sensor networks. LEACH routing protocol has many limitations due to sudden energy utilisation & cluster head nodes due to direct communication with the base station node. This fast node energy leak creates several black hole structures in the networks, resulting in data redundancy, data packets transmission, node upgrade costs, and end-to-end delay for WSN. The proposed model with LEACH protocol functionality has improved network performance, network (WSN) efficiency, and solving data redundancy issues. By using an independent Recurrent Neural Network (IRNN)-based data fusion algorithm, namely, DFAIRNN. The simulation and comparative results indicate that the mean method & minimum distance method used in the LEACH-DFAIRNN protocol can effectively resolve data redundancy issues caused by the adjacent sensor nodes by flooding data simultaneously to a single node.
               ",autonomous vehicle
10.1016/j.matpr.2021.07.089,filtered,Materials Today: Proceedings,sciencedirect,2021-07-17,sciencedirect,Investigations on optimizing performance of the distributed computing in heterogeneous environment using machine learning technique for large scale data set,https://api.elsevier.com/content/article/pii/S2214785321049415,"
                  Enforcing admired machine learning approaches to huge data enhanced novel issues for researchers. Conventional libraries could not suitably fulfil the requirement of complex model with wide variety of data and system parameters. Therefore new methodologies are required performing the computation on more than one machine over distributed environment. Some distributed frameworks on huge data such as MapReduce and TensorFlow have been deployed to solve various machine learning problems in heterogeneous distributed environment. The objective of this paper is providing a wide variety of useful information about platforms, approaches, problems, datasets, and optimization approaches in distributed systems. So researchers have been used the beneficial information to develop new approaches for efficient machine learning. This paper also covers the various formats of data like structured, semi structured and unstructured big data. A brief review of previous works is also represented in text and tabular format to provide motivation to the researchers for developing new paradigm of distributed computing environment.
               ",autonomous vehicle
10.1016/j.smrv.2021.101512,filtered,Sleep Medicine Reviews,sciencedirect,2021-10-31,sciencedirect,Artificial intelligence and sleep: Advancing sleep medicine,https://api.elsevier.com/content/article/pii/S1087079221000976,"
                  Artificial intelligence (AI) allows analysis of “big data” combining clinical, environmental and laboratory based objective measures to allow a deeper understanding of sleep and sleep disorders. This development has the potential to transform sleep medicine in coming years to the betterment of patient care and our collective understanding of human sleep. This review addresses the current state of the field starting with a broad definition of the various components and analytic methods deployed in AI. We review examples of AI use in screening, endotyping, diagnosing, and treating sleep disorders and place this in the context of precision/personalized sleep medicine. We explore the opportunities for AI to both facilitate and extend providers’ clinical impact and present ethical considerations regarding AI derived prognostic information. We cover early adopting specialties of AI in the clinical realm, such as radiology and pathology, to provide a road map for the challenges sleep medicine is likely to face when deploying this technology. Finally, we discuss pitfalls to ensure clinical AI implementation proceeds in the safest and most effective manner possible.
               ",autonomous vehicle
10.1016/B978-0-12-819154-5.00023-0,filtered,Knowledge Discovery in Big Data from Astronomy and Earth Observation,sciencedirect,2020-12-31,sciencedirect,Chapter 12: Learning in Big Data: Introduction to Machine Learning,https://api.elsevier.com/content/article/pii/B9780128191545000230,"
               
                  Machine learning (ML) is a subset of artificial intelligence that develops dynamic algorithms capable of data-driven decisions, in contrast to models that follow static programming instructions. ML is concerned with enabling computer programs automatically to improve their performance at some tasks through experience. Astronomy and geosciences are two areas where the application of ML can be very fruitful. While the adoption of ML methods in astronomy and geosciences has been slow, there are several published studies using ML in these disciplines.
               This chapter introduces and evaluates several ML techniques. Special attention is given to inductive learning, which is among the most mature of the ML approaches currently available. The supervised, unsupervised, semisupervised and reinforcement learning types are described.
               ML algorithms are programs of data-driven inference tools that offer an automated means of recognizing patterns in high-dimensional data. Current trends and recent developments in ML algorithms are discussed. Scalable ML algorithms and frameworks are also described.
               Selected case study applications in which ML techniques have been successfully deployed in astronomy and geosciences are described.
               The chapter concludes with a summary of some of the key research issues in ML related to astronomy and geosciences, with emphasis on the scope for the application of ML algorithms to the rapidly increasing volumes of astronomical and remotely sensed geophysical data for geological mapping and other problems.
            ",autonomous vehicle
10.1016/j.neuron.2020.09.005,filtered,Neuron,sciencedirect,2020-09-23,sciencedirect,Artificial Neural Networks for Neuroscientists: A Primer,https://api.elsevier.com/content/article/pii/S0896627320307054,"Artificial neural networks (ANNs) are essential tools in machine learning that have drawn increasing attention in neuroscience. Besides offering powerful techniques for data analysis, ANNs provide a new approach for neuroscientists to build models for complex behaviors, heterogeneous neural activity, and circuit connectivity, as well as to explore optimization in neural systems, in ways that traditional models are not designed for. In this pedagogical Primer, we introduce ANNs and demonstrate how they have been fruitfully deployed to study neuroscientific questions. We first discuss basic concepts and methods of ANNs. Then, with a focus on bringing this mathematical framework closer to neurobiology, we detail how to customize the analysis, structure, and learning of ANNs to better address a wide range of challenges in brain research. To help readers garner hands-on experience, this Primer is accompanied with tutorial-style code in PyTorch and Jupyter Notebook, covering major topics.",autonomous vehicle
10.1016/j.mlwa.2021.100046,filtered,Machine Learning with Applications,sciencedirect,2021-09-15,sciencedirect,Public policymaking for international agricultural trade using association rules and ensemble machine learning,https://api.elsevier.com/content/article/pii/S2666827021000232,"International economics has a long history of improving our understanding of factors causing trade, and the consequences of free flow of goods and services across countries. The recent shocks to the free-trade regime, especially trade disputes among major economies, as well as black swan events (such as trade wars and pandemics), raise the need for improved predictions to inform policy decisions. Artificial Intelligence (AI) methods are allowing economists to solve such prediction problems in new ways. In this manuscript, we present novel methods that predict and associate food and agricultural commodities traded internationally. Association Rules (AR) analysis has been deployed successfully for economic scenarios at the consumer or store level (such as for market basket analysis). In our work however; we present analysis of imports/exports associations and their effects on country–commodity trade flows. Moreover, Ensemble Machine Learning (EML) methods are developed to provide improved agricultural trade predictions, outlier events’ implications, and quantitative pointers to policy makers.",autonomous vehicle
10.1016/j.zemedi.2018.11.002,filtered,Zeitschrift für Medizinische Physik,sciencedirect,2019-05-31,sciencedirect,An overview of deep learning in medical imaging focusing on MRI,https://api.elsevier.com/content/article/pii/S0939388918301181,"What has happened in machine learning lately, and what does it mean for the future of medical image analysis? Machine learning has witnessed a tremendous amount of attention over the last few years. The current boom started around 2009 when so-called deep artificial neural networks began outperforming other established models on a number of important benchmarks. Deep neural networks are now the state-of-the-art machine learning models across a variety of areas, from image analysis to natural language processing, and widely deployed in academia and industry. These developments have a huge potential for medical imaging technology, medical data analysis, medical diagnostics and healthcare in general, slowly being realized. We provide a short overview of recent advances and some associated challenges in machine learning applied to medical image processing and image analysis. As this has become a very broad and fast expanding field we will not survey the entire landscape of applications, but put particular focus on deep learning in MRI. Our aim is threefold: (i) give a brief introduction to deep learning with pointers to core references; (ii) indicate how deep learning has been applied to the entire MRI processing chain, from acquisition to image retrieval, from segmentation to disease prediction; (iii) provide a starting point for people interested in experimenting and perhaps contributing to the field of deep learning for medical imaging by pointing out good educational resources, state-of-the-art open-source code, and interesting sources of data and problems related medical imaging.",autonomous vehicle
10.1016/j.nima.2020.164652,filtered,"Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment",sciencedirect,2021-01-01,sciencedirect,Machine learning for beam dynamics studies at the CERN Large Hadron Collider,https://api.elsevier.com/content/article/pii/S0168900220310494,"Machine learning entails a broad range of techniques that have been widely used in Science and Engineering since decades. High-energy physics has also profited from the power of these tools for advanced analysis of colliders data. It is only up until recently that Machine Learning has started to be applied successfully in the domain of Accelerator Physics, which is testified by intense efforts deployed in this domain by several laboratories worldwide. This is also the case of CERN, where recently focused efforts have been devoted to the application of Machine Learning techniques to beam dynamics studies at the Large Hadron Collider (LHC). This implies a wide spectrum of applications from beam measurements and machine performance optimisation to analysis of numerical data from tracking simulations of non-linear beam dynamics. In this paper, the LHC-related applications that are currently pursued are presented and discussed in detail, paying also attention to future developments.",autonomous vehicle
10.1016/j.compind.2021.103509,filtered,Computers in Industry,sciencedirect,2021-11-30,sciencedirect,Detecting cyberattacks using anomaly detection in industrial control systems: A Federated Learning approach,https://api.elsevier.com/content/article/pii/S0166361521001160,"
                  In recent years, the rapid development and wide application of advanced technologies have profoundly impacted industrial manufacturing, leading to smart manufacturing (SM). However, the Industrial IoT (IIoT)-based manufacturing systems are now one of the top industries targeted by a variety of attacks. In this research, we propose detecting Cyberattacks in Industrial Control Systems using Anomaly Detection. An anomaly detection architecture for the IIoT-based SM is proposed to deploy one of the top most concerned networking technique - a Federated Learning architecture - that can detect anomalies for time series data typically running inside an industrial system. The architecture achieves higher detection performance compared to the current detection solution for time series data. It also shows the feasibility and efficiency to be deployed on top of edge computing hardware of an IIoT-based SM that can save 35% of bandwidth consumed in the transmission link between the edge and the cloud. At the expense, the architecture needs to trade off with the computing resource consumed at edge devices for implementing the detection task. However, findings in maximal CPU usage of 85% and average Memory usage of 37% make this architecture totally realizable in an IIoT-based SM.
               ",autonomous vehicle
10.1016/B978-0-12-813086-5.00006-2,filtered,Biomedical Signal Analysis for Connected Healthcare,sciencedirect,2021-12-31,sciencedirect,6: Machine learning for biomedical signal analysis,https://api.elsevier.com/content/article/pii/B9780128130865000062,"
               In this chapter, we have investigated the conceptual framework of some popular machine learning (ML) algorithms and how they could be extended to biomedical signal analysis applications. Signal feature extraction techniques provide some form of systematic and compact representation of biomedical signals, and they form as the input to most ML models except in cases such as deep learning (DL) in which explicit feature extraction is not a necessary step. It's important to select features carefully that are suitable for an ethical and fair ML, and be as representative in ensuring equity, diversity, and inclusion in the data collection and training phases of ML algorithm, so that unwanted biases could be avoided. The right selection of ML algorithm depends on the application in hand, and how well a dataset has been curated and labeled. Also, the hardware platform plays a role in the appropriate selection of the ML algorithm. If the biomedical application has large computational resources and bandwidth to process, then cloud-based ML such as DL could be pursued. In cases where resources are constrained and/or speed is important, then edge ML or tiny ML approaches could be deployed. In case of tiny ML applications, the DL or classical ML algorithm could be pruned, quantized, and optimized by using criteria to suit microcontroller implementations that are inbuilt in most wearable biomedical devices. Guidelines on how the train and test datasets should be split and what forms of metrics should be considered in assessing the performances of the ML outcomes are also covered in this chapter.
            ",autonomous vehicle
10.1016/j.rser.2021.110969,filtered,Renewable and Sustainable Energy Reviews,sciencedirect,2021-07-31,sciencedirect,Intelligent building control systems for thermal comfort and energy-efficiency: A systematic review of artificial intelligence-assisted techniques,https://api.elsevier.com/content/article/pii/S1364032121002616,"
                  Building operations represent a significant percentage of the total primary energy consumed in most countries due to the proliferation of Heating, Ventilation and Air-Conditioning (HVAC) installations in response to the growing demand for improved thermal comfort. Reducing the associated energy consumption while maintaining comfortable conditions in buildings are conflicting objectives and represent a typical optimization problem that requires intelligent system design. Over the last decade, different methodologies based on the Artificial Intelligence (AI) techniques have been deployed to find the sweet spot between energy use in HVAC systems and suitable indoor comfort levels to the occupants. This paper performs a comprehensive and an in-depth systematic review of AI-based techniques used for building control systems by assessing the outputs of these techniques, and their implementations in the reviewed works, as well as investigating their abilities to improve the energy-efficiency, while maintaining thermal comfort conditions. This enables a holistic view of (1) the complexities of delivering thermal comfort to users inside buildings in an energy-efficient way, and (2) the associated bibliographic material to assist researchers and experts in the field in tackling such a challenge. Among the 20 AI tools developed for both energy consumption and comfort control, functions such as identification and recognition patterns, optimization, predictive control. Based on the findings of this work, the application of AI technology in building control is a promising area of research and still an ongoing, i.e., the performance of AI-based control is not yet completely satisfactory. This is mainly due in part to the fact that these algorithms usually need a large amount of high-quality real-world data, which is lacking in the building or, more precisely, the energy sector. Based on the current study, from 1993 to 2020, the application of AI techniques and personalized comfort models has enabled energy savings on average between 21.81 and 44.36%, and comfort improvement on average between 21.67 and 85.77%. Finally, this paper discusses the challenges faced in the use of AI for energy productivity and comfort improvement, and opens main future directions in relation with AI-based building control systems for human comfort and energy-efficiency management.
               ",autonomous vehicle
10.1016/j.future.2018.06.042,filtered,Future Generation Computer Systems,sciencedirect,2019-01-31,sciencedirect,CPS data streams analytics based on machine learning for Cloud and Fog Computing: A survey,https://api.elsevier.com/content/article/pii/S0167739X17330613,"
                  Cloud and Fog computing has emerged as a promising paradigm for the Internet of things (IoT) and cyber–physical systems (CPS). One characteristic of CPS is the reciprocal feedback loops between physical processes and cyber elements (computation, software and networking), which implies that data stream analytics is one of the core components of CPS. The reasons for this are: (i) it extracts the insights and the knowledge from the data streams generated by various sensors and other monitoring components embedded in the physical systems; (ii) it supports informed decision making; (iii) it enables feedback from the physical processes to the cyber counterparts; (iv) it eventually facilitates the integration of cyber and physical systems. There have been many successful applications of data streams analytics, powered by machine learning techniques, to CPS systems. Thus, it is necessary to have a survey on the particularities of the application of machine learning techniques to the CPS domain. In particular, we explore how machine learning methods should be deployed and integrated in Cloud and Fog architectures for better fulfilment of the requirements of mission criticality and time criticality arising in CPS domains. To the best of our knowledge, this paper is the first to systematically study machine learning techniques for CPS data stream analytics from various perspectives, especially from a perspective that leads to the discussion and guidance of how the CPS machine learning methods should be deployed in a Cloud and Fog architecture.
               ",autonomous vehicle
10.1016/j.compeleceng.2018.03.015,filtered,Computers & Electrical Engineering,sciencedirect,2019-03-31,sciencedirect,BCI cinematics – A pre-release analyser for movies using H<ce:inf loc=post>2</ce:inf>O deep learning platform,https://api.elsevier.com/content/article/pii/S0045790617315318,"
                  Entertainment industry has seen a phenomenal growth throughout the globe in recent times and movie industry enjoys a crucial role in the above emergence. A movie can capture the attention of a viewer and can trigger cognitive and emotional processes in the brain. In this article we assess the emotional outcome of the viewer while they watch the movie before its actual release that is, during its preview. Traditionally FMRI was used to assess the activity of brain but proved to be non-feasible and costly so we used EEG Sensors to monitor and record the functioning of the brain of movie viewer for further analysis. The collected data through EEG sensor were analysed using deep learning framework. H2O package of deep learning was employed to find high and low of different brain waves mapping to the emotions depicted in the every scene of the movie. Our proposed system named BCI cinematics obtained 85% accuracy and results were validated by obtaining the feedback from the stake holders. The outcome of this work will assist the creators to understand the emotional impact of movie over a normal viewer impartially thus enable them to modify certain scenes or change sequence of scenes and so on. When deployed in real time our system prove to be a cost saver for movie makers.
               ",autonomous vehicle
10.1016/B978-0-12-818279-6.00011-6,filtered,Thinking Machines,sciencedirect,2021-12-31,sciencedirect,Chapter 1: Introduction,https://api.elsevier.com/content/article/pii/B9780128182796000116,"
               
                  This chapter describes how machine learning is applied, the dawn of machine learning, and an example use case of Industry4.0 and transaction processing. In addition, this chapter introduces the types of machine learning being studied and what problems or issues they are used for. Further, previously deployed services and applications are also discussed. First, remarkable examples of machine learning are introduced. IBM's Watson AI machine, which indicated the advent of machine learning in the research domain, and Google's Go Playing machine, are introduced. Next, definitions of inference and learning are introduced, and a full perspective is provided through examples. The inference obtained from learning is then described. Before the learning of a neural network model, input data are cleaned and modified to effectively improve the learning task; the techniques used for this are also provided. In addition, a common learning method, taxonomy of learning, and its performance metrics and verifications are introduced.
               Then, Industry4.0 is introduced as a use case of machine learning. Two typical example models of factory automation are applied in the explanation. Finally, the use of transaction processing is introduced. Machine learning is applied to process huge datasets, and a transaction is a procedure applied between each data processing. Although there is no direct relationship between machine learning and the transaction process, a block chain used in the transaction process can be applied anywhere and combined with machine learning. Therefore, a block chain is introduced in this chapter.
            ",autonomous vehicle
10.1016/j.pecs.2008.01.001,filtered,Progress in Energy and Combustion Science,sciencedirect,2008-10-31,sciencedirect,Artificial intelligence techniques for photovoltaic applications: A review,https://api.elsevier.com/content/article/pii/S0360128508000026,"
                  Artificial intelligence (AI) techniques are becoming useful as alternate approaches to conventional techniques or as components of integrated systems. They have been used to solve complicated practical problems in various areas and are becoming more popular nowadays. They can learn from examples, are fault tolerant in the sense that they are able to handle noisy and incomplete data, are able to deal with nonlinear problems and once trained can perform prediction and generalization at high speed. AI-based systems are being developed and deployed worldwide in a wide variety of applications, mainly because of their symbolic reasoning, flexibility and explanation capabilities. AI has been used in different sectors, such as engineering, economics, medicine, military, marine, etc. They have also been applied for modeling, identification, optimization, prediction, forecasting and control of complex systems. The paper outlines an understanding of how AI systems operate by way of presenting a number of problems in photovoltaic systems application. Problems presented include three areas: forecasting and modeling of meteorological data, sizing of photovoltaic systems and modeling, simulation and control of photovoltaic systems. Published literature presented in this paper show the potential of AI as design tool in photovoltaic systems.
               ",autonomous vehicle
10.1016/j.ijpharm.2021.120554,filtered,International Journal of Pharmaceutics,sciencedirect,2021-06-01,sciencedirect,Industry 4.0 for pharmaceutical manufacturing: Preparing for the smart factories of the future,https://api.elsevier.com/content/article/pii/S0378517321003598,"Over the last two centuries, medicines have evolved from crude herbal and botanical preparations into more complex manufacturing of sophisticated drug products and dosage forms. Along with the evolution of medicines, the manufacturing practices for their production have advanced from small-scale manual processing with simple tools to large-scale production as part of a trillion-dollar pharmaceutical industry. Today’s pharmaceutical manufacturing technologies continue to evolve as the internet of things, artificial intelligence, robotics, and advanced computing begin to challenge the traditional approaches, practices, and business models for the manufacture of pharmaceuticals. The application of these technologies has the potential to dramatically increase the agility, efficiency, flexibility, and quality of the industrial production of medicines. How these technologies are deployed on the journey from data collection to the hallmark digital maturity of Industry 4.0 will define the next generation of pharmaceutical manufacturing. Acheiving the benefits of this future requires a vision for it and an understanding of the extant regulatory, technical, and logistical barriers to realizing it.",autonomous vehicle
10.1016/B978-0-12-822844-9.00011-6,filtered,Recent Trends in Computational Intelligence Enabled Research,sciencedirect,2021-12-31,sciencedirect,Chapter 2: Computational intelligence techniques for localization and clustering in wireless sensor networks,https://api.elsevier.com/content/article/pii/B9780128228449000116,"
               A wireless sensor network (WSN) are normally deployed in harsh environments to collect and deliver data to a remotely located base station. In a sensor network it is very important to know about the position of the sensor node (SN) and data collected by that node, as it has a significant impact on the overall performance of the WSN. Grouping SNs to form clusters has been adopted widely to overcome the scalability problem. It has been proved that for organizing a network into a connected hierarchy, clustering is an effective approach. In this chapter, we address the localization and clustering techniques in WSN, challenges/issues in providing localization and clustering for WSN, and the use of computational techniques for localization and clustering algorithms. We also outline the recent research works on the use of computational intelligence (CI) techniques and future challenges that need to be addressed in providing CI techniques for localization and clustering.
            ",autonomous vehicle
10.1016/B978-0-12-818576-6.00011-3,filtered,Artificial Intelligence to Solve Pervasive Internet of Things Issues,sciencedirect,2021-12-31,sciencedirect,Chapter 11: Adaptive Complex Systems: Digital Twins,https://api.elsevier.com/content/article/pii/B9780128185766000113,"
               The design, control, and maintenance of complex systems are a challenge. Often it is difficult to understand the whole-system behavior because the knowledge of component behavior and interaction is uncertain. Such systems are often deployed into dynamic environments whose behavior is liable to change. This chapter reviews the features of complex systems and proposes an approach based on creating digital twins of systems that are capable of adaptation. We discuss technologies for digital twins and propose that the adaptation should be based on machine learning. We provide a simple tutorial example of agents with machine learning using our proposed technology and describe how we have used the technology to build a digital twin for supply chain networks.
            ",autonomous vehicle
10.1016/j.procs.2017.08.343,filtered,Procedia Computer Science,sciencedirect,2017-12-31,sciencedirect,Classification of Asthma Severity and Medication Using TensorFlow and Multilevel Databases,https://api.elsevier.com/content/article/pii/S1877050917317532,"Escalating cost of treating chronic diseases demand that they be, to the extent possible, self-managed by the patients. In self-management of disease an imperative is to predict, the possible future state of morbidity (at time, T¹), given the present precursor conditions (at time, Tº) and expected precursor condition (at time, T¹). This paper reports the results of a study to evaluate the potential use of using TensorFlow and Inpatient Databases at national level and hospital level for predicting the asthma severity. Methods of Deep Neural Networks (DNN) have been deployed in classification of morbidity conditions, as well as treatment options. The results indicate that training a DNN to predict asthma severity level or the imminence of an asthma attack is possible.",autonomous vehicle
10.1016/B978-0-323-85172-5.00018-6,filtered,"Electronic Devices, Circuits, and Systems for Biomedical Applications",sciencedirect,2021-12-31,sciencedirect,Chapter 22: Health monitoring system,https://api.elsevier.com/content/article/pii/B9780323851725000186,"
               Electronics have become an essential part of biomedicine. The urge for real-time health monitoring and disease detection at an early stage has created a rapid growth of the market for smart sensors. Biosensors have investigated the prospects of point of care (POC) applications for better management of healthcare, and efforts are being made to make these more efficient. Integrating with micro-electro-mechanical systems (MEMS) and nano-electro-mechanical systems (NEMS) technology has enabled biosensors to be automated and more precise, with higher accuracy data sensing systems. The application of biosensors with POC has increased research related to nanotechnology, advanced functional sensing materials, miniaturized sensing system development, AI, and the internet of things (IoT). Breath analysis is one such form for which biosensors have been used. Diabetes, Parkinson disease, urinary tract infections, lung cancer, kidney disease, pancreas infection, etc., can be detected through breath analysis. This chapter deals with a smart sensor system for diagnosis of diseases, precisely chronologic at an early stage. The sensor system is developing for detecting volatile organic compounds. Sensor arrays are deployed to collect and process electromagnetic or acoustic signals. Health monitoring systems provides a better perception of the patient’s condition, allowing doctors to make the correct diagnosis in real time and enhance curative procedure. IoT integrated with machine learning and artificial intelligence plays a vital role here.
            ",autonomous vehicle
10.1016/j.robot.2013.11.011,filtered,Robotics and Autonomous Systems,sciencedirect,2014-04-30,sciencedirect,Autonomous tactile perception: A combined improved sensing and Bayesian nonparametric approach,https://api.elsevier.com/content/article/pii/S0921889013002285,"
                  In recent years, autonomous robots have increasingly been deployed in unknown environments and required to manipulate or categorize unknown objects. In order to cope with these unfamiliar situations, improvements must be made both in sensing technologies and in the capability to autonomously train perception models. In this paper, we explore this problem in the context of tactile surface identification and categorization. Using a highly-discriminant tactile probe based upon large bandwidth, triple axis accelerometer that is sensitive to surface texture and material properties, we demonstrate that unsupervised learning for surface identification with this tactile probe is feasible. To this end, we derived a Bayesian nonparametric approach based on Pitman–Yor processes to model power-law distributions, an extension of our previous work using Dirichlet processes Dallaire et al. (2011). When tested against a large collection of surfaces and without providing the actual number of surfaces, the tactile probe combined with our proposed approach demonstrated near-perfect recognition in many cases and achieved perfect recognition given the right conditions. We consider that our combined improvements demonstrate the feasibility of effective autonomous tactile perception systems.
               ",autonomous vehicle
10.1016/j.future.2021.04.005,filtered,Future Generation Computer Systems,sciencedirect,2021-09-30,sciencedirect,An argumentation enabled decision making approach for Fall Activity Recognition in Social IoT based Ambient Assisted Living systems,https://api.elsevier.com/content/article/pii/S0167739X21001205,"
                  With the advancement in Information and Communication Technologies (ICTs), smart devices are becoming even more smart and intelligent with every passing day. Further, the evolution of speaking and hearing enabled devices in an IoT network is transforming the face of research in the Social IoT domain. However, the integration of argumentation enabled devices in Social IoT network has not been fully explored by researchers in the past. Therefore, this research work focuses on development of argument enabled Social IoT networks. In this paper, a fuzzy argument based classification scheme termed as Classification Enhanced with Fuzzy Argumentation (CleFAR) is proposed. The proposed scheme is deployed for classification of fall activities in fall prevention applications. A novel framework for fall prevention system using Fall Activity Recognition (FAR) is presented. The proposed system is designed for the purpose of fall activity recognition in smart home Ambient Assisted Living (AAL) systems. To experimentally evaluate the system’s performance, a smart home AAL environment is simulated and the inhabitant’s routine activity dataset is generated. The fall activities are simulated using wearable fall detection systems. The proposed scheme is trained and tested on generated datasets and its performance is compared with traditional classification algorithms such as Random Forest (RF), Support Vector Machines (SVM), Naive Bayes (NB), Decision Tree (DT) and Artificial Neural Networks (ANN) as well as existing argumentation based game theoretic Weighted Voting Scheme (WVS). Experimental results indicate that the proposed scheme outperforms the traditional classification schemes and WVS approach with prediction accuracy up to 91%. It turns out that the proposed approach achieves significant improvement over the existing schemes.
               ",autonomous vehicle
10.1016/j.neucom.2017.02.024,filtered,Neurocomputing,sciencedirect,2017-06-07,sciencedirect,"Data-driven prognostics using a combination of constrained K-means clustering, fuzzy modeling and LOF-based score",https://api.elsevier.com/content/article/pii/S0925231217302941,"
                  Today, failure modes characterization and early detection is a key issue in complex assets. This is due to the negative impact of corrective operations and the conservative strategies usually put in practice, focused on preventive maintenance. In this paper anomaly detection issue is addressed in new monitoring sensor data by characterizing and modeling operational behaviors. The learning framework is performed on the basis of a machine learning approach that combines constrained K-means clustering for outlier detection and fuzzy modeling of distances to normality. A final score is also calculated over time, considering the membership degree to resulting fuzzy sets and a local outlier factor. Proposed solution is deployed in a CBM+ platform for online monitoring of the assets. In order to show the validity of the approach, experiments have been conducted on real operational faults in an auxiliary marine diesel engine. Experimental results show a fully comprehensive yet accurate prognostics approach, improving detection capabilities and knowledge management. The performance achieved is quite high (precision, sensitivity and specificity above 93% and 
                        
                           κ
                           =
                           0.93
                        
                     ), even more so given that a very small percentage of real faults are present in data.
               ",autonomous vehicle
10.1016/j.asoc.2014.01.026,filtered,Applied Soft Computing,sciencedirect,2014-05-31,sciencedirect,A support vector machine model for intelligent selection of data representations,https://api.elsevier.com/content/article/pii/S1568494614000453,"
                  The design and implementation of efficient abstract data types are important issues for software developers. Selecting and creating the appropriate data structure for implementing an abstract data type is not a trivial problem for a software developer, as it is hard to anticipate all the usage scenarios of the deployed application. Moreover, it is not clear how to select a good implementation for an abstract data type when access patterns to it are highly variant, or even unpredictable. The problem of automatic data structure selection is a complex one because each particular data structure is usually more efficient for some operations and less efficient for others, that is why a static analysis for choosing the best representation can be inappropriate, as the performed operations cannot be statically predicted. Therefore, we propose a predictive model in which the software system learns to choose the appropriate data representation, at runtime, based on the effective data usage pattern. This paper describes a novel approach in using a support vector machine model in order to dynamically select the most suitable representation for an aggregate according to the software system's execution context. Computational experiments confirm a good performance of the proposed model and indicates the potential of our proposal. The advantages of our approach in comparison with similar existing approaches are also emphasized.
               ",autonomous vehicle
10.1007/s40070-020-00116-7,filtered,EURO Journal on Decision Processes,sciencedirect,2020-11-30,sciencedirect,What does it mean to provide decision support to a responsible and competent expert?: The case of diagnostic decision support systems,https://api.elsevier.com/content/article/pii/S2193943821001151,"Decision support consists in helping a decision-maker to improve his/her decisions. However, clients requesting decision support are often themselves experts and are often taken by third parties and/or the general public to be responsible for the decisions they make. This predicament raises complex challenges for decision analysts, who have to avoid infringing upon the expertise and responsibility of the decision-maker. The case of diagnosis decision support in healthcare contexts is particularly illustrative. To support clinicians in their work and minimize the risk of medical error, various decision support systems have been developed, as part of information systems that are now ubiquitous in healthcare contexts. To develop, in collaboration with the hospitals of Lyon, a diagnostic decision support system for day-to-day customary consultations, we propose in this paper a critical analysis of current approaches to diagnostic decision support, which mainly consist in providing them with guidelines or even full-fledged diagnosis recommendations. We highlight that the use of such decision support systems by physicians raises responsibility issues, but also that it is at odds with the needs and constraints of customary consultations. We argue that the historical choice to favor guidelines or recommendations to physicians implies a very specific vision of what it means to support physicians, and we argue that the flaws of this vision partially explain why current diagnostic decision support systems are not accepted by physicians in their application to customary situations. Based on this analysis, we propose that decision support to physicians for customary cases should be deployed in an “adjustive” approach, which consists in providing physicians with the data on patients they need, when they need them, during consultations. The rationale articulated in this article has a more general bearing than clinical decision support and bears lessons for decision support activities in other contexts where decision-makers are competent and responsible experts.",autonomous vehicle
10.1016/j.sysarc.2015.07.007,filtered,Journal of Systems Architecture,sciencedirect,2015-11-30,sciencedirect,Exploring ICMetrics to detect abnormal program behaviour on embedded devices,https://api.elsevier.com/content/article/pii/S1383762115000776,"
                  Execution of unknown or malicious software on an embedded system may trigger harmful system behaviour targeted at stealing sensitive data and/or causing damage to the system. It is thus considered a potential and significant threat to the security of embedded systems. Generally, the resource constrained nature of commercial off-the-shelf (COTS) embedded devices, such as embedded medical equipment, does not allow computationally expensive protection solutions to be deployed on these devices, rendering them vulnerable. A Self-Organising Map (SOM) based and Fuzzy C-means based approaches are proposed in this paper for detecting abnormal program behaviour to boost embedded system security. The presented technique extracts features derived from processor’s Program Counter (PC) and Cycles per Instruction (CPI), and then utilises the features to identify abnormal behaviour using the SOM. Results achieved in our experiment show that the proposed SOM based and Fuzzy C-means based methods can identify unknown program behaviours not included in the training set with 90.9% and 98.7% accuracy.
               ",autonomous vehicle
10.1016/S0169-023X(00)00049-5,filtered,Data & Knowledge Engineering,sciencedirect,2001-03-31,sciencedirect,Information agent technology for the Internet: A survey,https://api.elsevier.com/content/article/pii/S0169023X00000495,"
                  The vast amount of heterogeneous information sources available on the Internet demands advanced solutions for acquiring, mediating, and maintaining relevant information for the common user. Intelligent information agents are autonomous computational software entities that are especially meant to (1) provide pro-active resource discovery, (2) resolve information impedance of information consumers and providers, and (3) offer value-added information services and products. These agents are supposed to cope with the difficulties associated with the information overload of the user, preferably just in time.
                  Based on a systematic classification of intelligent information agents, this paper presents an overview of the basic key enabling technologies needed to build such agents, and respective examples of information agent systems currently deployed on the Internet.
               ",autonomous vehicle
10.1016/j.compeleceng.2007.05.010,filtered,Computers & Electrical Engineering,sciencedirect,2007-11-30,sciencedirect,Improving network security using genetic algorithm approach,https://api.elsevier.com/content/article/pii/S0045790607000584,"
                  With the expansion of Internet and its importance, the types and number of the attacks have also grown making intrusion detection an increasingly important technique. In this work we have realized a misuse detection system based on genetic algorithm (GA) approach. For evolving and testing new rules for intrusion detection the KDD99Cup training and testing dataset were used. To be able to process network data in real time, we have deployed principal component analysis (PCA) to extract the most important features of the data. In that way we were able to keep the high level of detection rates of attacks while speeding up the processing of the data.
               ",autonomous vehicle
10.1016/j.apor.2021.102726,filtered,Applied Ocean Research,scopus,2021-08-01,scopus,An adaptive data-driven controller for underwater manipulators with variable payload,https://api.elsevier.com/content/abstract/scopus_id/85107617145,"
                  The underwater environment poses a complex problem for developing control systems for underwater manipulators. Modeling the system is a complicated and costly process due to the highly nonlinear dynamics and the presence of unknown hydrodynamical effects. Furthermore, manipulators are usually deployed on Autonomous Underwater Vehicles (AUVs) which further influence and change the dynamics of the arm. This is aggravated in underwater operations where manipulating different objects is necessary. These diverse manipulation tasks introduce external disturbances to the system and can lead to a fast degradation of the control system performance. In this article, we propose a novel adaptive controller for underwater robot manipulators that have to handle varying payloads with different masses, geometries, and buoyant forces. The proposed control strategy utilizes a data-driven model of the system in an optimal control formulation based on neural networks. Moreover, we developed an online tuning strategy, based on the adaptive interaction theory, which allows the gains of the controller to be updated online with respect to a set of performance metrics. Experiments were performed with the robotic arm manipulating a variety of payloads while mounted on both a fixed base and a free-floating vehicle. We present a number of simulated and experimental results that illustrate the benefits of the proposed strategy. In addition, a comparative study against a classical Model Predictive Control (MPC) demonstrates the benefits of our adaptive proposal.
               ",autonomous vehicle
10.1016/j.procs.2021.02.012,filtered,Procedia Computer Science,scopus,2021-01-01,scopus,The impact of the soft errors in convolutional neural network on GPUS: Alexnet as case study,https://api.elsevier.com/content/abstract/scopus_id/85105461752,"Convolutional Neural Networks (CNNs) have been increasingly deployed in many applications, including safety critical system such as healthcare and autonomous vehicles. Meanwhile, the vulnerability of CNN model to soft errors (e.g., caused by radiation induced) rapidly increases, thus reliability is crucial especially in real-time system. There are many traditional techniques for improve the reliability of the system, e.g., Triple Modular Redundancy, but these techniques incur high overheads, which makes them hard to deploy. In this paper, we experimentally evaluate the vulnerable parts of Alexnet mode (e.g., fault injector). Results show that FADD and LD are the top vulnerable instructions against soft errors for Alexnet model, both instructions generate at least 84% of injected faults as SDC errors. Thus, these the only parts of the Alexnet model that need to be hardened instead of using fully duplication solutions.",autonomous vehicle
10.1016/j.biosystemseng.2019.12.013,filtered,Biosystems Engineering,scopus,2020-03-01,scopus,"Internet of Things in arable farming: Implementation, applications, challenges and potential",https://api.elsevier.com/content/abstract/scopus_id/85078034632,"The Internet of Things is allowing agriculture, here specifically arable farming, to become data-driven, leading to more timely and cost-effective production and management of farms, and at the same time reducing their environmental impact. This review is addressing an analytical survey of the current and potential application of Internet of Things in arable farming, where spatial data, highly varying environments, task diversity and mobile devices pose unique challenges to be overcome compared to other agricultural systems. The review contributes an overview of the state of the art of technologies deployed. It provides an outline of the current and potential applications, and discusses the challenges and possible solutions and implementations. Lastly, it presents some future directions for the Internet of Things in arable farming. Current issues such as smart phones, intelligent management of Wireless Sensor Networks, middleware platforms, integrated Farm Management Information Systems across the supply chain, or autonomous vehicles and robotics stand out because of their potential to lead arable farming to smart arable farming. During the implementation, different challenges are encountered, and here interoperability is a key major hurdle throughout all the layers in the architecture of an Internet of Things system, which can be addressed by shared standards and protocols. Challenges such as affordability, device power consumption, network latency, Big Data analysis, data privacy and security, among others, have been identified by the articles reviewed and are discussed in detail. Different solutions to all identified challenges are presented addressing technologies such as machine learning, middleware platforms, or intelligent data management.",autonomous vehicle
10.1016/j.ifacol.2020.12.2306,filtered,IFAC-PapersOnLine,scopus,2020-01-01,scopus,Path-following control of fish-like robots: A deep reinforcement learning approach,https://api.elsevier.com/content/abstract/scopus_id/85102821107,"
                  In this paper, we propose a deep reinforcement learning (DRL) approach for path-following control of a fish-like robot. The desired path may be a randomly generated Bézier curve. First, to implement the locomotion control of the fish-like robot, we design a modified Central Pattern Generated (CPG) model, using which the fish achieves varied swimming behaviors just by adjusting a single control input. To reduce the reality gap between simulation and the physical system, using the experimental data of the real fish-like robot, we build a surrogate simulation environment, which also well balances the accuracy and the speed of training. Second, for the path-following control, we select the advantage actor-critic (A2C) approach and train the control policy in the surrogate simulation environment with a straight line as the desired path. Then the trained control policy is directly deployed on a physical fish-like robot to follow a randomly generated Bézier curve. The experimental results show that our proposed approach has good practical applicability in view of its efficiency and feasibility in controlling the physical fishlike robot. This work shows a novel and promising way to control biomimetic underwater robots in the real world.
               ",autonomous vehicle
10.1016/j.trpro.2020.03.108,filtered,Transportation Research Procedia,scopus,2020-01-01,scopus,Estimating time of arrival of trains at level crossings for the provision of multimodal cooperative services,https://api.elsevier.com/content/abstract/scopus_id/85084662425,"While cooperative services have been almost fully deployed in the road sector and are already being implemented in various cities in Europe as a pre-requisite for the introduction of autonomous vehicles, few attempts have been made in the same direction for the rail sector. This study proposes a system that aims to improve safety and minimize risk in the meeting point between road and rail, known as level crossings, by monitoring the location of floating road vehicles via a mobile device application. A neural network predictive model for estimating time of arrival of trains is also utilized. The safety system has been implemented and tested under real life conditions in the city of Thessaloniki, Greece.",autonomous vehicle
10.1109/TVT.2018.2819806,filtered,IEEE Transactions on Vehicular Technology,IEEE,2018-07-01 00:00:00,ieeexplore,Autonomous Vehicle Control Through the Dynamics and Controller Learning,https://ieeexplore.ieee.org/document/8325485/,"Parameters tuning of the model and the controller is an essential problem for autonomous vehicles. Traditionally, parameter tuning work is accomplished by manual operation or grid search, which is a tedious and time-consuming work. Recently, thanks to the development of machine learning community, several automatic controller parameter tuning approaches emerged, which usually model the performance function as a Gaussian process, and complete the automatic tuning procedure via Bayesian optimization. However, the existing approaches rarely consider the time-varying feature of the system performance, which is practical in many scenarios, induced by the unmodeled interactions between the system and the environment. In this paper, we take both of the dynamic model uncertainty and the controller parameters uncertainty into account, and tune them to find a global optimal choice for minimizing the time-varying control costs, which is modeled by the time-varying Gaussian process. We provide a novel algorithm, named as time-varying controller optimization. We validate our approach on synthetic simulation and real experiment, respectively. Taking the cumulative regret as the performance metric, we find that our approach has a better performance compared with the stationary algorithm.",autonomous vehicle
10.1109/IROS.2014.6943162,filtered,2014 IEEE/RSJ International Conference on Intelligent Robots and Systems,IEEE,2014-09-18 00:00:00,ieeexplore,Spatio-temporal motion features for laser-based moving objects detection and tracking,https://ieeexplore.ieee.org/document/6943162/,"This paper proposes a spatio-temporal motion feature detection and tracking method using range sensors working on a moving platform. The proposed spatio-temporal motion features are similar to optical flow but are extended on a moving platform with fusion of odometry and show much better classification accuracy with consideration of different uncertainties. In the proposal, the ego motion is compensated by odometry sensors and the laser scan points are accumulated and represented as space-time point clouds, from which the velocities and moving directions can be extracted. Based on these spatio-temporal features, a supervised learning technique is applied to classify the points as static or moving and Kalman filters are implemented to track the moving objects. A real experiment is performed during day and night on an autonomous vehicle platform and shows promising results in a crowded and dynamic environment.",autonomous vehicle
10.1109/ICUAS.2019.8797731,filtered,2019 International Conference on Unmanned Aircraft Systems (ICUAS),IEEE,2019-06-14 00:00:00,ieeexplore,Deep Learning with Semi-Synthetic Training Images for Detection of Non-Cooperative UAVs,https://ieeexplore.ieee.org/document/8797731/,"This paper presents a method to generate a dataset for training a deep convolutional network to detect a non cooperative unmanned aerial vehicle in video data. Deep convolutional network have shown a great potential for tasks like object detection and have been continuously improved in the last years. Still, the amount of training data is large and their generation can be complex and time consuming, especially if the appearance of the detected object is not clearly specified. The concept presented here is to train a deep convolutional neural network just with a few two dimensional images of unmanned aerial vehicle to simplify the process of generating training data. Performance of the trained network is evaluated with data from real experimental flights and compared with hand-labeled ground truth data to validate the correctness. To cover situations when the classifier fails at the detection, the output is integrated in a image processing pipeline for object tracking in order to establish a continuous tracking.",autonomous vehicle
10.1109/SPEEDAM.2014.6871963,filtered,"2014 International Symposium on Power Electronics, Electrical Drives, Automation and Motion",IEEE,2014-06-20 00:00:00,ieeexplore,A real-time system based on a neural network model to control hexacopter trajectories,https://ieeexplore.ieee.org/document/6871963/,"Modern aerospace vehicles are expected to have non-conventional flight envelopes and, in order to operate in uncertain environments, they must guarantee a high level of robustness and adaptability. A Neural Networks (NN) controller, with real-time learning capability, can be used in applications with manned or unmanned aerial vehicles. In this paper we propose a realtime system, based on a NN model, in order to control the trajectories of a hexacopter. The paper shows a performance evaluation, through a real experimental testbed, of the proposed approach in terms of error measures and obtained coordinates of the hexacopter.",autonomous vehicle
10.1007/s10846-015-0324-x,filtered,Journal of Intelligent & Robotic Systems,Springer,2016-12-01 00:00:00,springer,An Integrated System for UAV Control Using a Neural Network Implemented in a Prototyping Board,http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-015-0324-x,"Modern aerospace vehicles are expected to have non-conventional flight envelopes and then, in order to operate in uncertain environments, they must guarantee a high level of robustness and adaptability. A Neural Network (NN) controller, with real-time learning capability, can be used in applications with manned or unmanned aerial vehicles. In this paper a novel real-time control system, based on a NN model, in order to control the trajectories of a hexacopter is proposed. The proposed NN is optimized by the analytical calculation of the embedding parameters. The paper shows a performance evaluation, through a real experimental testbed, of the proposed approach in terms of error measures and computation of the angular velocities of the hexacopter.",autonomous vehicle
http://arxiv.org/abs/2010.15441v1,filtered,arxiv,arxiv,2020-10-29 09:29:47+00:00,arxiv,"Self-awareness in intelligent vehicles: Feature based dynamic Bayesian
  models for abnormality detection",http://arxiv.org/abs/2010.15441v1,"The evolution of Intelligent Transportation Systems in recent times
necessitates the development of self-awareness in agents. Before the intensive
use of Machine Learning, the detection of abnormalities was manually programmed
by checking every variable and creating huge nested conditions that are very
difficult to track. This paper aims to introduce a novel method to develop
self-awareness in autonomous vehicles that mainly focuses on detecting abnormal
situations around the considered agents. Multi-sensory time-series data from
the vehicles are used to develop the data-driven Dynamic Bayesian Network (DBN)
models used for future state prediction and the detection of dynamic
abnormalities. Moreover, an initial level collective awareness model that can
perform joint anomaly detection in co-operative tasks is proposed. The GNG
algorithm learns the DBN models' discrete node variables; probabilistic
transition links connect the node variables. A Markov Jump Particle Filter
(MJPF) is applied to predict future states and detect when the vehicle is
potentially misbehaving using learned DBNs as filter parameters. In this paper,
datasets from real experiments of autonomous vehicles performing various tasks
used to learn and test a set of switching DBN models.",autonomous vehicle
10.1016/j.engappai.2020.103612,filtered,Engineering Applications of Artificial Intelligence,sciencedirect,2020-05-31,sciencedirect,Incorporating domain knowledge into reinforcement learning to expedite welding sequence optimization,https://api.elsevier.com/content/article/pii/S0952197620300804,"
                  Welding Sequence Optimization (WSO) is very effective to minimize the structural deformation, however selecting proper welding sequence leads to a combinatorial optimization problem. State-of-the-art algorithms could take more than one week to compute the best sequence for an assembly of eight weld beads which is unrealistic for the early stages of Product Delivery Process (PDP). In this article, we develop and implement a novel Reinforcement Q-learning algorithm for WSO where structural deformation is used to compute reward function. We utilize a thermo-mechanical Finite Element Analysis (FEA) to predict deformation. The exploration–exploitation dilemma has been tackled by domain knowledge driven 
                        ε
                     -greedy algorithm into Q-RL which helps to expedite the WSO and we call this novel algorithm as DKQRL. We run welding simulation experiment using well-known Simufact® software on a typical widely used mounting bracket which contains eight welding beads. DKQRL allows the reduction of structural deformation up to 
                        ∼
                     71% and it substantially speeds up the computational time over Modified Lowest Cost Search (MLCS), Genetic Algorithm (GA), exhaustive search, and standard RL algorithm. Results of welding simulation demonstrate a reasonable agreement with real experiment in terms of structural deformation.
               ",autonomous vehicle
10.1016/j.comcom.2017.08.005,filtered,Computer Communications,sciencedirect,2017-11-01,sciencedirect,A reinforcement learning-based link quality estimation strategy for RPL and its impact on topology management,https://api.elsevier.com/content/article/pii/S0140366417305704,"
                  Over the last few years, standardisation efforts are consolidating the role of the Routing Protocol for Low-Power and Lossy Networks (RPL) as the standard routing protocol for IPv6-based Wireless Sensor Networks (WSNs). Although many core functionalities are well defined, others are left implementation dependent. Among them, the definition of an efficient link-quality estimation (LQE) strategy is of paramount importance, as it influences significantly both the quality of the selected network routes and nodes’ energy consumption. In this paper, we present RL-Probe, a novel strategy for link quality monitoring in RPL, which accurately measures link quality with minimal overhead and energy waste. To achieve this goal, RL-Probe leverages both synchronous and asynchronous monitoring schemes to maintain up-to-date information on link quality and to promptly react to sudden topology changes, e.g. due to mobility. Our solution relies on a reinforcement learning model to drive the monitoring procedures in order to minimise the overhead caused by active probing operations. The performance of the proposed solution is assessed by means of simulations and real experiments. Results demonstrated that RL-Probe helps in effectively improving packet loss rates, allowing nodes to promptly react to link quality variations as well as to link failures due to node mobility.
               ",autonomous vehicle
10.1016/j.jterra.2020.12.002,filtered,Journal of Terramechanics,scopus,2021-08-01,scopus,Recurrent and convolutional neural networks for deep terrain classification by autonomous robots,https://api.elsevier.com/content/abstract/scopus_id/85099601850,"
                  The future challenge for field robots is to increase the level of autonomy towards long distance (>1 km) and duration (>1h) applications. One of the key technologies is the ability to accurately estimate the properties of the traversed terrain to optimize onboard control strategies and energy efficient path-planning, ensuring safety and avoiding possible immobilization conditions that would lead to mission failure. Two main hypotheses are put forward in this research. The first hypothesis is that terrain can be effectively detected by relying exclusively on the measurement of quantities that pertain to the robot-ground interaction, i.e., on proprioceptive signals. Therefore, no visual or depth information is required. Then, artificial deep neural networks can provide an accurate and robust solution to the classification problem of different terrain types. Under these hypotheses, sensory signals are classified as time series directly by a Recurrent Neural Network or by a Convolutional Neural Network in the form of higher-level features or spectrograms resulting from additional processing. In both cases, results obtained from real experiments show comparable or better performance when contrasted with standard Support Vector Machine with the additional advantage of not requiring an a priori definition of the feature space.
               ",autonomous vehicle
10.1016/j.robot.2020.103652,filtered,Robotics and Autonomous Systems,scopus,2020-12-01,scopus,Self-awareness in intelligent vehicles: Feature based dynamic Bayesian models for abnormality detection,https://api.elsevier.com/content/abstract/scopus_id/85092022930,"
                  The evolution of Intelligent Transportation Systems in recent times necessitates the development of self-awareness in agents. Before the intensive use of Machine Learning, the detection of abnormalities was manually programmed by checking every variable and creating huge nested conditions that are very difficult to track. This paper aims to introduce a novel method to develop self-awareness in autonomous vehicles that mainly focuses on detecting abnormal situations around the considered agents. Multi-sensory time-series data from the vehicles are used to develop the data-driven Dynamic Bayesian Network (DBN) models used for future state prediction and the detection of dynamic abnormalities. Moreover, an initial level collective awareness model that can perform joint anomaly detection in co-operative tasks is proposed.
                  The GNG algorithm learns the DBN models’ discrete node variables; probabilistic transition links connect the node variables. A Markov Jump Particle Filter (MJPF) is applied to predict future states and detect when the vehicle is potentially misbehaving using learned DBNs as filter parameters.
                  In this paper, datasets from real experiments of autonomous vehicles performing various tasks used to learn and test a set of switching DBN models.
               ",autonomous vehicle
10.1016/j.oceaneng.2019.106602,filtered,Ocean Engineering,scopus,2019-12-15,scopus,End-to-end navigation for Autonomous Underwater Vehicle with Hybrid Recurrent Neural Networks,https://api.elsevier.com/content/abstract/scopus_id/85074239082,"
                  This paper presents a novel navigation method for Autonomous Underwater Vehicle (AUV). In respect of improving the precision of navigation, recent research mainly focused on how to reduce the system model error. However, existing optimization methods are less efficient and effective in decreasing interference of sensor deviation. Motivated by the excellent performance of deep-learning, a Hybrid Recurrent Neural Networks (Hybrid RNNs) framework is proposed to estimate the AUV position. Firstly, since the different sensors have different data frequency, this method employs unidirectional and bi-directional long short-term memory (LSTM) with multiple memory units to handle raw sensor values in a single calculation cycle. Subsequently, using the outputs of LSTMs and the time interval of the cycle above, the fully connected layers could obtain the displacements of AUV. Eventually, to verify the effectiveness of the proposed navigation algorithm, a series of evaluations have been carried out, which are based on a public dataset and real experimental data of our AUV. The evaluation results have been validated that the proposed method can reduce the interference of sensor deviation, and has better accuracy as well as fault tolerance for navigation. Meanwhile, it could also satisfy the real-time requirement.
               ",autonomous vehicle
10.1109/SSRR.2018.8468611,filtered,"2018 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)",IEEE,2018-08-08 00:00:00,ieeexplore,Reinforcement Learning for Autonomous UAV Navigation Using Function Approximation,https://ieeexplore.ieee.org/document/8468611/,"Unmanned aerial vehicles (UAV) are commonly used for search and rescue missions in unknown environments, where an exact mathematical model of the environment may not be available. This paper proposes a framework for the UAV to locate a missing human after a natural disaster in such environment, using a reinforcement learning (RL) algorithm. A function approximation based RL algorithm is proposed to deal with a large number of states representation and to obtain a faster convergence time. We conducted both simulated and real implementations to show how the UAVs can successfully learn to carry out the task without colliding with obstacles. Technical aspects for applying RL algorithm to a UAV system and UAV flight control were also addressed.",autonomous vehicle
http://arxiv.org/abs/1801.05086v1,filtered,arxiv,arxiv,2018-01-16 01:14:12+00:00,arxiv,Autonomous UAV Navigation Using Reinforcement Learning,http://arxiv.org/abs/1801.05086v1,"Unmanned aerial vehicles (UAV) are commonly used for missions in unknown
environments, where an exact mathematical model of the environment may not be
available. This paper provides a framework for using reinforcement learning to
allow the UAV to navigate successfully in such environments. We conducted our
simulation and real implementation to show how the UAVs can successfully learn
to navigate through an unknown environment. Technical aspects regarding to
applying reinforcement learning algorithm to a UAV system and UAV flight
control were also addressed. This will enable continuing research using a UAV
with learning capabilities in more important applications, such as wildfire
monitoring, or search and rescue missions.",autonomous vehicle
10.1109/ICICCS51141.2021.9432186,filtered,2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS),IEEE,2021-05-08 00:00:00,ieeexplore,Pothole and Object Detection for an Autonomous Vehicle Using YOLO,https://ieeexplore.ieee.org/document/9432186/,"Object Detection is an key software and a fundamental task for an autonomous driving system that provides remarkable change in computer vision. İn recent years, company's are planning to launch autonomous vehicle in an full swing that's the most important ascpets for object detection and one of most challenging task for locating specific object from from multiple objects in a specific scenario. The computer vision and machine learning algorithm is the important tool for detecting objects in and around the environment. In this paper, which consists of two parts The first part is implemented on object detection in the surrounding with Yolo (You Only Look Once)Algorithm provides exact classification and position which is configured on newly created datasets for classes of object: a car, a person, a truck, a bus, traffic light, motorcycle, pothole, wetland uses the Convolutional Neural Network and max-polling layer for prediction that improves detecting of small target and these deep learning technique provides a high accuracy for detecting real world. Detecting potholes in Indian road help the autonomous vehicle to move smoothly without getting struck in the potholes. In part two of the proposed method is implemented on Raspberry pi4 a popular embedded computer board explores suitability for the running objects. That solves the real world problems and improves the impact on detecting objects. Knowing pothole and wetland detection for self-driving vehicle is needed badly to solve the road lay problems like: accident, slowing down the transport system these are solved by deep learning.",autonomous vehicle
10.1109/ICCA51439.2020.9264552,filtered,2020 IEEE 16th International Conference on Control & Automation (ICCA),IEEE,2020-10-11 00:00:00,ieeexplore,Zero-Shot Autonomous Vehicle Policy Transfer: From Simulation to Real-World via Adversarial Learning,https://ieeexplore.ieee.org/document/9264552/,"In this article, we demonstrate a zero-shot transfer of an autonomous driving policy from simulation to University of Delaware's scaled smart city with adversarial multi-agent reinforcement learning, in which an adversary attempts to decrease the net reward by perturbing both the inputs and outputs of the autonomous vehicles during training. We train the autonomous vehicles to coordinate with each other while crossing a roundabout in the presence of an adversary in simulation. The adversarial policy successfully reproduces the simulated behavior and incidentally outperforms, in terms of travel time, both a human-driving baseline and adversary-free trained policies. Finally, we demonstrate that the addition of adversarial training considerably improves the performance of the policies after transfer to the real world compared to Gaussian noise injection.",autonomous vehicle
10.1109/TCSII.2020.3011367,filtered,IEEE Transactions on Circuits and Systems II: Express Briefs,IEEE,2021-01-01 00:00:00,ieeexplore,An Extensive Soft Error Reliability Analysis of a Real Autonomous Vehicle Software Stack,https://ieeexplore.ieee.org/document/9146326/,"Automotive systems are integrating artificial intelligence and complex software stacks aiming to interpret the real world, make decisions, and perform actions without human input. The occurrence of soft errors in such systems can lead to wrong decisions, which might ultimately incur in life losses. This brief focuses on the soft error susceptibility assessment of a real automotive application running on top of unmodified Linux kernels, and considering two commercially available processors, and three cross-compilers. Results collected from more than 29 thousand simulation hours show that the occurrence of faults in critical functions may cause 2.16× more failures on the system.",autonomous vehicle
10.1109/OCEANSE.2019.8867293,filtered,OCEANS 2019 - Marseille,IEEE,2019-06-20 00:00:00,ieeexplore,3D Multibeam Echo Sounder Data Processing Using Distributed Computing. Application To False Alarm Reduction And Unsupervised Underwater Object Recognition For Safe Navigation,https://ieeexplore.ieee.org/document/8867293/,"The goal of this study is to take advantage of artificial intelligence (AI) algorithms and distributed computing ecosystem to enhance the 3D-multibeam echo sounder data processing functionality. We consider first the post processing case, where a complete dataset has been recorded during sea trials. Hence, our suggested framework designed for massive real world data processing allows employing false alarm reduction and underwater object recognition techniques, which can be easily used as decision making for underwater autonomous vehicle safe navigation.",autonomous vehicle
10.1109/ICVES.2016.7548165,filtered,2016 IEEE International Conference on Vehicular Electronics and Safety (ICVES),IEEE,2016-07-12 00:00:00,ieeexplore,A new hopfield-type neural network approach to multi-goal vehicle navigation in unknown environments,https://ieeexplore.ieee.org/document/7548165/,"A Hopfield-type neural networks (HNN) algorithm associated with histogram navigation method is proposed in this paper for real-time map building and path planning for multiple goals applications. In real world applications such as rescue robots, service robots, mining mobile robots, and mine searching robots, etc., an autonomous vehicle needs to reach multiple goals with a shortest path that, in this paper, is capable of being implemented by a HNN method with minimized overall distance. Once a global trajectory is planned, a foraging-enabled trail is created to guide the vehicle to the multiple goals. A histogram-based local navigation algorithm is employed to plan a collision-free path along the trail planned by the global path planner. A re-planning-based algorithm aims to generate trajectory while an autonomous vehicle explores through a terrain with map building in unknown environments. In this paper, simulation and experimental results demonstrate that the real-time concurrent mapping and multi-goal navigation of an autonomous vehicle is successfully performed under unknown environments.",autonomous vehicle
10.1109/ISNCC49221.2020.9297258,filtered,"2020 International Symposium on Networks, Computers and Communications (ISNCC)",IEEE,2020-10-22 00:00:00,ieeexplore,Autonomous Learning Intelligent Vehicles Engineering: ALIVE 1.0,https://ieeexplore.ieee.org/document/9297258/,"The increasing number of vehicles on roads brings more risks associated with vehicular travel. Nevertheless, with the massive attraction towards self-driving vehicles and the use of artificial intelligence, a trained physical Autonomous Vehicle (AV) is now a major part of transports future. This paper discusses the limitations of the related research based on autonomous vehicles; particularly those who are not taking into account the real-world physics. It also proposes an Autonomous Learning Intelligent Vehicles Engineering, called ALIVE to let each vehicle have additional information about its surroundings in order to get an extended perception of its environment. Moreover, ALIVE car sensors will gather in real-time the required data concerning the vehicles environment which are fused into a learning algorithm predicting the vehicle's response. We tested our algorithm through different mazes to evaluate its efficiency to avoid obstacles and its capacity to adapt to any type of terrain. This has been done to make ALIVE versatile, open source, low-cost and work in any environment. Preliminary results demonstrate the effectiveness of ALIVE in terms of obstacle avoidance and delay minimization. Besides, we hope that our project can be used by other researchers to test their artificial intelligence in the real world instead of keeping it in a simulation.",autonomous vehicle
10.1109/ITSC48978.2021.9564891,filtered,2021 IEEE International Intelligent Transportation Systems Conference (ITSC),IEEE,2021-09-22 00:00:00,ieeexplore,Direct Image Based Traffic Junction Crossing System for Autonomous Vehicles,https://ieeexplore.ieee.org/document/9564891/,"One of the most common traffic scenario when navigating in urban area is the traffic junction. Crossing a traffic junction is not trivial for an autonomous vehicle as it needs to perform both scene understanding and decision making tasks. In this work we introduce a two-stage vision-based system for an autonomous vehicle that is capable of deciding when to cross a traffic junction safely. The first stage of the system consists of various convolutional neural network (CNN) models that are utilized to obtain information about the traffic junction. The information is then used in the second stage of the system to decide whether to cross the traffic junction. Here, it is represented as affordances and directly used by a Bayesian network to infer the final decision without the need for an environment model. The Bayesian network models the decision making process by taking into consideration the traffic rules associated with a traffic junction and avoiding collision with another traffic participant entering the traffic junction. We evaluated the feasibility of the system as well as the various components within it using real world data and achieved encouraging accuracy results. The results show the potential of the system to help autonomous vehicles to cross a traffic junction safely.",autonomous vehicle
10.1109/ICRA48506.2021.9561299,filtered,2021 IEEE International Conference on Robotics and Automation (ICRA),IEEE,2021-06-05 00:00:00,ieeexplore,Efficient and Robust LiDAR-Based End-to-End Navigation,https://ieeexplore.ieee.org/document/9561299/,"Deep learning has been used to demonstrate end-to-end neural network learning for autonomous vehicle control from raw sensory input. While LiDAR sensors provide reliably accurate information, existing end-to-end driving solutions are mainly based on cameras since processing 3D data requires a large memory footprint and computation cost. On the other hand, increasing the robustness of these systems is also critical; however, even estimating the model’s uncertainty is very challenging due to the cost of sampling-based methods. In this paper, we present an efficient and robust LiDAR-based end-to-end navigation framework. We first introduce Fast-LiDARNet that is based on sparse convolution kernel optimization and hardware-aware model design. We then propose Hybrid Evidential Fusion that directly estimates the uncertainty of the prediction from only a single forward pass and then fuses the control predictions intelligently. We evaluate our system on a full-scale vehicle and demonstrate lane-stable as well as navigation capabilities. In the presence of out-of-distribution events (e.g., sensor failures), our system significantly improves robustness and reduces the number of takeovers in the real world.",autonomous vehicle
10.1109/IV48863.2021.9575135,filtered,2021 IEEE Intelligent Vehicles Symposium (IV),IEEE,2021-07-17 00:00:00,ieeexplore,End-to-End Intersection Handling using Multi-Agent Deep Reinforcement Learning,https://ieeexplore.ieee.org/document/9575135/,"Navigating through intersections is one of the main challenging tasks for an autonomous vehicle. However, for the majority of intersections regulated by traffic lights, the problem could be solved by a simple rule-based method in which the autonomous vehicle behavior is closely related to the traffic light states. In this work, we focus on the implementation of a system able to navigate through intersections where only traffic signs are provided. We propose a multi-agent system using a continuous, model-free Deep Reinforcement Learning algorithm used to train a neural network for predicting both the acceleration and the steering angle at each time step. We demonstrate that agents learn both the basic rules needed to handle intersections by understanding the priorities of other learners inside the environment, and to drive safely along their paths. Moreover, a comparison between our system and a rule-based method proves that our model achieves better results especially with dense traffic conditions. Finally, we test our system on real world scenarios using real recorded traffic data, proving that our module is able to generalize both to unseen environments and to different traffic conditions.",autonomous vehicle
10.1109/ITSC45102.2020.9294625,filtered,2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC),IEEE,2020-09-23 00:00:00,ieeexplore,Exploring the Capabilities and Limits of 3D Monocular Object Detection - A Study on Simulation and Real World Data,https://ieeexplore.ieee.org/document/9294625/,"3D object detection based on monocular camera data is a key enabler for autonomous driving. The task however, is ill-posed due to lack of depth information in 2D images. Recent deep learning methods show promising results to recover depth information from single images by learning priors about the environment. Several competing strategies tackle this problem. In addition to the network design, the major difference of these competing approaches lies in using a supervised or self-supervised optimization loss function, which require different data and ground truth information. In this paper, we evaluate the performance of a 3D object detection pipeline which is parameterizable with different depth estimation configurations. We implement a simple distance calculation approach based on camera intrinsics and 2D bounding box size, a self-supervised, and a supervised learning approach for depth estimation. Ground truth depth information cannot be recorded reliable in real world scenarios. This shifts our training focus to simulation data. In simulation, labeling and ground truth generation can be automatized. We evaluate the detection pipeline on simulator data and a real world sequence from an autonomous vehicle on a race track. The benefit of training on simulation data for the application of the network on real world data is investigated. Advantages and drawbacks of the different depth estimation strategies are discussed.",autonomous vehicle
10.1109/ITSC45102.2020.9294368,filtered,2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC),IEEE,2020-09-23 00:00:00,ieeexplore,Formal Scenario-Based Testing of Autonomous Vehicles: From Simulation to the Real World,https://ieeexplore.ieee.org/document/9294368/,"We present a new approach to automated scenario-based testing of the safety of autonomous vehicles, especially those using advanced artificial intelligence-based components, spanning both simulation-based evaluation as well as testing in the real world. Our approach is based on formal methods, combining formal specification of scenarios and safety properties, algorithmic test case generation using formal simulation, test case selection for track testing, executing test cases on the track, and analyzing the resulting data. Experiments with a real autonomous vehicle at an industrial testing facility support our hypotheses that (i) formal simulation can be effective at identifying test cases to run on the track, and (ii) the gap between simulated and real worlds can be systematically evaluated and bridged.",autonomous vehicle
10.1109/ITSC48978.2021.9564750,filtered,2021 IEEE International Intelligent Transportation Systems Conference (ITSC),IEEE,2021-09-22 00:00:00,ieeexplore,Frequency Modulated Continuous Wave Radar-Based Navigation Algorithm using Artificial Neural Network for Autonomous Driving,https://ieeexplore.ieee.org/document/9564750/,"Autonomous driving is a highly complex task, which involves the use of numerous sensors and various algorithms. Testing of algorithms is difficult and therefore mostly done in simulations. Radar technology will play a key part due to various advantages. In this paper we present a solution to one aspect of autonomous driving, which is the development of a detection algorithm on a moving platform, which is capable of tracking and sending the commands to follow a preceding object, by means of sensor data from a low power 60 GHz Frequency Modulated Continuous Wave (FMCW) radar. The moving platform is based on a miniaturized autonomous vehicle that is used for data gathering as well as algorithm evaluation. To the best of the author's knowledge, this is the first time that processing of radar data via Deep Convolutional Neural Networks (DCNN) for navigation purposes is performed in real time on the edge device operating in a real world environment and not simulative.",autonomous vehicle
10.1109/ISDA.2011.6121753,filtered,2011 11th International Conference on Intelligent Systems Design and Applications,IEEE,2011-11-24 00:00:00,ieeexplore,LIDAR based perception solution for autonomous vehicles,https://ieeexplore.ieee.org/document/6121753/,"In this work, a solution for clustering and tracking obstacles in the area covered by a LIDAR sensor is presented. It is based on a combination of simple artificial intelligence techniques and it is conceived as an initial version of a detection and tracking system for objects of any shape that an autonomous vehicle might find in its surroundings. The proposed solution divides the problem into three consecutive phases: 1) segmentation, 2) fragmentation detection and clustering and 3) tracking. The work done has been tested with real world LIDAR scan samples taken from an instrumented vehicle.",autonomous vehicle
10.1109/ICRA.2019.8793668,filtered,2019 International Conference on Robotics and Automation (ICRA),IEEE,2019-05-24 00:00:00,ieeexplore,Learning to Drive from Simulation without Real World Labels,https://ieeexplore.ieee.org/document/8793668/,"Simulation can be a powerful tool for under-standing machine learning systems and designing methods to solve real-world problems. Training and evaluating methods purely in simulation is often “doomed to succeed” at the desired task in a simulated environment, but the resulting models are incapable of operation in the real world. Here we present and evaluate a method for transferring a vision-based lane following driving policy from simulation to operation on a rural road without any real-world labels. Our approach leverages recent advances in image-to-image translation to achieve domain transfer while jointly learning a single-camera control policy from simulation control labels. We assess the driving performance of this method using both open-loop regression metrics, and closed-loop performance operating an autonomous vehicle on rural and urban roads.",autonomous vehicle
10.1109/ICTAI.2019.00220,filtered,2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI),IEEE,2019-11-06 00:00:00,ieeexplore,Learning to Drive via Apprenticeship Learning and Deep Reinforcement Learning,https://ieeexplore.ieee.org/document/8995417/,"With the implementation of reinforcement learning (RL) algorithms, current state-of-art autonomous vehicle technology have the potential to get closer to full automation. However, most of the applications have been limited to game domains or discrete action space which are far from the real world driving. Moreover, it is very tough to tune the parameters of reward mechanism since the driving styles vary a lot among the different users. For instance, an aggressive driver may prefer driving with high acceleration whereas some conservative drivers prefer a safer driving style. Therefore, we propose an apprenticeship learning in combination with deep reinforcement learning approach that allows the agent to learn the driving and stopping behaviors with continuous actions. We use gradient inverse reinforcement learning (GIRL) algorithm to recover the unknown reward function and employ REINFORCE as well as Deep Deterministic Policy Gradient algorithm (DDPG) to learn the optimal policy. The performance of our method is evaluated in simulation-based scenario and the results demonstrate that the agent performs human like driving and even better in some aspects after training.",autonomous vehicle
10.1109/ITSC48978.2021.9565009,filtered,2021 IEEE International Intelligent Transportation Systems Conference (ITSC),IEEE,2021-09-22 00:00:00,ieeexplore,PandaSet: Advanced Sensor Suite Dataset for Autonomous Driving,https://ieeexplore.ieee.org/document/9565009/,"The accelerating development of autonomous driving technology has placed greater demands on obtaining large amounts of high-quality data. Representative, labeled, real world data serves as the fuel for training deep learning networks, critical for improving self-driving perception algorithms. In this paper, we introduce PandaSet, the first dataset produced by a complete, high-precision autonomous vehicle sensor kit with a no-cost commercial license. The dataset was collected using one 360° mechanical spinning LiDAR, one forward-facing, long-range LiDAR, and 6 cameras. The dataset contains more than 100 scenes, each of which is 8 seconds long, and provides 28 types of labels for object classification and 37 types of labels for semantic segmentation. We provide baselines for LiDAR-only 3D object detection, LiDAR-camera fusion 3D object detection and LiDAR point cloud segmentation. For more details about PandaSet and the development kit, see https://scale.com/open-datasets/pandaset.",autonomous vehicle
10.1109/IROS.2018.8593420,filtered,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),IEEE,2018-10-05 00:00:00,ieeexplore,Safe Reinforcement Learning on Autonomous Vehicles,https://ieeexplore.ieee.org/document/8593420/,"There have been numerous advances in reinforcement learning, but the typically unconstrained exploration of the learning process prevents the adoption of these methods in many safety critical applications. Recent work in safe reinforcement learning uses idealized models to achieve their guarantees, but these models do not easily accommodate the stochasticity or high-dimensionality of real world systems. We investigate how prediction provides a general and intuitive framework to constraint exploration, and show how it can be used to safely learn intersection handling behaviors on an autonomous vehicle.",autonomous vehicle
10.1109/SIMPAR.2018.8376285,filtered,"2018 IEEE International Conference on Simulation, Modeling, and Programming for Autonomous Robots (SIMPAR)",IEEE,2018-05-19 00:00:00,ieeexplore,The sleepwalker framework: Verification and validation of autonomous vehicles by mixed reality LiDAR stimulation,https://ieeexplore.ieee.org/document/8376285/,"Verification and validation of autonomous mobile systems, such as autonomous vehicles, is indispensable, since conflicts and serious incidents are rarely acceptable when human beings are involved. Although integrative simulation frameworks are commonly applied to test these systems, such simulations are usually too idealistic, while real world tests are both, expensive and not reproducible. To overcome this problem, we present the framework Sleepwalker for verifying and validating autonomous vehicles: Similar to a human sleepwalker, our framework stimulates the automated driving function at a sensor close level with virtual laserscans mixed with sensor data from the real environment. Thus, the autonomous driving function explicitely builds up a mixed reality environment model as a basis for the subsequent components and therefore enables an overall performance assessment. The instantiation of the framework is adaptable so it to can be balanced between the required result's plausibility and scenario criticality. We demonstrate the distinguished benefits of our framework by different instantiations stimulating an autonomous vehicle and conclude with further research questions.",autonomous vehicle
10.1109/ITSC.2014.6958056,filtered,17th International IEEE Conference on Intelligent Transportation Systems (ITSC),IEEE,2014-10-11 00:00:00,ieeexplore,Traffic light recognition in varying illumination using deep learning and saliency map,https://ieeexplore.ieee.org/document/6958056/,"The accurate detection and recognition of traffic lights is important for autonomous vehicle navigation and advanced driver aid systems. In this paper, we present a traffic light recognition algorithm for varying illumination conditions using computer vision and machine learning. More specifically, a convolutional neural network is used to extract and detect features from visual camera images. To improve the recognition accuracy, an on-board GPS sensor is employed to identify the region-of-interest, in the visual image, that contains the traffic light. In addition, a saliency map containing the traffic light location is generated using the normal illumination recognition to assist the recognition under low illumination conditions. The proposed algorithm was evaluated on our data sets acquired in a variety of real world environments and compared with the performance of a baseline traffic signal recognition algorithm. The experimental results demonstrate the high recognition accuracy of the proposed algorithm in varied illumination conditions.",autonomous vehicle
10.1109/VR50410.2021.00054,filtered,2021 IEEE Virtual Reality and 3D User Interfaces (VR),IEEE,2021-04-01 00:00:00,ieeexplore,Virtual Morality: Using Virtual Reality to Study Moral Behavior in Extreme Accident Situations,https://ieeexplore.ieee.org/document/9417784/,"Virtual Reality (VR) technologies are widely employed to investigate human behavior in dangerous situations that cannot be safely reproduced in the real world, allowing researchers to study in an ecological way complex scenarios such as training for risky jobs, safety procedures, emergencies and, more recently, moral dilemmas in driving context. Understanding how people act when facing severe accidents involving unavoidable collisions has extremely important implications for the design and development of the “decisional system” of Autonomous Vehicles (AV s). However, previous studies have not focused on the differences between being the driver acting in a complex moral situation or being in a self-driving car that chooses for you. In the present paper, we described a case study that uses a first-person virtual reality simulation to investigate people's emotional reactions, perceived sense of responsibility, and acceptability of moral behavior in human and autonomous driving modalities. The main findings showed that participants experienced a high sense of presence in our simulation and react differently to the two driving conditions, showing a greater arousal, a more negative valence, and an increased sense of responsibility when faced moral dilemmas as drivers. Instead, in scenarios that did not involve killing someone (non-moral dilemmas), being in a fully autonomous vehicle was judged less pleasant than being the actual driver. These results suggest that people prefer to be in control only in common driving situations and not when their actions have deadly consequences on other people, suggesting the need to consider emotional factors in studying decision-making applied to autonomous vehicles, as a mean to reach a more complete understanding of people's reactions to this new technology, and to possibly gain insights for the design of autonomous driving systems and, more generally, AI-driven machines.",autonomous vehicle
10.1109/JSAC.2021.3087248,filtered,IEEE Journal on Selected Areas in Communications,IEEE,2021-08-01 00:00:00,ieeexplore,Effective Communications: A Joint Learning and Communication Framework for Multi-Agent Reinforcement Learning Over Noisy Channels,https://ieeexplore.ieee.org/document/9466501/,"We propose a novel formulation of the “effectiveness problem” in communications, put forth by Shannon and Weaver in their seminal work “<italic>The Mathematical Theory of Communication</italic>”, by considering multiple agents communicating over a noisy channel in order to achieve better coordination and cooperation in a multi-agent reinforcement learning (MARL) framework. Specifically, we consider a multi-agent partially observable Markov decision process (MA-POMDP), in which the agents, in addition to interacting with the environment, can also communicate with each other over a noisy communication channel. The noisy communication channel is considered explicitly as part of the dynamics of the environment, and the message each agent sends is part of the action that the agent can take. As a result, the agents learn not only to collaborate with each other but also to communicate “effectively” over a noisy channel. This framework generalizes both the traditional communication problem, where the main goal is to convey a message reliably over a noisy channel, and the “learning to communicate” framework that has received recent attention in the MARL literature, where the underlying communication channels are assumed to be error-free. We show via examples that the joint policy learned using the proposed framework is superior to that where the communication is considered separately from the underlying MA-POMDP. This is a very powerful framework, which has many real world applications, from autonomous vehicle planning to drone swarm control, and opens up the rich toolbox of deep reinforcement learning for the design of multi-user communication systems.",autonomous vehicle
10.1109/CONIT51480.2021.9498342,filtered,2021 International Conference on Intelligent Technologies (CONIT),IEEE,2021-06-27 00:00:00,ieeexplore,Deep Learning for Vision and Decision Making in Self Driving Cars-Challenges with Ethical Decision Making,https://ieeexplore.ieee.org/document/9498342/,"In recent times self-driving vehicle is a revolutionary Idea. Self-Driving cars are the driver less cars where the car runs by itself called as Autonomous cars. There are lot of underlying Technologies like Machine Learning and Deep Learning. This paper focuses on vision and decision making capabilities of self-driving cars using Deep Learning and also ethical challenges while making sudden decisions. Deep Learning is a sub part of Machine Learning which is inspired by the working process and functionality of biological neurons. Vision is the important and strong aspect of self-driving car that contribute a lot i.e., sensing the environment to identify obstacles, reading traffic signs, understanding traffic signal light status, traffic light count down time recognition and finally making appropriate decision on what it sees. Decision making is a complex task when it comes to real time scenarios, where the autonomous driving agent need to make decisions based on the data generated in real world. There is huge amount of data generated by various sensors, radars and LIDAR’s. Every time it is like a new experience for the autonomous driving agent, it is difficult to make different policies for different driving scenarios because of existing rules and amount of previous data available. Decision making depends on different technologies like computer vision and deep learning. Ethical decision making, sacrificial decision making is really a tough job for autonomous driving agent in unavoidable accident situations where people lives are at stake.",autonomous vehicle
10.1109/IJCNN52387.2021.9534086,filtered,2021 International Joint Conference on Neural Networks (IJCNN),IEEE,2021-07-22 00:00:00,ieeexplore,Lane Intrusion Behaviors Dataset: Action Recognition in Real-world Highway Scenarios for Self-driving,https://ieeexplore.ieee.org/document/9534086/,"It is necessary for the development of self-driving to fulfill the requirements for safety, stability, and intelligence, especially in high-speed conditions. Therefore, the detection of pedestrians that may occur in highway scenarios during driving and understanding the meaning of their behaviors in advance are significantly important for the self-driving vehicle to make correct decisions. However, no existing datasets are available for behavior recognition in self-driving scenarios. In order to advance the task of interactive cognition between the vehicle and pedestrians, in this paper, we present a new dataset, called THU-IntrudBehavior, that collects lane intrusion behaviors of pedestrians that can be applied in real world highway scenarios. The dataset contains diverse behaviors of single or multiple pedestrians/cyclists that are simulated in different urban roads under various weather conditions. We describe annotations of each video and report several experimental results of baseline methods on our self-collected dataset. Our THU-IntrudBehavior dataset provides new support for behavior recognition in high-speed conditions for self-driving.",autonomous vehicle
10.1109/ICME46284.2020.9102928,filtered,2020 IEEE International Conference on Multimedia and Expo (ICME),IEEE,2020-07-10 00:00:00,ieeexplore,A Study Of Parking-Slot Detection With The Aid Of Pixel-Level Domain Adaptation,https://ieeexplore.ieee.org/document/9102928/,"The self-parking system is an important component of self-driving vehicles. Such a system needs to detect and locate the parking-slots from surround-view images, and then guide the vehicle to the designated parking-slot. In the real world, the appearances and environmental conditions of parking-slots can be rich and varied. Thus, to train the parking-slot detection model, it is necessary to collect and label a huge quantity of surround-view images covering as many real cases as possible. Such a process is cumbersome and costly, and will be repeated whenever encountering an unseen parking condition that is quite different from the ones covered by existing training set. To this end, in this paper we propose an extensible pipeline, namely FakePS, to assist parking-slot detection model training by making use of synthetic data. Specifically, with FakePS, we can first build various simulated parking scenes and collect labeled surround-view images automatically. Besides, we resort to pixel-level domain adaptation strategies to enhance the realism of the synthetic images using unlabeled real images while preserving their label information. The efficacy of FakePS has been corroborated by experimental results.",autonomous vehicle
10.1109/ICARSC52212.2021.9429787,filtered,2021 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC),IEEE,2021-04-29 00:00:00,ieeexplore,Advanced Motion Prediction for Self-Driving Cars,https://ieeexplore.ieee.org/document/9429787/,"We aim at socially-aware and socially-consistent vehicles and VRUs trajectory forecasting and interaction understanding. Accurately forecasting the motion of surrounding agents is an extremely complex and challenging task, considering that many factors can affect the future trajectory of an object. The variety and complexity of road scenes is immense and traffic scene dynamics can be extremely different among different, or even similar, scenarios. Therefore, one major challenge of developing prediction methods is to find comprehensive and generic representations for all common scenarios that can be encountered in the real world. However, one major open question in the field of motion forecasting is how to model such interactions among traffic agents. Understanding how the ego-vehicle actions might influence other actors' behaviors is essential for safe and comfortable motion planning of self-driving vehicles. Additionally, these predictions must be consistent among vehicles and non-overlapping. This can only be achieved by deeply understanding the scene dynamics and the essence of interactions among traffic participants. On the other side, most deep learning based models used for trajectory forecasting operate on data of a fixed size and a fixed spatial organization. We propose to tackle these problems harnessing the power of graph neural networks by modelling each traffic agent as a node and possible interactions between them as edges, obtaining a high-level representation of the traffic scene as a graph.",autonomous vehicle
10.1109/ICSPIS48872.2019.9066130,filtered,2019 5th Iranian Conference on Signal Processing and Intelligent Systems (ICSPIS),IEEE,2019-12-19 00:00:00,ieeexplore,Deep Vision for Navigation of Autonomous Motorcycle in Urban and Semi-Urban Environments,https://ieeexplore.ieee.org/document/9066130/,"Deep neural networks are currently the best solution for road and traffic scene interpretation for autonomous and self-driving vehicles. Compared to the autonomous cars, motorcycles have significant flexibility and advantages in crowded traffic situations and especially in non-urban and off-road areas. Many off-road tracks especially for agriculture and environment management tasks are only traversable with motorcycles. In this paper, a deep neural network is used for design and implementation of the vision system for navigation of an autonomous motorcycle. The proposed framework is evaluated using real world scenarios captured by a real motorcycle in various complex situations. The experimental results show that the proposed framework is capable of highly accurate interpretation of various environments for autonomous navigation of a motorcycle.",autonomous vehicle
10.1109/ICRA48506.2021.9560957,filtered,2021 IEEE International Conference on Robotics and Automation (ICRA),IEEE,2021-06-05 00:00:00,ieeexplore,Out-of-Distribution Robustness with Deep Recursive Filters,https://ieeexplore.ieee.org/document/9560957/,"Accurate state and uncertainty estimation is imperative for mobile robots and self driving vehicles to achieve safe navigation in pedestrian rich environments. A critical component of state and uncertainty estimation for robot navigation is to perform robustly under out-of-distribution noise. Traditional methods of state estimation decouple perception and state estimation making it difficult to operate on noisy, high dimensional data. Here, we describe an approach that combines the expressiveness of deep neural networks with principled approaches to uncertainty estimation found in recursive filters. We particularly focus on techniques that provide better robustness to out-of-distribution noise and demonstrate applicability of our approach on two scenarios: a simple noisy pendulum state estimation problem and real world pedestrian localization using the nuScenes dataset [1]. We show that our approach improves state and uncertainty estimation compared to baselines while achieving approximately 3× improvement in computational efficiency.",autonomous vehicle
10.1109/ICAIIC.2019.8669037,filtered,2019 International Conference on Artificial Intelligence in Information and Communication (ICAIIC),IEEE,2019-02-13 00:00:00,ieeexplore,Deep Learning Algorithm using Virtual Environment Data for Self-driving Car,https://ieeexplore.ieee.org/document/8669037/,"Recent outstanding progresses in artificial intelligence researches enable many tries to implement self-driving cars. However, in real world, there are a lot of risks and cost problems to acquire training data for self-driving artificial intelligence algorithms. This paper proposes an algorithm to collect training data from a driving game, which has quite similar environment to the real world. In the data collection scheme, the proposed algorithm gathers both driving game screen image and control key value. We employ the collected data from virtual game environment to learn a deep neural network. Experimental result for applying the virtual driving game data to drive real world children's car show the effectiveness of the proposed algorithm.",autonomous vehicle
10.1109/ICECA.2018.8474620,filtered,"2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA)",IEEE,2018-03-31 00:00:00,ieeexplore,"Working model of Self-driving car using Convolutional Neural Network, Raspberry Pi and Arduino",https://ieeexplore.ieee.org/document/8474620/,"The evolution of Artificial Intelligence has served as the catalyst in the field of technology. We can now develop things which was once just an imagination. One of such creation is the birth of self-driving car. Days have come where one can do their work or even sleep in the car and without even touching the steering wheel, accelerator you will still be able to reach your target destination safely. This paper proposes a working model of self-driving car which is capable of driving from one location to the other or to say on different types of tracks such as curved tracks, straight tracks and straight followed by curved tracks. A camera module is mounted over the top of the car along with Raspberry Pi sends the images from real world to the Convolutional Neural Network which then predicts one of the following directions. i.e. right, left, forward or stop which is then followed by sending a signal from the Arduino to the controller of the remote controlled car and as a result of it the car moves in the desired direction without any human intervention.",autonomous vehicle
10.1109/IJCNN48605.2020.9207499,filtered,2020 International Joint Conference on Neural Networks (IJCNN),IEEE,2020-07-24 00:00:00,ieeexplore,Image-Based Real-Time Path Generation Using Deep Neural Networks,https://ieeexplore.ieee.org/document/9207499/,"We propose an image-based real-time path planner for the self-driving car IARA, named DeepPath. DeepPath uses a CNN for inferring paths from images. During the self-driving car operation, DeepPath receives an image and the current car pose. Then, it sends the image to a CNN trained to infer a model of the path. After that, DeepPath generates the path in the IARA's coordinate system using the path model. Subsequently, given the current IARA's pose, DeepPath transforms each pose of the path in the IARA's coordinate system into another pose in the world coordinate system. Finally, it sends the path to the IARA's Behavior Selector subsystem, the next subsystem in the IARA's Decision-Making system. We evaluated the performance of DeepPath in real world scenarios. Our results showed that DeepPath is able to correctly generate paths for IARA that differ only slightly from those defined by humans.",autonomous vehicle
10.1109/INMIC.2018.8595684,filtered,2018 IEEE 21st International Multi-Topic Conference (INMIC),IEEE,2018-11-02 00:00:00,ieeexplore,Self-Driving Cars Using CNN and Q-Learning,https://ieeexplore.ieee.org/document/8595684/,"DrivingMatter is an experiment carried out to understand the deeper side of an autonomous car. In 1900s, idea was to drive car on Moon from Earth. This was initial motivation which grew from there and now expanding to complex system of roads in the real world. A book-sized Raspberry Pi based autonomous car is built to carry out the experiment on hardware. Software side was accomplished by developing a Python based library for controlling and communicating with car over a network or locally within the car. For environment learning two methodologies are practiced; Supervised learning: Drove the car on an environment/road and collected 3, 000+ data-points. Based on this a CNN model was trained which achieved 73 % test 89 % train accuracy. Reinforcement learning: Car is trained for three different road signs; Stop, No left, and Traffic light using DQN with existing CNN model. These road signs are detected in the environment using OpenCV cascade classifiers.",autonomous vehicle
10.1109/LRA.2018.2857402,filtered,IEEE Robotics and Automation Letters,IEEE,2018-10-01 00:00:00,ieeexplore,Failing to Learn: Autonomously Identifying Perception Failures for Self-Driving Cars,https://ieeexplore.ieee.org/document/8412512/,"One of the major open challenges in self-driving cars is the ability to detect cars and pedestrians to safely navigate in the world. Deep learning-based object detector approaches have enabled great advances in using camera imagery to detect and classify objects. But for a safety critical application, such as autonomous driving, the error rates of the current state of the art are still too high to enable safe operation. Moreover, the characterization of object detector performance is primarily limited to testing on prerecorded datasets. Errors that occur on novel data go undetected without additional human labels. In this letter, we propose an automated method to identify mistakes made by object detectors without ground truth labels. We show that inconsistencies in the object detector output between a pair of similar images can be used as hypotheses for false negatives (e.g., missed detections) and using a novel set of features for each hypothesis, an off-the-shelf binary classifier can be used to find valid errors. In particular, we study two distinct cues-temporal and stereo inconsistencies-using data that are readily available on most autonomous vehicles. Our method can be used with any camera-based object detector and we illustrate the technique on several sets of real world data. We show that a state-of-the-art detector, tracker, and our classifier trained only on synthetic data can identify valid errors on KITTI tracking dataset with an average precision of 0.94. We also release a new tracking dataset with 104 sequences totaling 80,655 labeled pairs of stereo images along with ground truth disparity from a game engine to facilitate further research.",autonomous vehicle
10.1109/ICRA.2018.8460994,filtered,2018 IEEE International Conference on Robotics and Automation (ICRA),IEEE,2018-05-25 00:00:00,ieeexplore,Deep Trail-Following Robotic Guide Dog in Pedestrian Environments for People who are Blind and Visually Impaired - Learning from Virtual and Real Worlds,https://ieeexplore.ieee.org/document/8460994/,"Navigation in pedestrian environments is critical to enabling independent mobility for the blind and visually impaired (BVI) in their daily lives. White canes have been commonly used to obtain contact feedback for following walls, curbs, or man-made trails, whereas guide dogs can assist in avoiding physical contact with obstacles or other pedestrians. However, the infrastructures of tactile trails or guide dogs are expensive to maintain. Inspired by the autonomous lane following of self-driving cars, we wished to combine the capabilities of existing navigation solutions for BVI users. We proposed an autonomous, trail-following robotic guide dog that would be robust to variances of background textures, illuminations, and interclass trail variations. A deep convolutional neural network (CNN) is trained from both the virtual and realworld environments. Our work included major contributions: 1) conducting experiments to verify that the performance of our models trained in virtual worlds was comparable to that of models trained in the real world; 2) conducting user studies with 10 blind users to verify that the proposed robotic guide dog could effectively assist them in reliably following man-made trails.",autonomous vehicle
10.23919/SPA.2019.8936736,filtered,"2019 Signal Processing: Algorithms, Architectures, Arrangements, and Applications (SPA)",IEEE,2019-09-20 00:00:00,ieeexplore,Machine Learning for Embodied Agents: From Signals to Symbols and Actions,https://ieeexplore.ieee.org/document/8936736/,"The aim of this tutorial lecture is to show the role of machine learning and some other AI-related techniques in embodied autonomous agents, and autonomous robots in particular. In this tutorial we bring to the forefront the aspects of robotics that are closely related to computer science. We believe that the progress in algorithms and data processing methods together with the rapid increase in the available computing power were the driving forces behind the successes of modern robotics in the last decade. During this period robots of various classes migrated from university laboratories to commercial companies and then to our everyday life, as now everybody can buy an autonomous vacuum cleaner or lawnmower, while self-driving cars and drones for goods delivery are waiting for proper legal regulations to enter the market. Robotics and Artificial Intelligence already went a long path of mutual inspiration and common development, starting from the symbolic AI (aka Good Old-Fashioned Artificial Intelligence) and its extensive use in early autonomous robots, such as Shakey the robot, created in SRI International by Nils Nilsson, considered one of the ""fathers"" of modern AI. We briefly characterize the range of the most important applications of typical AI methods in modern robotics, including motion planning algorithms [2,3], interpretation of sensory data leading to creation of a world model [4 ,5], and classical learning methods, such as reinforcement learning [6]. However, what made robotics a part of the new wave of AI applications was the recent ""revolution"" of machine learning, mostly grounded in the enormous success of the deep learning paradigm and its many variants that proved to outclass classic methods in a broad range of problems related to the processing of images and other types of signals. The quick adoption of the recent advances in Machine Learning (ML) in robotics seems to be motivated by the fact that ML gives the possibility to infer solutions from data, as opposed to the classic model-based paradigm that was for decades used in robotics. Whereas the modelbased solutions are mathematically elegant and theoretically provable (with respect to stability, convergence, etc.) they often fail once confronted with real-world problems and real sensory data, as their underlying mathematical models are only a very rough approximation of the real world. Therefore, a wider adoption of ML in robotics gives a chance to make robots more robust and adaptive. On the other hand, we should try to use the new techniques without discarding the knowledge and expertise we already have - machine learning methods can benefit a lot from the prior knowledge and the known structure of the problem that has to be solved by learning. This knowledge and structure can be adopted from the model-based methods that a re already well-established in robotics. In the lecture robots are understood in a broad sense, as all embodied agents that have means to physically interact with the environment. They can be either manipulators, mobile robots, aerial vehicles, self-driving cars, and various ""smart"" devices and sensors. In the second part of the lecture attention is paid to specific problems that appear in application of machine learning to embodied agents, such as the need to search a for solution in huge, multi-dimensional spaces (""curse of dimensionality""), and the ever-present problem of representation and incorporation of uncertainty in the processing of real-world data. Some examples of applications of autonomous robots are given, which were successful due to the use of AI - in particular the probabilistic representation of knowledge and machine learning. The most prominent examples are the DARPA competitions: ""Grand Challenge"", ""Urban Challenge"" and ""Robotics Challenge"" (DRC), and the ""Amazon Picking Challenge"", which proves the interest of large corporations in the development of AI-based robotics [7]. In the third part of the lecture new research directions offered by machine learning and the increased availability of training data are discussed. An overview of the most popular application areas of ML in robotics and other autonomous systems is presented along with the typical machine learning paradigms applied in these areas. The focus is on deep learning, mostly using convolutional neural networks to process various sensory data. We discuss three aspects of embodied agents that make machine learning in robotics quite specific with respect to other application areas, such as medical images or natural language processing. The first aspect is dealing with the ""open world"", in which autonomous robots usually operate. This situation breaks the assumptions underlying some popular ML methods, and creates the need to face the problem of unknown classes identification [8] incremental learning [9], and the uncertainty of sensory data [10]. We also stress out that an embodied agent has the ability to actively acquire information [11]. The second aspect is the inference about the scene seen by the agent, where in the case of robotics, semantics and geometry intermingle [12], because the robot has to work in a three-dimensional world, although it often perceives it through twodimensional images [13,14]. The third aspect of our analysis is related to the most important feature of robots that distinguishes them from all other learning agents (software-based). Robots are embodied agents, that is they have a physical ""body"", and are subject to physical constraints, such as the maximum speed of motion or maximum range of perception. Therefore, in ML for robots analysis of the spatio-temporal dependencies in data is very important [15]. Robots support advanced learning methods thanks to the possibility of interaction with the environment - a simple example is active vision with moving camera, a much more complex one is manipulation with active testing of the behavior of objects (repositioning, pushing) [16]. At the end of the lecture, in the context of specific needs and limitations characteristic to the applications of ML in robotics, new concepts of machine learning (e.g. deep reinforcement learning [17], interactive perception [18]) are presented. The lecture is summarized with a brief discussion of the most important challenges and open problems of ML applied to embodied agents.",autonomous vehicle
10.1109/FormaliSE.2019.00012,filtered,2019 IEEE/ACM 7th International Conference on Formal Methods in Software Engineering (FormaliSE),IEEE,2019-05-27 00:00:00,ieeexplore,Parallelizable Reachability Analysis Algorithms for Feed-Forward Neural Networks,https://ieeexplore.ieee.org/document/8807491/,"Artificial neural networks (ANN) have displayed considerable utility in a wide range of applications such as image processing, character and pattern recognition, self-driving cars, evolutionary robotics, and non-linear system identification and control. While ANNs are able to carry out complicated tasks efficiently, they are susceptible to unpredictable and errant behavior due to irregularities that emanate from their complex non-linear structure. As a result, there have been reservations about incorporating them into safety-critical systems. In this paper, we present a reachability analysis method for feed-forward neural networks (FNN) that employ rectified linear units (ReLUs) as activation functions. The crux of our approach relies on three reachable-set computation algorithms, namely exact schemes, lazy-approximate schemes, and mixing schemes. The exact scheme computes an exact reachable set for FNN, while the lazy-approximate and mixing schemes generate an over-approximation of the exact reachable set. All schemes are designed efficiently to run on parallel platforms to reduce the computation time and enhance the scalability. Our methods are implemented in a toolbox called, NNV, and is evaluated using a set of benchmarks that consist of realistic neural networks with sizes that range from tens to a thousand neurons. Notably, NNV successfully computes and visualizes the exact reachable sets of the real world ACAS Xu deep neural networks (DNNs), which are a variant of a family of novel airborne collision detection systems known as the ACAS System X, using a representation of tens to hundreds of polyhedra.",autonomous vehicle
10.1109/ICCCNT.2018.8493745,filtered,"2018 9th International Conference on Computing, Communication and Networking Technologies (ICCCNT)",IEEE,2018-07-12 00:00:00,ieeexplore,Synthetic to Real World Image Translation Using Generative Adversarial Networks,https://ieeexplore.ieee.org/document/8493745/,In this paper we perform synthetic to real world image translation using Cycle Consistent Adversarial Networks and further provide insights as to how the translation can be utilized to build a framework that can solve a plethora of domain adaptation tasks by reducing the same to a supervised problem via image generation and label transfer from a source domain (synthetic images) to a target domain (real world images) thereby eliminating the need for a labeled target domain dataset. We run experiments taking the (GTA) dataset as the source domain and the Cityscape dataset as the target domain and provide a comprehensive evaluation of the experiments. We also provide analysis and visualization of existing domain adaptation techniques and evaluate their pros and cons. A potential application of the concept is in training of self-driving cars as it is difficult to obtain an extensive labeled dataset for every geographical region.,autonomous vehicle
10.1109/BlackSeaCom52164.2021.9527756,filtered,2021 IEEE International Black Sea Conference on Communications and Networking (BlackSeaCom),IEEE,2021-05-28 00:00:00,ieeexplore,Adversarial Machine Learning Security Problems for 6G: mmWave Beam Prediction Use-Case,https://ieeexplore.ieee.org/document/9527756/,"6G is the next generation for the communication systems. In recent years, machine learning algorithms have been applied widely in various fields such as health, transportation, and the autonomous car. The predictive algorithms will be used in 6G problems. With the rapid developments of deep learning techniques, it is critical to take the security concern into account when applying the algorithms. While machine learning offers significant advantages for 6G, AI models’ security is normally ignored. Due to the many applications in the real world, security is a vital part of the algorithms. This paper proposes a mitigation method for adversarial attacks against proposed 6G machine learning models for the millimeter-wave (mmWave) beam prediction using adversarial learning. The main idea behind adversarial attacks against machine learning models is to produce faulty results by manipulating trained deep learning models for 6G applications for mmWave beam prediction. We also present the adversarial learning mitigation method’s performance for 6G security in millimeter-wave beam prediction application with fast gradient sign method attack. The mean square errors of the defended model under attack are very close to the undefended model without attack.",autonomous vehicle
10.1109/ICMLA.2016.0020,filtered,2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA),IEEE,2016-12-20 00:00:00,ieeexplore,Assessing Threat of Adversarial Examples on Deep Neural Networks,https://ieeexplore.ieee.org/document/7838124/,"Deep neural networks are facing a potential security threat from adversarial examples, inputs that look normal but cause an incorrect classification by the deep neural network. For example, the proposed threat could result in hand-written digits on a scanned check being incorrectly classified but looking normal when humans see them. This research assesses the extent to which adversarial examples pose a security threat, when one considers the normal image acquisition process. This process is mimicked by simulating the transformations that normally occur in of acquiring the image in a real world application, such as using a scanner to acquire digits for a check amount or using a camera in an autonomous car. These small transformations negate the effect of the carefully crafted perturbations of adversarial examples, resulting in a correct classification by the deep neural network. Thus just acquiring the image decreases the potential impact of the proposed security threat. We also show that the already widely used process of averaging over multiple crops neutralizes most adversarial examples. Normal preprocessing, such as text binarization, almost completely neutralizes adversarial examples. This is the first paper to show that for text driven classification, adversarial examples are an academic curiosity, not a security threat.",autonomous vehicle
10.1109/IVS.2013.6629656,filtered,2013 IEEE Intelligent Vehicles Symposium (IV),IEEE,2013-06-26 00:00:00,ieeexplore,From autonomous robotics toward autonomous cars,https://ieeexplore.ieee.org/document/6629656/,"For decades, scientists have dreamed of building autonomous cars that can drive without a human driver. Progress in this kind of research recently received an increasing attention in car industries. There are many autonomous car models recently developed. However, they are still infancy since they still lack efficiency and reliability. To obtain efficient and reliable systems, the validation process plays an important role. Nowadays, the validation is strongly related to the number of kilometers of drive. Thus, simulation techniques are used before going into real world driving. We focused our work on developing a methodology to smothly move from simulation into real world car driving. We defined a versatile architecture that simplifies the evaluation of different types of algorithms. Several evaluation systems are shown and discussed.",autonomous vehicle
10.1109/IJCNN.2014.6889888,filtered,2014 International Joint Conference on Neural Networks (IJCNN),IEEE,2014-07-11 00:00:00,ieeexplore,Image-based global localization using VG-RAM Weightless Neural Networks,https://ieeexplore.ieee.org/document/6889888/,"Mapping and localization are fundamental problems in autonomous robotics. Autonomous robots need to know where they are in their area of operation to navigate through it and to perform activities of interest. In this paper, we propose an Image-Based Global Localization (VibGL) system that uses Virtual Generalizing Random Access Memory Weightless Neural Networks (VG-RAM WNN). For mapping, we employ a VG-RAM WNN that learns the world positions associated with the images captured along a trajectory. During the localization, new images from the trajectory are presented to the VG-RAM WNN, which outputs their positions in the world. We performed experiments with our VibGL system applied to the problem of localizing an autonomous car. Our experimental results show that the system is able to learn large maps (several kilometers in length) of real world environments and perform global localization with median pose precision of about 3m. Considering a tolerance of 10m VibGL is able to localize the car 95% of the time.",autonomous vehicle
10.1109/ICRA.2015.7139699,filtered,2015 IEEE International Conference on Robotics and Automation (ICRA),IEEE,2015-05-30 00:00:00,ieeexplore,"Image-based mapping, global localization and position tracking using VG-RAM weightless neural networks",https://ieeexplore.ieee.org/document/7139699/,"Humans can easily memorize images of places and labels (road names, addresses, etc.) associated with them, as well as trajectories defined by sequences of images and corresponding positions. Later, they are able to remember places' labels and relative positions when seeing the same images again. In this work, we present an image-based mapping, global localization and position tracking system based on Virtual Generalizing Random Access Memory (VG-RAM) weightless neural networks, dubbed VIBML. VIBML mimics humans ability of learning about a place and of recognizing the same place in a later moment, as well as of tracking self-movement through the environment using images. We evaluated the performance of VIBML on the precise localization of an autonomous car using real-world datasets. Our experimental results showed that VIBML is able to localize car-like robots on large maps of real world environments with accuracy equivalent to that of state-of-the-art methods - VIBML is able to localize an autonomous car with average positioning error of 1.12m and with 75% of the poses with error below 1.5m in a 3.75km path around the main campus of the Federal University of Espírito Santo.",autonomous vehicle
10.1109/IJCNN.2018.8489363,filtered,2018 International Joint Conference on Neural Networks (IJCNN),IEEE,2018-07-13 00:00:00,ieeexplore,Mapping Road Lanes Using Laser Remission and Deep Neural Networks,https://ieeexplore.ieee.org/document/8489363/,"We propose the use of deep neural networks (DNN) for solving the problem of inferring the position and relevant properties of lanes of urban roads with poor or absent horizontal signalization, in order to allow the operation of autonomous cars in such situations. We take a segmentation approach to the problem and use the Efficient Neural Network (ENet) DNN for segmenting LiDAR remission grid maps into road maps. We represent road maps using what we called road grid maps. Road grid maps are square matrixes and each element of these matrixes represents a small square region of real-world space. The value of each element is a code associated with the semantics of the road map. Our road grid maps contain all information about the roads' lanes required for building the Road Definition Data Files (RDDFs) that are necessary for the operation of our autonomous car, IARA (Intelligent Autonomous Robotic Automobile). We have built a dataset of tens of kilometers of manually marked road lanes and used part of it to train ENet to segment road grid maps from remission grid maps. After being trained, ENet achieved an average segmentation accuracy of 83.7%. We have tested the use of inferred road grid maps in the real world using IARA on a stretch of 3.7 km of urban roads and it has shown performance equivalent to that of the previous IARA's subsystem that uses a manually generated RDDF.",autonomous vehicle
10.1109/LRA.2021.3062354,filtered,IEEE Robotics and Automation Letters,IEEE,2021-04-01 00:00:00,ieeexplore,Robust LiDAR Feature Localization for Autonomous Vehicles Using Geometric Fingerprinting on Open Datasets,https://ieeexplore.ieee.org/document/9363614/,"Localization is a key task for autonomous vehicles. It is often solved with GNSS but due to multipath the performance is often not sufficient. Feature localization systems using LiDAR can deliver an accurate localization but the creation of the necessary feature maps is an effortful task. With digitization of urban planning processes a lot of street level data is being generated and increasingly becomes openly available. We propose a novel feature localization system which utilizes geometric fingerprinting to robustly associate features to a feature map generated from this open data from the city of Berlin. With this association, we perform a precise localization of a vehicle in areas spanning over several square kilometers using an optional IMU, the vehicle's CAN-odometry and an initial pose estimate. We evaluated our system with our autonomous car in real world scenarios and achieved a centimeter precision localization accuracy outperforming a high-cost GNSS. The source code will be published at https://github.com/dcmlr/fingerprint-localization.",autonomous vehicle
10.1109/CVPR.2019.00925,filtered,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),IEEE,2019-06-20 00:00:00,ieeexplore,Attention-Based Adaptive Selection of Operations for Image Restoration in the Presence of Unknown Combined Distortions,https://ieeexplore.ieee.org/document/8954082/,"Many studies have been conducted so far on image restoration, the problem of restoring a clean image from its distorted version. There are many different types of distortion affecting image quality. Previous studies have focused on single types of distortion, proposing methods for removing them. However, image quality degrades due to multiple factors in the real world. Thus, depending on applications, e.g., vision for autonomous cars or surveillance cameras, we need to be able to deal with multiple combined distortions with unknown mixture ratios. For this purpose, we propose a simple yet effective layer architecture of neural networks. It performs multiple operations in parallel, which are weighted by an attention mechanism to enable selection of proper operations depending on the input. The layer can be stacked to form a deep network, which is differentiable and thus can be trained in an end-to-end fashion by gradient descent. The experimental results show that the proposed method works better than previous methods by a good margin on tasks of restoring images with multiple combined distortions.",autonomous vehicle
10.1109/IROS.2018.8594090,filtered,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),IEEE,2018-10-05 00:00:00,ieeexplore,End to End Vehicle Lateral Control Using a Single Fisheye Camera,https://ieeexplore.ieee.org/document/8594090/,"Convolutional neural networks are commonly used to control the steering angle for autonomous cars. Most of the time, multiple long range cameras are used to generate lateral failure cases. In this paper we present a novel model to generate this data and label augmentation using only one short range fisheye camera. We present our simulator and how it can be used as a consistent metric for lateral end-to-end control evaluation. Experiments are conducted on a custom dataset corresponding to more than 10000 km and 200 hours of open road driving. Finally we evaluate this model on real world driving scenarios, open road and a custom test track with challenging obstacle avoidance and sharp turns. In our simulator based on real-world videos, the final model was capable of more than 99% autonomy on urban road.",autonomous vehicle
10.1109/VTC2020-Fall49728.2020.9348690,filtered,2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall),IEEE,2020-12-16 00:00:00,ieeexplore,Fully Convolutional Neural Networks for Automotive Radar Interference Mitigation,https://ieeexplore.ieee.org/document/9348690/,"The interest of the automotive industry has progressively focused on subjects related to driver assistance systems as well as autonomous cars. Cars combine a variety of sensors to perceive their surroundings robustly. Among them, radar sensors are indispensable because of their independence of lighting conditions and the possibility to directly measure velocity. However, radar interference is an issue that becomes prevalent with the increasing amount of radar systems in automotive scenarios. In this paper, we address this issue for frequency modulated continuous wave (FMCW) radars with fully convolutional neural networks (FCNs), a state-of-the-art deep learning technique. We propose two FCNs that take spectrograms of the beat signals as input, and provide the corresponding clean range profiles as output. We propose two architectures for interference mitigation which outperform the classical zeroing technique. Moreover, considering the lack of databases for this task, we release as open source a large scale data set that closely replicates real world automotive scenarios for single-interference cases, allowing others to objectively compare their future work in this domain. The data set is available for download at: http://github.com/ristea/arim.",autonomous vehicle
10.1109/3DV50981.2020.00113,filtered,2020 International Conference on 3D Vision (3DV),IEEE,2020-11-28 00:00:00,ieeexplore,MaskNet: A Fully-Convolutional Network to Estimate Inlier Points,https://ieeexplore.ieee.org/document/9320103/,"Point clouds have grown in importance in the way computers perceive the world. From LIDAR sensors in autonomous cars and drones to the time of flight and stereo vision systems in our phones, point clouds are everywhere. Despite their ubiquity, point clouds in the real world are often missing points because of sensor limitations or occlusions, or contain extraneous points from sensor noise or artifacts. These problems challenge algorithms that require computing correspondences between a pair of point clouds. Therefore, this paper presents a fully-convolutional neural network that identifies which points in one point cloud are most similar (inliers) to the points in another. We show improvements in learning-based and classical point cloud registration approaches when retrofitted with our network. We demonstrate these improvements on synthetic and real-world datasets. Finally, our network produces impressive results on test datasets that were unseen during training, thus exhibiting generalizability. Code and videos are available at https://github.com/vinits5/masknet.",autonomous vehicle
10.1109/ICTER.2014.7083870,filtered,2014 14th International Conference on Advances in ICT for Emerging Regions (ICTer),IEEE,2014-12-13 00:00:00,ieeexplore,Large scale data processing in real world: From analytics to predictions,https://ieeexplore.ieee.org/document/7083870/,"Summary form only given. Large scale data processing analyses and makes sense of large amounts of data. Although the field itself is not new, it is finding many usecases under the theme ""Bigdata"" where Google itself, IBM Watson, and Google's Driverless car are some of success stories. Spanning many fields, Large scale data processing brings together technologies like Distributed Systems, Machine Learning, Statistics, and Internet of Things together. It is a multi-billion-dollar industry including use cases like targeted advertising, fraud detection, product recommendations, and market surveys. With new technologies like Internet of Things (IoT), these use cases are expanding to scenarios like Smart Cities, Smart health, and Smart Agriculture. Some usecases like Urban Planning can be slow, which is done in batch mode, while others like stock markets need results within Milliseconds, which are done in streaming fashion. There are different technologies for each case: MapReduce for batch processing and Complex Event Processing and Stream Processing for real-time usecases. Furthermore, the type of analysis range from basic statistics like mean to complicated prediction models based on machine Learning. In this talk, we will discuss data processing landscape: concepts, usecases, technologies and open questions while drawing examples from real world scenarios.",autonomous vehicle
10.1109/ICCC51575.2020.9345035,filtered,2020 IEEE 6th International Conference on Computer and Communications (ICCC),IEEE,2020-12-14 00:00:00,ieeexplore,Artificial Intelligence Security Issues and Responses,https://ieeexplore.ieee.org/document/9345035/,"As a current disruptive and transformative technology, artificial intelligence is constantly infiltrating all aspects of production and life. However, with the in-depth development and application of artificial intelligence, the security challenges it faces have become more and more prominent. In the real world, attacks against intelligent systems such as the Internet of Things, smart homes, and driverless cars are constantly appearing, and incidents of artificial intelligence being used in cyber-attacks and cybercrimes frequently occur. This article aims to discuss artificial intelligence security issues and propose some countermeasures.",autonomous vehicle
10.1109/AERO.2018.8396807,filtered,2018 IEEE Aerospace Conference,IEEE,2018-03-10 00:00:00,ieeexplore,Learning safe recovery trajectories with deep neural networks for unmanned aerial vehicles,https://ieeexplore.ieee.org/document/8396807/,"Unmanned vehicles that use vision sensors for perception to aid autonomous flight are a highly popular area of research. However, these systems are often prone to failures that are often hard to model. Previous work has focused on using deep learning to detect these failures. In this work, we build on these failure detection systems and develop a pipeline that learns to identify the correct trajectory to execute that restores the vision system and the unmanned vehicle to a safe state. The key challenge with using a deep learning pipeline for this problem is the limited amount of training data available from a real world system. Ideally one requires millions of data points to sufficiently train a model from scratch. However, this is not feasible for an unmanned aerial vehicle. The dataset we operate with is limited to 400-500 points. To sufficiently learn from such a small dataset we leverage the idea of transfer learning and non linear dimensionality reduction. We deploy our pipeline on an unmanned aerial vehicle flying autonomously through outdoor clutter (in a GPS denied environment) and show that we are able to achieve long durations of safe autonomous flight.",autonomous vehicle
10.1109/CICA.2009.4982774,filtered,2009 IEEE Symposium on Computational Intelligence in Control and Automation,IEEE,2009-04-02 00:00:00,ieeexplore,Tutorial CICA-T Computing with intelligence for identification and control of nonlinear systems,https://ieeexplore.ieee.org/document/4982774/,"System characterization and identification are fundamental problems in systems theory and play a major role in the design of controllers. System identification and nonlinear control has been proposed and implemented using intelligent systems such as neural networks, fuzzy logic, reinforcement learning, artificial immune system and many others using inverse models, direct/indirect adaptive, or cloning a linear controller. Adaptive Critic Designs (ACDs) are neural networks capable of optimization over time under conditions of noise and uncertainty. The ACD technique develops optimal control laws using two networks - critic and action. There are merits for each approach adopted will be presented. The primary aim of this tutorial is to provide control and system engineers/researchers from industry/academia, new to the field of computational intelligence with the fundamentals required to benefit from and contribute to the rapidly growing field of computational intelligence and its real world applications, including identification and control of power and energy systems, unmanned vehicle navigation, signal and image processing, and evolvable and adaptive hardware systems.",autonomous vehicle
10.1109/SOLI.2014.6960699,filtered,"Proceedings of 2014 IEEE International Conference on Service Operations and Logistics, and Informatics",IEEE,2014-10-10 00:00:00,ieeexplore,Vehicle position estimation using geometric constants in traffic scene,https://ieeexplore.ieee.org/document/6960699/,"Determination of the correct positional relation is vital for human driver. For unmanned vehicles, the obstacle position in front of the view is also necessary for collision detection. The paper is devoted to the problem that estimates the vehicle position in real world using only a single 2D image. The estimation is an ill-posed problem due to the projective transform; however, through incorporating the geometric constants in the traffic scene, we proposed a solution that calculates the position with sufficient accuracy. The contribution of the proposed method is the use of two geometric constants: the standard size of license plate and the lane-width. Observation shows that the size of license plates has limited patterns and lane-width between two adjacent lanes is usually constant. Introduction of the two constants compensates the uncertainty caused by lack of depth in the mapping between the detected license plates and its position in real world. The conducted experiments show that compared to the conventional methods, the proposed one is accurate for estimating the position.",autonomous vehicle
10.1109/ICIBA50161.2020.9277438,filtered,"2020 IEEE International Conference on Information Technology,Big Data and Artificial Intelligence (ICIBA)",IEEE,2020-11-08 00:00:00,ieeexplore,Recognition and Locating of Damaged Poles in Distribution Network Through Images Shot by Unmanned Aerial Vehicle (UA V),https://ieeexplore.ieee.org/document/9277438/,"The disaster recognition and locating are important for the rush repairment after disaster happened. And there have been some advanced facilities applied for the image collecting, such as unmanned aerial vehicle (UAV). To accelerate the image processing, the intelligent recognition and automatic location solution are both considered instead of the manual way. Firstly, the model based on yolov5 is construed to realize the recognition of damaged poles in distribution network, marked by a rectangle box. Then, the coordinate transformation is adopted to derive the positions of damaged poles in real world with the inputs of coordinates in images and the necessary information extracted from images. With the locations of damaged poles collected, the fast disaster locating can be realized. At last, the practical images are chosen to testify the performance of intelligent recognition and location solution.",autonomous vehicle
10.1109/ACCESS.2020.3026192,filtered,IEEE Access,IEEE,2020-01-01 00:00:00,ieeexplore,Real World Object Detection Dataset for Quadcopter Unmanned Aerial Vehicle Detection,https://ieeexplore.ieee.org/document/9205392/,"Recent years have shown a noticeable rise in the number of incidents with drones, related to both civilian and military installations. While drone neutralization techniques have become increasingly effective, detection most often relies on professional equipment, which is too expensive to be used for all critical nodes and applications. Therefore, there is a need for drone detection systems that could work on low performance hardware. Its critical component consists of an object detection system. In this article, we introduce a new object detection dataset, built entirely to train computer vision based object detection machine learning algorithms for a task of binary object detection to enable automated, industrial camera based detection of multiple drone objects using camera feed. The dataset expands existing multiclass image classification and object detection datasets (ImageNet, MS-COCO, PASCAL VOC, anti-UAV) with a diversified dataset of drone images. In order to maximize the effectiveness of the model, real world footage was utilized, transformed into images and hand-labelled to create a custom set of 56821 images and 55539 bounding boxes. Additionally, semi-automated labelling was proposed, tested and proved to be very useful for object detection applications. The dataset was divided into train and test subsets for further processing and used to generate 603 easily deployable Haar Cascades as well as 819 high performing Deep Neural Networks based models. They were used to test different object detection methods to determine the long term feasibility of a large scale drone detection system utilizing machine learning algorithms. The study has shown that Haar Cascade can be used as the Minimum Viable Product model for mediocre performance but fails to scale up effectively for a larger dataset compared to the Deep Neural Network model.",autonomous vehicle
10.1109/ICRAE48301.2019.9043821,filtered,2019 4th International Conference on Robotics and Automation Engineering (ICRAE),IEEE,2019-11-24 00:00:00,ieeexplore,An Improved Method Based on Deep Reinforcement Learning for Target Searching,https://ieeexplore.ieee.org/document/9043821/,"Unmanned Aerial Vehicle (UAV), due to their high mobility and the ability to cover areas of different heights and locations at relatively low cost, are increasingly used for disaster monitoring and detecting. However, developing and testing UAVs in real world is an expensive task, especially in the domain of search and rescue, most of the previous systems are developed on the basis of greedy or potential-based heuristics without neural network. On the basis of the recent development of deep neural network architecture and deep reinforcement learning (DRL), in this research we improved the probability of success rate of searching target in an unstructured environment by combining image processing algorithms and reinforcement learning methods (RL). This paper aims at the deficiency of target tracking in unstructured environment, trying to propose an algorithm of stationary target positioning of UAV based on computer vision system. Firstly, a new input source is formed by acquiring depth information image of current environment and combining segmentation image. Secondly, the DQN algorithm is used to regulate the reinforcement learning model, and the specific flight response can be independently selected by the UAV through training. This paper utilizes open-source Microsoft UAV simulator AirSim as training and test environment based with Keras a machine learning framework. The main approach investigated in this research is modifying the network of Deep Q-Network, which designs the moving target tracking experiment of UAV in simulation scene. The experimental results demonstrate that this method has better tracking effect.",autonomous vehicle
10.1109/ICAIIC51459.2021.9415209,filtered,2021 International Conference on Artificial Intelligence in Information and Communication (ICAIIC),IEEE,2021-04-16 00:00:00,ieeexplore,Controller module implementation to reduce interrupt in CNPC uplink,https://ieeexplore.ieee.org/document/9415209/,"The unmanned aerial vehicle is used in diverse area. In order to make more use of the unmanned aerial vehicle, reliable communication system is required. CNPC has been developed to standardize the communication system for unmanned aerial vehicle over 150kg. CNPC uplink should support diverse UAV in TDD. To implement CNPC in real world, operating system and FPGA should be used with the interface between the two. To reduce the use of interrupts in uplink implementations on FPGA, simple controller is designed to generate signals which act as the interrupts whenever other user message is needed. To implement this controller in FPGA, this paper deals with timing diagram for this module.",autonomous vehicle
10.1109/TAAI.2015.7407084,filtered,2015 Conference on Technologies and Applications of Artificial Intelligence (TAAI),IEEE,2015-11-22 00:00:00,ieeexplore,Geometric Relation matching based object identification for UAV and UGV cooperation,https://ieeexplore.ieee.org/document/7407084/,"Cognitive sharing of objects is fundamental in a heterogeneous robot system composed of a Unmanned Aerial Vehicle and a ground robot. Since the viewpoint of UAV is greatly different from ground robot, they may have different perceptions about the same objects. That makes it difficult to realize cognitive sharing. In this paper, we proposed a cognitive sharing method between UAV and ground robot by sharing Geometric Relation-based Triangle Representations(GRTR). This paper discribes a robust method for UAV and ground robot to identify the same object among similar objects without sharing appearance information. To copy with the problem of increasing computational cost for the recognition of objects in the ROI, entropy evaluation is employed to evaluate and select unique representations. Finally, we illustrated the proposed method with robots in real world.",autonomous vehicle
10.1109/KBEI.2019.8734904,filtered,2019 5th Conference on Knowledge Based Engineering and Innovation (KBEI),IEEE,2019-03-01 00:00:00,ieeexplore,Low Altitude Aerial Scene Synthesis Using Generative Adversarial Networks for Autonomous Natural Resource Management,https://ieeexplore.ieee.org/document/8734904/,"Deep neural networks are currently the best solution for aerial scene interpretation for Unmanned Aerial Vehicle (UAV) based remote sensing. A problem faced by the deep neural networks is that the deep models require significantly large training datasets which should cover almost all of the scenarios. Gathering these datasets is usually very time consuming and expensive. In this paper, data augmentation and generative adversarial network are used for autonomous synthesis of low altitude aerial scenes for creating a training dataset for deep low altitude aerial video interpretation. The proposed system is evaluated using a real world scenario of road following under foliage in a jungle and the experimental results show that the proposed framework is capable of producing high accuracy training datasets for UAV vision system in natural resource management scenarios.",autonomous vehicle
10.1109/ICUAS51884.2021.9476867,filtered,2021 International Conference on Unmanned Aircraft Systems (ICUAS),IEEE,2021-06-18 00:00:00,ieeexplore,RF Detection and Classification of Unmanned Aerial Vehicles in Environments with Wireless Interference,https://ieeexplore.ieee.org/document/9476867/,"Unmanned Aerial Vehicle (UAV) detection and classification methods include the use of audio, video, thermal, RADAR and radio frequency (RF) signals. RF signals have the ability to detect UAVs at longer ranges but interference from other signals in the same frequency band such as Bluetooth and Wi-Fi at 2.4GHz is a known limitation. The experiments in this paper evaluate the effect of real world Bluetooth and Wi-Fi signal interference on UAV detection and classification, using transfer learning via Convolutional Neural Network (CNN) feature extraction and machine learning classifiers Logistic Regression (LR) and k Nearest Neighbour (kNN). 2 class UAV detection, 4 class UAV type and 10 class flight mode classification are evaluated with graphical representation from the time and frequency domain. Flight modes evaluated included mode 1 - switched on and connected to the controller, mode 2 - hovering and mode 3 - flying. Results show that Bluetooth signals are more likely to interfere with detection and classification accuracy than Wi-Fi signals but that accuracy can be maintained at over 96% by using frequency domain features with LR as the classifier. Time domain features were shown to be less robust than frequency domain features when interefence signals were introduced. In the presence of Bluetooth or Wi-Fi signals, 2 class UAV detection produced 100% accuracy, 4 class UAV type classification produced 99.9% (+/- 0.1%) and 10 class UAV flight mode classification produced 96.4% (+/- 0.5%) accuracy. Overall we have shown frequency domain features extracted from a CNN to be more robust than time domain features in the presence of interference and that high accuracy can be maintained using LR as a classifier with CNN derived features.",autonomous vehicle
10.1109/ICCVW.2017.246,filtered,2017 IEEE International Conference on Computer Vision Workshops (ICCVW),IEEE,2017-10-29 00:00:00,ieeexplore,Creating Roadmaps in Aerial Images with Generative Adversarial Networks and Smoothing-Based Optimization,https://ieeexplore.ieee.org/document/8265456/,"Recognizing roads and intersections in aerial images is a challenging problem in computer vision with many real world applications, such as localization and navigation for unmanned aerial vehicles (UAVs). The problem is currently gaining momentum in computer vision and is still far from being solved. While recent approaches have greatly improved due to the advances in deep learning, they provide only pixel-level semantic segmentations. In this paper, we argue that roads and intersections should be recognized at the higher semantic level of road graphs - with roads being edges that connect nodes. Towards this goal we present a method consisting of two stages. During the first stage, we detect roads and intersections with a novel, dual-hop generative adversarial network (DH-GAN) that segments images at the level of pixels. At the second stage, given the pixelwise road segmentation, we find its best covering road graph by applying a smoothing-based graph optimization procedure. Our approach is able to outperform recent published methods and baselines on a large dataset with European roads.",autonomous vehicle
10.1109/DASC.2017.8102146,filtered,2017 IEEE/AIAA 36th Digital Avionics Systems Conference (DASC),IEEE,2017-09-21 00:00:00,ieeexplore,Development and testing of an intrusion detection system for unmanned aerial systems,https://ieeexplore.ieee.org/document/8102146/,"This paper discusses the development, testing and prospective use of an intrusion detection system (IDS) for unmanned aerial vehicles (UAVs) and systems (UASs). Intrusion detection systems are typically used in computer networking and other applications to detect and respond to attempts to compromise computers, servers, firewalls and other network resources. In the context of the development of an IDS for UAV/UAS applications, several topics are considered. These include what an IDS is and how it is used, why do UAVs/UASs need an IDS and attack detection expectations for IDSs used in UAV/UAS applications. Because UAVs and UASs operate in the real world, with numerous and varied sensory inputs, testing and validation of these systems is particularly problematic. IDS Training challenges and the use of automated training to validate UAV/UAS IDS systems is, thus, a major consideration and also covered. The use of adaptive testing, in particular, is discussed.",autonomous vehicle
10.1109/ICTAI.2017.00144,filtered,2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI),IEEE,2017-11-08 00:00:00,ieeexplore,Evaluating Hardware Platforms and Path Re-planning Strategies for the UAV Emergency Landing Problem,https://ieeexplore.ieee.org/document/8372047/,"The present paper evaluates some strategies to apply path re-planning algorithms for emergency landing of Unmanned Aerial Vehicles (UAVs). The strategies proposed are based on executing only one path re-planning algorithm or a combination of them using an ensemble approach. The proposed methods are integrated to the security supervision system of the UAV, namely In-Fly Awareness (IFA), where decision-making algorithms are applying after a critical situation happens. The critical situations considered are battery overheating and engine failure. The performance of the proposed strategies for emergency landing is evaluated in a real world scenario using the Software-In-The-Loop (SITL) technique. Computational results reported show that these strategies are promising based on the success rate to land the UAV safely.",autonomous vehicle
10.1109/ICARCV.2006.345471,filtered,"2006 9th International Conference on Control, Automation, Robotics and Vision",IEEE,2006-12-08 00:00:00,ieeexplore,Terrain Modeling Using Machine Learning Methods,https://ieeexplore.ieee.org/document/4150400/,"The problem of terrain modeling is basically a type of function approximation problem. This type of problem has been widely studied in the soft computing community. In recent years, neural networks have been successfully applied to surface reconstruction and classification problems involving scattered data. However, due to the iterative nature of training a neural network, the resulting high cost in computational time limits the implementation of machine learning based methods in many real world applications (for example, navigation applications in unmanned aerial vehicles) that require fast generation of terrain models. A recently proposed machine learning method, the extreme learning machine (ELM), is able to train single-layer feed forward neural networks with excellent speed and good generalization. In this paper, we present terrain modeling using various machine learning methods, and we compare the performances of these methods with ELM. We also present a comparison of terrain modeling performances between ELM and the popular choice of terrain and surface modeling technique, the Delaunay triangulation with linear interpolation. Our results show that machine learning using ELM offers a potential solution to terrain modeling problems with good performances",autonomous vehicle
10.1007/s10846-021-01489-w,filtered,Journal of Intelligent & Robotic Systems,Springer,2021-09-17 00:00:00,springer,End-to-End Probabilistic Depth Perception and 3D Obstacle Avoidance using POMDP,http://link.springer.com/openurl/pdf?id=doi:10.1007/s10846-021-01489-w,"In most real world applications, noisy and incomplete information about the robot proximity is inevitable due to imperfections coupled with the onboard sensors. The perception and control problems go hand in hand in order to efficiently plan safe robot maneuvers. This paper proposes a method to generate robot actions directly from a sequence of depth images. The notion of Artificial Potential Field (APF) approach is used where a robot action is obtained by combining the attractive and repulsive actions generated by the goal and the obstacles respectively. This article assumes environment perception uncertainty that relates to the estimation of an obstacle’s location relative to the robot. The repulsive action generation is formulated as a Partially Observable Markov Decision Process (POMDP). A Particle Filter (PF) approach is used to estimate and track valid scene points in the robot sensing horizon from an imperfect depth image stream. The most probable candidates for an occupied region are used to generate a velocity action that minimizes the repulsive potential at each time instant. Approximately optimal solutions to the POMDP are obtained using the QMDP technique which enables us to perform computationally expensive operations prior to a robot run. Consequently, suitable repulsive actions are generated onboard the robot, each time an image is received, in a computationally feasible way. An attractive action, obtained by solving for the negative gradient of the attractive potential is finally added to the repulsive action to generate a final robot action at every time step. Lastly, the robustness and reliability of this approach is demonstrated close-loop on a quadrotor UAV equipped with a depth camera. The experiments also demonstrate that the method is very computationally efficient and can be run on a variety of platforms that have limited resources on-board.",autonomous vehicle
10.1007/978-3-030-65661-4_11,filtered,Deep Learning and Big Data for Intelligent Transportation,Springer,2021-01-01 00:00:00,springer,"Synergy of Internet of Things with Cloud, Artificial Intelligence and Blockchain for Empowering Autonomous Vehicles",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-65661-4_11,"Out of the advancements in Information Technology, the Internet of Things (IoT) plays an important and major role as it metamorphose the object from real world Scenario to intelligent virtual form. The term Internet of Things is coined from two phrases such as Internet and Thing which states that the physical objects such as computing devices acts through the network of connection. This technological ecosystem allows the object or thing to collect and transfer the data through the internet, without any physical assistance. It includes four major processes such as collect, communicate, analyse and act. The main purpose of IoT is making the human life smart thereby reducing the human effort. The cloud is an environment that seems to be a reinforcement of booming technology. It provides everything as service, right from storage to computing power through internet. It seems to be a flexible computing model that has intensified the growth of information technology. It enchanted the sprout of IoT as it needs more storage for the data that are acquired from the objects. Another booming technology is artificial intelligence where the intelligence of machine is used for enabling smart tasks than using the human intelligence. It is in existence since 1950 s but the resurgence of it happens during twenty-first century with the advances in computing power and storage of voluminous data. The main purpose of AI is to achieve accurate interpretation of voluminous data and extract valuable learning from the data thereby achieving the appropriate goals in a flexible manner. The IoT with this gleaming AI allows the physical objects to collect the valuable data through continuous streaming and allows it to perceive its tasks and domains for greatest chance of prosperous goal achievement. Blockchain is another revolution of the information technology. The blockchain or Distributed Ledger Technology is a promising technology where the digital assets of myriad users are managed by maintaining the transparency and evading the undesirable alterations. It stores and manages the data in the form of multiple blocks with respective cryptographic hashing. It is a distributed and decentralized model where the digital form of transactions are recorded in multiple devices, this allows the system to do any alterations or changes in each and every blocks so as to make changes in the record. This model avoids the precarious changes that may occur in the digital world. The IoT with this blockchain technology or the blockchain of thing may allow the digital environment to create a permanent, verifiable and secure method of managing the valuable data through intelligent machines. It will enable humanless interventions for decision making through proper environment interactions. This chapter elaborates all the four technologies such as IoT, AI, Cloud and Blockchain with regard to the autonomous vehicles. The need for these flickering technologies are explored and exposed so as to understand these technologies. The synergies of IoT with other three technologies are discussed for better understanding and upgradation of the technology. It also scrutinizes the recent developments with all these technological synergies.",autonomous vehicle
10.1007/978-3-030-65299-9_4,filtered,Information Security Applications,Springer,2020-01-01 00:00:00,springer,Unsupervised Intrusion Detection System for Unmanned Aerial Vehicle with Less Labeling Effort,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-65299-9_4,"Along with the importance of safety, an IDS has become a significant task in the real world. Prior studies proposed various intrusion detection models for the UAV. Past rule-based approaches provided a concrete baseline IDS model, and the machine learning-based method achieved a precise intrusion detection performance on the UAV with supervised learning models. However, previous methods have room for improvement to be implemented in the real world. Prior methods required a large labeling effort on the dataset, and the model could not identify attacks that were not trained before. To jump over these hurdles, we propose an IDS with unsupervised learning. As unsupervised learning does not require labeling, our model let the practitioner not to label every type of attack from the flight data. Moreover, the model can identify an abnormal status of the UAV regardless of the type of attack. We trained an autoencoder with the benign flight data only and checked the model provides a different reconstruction loss at the benign flight and the flight under attack. We discovered that the model produces much higher reconstruction loss with the flight under attack than the benign flight; thus, this reconstruction loss can be utilized to recognize an intrusion to the UAV. With consideration of the computation overhead and the detection performance in the wild, we expect our model can be a concrete and practical baseline IDS on the UAV.",autonomous vehicle
10.1007/978-3-030-37629-1_60,filtered,Innovations in Smart Cities Applications Edition 3,Springer,2020-01-01 00:00:00,springer,Applying External Guidance Commands to Deep Reinforcement Learning for Autonomous Driving,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-37629-1_60,"End-to-end deep reinforcement learning [ 1 ] algorithms used in autonomous car field and trained on lane-keeping task achieve good results in roads that don’t require decision making but cannot deal with situations where getting driving direction is mandatory like choosing to turn left or right in an upcoming crossroads, deciding when to leave a traffic circle or toward which path/destination to go. In this paper we introduce a new Deep Reinforcement Learning model that enable to integrate guidance commands at test time as a complementary input that indicate the right direction, that we call Deep Reinforcement Learning with guidance (DRLG), we apply the DRLG architecture on two algorithms, the asynchronous advantage actor-critic A3C and the Deep Deterministic Policy Gradient algorithm DDPG. For the training and experimentations of the new model, we adopt the CARLA virtual environment, a High-fidelity realistic driving simulator as a testbed since leading driving tests in the real world turns out to be neither safe nor affordable in term of materials and requirements. The results of testing show that DDPG and A3C with Guidance (DDPGG and A3CG) models succeed on their driving task through roads/roundabouts, by being appropriately responsive to the external commands, which allow to the autonomous car to follow the indicated route and take the right turns.",autonomous vehicle
10.1007/978-3-030-18963-1_2,filtered,Nonlinear Approaches in Engineering Applications,Springer,2020-01-01 00:00:00,springer,Artificial Intelligence and Internet of Things for Autonomous Vehicles,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-18963-1_2,"Artificial Intelligence (AI) is a machine intelligence tool providing enormous possibilities for smart industrial revolution. Internet of Things (IoT) is the axiom of industry 4.0 revolution, including a worldwide infrastructure for collecting and processing of the data/information from storage, actuation, sensing, advanced services and communication technologies. The combination of high-speed, resilient, low-latency connectivity, and technologies of AI and IoT will enable the transformation towards fully smart Autonomous Vehicle (AV) that illustrate the complementary between real world and digital knowledge for industry 4.0. The purpose of this articla is to examine how the latest approaches in AI and IoT can assist in the search for the Autonomous Vehicles. It has been shown that human errors are the source of 90% of automotive crashes, and the safest drivers drive ten times better than the average (Wu et al. Accident Analysis and Prevention, 117, 21–31, 2018). The automated vehicle safety is significant, and users are requiring 1000 times smaller acceptable risk level. Some of the incredible benefits of AVs are: (1) increasing vehicle safety, (2) reduction of accidents, (3) reduction of fuel consumption, (4) releasing of driver time and business opportunities, (5) new potential market opportunities, and (6) reduced emissions and dust particles. However, AVs must use large-scale data/information from their sensors and devices.",autonomous vehicle
http://arxiv.org/abs/1910.00399v1,filtered,arxiv,arxiv,2019-09-27 20:36:28+00:00,arxiv,Safe Reinforcement Learning on Autonomous Vehicles,http://arxiv.org/abs/1910.00399v1,"There have been numerous advances in reinforcement learning, but the
typically unconstrained exploration of the learning process prevents the
adoption of these methods in many safety critical applications. Recent work in
safe reinforcement learning uses idealized models to achieve their guarantees,
but these models do not easily accommodate the stochasticity or
high-dimensionality of real world systems. We investigate how prediction
provides a general and intuitive framework to constraint exploration, and show
how it can be used to safely learn intersection handling behaviors on an
autonomous vehicle.",autonomous vehicle
http://arxiv.org/abs/2107.03600v1,filtered,arxiv,arxiv,2021-07-08 04:39:35+00:00,arxiv,"Reinforcement Learning based Negotiation-aware Motion Planning of
  Autonomous Vehicles",http://arxiv.org/abs/2107.03600v1,"For autonomous vehicles integrating onto roadways with human traffic
participants, it requires understanding and adapting to the participants'
intention and driving styles by responding in predictable ways without explicit
communication. This paper proposes a reinforcement learning based
negotiation-aware motion planning framework, which adopts RL to adjust the
driving style of the planner by dynamically modifying the prediction horizon
length of the motion planner in real time adaptively w.r.t the event of a
change in environment, typically triggered by traffic participants' switch of
intents with different driving styles. The framework models the interaction
between the autonomous vehicle and other traffic participants as a Markov
Decision Process. A temporal sequence of occupancy grid maps are taken as
inputs for RL module to embed an implicit intention reasoning. Curriculum
learning is employed to enhance the training efficiency and the robustness of
the algorithm. We applied our method to narrow lane navigation in both
simulation and real world to demonstrate that the proposed method outperforms
the common alternative due to its advantage in alleviating the social dilemma
problem with proper negotiation skills.",autonomous vehicle
http://arxiv.org/abs/2005.13976v1,filtered,arxiv,arxiv,2020-05-22 19:00:38+00:00,arxiv,"Towards Automated Safety Coverage and Testing for Autonomous Vehicles
  with Reinforcement Learning",http://arxiv.org/abs/2005.13976v1,"The kind of closed-loop verification likely to be required for autonomous
vehicle (AV) safety testing is beyond the reach of traditional test
methodologies and discrete verification. Validation puts the autonomous vehicle
system to the test in scenarios or situations that the system would likely
encounter in everyday driving after its release. These scenarios can either be
controlled directly in a physical (closed-course proving ground) or virtual
(simulation of predefined scenarios) environment, or they can arise
spontaneously during operation in the real world (open-road testing or
simulation of randomly generated scenarios).
  In AV testing, simulation serves primarily two purposes: to assist the
development of a robust autonomous vehicle and to test and validate the AV
before release. A challenge arises from the sheer number of scenario variations
that can be constructed from each of the above sources due to the high number
of variables involved (most of which are continuous). Even with continuous
variables discretized, the possible number of combinations becomes practically
infeasible to test. To overcome this challenge we propose using reinforcement
learning (RL) to generate failure examples and unexpected traffic situations
for the AV software implementation. Although reinforcement learning algorithms
have achieved notable results in games and some robotic manipulations, this
technique has not been widely scaled up to the more challenging real world
applications like autonomous driving.",autonomous vehicle
http://arxiv.org/abs/2010.05436v1,filtered,arxiv,arxiv,2020-10-12 03:52:10+00:00,arxiv,"Leveraging the Capabilities of Connected and Autonomous Vehicles and
  Multi-Agent Reinforcement Learning to Mitigate Highway Bottleneck Congestion",http://arxiv.org/abs/2010.05436v1,"Active Traffic Management strategies are often adopted in real-time to
address such sudden flow breakdowns. When queuing is imminent, Speed
Harmonization (SH), which adjusts speeds in upstream traffic to mitigate
traffic showckwaves downstream, can be applied. However, because SH depends on
driver awareness and compliance, it may not always be effective in mitigating
congestion. The use of multiagent reinforcement learning for collaborative
learning, is a promising solution to this challenge. By incorporating this
technique in the control algorithms of connected and autonomous vehicle (CAV),
it may be possible to train the CAVs to make joint decisions that can mitigate
highway bottleneck congestion without human driver compliance to altered speed
limits. In this regard, we present an RL-based multi-agent CAV control model to
operate in mixed traffic (both CAVs and human-driven vehicles (HDVs)). The
results suggest that even at CAV percent share of corridor traffic as low as
10%, CAVs can significantly mitigate bottlenecks in highway traffic. Another
objective was to assess the efficacy of the RL-based controller vis-\`a-vis
that of the rule-based controller. In addressing this objective, we duly
recognize that one of the main challenges of RL-based CAV controllers is the
variety and complexity of inputs that exist in the real world, such as the
information provided to the CAV by other connected entities and sensed
information. These translate as dynamic length inputs which are difficult to
process and learn from. For this reason, we propose the use of Graphical
Convolution Networks (GCN), a specific RL technique, to preserve information
network topology and corresponding dynamic length inputs. We then use this,
combined with Deep Deterministic Policy Gradient (DDPG), to carry out
multi-agent training for congestion mitigation using the CAV controllers.",autonomous vehicle
http://arxiv.org/abs/1908.11157v2,filtered,arxiv,arxiv,2019-08-29 11:31:10+00:00,arxiv,Active Learning for UAV-based Semantic Mapping,http://arxiv.org/abs/1908.11157v2,"Unmanned aerial vehicles combined with computer vision systems, such as
convolutional neural networks, offer a flexible and affordable solution for
terrain monitoring, mapping, and detection tasks. However, a key challenge
remains the collection and annotation of training data for the given sensors,
application, and mission. We introduce an informative path planning system that
incorporates novelty estimation into its objective function, based on research
for uncertainty estimation in deep learning. The system is designed for data
collection to reduce both the number of flights and of annotated images. We
evaluate the approach on real world terrain mapping data and show significantly
smaller collected training dataset compared to standard lawnmower data
collection techniques.",autonomous vehicle
http://arxiv.org/abs/2009.14551v2,filtered,arxiv,arxiv,2020-09-30 10:40:44+00:00,arxiv,Explainable Deep Reinforcement Learning for UAV Autonomous Navigation,http://arxiv.org/abs/2009.14551v2,"Autonomous navigation in unknown complex environment is still a hard problem,
especially for small Unmanned Aerial Vehicles (UAVs) with limited computation
resources. In this paper, a neural network-based reactive controller is
proposed for a quadrotor to fly autonomously in unknown outdoor environment.
The navigation controller makes use of only current sensor data to generate the
control signal without any optimization or configuration space searching, which
reduces both memory and computation requirement. The navigation problem is
modelled as a Markov Decision Process (MDP) and solved using deep reinforcement
learning (DRL) method. Specifically, to get better understanding of the trained
network, some model explanation methods are proposed. Based on the feature
attribution, each decision making result during flight is explained using both
visual and texture explanation. Moreover, some global analysis are also
provided for experts to evaluate and improve the trained neural network. The
simulation results illustrated the proposed method can make useful and
reasonable explanation for the trained model, which is beneficial for both
non-expert users and controller designer. Finally, the real world tests shown
the proposed controller can navigate the quadrotor to goal position
successfully and the reactive controller performs much faster than some
conventional approach under the same computation resource.",autonomous vehicle
http://arxiv.org/abs/1411.6326v1,filtered,arxiv,arxiv,2014-11-24 02:09:59+00:00,arxiv,Vision and Learning for Deliberative Monocular Cluttered Flight,http://arxiv.org/abs/1411.6326v1,"Cameras provide a rich source of information while being passive, cheap and
lightweight for small and medium Unmanned Aerial Vehicles (UAVs). In this work
we present the first implementation of receding horizon control, which is
widely used in ground vehicles, with monocular vision as the only sensing mode
for autonomous UAV flight in dense clutter. We make it feasible on UAVs via a
number of contributions: novel coupling of perception and control via relevant
and diverse, multiple interpretations of the scene around the robot, leveraging
recent advances in machine learning to showcase anytime budgeted cost-sensitive
feature selection, and fast non-linear regression for monocular depth
prediction. We empirically demonstrate the efficacy of our novel pipeline via
real world experiments of more than 2 kms through dense trees with a quadrotor
built from off-the-shelf parts. Moreover our pipeline is designed to combine
information from other modalities like stereo and lidar as well if available.",autonomous vehicle
http://arxiv.org/abs/2010.08546v1,filtered,arxiv,arxiv,2020-10-17 17:18:17+00:00,arxiv,"A Generative Model based Adversarial Security of Deep Learning and
  Linear Classifier Models",http://arxiv.org/abs/2010.08546v1,"In recent years, machine learning algorithms have been applied widely in
various fields such as health, transportation, and the autonomous car. With the
rapid developments of deep learning techniques, it is critical to take the
security concern into account for the application of the algorithms. While
machine learning offers significant advantages in terms of the application of
algorithms, the issue of security is ignored. Since it has many applications in
the real world, security is a vital part of the algorithms. In this paper, we
have proposed a mitigation method for adversarial attacks against machine
learning models with an autoencoder model that is one of the generative ones.
The main idea behind adversarial attacks against machine learning models is to
produce erroneous results by manipulating trained models. We have also
presented the performance of autoencoder models to various attack methods from
deep neural networks to traditional algorithms by using different methods such
as non-targeted and targeted attacks to multi-class logistic regression, a fast
gradient sign method, a targeted fast gradient sign method and a basic
iterative method attack to neural networks for the MNIST dataset.",autonomous vehicle
http://arxiv.org/abs/2106.15045v1,filtered,arxiv,arxiv,2021-06-29 01:16:01+00:00,arxiv,"EVPropNet: Detecting Drones By Finding Propellers For Mid-Air Landing
  And Following",http://arxiv.org/abs/2106.15045v1,"The rapid rise of accessibility of unmanned aerial vehicles or drones pose a
threat to general security and confidentiality. Most of the commercially
available or custom-built drones are multi-rotors and are comprised of multiple
propellers. Since these propellers rotate at a high-speed, they are generally
the fastest moving parts of an image and cannot be directly ""seen"" by a
classical camera without severe motion blur. We utilize a class of sensors that
are particularly suitable for such scenarios called event cameras, which have a
high temporal resolution, low-latency, and high dynamic range.
  In this paper, we model the geometry of a propeller and use it to generate
simulated events which are used to train a deep neural network called EVPropNet
to detect propellers from the data of an event camera. EVPropNet directly
transfers to the real world without any fine-tuning or retraining. We present
two applications of our network: (a) tracking and following an unmarked drone
and (b) landing on a near-hover drone. We successfully evaluate and demonstrate
the proposed approach in many real-world experiments with different propeller
shapes and sizes. Our network can detect propellers at a rate of 85.1% even
when 60% of the propeller is occluded and can run at upto 35Hz on a 2W power
budget. To our knowledge, this is the first deep learning-based solution for
detecting propellers (to detect drones). Finally, our applications also show an
impressive success rate of 92% and 90% for the tracking and landing tasks
respectively.",autonomous vehicle
http://arxiv.org/abs/2003.03576v1,filtered,arxiv,arxiv,2020-03-07 13:05:03+00:00,arxiv,"A machine learning environment for evaluating autonomous driving
  software",http://arxiv.org/abs/2003.03576v1,"Autonomous vehicles need safe development and testing environments. Many
traffic scenarios are such that they cannot be tested in the real world. We see
hybrid photorealistic simulation as a viable tool for developing AI (artificial
intelligence) software for autonomous driving. We present a machine learning
environment for detecting autonomous vehicle corner case behavior. Our
environment is based on connecting the CARLA simulation software to TensorFlow
machine learning framework and custom AI client software. The AI client
software receives data from a simulated world via virtual sensors and
transforms the data into information using machine learning models. The AI
clients control vehicles in the simulated world. Our environment monitors the
state assumed by the vehicle AIs to the ground truth state derived from the
simulation model. Our system can search for corner cases where the vehicle AI
is unable to correctly understand the situation. In our paper, we present the
overall hybrid simulator architecture and compare different configurations. We
present performance measurements from real setups, and outline the main
parameters affecting the hybrid simulator performance.",autonomous vehicle
http://arxiv.org/abs/2103.07268v1,filtered,arxiv,arxiv,2021-03-12 13:42:25+00:00,arxiv,"Adversarial Machine Learning Security Problems for 6G: mmWave Beam
  Prediction Use-Case",http://arxiv.org/abs/2103.07268v1,"6G is the next generation for the communication systems. In recent years,
machine learning algorithms have been applied widely in various fields such as
health, transportation, and the autonomous car. The predictive algorithms will
be used in 6G problems. With the rapid developments of deep learning
techniques, it is critical to take the security concern into account to apply
the algorithms. While machine learning offers significant advantages for 6G, AI
models' security is ignored. Since it has many applications in the real world,
security is a vital part of the algorithms. This paper has proposed a
mitigation method for adversarial attacks against proposed 6G machine learning
models for the millimeter-wave (mmWave) beam prediction with adversarial
learning. The main idea behind adversarial attacks against machine learning
models is to produce faulty results by manipulating trained deep learning
models for 6G applications for mmWave beam prediction use case. We have also
presented the adversarial learning mitigation method's performance for 6G
security in millimeter-wave beam prediction application with fast gradient sign
method attack. The mean square errors of the defended model and undefended
model are very close.",autonomous vehicle
http://arxiv.org/abs/2106.07299v1,filtered,arxiv,arxiv,2021-06-14 11:05:53+00:00,arxiv,"Dynamic Based Estimator for UAVs with Real-time Identification Using DNN
  and the Modified Relay Feedback Test",http://arxiv.org/abs/2106.07299v1,"Control performance of Unmanned Aerial Vehicles (UAVs) is directly affected
by their ability to estimate their states accurately. With the increasing
popularity of autonomous UAV solutions in real world applications, it is
imperative to develop robust adaptive estimators that can ameliorate sensor
noises in low-cost UAVs. Utilizing the knowledge of UAV dynamics in estimation
can provide significant advantages, but remains challenging due to the complex
and expensive pre-flight experiments required to obtain UAV dynamic parameters.
In this paper, we propose two decoupled dynamic model based Extended Kalman
Filters for UAVs, that provide high rate estimates for position, and velocity
of rotational and translational states, as well as filtered inertial
acceleration. The dynamic model parameters are estimated online using the Deep
Neural Network and Modified Relay Feedback Test (DNN-MRFT) framework, without
requiring any prior knowledge of the UAV physical parameters. The designed
filters with real-time identified process model parameters are tested
experimentally and showed two advantages. Firstly, smooth and lag-free
estimates of the UAV rotational speed and inertial acceleration are obtained,
and used to improve the closed loop system performance, reducing the controller
action by over 6 %. Secondly, the proposed approach enabled the UAV to track
aggressive trajectories with low rate position measurements, a task usually
infeasible under those conditions. The experimental data shows that we achieved
estimation performance matching other methods that requires full knowledge of
the UAV parameters.",autonomous vehicle
http://arxiv.org/abs/2002.05149v6,filtered,arxiv,arxiv,2020-02-12 18:50:11+00:00,arxiv,Self-explaining AI as an alternative to interpretable AI,http://arxiv.org/abs/2002.05149v6,"The ability to explain decisions made by AI systems is highly sought after,
especially in domains where human lives are at stake such as medicine or
autonomous vehicles. While it is often possible to approximate the input-output
relations of deep neural networks with a few human-understandable rules, the
discovery of the double descent phenomena suggests that such approximations do
not accurately capture the mechanism by which deep neural networks work. Double
descent indicates that deep neural networks typically operate by smoothly
interpolating between data points rather than by extracting a few high level
rules. As a result, neural networks trained on complex real world data are
inherently hard to interpret and prone to failure if asked to extrapolate. To
show how we might be able to trust AI despite these problems we introduce the
concept of self-explaining AI. Self-explaining AIs are capable of providing a
human-understandable explanation of each decision along with confidence levels
for both the decision and explanation. For this approach to work, it is
important that the explanation actually be related to the decision, ideally
capturing the mechanism used to arrive at the explanation. Finally, we argue it
is important that deep learning based systems include a ""warning light"" based
on techniques from applicability domain analysis to warn the user if a model is
asked to extrapolate outside its training distribution. For a video
presentation of this talk see https://www.youtube.com/watch?v=Py7PVdcu7WY& .",autonomous vehicle
http://arxiv.org/abs/2007.11102v1,filtered,arxiv,arxiv,2020-07-21 21:33:26+00:00,arxiv,"Fully Convolutional Neural Networks for Automotive Radar Interference
  Mitigation",http://arxiv.org/abs/2007.11102v1,"The interest of the automotive industry has progressively focused on subjects
related to driver assistance systems as well as autonomous cars. Cars combine a
variety of sensors to perceive their surroundings robustly. Among them, radar
sensors are indispensable because of their independence of lighting conditions
and the possibility to directly measure velocity. However, radar interference
is an issue that becomes prevalent with the increasing amount of radar systems
in automotive scenarios. In this paper, we address this issue for frequency
modulated continuous wave (FMCW) radars with fully convolutional neural
networks (FCNs), a state-of-the-art deep learning technique. We propose two
FCNs that take spectrograms of the beat signals as input, and provide the
corresponding clean range profiles as output. We propose two architectures for
interference mitigation which outperform the classical zeroing technique.
Moreover, considering the lack of databases for this task, we release as open
source a large scale data set that closely replicates real world automotive
scenarios for single-interference cases, allowing others to objectively compare
their future work in this domain. The data set is available for download at:
http://github.com/ristea/arim.",autonomous vehicle
http://arxiv.org/abs/1804.10662v1,filtered,arxiv,arxiv,2018-04-27 19:45:54+00:00,arxiv,Mapping Road Lanes Using Laser Remission and Deep Neural Networks,http://arxiv.org/abs/1804.10662v1,"We propose the use of deep neural networks (DNN) for solving the problem of
inferring the position and relevant properties of lanes of urban roads with
poor or absent horizontal signalization, in order to allow the operation of
autonomous cars in such situations. We take a segmentation approach to the
problem and use the Efficient Neural Network (ENet) DNN for segmenting LiDAR
remission grid maps into road maps. We represent road maps using what we called
road grid maps. Road grid maps are square matrixes and each element of these
matrixes represents a small square region of real-world space. The value of
each element is a code associated with the semantics of the road map. Our road
grid maps contain all information about the roads' lanes required for building
the Road Definition Data Files (RDDFs) that are necessary for the operation of
our autonomous car, IARA (Intelligent Autonomous Robotic Automobile). We have
built a dataset of tens of kilometers of manually marked road lanes and used
part of it to train ENet to segment road grid maps from remission grid maps.
After being trained, ENet achieved an average segmentation accuracy of 83.7%.
We have tested the use of inferred road grid maps in the real world using IARA
on a stretch of 3.7 km of urban roads and it has shown performance equivalent
to that of the previous IARA's subsystem that uses a manually generated RDDF.",autonomous vehicle
http://arxiv.org/abs/1706.05904v2,filtered,arxiv,arxiv,2017-06-19 12:40:30+00:00,arxiv,Pedestrian Prediction by Planning using Deep Neural Networks,http://arxiv.org/abs/1706.05904v2,"Accurate traffic participant prediction is the prerequisite for collision
avoidance of autonomous vehicles. In this work, we predict pedestrians by
emulating their own motion planning. From online observations, we infer a
mixture density function for possible destinations. We use this result as the
goal states of a planning stage that performs motion prediction based on common
behavior patterns. The entire system is modeled as one monolithic neural
network and trained via inverse reinforcement learning. Experimental validation
on real world data shows the system's ability to predict both, destinations and
trajectories accurately.",autonomous vehicle
http://arxiv.org/abs/1808.06940v1,filtered,arxiv,arxiv,2018-08-20 09:25:30+00:00,arxiv,End to End Vehicle Lateral Control Using a Single Fisheye Camera,http://arxiv.org/abs/1808.06940v1,"Convolutional neural networks are commonly used to control the steering angle
for autonomous cars. Most of the time, multiple long range cameras are used to
generate lateral failure cases. In this paper we present a novel model to
generate this data and label augmentation using only one short range fisheye
camera. We present our simulator and how it can be used as a consistent metric
for lateral end-to-end control evaluation. Experiments are conducted on a
custom dataset corresponding to more than 10000 km and 200 hours of open road
driving. Finally we evaluate this model on real world driving scenarios, open
road and a custom test track with challenging obstacle avoidance and sharp
turns. In our simulator based on real-world videos, the final model was capable
of more than 99% autonomy on urban road",autonomous vehicle
http://arxiv.org/abs/2001.07769v3,filtered,arxiv,arxiv,2020-01-21 20:41:27+00:00,arxiv,"Massif: Interactive Interpretation of Adversarial Attacks on Deep
  Learning",http://arxiv.org/abs/2001.07769v3,"Deep neural networks (DNNs) are increasingly powering high-stakes
applications such as autonomous cars and healthcare; however, DNNs are often
treated as ""black boxes"" in such applications. Recent research has also
revealed that DNNs are highly vulnerable to adversarial attacks, raising
serious concerns over deploying DNNs in the real world. To overcome these
deficiencies, we are developing Massif, an interactive tool for deciphering
adversarial attacks. Massif identifies and interactively visualizes neurons and
their connections inside a DNN that are strongly activated or suppressed by an
adversarial attack. Massif provides both a high-level, interpretable overview
of the effect of an attack on a DNN, and a low-level, detailed description of
the affected neurons. These tightly coupled views in Massif help people better
understand which input features are most vulnerable or important for correct
predictions.",autonomous vehicle
http://arxiv.org/abs/2010.09185v1,filtered,arxiv,arxiv,2020-10-19 03:18:35+00:00,arxiv,MaskNet: A Fully-Convolutional Network to Estimate Inlier Points,http://arxiv.org/abs/2010.09185v1,"Point clouds have grown in importance in the way computers perceive the
world. From LIDAR sensors in autonomous cars and drones to the time of flight
and stereo vision systems in our phones, point clouds are everywhere. Despite
their ubiquity, point clouds in the real world are often missing points because
of sensor limitations or occlusions, or contain extraneous points from sensor
noise or artifacts. These problems challenge algorithms that require computing
correspondences between a pair of point clouds. Therefore, this paper presents
a fully-convolutional neural network that identifies which points in one point
cloud are most similar (inliers) to the points in another. We show improvements
in learning-based and classical point cloud registration approaches when
retrofitted with our network. We demonstrate these improvements on synthetic
and real-world datasets. Finally, our network produces impressive results on
test datasets that were unseen during training, thus exhibiting
generalizability. Code and videos are available at
https://github.com/vinits5/masknet",autonomous vehicle
http://arxiv.org/abs/2001.09684v2,filtered,arxiv,arxiv,2020-01-27 10:53:11+00:00,arxiv,"Challenges and Countermeasures for Adversarial Attacks on Deep
  Reinforcement Learning",http://arxiv.org/abs/2001.09684v2,"Deep Reinforcement Learning (DRL) has numerous applications in the real world
thanks to its outstanding ability in quickly adapting to the surrounding
environments. Despite its great advantages, DRL is susceptible to adversarial
attacks, which precludes its use in real-life critical systems and applications
(e.g., smart grids, traffic controls, and autonomous vehicles) unless its
vulnerabilities are addressed and mitigated. Thus, this paper provides a
comprehensive survey that discusses emerging attacks in DRL-based systems and
the potential countermeasures to defend against these attacks. We first cover
some fundamental backgrounds about DRL and present emerging adversarial attacks
on machine learning techniques. We then investigate more details of the
vulnerabilities that the adversary can exploit to attack DRL along with the
state-of-the-art countermeasures to prevent such attacks. Finally, we highlight
open issues and research challenges for developing solutions to deal with
attacks for DRL-based intelligent systems.",autonomous vehicle
http://arxiv.org/abs/1610.04256v1,filtered,arxiv,arxiv,2016-10-13 20:34:48+00:00,arxiv,Assessing Threat of Adversarial Examples on Deep Neural Networks,http://arxiv.org/abs/1610.04256v1,"Deep neural networks are facing a potential security threat from adversarial
examples, inputs that look normal but cause an incorrect classification by the
deep neural network. For example, the proposed threat could result in
hand-written digits on a scanned check being incorrectly classified but looking
normal when humans see them. This research assesses the extent to which
adversarial examples pose a security threat, when one considers the normal
image acquisition process. This process is mimicked by simulating the
transformations that normally occur in acquiring the image in a real world
application, such as using a scanner to acquire digits for a check amount or
using a camera in an autonomous car. These small transformations negate the
effect of the carefully crafted perturbations of adversarial examples,
resulting in a correct classification by the deep neural network. Thus just
acquiring the image decreases the potential impact of the proposed security
threat. We also show that the already widely used process of averaging over
multiple crops neutralizes most adversarial examples. Normal preprocessing,
such as text binarization, almost completely neutralizes adversarial examples.
This is the first paper to show that for text driven classification,
adversarial examples are an academic curiosity, not a security threat.",autonomous vehicle
http://arxiv.org/abs/2010.01931v1,filtered,arxiv,arxiv,2020-10-05 11:41:11+00:00,arxiv,Offline Learning for Planning: A Summary,http://arxiv.org/abs/2010.01931v1,"The training of autonomous agents often requires expensive and unsafe
trial-and-error interactions with the environment. Nowadays several data sets
containing recorded experiences of intelligent agents performing various tasks,
spanning from the control of unmanned vehicles to human-robot interaction and
medical applications are accessible on the internet. With the intention of
limiting the costs of the learning procedure it is convenient to exploit the
information that is already available rather than collecting new data.
Nevertheless, the incapability to augment the batch can lead the autonomous
agents to develop far from optimal behaviours when the sampled experiences do
not allow for a good estimate of the true distribution of the environment.
Offline learning is the area of machine learning concerned with efficiently
obtaining an optimal policy with a batch of previously collected experiences
without further interaction with the environment. In this paper we adumbrate
the ideas motivating the development of the state-of-the-art offline learning
baselines. The listed methods consist in the introduction of epistemic
uncertainty dependent constraints during the classical resolution of a Markov
Decision Process, with and without function approximators, that aims to
alleviate the bad effects of the distributional mismatch between the available
samples and real world. We provide comments on the practical utility of the
theoretical bounds that justify the application of these algorithms and suggest
the utilization of Generative Adversarial Networks to estimate the
distributional shift that affects all of the proposed model-free and
model-based approaches.",autonomous vehicle
http://arxiv.org/abs/2110.00808v1,filtered,arxiv,arxiv,2021-10-02 13:55:50+00:00,arxiv,Cycle-Consistent World Models for Domain Independent Latent Imagination,http://arxiv.org/abs/2110.00808v1,"End-to-end autonomous driving seeks to solve the perception, decision, and
control problems in an integrated way, which can be easier to generalize at
scale and be more adapting to new scenarios. However, high costs and risks make
it very hard to train autonomous cars in the real world. Simulations can
therefore be a powerful tool to enable training. Due to slightly different
observations, agents trained and evaluated solely in simulation often perform
well there but have difficulties in real-world environments. To tackle this
problem, we propose a novel model-based reinforcement learning approach called
Cycleconsistent World Models. Contrary to related approaches, our model can
embed two modalities in a shared latent space and thereby learn from samples in
one modality (e.g., simulated data) and be used for inference in different
domain (e.g., real-world data). Our experiments using different modalities in
the CARLA simulator showed that this enables CCWM to outperform
state-of-the-art domain adaptation approaches. Furthermore, we show that CCWM
can decode a given latent representation into semantically coherent
observations in both modalities.",autonomous vehicle
http://arxiv.org/abs/1812.00733v2,filtered,arxiv,arxiv,2018-12-03 13:50:40+00:00,arxiv,"Attention-based Adaptive Selection of Operations for Image Restoration
  in the Presence of Unknown Combined Distortions",http://arxiv.org/abs/1812.00733v2,"Many studies have been conducted so far on image restoration, the problem of
restoring a clean image from its distorted version. There are many different
types of distortion which affect image quality. Previous studies have focused
on single types of distortion, proposing methods for removing them. However,
image quality degrades due to multiple factors in the real world. Thus,
depending on applications, e.g., vision for autonomous cars or surveillance
cameras, we need to be able to deal with multiple combined distortions with
unknown mixture ratios. For this purpose, we propose a simple yet effective
layer architecture of neural networks. It performs multiple operations in
parallel, which are weighted by an attention mechanism to enable selection of
proper operations depending on the input. The layer can be stacked to form a
deep network, which is differentiable and thus can be trained in an end-to-end
fashion by gradient descent. The experimental results show that the proposed
method works better than previous methods by a good margin on tasks of
restoring images with multiple combined distortions.",autonomous vehicle
http://arxiv.org/abs/2104.13617v2,filtered,arxiv,arxiv,2021-04-28 07:54:40+00:00,arxiv,"End-to-End Intersection Handling using Multi-Agent Deep Reinforcement
  Learning",http://arxiv.org/abs/2104.13617v2,"Navigating through intersections is one of the main challenging tasks for an
autonomous vehicle. However, for the majority of intersections regulated by
traffic lights, the problem could be solved by a simple rule-based method in
which the autonomous vehicle behavior is closely related to the traffic light
states. In this work, we focus on the implementation of a system able to
navigate through intersections where only traffic signs are provided. We
propose a multi-agent system using a continuous, model-free Deep Reinforcement
Learning algorithm used to train a neural network for predicting both the
acceleration and the steering angle at each time step. We demonstrate that
agents learn both the basic rules needed to handle intersections by
understanding the priorities of other learners inside the environment, and to
drive safely along their paths. Moreover, a comparison between our system and a
rule-based method proves that our model achieves better results especially with
dense traffic conditions. Finally, we test our system on real world scenarios
using real recorded traffic data, proving that our module is able to generalize
both to unseen environments and to different traffic conditions.",autonomous vehicle
http://arxiv.org/abs/2011.05617v1,filtered,arxiv,arxiv,2020-11-11 08:17:08+00:00,arxiv,Sim-To-Real Transfer for Miniature Autonomous Car Racing,http://arxiv.org/abs/2011.05617v1,"Sim-to-real, a term that describes where a model is trained in a simulator
then transferred to the real world, is a technique that enables faster deep
reinforcement learning (DRL) training. However, differences between the
simulator and the real world often cause the model to perform poorly in the
real world. Domain randomization is a way to bridge the sim-to-real gap by
exposing the model to a wide range of scenarios so that it can generalize to
real-world situations. However, following domain randomization to train an
autonomous car racing model with DRL can lead to undesirable outcomes. Namely,
a model trained with randomization tends to run slower; a higher completion
rate on the testing track comes at the expense of longer lap times. This paper
aims to boost the robustness of a trained race car model without compromising
racing lap times. For a training track and a testing track having the same
shape (and same optimal paths), but with different lighting, background, etc.,
we first train a model (teacher model) that overfits the training track, moving
along a near optimal path. We then use this model to teach a student model the
correct actions along with randomization. With our method, a model with 18.4\%
completion rate on the testing track is able to help teach a student model with
52\% completion. Moreover, over an average of 50 trials, the student is able to
finish a lap 0.23 seconds faster than the teacher. This 0.23 second gap is
significant in tight races, with lap times of about 10 to 12 seconds.",autonomous vehicle
http://arxiv.org/abs/2005.07424v1,filtered,arxiv,arxiv,2020-05-15 09:05:17+00:00,arxiv,"Exploring the Capabilities and Limits of 3D Monocular Object Detection
  -- A Study on Simulation and Real World Data",http://arxiv.org/abs/2005.07424v1,"3D object detection based on monocular camera data is a key enabler for
autonomous driving. The task however, is ill-posed due to lack of depth
information in 2D images. Recent deep learning methods show promising results
to recover depth information from single images by learning priors about the
environment. Several competing strategies tackle this problem. In addition to
the network design, the major difference of these competing approaches lies in
using a supervised or self-supervised optimization loss function, which require
different data and ground truth information. In this paper, we evaluate the
performance of a 3D object detection pipeline which is parameterizable with
different depth estimation configurations. We implement a simple distance
calculation approach based on camera intrinsics and 2D bounding box size, a
self-supervised, and a supervised learning approach for depth estimation.
  Ground truth depth information cannot be recorded reliable in real world
scenarios. This shifts our training focus to simulation data. In simulation,
labeling and ground truth generation can be automatized. We evaluate the
detection pipeline on simulator data and a real world sequence from an
autonomous vehicle on a race track. The benefit of simulation training to real
world application is investigated. Advantages and drawbacks of the different
depth estimation strategies are discussed.",autonomous vehicle
http://arxiv.org/abs/1907.05274v1,filtered,arxiv,arxiv,2019-07-06 04:53:49+00:00,arxiv,Affine Disentangled GAN for Interpretable and Robust AV Perception,http://arxiv.org/abs/1907.05274v1,"Autonomous vehicles (AV) have progressed rapidly with the advancements in
computer vision algorithms. The deep convolutional neural network as the main
contributor to this advancement has boosted the classification accuracy
dramatically. However, the discovery of adversarial examples reveals the
generalization gap between dataset and the real world. Furthermore, affine
transformations may also confuse computer vision based object detectors. The
degradation of the perception system is undesirable for safety critical systems
such as autonomous vehicles. In this paper, a deep learning system is proposed:
Affine Disentangled GAN (ADIS-GAN), which is robust against affine
transformations and adversarial attacks. It is demonstrated that conventional
data augmentation for affine transformation and adversarial attacks are
orthogonal, while ADIS-GAN can handle both attacks at the same time. Useful
information such as image rotation angle and scaling factor are also generated
in ADIS-GAN. On MNIST dataset, ADIS-GAN can achieve over 98 percent
classification accuracy within 30 degrees rotation, and over 90 percent
classification accuracy against FGSM and PGD adversarial attack.",autonomous vehicle
http://arxiv.org/abs/2105.09932v1,filtered,arxiv,arxiv,2021-05-20 17:52:37+00:00,arxiv,Efficient and Robust LiDAR-Based End-to-End Navigation,http://arxiv.org/abs/2105.09932v1,"Deep learning has been used to demonstrate end-to-end neural network learning
for autonomous vehicle control from raw sensory input. While LiDAR sensors
provide reliably accurate information, existing end-to-end driving solutions
are mainly based on cameras since processing 3D data requires a large memory
footprint and computation cost. On the other hand, increasing the robustness of
these systems is also critical; however, even estimating the model's
uncertainty is very challenging due to the cost of sampling-based methods. In
this paper, we present an efficient and robust LiDAR-based end-to-end
navigation framework. We first introduce Fast-LiDARNet that is based on sparse
convolution kernel optimization and hardware-aware model design. We then
propose Hybrid Evidential Fusion that directly estimates the uncertainty of the
prediction from only a single forward pass and then fuses the control
predictions intelligently. We evaluate our system on a full-scale vehicle and
demonstrate lane-stable as well as navigation capabilities. In the presence of
out-of-distribution events (e.g., sensor failures), our system significantly
improves robustness and reduces the number of takeovers in the real world.",autonomous vehicle
http://arxiv.org/abs/2004.00801v1,filtered,arxiv,arxiv,2020-04-02 03:52:03+00:00,arxiv,"Exploration of Reinforcement Learning for Event Camera using Car-like
  Robots",http://arxiv.org/abs/2004.00801v1,"We demonstrate the first reinforcement-learning application for robots
equipped with an event camera. Because of the considerably lower latency of the
event camera, it is possible to achieve much faster control of robots compared
with the existing vision-based reinforcement-learning applications using
standard cameras. To handle a stream of events for reinforcement learning, we
introduced an image-like feature and demonstrated the feasibility of training
an agent in a simulator for two tasks: fast collision avoidance and obstacle
tracking. Finally, we set up a robot with an event camera in the real world and
then transferred the agent trained in the simulator, resulting in successful
fast avoidance of randomly thrown objects. Incorporating event camera into
reinforcement learning opens new possibilities for various robotics
applications that require swift control, such as autonomous vehicles and
drones, through end-to-end learning approaches.",autonomous vehicle
http://arxiv.org/abs/2003.07739v2,filtered,arxiv,arxiv,2020-03-17 14:17:52+00:00,arxiv,"Formal Scenario-Based Testing of Autonomous Vehicles: From Simulation to
  the Real World",http://arxiv.org/abs/2003.07739v2,"We present a new approach to automated scenario-based testing of the safety
of autonomous vehicles, especially those using advanced artificial
intelligence-based components, spanning both simulation-based evaluation as
well as testing in the real world. Our approach is based on formal methods,
combining formal specification of scenarios and safety properties, algorithmic
test case generation using formal simulation, test case selection for track
testing, executing test cases on the track, and analyzing the resulting data.
Experiments with a real autonomous vehicle at an industrial testing facility
support our hypotheses that (i) formal simulation can be effective at
identifying test cases to run on the track, and (ii) the gap between simulated
and real worlds can be systematically evaluated and bridged.",autonomous vehicle
http://arxiv.org/abs/1903.05252v4,filtered,arxiv,arxiv,2019-03-12 23:04:03+00:00,arxiv,"Zero-Shot Autonomous Vehicle Policy Transfer: From Simulation to
  Real-World via Adversarial Learning",http://arxiv.org/abs/1903.05252v4,"In this article, we demonstrate a zero-shot transfer of an autonomous driving
policy from simulation to University of Delaware's scaled smart city with
adversarial multi-agent reinforcement learning, in which an adversary attempts
to decrease the net reward by perturbing both the inputs and outputs of the
autonomous vehicles during training. We train the autonomous vehicles to
coordinate with each other while crossing a roundabout in the presence of an
adversary in simulation. The adversarial policy successfully reproduces the
simulated behavior and incidentally outperforms, in terms of travel time, both
a human-driving baseline and adversary-free trained policies. Finally, we
demonstrate that the addition of adversarial training considerably improves the
performance \eat{stability and robustness} of the policies after transfer to
the real world compared to Gaussian noise injection.",autonomous vehicle
http://arxiv.org/abs/2001.03864v1,filtered,arxiv,arxiv,2020-01-12 06:06:03+00:00,arxiv,"Learning to drive via Apprenticeship Learning and Deep Reinforcement
  Learning",http://arxiv.org/abs/2001.03864v1,"With the implementation of reinforcement learning (RL) algorithms, current
state-of-art autonomous vehicle technology have the potential to get closer to
full automation. However, most of the applications have been limited to game
domains or discrete action space which are far from the real world driving.
Moreover, it is very tough to tune the parameters of reward mechanism since the
driving styles vary a lot among the different users. For instance, an
aggressive driver may prefer driving with high acceleration whereas some
conservative drivers prefer a safer driving style. Therefore, we propose an
apprenticeship learning in combination with deep reinforcement learning
approach that allows the agent to learn the driving and stopping behaviors with
continuous actions. We use gradient inverse reinforcement learning (GIRL)
algorithm to recover the unknown reward function and employ REINFORCE as well
as Deep Deterministic Policy Gradient algorithm (DDPG) to learn the optimal
policy. The performance of our method is evaluated in simulation-based scenario
and the results demonstrate that the agent performs human like driving and even
better in some aspects after training.",autonomous vehicle
http://arxiv.org/abs/1705.05065v2,filtered,arxiv,arxiv,2017-05-15 04:06:22+00:00,arxiv,"AirSim: High-Fidelity Visual and Physical Simulation for Autonomous
  Vehicles",http://arxiv.org/abs/1705.05065v2,"Developing and testing algorithms for autonomous vehicles in real world is an
expensive and time consuming process. Also, in order to utilize recent advances
in machine intelligence and deep learning we need to collect a large amount of
annotated training data in a variety of conditions and environments. We present
a new simulator built on Unreal Engine that offers physically and visually
realistic simulations for both of these goals. Our simulator includes a physics
engine that can operate at a high frequency for real-time hardware-in-the-loop
(HITL) simulations with support for popular protocols (e.g. MavLink). The
simulator is designed from the ground up to be extensible to accommodate new
types of vehicles, hardware platforms and software protocols. In addition, the
modular design enables various components to be easily usable independently in
other projects. We demonstrate the simulator by first implementing a quadrotor
as an autonomous vehicle and then experimentally comparing the software
components with real-world flights.",autonomous vehicle
http://arxiv.org/abs/2107.11762v1,filtered,arxiv,arxiv,2021-07-25 09:15:46+00:00,arxiv,"DR2L: Surfacing Corner Cases to Robustify Autonomous Driving via Domain
  Randomization Reinforcement Learning",http://arxiv.org/abs/2107.11762v1,"How to explore corner cases as efficiently and thoroughly as possible has
long been one of the top concerns in the context of deep reinforcement learning
(DeepRL) autonomous driving. Training with simulated data is less costly and
dangerous than utilizing real-world data, but the inconsistency of parameter
distribution and the incorrect system modeling in simulators always lead to an
inevitable Sim2real gap, which probably accounts for the underperformance in
novel, anomalous and risky cases that simulators can hardly generate. Domain
Randomization(DR) is a methodology that can bridge this gap with little or no
real-world data. Consequently, in this research, an adversarial model is put
forward to robustify DeepRL-based autonomous vehicles trained in simulation to
gradually surfacing harder events, so that the models could readily transfer to
the real world.",autonomous vehicle
http://arxiv.org/abs/2101.10369v2,filtered,arxiv,arxiv,2021-01-02 10:43:41+00:00,arxiv,"Effective Communications: A Joint Learning and Communication Framework
  for Multi-Agent Reinforcement Learning over Noisy Channels",http://arxiv.org/abs/2101.10369v2,"We propose a novel formulation of the ""effectiveness problem"" in
communications, put forth by Shannon and Weaver in their seminal work [2], by
considering multiple agents communicating over a noisy channel in order to
achieve better coordination and cooperation in a multi-agent reinforcement
learning (MARL) framework. Specifically, we consider a multi-agent partially
observable Markov decision process (MA-POMDP), in which the agents, in addition
to interacting with the environment can also communicate with each other over a
noisy communication channel. The noisy communication channel is considered
explicitly as part of the dynamics of the environment and the message each
agent sends is part of the action that the agent can take. As a result, the
agents learn not only to collaborate with each other but also to communicate
""effectively"" over a noisy channel. This framework generalizes both the
traditional communication problem, where the main goal is to convey a message
reliably over a noisy channel, and the ""learning to communicate"" framework that
has received recent attention in the MARL literature, where the underlying
communication channels are assumed to be error-free. We show via examples that
the joint policy learned using the proposed framework is superior to that where
the communication is considered separately from the underlying MA-POMDP. This
is a very powerful framework, which has many real world applications, from
autonomous vehicle planning to drone swarm control, and opens up the rich
toolbox of deep reinforcement learning for the design of multi-user
communication systems.",autonomous vehicle
http://arxiv.org/abs/1905.05162v1,filtered,arxiv,arxiv,2019-05-13 17:45:02+00:00,arxiv,"Locally Weighted Regression Pseudo-Rehearsal for Online Learning of
  Vehicle Dynamics",http://arxiv.org/abs/1905.05162v1,"We consider the problem of online adaptation of a neural network designed to
represent vehicle dynamics. The neural network model is intended to be used by
an MPC control law to autonomously control the vehicle. This problem is
challenging because both the input and target distributions are non-stationary,
and naive approaches to online adaptation result in catastrophic forgetting,
which can in turn lead to controller failures. We present a novel online
learning method, which combines the pseudo-rehearsal method with locally
weighted projection regression. We demonstrate the effectiveness of the
resulting Locally Weighted Projection Regression Pseudo-Rehearsal (LW-PR$^2$)
method in simulation and on a large real world dataset collected with a 1/5
scale autonomous vehicle.",autonomous vehicle
http://arxiv.org/abs/1901.05101v1,filtered,arxiv,arxiv,2019-01-16 01:20:00+00:00,arxiv,"ReNeg and Backseat Driver: Learning from Demonstration with Continuous
  Human Feedback",http://arxiv.org/abs/1901.05101v1,"In autonomous vehicle (AV) control, allowing mistakes can be quite dangerous
and costly in the real world. For this reason we investigate methods of
training an AV without allowing the agent to explore and instead having a human
explorer collect the data. Supervised learning has been explored for AV
control, but it encounters the issue of the covariate shift. That is, training
data collected from an optimal demonstration consists only of the states
induced by the optimal control policy, but at runtime, the trained agent may
encounter a vastly different state distribution with little relevant training
data. To mitigate this issue, we have our human explorer make sub-optimal
decisions. In order to have our agent not replicate these sub-optimal
decisions, supervised learning requires that we either erase these actions, or
replace these action with the correct action. Erasing is wasteful and replacing
is difficult, since it is not easy to know the correct action without driving.
We propose an alternate framework that includes continuous scalar feedback for
each action, marking which actions we should replicate, which we should avoid,
and how sure we are. Our framework learns continuous control from sub-optimal
demonstration and evaluative feedback collected before training. We find that a
human demonstrator can explore sub-optimal states in a safe manner, while still
getting enough gradation to benefit learning. The collection method for data
and feedback we call ""Backseat Driver."" We call the more general learning
framework ReNeg, since it learns a regression from states to actions given
negative as well as positive examples. We empirically validate several models
in the ReNeg framework, testing on lane-following with limited data. We find
that the best solution is a generalization of mean-squared error and
outperforms supervised learning on the positive examples alone.",autonomous vehicle
http://arxiv.org/abs/1812.03823v2,filtered,arxiv,arxiv,2018-12-10 14:31:58+00:00,arxiv,Learning to Drive from Simulation without Real World Labels,http://arxiv.org/abs/1812.03823v2,"Simulation can be a powerful tool for understanding machine learning systems
and designing methods to solve real-world problems. Training and evaluating
methods purely in simulation is often ""doomed to succeed"" at the desired task
in a simulated environment, but the resulting models are incapable of operation
in the real world. Here we present and evaluate a method for transferring a
vision-based lane following driving policy from simulation to operation on a
rural road without any real-world labels. Our approach leverages recent
advances in image-to-image translation to achieve domain transfer while jointly
learning a single-camera control policy from simulation control labels. We
assess the driving performance of this method using both open-loop regression
metrics, and closed-loop performance operating an autonomous vehicle on rural
and urban roads.",autonomous vehicle
http://arxiv.org/abs/2007.16162v2,filtered,arxiv,arxiv,2020-07-31 16:32:23+00:00,arxiv,Imitative Planning using Conditional Normalizing Flow,http://arxiv.org/abs/2007.16162v2,"We explore the application of normalizing flows for improving the performance
of trajectory planning for autonomous vehicles (AVs). Normalizing flows provide
an invertible mapping from a known prior distribution to a potentially complex,
multi-modal target distribution and allow for fast sampling with exact PDF
inference. By modeling a trajectory planner's cost manifold as an energy
function we learn a scene conditioned mapping from the prior to a Boltzmann
distribution over the AV control space. This mapping allows for control samples
and their associated energy to be generated jointly and in parallel. We propose
using neural autoregressive flow (NAF) as part of an end-to-end deep learned
system that allows for utilizing sensors, map, and route information to
condition the flow mapping. Finally, we demonstrate the effectiveness of our
approach on real world datasets over IL and hand constructed trajectory
sampling techniques.",autonomous vehicle
http://arxiv.org/abs/2002.10570v2,filtered,arxiv,arxiv,2020-02-24 22:17:25+00:00,arxiv,"Real-time Fusion Network for RGB-D Semantic Segmentation Incorporating
  Unexpected Obstacle Detection for Road-driving Images",http://arxiv.org/abs/2002.10570v2,"Semantic segmentation has made striking progress due to the success of deep
convolutional neural networks. Considering the demands of autonomous driving,
real-time semantic segmentation has become a research hotspot these years.
However, few real-time RGB-D fusion semantic segmentation studies are carried
out despite readily accessible depth information nowadays. In this paper, we
propose a real-time fusion semantic segmentation network termed RFNet that
effectively exploits complementary cross-modal information. Building on an
efficient network architecture, RFNet is capable of running swiftly, which
satisfies autonomous vehicles applications. Multi-dataset training is leveraged
to incorporate unexpected small obstacle detection, enriching the recognizable
classes required to face unforeseen hazards in the real world. A comprehensive
set of experiments demonstrates the effectiveness of our framework. On
Cityscapes, Our method outperforms previous state-of-the-art semantic
segmenters, with excellent accuracy and 22Hz inference speed at the full
2048x1024 resolution, outperforming most existing RGB-D networks.",autonomous vehicle
http://arxiv.org/abs/1905.13428v1,filtered,arxiv,arxiv,2019-05-31 06:02:52+00:00,arxiv,"Attentional Policies for Cross-Context Multi-Agent Reinforcement
  Learning",http://arxiv.org/abs/1905.13428v1,"Many potential applications of reinforcement learning in the real world
involve interacting with other agents whose numbers vary over time. We propose
new neural policy architectures for these multi-agent problems. In contrast to
other methods of training an individual, discrete policy for each agent and
then enforcing cooperation through some additional inter-policy mechanism, we
follow the spirit of recent work on the power of relational inductive biases in
deep networks by learning multi-agent relationships at the policy level via an
attentional architecture. In our method, all agents share the same policy, but
independently apply it in their own context to aggregate the other agents'
state information when selecting their next action. The structure of our
architectures allow them to be applied on environments with varying numbers of
agents. We demonstrate our architecture on a benchmark multi-agent autonomous
vehicle coordination problem, obtaining superior results to a full-knowledge,
fully-centralized reference solution, and significantly outperforming it when
scaling to large numbers of agents.",autonomous vehicle
http://arxiv.org/abs/2109.12155v1,filtered,arxiv,arxiv,2021-09-24 19:20:00+00:00,arxiv,"Learning-based Initialization Strategy for Safety of Multi-Vehicle
  Systems",http://arxiv.org/abs/2109.12155v1,"Multi-vehicle collision avoidance is a highly crucial problem due to the
soaring interests of introducing autonomous vehicles into the real world in
recent years. The safety of these vehicles while they complete their objectives
is of paramount importance. Hamilton-Jacobi (HJ) reachability is a promising
tool for guaranteeing safety for low-dimensional systems. However, due to its
exponential complexity in computation time, no reachability-based methods have
been able to guarantee safety for more than three vehicles successfully in
unstructured scenarios. For systems with four or more vehicles,we can only
empirically validate their safety performance.While reachability-based safety
methods enjoy a flexible least-restrictive control strategy, it is challenging
to reason about long-horizon trajectories online because safety at any given
state is determined by looking up its safety value in a pre-computed table that
does not exhibit favorable properties that continuous functions have. This
motivates the problem of improving the safety performance of unstructured
multi-vehicle systems when safety cannot be guaranteed given any
least-restrictive safety-aware collision avoidance algorithm while avoiding
online trajectory optimization. In this paper, we propose a novel approach
using supervised learning to enhance the safety of vehicles by proposing new
initial states in very close neighborhood of the original initial states of
vehicles. Our experiments demonstrate the effectiveness of our proposed
approach and show that vehicles are able to get to their goals with better
safety performance with our approach compared to a baseline approach in
wide-ranging scenarios.",autonomous vehicle
http://arxiv.org/abs/2007.02203v6,filtered,arxiv,arxiv,2020-07-04 23:00:52+00:00,arxiv,"Accuracy-Efficiency Trade-Offs and Accountability in Distributed ML
  Systems",http://arxiv.org/abs/2007.02203v6,"Trade-offs between accuracy and efficiency pervade law, public health, and
other non-computing domains, which have developed policies to guide how to
balance the two in conditions of uncertainty. While computer science also
commonly studies accuracy-efficiency trade-offs, their policy implications
remain poorly examined. Drawing on risk assessment practices in the US, we
argue that, since examining these trade-offs has been useful for guiding
governance in other domains, we need to similarly reckon with these trade-offs
in governing computer systems. We focus our analysis on distributed machine
learning systems. Understanding the policy implications in this area is
particularly urgent because such systems, which include autonomous vehicles,
tend to be high-stakes and safety-critical. We 1) describe how the trade-off
takes shape for these systems, 2) highlight gaps between existing US risk
assessment standards and what these systems require to be properly assessed,
and 3) make specific calls to action to facilitate accountability when
hypothetical risks concerning the accuracy-efficiency trade-off become realized
as accidents in the real world. We close by discussing how such accountability
mechanisms encourage more just, transparent governance aligned with public
values.",autonomous vehicle
http://arxiv.org/abs/1806.00678v1,filtered,arxiv,arxiv,2018-06-02 17:46:33+00:00,arxiv,AutoRally An open platform for aggressive autonomous driving,http://arxiv.org/abs/1806.00678v1,"This article presents AutoRally, a 1$:$5 scale robotics testbed for
autonomous vehicle research. AutoRally is designed for robustness, ease of use,
and reproducibility, so that a team of two people with limited knowledge of
mechanical engineering, electrical engineering, and computer science can
construct and then operate the testbed to collect real world autonomous driving
data in whatever domain they wish to study. Complete documentation to construct
and operate the platform is available online along with tutorials, example
controllers, and a driving dataset collected at the Georgia Tech Autonomous
Racing Facility. Offline estimation algorithms are used to determine parameters
for physics-based dynamics models using an adaptive limited memory joint state
unscented Kalman filter. Online vehicle state estimation using a factor graph
optimization scheme and a convolutional neural network for semantic
segmentation of drivable surface are presented. All algorithms are tested with
real world data from the fleet of six AutoRally robots at the Georgia Tech
Autonomous Racing Facility tracks, and serve as a demonstration of the
robot$'$s capabilities.",autonomous vehicle
http://arxiv.org/abs/1905.04354v2,filtered,arxiv,arxiv,2019-05-10 19:39:32+00:00,arxiv,"FastDraw: Addressing the Long Tail of Lane Detection by Adapting a
  Sequential Prediction Network",http://arxiv.org/abs/1905.04354v2,"The search for predictive models that generalize to the long tail of sensor
inputs is the central difficulty when developing data-driven models for
autonomous vehicles. In this paper, we use lane detection to study modeling and
training techniques that yield better performance on real world test drives. On
the modeling side, we introduce a novel fully convolutional model of lane
detection that learns to decode lane structures instead of delegating structure
inference to post-processing. In contrast to previous works, our convolutional
decoder is able to represent an arbitrary number of lanes per image, preserves
the polyline representation of lanes without reducing lanes to polynomials, and
draws lanes iteratively without requiring the computational and temporal
complexity of recurrent neural networks. Because our model includes an estimate
of the joint distribution of neighboring pixels belonging to the same lane, our
formulation includes a natural and computationally cheap definition of
uncertainty. On the training side, we demonstrate a simple yet effective
approach to adapt the model to new environments using unsupervised style
transfer. By training FastDraw to make predictions of lane structure that are
invariant to low-level stylistic differences between images, we achieve strong
performance at test time in weather and lighting conditions that deviate
substantially from those of the annotated datasets that are publicly available.
We quantitatively evaluate our approach on the CVPR 2017 Tusimple lane marking
challenge, difficult CULane datasets, and a small labeled dataset of our own
and achieve competitive accuracy while running at 90 FPS.",autonomous vehicle
http://arxiv.org/abs/1907.05418v1,filtered,arxiv,arxiv,2019-07-11 17:59:13+00:00,arxiv,Adversarial Objects Against LiDAR-Based Autonomous Driving Systems,http://arxiv.org/abs/1907.05418v1,"Deep neural networks (DNNs) are found to be vulnerable against adversarial
examples, which are carefully crafted inputs with a small magnitude of
perturbation aiming to induce arbitrarily incorrect predictions. Recent studies
show that adversarial examples can pose a threat to real-world
security-critical applications: a ""physical adversarial Stop Sign"" can be
synthesized such that the autonomous driving cars will misrecognize it as
others (e.g., a speed limit sign). However, these image-space adversarial
examples cannot easily alter 3D scans of widely equipped LiDAR or radar on
autonomous vehicles. In this paper, we reveal the potential vulnerabilities of
LiDAR-based autonomous driving detection systems, by proposing an optimization
based approach LiDAR-Adv to generate adversarial objects that can evade the
LiDAR-based detection system under various conditions. We first show the
vulnerabilities using a blackbox evolution-based algorithm, and then explore
how much a strong adversary can do, using our gradient-based approach
LiDAR-Adv. We test the generated adversarial objects on the Baidu Apollo
autonomous driving platform and show that such physical systems are indeed
vulnerable to the proposed attacks. We also 3D-print our adversarial objects
and perform physical experiments to illustrate that such vulnerability exists
in the real world. Please find more visualizations and results on the anonymous
website: https://sites.google.com/view/lidar-adv.",autonomous vehicle
http://arxiv.org/abs/1707.00051v4,filtered,arxiv,arxiv,2017-06-30 21:42:47+00:00,arxiv,"Failing to Learn: Autonomously Identifying Perception Failures for
  Self-driving Cars",http://arxiv.org/abs/1707.00051v4,"One of the major open challenges in self-driving cars is the ability to
detect cars and pedestrians to safely navigate in the world. Deep
learning-based object detector approaches have enabled great advances in using
camera imagery to detect and classify objects. But for a safety critical
application, such as autonomous driving, the error rates of the current state
of the art are still too high to enable safe operation. Moreover, the
characterization of object detector performance is primarily limited to testing
on prerecorded datasets. Errors that occur on novel data go undetected without
additional human labels. In this letter, we propose an automated method to
identify mistakes made by object detectors without ground truth labels. We show
that inconsistencies in the object detector output between a pair of similar
images can be used as hypotheses for false negatives (e.g., missed detections)
and using a novel set of features for each hypothesis, an off-the-shelf binary
classifier can be used to find valid errors. In particular, we study two
distinct cues - temporal and stereo inconsistencies - using data that are
readily available on most autonomous vehicles. Our method can be used with any
camera-based object detector and we illustrate the technique on several sets of
real world data. We show that a state-of-the-art detector, tracker, and our
classifier trained only on synthetic data can identify valid errors on KITTI
tracking dataset with an average precision of 0.94. We also release a new
tracking dataset with 104 sequences totaling 80,655 labeled pairs of stereo
images along with ground truth disparity from a game engine to facilitate
further research. The dataset and code are available at
https://fcav.engin.umich.edu/research/failing-to-learn",autonomous vehicle
http://arxiv.org/abs/2010.04331v3,filtered,arxiv,arxiv,2020-10-09 02:31:34+00:00,arxiv,"Targeted Physical-World Attention Attack on Deep Learning Models in Road
  Sign Recognition",http://arxiv.org/abs/2010.04331v3,"Real world traffic sign recognition is an important step towards building
autonomous vehicles, most of which highly dependent on Deep Neural Networks
(DNNs). Recent studies demonstrated that DNNs are surprisingly susceptible to
adversarial examples. Many attack methods have been proposed to understand and
generate adversarial examples, such as gradient based attack, score based
attack, decision based attack, and transfer based attacks. However, most of
these algorithms are ineffective in real-world road sign attack, because (1)
iteratively learning perturbations for each frame is not realistic for a fast
moving car and (2) most optimization algorithms traverse all pixels equally
without considering their diverse contribution. To alleviate these problems,
this paper proposes the targeted attention attack (TAA) method for real world
road sign attack. Specifically, we have made the following contributions: (1)
we leverage the soft attention map to highlight those important pixels and skip
those zero-contributed areas - this also helps to generate natural
perturbations, (2) we design an efficient universal attack that optimizes a
single perturbation/noise based on a set of training images under the guidance
of the pre-trained attention map, (3) we design a simple objective function
that can be easily optimized, (4) we evaluate the effectiveness of TAA on real
world data sets. Experimental results validate that the TAA method improves the
attack successful rate (nearly 10%) and reduces the perturbation loss (about a
quarter) compared with the popular RP2 method. Additionally, our TAA also
provides good properties, e.g., transferability and generalization capability.
We provide code and data to ensure the reproducibility:
https://github.com/AdvAttack/RoadSignAttack.",autonomous vehicle
http://arxiv.org/abs/2012.10672v2,filtered,arxiv,arxiv,2020-12-19 12:26:06+00:00,arxiv,RMT: Rule-based Metamorphic Testing for Autonomous Driving Models,http://arxiv.org/abs/2012.10672v2,"Deep neural network models are widely used for perception and control in
autonomous driving. Recent work uses metamorphic testing but is limited to
using equality-based metamorphic relations and does not provide expressiveness
for defining inequality-based metamorphic relations. To encode real world
traffic rules, domain experts must be able to express higher order relations
e.g., a vehicle should decrease speed in certain ratio, when there is a vehicle
x meters ahead and compositionality e.g., a vehicle must have a larger
deceleration, when there is a vehicle ahead and when the weather is rainy and
proportional compounding effect to the test outcome. We design RMT, a
declarative rule-based metamorphic testing framework. It provides three
components that work in concert:(1) a domain specific language that enables an
expert to express higher-order, compositional metamorphic relations, (2)
pluggable transformation engines built on a variety of image and graphics
processing techniques, and (3) automated test generation that translates a
human-written rule to a corresponding executable, metamorphic relation and
synthesizes meaningful inputs.Our evaluation using three driving models shows
that RMT can generate meaningful test cases on which 89% of erroneous
predictions are found by enabling higher-order metamorphic relations.
Compositionality provides further aids for generating meaningful, synthesized
inputs-3012 new images are generated by compositional rules. These detected
erroneous predictions are manually examined and confirmed by six human judges
as meaningful traffic rule violations. RMT is the first to expand automated
testing capability for autonomous vehicles by enabling easy mapping of traffic
regulations to executable metamorphic relations and to demonstrate the benefits
of expressivity, customization, and pluggability.",autonomous vehicle
10.1016/j.jii.2021.100224,filtered,Journal of Industrial Information Integration,sciencedirect,2021-09-30,sciencedirect,Study on artificial intelligence: The state of the art and future prospects,https://api.elsevier.com/content/article/pii/S2452414X21000248,"
                  In the world, the technological and industrial revolution is accelerating by the widespread application of new generation information and communication technologies, such as AI, IoT (the Internet of Things), and blockchain technology. Artificial intelligence has attracted much attention from government, industry, and academia. In this study, popular articles published in recent years that relate to artificial intelligence are selected and explored. This study aims to provide a review of artificial intelligence based on industry information integration. It presents an overview of the scope of artificial intelligence using background, drivers, technologies, and applications, as well as logical opinions regarding the development of artificial intelligence. This paper may play a role in AI-related research and should provide important insights for practitioners in the real world.The main contribution of this study is that it clarifies the state of the art of AI for future study.
               ",autonomous vehicle
10.1016/j.neunet.2019.01.012,filtered,Neural Networks,sciencedirect,2019-05-31,sciencedirect,Continual lifelong learning with neural networks: A review,https://api.elsevier.com/content/article/pii/S0893608019300231,"Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for computational learning systems and autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference. This limitation represents a major drawback for state-of-the-art deep neural network models that typically learn representations from stationary batches of training data, thus without accounting for situations in which information becomes incrementally available over time. In this review, we critically summarize the main challenges linked to lifelong learning for artificial learning systems and compare existing neural network approaches that alleviate, to different extents, catastrophic forgetting. Although significant advances have been made in domain-specific learning with neural networks, extensive research efforts are required for the development of robust lifelong learning on autonomous agents and robots. We discuss well-established and emerging research motivated by lifelong learning factors in biological systems such as structural plasticity, memory replay, curriculum and transfer learning, intrinsic motivation, and multisensory integration.",autonomous vehicle
10.1016/j.ins.2020.11.048,filtered,Information Sciences,sciencedirect,2021-04-30,sciencedirect,A novel lifelong learning model based on cross domain knowledge extraction and transfer to classify underwater images,https://api.elsevier.com/content/article/pii/S0020025520311464,"
                  Artificial intelligence based autonomous systems interacting with dynamic environment are required to continuously learn, accumulate and improve the learned knowledge. Currently, most artificial intelligence based systems lack this ability and work in isolated learning paradigm. Human beings follow the continuous learning process by retaining and accumulating the learnt knowledge, and by using the learnt knowledge to solve the problem at hand. In this paper, we present a lifelong learning model, to solve challenging problem of real world underwater image classification. The proposed model is capable to learn from simple problems, accumulates the learnt knowledge by continual learning and uses the learnt knowledge to solve future complex problems of the same or related domain, in a similar way as humans do. In the proposed model, firstly, a deep classification convolutional autoencoder is presented to extract spatially localized features from images by utilizing convolution filters, then a code fragment based learning classifier system, with rich knowledge encoding scheme, is proposed for knowledge representation and transfer. In order to validate the model, experiments are conducted on two underwater images datasets and one in-air images dataset. Experiments results demonstrate that the proposed method outperforms base line method and state-of-the-art convolution neural network (CNN) methods.
               ",autonomous vehicle
10.1016/j.inffus.2019.12.004,filtered,Information Fusion,sciencedirect,2020-06-30,sciencedirect,"Continual learning for robotics: Definition, framework, learning strategies, opportunities and challenges",https://api.elsevier.com/content/article/pii/S1566253519307377,"
                  Continual learning (CL) is a particular machine learning paradigm where the data distribution and learning objective change through time, or where all the training data and objective criteria are never available at once. The evolution of the learning process is modeled by a sequence of learning experiences where the goal is to be able to learn new skills all along the sequence without forgetting what has been previously learned. CL can be seen as an online learning where knowledge fusion needs to take place in order to learn from streams of data presented sequentially in time. Continual learning also aims at the same time at optimizing the memory, the computation power and the speed during the learning process. An important challenge for machine learning is not necessarily finding solutions that work in the real world but rather finding stable algorithms that can learn in real world. Hence, the ideal approach would be tackling the real world in a embodied platform: an autonomous agent. Continual learning would then be effective in an autonomous agent or robot, which would learn autonomously through time about the external world, and incrementally develop a set of complex skills and knowledge.Robotic agents have to learn to adapt and interact with their environment using a continuous stream of observations. Some recent approaches aim at tackling continual learning for robotics, but most recent papers on continual learning only experiment approaches in simulation or with static datasets. Unfortunately, the evaluation of those algorithms does not provide insights on whether their solutions may help continual learning in the context of robotics. This paper aims at reviewing the existing state of the art of continual learning, summarizing existing benchmarks and metrics, and proposing a framework for presenting and evaluating both robotics and non robotics approaches in a way that makes transfer between both fields easier. We put light on continual learning in the context of robotics to create connections between fields and normalize approaches.
               ",autonomous vehicle
10.1016/j.robot.2020.103630,filtered,Robotics and Autonomous Systems,sciencedirect,2020-11-30,sciencedirect,Improving robot dual-system motor learning with intrinsically motivated meta-control and latent-space experience imagination,https://api.elsevier.com/content/article/pii/S092188902030470X,"Combining model-based and model-free learning systems has been shown to improve the sample efficiency of learning to perform complex robotic tasks. However, dual-system approaches fail to consider the reliability of the learned model when it is applied to make multiple-step predictions, resulting in a compounding of prediction errors and performance degradation. In this paper, we present a novel dual-system motor learning approach where a meta-controller arbitrates online between model-based and model-free decisions based on an estimate of the local reliability of the learned model. The reliability estimate is used in computing an intrinsic feedback signal, encouraging actions that lead to data that improves the model. Our approach also integrates arbitration with imagination where a learned latent-space model generates imagined experiences, based on its local reliability, to be used as additional training data. We evaluate our approach against baseline and state-of-the-art methods on learning vision-based robotic grasping in simulation and real world. The results show that our approach outperforms the compared methods and learns near-optimal grasping policies in dense- and sparse-reward environments.",autonomous vehicle
10.1016/j.arr.2018.11.003,filtered,Ageing Research Reviews,sciencedirect,2019-01-31,sciencedirect,Artificial intelligence for aging and longevity research: Recent advances and perspectives,https://api.elsevier.com/content/article/pii/S156816371830240X,"The applications of modern artificial intelligence (AI) algorithms within the field of aging research offer tremendous opportunities. Aging is an almost universal unifying feature possessed by all living organisms, tissues, and cells. Modern deep learning techniques used to develop age predictors offer new possibilities for formerly incompatible dynamic and static data types. AI biomarkers of aging enable a holistic view of biological processes and allow for novel methods for building causal models—extracting the most important features and identifying biological targets and mechanisms. Recent developments in generative adversarial networks (GANs) and reinforcement learning (RL) permit the generation of diverse synthetic molecular and patient data, identification of novel biological targets, and generation of novel molecular compounds with desired properties and geroprotectors. These novel techniques can be combined into a unified, seamless end-to-end biomarker development, target identification, drug discovery and real world evidence pipeline that may help accelerate and improve pharmaceutical research and development practices. Modern AI is therefore expected to contribute to the credibility and prominence of longevity biotechnology in the healthcare and pharmaceutical industry, and to the convergence of countless areas of research.",autonomous vehicle
10.1016/j.smhl.2018.07.015,filtered,Smart Health,sciencedirect,2018-12-31,sciencedirect,New attacks on RNN based healthcare learning system and their detections,https://api.elsevier.com/content/article/pii/S2352648318300503,"
                  Advances in machine learning (ML) in recent years have enabled a wide range of applications such as data analytics, autonomous systems, and security diagnostics. For example, recurrent neural networks (RNNs), such as long short-term memory networks (LSTMs), serve as a fundamental building block for many sequence learning tasks. Many researchers construct learning based inference and decision making models using primitive learning modules (PLMs) hosted in popular developer platforms, e.g., github. However, most of the publicly available primitive learning modules (PLMs) are maintained by third parties and lack proper checking to ensure they have not been maliciously modified by adversaries. In this paper, we articulate a particular threat to Recurrent Neural Network (RNN) based ML systems by introducing a new attack, which adjusts the weights of a RNN-based model causing it to produce wrong prediction results. Via synthetic and real world datasets, we demonstrate that such an attack is feasible. Next, we propose a detection scheme which can be used to infer if a particular PLM used in a RNN-based ML system contains such malicious behaviors. Experimental results show that our RNN based attack algorithm decreases the system performance when weights of important features are modified during training. In addition, our results also show that our detection mechanism is useful in identifying such malicious PLM.
               ",autonomous vehicle
10.1016/0167-8191(90)90089-R,filtered,Parallel Computing,sciencedirect,1990-08-31,sciencedirect,"Neural networks for learning in the real world: representation, reinforcement and dynamics",https://api.elsevier.com/content/article/pii/016781919090089R,"
                  It is argued that the backpropagation learning algorithm is unsuited to tackling real world problems such as sensory-motor coordination learning or the encoding of large amounts of background knowledge in neural networks. One difficulty in the real world - the unavailability of ‘teachers’ who already know the solution to problems, may be overcome by the use of reinforcement learning algorithms in place of backpropagation. It is suggested that the complexity of search space in real world neural network learning problems may be reduced if learning is divided into two components. One component is concerned with abstracting structure from the environment and hence with developing representations of stimuli. The other component involves associating and refining these representations on the basis of feedback from the environment. Time-dependent learning problems are also considered in this hybrid framework. Finally, an ‘open systems’ approach in which subsets of a network may adapt independently on the basis of spatio-temporal patterns is briefly discussed.
               ",autonomous vehicle
10.1016/j.jmsy.2021.07.021,filtered,Journal of Manufacturing Systems,sciencedirect,2021-07-31,sciencedirect,Artificial intelligence for throughput bottleneck analysis – State-of-the-art and future directions,https://api.elsevier.com/content/article/pii/S0278612521001588,"Identifying, and eventually eliminating throughput bottlenecks, is a key means to increase throughput and productivity in production systems. In the real world, however, eliminating throughput bottlenecks is a challenge. This is due to the landscape of complex factory dynamics, with several hundred machines operating at any given time. Academic researchers have tried to develop tools to help identify and eliminate throughput bottlenecks. Historically, research efforts have focused on developing analytical and discrete event simulation modelling approaches to identify throughput bottlenecks in production systems. However, with the rise of industrial digitalisation and artificial intelligence (AI), academic researchers explored different ways in which AI might be used to eliminate throughput bottlenecks, based on the vast amounts of digital shop floor data. By conducting a systematic literature review, this paper aims to present state-of-the-art research efforts into the use of AI for throughput bottleneck analysis. To make the work of the academic AI solutions more accessible to practitioners, the research efforts are classified into four categories: (1) identify, (2) diagnose, (3) predict and (4) prescribe. This was inspired by real-world throughput bottleneck management practice. The categories, identify and diagnose focus on analysing historical throughput bottlenecks, whereas predict and prescribe focus on analysing future throughput bottlenecks. This paper also provides future research topics and practical recommendations which may help to further push the boundaries of the theoretical and practical use of AI in throughput bottleneck analysis.",autonomous vehicle
10.1016/j.procs.2019.01.118,filtered,Procedia Computer Science,sciencedirect,2019-12-31,sciencedirect,Automatic data labeling by neural networks for the counting of objects in videos,https://api.elsevier.com/content/article/pii/S1877050919301255,"The paper proposes an efficient method for training a neural network to count moving objects in a video, while another neural network concurrently prepares a labeled dataset for the first one. The detection, tracking, and counting of objects is crucial for effective Intelligence Transportation Systems (ITS), which should reduce congestion and recognize traffic offenders on highways and in urban areas. Creation of labeled data for training a neural network is one of the essential prerequisites for successful application of supervised machine learning. In this paper, the experimental results of the automatic labeling and counting of vehicles under real world conditions are shown. The method shows that by using the Convolutional Neural Network (CNN), the computing power and speed-up time for training a Recurrent Neural Network (RNN) with a Long Short-Term Memory (LSTM) cell for counting moving objects can be decreased.",autonomous vehicle
10.1016/j.neucom.2016.03.067,filtered,Neurocomputing,sciencedirect,2016-09-26,sciencedirect,Self-adjusting feature maps network and its applications,https://api.elsevier.com/content/article/pii/S0925231216303009,"
                  This paper, proposes a novel artificial neural network, called self-adjusting feature map (SAM), and develop its unsupervised learning ability with self-adjusting mechanism. The trained network structure of representative connected neurons not only displays the spatial relation of the input data distribution but also quantizes the data well. The SAM can automatically isolate a set of connected neurons, in which, the used number of the sets may indicate the number of clusters. The idea of self-adjusting mechanism is based on combining of mathematical statistics and neurological advantages and retreat of waste. In the training process, for each representative neuron has are three phases, growth, adaptation and decline. The network of representative neurons, first create the necessary neurons according to the local density of the input data in the growth phase. In the adaption phase, it adjusts neighborhood neuron pair׳s connected/disconnected topology constantly according to the statistics of input feature data. Finally, the unnecessary neurons of the network are merged or remove in the decline phase. In this paper, we exploit the SAM to handle some peculiar cases that cannot be handled easily by classical unsupervised learning networks such as self-organizing map (SOM) network. The remarkable characteristics of the SAM can be seen on various real world cases in the experimental results.
               ",autonomous vehicle
10.1016/0921-8890(95)00035-E,filtered,Robotics and Autonomous Systems,sciencedirect,1995-11-30,sciencedirect,Artificial neural network for mobile robot topological localization,https://api.elsevier.com/content/article/pii/092188909500035E,"
                  This paper presents a neural network based approach to a mobile robot localization in front of a certain local object. The robot is equipped with ultrasonic range sensors mounted around the platform. We employ the Fuzzy-ARTMAP network for supervised learning of associations between vectors of sensor readouts and the robot's pose coordinates. In this approach, a world model in the form of a map, as well as its updating routine, become superflous for the considered problem solution. The system, trained on real world data of a door neighborhood region reveals satisfactory performance, sufficient for door-passing task purposes. The proposed method of a mobile robot positioning may be efficiently applied in environments containing natural, geometrical beacons.
               ",autonomous vehicle
10.1016/0370-1573(91)90146-D,filtered,Physics Reports,sciencedirect,1991-09-30,sciencedirect,Neural networks and applications tutorial,https://api.elsevier.com/content/article/pii/037015739190146D,"
                  The importance of neural networks has grown dramatically during this decade. While only a few years ago they were primarily of academic interest, now dozens of companies and many universities are investigating the potential use of these systems and products are beginning to appear.
                  The idea of building a machine whose architecture is inspired by that of the brain has roots which go far back in history. Nowadays, technological advances of computers and the availability of custom integrated circuits, permit simulations of hundreds or even thousands of neurons. In conjunction, the growing interest in learning machines, non-linear dynamics and parallel computation spurred renewed attention in artificial neural networks.
                  Many tentative applications have been proposed, including decision systems (associative memories, classifiers, data compressors and optimizers), or parametric models for signal processing purposes (system identification, automatic control, noise canceling, etc.). While they do not always outperform standard methods, neural network approaches are already used in some real world applications for pattern recognition and signal processing tasks.
                  The tutorial is divided into six lectures, that where presented at the Third Graduate Summer Course on Computational Physics (September 3–7, 1990) on Parallel Architectures and Applications, organized by the European Physical Society: (1) Introduction: machine learning and biological computation. (2) Adaptive artificial neurons (perceptron, ADALINE, sigmoid units, etc.): learning rules and implementations. (3) Neural network systems: architectures, learning algorithms. (4) Applications: pattern recognition, signal processing, etc. (5) Elements of learning theory: how to build networks which generalize. (6) A case study: a neural network for on-line recognition of handwritten alphanumeric characters.
               ",autonomous vehicle
10.1016/S0921-8890(99)00122-0,filtered,Robotics and Autonomous Systems,sciencedirect,2000-06-30,sciencedirect,ARBIB: An autonomous robot based on inspirations from biology,https://api.elsevier.com/content/article/pii/S0921889099001220,"
                  Simple artificial creatures (‘animats’), which operate as autonomous, adaptive robots in the real world, can serve both as models of biology and as a radical alternative to conventional methods of designing intelligent systems. We describe the evolution and implementation of the autonomous robot ARBIB, which learns from and adapts to its environment. A primary goal was to test the notion that effective robot learning can be based on neural habituation and sensitization, so validating the suggestion of Hawkins and Kandel that (associative) classical and ‘higher-order’ conditioning might be based on an elaboration of these (non-associative) forms of learning. Accordingly, ARBIB’s ‘nervous system’ has a non-homogeneous population of spiking neurons, and learning is by modification of basic, pre-existing (‘hard-wired’) reflexes. By monitoring firing rates of specific neurons and synaptic weights between neural connections as ARBIB learns from its environment, we confirm that both classical and higher-order conditioning occur, leading to the emergence of interesting and ecologically valid behaviors.
               ",autonomous vehicle
10.1016/j.procs.2016.08.127,filtered,Procedia Computer Science,sciencedirect,2016-12-31,sciencedirect,CL-AntInc Algorithm for Clustering Binary Data Streams Using the Ants Behavior,https://api.elsevier.com/content/article/pii/S1877050916319287,"In this paper, we present a new approach using a non-hierarchical method in graph environment and the concept of artificial ants for both clustering and visualization using Tulip framework. This model can be presented to take into account data in blocks in an incremental way. It seems especially interesting to process binary data streaming. In this algorithm, we also suggest to apply swarm intelligence techniques for the incremental processing of this new challenging data type. The main novelty of this research work resides on the adaptation of CL-AntInc to perform clustering binary data streams and building growing graphs increasingly for this type of data. The proposed algorithm performance is evaluated using real world data sets extracted from Machine Learning Repository. Our algorithm is competitive when compared with other stream clustering methods.",autonomous vehicle
10.3182/20100826-3-TR-4015.00062,filtered,IFAC Proceedings Volumes,sciencedirect,2010-12-31,sciencedirect,Direct Policy Search Method in Fault Tolerant Autonomous Systems,https://api.elsevier.com/content/article/pii/S1474667015323880,"
                  This work is concerned with a new type of realtime reconfigurable control systems that is based on the use of a multi-agent system. To this end, two stages have been examined in the context of decision making; the fault detection and identification (FDI) stage and the reconfiguration stage (RC). The agent based FDI detects that a fault has occurred. It then further diagnoses the situation. The RC stage follows this by adapting or changing the control architecture to accommodate the fault. The agent based problem is to synchronize or integrate these two stages in the overall structure of a control system on real world applications. The multi-agent architecture proposed in this paper has several advantages in terms of modularity, reliability, ability to learn and achieve overall higher robustness over past “single software” methods. Specifically, this paper concentrates on one of the agents introduced, namely the Reconfiguration agent. Tests on a simulation of an example system have been carried out to demonstrate this new organisation of reconfigurable control systems.
               ",autonomous vehicle
10.1016/S0921-8890(97)80707-5,filtered,Robotics and Autonomous Systems,sciencedirect,1997-06-30,sciencedirect,Sensory—motor coordination: The metaphor and beyond,https://api.elsevier.com/content/article/pii/S0921889097807075,"
                  Any agent in the real world has to be able to make distinctions between different types of objects, i.e. it must have the competence of categorization. In mobile agents, there is a large variation in proximal sensory stimulation originating from the same object. Therefore, categorization behavior is hard to achieve, and the successes in the past in solving this problem have been limited. In this paper it is proposed that the problem of categorization in the real world is significantly simplified if it is viewed as one of sensory—motor coordination, rather than one of information processing happening “on the input side”. A series of models are presented to illustrate the approach. It is concluded that we should consider replacing the metaphor of information processing for intelligent systems by the one of sensory-motor coordination. However, the principle of sensory-motor coordination is more than a metaphor. It offers concrete mechanisms for putting agents to work in the real world. These ideas are illustrated with a series of experiments.
               ",autonomous vehicle
10.1016/j.inffus.2021.09.017,filtered,Information Fusion,sciencedirect,2022-02-28,sciencedirect,"On the use of information fusion techniques to improve information quality: Taxonomy, opportunities and challenges",https://api.elsevier.com/content/article/pii/S1566253521001925,"
                  The information fusion field has recently been attracting a lot of interest within the scientific community, as it provides, through the combination of different sources of heterogeneous information, a fuller and/or more precise understanding of the real world than can be gained considering the above sources separately. One of the fundamental aims of computer systems, and especially decision support systems, is to assure that the quality of the information they process is high. There are many different approaches for this purpose, including information fusion. Information fusion is currently one of the most promising methods. It is particularly useful under circumstances where quality might be compromised, for example, either intrinsically due to imperfect information (vagueness, uncertainty, …) or because of limited resources (energy, time, …). In response to this goal, a wide range of research has been undertaken over recent years. To date, the literature reviews in this field have focused on problem-specific issues and have been circumscribed to certain system types. Therefore, there is no holistic and systematic knowledge of the state of the art to help establish the steps to be taken in the future. In particular, aspects like what impact different information fusion methods have on information quality, how information quality is characterised, measured and evaluated in different application domains depending on the problem data type or whether fusion is designed as a flexible process capable of adapting to changing system circumstances and their intrinsically limited resources have not been addressed. This paper aims precisely to review the literature on research into the use of information fusion techniques specifically to improve information quality, analysing the above issues in order to identify a series of challenges and research directions, which are presented in this paper.
               ",autonomous vehicle
10.1016/j.trd.2021.102896,filtered,Transportation Research Part D: Transport and Environment,scopus,2021-08-01,scopus,A time series clustering based approach for construction of real-world drive cycles,https://api.elsevier.com/content/abstract/scopus_id/85107719169,"
                  Building representative real world drive cycles is an important component in the modelling of emissions, battery health of electric vehicles and autonomous vehicles. All these applications are sensitive to the transients and diversity present in real world driving patterns, which are not adequately captured by current approaches. To address this lacuna, we use clustering techniques involving time-series (shape) based distances on the raw data directly to obtain representative sets of real world drive cycles. We demonstrate the efficacy of our approach using experimental data from a fleet of eight motorcycles run across five locations in India. Dynamic Time Warping (DTW) distance based clustering gives optimal results. We give theoretical and experimental justification for our constructions. We believe that the constructed drive cycles using the proposed approach would help in assessing the impact of various policies aimed at building eco-friendly transportation systems.
               ",autonomous vehicle
10.1016/j.bdr.2020.100179,filtered,Big Data Research,scopus,2021-02-15,scopus,A Data-Driven Method for Hybrid Data Assimilation with Multilayer Perceptron,https://api.elsevier.com/content/abstract/scopus_id/85098157745,"
                  Accurate and timely weather prediction is of significance for autonomous vehicles, such as designing more appropriate sensors or other configurations and developing safer driving strategies. Generally, as the mainstream weather prediction method, numerical weather prediction (NWP) relies on high-quality spatio-temporal observations. However, the precise state of the real world is not measurable. Thus, how to obtain a proper initial condition estimation based on big geospatial-temporal data is a crucial procedure for NWP. Data assimilation (DA) has been a traditional solution to the problem, for the better performance of which various mathematical-physics models have been used. However, the computational effectiveness and efficiency are still largely compromised by the complicated and nonparallel integration process in existing DA methods. In this paper, we propose a novel data-driven method named HDA-MLP to address the DA problem. We first constructed a customized MLP by introducing the temporal peculiarities of the state variables to simulate and optimize pure 3DVar and EnKF. Then we blended the optimized analysis fields directly by implicitly updating the background error covariance matrix through another neural network model to alleviate the dependence on traditional DA methods. We conducted extensive experiments to investigate the effectiveness and efficiency of the proposal by utilizing two classical nonlinear dynamic models. Results reveal that our approach has better robustness and enhanced capability to capture the variation of state variables. Notably, the analysis quality and computational efficiency are significantly improved.
               ",autonomous vehicle
10.1016/j.trc.2020.102649,filtered,Transportation Research Part C: Emerging Technologies,scopus,2020-08-01,scopus,Differential variable speed limits control for freeway recurrent bottlenecks via deep actor-critic algorithm,https://api.elsevier.com/content/abstract/scopus_id/85086802562,"
                  Variable speed limit (VSL) control is a flexible way to improve traffic conditions, increase safety, and reduce emissions. There is an emerging trend of using reinforcement learning methods for VSL control. Currently, deep learning is enabling reinforcement learning to develop autonomous control agents for problems that were previously intractable. In this paper, a more effective deep reinforcement learning (DRL) model is developed for differential variable speed limit (DVSL) control, in which dynamic and distinct speed limits among lanes can be imposed. The proposed DRL model uses a novel actor-critic architecture to learn a large number of discrete speed limits in a continuous action space. Different reward signals, such as total travel time, bottleneck speed, emergency braking, and vehicular emissions are used to train the DVSL controller, and a comparison between these reward signals is conducted. The proposed DRL-based DVSL controllers are tested on a freeway with a simulated recurrent bottleneck. The simulation results show that the DRL based DVSL control strategy is able to improve the safety, efficiency and environment-friendliness of the freeway. In order to verify whether the controller generalizes to real world implementation, we also evaluate the generalization of the controllers on environments with different driving behavior attributes. and the robustness of the DRL agent is observed from the results.
               ",autonomous vehicle
10.1016/j.image.2020.115811,filtered,Signal Processing: Image Communication,scopus,2020-05-01,scopus,Quality-guided lane detection by deeply modeling sophisticated traffic context,https://api.elsevier.com/content/abstract/scopus_id/85081131302,"
                  Lane detection is a useful technique in modern autonomous vehicles systems, which assists vehicle to accurately localize itself according to detected road lines. Traditional methods leveraged edge detection and Hough transform based algorithms to plot lines along the detected lane. Noticeably, they did not take the informative feature road gradient into account. In addition, most previous deep learning-based algorithms consider lane detection as pixel-wise lane segmentation, where only fixed number of lanes can be detected. In order to solve these limitations, we propose a quality guided lane detection algorithm by modeling the sophisticated traffic context, where variable number of lanes can be satisfactorily handled. Specifically, we first leverage chessboard images for camera calibration to calculate correspondence between real world and image coordinate system. Subsequently, we capture image regions of interest that only contains lane information by leveraging the prior knowledge and image quality scores. Afterwards, we design an end-to-end two-stage CNN architecture for lane detection, where binary lane mask is utilized for lane matching. Comprehensive experiments have demonstrated that our proposed method can cope with variable number of lanes effectively.
               ",autonomous vehicle
10.1016/j.ress.2019.106555,filtered,Reliability Engineering and System Safety,scopus,2019-11-01,scopus,A cognitive architecture safety design for safety critical systems,https://api.elsevier.com/content/abstract/scopus_id/85068360978,"
                  This research is presented as a safety analysis of a cognitive architecture with an intelligent decision support model (IDSM) that is embedded into an autonomous non-deterministic safety-critical system.
                  Cognitive technology is currently simulated within safety-critical systems in order to highlight variables of interest, interface with intelligent technologies, and provide an environment that improves the system's cognitive performance. In this research, the safety of the architecture was analyzed on an actual safety-critical system, an unmanned surface vehicle (USV). The safety analysis was conducted in both a simulated and a real world nautical based environment. The objective was to define the safety design of a cognitive architecture. The input to the safety design was provided through an approach that identified and mitigated hazards associated with a USV controlled by a cognitive architecture. This analysis provided a structured, task-oriented approach for the dissemination of information concerning safety requirements. This approach was necessary to achieve a safe execution of the USV's capabilities through a design that reduces the potential for injury to personnel and damage to equipment.
                  Other real time applications that would benefit from advancing the safety of cognitive technologies are unmanned platforms, transportation technologies, and service robotics. The results will provide cognitive science researchers with a reference for safety engineering of artificially intelligent safety-critical systems.
               ",autonomous vehicle
10.1109/AICAS51828.2021.9458488,filtered,2021 IEEE 3rd International Conference on Artificial Intelligence Circuits and Systems (AICAS),IEEE,2021-06-09 00:00:00,ieeexplore,Evaluation of Machine Learning-based Detection against Side-Channel Attacks on Autonomous Vehicle,https://ieeexplore.ieee.org/document/9458488/,"Autonomous vehicles are becoming increasingly popular, but their reliance on computer systems to sense and operate in the physical world has introduced new security risks. Recent studies have shown that using Cache-based Side-Channel Attacks (SCAs) could infer sensitive users' information (e.g., which route the user is taking) highlighting significant vulnerability posed to today's computer systems. As a result, it is crucial to propose effective detection mechanisms against emerging microarchitectural SCAs on autonomous driving systems. In response, we first identify the threat model and victim applications of autonomous driving systems in this work. Next, we explore the suitability of various machine learning-based classifiers trained by information collected from built-in hardware performance counter registers available in modern autonomous vehicle systems. To this end, various supervised machine learning models are implemented for cache-based SCAs detection and precisely compared and characterized in terms of detection accuracy, robustness, and latency of the detection. Our experiments conducted on an Intel Xeon, which Waymo autonomous driving vendor uses, demonstrate that J48 achieves 99.5% accuracy with the highest efficiency compared with other investigated models.",autonomous vehicle
10.1109/UEMCON.2018.8796670,filtered,"2018 9th IEEE Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)",IEEE,2018-11-10 00:00:00,ieeexplore,"Building Towards ""Invisible Cloak"": Robust Physical Adversarial Attack on YOLO Object Detector",https://ieeexplore.ieee.org/document/8796670/,"Deep learning based object detection algorithms like R-CNN, SSD, YOLO have been applied to many scenarios, including video surveillance, autonomous vehicle, intelligent robotics et al. With more and more application and autonomy left to deep learning based artificial intelligence, humans want to ensure that the machine does the best for them under their control. However, deep learning algorithms are known to be vulnerable to carefully crafted input known as adversarial examples which makes it possible for an attacker to fool an AI system. In this work, we explored the mechanism behind the YOLO object detector and proposed an optimization method to craft adversarial examples to attack the YOLO model. The experiment shows that this white box attack method is effective and has a success rate of 100% in crafting digital adversarial examples to fool the YOLO model. We also proposed a robust physical adversarial sticker generation method based on an extended Expectation Over Transformation (EOT) method(a method to craft adversarial example in the physical world). We conduct experiments to find the most effective approach to generate adversarial stickers. We tested the stickers both digitally as a watermark and physically showing it on an electronic screen on the front surface of a person. Our result shows that the sticker attack as a watermark has a success rate of 90% and 45% on photos taken indoors and on random 318 pictures from ImageNet. Our physical attack also has a success rate of 72% on photos taken indoors. We shared our project source code on the Github and our work is reproducible.",autonomous vehicle
10.1109/LRA.2020.2966414,filtered,IEEE Robotics and Automation Letters,IEEE,2020-04-01 00:00:00,ieeexplore,Learning Robust Control Policies for End-to-End Autonomous Driving From Data-Driven Simulation,https://ieeexplore.ieee.org/document/8957584/,"In this work, we present a data-driven simulation and training engine capable of learning end-to-end autonomous vehicle control policies using only sparse rewards. By leveraging real, human-collected trajectories through an environment, we render novel training data that allows virtual agents to drive along a continuum of new local trajectories consistent with the road appearance and semantics, each with a different view of the scene. We demonstrate the ability of policies learned within our simulator to generalize to and navigate in previously unseen real-world roads, without access to any human control labels during training. Our results validate the learned policy onboard a full-scale autonomous vehicle, including in previously un-encountered scenarios, such as new roads and novel, complex, near-crash situations. Our methods are scalable, leverage reinforcement learning, and apply broadly to situations requiring effective perception and robust operation in the physical world.",autonomous vehicle
10.1109/CRV.2018.00028,filtered,2018 15th Conference on Computer and Robot Vision (CRV),IEEE,2018-05-10 00:00:00,ieeexplore,Systematic Street View Sampling: High Quality Annotation of Power Infrastructure in Rural Ontario,https://ieeexplore.ieee.org/document/8575746/,"Google Street View and the emergence of self-driving vehicles afford an unprecedented capacity to observe our planet. Fused with dramatic advances in artificial intelligence, the capability to extract patterns and meaning from those data streams heralds an era of insights into the physical world. In order to draw appropriate inferences about and between environments, the systematic selection of these data is necessary to create representative and unbiased samples. To this end, we introduce the Systematic Street View Sampler (S<sup>3</sup>) framework, enabling researchers to produce their own user-defined datasets of Street View imagery. We describe the algorithm and express its asymptotic complexity in relation to a new limiting computational resource (Google API Call Count). Using the Amazon Mechanical Turk distributed annotation environment, we demonstrate the utility of S3 in generating high quality representative datasets useful for machine vision applications. The S3 algorithm is open-source and available at github.com/CU-BIC/S3 along with the high quality dataset representing power infrastructure in rural regions of southern Ontario, Canada.",autonomous vehicle
10.23919/CSMS.2021.0004,filtered,Complex System Modeling and Simulation,TUP,2021-03-01 00:00:00,ieeexplore,3D Environmental Perception Modeling in the Simulated Autonomous-Driving Systems,https://ieeexplore.ieee.org/document/9426465/,"Self-driving vehicles require a number of tests to prevent fatal accidents and ensure their appropriate operation in the physical world. However, conducting vehicle tests on the road is difficult because such tests are expensive and labor intensive. In this study, we used an autonomous-driving simulator, and investigated the three-dimensional environmental perception problem of the simulated system. Using the open-source CARLA simulator, we generated a CarlaSim from unreal traffic scenarios, comprising 15000 camera-LiDAR (Light Detection and Ranging) samples with annotations and calibration files. Then, we developed Multi-Sensor Fusion Perception (MSFP) model for consuming two-modal data and detecting objects in the scenes. Furthermore, we conducted experiments on the KITTI and CarlaSim datasets; the results demonstrated the effectiveness of our proposed methods in terms of perception accuracy, inference efficiency, and generalization performance. The results of this study will faciliate the future development of autonomous-driving simulated tests.",autonomous vehicle
10.1145/3125503.3125568,filtered,2017 International Conference on Embedded Software (EMSOFT),IEEE,2017-10-20 00:00:00,ieeexplore,Work-in-progress: testing autonomous cyber-physical systems using fuzzing features from convolutional neural networks,https://ieeexplore.ieee.org/document/8094374/,Autonomous cyber-physical systems rely on modern machine learning methods such as deep neural networks to control their interactions with the physical world. Testing of such intelligent cyberphysical systems is a challenge due to the huge state space associated with high-resolution visual sensory inputs. We demonstrate how fuzzing the input using patterns obtained from the convolutional filters of an unrelated convolutional neural network can be used to test computer vision algorithms implemented in intelligent cyber-physical systems. Our method discovers interesting counterexamples to a pedestrian detection algorithm implemented in the popular OpenCV library. Our approach also unearths counterexamples to the correct behavior of an autonomous car similar to NVIDIA's end-to-end self-driving deep neural net running on the Udacity open-source simulator.,autonomous vehicle
10.1109/ICComm.2018.8484837,filtered,2018 International Conference on Communications (COMM),IEEE,2018-06-16 00:00:00,ieeexplore,Modelling Smart Mobile Robotic Networks from a Cyber Physical System Perspective,https://ieeexplore.ieee.org/document/8484837/,"Mobile robotic network (MRN) consists of a group of robotic nodes (such as mobile sensors, unmanned vehicles, UAVs and mobile robots) that can communicate with each other for collaboration, in which motion control and communication will both play crucial roles. With recent advances in artificial intelligence, robotic nodes are becoming smart with more powerful computational capability. Therefore, there appears a strong trend to integrally design MRNs from these three aspects: motion control, communication and computation. Cyber physical system that bridges the cyber world of communication and computation with the physical world of motion control provides us a new perspective to MRNs. In this research, we analyze the tight integration and coupling of these cyber physical aspects in MRNs, and provide a framework to specify the effect of each aspect and the transitions among them in terms of their contributions to the network performance. We use illustrative examples of flock motion, topology motion and ad hoc networking in MRNs to demonstrate the framework.",autonomous vehicle
10.1109/GLOBECOM38437.2019.9014216,filtered,2019 IEEE Global Communications Conference (GLOBECOM),IEEE,2019-12-13 00:00:00,ieeexplore,Machine Learning Aided Trajectory Design and Power Control of Multi-UAV,https://ieeexplore.ieee.org/document/9014216/,"A novel framework is proposed for the trajectory design of multiple unmanned aerial vehicles (UAVs) based on the prediction of users' mobility information. The problem of joint trajectory design and power control is formulated for maximizing the instantaneous sum transmit rate while satisfying the rate requirement of users. In an effort to solve this pertinent problem, a three-step approach is proposed which is based on machine learning techniques. Firstly, a multi-agent Q-learning based placement algorithm is proposed for determining the optimal positions of the UAVs based on the initial location of the users. Secondly, in an effort to determine the mobility information of users based on a real dateset, their position data is collected from Twitter to describe the anonymous user- trajectories in the physical world. In the meantime, an echo state network (ESN) based prediction algorithm is proposed for predicting the future positions of users based on the real dataset. Thirdly, a proposed multi-agent Q-learning based algorithm is invoked for predicting the position of UAVs in each time slot based on the movement of users. The algorithm is proved to be able to converge to an optimal state equation. Numerical results are provided to demonstrate that as the size of the reservoir pool increases, the proposed ESN approach improves the prediction accuracy. Finally, we demonstrate that throughput gains of about 17% are achieved.",autonomous vehicle
10.1109/ICPADS47876.2019.00097,filtered,2019 IEEE 25th International Conference on Parallel and Distributed Systems (ICPADS),IEEE,2019-12-06 00:00:00,ieeexplore,SEAD: Towards A Social-Media-Driven Energy-Aware Drone Sensing Framework,https://ieeexplore.ieee.org/document/8975715/,"Autonomous unmanned aerial vehicles (UAVs) have become an important tool for efficient disaster response. Despite the virtues of UAVs in disaster response applications, various limitations (e.g., requiring manual input, finite battery life) hinder their mass adoption. In contrast, social sensing is emerging as a new sensing paradigm that utilizes signals provided by ""human sensors"" to gather awareness of the events occurring in the physical world. Despite being inherently broader in scope, a shortcoming of social sensing is the reliability of the sensing data that are contributed by humans. In this paper, we introduce the concept of jointly exploiting the reliability of drones and the scope of social sensing to efficiently uncover the truthful events during disasters. However, such a tight integration of social and physical sensing introduces several technical challenges. The first challenge is satisfying the conflicting objectives of event coverage of the application and energy conservation of drones. The second challenge is adapting to the dynamics of the physical world and social media. In this paper, we present a Social-media-driven Energy-Aware Drone (SEAD) sensing framework to address the above challenges. In particular, we develop a reinforcement learning-based drone dispatching scheme that adapts to the physical and social environments and launches an appropriate proportion of drones for event exploration. We further utilize a bottom-up game-theoretic task allocation approach to guide drones effectively to the event locations. The evaluation with a real-world disaster case study show that SEAD noticeably outperforms state-of-the-art baselines in terms of detection effectiveness and energy efficiency.",autonomous vehicle
10.1109/INFOCOM41043.2020.9155522,filtered,IEEE INFOCOM 2020 - IEEE Conference on Computer Communications,IEEE,2020-07-09 00:00:00,ieeexplore,SocialDrone: An Integrated Social Media and Drone Sensing System for Reliable Disaster Response,https://ieeexplore.ieee.org/document/9155522/,"Social media sensing has emerged as a new disaster response application paradigm to collect real-time observations from online social media users about the disaster status. Due to the noisy nature of social media data, the task of identifying trustworthy information (referred to as ""truth discovery"") has been a crucial task in social media sensing. However, existing truth discovery solutions often fall short of providing accurate results in disaster response applications due to the spread of misinformation and difficulty of an efficient verification in such scenarios. In this paper, we present SocialDrone, a novel closed-loop social-physical active sensing framework that integrates social media and unmanned aerial vehicles (UAVs) for reliable disaster response applications. In SocialDrone, signals emitted from the social media are distilled to drive the drones to target areas to verify the emergency events. The verification results are then taken back to improve the sensing and distillation process on social media. The SocialDrone framework introduces several unique challenges: i) how to drive the drones using the unreliable social media signals? ii) How to ensure the system is adaptive to the high dynamics from both the physical world and social media? iii) How to incorporate real-world constraints (e.g., the deadlines of events, limited number of drones) into the framework? The SocialDrone addresses these challenges by building a novel integrated social-physical sensing system that leverages techniques from game theory, constrained optimization, and reinforcement learning. The evaluation results on a real-world disaster response application show that SocialDrone significantly outperforms state-of-the-art truth discovery schemes and drone-only solutions by providing more effective disaster response.",autonomous vehicle
10.1109/TVT.2019.2920284,filtered,IEEE Transactions on Vehicular Technology,IEEE,2019-08-01 00:00:00,ieeexplore,Trajectory Design and Power Control for Multi-UAV Assisted Wireless Networks: A Machine Learning Approach,https://ieeexplore.ieee.org/document/8727504/,"A novel framework is proposed for the trajectory design of multiple unmanned aerial vehicles (UAVs) based on the prediction of users' mobility information. The problem ofjoint trajectory design and power control is formulated for maximizing the instantaneous sum transmit rate while satisfying the rate requirement of users. In an effort to solve this pertinent problem, a threestep approach is proposed, which is based on machine learning techniques to obtain both the position information of users and the trajectory design of UAVs. First, a multi-agent Q-learning-based placement algorithm is proposed for determining the optimal positions of the UAVs based on the initial location of the users. Second, in an effort to determine the mobility information of users based on a real dataset, their position data is collected from Twitter to describe the anonymous user-trajectories in the physical world. In the meantime, an echo state network (ESN) based prediction algorithm is proposed for predicting the future positions of users based on the real dataset. Third, a multi-agent Q-learning-based algorithm is conceived for predicting the position of UAVs in each time slot based on the movement of users. In this algorithm, multiple UAVs act as agents to find optimal actions by interacting with their environment and learn from their mistakes. Additionally, we also prove that the proposed multi-agent Q-learning-based trajectory design and power control algorithm can converge under mild conditions. Numerical results are provided to demonstrate that as the size of the reservoir increases, the proposed ESN approach improves the prediction accuracy. Finally, we demonstrate that the throughput gains of about 17% are achieved.",autonomous vehicle
10.1007/978-3-030-60467-7_7,filtered,Innovation and Research,Springer,2021-01-01 00:00:00,springer,Intelligent and Autonomous Guidance Through a Geometric Model for Conventional Vehicles,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60467-7_7,"Cyber-physical systems (CPS) in the automobile industry are facing major challenges related to the use and validation of these CPS, which entails high costs in the implementation and training tests in the physical world, thus limiting research. Therefore, there is a need to shorten the validation times of these CPS with the use of 3D simulation software. This research article proposes to simulate a CPS in the simulation software Webots, with the aim of emulating the autonomous movement of conventional vehicles by integrating a GPS sensor and a compass sensor which provide information on location and orientation, these data are used for the implementation of a geometric model by vectors, the same one that is developed in a controller that allows to take actions on the vehicles in the simulation software in order to emulate an urban traffic. Finally, a series of configurations have been made to evaluate the geometric model, managing to maintain the default speed of 94.194% with curves greater than 90 degrees. In addition, the validation of this system in a real environment through the instrumentation in land vehicles is drawn as future lines.",autonomous vehicle
http://arxiv.org/abs/1812.07665v2,filtered,arxiv,arxiv,2018-12-18 22:10:42+00:00,arxiv,"Trajectory Design and Power Control for Multi-UAV Assisted Wireless
  Networks: A Machine Learning Approach",http://arxiv.org/abs/1812.07665v2,"A novel framework is proposed for the trajectory design of multiple unmanned
aerial vehicles (UAVs) based on the prediction of users' mobility information.
The problem of joint trajectory design and power control is formulated for
maximizing the instantaneous sum transmit rate while satisfying the rate
requirement of users. In an effort to solve this pertinent problem, a
three-step approach is proposed which is based on machine learning techniques
to obtain both the position information of users and the trajectory design of
UAVs. Firstly, a multi-agent Q-learning based placement algorithm is proposed
for determining the optimal positions of the UAVs based on the initial location
of the users. Secondly, in an effort to determine the mobility information of
users based on a real dataset, their position data is collected from Twitter to
describe the anonymous user-trajectories in the physical world. In the
meantime, an echo state network (ESN) based prediction algorithm is proposed
for predicting the future positions of users based on the real dataset.
Thirdly, a multi-agent Q-learning based algorithm is conceived for predicting
the position of UAVs in each time slot based on the movement of users. In this
algorithm, multiple UAVs act as agents to find optimal actions by interacting
with their environment and learn from their mistakes. Additionally, we also
prove that the proposed multi-agent Q-learning based trajectory design and
power control algorithm can converge under mild conditions. Numerical results
are provided to demonstrate that as the size of the reservoir increases, the
proposed ESN approach improves the prediction accuracy. Finally, we demonstrate
that throughput gains of about 17% are achieved.",autonomous vehicle
http://arxiv.org/abs/1909.05314v1,filtered,arxiv,arxiv,2019-09-11 19:10:07+00:00,arxiv,"ScieNet: Deep Learning with Spike-assisted Contextual Information
  Extraction",http://arxiv.org/abs/1909.05314v1,"Deep neural networks (DNNs) provide high image classification accuracy, but
experience significant performance degradation when perturbation from various
sources are present in the input. The lack of resilience to input perturbations
makes DNN less reliable for systems interacting with physical world such as
autonomous vehicles, robotics, to name a few, where imperfect input is the
normal condition. We present a hybrid deep network architecture with
spike-assisted contextual information extraction (ScieNet). ScieNet integrates
unsupervised learning using spiking neural network (SNN) for unsupervised
contextual informationextraction with a back-end DNN trained for
classification. The integrated network demonstrates high resilience to input
perturbations without relying on prior training on perturbed inputs. We
demonstrate ScieNet with different back-end DNNs for image classification using
CIFAR dataset considering stochastic (noise) and structured (rain) input
perturbations. Experimental results demonstrate significant improvement in
accuracy on noisy and rainy images without prior training, while maintaining
state-of-the-art accuracy on clean images.",autonomous vehicle
http://arxiv.org/abs/1804.05810v3,filtered,arxiv,arxiv,2018-04-16 17:29:43+00:00,arxiv,"ShapeShifter: Robust Physical Adversarial Attack on Faster R-CNN Object
  Detector",http://arxiv.org/abs/1804.05810v3,"Given the ability to directly manipulate image pixels in the digital input
space, an adversary can easily generate imperceptible perturbations to fool a
Deep Neural Network (DNN) image classifier, as demonstrated in prior work. In
this work, we propose ShapeShifter, an attack that tackles the more challenging
problem of crafting physical adversarial perturbations to fool image-based
object detectors like Faster R-CNN. Attacking an object detector is more
difficult than attacking an image classifier, as it needs to mislead the
classification results in multiple bounding boxes with different scales.
Extending the digital attack to the physical world adds another layer of
difficulty, because it requires the perturbation to be robust enough to survive
real-world distortions due to different viewing distances and angles, lighting
conditions, and camera limitations. We show that the Expectation over
Transformation technique, which was originally proposed to enhance the
robustness of adversarial perturbations in image classification, can be
successfully adapted to the object detection setting. ShapeShifter can generate
adversarially perturbed stop signs that are consistently mis-detected by Faster
R-CNN as other objects, posing a potential threat to autonomous vehicles and
other safety-critical computer vision systems.",autonomous vehicle
http://arxiv.org/abs/1812.10812v1,filtered,arxiv,arxiv,2018-12-27 19:55:54+00:00,arxiv,"DeepBillboard: Systematic Physical-World Testing of Autonomous Driving
  Systems",http://arxiv.org/abs/1812.10812v1,"Deep Neural Networks (DNNs) have been widely applied in many autonomous
systems such as autonomous driving. Recently, DNN testing has been intensively
studied to automatically generate adversarial examples, which inject
small-magnitude perturbations into inputs to test DNNs under extreme
situations. While existing testing techniques prove to be effective, they
mostly focus on generating digital adversarial perturbations (particularly for
autonomous driving), e.g., changing image pixels, which may never happen in
physical world. There is a critical missing piece in the literature on
autonomous driving testing: understanding and exploiting both digital and
physical adversarial perturbation generation for impacting steering decisions.
In this paper, we present DeepBillboard, a systematic physical-world testing
approach targeting at a common and practical driving scenario: drive-by
billboards. DeepBillboard is capable of generating a robust and resilient
printable adversarial billboard, which works under dynamic changing driving
conditions including viewing angle, distance, and lighting. The objective is to
maximize the possibility, degree, and duration of the steering-angle errors of
an autonomous vehicle driving by the generated adversarial billboard. We have
extensively evaluated the efficacy and robustness of DeepBillboard through
conducting both digital and physical-world experiments. Results show that
DeepBillboard is effective for various steering models and scenes. Furthermore,
DeepBillboard is sufficiently robust and resilient for generating
physical-world adversarial billboard tests for real-world driving under various
weather conditions. To the best of our knowledge, this is the first study
demonstrating the possibility of generating realistic and continuous
physical-world tests for practical autonomous driving systems.",autonomous vehicle
http://arxiv.org/abs/1909.01867v1,filtered,arxiv,arxiv,2019-09-01 11:50:17+00:00,arxiv,"3D Bounding Box Estimation for Autonomous Vehicles by Cascaded Geometric
  Constraints and Depurated 2D Detections Using 3D Results",http://arxiv.org/abs/1909.01867v1,"3D object detection is one of the most important tasks in 3D vision
perceptual system of autonomous vehicles. In this paper, we propose a novel two
stage 3D object detection method aimed at get the optimal solution of object
location in 3D space based on regressing two additional 3D object properties by
a deep convolutional neural network and combined with cascaded geometric
constraints between the 2D and 3D boxes. First, we modify the existing 3D
properties regressing network by adding two additional components, viewpoints
classification and the center projection of the 3D bounding box s bottom face.
Second, we use the predicted center projection combined with similar triangle
constraint to acquire an initial 3D bounding box by a closed-form solution.
Then, the location predicted by previous step is used as the initial value of
the over-determined equations constructed by 2D and 3D boxes fitting constraint
with the configuration determined with the classified viewpoint. Finally, we
use the recovered physical world information by the 3D detections to filter out
the false detection and false alarm in 2D detections. We compare our method
with the state-of-the-arts on the KITTI dataset show that although conceptually
simple, our method outperforms more complex and computational expensive methods
not only by improving the overall precision of 3D detections, but also
increasing the orientation estimation precision. Furthermore our method can
deal with the truncated objects to some extent and remove the false alarm and
false detections in both 2D and 3D detections.",autonomous vehicle
10.1016/j.neunet.2021.05.006,filtered,Neural Networks,sciencedirect,2021-11-30,sciencedirect,Learning to recognize while learning to speak: Self-supervision and developing a speaking motor,https://api.elsevier.com/content/article/pii/S0893608021001982,"
                  Traditionally, learning speech synthesis and speech recognition were investigated as two separate tasks. This separation hinders incremental development for concurrent synthesis and recognition, where partially-learned synthesis and partially-learned recognition must help each other throughout lifelong learning. This work is a paradigm shift—we treat synthesis and recognition as two intertwined aspects of a lifelong learning agent. Furthermore, in contrast to existing recognition or synthesis systems, babies do not need their mothers to directly supervise their vocal tracts at every moment during the learning. We argue that self-generated non-symbolic states/actions at fine-grained time level help such a learner as necessary temporal contexts. Here, we approach a new and challenging problem—how to enable an autonomous learning system to develop an artificial speaking motor for generating temporally-dense (e.g., frame-wise) actions on the fly without human handcrafting a set of symbolic states. The self-generated states/actions are Muscles-like, High-dimensional, Temporally-dense and Globally-smooth (MHTG), so that these states/actions are directly attended for concurrent synthesis and recognition for each time frame. Human teachers are relieved from supervising learner’s motor ends. The Candid Covariance-free Incremental (CCI) Principal Component Analysis (PCA) is applied to develop such an artificial speaking motor where PCA features drive the motor. Since each life must develop normally, each Developmental Network-2 (DN-2) reaches the same network (maximum likelihood, ML) regardless of randomly initialized weights, where ML is not just for a function approximator but rather an emergent Turing Machine. The machine-synthesized sounds are evaluated by both the neural network and humans with recognition experiments. Our experimental results showed learning-to-synthesize and learning-to-recognize-through-synthesis for phonemes. This work corresponds to a key step toward our goal to close a great gap toward fully autonomous machine learning directly from the physical world.
               ",autonomous vehicle
10.1016/j.physrep.2019.03.001,filtered,Physics Reports,sciencedirect,2019-05-30,sciencedirect,"A high-bias, low-variance introduction to Machine Learning for physicists",https://api.elsevier.com/content/article/pii/S0370157319300766,"Machine Learning (ML) is one of the most exciting and dynamic areas of modern research and application. The purpose of this review is to provide an introduction to the core concepts and tools of machine learning in a manner easily understood and intuitive to physicists. The review begins by covering fundamental concepts in ML and modern statistics such as the bias–variance tradeoff, overfitting, regularization, generalization, and gradient descent before moving on to more advanced topics in both supervised and unsupervised learning. Topics covered in the review include ensemble models, deep learning and neural networks, clustering and data visualization, energy-based models (including MaxEnt models and Restricted Boltzmann Machines), and variational methods. Throughout, we emphasize the many natural connections between ML and statistical physics. A notable aspect of the review is the use of Python Jupyter notebooks to introduce modern ML/statistical packages to readers using physics-inspired datasets (the Ising Model and Monte-Carlo simulations of supersymmetric decays of proton–proton collisions). We conclude with an extended outlook discussing possible uses of machine learning for furthering our understanding of the physical world as well as open problems in ML where physicists may be able to contribute.",autonomous vehicle
10.1016/j.aei.2020.101209,filtered,Advanced Engineering Informatics,sciencedirect,2021-01-31,sciencedirect,Evolutionary digital twin: A new approach for intelligent industrial product development,https://api.elsevier.com/content/article/pii/S1474034620301786,"
                  To fulfill increasingly difficult and demanding tasks in the ever-changing complex world, intelligent industrial products are to be developed with higher flexibility and adaptability. Digital twin (DT) brings about a possible means, due to its ability to provide candidate behavior adjustments based on received “feedbacks” from its physical part. However, such candidate adjustments are deterministic, and thus lack of flexibility and adaptability. To address such problem, in this paper an extended concept – evolutionary digital twin (EDT) and an EDT-based new mode for intelligent industrial product development has been proposed. With our proposed EDT, a more precise approximated model of the physical world could be established through supervised learning, based on which the collaborative exploration for optimal policies via parallel simulation in multiple cyberspaces could be performed through reinforcement learning. Hence, more flexibility and adaptability could be brought to industrial products through machine learning (such as supervised learning and reinforcement learning) based self-evolution. As a primary verification of the effectiveness of our proposed approach, a case study has been carried out. The experimental results have well confirmed the effectiveness of our EDT based development mode.
               ",autonomous vehicle
10.1016/j.dcan.2017.10.002,filtered,Digital Communications and Networks,sciencedirect,2018-08-31,sciencedirect,Machine learning for internet of things data analysis: a survey,https://api.elsevier.com/content/article/pii/S235286481730247X,"Rapid developments in hardware, software, and communication technologies have facilitated the emergence of Internet-connected sensory devices that provide observations and data measurements from the physical world. By 2020, it is estimated that the total number of Internet-connected devices being used will be between 25 and 50 billion. As these numbers grow and technologies become more mature, the volume of data being published will increase. The technology of Internet-connected devices, referred to as Internet of Things (IoT), continues to extend the current Internet by providing connectivity and interactions between the physical and cyber worlds. In addition to an increased volume, the IoT generates big data characterized by its velocity in terms of time and location dependency, with a variety of multiple modalities and varying data quality. Intelligent processing and analysis of this big data are the key to developing smart IoT applications. This article assesses the various machine learning methods that deal with the challenges presented by IoT data by considering smart cities as the main use case. The key contribution of this study is the presentation of a taxonomy of machine learning algorithms explaining how different techniques are applied to the data in order to extract higher level information. The potential and challenges of machine learning for IoT data analytics will also be discussed. A use case of applying a Support Vector Machine (SVM) to Aarhus smart city traffic data is presented for a more detailed exploration.",autonomous vehicle
10.3182/20080706-5-KR-1001.02614,filtered,IFAC Proceedings Volumes,sciencedirect,2008-12-31,sciencedirect,Learning and Adaptation of Skills in Autonomous Physical Agents,https://api.elsevier.com/content/article/pii/S1474667016414795,"
                  A skills learning methodology is presented for autonomous physical agents. Adaptation of skills and learning is a fundamental part of the simple agent behaviours outlined. A general framework of skills learning is described that uses skill macros to define simple behaviours by agents that communicate, sense and act in the physical world. Programmed playfulness can be easily implemented in this framework that plays an important part in acquiring sophisticated skills. Reusability of results in learning algorithms is supported by ontology based classification of learning in skills. Ontologies provide references to object instances that enable modularization of software and easy interfacing of skills with learning algorithms.
               ",autonomous vehicle
10.1016/B978-0-08-097086-8.43068-0,filtered,International Encyclopedia of the Social & Behavioral Sciences,sciencedirect,2015-12-31,sciencedirect,Motor Control Models: Learning and Performance,https://api.elsevier.com/content/article/pii/B9780080970868430680,"
               The focus of the article is on the variety of attempts that have been investigated for capturing the complexity of purposive action and adaptive behavior, having defined a coordinated action as a class of movements plus a goal. Redundancy is a side effect of this connection, and thus redundancy is necessarily task oriented, something to be managed ‘online’ and rapidly updated as the action unfolds. The article then analyzes two main computational mechanisms that have been proposed as candidates of how the brain may deal with motor redundancy: (1) the force-field-based solution known as Equilibrium-Point Hypothesis (EPH) and (2) the cost-function-based solution to the degrees of freedom problem, namely Optimal Control Theory. However, both theories apply only to overt actions where force fields and cost functions are directly related to the interaction of the body with the physical world in the course of a real action. Considering that overt actions are just the tip of the iceberg, hiding the vast domain of covert actions that are the skeleton of motor cognition, an extension of EPH is described, Passive Motion Paradigm (PMP). The relationships between PMP, the simulation theory of covert actions, internal models, and the body schema concept are also analyzed. Finally, general learning mechanisms that may support the acquisition of internal computational modules are briefly summarized.
            ",autonomous vehicle
10.1016/j.artmed.2008.07.002,filtered,Artificial Intelligence in Medicine,sciencedirect,2008-10-31,sciencedirect,Artificial consciousness: A discipline between technological and theoretical obstacles,https://api.elsevier.com/content/article/pii/S0933365708000912,"
                  Artificial consciousness is still far from being an established discipline. We will try to outline some theoretical assumption that could help in dealing with phenomenal consciousness. What are the technological and theoretical obstacles that face the enthusiast scholars of artificial consciousness? After presenting an outline of the state of artificial consciousness, we will focus on the relevance of phenomenal consciousness. Artificial consciousness needs to tackle the issue of phenomenal consciousness in a physical world. Up to now, the only models that give some hope of succeeding are the various kinds of externalism.
               ",autonomous vehicle
