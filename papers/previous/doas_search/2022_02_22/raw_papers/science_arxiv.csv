id,updated,published,title,summary,database
http://arxiv.org/abs/2202.10335v1,2022-02-21T16:15:57Z,2022-02-21T16:15:57Z,Explainability in Machine Learning: a Pedagogical Perspective,"Given the importance of integrating of explainability into machine learning,
at present, there are a lack of pedagogical resources exploring this.
Specifically, we have found a need for resources in explaining how one can
teach the advantages of explainability in machine learning. Often pedagogical
approaches in the field of machine learning focus on getting students prepared
to apply various models in the real world setting, but much less attention is
given to teaching students the various techniques one could employ to explain a
model's decision-making process. Furthermore, explainability can benefit from a
narrative structure that aids one in understanding which techniques are
governed by which questions about the data.
  We provide a pedagogical perspective on how to structure the learning process
to better impart knowledge to students and researchers in machine learning,
when and how to implement various explainability techniques as well as how to
interpret the results. We discuss a system of teaching explainability in
machine learning, by exploring the advantages and disadvantages of various
opaque and transparent machine learning models, as well as when to utilize
specific explainability techniques and the various frameworks used to structure
the tools for explainability. Among discussing concrete assignments, we will
also discuss ways to structure potential assignments to best help students
learn to use explainability as a tool alongside any given machine learning
application.
  Data science professionals completing the course will have a birds-eye view
of a rapidly developing area and will be confident to deploy machine learning
more widely. A preliminary analysis on the effectiveness of a recently
delivered course following the structure presented here is included as evidence
supporting our pedagogical approach.",arxiv
http://arxiv.org/abs/2202.10144v1,2022-02-21T11:39:24Z,2022-02-21T11:39:24Z,"Inferring Network Structure with Unobservable Nodes from Time Series
  Data","Network structures play important roles in social, technological and
biological systems. However, the observable nodes and connections in real cases
are often incomplete or unavailable due to measurement errors, private
protection issues, or other problems. Therefore, inferring the complete network
structure is useful for understanding human interactions and complex dynamics.
The existing studies have not fully solved the problem of inferring network
structure with partial information about connections or nodes. In this paper,
we tackle the problem by utilizing time-series data generated by network
dynamics. We regard the network inference problem based on dynamical time
series data as a problem of minimizing errors for predicting states of
observable nodes and proposed a novel data-driven deep learning model called
Gumbel-softmax Inference for Network (GIN) to solve the problem under
incomplete information. The GIN framework includes three modules: a dynamics
learner, a network generator, and an initial state generator to infer the
unobservable parts of the network. We implement experiments on artificial and
empirical social networks with discrete and continuous dynamics. The
experiments show that our method can infer the unknown parts of the structure
and the initial states of the observable nodes with up to 90\% accuracy. The
accuracy declines linearly with the increase of the fractions of unobservable
nodes. Our framework may have wide applications where the network structure is
hard to obtain and the time series data is rich.",arxiv
http://arxiv.org/abs/2202.08450v1,2022-02-17T05:33:27Z,2022-02-17T05:33:27Z,"Design-Bench: Benchmarks for Data-Driven Offline Model-Based
  Optimization","Black-box model-based optimization (MBO) problems, where the goal is to find
a design input that maximizes an unknown objective function, are ubiquitous in
a wide range of domains, such as the design of proteins, DNA sequences,
aircraft, and robots. Solving model-based optimization problems typically
requires actively querying the unknown objective function on design proposals,
which means physically building the candidate molecule, aircraft, or robot,
testing it, and storing the result. This process can be expensive and time
consuming, and one might instead prefer to optimize for the best design using
only the data one already has. This setting -- called offline MBO -- poses
substantial and different algorithmic challenges than more commonly studied
online techniques. A number of recent works have demonstrated success with
offline MBO for high-dimensional optimization problems using high-capacity deep
neural networks. However, the lack of standardized benchmarks in this emerging
field is making progress difficult to track. To address this, we present
Design-Bench, a benchmark for offline MBO with a unified evaluation protocol
and reference implementations of recent methods. Our benchmark includes a suite
of diverse and realistic tasks derived from real-world optimization problems in
biology, materials science, and robotics that present distinct challenges for
offline MBO. Our benchmark and reference implementations are released at
github.com/rail-berkeley/design-bench and
github.com/rail-berkeley/design-baselines.",arxiv
http://arxiv.org/abs/2202.07785v1,2022-02-15T23:21:23Z,2022-02-15T23:21:23Z,Predictability and Surprise in Large Generative Models,"Large-scale pre-training has recently emerged as a technique for creating
capable, general purpose, generative models such as GPT-3, Megatron-Turing NLG,
Gopher, and many others. In this paper, we highlight a counterintuitive
property of such models and discuss the policy implications of this property.
Namely, these generative models have an unusual combination of predictable loss
on a broad training distribution (as embodied in their ""scaling laws""), and
unpredictable specific capabilities, inputs, and outputs. We believe that the
high-level predictability and appearance of useful capabilities drives rapid
development of such models, while the unpredictable qualities make it difficult
to anticipate the consequences of model deployment. We go through examples of
how this combination can lead to socially harmful behavior with examples from
the literature and real world observations, and we also perform two novel
experiments to illustrate our point about harms from unpredictability.
Furthermore, we analyze how these conflicting properties combine to give model
developers various motivations for deploying these models, and challenges that
can hinder deployment. We conclude with a list of possible interventions the AI
community may take to increase the chance of these models having a beneficial
impact. We intend this paper to be useful to policymakers who want to
understand and regulate AI systems, technologists who care about the potential
policy impact of their work, and academics who want to analyze, critique, and
potentially develop large generative models.",arxiv
http://arxiv.org/abs/2202.10336v1,2022-02-15T03:34:56Z,2022-02-15T03:34:56Z,Artificial Intelligence for the Metaverse: A Survey,"Along with the massive growth of the Internet from the 1990s until now,
various innovative technologies have been created to bring users breathtaking
experiences with more virtual interactions in cyberspace. Many virtual
environments with thousands of services and applications, from social networks
to virtual gaming worlds, have been developed with immersive experience and
digital transformation, but most are incoherent instead of being integrated
into a platform. In this context, metaverse, a term formed by combining meta
and universe, has been introduced as a shared virtual world that is fueled by
many emerging technologies, such as fifth-generation networks and beyond,
virtual reality, and artificial intelligence (AI). Among such technologies, AI
has shown the great importance of processing big data to enhance immersive
experience and enable human-like intelligence of virtual agents. In this
survey, we make a beneficial effort to explore the role of AI in the foundation
and development of the metaverse. We first deliver a preliminary of AI,
including machine learning algorithms and deep learning architectures, and its
role in the metaverse. We then convey a comprehensive investigation of AI-based
methods concerning six technical aspects that have potentials for the
metaverse: natural language processing, machine vision, blockchain, networking,
digital twin, and neural interface, and being potential for the metaverse.
Subsequently, several AI-aided applications, such as healthcare, manufacturing,
smart cities, and gaming, are studied to be deployed in the virtual worlds.
Finally, we conclude the key contribution of this survey and open some future
research directions in AI for the metaverse.",arxiv
http://arxiv.org/abs/2202.07475v1,2022-02-14T14:24:57Z,2022-02-14T14:24:57Z,"A Real-time System for Detecting Landslide Reports on Social Media using
  Artificial Intelligence","This paper presents an online system that leverages social media data in real
time to identify landslide-related information automatically using
state-of-the-art artificial intelligence techniques. The designed system can
(i) reduce the information overload by eliminating duplicate and irrelevant
content, (ii) identify landslide images, (iii) infer geolocation of the images,
and (iv) categorize the user type (organization or person) of the account
sharing the information. The system was deployed in February 2020 online at
https://landslide-aidr.qcri.org/landslide_system.php to monitor live Twitter
data stream and has been running continuously since then to provide
time-critical information to partners such as British Geological Survey and
European Mediterranean Seismological Centre. We trust this system can both
contribute to harvesting of global landslide data for further research and
support global landslide maps to facilitate emergency response and decision
making.",arxiv
http://arxiv.org/abs/2202.06639v1,2022-02-14T11:47:26Z,2022-02-14T11:47:26Z,"On the Complexity of Object Detection on Real-world Public
  Transportation Images for Social Distancing Measurement","Social distancing in public spaces has become an essential aspect in helping
to reduce the impact of the COVID-19 pandemic. Exploiting recent advances in
machine learning, there have been many studies in the literature implementing
social distancing via object detection through the use of surveillance cameras
in public spaces. However, to date, there has been no study of social distance
measurement on public transport. The public transport setting has some unique
challenges, including some low-resolution images and camera locations that can
lead to the partial occlusion of passengers, which make it challenging to
perform accurate detection. Thus, in this paper, we investigate the challenges
of performing accurate social distance measurement on public transportation. We
benchmark several state-of-the-art object detection algorithms using real-world
footage taken from the London Underground and bus network. The work highlights
the complexity of performing social distancing measurement on images from
current public transportation onboard cameras. Further, exploiting domain
knowledge of expected passenger behaviour, we attempt to improve the quality of
the detections using various strategies and show improvement over using vanilla
object detection alone.",arxiv
http://arxiv.org/abs/2202.05334v1,2022-02-10T21:26:54Z,2022-02-10T21:26:54Z,"Learning the Pedestrian-Vehicle Interaction for Pedestrian Trajectory
  Prediction","In this paper, we study the interaction between pedestrians and vehicles and
propose a novel neural network structure called the Pedestrian-Vehicle
Interaction (PVI) extractor for learning the pedestrian-vehicle interaction. We
implement the proposed PVI extractor on both sequential approaches (long
short-term memory (LSTM) models) and non-sequential approaches (convolutional
models). We use the Waymo Open Dataset that contains real-world urban traffic
scenes with both pedestrian and vehicle annotations. For the LSTM-based models,
our proposed model is compared with Social-LSTM and Social-GAN, and using our
proposed PVI extractor reduces the average displacement error (ADE) and the
final displacement error (FDE) by 7.46% and 5.24%, respectively. For the
convolutional-based models, our proposed model is compared with Social-STGCNN
and Social-IWSTCNN, and using our proposed PVI extractor reduces the ADE and
FDE by 2.10% and 1.27%, respectively. The results show that the
pedestrian-vehicle interaction influences pedestrian behavior, and the models
using the proposed PVI extractor can capture the interaction between
pedestrians and vehicles, and thereby outperform the compared methods.",arxiv
http://arxiv.org/abs/2202.00617v1,2022-02-01T18:05:31Z,2022-02-01T18:05:31Z,"A General, Evolution-Inspired Reward Function for Social Robotics","The field of social robotics will likely need to depart from a paradigm of
designed behaviours and imitation learning and adopt modern reinforcement
learning (RL) methods to enable robots to interact fluidly and efficaciously
with humans. In this paper, we present the Social Reward Function as a
mechanism to provide (1) a real-time, dense reward function necessary for the
deployment of RL agents in social robotics, and (2) a standardised objective
metric for comparing the efficacy of different social robots. The Social Reward
Function is designed to closely mimic those genetically endowed social
perception capabilities of humans in an effort to provide a simple, stable and
culture-agnostic reward function. Presently, datasets used in social robotics
are either small or significantly out-of-domain with respect to social
robotics. The use of the Social Reward Function will allow larger in-domain
datasets to be collected close to the behaviour policy of social robots, which
will allow both further improvements to reward functions and to the behaviour
policies of social robots. We believe this will be the key enabler to
developing efficacious social robots in the future.",arxiv
http://arxiv.org/abs/2201.08475v1,2022-01-20T22:30:59Z,2022-01-20T22:30:59Z,GenGNN: A Generic FPGA Framework for Graph Neural Network Acceleration,"Graph neural networks (GNNs) have recently exploded in popularity thanks to
their broad applicability to ubiquitous graph-related problems such as quantum
chemistry, drug discovery, and high energy physics. However, meeting demand for
novel GNN models and fast inference simultaneously is challenging because of
the gap between the difficulty in developing efficient FPGA accelerators and
the rapid pace of creation of new GNN models. Prior art focuses on the
acceleration of specific classes of GNNs but lacks the generality to work
across existing models or to extend to new and emerging GNN models. In this
work, we propose a generic GNN acceleration framework using High-Level
Synthesis (HLS), named GenGNN, with two-fold goals. First, we aim to deliver
ultra-fast GNN inference without any graph pre-processing for real-time
requirements. Second, we aim to support a diverse set of GNN models with the
extensibility to flexibly adapt to new models. The framework features an
optimized message-passing structure applicable to all models, combined with a
rich library of model-specific components. We verify our implementation
on-board on the Xilinx Alveo U50 FPGA and observe a speed-up of up to 25x
against CPU (6226R) baseline and 13x against GPU (A6000) baseline. Our HLS code
will be open-source on GitHub upon acceptance.",arxiv
http://arxiv.org/abs/2201.06599v1,2022-01-17T19:25:33Z,2022-01-17T19:25:33Z,"Who supervises the supervisor? Model monitoring in production using deep
  feature embeddings with applications to workpiece inspection","The automation of condition monitoring and workpiece inspection plays an
essential role in maintaining high quality as well as high throughput of the
manufacturing process. To this end, the recent rise of developments in machine
learning has lead to vast improvements in the area of autonomous process
supervision. However, the more complex and powerful these models become, the
less transparent and explainable they generally are as well. One of the main
challenges is the monitoring of live deployments of these machine learning
systems and raising alerts when encountering events that might impact model
performance. In particular, supervised classifiers are typically build under
the assumption of stationarity in the underlying data distribution. For
example, a visual inspection system trained on a set of material surface
defects generally does not adapt or even recognize gradual changes in the data
distribution - an issue known as ""data drift"" - such as the emergence of new
types of surface defects. This, in turn, may lead to detrimental
mispredictions, e.g. samples from new defect classes being classified as
non-defective. To this end, it is desirable to provide real-time tracking of a
classifier's performance to inform about the putative onset of additional error
classes and the necessity for manual intervention with respect to classifier
re-training. Here, we propose an unsupervised framework that acts on top of a
supervised classification system, thereby harnessing its internal deep feature
representations as a proxy to track changes in the data distribution during
deployment and, hence, to anticipate classifier performance degradation.",arxiv
http://arxiv.org/abs/2201.06912v1,2022-01-14T17:41:26Z,2022-01-14T17:41:26Z,Digital Twin: From Concept to Practice,"Recent technological developments and advances in Artificial Intelligence
(AI) have enabled sophisticated capabilities to be a part of Digital Twin (DT),
virtually making it possible to introduce automation into all aspects of work
processes. Given these possibilities that DT can offer, practitioners are
facing increasingly difficult decisions regarding what capabilities to select
while deploying a DT in practice. The lack of research in this field has not
helped either. It has resulted in the rebranding and reuse of emerging
technological capabilities like prediction, simulation, AI, and Machine
Learning (ML) as necessary constituents of DT. Inappropriate selection of
capabilities in a DT can result in missed opportunities, strategic
misalignments, inflated expectations, and risk of it being rejected as just
hype by the practitioners. To alleviate this challenge, this paper proposes the
digitalization framework, designed and developed by following a Design Science
Research (DSR) methodology over a period of 18 months. The framework can help
practitioners select an appropriate level of sophistication in a DT by weighing
the pros and cons for each level, deciding evaluation criteria for the digital
twin system, and assessing the implications of the selected DT on the
organizational processes and strategies, and value creation. Three real-life
case studies illustrate the application and usefulness of the framework.",arxiv
http://arxiv.org/abs/2201.05115v1,2022-01-13T18:20:32Z,2022-01-13T18:20:32Z,Functional Anomaly Detection: a Benchmark Study,"The increasing automation in many areas of the Industry expressly demands to
design efficient machine-learning solutions for the detection of abnormal
events. With the ubiquitous deployment of sensors monitoring nearly
continuously the health of complex infrastructures, anomaly detection can now
rely on measurements sampled at a very high frequency, providing a very rich
representation of the phenomenon under surveillance. In order to exploit fully
the information thus collected, the observations cannot be treated as
multivariate data anymore and a functional analysis approach is required. It is
the purpose of this paper to investigate the performance of recent techniques
for anomaly detection in the functional setup on real datasets. After an
overview of the state-of-the-art and a visual-descriptive study, a variety of
anomaly detection methods are compared. While taxonomies of abnormalities (e.g.
shape, location) in the functional setup are documented in the literature,
assigning a specific type to the identified anomalies appears to be a
challenging task. Thus, strengths and weaknesses of the existing approaches are
benchmarked in view of these highlighted types in a simulation study. Anomaly
detection methods are next evaluated on two datasets, related to the monitoring
of helicopters in flight and to the spectrometry of construction materials
namely. The benchmark analysis is concluded by recommendation guidance for
practitioners.",arxiv
http://arxiv.org/abs/2201.04014v2,2022-01-13T10:00:35Z,2022-01-11T15:53:53Z,Captcha Attack: Turning Captchas Against Humanity,"Nowadays, people generate and share massive content on online platforms
(e.g., social networks, blogs). In 2021, the 1.9 billion daily active Facebook
users posted around 150 thousand photos every minute. Content moderators
constantly monitor these online platforms to prevent the spreading of
inappropriate content (e.g., hate speech, nudity images). Based on deep
learning (DL) advances, Automatic Content Moderators (ACM) help human
moderators handle high data volume. Despite their advantages, attackers can
exploit weaknesses of DL components (e.g., preprocessing, model) to affect
their performance. Therefore, an attacker can leverage such techniques to
spread inappropriate content by evading ACM.
  In this work, we propose CAPtcha Attack (CAPA), an adversarial technique that
allows users to spread inappropriate text online by evading ACM controls. CAPA,
by generating custom textual CAPTCHAs, exploits ACM's careless design
implementations and internal procedures vulnerabilities. We test our attack on
real-world ACM, and the results confirm the ferocity of our simple yet
effective attack, reaching up to a 100% evasion success in most cases. At the
same time, we demonstrate the difficulties in designing CAPA mitigations,
opening new challenges in CAPTCHAs research area.",arxiv
http://arxiv.org/abs/2201.03413v1,2022-01-10T15:52:17Z,2022-01-10T15:52:17Z,Systems Challenges for Trustworthy Embodied Systems,"A new generation of increasingly autonomous and self-learning systems, which
we call embodied systems, is about to be developed. When deploying these
systems into a real-life context we face various engineering challenges, as it
is crucial to coordinate the behavior of embodied systems in a beneficial
manner, ensure their compatibility with our human-centered social values, and
design verifiably safe and reliable human-machine interaction. We are arguing
that raditional systems engineering is coming to a climacteric from embedded to
embodied systems, and with assuring the trustworthiness of dynamic federations
of situationally aware, intent-driven, explorative, ever-evolving, largely
non-predictable, and increasingly autonomous embodied systems in uncertain,
complex, and unpredictable real-world contexts. We are also identifying a
number of urgent systems challenges for trustworthy embodied systems, including
robust and human-centric AI, cognitive architectures, uncertainty
quantification, trustworthy self-integration, and continual analysis and
assurance.",arxiv
http://arxiv.org/abs/2201.03550v1,2022-01-09T17:43:03Z,2022-01-09T17:43:03Z,"Machine learning enabling high-throughput and remote operations at
  large-scale user facilities","Imaging, scattering, and spectroscopy are fundamental in understanding and
discovering new functional materials. Contemporary innovations in automation
and experimental techniques have led to these measurements being performed much
faster and with higher resolution, thus producing vast amounts of data for
analysis. These innovations are particularly pronounced at user facilities and
synchrotron light sources. Machine learning (ML) methods are regularly
developed to process and interpret large datasets in real-time with
measurements. However, there remain conceptual barriers to entry for the
facility general user community, whom often lack expertise in ML, and technical
barriers for deploying ML models. Herein, we demonstrate a variety of
archetypal ML models for on-the-fly analysis at multiple beamlines at the
National Synchrotron Light Source II (NSLS-II). We describe these examples
instructively, with a focus on integrating the models into existing
experimental workflows, such that the reader can easily include their own ML
techniques into experiments at NSLS-II or facilities with a common
infrastructure. The framework presented here shows how with little effort,
diverse ML models operate in conjunction with feedback loops via integration
into the existing Bluesky Suite for experimental orchestration and data
management.",arxiv
http://arxiv.org/abs/2201.02503v1,2022-01-07T15:42:50Z,2022-01-07T15:42:50Z,"A Review of Deep Learning Techniques for Markerless Human Motion on
  Synthetic Datasets","Markerless motion capture has become an active field of research in computer
vision in recent years. Its extensive applications are known in a great variety
of fields, including computer animation, human motion analysis, biomedical
research, virtual reality, and sports science. Estimating human posture has
recently gained increasing attention in the computer vision community, but due
to the depth of uncertainty and the lack of the synthetic datasets, it is a
challenging task. Various approaches have recently been proposed to solve this
problem, many of which are based on deep learning. They are primarily focused
on improving the performance of existing benchmarks with significant advances,
especially 2D images. Based on powerful deep learning techniques and recently
collected real-world datasets, we explored a model that can predict the
skeleton of an animation based solely on 2D images. Frames generated from
different real-world datasets with synthesized poses using different body
shapes from simple to complex. The implementation process uses DeepLabCut on
its own dataset to perform many necessary steps, then use the input frames to
train the model. The output is an animated skeleton for human movement. The
composite dataset and other results are the ""ground truth"" of the deep model.",arxiv
http://arxiv.org/abs/2201.02279v1,2022-01-06T23:50:09Z,2022-01-06T23:50:09Z,De-rendering 3D Objects in the Wild,"With increasing focus on augmented and virtual reality applications (XR)
comes the demand for algorithms that can lift objects from images and videos
into representations that are suitable for a wide variety of related 3D tasks.
Large-scale deployment of XR devices and applications means that we cannot
solely rely on supervised learning, as collecting and annotating data for the
unlimited variety of objects in the real world is infeasible. We present a
weakly supervised method that is able to decompose a single image of an object
into shape (depth and normals), material (albedo, reflectivity and shininess)
and global lighting parameters. For training, the method only relies on a rough
initial shape estimate of the training objects to bootstrap the learning
process. This shape supervision can come for example from a pretrained depth
network or - more generically - from a traditional structure-from-motion
pipeline. In our experiments, we show that the method can successfully
de-render 2D images into a decomposed 3D representation and generalizes to
unseen object categories. Since in-the-wild evaluation is difficult due to the
lack of ground truth data, we also introduce a photo-realistic synthetic test
set that allows for quantitative evaluation.",arxiv
http://arxiv.org/abs/2201.02734v1,2022-01-02T01:43:24Z,2022-01-02T01:43:24Z,Building Human-like Communicative Intelligence: A Grounded Perspective,"Modern Artificial Intelligence (AI) systems excel at diverse tasks, from
image classification to strategy games, even outperforming humans in many of
these domains. After making astounding progress in language learning in the
recent decade, AI systems, however, seem to approach the ceiling that does not
reflect important aspects of human communicative capacities. Unlike human
learners, communicative AI systems often fail to systematically generalize to
new data, suffer from sample inefficiency, fail to capture common-sense
semantic knowledge, and do not translate to real-world communicative
situations. Cognitive Science offers several insights on how AI could move
forward from this point. This paper aims to: (1) suggest that the dominant
cognitively-inspired AI directions, based on nativist and symbolic paradigms,
lack necessary substantiation and concreteness to guide progress in modern AI,
and (2) articulate an alternative, ""grounded"", perspective on AI advancement,
inspired by Embodied, Embedded, Extended, and Enactive Cognition (4E) research.
I review results on 4E research lines in Cognitive Science to distinguish the
main aspects of naturalistic learning conditions that play causal roles for
human language development. I then use this analysis to propose a list of
concrete, implementable components for building ""grounded"" linguistic
intelligence. These components include embodying machines in a
perception-action cycle, equipping agents with active exploration mechanisms so
they can build their own curriculum, allowing agents to gradually develop motor
abilities to promote piecemeal language development, and endowing the agents
with adaptive feedback from their physical and social environment. I hope that
these ideas can direct AI research towards building machines that develop
human-like language abilities through their experiences with the world.",arxiv
