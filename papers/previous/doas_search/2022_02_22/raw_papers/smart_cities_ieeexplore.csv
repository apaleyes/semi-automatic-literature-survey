doi,title,publisher,content_type,abstract,html_url,publication_title,publication_date,database
10.1109/CCNC49033.2022.9700515,CAVE-VR and Unity Game Engine for Visualizing City Scale 3D Meshes,IEEE,Conferences,"Modeling and simulation of large urban regions is beneficial for a range of applications including intelligent transportation, smart cities, infrastructure planning, and training artificial intelligence for autonomous navigation systems including ground vehicles and aerial drones. Immersive environments including virtual reality (VR), augmented reality (AR), mixed reality (MR or XR) can be used to explore city scale regions for planning, design, training and operations. Virtual environments are in the midst of rapid change as innovations in display tech-nologies, graphics processors and game engine software present new opportunities for incorporating modeling and simulation into engineering workflows. Game engine software like Unity with photorealistic rendering and realistic physics have plug-in support for a variety of virtual environments. In this paper, we explore the visualization of urban scale real world accurate meshes in virtual environments, including the Microsoft HoloLens head mounted display or the CAVE VR for multi-user interaction.",https://ieeexplore.ieee.org/document/9700515/,2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC),8-11 Jan. 2022,ieeexplore
10.1109/CCNC49033.2022.9700725,Mitigating Location-based Attacks Using Predication Models in Vehicular Ad-Hoc Networks,IEEE,Conferences,"The modern world is constantly in a state of technological revolution. Everyday new technological ideas, inventions, and threats emerge. With modern computer software and hardware advancements, we have the emergence of the Internet of Things (IoT). In conjunction, modern car companies have a push from public demand for a fully-autonomous car. To accomplish autonomy, small, and secure Vehicular Ad-Hoc Networks (VANETs) it is necessary to ensure that the systems that rely on connected vehicle data is reliable and accurate. In the event there is a malicious actor manipulating the data through replica and injection attacks or there is a hardware failure yielding inaccurate location information, it is necessary to explore efficient methods for predicting connected vehicles locations such that these systems, which rely on accurate information are not impacted. This study analyzes multiple clustering and prediction models to discover how effectively a multi-layered machine learning approach is able to meet the real-time requirement of future generation smart cities.",https://ieeexplore.ieee.org/document/9700725/,2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC),8-11 Jan. 2022,ieeexplore
10.1109/CCNC49033.2022.9700676,QoS-Aware Priority-Based Task Offloading for Deep Learning Services at the Edge,IEEE,Conferences,"Emerging Edge Computing (EC) technology has shown promise for many delay-sensitive Deep Learning (DL) based applications of smart cities in terms of improved Quality-of-Service (QoS). EC requires judicious decisions which jointly consider the limited capacity of the edge servers and provided QoS of DL-dependent services. In a smart city environment, tasks may have varying priorities in terms of when and how to serve them; thus, priorities of the tasks have to be considered when making resource management decisions. In this paper, we focus on finding optimal offloading decisions in a three-tier user-edge-cloud architecture while considering different priority classes for the DL-based services and making a trade-off between a task’s completion time and the provided accuracy by the DL-based service. We cast the optimization problem as an Integer Linear Program (ILP) where the objective is to maximize a function called gain of system (GoS) defined based on provided QoS and priority of the tasks. We prove the problem is NP-hard. We then propose an efficient offloading algorithm, called PGUS, that is shown to achieve near-optimal results in terms of the provided GoS. Finally, we compare our proposed algorithm, PGUS, with heuristics and a state-of-the-art algorithm, called GUS, using both numerical analysis and real-world implementation. Our results show that PGUS outperforms GUS by a factor of 45% in average in terms of serving the top 25% higher priority classes of the tasks while still keeping the overall percentage of the dropped tasks minimal and the overall gain of system maximized.",https://ieeexplore.ieee.org/document/9700676/,2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC),8-11 Jan. 2022,ieeexplore
10.1109/TII.2021.3077865,A Data Stream Cleaning System Using Edge Intelligence for Smart City Industrial Environments,IEEE,Journals,"Cities are becoming smarter because of recent advances in artificial intelligence and the Internet of Things. However, heterogeneous data source in smart cities are continuously producing low-quality data, and ever-growing applications have greater real-time requirements. Therefore, this article proposes a data stream cleaning system (named DSCS) using edge intelligence to utilize the advantages of cloud servers and edge devices. The DSCS in edge nodes consists of a dynamic protocol interpreter, a structure parser, and a cleaning model activator. Meanwhile, a cloud server, which has pools of protocol and structured programs and cleaning models, supports the edge nodes to adapt massive heterogeneous data sources. To validate the proposed data cleaning system, we applied it to two scenarios: monitoring the injection molding machines, and base stations. The DSCS can have a stable processing time when the number of accessed edge devices is increased, as well as a good cleaning effect.",https://ieeexplore.ieee.org/document/9424956/,IEEE Transactions on Industrial Informatics,Feb. 2022,ieeexplore
10.1109/TII.2021.3077865,A Data Stream Cleaning System Using Edge Intelligence for Smart City Industrial Environments,IEEE,Journals,"Cities are becoming smarter because of recent advances in artificial intelligence and the Internet of Things. However, heterogeneous data source in smart cities are continuously producing low-quality data, and ever-growing applications have greater real-time requirements. Therefore, this article proposes a data stream cleaning system (named DSCS) using edge intelligence to utilize the advantages of cloud servers and edge devices. The DSCS in edge nodes consists of a dynamic protocol interpreter, a structure parser, and a cleaning model activator. Meanwhile, a cloud server, which has pools of protocol and structured programs and cleaning models, supports the edge nodes to adapt massive heterogeneous data sources. To validate the proposed data cleaning system, we applied it to two scenarios: monitoring the injection molding machines, and base stations. The DSCS can have a stable processing time when the number of accessed edge devices is increased, as well as a good cleaning effect.",https://ieeexplore.ieee.org/document/9424956/,IEEE Transactions on Industrial Informatics,Feb. 2022,ieeexplore
10.1109/CCNC49033.2022.9700676,QoS-Aware Priority-Based Task Offloading for Deep Learning Services at the Edge,IEEE,Conferences,"Emerging Edge Computing (EC) technology has shown promise for many delay-sensitive Deep Learning (DL) based applications of smart cities in terms of improved Quality-of-Service (QoS). EC requires judicious decisions which jointly consider the limited capacity of the edge servers and provided QoS of DL-dependent services. In a smart city environment, tasks may have varying priorities in terms of when and how to serve them; thus, priorities of the tasks have to be considered when making resource management decisions. In this paper, we focus on finding optimal offloading decisions in a three-tier user-edge-cloud architecture while considering different priority classes for the DL-based services and making a trade-off between a task’s completion time and the provided accuracy by the DL-based service. We cast the optimization problem as an Integer Linear Program (ILP) where the objective is to maximize a function called gain of system (GoS) defined based on provided QoS and priority of the tasks. We prove the problem is NP-hard. We then propose an efficient offloading algorithm, called PGUS, that is shown to achieve near-optimal results in terms of the provided GoS. Finally, we compare our proposed algorithm, PGUS, with heuristics and a state-of-the-art algorithm, called GUS, using both numerical analysis and real-world implementation. Our results show that PGUS outperforms GUS by a factor of 45% in average in terms of serving the top 25% higher priority classes of the tasks while still keeping the overall percentage of the dropped tasks minimal and the overall gain of system maximized.",https://ieeexplore.ieee.org/document/9700676/,2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC),8-11 Jan. 2022,ieeexplore
10.1109/JIOT.2021.3100068,ASTCN: An Attentive Spatial–Temporal Convolutional Network for Flow Prediction,IEEE,Journals,"Flow prediction attracts intensive research interests, since it can offer essential support to many crucial problems in public safety and smart city, e.g., epidemic spread prediction and medical resource allocation optimization. Among all the models in flow prediction, deep learning models (e.g., convolutional neural networks, recurrent neural networks, and graph neural networks) are popular and outperform other statistics and machine learning models, since they can learn intrinsic structures and extract features from spatial–temporal (ST) data. However, most of them set strict temporal periods in the prediction or separate the interaction between spatial and temporal correlations. Therefore, the prediction accuracy is affected. To overcome the difficulties, we propose a flow prediction network attentive spatial–temporal convolutional network (ASTCN), which can effectively handle large-scale flow data and learn complex features. In ASTCN, we leverage an attention mechanism to overcome the previous problem of strict temporal periods, and can effectively fuse ST data with multiple factors from different time-series sources. Furthermore, we propose a causal 3-D convolutional layer based on temporal convolutional networks (TCNs). It can simultaneously extract both spatial and temporal features to improve the prediction accuracy. We comprehensively conducted our experiments based on real-world data sets. Experimental results show that ASTCN outperforms the state-of-the-art methods by at least 3.78% in root mean square error. Therefore, ASTCN is a potential solution to other large-scale ST problems.",https://ieeexplore.ieee.org/document/9511315/,IEEE Internet of Things Journal,"1 March1, 2022",ieeexplore
10.1109/JIOT.2021.3097768,User-Aware and Flexible Proactive Caching Using LSTM and Ensemble Learning in IoT-MEC Networks,IEEE,Journals,"To meet the stringent demands of emerging Internet-of-Things (IoT) applications, such as smart home, smart city, and virtual reality in 5G/6G IoT networks, edge content caching for mobile/multiaccess edge computing (MEC) has been identified as a promising approach to improve the quality of services in terms of latency and energy consumption. However, the limitations of cache capacity make it difficult to develop an effective common caching framework that satisfies diverse user preferences. In this article, we propose a new content caching strategy that maximizes the cache hit ratio through flexible prediction in dynamically changing network and user environments. It is based on a hierarchical deep learning architecture: long short-term memory (LSTM)-based local learning and ensemble-based meta-learning. First, as a local learning model, we employ an LSTM method with seasonal-trend decomposition using loess (STL)-based preprocessing. It identifies the attributes for demand prediction on the contents in various demographic user groups. Second, as a metalearning model, we employ a regression-based ensemble learning method, which uses an online convex optimization framework and exhibits sublinear “regret” performance. It orchestrates the obtained multiple demographic user preferences into a unified caching strategy in real time. Extensive experiments were conducted on the popular MovieLens data sets. It was shown that the proposed control provides up to a 30% higher cache hit ratio than conventional representative algorithms and a near-optimal cache hit ratio within approximately 9% of the optimal caching scheme with perfect prior knowledge of content popularity. The proposed learning and caching control can be implemented as a core function of the 5G/6G standard’s network data analytic function (NWDAF) module.",https://ieeexplore.ieee.org/document/9488291/,IEEE Internet of Things Journal,"1 March1, 2022",ieeexplore
10.1109/TNSE.2021.3050781,VFChain: Enabling Verifiable and Auditable Federated Learning via Blockchain Systems,IEEE,Journals,"Advanced artificial intelligence techniques, such as federated learning, has been applied to broad areas, e.g., image classification, speech recognition, smart city, and healthcare. Despite intensive research on federated learning, existing schemes are vulnerable to attacks and can hardly meet the security requirements for real-world applications. The problem of designing a secure federated learning framework to ensure the correctness of training procedure has not been sufficiently studied and remains open. In this paper, we propose VFChain, a verifiable and auditable federated learning framework based on the blockchain system. First, to provide the verifiability, a committee is selected through the blockchain to collectively aggregate models and record verifiable proofs in the blockchain. Then, to provide the auditability, a novel authenticated data structure is proposed for blockchain to improve the search efficiency of verifiable proofs and support a secure rotation of committee. Finally, to further improve the search efficiency, an optimization scheme is proposed to support multiple-model learning tasks. We implement VFChain and conduct extensive experiments by utilizing the popular deep learning models over the public real-world dataset. The evaluation results demonstrate the effectiveness of our proposed VFChain system.",https://ieeexplore.ieee.org/document/9321132/,IEEE Transactions on Network Science and Engineering,1 Jan.-Feb. 2022,ieeexplore
10.1109/TKDE.2020.2985954,Incorporating Multi-Source Urban Data for Personalized and Context-Aware Multi-Modal Transportation Recommendation,IEEE,Journals,"Transportation recommendation is one important map service in navigation applications. Previous transportation recommendation solutions fail to deliver satisfactory user experience because their recommendations only consider routes in one transportation mode (uni-modal, e.g., taxi, bus, cycle) and largely overlook situational context. In this work, we propose <inline-formula><tex-math notation=""LaTeX"">$\mathsf {Hydra}$</tex-math><alternatives><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mi mathvariant=""sans-serif"">Hydra</mml:mi></mml:math><inline-graphic xlink:href=""liu-ieq1-2985954.gif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula>, a multi-task deep learning based recommendation system that offers multi-modal transportation planning and is adaptive to various situational context (e.g., nearby point-of-interest (POI) distribution and weather). We leverage the availability of existing routing engines and big urban data, and design a novel two-level framework that integrates uni-modal and multi-modal (e.g., taxi-bus, bus-cycle) routes as well as heterogeneous urban data for intelligent multi-modal transportation recommendation. In addition to urban context features constructed from multi-source urban data, we learn the latent representations of users, origin-destination (OD) pairs and transportation modes based on user implicit feedbacks, which captures the collaborative transportation mode preferences of users and OD pairs. Moreover, we propose two models to recommend the proper route among various uni-modal and multi-modal transportation routes: (1) a light-weight gradient boosting decision tree (GBDT) based recommendation model; and (2) a multi-task wide and deep learning (MTWDL) based recommendation model. We also optimize the framework to support real-time, large-scale route query and recommendation. We deploy <inline-formula><tex-math notation=""LaTeX"">$\mathsf {Hydra}$</tex-math><alternatives><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mi mathvariant=""sans-serif"">Hydra</mml:mi></mml:math><inline-graphic xlink:href=""liu-ieq2-2985954.gif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> on Baidu Maps,<xref ref-type=""fn"" rid=""fn1""><sup>1</sup></xref><fn id=""fn1""><label>1.</label><p><uri>https://maps.baidu.com/</uri>.</p> </fn> one of the world's largest map services. Real-world urban-scale experiments demonstrate the effectiveness and efficiency of our proposed system. Since its deployment in August 2018, <inline-formula><tex-math notation=""LaTeX"">$\mathsf {Hydra}$</tex-math><alternatives><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mi mathvariant=""sans-serif"">Hydra</mml:mi></mml:math><inline-graphic xlink:href=""liu-ieq3-2985954.gif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> has answered over a hundred million route recommendation queries made by over ten million distinct users. The GBDT based model and MTWDL based model achieve 82.8 and 96.6 percent relative improvement of user click ratio, respectively.",https://ieeexplore.ieee.org/document/9063461/,IEEE Transactions on Knowledge and Data Engineering,1 Feb. 2022,ieeexplore
10.1109/CCNC49033.2022.9700515,CAVE-VR and Unity Game Engine for Visualizing City Scale 3D Meshes,IEEE,Conferences,"Modeling and simulation of large urban regions is beneficial for a range of applications including intelligent transportation, smart cities, infrastructure planning, and training artificial intelligence for autonomous navigation systems including ground vehicles and aerial drones. Immersive environments including virtual reality (VR), augmented reality (AR), mixed reality (MR or XR) can be used to explore city scale regions for planning, design, training and operations. Virtual environments are in the midst of rapid change as innovations in display tech-nologies, graphics processors and game engine software present new opportunities for incorporating modeling and simulation into engineering workflows. Game engine software like Unity with photorealistic rendering and realistic physics have plug-in support for a variety of virtual environments. In this paper, we explore the visualization of urban scale real world accurate meshes in virtual environments, including the Microsoft HoloLens head mounted display or the CAVE VR for multi-user interaction.",https://ieeexplore.ieee.org/document/9700515/,2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC),8-11 Jan. 2022,ieeexplore
10.1109/SCSET55041.2022.00053,Research on Leak Location Method of Water Supply Network based on Deep Neural Network Model,IEEE,Conferences,"The water supply network is one of the important infrastructure in urban construction. It has strong theoretical and practical significance to realize the real-time monitoring and leak location of the water supply network. In this paper, based on the similarity of water supply network node pressure, fuzzy C-means clustering algorithm is used to realize the selection of finite monitoring points. On this basis, a depth neural network model is constructed according to the pressure changes of the monitoring points before and after the leakage of the water supply network, so as to locate the leakage points. In the experimental part, hydraulics simulation was conducted by using EPANETH pipe network adjustment software according to the layout structure of water supply network, and the pressure of all nodes was obtained. A deep neural network model was established by Keras in Tensorflow framework. After model training and testing, the training error was controlled within the effective range of 5 %. Finally, the model is applied to the actual leakage problem of underground water supply network in Langxi County of Xuancheng City, and the accurate location of the leakage point is realized. The experiment proves the feasibility and accuracy of the method proposed in this paper.",https://ieeexplore.ieee.org/document/9700905/,2022 International Seminar on Computer Science and Engineering Technology (SCSET),8-9 Jan. 2022,ieeexplore
10.1109/TGRS.2021.3056624,Attention-Based Multiscale Residual Adaptation Network for Cross-Scene Classification,IEEE,Journals,"In recent years, classification has obtained ever-rising attention and has been applied to many areas in the field of remote sensing, including land use, forest monitoring, urban planning, and vegetation management. Due to the lack of labeled data and the poor generalization ability of supervised models, cross-scene classification is proposed for better utilization of the existing knowledge. Existing adaptation methods for cross-scene classification only consider the marginal distribution, while the conditional distribution is equally important in real applications. In addition, approaches based on deep learning align the distribution of features extracted from a single-scale structure, leading to the loss of information. To overcome the above drawbacks, an Attention-based Multiscale Residual Adaptation Network (AMRAN) is proposed for cross-scene classification tasks. In the proposed AMRAN, both the marginal and conditional distributions are taken into consideration for more comprehensive alignment. Besides, the attention mechanism and the multiscale strategy are used to extract more robust features and more complete information, respectively. Experimental results between four existing scene classification data sets demonstrate that AMRAN has a significant improvement compared with the state-of-the-art deep adaptation methods.",https://ieeexplore.ieee.org/document/9377566/,IEEE Transactions on Geoscience and Remote Sensing,2022,ieeexplore
10.1109/ACCESS.2021.3137031,Autonomous Detection and Deterrence of Pigeons on Buildings by Drones,IEEE,Journals,"Pigeons may transmit diseases to humans and cause damages to buildings, monuments, and other infrastructure. Therefore, several control strategies have been developed, but they have been found to be either ineffective or harmful to animals and often depend on human operation. This study proposes a system capable of autonomously detecting and deterring pigeons on building roofs using a drone. The presence and position of pigeons were detected in real time by a neural network using images taken by a video camera located on the roof. Moreover, a drone was utilized to deter the animals. Field experiments were conducted in a real-world urban setting to assess the proposed system by comparing the number of animals and their stay durations for over five days against the 21-day-trial experiment without the drone. During the five days of experiments, the drone was automatically deployed 55 times and was significantly effective in reducing the number of birds and their stay durations without causing any harm to them. In conclusion, this study has proven the effectiveness of this system in deterring birds, and this approach can be seen as a fully autonomous alternative to the already existing methods.",https://ieeexplore.ieee.org/document/9656717/,IEEE Access,2022,ieeexplore
10.1109/JAS.2021.1003907,Domain-Invariant Similarity Activation Map Contrastive Learning for Retrieval-Based Long-Term Visual Localization,IEEE,Journals,"Visual localization is a crucial component in the application of mobile robot and autonomous driving. Image retrieval is an efficient and effective technique in image-based localization methods. Due to the drastic variability of environmental conditions, e.g., illumination changes, retrieval-based visual localization is severely affected and becomes a challenging problem. In this work, a general architecture is first formulated probabilistically to extract domain-invariant features through multi-domain image translation. Then, a novel gradient-weighted similarity activation mapping loss (Grad-SAM) is incorporated for finer localization with high accuracy. We also propose a new adaptive triplet loss to boost the contrastive learning of the embedding in a self-supervised manner. The final coarse-to-fine image retrieval pipeline is implemented as the sequential combination of models with and without Grad-SAM loss. Extensive experiments have been conducted to validate the effectiveness of the proposed approach on the CMU-Seasons dataset. The strong generalization ability of our approach is verified with the RobotCar dataset using models pre-trained on urban parts of the CMU-Seasons dataset. Our performance is on par with or even outperforms the state-of-the-art image-based localization baselines in medium or high precision, especially under challenging environments with illumination variance, vegetation, and night-time images. Moreover, real-site experiments have been conducted to validate the efficiency and effectiveness of the coarse-to-fine strategy for localization.",https://ieeexplore.ieee.org/document/9358457/,IEEE/CAA Journal of Automatica Sinica,February 2022,ieeexplore
10.1109/LGRS.2020.3030839,Hybrid Attention Networks for Flow and Pressure Forecasting in Water Distribution Systems,IEEE,Journals,"Multivariate geo-sensory time series prediction is challenging because of the complex spatial and temporal correlations. In urban water distribution systems (WDSs), numerous spatial-correlated sensors have been deployed to continuously collect hydraulic data. Forecasts of the monitored flow and pressure time series are of vital importance for operational decision making, alerts, and anomaly detection. To address this issue, we proposed a hybrid dual-stage spatial–temporal attention-based recurrent neural networks (hDS-RNN). Our model consists of two stages: a spatial attention-based encoder and a temporal attention-based decoder. Specifically, a hybrid spatial attention mechanism that employs inputs along the temporal and spatial axes is proposed. Experiments on a real-world data set are conducted, which demonstrate that our model outperformed seven baseline models in flow and pressure predictions in WDS.",https://ieeexplore.ieee.org/document/9241394/,IEEE Geoscience and Remote Sensing Letters,2022,ieeexplore
10.1109/TKDE.2020.2985954,Incorporating Multi-Source Urban Data for Personalized and Context-Aware Multi-Modal Transportation Recommendation,IEEE,Journals,"Transportation recommendation is one important map service in navigation applications. Previous transportation recommendation solutions fail to deliver satisfactory user experience because their recommendations only consider routes in one transportation mode (uni-modal, e.g., taxi, bus, cycle) and largely overlook situational context. In this work, we propose <inline-formula><tex-math notation=""LaTeX"">$\mathsf {Hydra}$</tex-math><alternatives><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mi mathvariant=""sans-serif"">Hydra</mml:mi></mml:math><inline-graphic xlink:href=""liu-ieq1-2985954.gif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula>, a multi-task deep learning based recommendation system that offers multi-modal transportation planning and is adaptive to various situational context (e.g., nearby point-of-interest (POI) distribution and weather). We leverage the availability of existing routing engines and big urban data, and design a novel two-level framework that integrates uni-modal and multi-modal (e.g., taxi-bus, bus-cycle) routes as well as heterogeneous urban data for intelligent multi-modal transportation recommendation. In addition to urban context features constructed from multi-source urban data, we learn the latent representations of users, origin-destination (OD) pairs and transportation modes based on user implicit feedbacks, which captures the collaborative transportation mode preferences of users and OD pairs. Moreover, we propose two models to recommend the proper route among various uni-modal and multi-modal transportation routes: (1) a light-weight gradient boosting decision tree (GBDT) based recommendation model; and (2) a multi-task wide and deep learning (MTWDL) based recommendation model. We also optimize the framework to support real-time, large-scale route query and recommendation. We deploy <inline-formula><tex-math notation=""LaTeX"">$\mathsf {Hydra}$</tex-math><alternatives><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mi mathvariant=""sans-serif"">Hydra</mml:mi></mml:math><inline-graphic xlink:href=""liu-ieq2-2985954.gif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> on Baidu Maps,<xref ref-type=""fn"" rid=""fn1""><sup>1</sup></xref><fn id=""fn1""><label>1.</label><p><uri>https://maps.baidu.com/</uri>.</p> </fn> one of the world's largest map services. Real-world urban-scale experiments demonstrate the effectiveness and efficiency of our proposed system. Since its deployment in August 2018, <inline-formula><tex-math notation=""LaTeX"">$\mathsf {Hydra}$</tex-math><alternatives><mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mi mathvariant=""sans-serif"">Hydra</mml:mi></mml:math><inline-graphic xlink:href=""liu-ieq3-2985954.gif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> has answered over a hundred million route recommendation queries made by over ten million distinct users. The GBDT based model and MTWDL based model achieve 82.8 and 96.6 percent relative improvement of user click ratio, respectively.",https://ieeexplore.ieee.org/document/9063461/,IEEE Transactions on Knowledge and Data Engineering,1 Feb. 2022,ieeexplore
10.1109/JSTARS.2022.3142898,WH-MAVS: A Novel Dataset and Deep Learning Benchmark for Multiple Land Use and Land Cover Applications,IEEE,Journals,"Over the past decade, many excellent data sharing efforts have enriched the remote sensing scene classification (SC) methods. These datasets have achieved great success in complex high-level semantic information interpretation. However, most existing datasets are collected from standard and ungeoreferenced image patches for algorithm training and evaluation. These datasets do not fit for practical applications and cannot be directly applied in further geographical study. Accordingly, we provide a large range high-resolution SC dataset with multiple time phases, called “<bold>W</bold>u<bold>h</bold>an <bold>M</bold>ulti<bold>a</bold>pplication <bold>V</bold>HR <bold>S</bold>cene classification dataset (WH-MAVS).” It facilitates the study of SC and scene change detection (SCD) algorithms. Moreover, it can also be directly employed to perform a variety of real-life land use application tasks. To the best of our knowledge, this is the first free, publicly available, georeferenced, and annotated dataset to cover almost an entire megacity. The WH-MAVS was collected and annotated from Google Earth imagery with the same spatial resolution and uniform nonoverlapping patch size, covering the central area of Wuhan, China. The total number of scene samples is 47 137, which belong to 14 classes with 23 567 labeled patches for each time phase in 2014 and 2016, respectively. The geographic coordinates of all samples in both time phases exhibit one-to-one correspondence with 23 202 unchanged image patches of scene categories and 365 changed ones. The distribution of the number of samples in each class is highly imbalanced; moreover, there are large intraclass differences and indistinguishable interclass variances. These characteristics are closer to the real land use/land cover application tasks and introduce further challenges to the related algorithm research. In addition, we conducted benchmark experiments on SC and SCD based on the WH-MAVS dataset with widely used deep learning models. DenseNet169 was found to achieve the best performance. The overall accuracies are 91.07% and 92.09%, respectively, in the 2014 and 2016 validation sets of WH-MAVS. Furthermore, SCD obtained by DenseNet169 has a binary change detection accuracy of 89.56% and a multiple (from–to) change detection accuracy of 86.70%. Over and above the research value of the algorithm, it is also proven to have practical applications in fields such as urban planning, landscape pattern analysis, and urban dynamic monitoring and analysis.",https://ieeexplore.ieee.org/document/9681304/,IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,2022,ieeexplore
10.1109/CCNC49033.2022.9700515,CAVE-VR and Unity Game Engine for Visualizing City Scale 3D Meshes,IEEE,Conferences,"Modeling and simulation of large urban regions is beneficial for a range of applications including intelligent transportation, smart cities, infrastructure planning, and training artificial intelligence for autonomous navigation systems including ground vehicles and aerial drones. Immersive environments including virtual reality (VR), augmented reality (AR), mixed reality (MR or XR) can be used to explore city scale regions for planning, design, training and operations. Virtual environments are in the midst of rapid change as innovations in display tech-nologies, graphics processors and game engine software present new opportunities for incorporating modeling and simulation into engineering workflows. Game engine software like Unity with photorealistic rendering and realistic physics have plug-in support for a variety of virtual environments. In this paper, we explore the visualization of urban scale real world accurate meshes in virtual environments, including the Microsoft HoloLens head mounted display or the CAVE VR for multi-user interaction.",https://ieeexplore.ieee.org/document/9700515/,2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC),8-11 Jan. 2022,ieeexplore
10.1109/TII.2021.3077865,A Data Stream Cleaning System Using Edge Intelligence for Smart City Industrial Environments,IEEE,Journals,"Cities are becoming smarter because of recent advances in artificial intelligence and the Internet of Things. However, heterogeneous data source in smart cities are continuously producing low-quality data, and ever-growing applications have greater real-time requirements. Therefore, this article proposes a data stream cleaning system (named DSCS) using edge intelligence to utilize the advantages of cloud servers and edge devices. The DSCS in edge nodes consists of a dynamic protocol interpreter, a structure parser, and a cleaning model activator. Meanwhile, a cloud server, which has pools of protocol and structured programs and cleaning models, supports the edge nodes to adapt massive heterogeneous data sources. To validate the proposed data cleaning system, we applied it to two scenarios: monitoring the injection molding machines, and base stations. The DSCS can have a stable processing time when the number of accessed edge devices is increased, as well as a good cleaning effect.",https://ieeexplore.ieee.org/document/9424956/,IEEE Transactions on Industrial Informatics,Feb. 2022,ieeexplore
10.1109/CCNC49033.2022.9700515,CAVE-VR and Unity Game Engine for Visualizing City Scale 3D Meshes,IEEE,Conferences,"Modeling and simulation of large urban regions is beneficial for a range of applications including intelligent transportation, smart cities, infrastructure planning, and training artificial intelligence for autonomous navigation systems including ground vehicles and aerial drones. Immersive environments including virtual reality (VR), augmented reality (AR), mixed reality (MR or XR) can be used to explore city scale regions for planning, design, training and operations. Virtual environments are in the midst of rapid change as innovations in display tech-nologies, graphics processors and game engine software present new opportunities for incorporating modeling and simulation into engineering workflows. Game engine software like Unity with photorealistic rendering and realistic physics have plug-in support for a variety of virtual environments. In this paper, we explore the visualization of urban scale real world accurate meshes in virtual environments, including the Microsoft HoloLens head mounted display or the CAVE VR for multi-user interaction.",https://ieeexplore.ieee.org/document/9700515/,2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC),8-11 Jan. 2022,ieeexplore
10.1109/CCNC49033.2022.9700579,Demo: An Experimental Environment Based On Mini-PCs For Federated Learning Research,IEEE,Conferences,"There is a growing research interest in Federated Learning (FL), a promising approach for data privacy preservation and proximity of training to the network edge, where data is generated. Resource consumption for Machine Learning (ML) training and inference is important for edge nodes, but most of the proposed protocols and algorithms for FL are evaluated by simulations. In this demo paper, we present an environment based on distributed mini-PCs to enable experimental study of FL protocols and algorithms. We have installed low-capacity mini-PCs within a wireless city-level mesh network and deployed container-based FL components on these nodes. We show the deployed FL clients and server at different nodes in the city and demonstrate how an FL experiment can be set and run in a real environment.",https://ieeexplore.ieee.org/document/9700579/,2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC),8-11 Jan. 2022,ieeexplore
10.1109/WACV51458.2022.00308,Multi-branch Neural Networks for Video Anomaly Detection in Adverse Lighting and Weather Conditions,IEEE,Conferences,"Automated anomaly detection in surveillance videos has attracted much interest as it provides a scalable alternative to manual monitoring. Most existing approaches achieve good performance on clean benchmark datasets recorded in well-controlled environments. However, detecting anomalies is much more challenging in the real world. Adverse weather conditions like rain or changing brightness levels cause a significant shift in the input data distribution, which in turn can lead to the detector model incorrectly reporting high anomaly scores. Additionally, surveillance cameras are usually deployed in evolving environments such as a city street of which the appearance changes over time because of seasonal changes or roadworks. The anomaly detection model will need to be updated periodically to deal with these issues. In this paper, we introduce a multi-branch model that is equipped with a trainable preprocessing step and multiple identical branches for detecting anomalies during day and night as well as in sunny and rainy conditions. We experimentally validate our approach on a distorted version of the Avenue dataset and provide qualitative results on real-world surveillance camera data. Experimental results show that our method outperforms the existing methods in terms of detection accuracy while being faster and more robust on scenes with varying visibility.",https://ieeexplore.ieee.org/document/9706717/,2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV),3-8 Jan. 2022,ieeexplore
10.1109/CCNC49033.2022.9700676,QoS-Aware Priority-Based Task Offloading for Deep Learning Services at the Edge,IEEE,Conferences,"Emerging Edge Computing (EC) technology has shown promise for many delay-sensitive Deep Learning (DL) based applications of smart cities in terms of improved Quality-of-Service (QoS). EC requires judicious decisions which jointly consider the limited capacity of the edge servers and provided QoS of DL-dependent services. In a smart city environment, tasks may have varying priorities in terms of when and how to serve them; thus, priorities of the tasks have to be considered when making resource management decisions. In this paper, we focus on finding optimal offloading decisions in a three-tier user-edge-cloud architecture while considering different priority classes for the DL-based services and making a trade-off between a task’s completion time and the provided accuracy by the DL-based service. We cast the optimization problem as an Integer Linear Program (ILP) where the objective is to maximize a function called gain of system (GoS) defined based on provided QoS and priority of the tasks. We prove the problem is NP-hard. We then propose an efficient offloading algorithm, called PGUS, that is shown to achieve near-optimal results in terms of the provided GoS. Finally, we compare our proposed algorithm, PGUS, with heuristics and a state-of-the-art algorithm, called GUS, using both numerical analysis and real-world implementation. Our results show that PGUS outperforms GUS by a factor of 45% in average in terms of serving the top 25% higher priority classes of the tasks while still keeping the overall percentage of the dropped tasks minimal and the overall gain of system maximized.",https://ieeexplore.ieee.org/document/9700676/,2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC),8-11 Jan. 2022,ieeexplore
10.1109/SCSET55041.2022.00053,Research on Leak Location Method of Water Supply Network based on Deep Neural Network Model,IEEE,Conferences,"The water supply network is one of the important infrastructure in urban construction. It has strong theoretical and practical significance to realize the real-time monitoring and leak location of the water supply network. In this paper, based on the similarity of water supply network node pressure, fuzzy C-means clustering algorithm is used to realize the selection of finite monitoring points. On this basis, a depth neural network model is constructed according to the pressure changes of the monitoring points before and after the leakage of the water supply network, so as to locate the leakage points. In the experimental part, hydraulics simulation was conducted by using EPANETH pipe network adjustment software according to the layout structure of water supply network, and the pressure of all nodes was obtained. A deep neural network model was established by Keras in Tensorflow framework. After model training and testing, the training error was controlled within the effective range of 5 %. Finally, the model is applied to the actual leakage problem of underground water supply network in Langxi County of Xuancheng City, and the accurate location of the leakage point is realized. The experiment proves the feasibility and accuracy of the method proposed in this paper.",https://ieeexplore.ieee.org/document/9700905/,2022 International Seminar on Computer Science and Engineering Technology (SCSET),8-9 Jan. 2022,ieeexplore
10.1109/JIOT.2021.3100068,ASTCN: An Attentive Spatial–Temporal Convolutional Network for Flow Prediction,IEEE,Journals,"Flow prediction attracts intensive research interests, since it can offer essential support to many crucial problems in public safety and smart city, e.g., epidemic spread prediction and medical resource allocation optimization. Among all the models in flow prediction, deep learning models (e.g., convolutional neural networks, recurrent neural networks, and graph neural networks) are popular and outperform other statistics and machine learning models, since they can learn intrinsic structures and extract features from spatial–temporal (ST) data. However, most of them set strict temporal periods in the prediction or separate the interaction between spatial and temporal correlations. Therefore, the prediction accuracy is affected. To overcome the difficulties, we propose a flow prediction network attentive spatial–temporal convolutional network (ASTCN), which can effectively handle large-scale flow data and learn complex features. In ASTCN, we leverage an attention mechanism to overcome the previous problem of strict temporal periods, and can effectively fuse ST data with multiple factors from different time-series sources. Furthermore, we propose a causal 3-D convolutional layer based on temporal convolutional networks (TCNs). It can simultaneously extract both spatial and temporal features to improve the prediction accuracy. We comprehensively conducted our experiments based on real-world data sets. Experimental results show that ASTCN outperforms the state-of-the-art methods by at least 3.78% in root mean square error. Therefore, ASTCN is a potential solution to other large-scale ST problems.",https://ieeexplore.ieee.org/document/9511315/,IEEE Internet of Things Journal,"1 March1, 2022",ieeexplore
10.1109/TII.2021.3091597,Optimal Sizing and Efficient Routing of Electric Vehicles for a Vehicle-on-Demand System,IEEE,Journals,"Due to the steep rise in global population, urbanization, and industrialization, most of the cities in the world today are witnessing increased carbon footprints and reduced per capita space. In such a scenario, vehicle sharing and carpooling systems, specifically with electric vehicles (EV), can significantly help due to the reduced cost of ownership, maintenance, and parking space. In this article, we study the challenging problem of optimal sizing and efficient routing for an electric vehicle-on-demand system. Users demand EVs at the pooling stations at different time instances with individual deadlines to reach the destinations. The objective is to fulfill all the demands respecting the deadlines with minimum investment, which essentially translates to minimizing the total number of EVs. We define the problem formally using mixed-integer linear programming formulation and propose a set of intelligent and efficient heuristic algorithms to solve it efficiently. The proposed algorithms’ performances are tested and validated in a simulated environment on a reasonable size city network with many EV demands. The results obtained show that the proposed heuristic algorithms are competent by reducing 200–360 EVs per day on a network of 282 charging ports, indicating their scalability to be implemented in real-world scenarios.",https://ieeexplore.ieee.org/document/9462468/,IEEE Transactions on Industrial Informatics,March 2022,ieeexplore
10.1109/TITS.2020.3029537,Spatial Positioning Token (SPToken) for Smart Mobility,IEEE,Journals,"We introduce a permissioned distributed ledger technology (DLT) design for crowdsourced smart mobility applications. This architecture is based on a directed acyclic graph architecture (similar to the IOTA tangle) and uses both Proof-of-Work and Proof-of-Position mechanisms to provide protection against spam attacks and malevolent actors. In addition to enabling individuals to retain ownership of their data and to monetize it, the architecture is also suitable for distributed privacy-preserving machine learning algorithms, is lightweight, and can be implemented in simple internet-of-things (IoT) devices. To demonstrate its efficacy, we apply this framework to reinforcement learning settings where a third party is interested in acquiring information from agents. In particular, one may be interested in sampling an unknown vehicular traffic flow in a city, using a DLT-type architecture and without perturbing the density, with the idea of realizing a set of virtual tokens as surrogates of real vehicles to explore geographical areas of interest. These tokens, whose authenticated position determines write access to the ledger, are thus used to emulate the probing actions of commanded (real) vehicles on a given planned route by “jumping” from a passing-by vehicle to another to complete the planned trajectory. Consequently, the environment stays unaffected (i.e., the autonomy of participating vehicles is not influenced by the algorithm), regardless of the number of emitted tokens. The design of such a DLT architecture is presented, and numerical results from large-scale simulations are provided to validate the proposed approach.",https://ieeexplore.ieee.org/document/9238413/,IEEE Transactions on Intelligent Transportation Systems,Feb. 2022,ieeexplore
10.1109/JIOT.2021.3097768,User-Aware and Flexible Proactive Caching Using LSTM and Ensemble Learning in IoT-MEC Networks,IEEE,Journals,"To meet the stringent demands of emerging Internet-of-Things (IoT) applications, such as smart home, smart city, and virtual reality in 5G/6G IoT networks, edge content caching for mobile/multiaccess edge computing (MEC) has been identified as a promising approach to improve the quality of services in terms of latency and energy consumption. However, the limitations of cache capacity make it difficult to develop an effective common caching framework that satisfies diverse user preferences. In this article, we propose a new content caching strategy that maximizes the cache hit ratio through flexible prediction in dynamically changing network and user environments. It is based on a hierarchical deep learning architecture: long short-term memory (LSTM)-based local learning and ensemble-based meta-learning. First, as a local learning model, we employ an LSTM method with seasonal-trend decomposition using loess (STL)-based preprocessing. It identifies the attributes for demand prediction on the contents in various demographic user groups. Second, as a metalearning model, we employ a regression-based ensemble learning method, which uses an online convex optimization framework and exhibits sublinear “regret” performance. It orchestrates the obtained multiple demographic user preferences into a unified caching strategy in real time. Extensive experiments were conducted on the popular MovieLens data sets. It was shown that the proposed control provides up to a 30% higher cache hit ratio than conventional representative algorithms and a near-optimal cache hit ratio within approximately 9% of the optimal caching scheme with perfect prior knowledge of content popularity. The proposed learning and caching control can be implemented as a core function of the 5G/6G standard’s network data analytic function (NWDAF) module.",https://ieeexplore.ieee.org/document/9488291/,IEEE Internet of Things Journal,"1 March1, 2022",ieeexplore
10.1109/TNSE.2021.3050781,VFChain: Enabling Verifiable and Auditable Federated Learning via Blockchain Systems,IEEE,Journals,"Advanced artificial intelligence techniques, such as federated learning, has been applied to broad areas, e.g., image classification, speech recognition, smart city, and healthcare. Despite intensive research on federated learning, existing schemes are vulnerable to attacks and can hardly meet the security requirements for real-world applications. The problem of designing a secure federated learning framework to ensure the correctness of training procedure has not been sufficiently studied and remains open. In this paper, we propose VFChain, a verifiable and auditable federated learning framework based on the blockchain system. First, to provide the verifiability, a committee is selected through the blockchain to collectively aggregate models and record verifiable proofs in the blockchain. Then, to provide the auditability, a novel authenticated data structure is proposed for blockchain to improve the search efficiency of verifiable proofs and support a secure rotation of committee. Finally, to further improve the search efficiency, an optimization scheme is proposed to support multiple-model learning tasks. We implement VFChain and conduct extensive experiments by utilizing the popular deep learning models over the public real-world dataset. The evaluation results demonstrate the effectiveness of our proposed VFChain system.",https://ieeexplore.ieee.org/document/9321132/,IEEE Transactions on Network Science and Engineering,1 Jan.-Feb. 2022,ieeexplore
10.1109/CCNC49033.2022.9700515,CAVE-VR and Unity Game Engine for Visualizing City Scale 3D Meshes,IEEE,Conferences,"Modeling and simulation of large urban regions is beneficial for a range of applications including intelligent transportation, smart cities, infrastructure planning, and training artificial intelligence for autonomous navigation systems including ground vehicles and aerial drones. Immersive environments including virtual reality (VR), augmented reality (AR), mixed reality (MR or XR) can be used to explore city scale regions for planning, design, training and operations. Virtual environments are in the midst of rapid change as innovations in display tech-nologies, graphics processors and game engine software present new opportunities for incorporating modeling and simulation into engineering workflows. Game engine software like Unity with photorealistic rendering and realistic physics have plug-in support for a variety of virtual environments. In this paper, we explore the visualization of urban scale real world accurate meshes in virtual environments, including the Microsoft HoloLens head mounted display or the CAVE VR for multi-user interaction.",https://ieeexplore.ieee.org/document/9700515/,2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC),8-11 Jan. 2022,ieeexplore
10.1109/CCNC49033.2022.9700725,Mitigating Location-based Attacks Using Predication Models in Vehicular Ad-Hoc Networks,IEEE,Conferences,"The modern world is constantly in a state of technological revolution. Everyday new technological ideas, inventions, and threats emerge. With modern computer software and hardware advancements, we have the emergence of the Internet of Things (IoT). In conjunction, modern car companies have a push from public demand for a fully-autonomous car. To accomplish autonomy, small, and secure Vehicular Ad-Hoc Networks (VANETs) it is necessary to ensure that the systems that rely on connected vehicle data is reliable and accurate. In the event there is a malicious actor manipulating the data through replica and injection attacks or there is a hardware failure yielding inaccurate location information, it is necessary to explore efficient methods for predicting connected vehicles locations such that these systems, which rely on accurate information are not impacted. This study analyzes multiple clustering and prediction models to discover how effectively a multi-layered machine learning approach is able to meet the real-time requirement of future generation smart cities.",https://ieeexplore.ieee.org/document/9700725/,2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC),8-11 Jan. 2022,ieeexplore
10.1109/CCNC49033.2022.9700676,QoS-Aware Priority-Based Task Offloading for Deep Learning Services at the Edge,IEEE,Conferences,"Emerging Edge Computing (EC) technology has shown promise for many delay-sensitive Deep Learning (DL) based applications of smart cities in terms of improved Quality-of-Service (QoS). EC requires judicious decisions which jointly consider the limited capacity of the edge servers and provided QoS of DL-dependent services. In a smart city environment, tasks may have varying priorities in terms of when and how to serve them; thus, priorities of the tasks have to be considered when making resource management decisions. In this paper, we focus on finding optimal offloading decisions in a three-tier user-edge-cloud architecture while considering different priority classes for the DL-based services and making a trade-off between a task’s completion time and the provided accuracy by the DL-based service. We cast the optimization problem as an Integer Linear Program (ILP) where the objective is to maximize a function called gain of system (GoS) defined based on provided QoS and priority of the tasks. We prove the problem is NP-hard. We then propose an efficient offloading algorithm, called PGUS, that is shown to achieve near-optimal results in terms of the provided GoS. Finally, we compare our proposed algorithm, PGUS, with heuristics and a state-of-the-art algorithm, called GUS, using both numerical analysis and real-world implementation. Our results show that PGUS outperforms GUS by a factor of 45% in average in terms of serving the top 25% higher priority classes of the tasks while still keeping the overall percentage of the dropped tasks minimal and the overall gain of system maximized.",https://ieeexplore.ieee.org/document/9700676/,2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC),8-11 Jan. 2022,ieeexplore
10.1109/TII.2021.3077865,A Data Stream Cleaning System Using Edge Intelligence for Smart City Industrial Environments,IEEE,Journals,"Cities are becoming smarter because of recent advances in artificial intelligence and the Internet of Things. However, heterogeneous data source in smart cities are continuously producing low-quality data, and ever-growing applications have greater real-time requirements. Therefore, this article proposes a data stream cleaning system (named DSCS) using edge intelligence to utilize the advantages of cloud servers and edge devices. The DSCS in edge nodes consists of a dynamic protocol interpreter, a structure parser, and a cleaning model activator. Meanwhile, a cloud server, which has pools of protocol and structured programs and cleaning models, supports the edge nodes to adapt massive heterogeneous data sources. To validate the proposed data cleaning system, we applied it to two scenarios: monitoring the injection molding machines, and base stations. The DSCS can have a stable processing time when the number of accessed edge devices is increased, as well as a good cleaning effect.",https://ieeexplore.ieee.org/document/9424956/,IEEE Transactions on Industrial Informatics,Feb. 2022,ieeexplore
10.1109/TII.2021.3091597,Optimal Sizing and Efficient Routing of Electric Vehicles for a Vehicle-on-Demand System,IEEE,Journals,"Due to the steep rise in global population, urbanization, and industrialization, most of the cities in the world today are witnessing increased carbon footprints and reduced per capita space. In such a scenario, vehicle sharing and carpooling systems, specifically with electric vehicles (EV), can significantly help due to the reduced cost of ownership, maintenance, and parking space. In this article, we study the challenging problem of optimal sizing and efficient routing for an electric vehicle-on-demand system. Users demand EVs at the pooling stations at different time instances with individual deadlines to reach the destinations. The objective is to fulfill all the demands respecting the deadlines with minimum investment, which essentially translates to minimizing the total number of EVs. We define the problem formally using mixed-integer linear programming formulation and propose a set of intelligent and efficient heuristic algorithms to solve it efficiently. The proposed algorithms’ performances are tested and validated in a simulated environment on a reasonable size city network with many EV demands. The results obtained show that the proposed heuristic algorithms are competent by reducing 200–360 EVs per day on a network of 282 charging ports, indicating their scalability to be implemented in real-world scenarios.",https://ieeexplore.ieee.org/document/9462468/,IEEE Transactions on Industrial Informatics,March 2022,ieeexplore
10.1109/TITS.2020.3015542,Taxi Demand Prediction Using Parallel Multi-Task Learning Model,IEEE,Journals,"Accurate and real-time taxi demand prediction can help managers pre-allocate taxi resources in cities, which assists drivers quickly finding passengers and reduce passengers’ waiting time. Most of the existing studies focus on mining spatial-temporal characteristics of taxi demand distributions, while lacking in modeling the correlations between taxi pick-up demand and the drop-off demand from the perspective of multi-task learning. In this article, we propose a multi-task learning model containing three parallel LSTM layers to co-predict taxi pick-up and drop-off demands, and compare the performance of single demand prediction methodology and that of two demands’ co-prediction methodology. Experimental results on real-world datasets demonstrate that the pick-up demand and the drop-off demand do depend on each other, and the effectiveness of the proposed co-prediction methods.",https://ieeexplore.ieee.org/document/9172100/,IEEE Transactions on Intelligent Transportation Systems,Feb. 2022,ieeexplore
10.1109/TITS.2020.3029537,Spatial Positioning Token (SPToken) for Smart Mobility,IEEE,Journals,"We introduce a permissioned distributed ledger technology (DLT) design for crowdsourced smart mobility applications. This architecture is based on a directed acyclic graph architecture (similar to the IOTA tangle) and uses both Proof-of-Work and Proof-of-Position mechanisms to provide protection against spam attacks and malevolent actors. In addition to enabling individuals to retain ownership of their data and to monetize it, the architecture is also suitable for distributed privacy-preserving machine learning algorithms, is lightweight, and can be implemented in simple internet-of-things (IoT) devices. To demonstrate its efficacy, we apply this framework to reinforcement learning settings where a third party is interested in acquiring information from agents. In particular, one may be interested in sampling an unknown vehicular traffic flow in a city, using a DLT-type architecture and without perturbing the density, with the idea of realizing a set of virtual tokens as surrogates of real vehicles to explore geographical areas of interest. These tokens, whose authenticated position determines write access to the ledger, are thus used to emulate the probing actions of commanded (real) vehicles on a given planned route by “jumping” from a passing-by vehicle to another to complete the planned trajectory. Consequently, the environment stays unaffected (i.e., the autonomy of participating vehicles is not influenced by the algorithm), regardless of the number of emitted tokens. The design of such a DLT architecture is presented, and numerical results from large-scale simulations are provided to validate the proposed approach.",https://ieeexplore.ieee.org/document/9238413/,IEEE Transactions on Intelligent Transportation Systems,Feb. 2022,ieeexplore
10.1109/TII.2021.3071771,A Utility-Based Subcontract Method for Sensing Task in Mobile Crowd Sensing,IEEE,Journals,"In mobile crowd sensing, the mobile terminal integrates a variety of widely distributed sensing devices and communication ports. Sensing devices and communication ports can collect and share all kinds of perception data. However, inherent contradictions exist among perceived ability, communication port, and moving rule while collecting real-time and accurate sensing information. This article mainly focused on recruited and selected mobile nodes and assigned sensing tasks to improve the quality of sensing information. The optimization of the implementation stage of the sensing task is beyond the scope of this study. This article proposes a utility-based sensing task decomposition and subcontract algorithm, which is a method of sensing data acquisition that establishes direct collaboration between mobile nodes. A mobility model based on Markov chain is established to forecast the spatial distribution of sensing nodes. A utility function is designed to estimate the sensing task execution capacity of sensing nodes based on spatial distribution and tempo-spatial coverage of the collected data. The sensing tasks are then decomposed and subcontracted to neighboring nodes according to the utilities of the neighboring nodes to the decomposed sensing tasks. This method improves the quality of sensing data in terms of sensing data coverage and finished ratio of sensing task.",https://ieeexplore.ieee.org/document/9399247/,IEEE Transactions on Industrial Informatics,Feb. 2022,ieeexplore
10.1109/ACCESS.2022.3146728,Assistive Devices Analysis for Visually Impaired Persons: A Review on Taxonomy,IEEE,Journals,"Visually impaired persons (VIPs) comprise a significant portion of the population and they are present in all corners of the world. In recent times, the technology proved its presence in every domain of life and innovative devices are assisting humans in all fields especially, artificial intelligence has dominated and outperformed the rest of the trades. VIPs need assistance in performing daily life tasks like object/obstacle detection and recognition, navigation, and mobility, particularly in indoor and outdoor environments. Moreover, the protection and safety of these people are of prime concern. Several devices and applications have been developed for the assistance of VIPs. Firstly, these devices take input from the surrounding environment through different sensors e.g. infrared radiation, ultrasonic, imagery sensor, etc. In the second stage, state of the art machine learning techniques process these signals and extract useful information. Finally, feedback is provided to the user through auditory and/or vibratory means. It is observed that most of the existing devices are constrained in their abilities. The paper presents a comprehensive comparative analysis of the state-of-the-art assistive devices for VIPs. These techniques are categorized based on their functionality and working principles. The main attributes, challenges, and limitations of these techniques have also been highlighted. Moreover, a score-based quantitative analysis of these devices is performed to highlight their feature enrichment capability for each category. It may help to select an appropriate device for a particular scenario.",https://ieeexplore.ieee.org/document/9693966/,IEEE Access,2022,ieeexplore
10.1109/TNSE.2021.3072911,Prioritized Content Determination and Dissemination Using Reinforcement Learning in DTNs,IEEE,Journals,"In a battlefield, several groups of soldiers are deployed with different mission goals by the command and control center (CC). To continue the missions appropriately and get a better understanding of the situation, the soldiers, as well as the CC, need to collect information of interest generated in different battle zones. However, due to the damaged network infrastructure in the hostile areas, it is a challenge to determine the topics of interest associated with the events and missions, and efficiently forward the associated content to the CC. Hence, the devices of the soldiers (nodes) generate, store and forward content hop by hop using a Delay Tolerant Network (DTN). While forwarding content, nodes avoid congestion so that meaningful content related to prioritized mission goals can be disseminated. In this dynamic surrounding, any sudden but important event-related content should also be sent to the CC with the help of intermediate nodes regardless of their own mission interests. We design a scheme to forward contents generated by the nodes to the CC using Reinforcement Learning (RL) while maximizing the number of interesting data in the respective nodes' buffer, and avoiding congestion. In this forwarding process, we focus on identifying the trending topics/keywords among changing missions and their related data at the node level, and the changes of interest of the nodes based on their mobility and connectivity patterns. Experiments are conducted using real datasets and ONE simulator to show the effectiveness of Reinforcement Learning (RL) on the prioritized content dissemination in a DTN.",https://ieeexplore.ieee.org/document/9403937/,IEEE Transactions on Network Science and Engineering,1 Jan.-Feb. 2022,ieeexplore
10.1109/TITS.2020.3029537,Spatial Positioning Token (SPToken) for Smart Mobility,IEEE,Journals,"We introduce a permissioned distributed ledger technology (DLT) design for crowdsourced smart mobility applications. This architecture is based on a directed acyclic graph architecture (similar to the IOTA tangle) and uses both Proof-of-Work and Proof-of-Position mechanisms to provide protection against spam attacks and malevolent actors. In addition to enabling individuals to retain ownership of their data and to monetize it, the architecture is also suitable for distributed privacy-preserving machine learning algorithms, is lightweight, and can be implemented in simple internet-of-things (IoT) devices. To demonstrate its efficacy, we apply this framework to reinforcement learning settings where a third party is interested in acquiring information from agents. In particular, one may be interested in sampling an unknown vehicular traffic flow in a city, using a DLT-type architecture and without perturbing the density, with the idea of realizing a set of virtual tokens as surrogates of real vehicles to explore geographical areas of interest. These tokens, whose authenticated position determines write access to the ledger, are thus used to emulate the probing actions of commanded (real) vehicles on a given planned route by “jumping” from a passing-by vehicle to another to complete the planned trajectory. Consequently, the environment stays unaffected (i.e., the autonomy of participating vehicles is not influenced by the algorithm), regardless of the number of emitted tokens. The design of such a DLT architecture is presented, and numerical results from large-scale simulations are provided to validate the proposed approach.",https://ieeexplore.ieee.org/document/9238413/,IEEE Transactions on Intelligent Transportation Systems,Feb. 2022,ieeexplore
10.1109/OJITS.2021.3139393,NAPC: A Neural Algorithm for Automated Passenger Counting in Public Transport on a Privacy-Friendly Dataset,IEEE,Journals,"Real-time load information in public transport is of high importance for both passengers and service providers. Neural algorithms have shown a high performance on various object counting tasks and play a continually growing methodological role in developing automated passenger counting systems. However, the publication of public-space video footage is often contradicted by legal and ethical considerations to protect the passengers’ privacy. This work proposes an end-to-end Long Short-Term Memory network with a problem-adapted cost function that learned to count boarding and alighting passengers on a publicly available, comprehensive dataset of approx.13,000 manually annotated low-resolution 3D LiDAR video recordings (depth information only) from the doorways of a regional train. These depth recordings do not allow the identification of single individuals. For each door opening phase, the trained models predict the correct passenger count (ranging from 0 to 67) in approx.96% of boarding and alighting, respectively. Repeated training with different training and validation sets confirms the independence of this result from a specific test set.",https://ieeexplore.ieee.org/document/9665722/,IEEE Open Journal of Intelligent Transportation Systems,2022,ieeexplore
10.1109/JSEN.2021.3132460,Automatic Rail Component Detection Based on AttnConv-Net,IEEE,Journals,"The automatic detection of major rail components using railway images is beneficial to ensure the rail transport safety. In this paper, we propose an attention-powered deep convolutional network (AttnConv-net) to detect multiple rail components including the rail, clips, and bolts. The proposed method consists of a deep convolutional neural network (DCNN) as the backbone, cascading attention blocks (CAB), and two feed forward networks (FFN). Two types of positional embedding are applied to enrich information in latent features extracted from the backbone. Based on processed latent features, the CAB aims to learn the local context of rail components including their categories and component boundaries. Final categories and bounding boxes are generated via two FFN implemented in parallel. To enhance the detection of small components, various data augmentation methods are employed in training process. The effectiveness of the proposed AttnConv-net is validated with one real dataset and another synthesized dataset. Compared with classic convolutional neural network based methods, our proposed method simplifies the detection pipeline by eliminating the need of prior- and post-processing, which offers a new speed-quality solution to enable faster and more accurate image-based rail component detections.",https://ieeexplore.ieee.org/document/9634063/,IEEE Sensors Journal,"1 Feb.1, 2022",ieeexplore
10.1109/ACCESS.2022.3141913,Decentralized Federated Learning for Healthcare Networks: A Case Study on Tumor Segmentation,IEEE,Journals,"Smart healthcare relies on artificial intelligence (AI) functions for learning and analysis of patient data. Since large and diverse datasets for training of Machine Learning (ML) models can rarely be found in individual medical centers, classical centralized AI requires moving privacy-sensitive data from medical institutions to data centers that process the fused information. Training on data centers thus requires higher communication resource/energy demands while violating privacy. This is considered today as a significant bottleneck in pursuing scientific collaboration across trans-national clinical medical research centers. Recently, federated learning (FL) has emerged as a distributed AI approach that enables the cooperative training of ML models, without the need of sharing patient data. This paper dives into the analysis of different FL methods and proposes a real-time distributed networking framework based on the Message Queuing Telemetry Transport (MQTT) protocol. In particular, we design a number of solutions for ML over networks, based on FL tools relying on a parameter server (PS) and fully decentralized paradigms driven by consensus methods. The proposed approach is validated in the context of brain tumor segmentation, using a modified version of the popular U-NET model with representative clinical datasets obtained from the daily clinical workflow. The FL process is implemented on multiple physically separated machines located in different countries and communicating over the Internet. The real-time test-bed is used to obtain measurements of training accuracy vs. latency trade-offs, and to highlight key operational conditions that affect the performance in real deployments.",https://ieeexplore.ieee.org/document/9676574/,IEEE Access,2022,ieeexplore
10.1109/OJITS.2021.3139393,NAPC: A Neural Algorithm for Automated Passenger Counting in Public Transport on a Privacy-Friendly Dataset,IEEE,Journals,"Real-time load information in public transport is of high importance for both passengers and service providers. Neural algorithms have shown a high performance on various object counting tasks and play a continually growing methodological role in developing automated passenger counting systems. However, the publication of public-space video footage is often contradicted by legal and ethical considerations to protect the passengers’ privacy. This work proposes an end-to-end Long Short-Term Memory network with a problem-adapted cost function that learned to count boarding and alighting passengers on a publicly available, comprehensive dataset of approx.13,000 manually annotated low-resolution 3D LiDAR video recordings (depth information only) from the doorways of a regional train. These depth recordings do not allow the identification of single individuals. For each door opening phase, the trained models predict the correct passenger count (ranging from 0 to 67) in approx.96% of boarding and alighting, respectively. Repeated training with different training and validation sets confirms the independence of this result from a specific test set.",https://ieeexplore.ieee.org/document/9665722/,IEEE Open Journal of Intelligent Transportation Systems,2022,ieeexplore
