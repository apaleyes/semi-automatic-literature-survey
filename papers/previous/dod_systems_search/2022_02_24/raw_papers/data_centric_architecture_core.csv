id,datePublished,description,title,doi,downloadUrl,publisher,journals,database
22878944,2007,"Data is becoming increasingly crucial for training and (self-) evaluation of spoken dialog systems (SDS). Data is used to train models (e.g. acoustic models) and is ‘forgotten’. Data is generated on-line from the different components of the SDS system, e.g. the dialog manager, as well as from the world it is interacting with (e.g. news streams, ambient sensors etc.). The data is used to evaluate and analyze conversational systems both on-line and off-line. We need to be able query such heterogeneous data for further processing. In this paper we present an approach with two novel components: first, an architecture for SDSs that takes a data-centric view, ensuring persistency and consistency of data as it is generated. The architecture is centered around a database that stores dialog data beyond the lifetime of individual dialog sessions, facilitating dialog mining, annotation, and logging. Second, we take advantage of the state-fullness of the data-centric architecture by means of a lightweight, reactive and inference-based dialog manager that itself is stateless. The feasibility of our approach has been validated within a phone-based university help-desk application. We detail SDS architecture and dialog management, model, and data representation",A Data-Centric Architecture for Data-Driven Spoken Dialog Systems,10.1109/asru.2007.4430168,https://core.ac.uk/download/pdf/22878944.pdf,,,core
100035025,2012,"Opportunistic networks are a subset of delay tolerant networks where the contacts are unscheduled. Such networks can be formed ad hoc by wire-less devices, such as mobile phones and laptops. In this work we use a data-centric architecture for opportunistic networks to evaluate data dis-semination overhead, congestion in nodes ’ buffer, and the impact of transfer ordering. Dissemination brings an overhead since data is replicated to be spread in the network and overhead leads to congestion, i.e., overloaded buffers. We develop and implement an emulation testbed to experimentally eval-uate properties of opportunistic networks. We evaluate the repeatability of experiments in the emulated testbed that is based on virtual computers. We show that the timing variations are on the order of milliseconds. The testbed was used to investigate overhead in data dissemination, congestion avoidance, and transfer ordering in opportunistic networks. We show that the overhead can be reduced by informing other nodes in the network about what data a node is carrying. Congestion avoidance was evaluated in terms of buffer management, since that is the available tool in an opportunistic network, to handle congestion. It was shown that replication information of data objects in the buffer yields the best results. We show that in a data-centric architecture were each data item is valued differently, transfer ordering is important to achieve delivery of the most valued data. 1 ",Measurements in Opportunistic Networks,,,,,core
344667711,2020-05-01T07:00:00,"Internet of Things (IoT) has great potential in enabling many beneficial applications (i.e., connected vehicle applications). Named Data Networking (NDN) recently emerges as a promising networking paradigm in supporting IoT due to its data-centric architecture. In this dissertation, we present our research on design a scalable, efficient and secure ndn-based data retrieval framework for Internet of Things. Our work includes three parts:First, we envision an NDN-based Connected Vehicles (CV) application framework with a distributed data service model, as CV is a typical scenario of IoT. The scalability of the framework is greatly challenged by the fast mobility and vast moving area of vehicles. To handle such an issue, we develop a novel hyperbolic hierarchical NDN backbone architecture (H2NDN) by exploiting the location dependency of CV applications. H2NDN designs the backbone routers topology and the data/interest namespace by following the hierarchical architecture of geographic locations. The efficient data searching only requires static forwarding information base (FIB) configuration over NDN routers. To avoid overloading high-level routers, H2NDN integrates hyperbolic routing through carefully designed hyperbolic planes.Second, a distributed adaptive caching strategy is proposed to improve the efficiency of data caches on NDN routers. NDN provides native support to cache data at routers for future Interest packets. As we model the caching problem, the goal of cache allocation is to maximize the savings of Interest/Data forwarding hops under the limited cache space on each router. We discuss the impracticality of global optimization and provide the local caching method. Extensive ndnSIM based simulation with real traffic data proves the efficiency and scalability of the proposed H2NDN architecture.Finally, although NDN provides some security advantages such as secures data directly and uses name semantics to enable applications to reason about security, employing NDN to support IoT applications nevertheless presents some new challenges about security. In this dissertation, we focus on two resultant attacks that are not effectively handled in current studies, namely the targeted blackhole attack and the targeted content poisoning attack. We propose a lightweight and efficient approach named SmartDetour to tackle the two attacks. To ensure high scalability and collusion-resilience, SmartDetour lets each router respond to attacks (i.e., packet drops or corrupted data) independently in order to isolate attackers. The core solution contains a reputation-based probabilistic forwarding strategy and a proactive attacker detection algorithm. Extensive ndnSIM based simulation demonstrates the efficiency and accuracy of the proposed SmartDetour",DESIGN A SCALABLE AND SECURE NDN-BASED DATA RETRIEVAL FRAMEWORK FOR INTERNET OF THINGS,,,OpenSIUC,,core
23201345,2013-09-24,"We present the ADAMACH data centric dialog system, that allows to perform on- and offline mining of dialog context, speech recognition results and other system-generated representations, both within and across dialogs. The architecture implements a “fat pipeline” for speech and language processing. We detail how the approach integrates domain knowledge and evolving empirical data, based on a user study in the University Helpdesk domain. ",S.: Persistent Information State in a Data-Centric Architecture,,,,,core
24476356,2003,"Traditional database system architectures face a rapidly evolving operating environment, where millions of users store and access terabytes of data. In order to cope with increasing demands for performance, high-end DBMS employ parallel processing techniques coupled with a plethora of sophisticated features. However, the widely adopted, work-centric, thread-parallel execution model entails several shortcomings that limit server performance when executing workloads with changing requirements. Moreover, the monolithic approach in DBMS software has lead to complexanddifficulttoextenddesigns. This paper introduces a staged design for high-performance, evolvable DBMS that are easy to tune and maintain. We propose to break the database system into modules and to encapsulate them into self-contained stages connected to each other through queues. The staged, data-centric design remedies the weaknesses of modern DBMS by providing solutions at both a hardware and a software engineering level. ",A Case for Staged Database Systems,,,,,core
402919123,2020-11-22T22:01:43,"© 2013 IEEE. MapReduce plays a critical role as a leading framework for big data analytics. In this paper, we consider a geo-distributed cloud architecture that provides MapReduce services based on the big data collected from end users all over the world. Existing work handles MapReduce jobs by a traditional computation-centric approach that all input data distributed in multiple clouds are aggregated to a virtual cluster that resides in a single cloud. Its poor efficiency and high cost for big data support motivate us to propose a novel data-centric architecture with three key techniques, namely, cross-cloud virtual cluster, data-centric job placement, and network coding based traffic routing. Our design leads to an optimization framework with the objective of minimizing both computation and transmission cost for running a set of MapReduce jobs in geo-distributed clouds. We further design a parallel algorithm by decomposing the original large-scale problem into several distributively solvable subproblems that are coordinated by a high-level master problem. Finally, we conduct real-world experiments and extensive simulations to show that our proposal significantly outperforms the existing works",Cross-Cloud MapReduce for Big Data,10.1109/TCC.2015.2474385,http://hdl.handle.net/10453/144234,'Institute of Electrical and Electronics Engineers (IEEE)',"[{'title': 'IEEE Transactions on Cloud Computing', 'identifiers': ['issn:2168-7161', '2168-7161']}]",core
21878955,2001,"This article begins by introducing a data-centric  architecture that abstracts collaborative tasks as  editing of data repositories, followed by descriptions  of the role of XML in managing heterogeneity  and intelligent software agents in discovering  network and computing environment condition",Adaptive Collaboration for Wired and Wireless Platforms - A data-centric architecture for collaboration environments uses XML to adapt shared data dynamically between devices with widely disparate capabilities.,,,,,core
21876091,2001,"Emacspeak has pioneered the speech-enabling approach to providing intelligent  spoken feedback for a variety of daily computing tasks. This includes audio  formatted output from World Wide Web (WWW) pages by utilizing Aural Cascading  Style Sheets (ACSS). However, until recently such spoken output has been  limited by presentational HTML pages optimized for visual interaction.  The WWW is presently transitioning toward a data-centric architecture; content  ---and its semantics--- is encapsulated in XML ([W3C98]) pages designed to  be served in a manner most appropriate to a given client. This opens up significant  opportunities in generating high-quality spoken feedback from richly encoded  WWW content. Though XML is still in its early stages of wide-spread adoption,  some of the benefits to come can already be seen today. Many sites now offer  access to both presentational HTML, as well as the underlying data. Examples  include historical stock charts, driving directions, and other useful information.  Emacspeak now exploits the availability of such semantically encoded content  to provide a richer end-user experience. This article introduces some of the data  acquisition techniques used in Emacspeak and focuses on the end-user experience  when interacting with such structured information.  ",Emacspeak - Toward The Speech-enabled Semantic WWW,,,,,core
21163422,2009,"This chapter describes a design methodology for business processes and workflows that focuses first on “business artifacts”, which represent key (real or conceptual) business entities, including both the business-relevant data about them and their macro-level lifecycles. Individual workflow services (a.k.a. tasks) are then incorporated, by specifying how they operate on the artifacts and fit into their lifecycles. The resulting workflow is specified in a particular artifact-centric workflow model, which is introduced using an extended example. At the logical level this workflow model is largely declarative, in contrast with most traditional workflow models which are procedural and/or graph-based. The chapter includes a discussion of how the declarative, artifact-centric workflow specification can be mapped into an optimized physical realization. 1",A data-centric design methodology for business processes,,,,,core
21082391,2009-11-19,"The complexity of developing and deploying context-aware pervasive-computing applications calls for distributed software infrastructures that assist applications to collect, aggregate, and disseminate contextual data. In this paper, we motivate a data-centric design for such an infrastructure to support context-aware applications. Our middleware system, Solar, treats contextual data sources as stream publishers and the core of Solar is a scalable and self-organizing peer-to-peer overlay to support data-driven services. We present how different services could be systematically integrated on top of the Solar overlay. We also discuss our experience and lessons learned when using Solar to support several implemented scenarios. We conclude that a data-centric infrastructure is necessary to facilitate both development and deployment of pervasive-computing applications",Data-Centric Middleware for Context-Aware Pervasive Computing,,,,,core
101189216,2015-01-16,"We present the ADAMACH data centric dia-log system, that allows to perform on- and off-line mining of dialog context, speech recog-nition results and other system-generated rep-resentations, both within and across dialogs. The architecture implements a “fat pipeline” for speech and language processing. We detail how the approach integrates domain knowl-edge and evolving empirical data, based on a user study in the University Helpdesk domain. ",S.: Persistent Information State in a Data-Centric Architecture,,,,,core
49712450,2013-03-25T00:00:00,"International audienceContent-Centric Networking (CCN) is a promising data-centric architecture, based on in-network caching, name-driven routing, and receiver-initiated sessions, which can greatly enhance the way Internet resources are currently used, making support for a broader set of users with increasing traffic demands possible. The CCN vision is, currently, attracting the attention of many researchers across the world, since it has all the potential to become ready to the market, to be gradually deployed in the Internet of today, and to facilitate a graceful transition from a host-centric networking rationale to a more effective data-centric working behaviour. At the same time, several issues have to be investigated before CCN can be safely deployed at the Internet scale. They include routing, congestion control, caching operations, name-space planning, and application design. With reference to application-related facets, it is worth noticing that the demand for TV services is growing at an exponential rate over time, thus requiring a very careful analysis of their performance in CCN architectures. To this end, in the present contribution we deploy a CCNTV system, capable of delivering real-time streaming TV services, and we evaluate its performance through a simulation campaign based on real-world topologies",CCN-TV: a data-centric approach to real-time video services,10.1109/WAINA.2013.19,https://core.ac.uk/download/49712450.pdf,'Institute of Electrical and Electronics Engineers (IEEE)',,core
489479867,2023-06-19T00:00:00,"The effective implementation of Industry 4.0 requires the reformulation of industrial processes in order to achieve the vertical and horizontal digitalization of the value chain. For this purpose, it is necessary to provide tools that enable their successful implementation. This paper therefore proposes a data-centric, distributed, dynamically scalable reference architecture that integrates cutting-edge technologies being aware of the existence of legacy technology typically present in these environments. In order to make its implementation easier, we have designed a metamodel that collects the description of all the elements involved in a digital platform (data, resources, applications and monitoring metrics) as well as the necessary information to configure, deploy and execute applications on it. Likewise, we provide a tool compliant to the metamodel that automates the generation of configuration, deployment and launch files and their corresponding transference and execution in the nodes of the platform. We show the flexibility, extensibility and validity of our software artefacts through their application in two case studies, one addressed to preprocess and store pollution data and the other one, more complex, which simulates the management of an electric power distribution of a smart city",A big data-centric architecture metamodel for Industry 4.0,10.1016/j.future.2021.06.020,,'Elsevier BV',"[{'title': 'Future Generation Computer Systems', 'identifiers': ['issn:1872-7115', 'issn:0167-739X', '0167-739x', '1872-7115']}]",core
21082795,2009-11-19,"The complexity of developing and deploying context-aware pervasive-computing applications calls for distributed software infrastructures that assist applications to collect, aggregate, and disseminate contextual data. In this paper, we motivate a data-centric design for such an infrastructure to support context-aware applications. Our middleware system, Solar, treats contextual data sources as stream publishers. The core of Solar is a scalable and self-organizing peer-to-peer overlay to support data-driven services. We describe how different services can be systematically integrated on top of the Solar overlay and evaluate the resource-discovery and data-dissemination services. We also discuss our experience and lessons learned when using Solar to support several implemented scenarios. We conclude that a data-centric infrastructure is necessary to facilitate both development and deployment of context-aware pervasive-computing applications",Data-Centric Middleware for Context-Aware Pervasive Computing,,,,,core
20997632,2009-02-02,"Wireless sensor networks dynamic runtime configuration Abstract — Current Wireless Sensor Networks (WSN) use fixed layered architectures, that can be modified only at compile time. Using a non-layered architecture, which allows dynamic loading of modules and automatic reconfiguration to adapt to the surrounding environment was believed to be too resource consuming to be employed. We have created a so-called data centric architecture and developed a new operating system (DCOS), to support it. As we will show in this paper, the new architecture and operating system are good candidates for WSNs, allowing flexibility in the configuration and exploitation of the sensor network",,,,,,core
103016849,2013,"Big Data are becoming a new technology focus both in science and in industry and motivate technology shift to data centric architecture and operational models. There is a vital need to define the basic information/semantic models, architecture components and operational models that together comprise a so-called Big Data Ecosystem. This paper discusses a nature of Big Data that may originate from different scientific, industry and social activity domains and proposes improved Big Data definition that includes the following parts: Big Data properties ( also called Big Data 5V: Volume, Velocity, Variety, Value and Veracity), data models and structures, data analytics, infrastructure and security. The paper discusses paradigm change from traditional host or service based to data centric architecture and operational models in Big Data. The Big Data Architecture Framework (BDAF) is proposed to address all aspects of the Big Data Ecosystem and includes the following components: Big Data Infrastructure, Big Data Analytics, Data structures and models, Big Data Lifecycle Management, Big Data Security. The paper analyses requirements to and provides suggestions how the mentioned above components can address the main Big Data challenges. The presented work intends to provide a consolidated view of the Big Dat",Architecture Framework and Components for the Big Data Ecosystem Draft Version 0.2,,,,,core
327066521,2020-07-21T00:00:00,"Current operating systems are complex systems that were designed before
today's computing environments. This makes it difficult for them to meet the
scalability, heterogeneity, availability, and security challenges in current
cloud and parallel computing environments. To address these problems, we
propose a radically new OS design based on data-centric architecture: all
operating system state should be represented uniformly as database tables, and
operations on this state should be made via queries from otherwise stateless
tasks. This design makes it easy to scale and evolve the OS without
whole-system refactoring, inspect and debug system state, upgrade components
without downtime, manage decisions using machine learning, and implement
sophisticated security features. We discuss how a database OS (DBOS) can
improve the programmability and performance of many of today's most important
applications and propose a plan for the development of a DBOS proof of concept",DBOS: A Proposal for a Data-Centric Operating System,,http://arxiv.org/abs/2007.11112,,,core
37831935,2010,"Opportunistic networks are multi-hop ad hoc networks in which nodes opportunistically exploit any pair-wise contact to share and forward content, without requiring any pre-existing Internet infrastructure. Opportunistic networks tolerate partitions, long disconnections, and topology instability in general. In this challenging environment, leveraging users\u27 mobility represents the most effective way to deliver content to interested users. In this paper we propose a context- and social-aware middleware that autonomically learns context and social information on the users of the network, and that uses this information in order to predict users\u27 future movements. In order to evaluate the proposed middleware on a realistic scenario, we have designed and implemented a context- and social-aware content sharing service, exploiting the functionality of the middleware. Both the middleware and the content sharing service have been integrated with an existing data-centric architecture (the Haggle architecture) for opportunistic networks. Finally, we have validated the proposed content sharing application on a small-scale testbed and, on a larger scale, we have investigated the advantages provided by context- and social-aware sharing strategies by means of extensive simulations. The main result of this paper is the definition and implementation of a context- and social-aware middleware able to share context information with all the interested components improving the efficiency and performances of services and protocols in opportunistic networks. With respect to content sharing strategies that do not exploit context and social information, we have obtained up to 200% improvements in terms of hit rate (probability that users receive the content they request) and 99% reduction in resource consumption in terms of traffic generated on the network",Context- and Social-aware Middleware for Opportunistic Networks,10.1016/j.jnca.2010.03.017,,Elsevier,,core
482437587,2021-01-01T00:00:00,"In-The-wild research allows the HCI community to gain insights into personal behaviour and characteristics. For designers and researchers, this means having access to rich spatiotemporal insights reflecting user's characteristics, behaviours, and needs. However, designerly contexts require contextualized and meaningful data, and collecting it in-The-wild involves a great effort. In addition, ethical implications need to be considered. In this paper, we propose designerly data donation, a participatory approach for data collection in-The-wild, as an effective and ethical way to enable data-centric design processes. We present the potential benefits of designerly data donation around three axes: value gain, data contextualization, and roles and relationships. And we introduce the challenges of designerly data donation at the intersection of HCI, UbiComp, and design.Internet of ThingsIndustrial Design Engineerin",Towards Designerly Data Donation,10.1145/3460418.3479362,,'Association for Computing Machinery (ACM)',,core
31001433,2012-01-01T00:00:00,"The performance requirements for the next generations of airliners are stringent and

require invention and design of unconventional configurations departing from the classical

Cayley functional decomposition. The break with tradition calls for higher fidelity physics-

based predictions of performance early on in the project. The paper makes the case for a

unified, open, data-centric software environment for aircraft design and describes the merge

of the CEASIOM conceptual design software package, developed by a number of partners

including KTH, with the CPACS formalized data management system developed at DLR.

The system provides multi-fidelity and multi-disciplinary analysis capabilities for concur-

rent design by geographically distributed expert teams. The data-centric architecture uses

the CPACS schema and access mechanisms for management of design data across all dis-

ciplines and fidelity levels. This makes the system extensible and mitigates the problems

encountered in handing over the model to later design phases. The concepts have been

tested by interfacing external modules to CEASIOM/CPACS through a graphical CPACS

XML editor, the ACbuilder gateway. Results of comparative analyses on models imported

in this way from the RDS and VAMPzero conceptual design packages are reported here.

CPACS will be released to the general public in spring ’12. The CEASIOM team expe-

rience of joining forces via CPACS with DLR is altogether positive and further in-house

development of software for aircraft performance prediction and design by the CEASIOM

team will use the CPACS system",Towards a Unified Framework using CPACS for Geometry Management in Aircraft Design,10.2514/6.2012-549,,,,core
10560731,"May 23, 2011","The NASA Center for Climate Simulation (NCCS) provides high performance computational resources, a multi-petabyte archive, and data services in support of climate simulation research and other NASA-sponsored science. This talk describes the NCCS's data-centric architecture and processing, which are evolving in anticipation of researchers' growing requirements for higher resolution simulations and increased data sharing among NCCS users and the external science community",Data Serving Climate Simulation Science at the NASA Center for Climate Simulation,,https://core.ac.uk/download/pdf/10560731.pdf,,,core
154998673,2003-11-26,,Data Centric Architecture for Wireless Sensor Networks,,,Technology Foundation (STW),,core
21713899,2012-02-20,"We present the ADAMACH data centric dialog system, that allows to perform on- and offline mining of dialog context, speech recognition results and other system-generated representations, both within and across dialogs. The architecture implements a “fat pipeline” for speech and language processing. We detail how the approach integrates domain knowledge and evolving empirical data, based on a user study in the University Helpdesk domain. ",S.: Persistent Information State in a Data-Centric Architecture,,,,,core
11463209,2004,"Current Wireless Sensor Networks (WSN) use fixed layered architectures, that can be modified only at compile time. Using a non-layered architecture, which allows dynamic loading of modules and automatic reconfiguration to adapt to the surrounding environment was believed to be too resource consuming to be employed. We have created a so-called data centric architecture and developed a new operating system (DCOS), to support it. As we will show in this paper, the new architecture and operating system are good candidates for WSNs, allowing flexibility in the configuration and exploitation of the sensor network",Wireless sensor networks dynamic runtime configuration,,,,,core
24745372,2007,"Data-centric design is emerging as a key tenet for building advanced data-critical distributed real-time and embedded systems. These systems must find the right data, know where to send it, and deliver it to the right place at the right time. Data Distribution Service (DDS) specifies an API designed for enabling real-time data distribution and is well suited for such complex distributed systems and QoS-enabled applications. It is also, widely known that Control Area Networks (CAN) are used in real-time, distributed and parallel processing. Thus, the goal idea of this paper is to study an implementation of publish-subscribe messaging middleware that supports the DDS specifications and that is customized for real-time networking. This implementation introduces an efficient approach of data temporal consistency and real-time network-scheduler that schedules network traffic based upon DDS QoS-policies. A simulator has been developed to demonstrate that our implementation fulfills the guarantees predicted by the theoretical results. Key words: Publish-Subscribe, data distribution, Real-Time Middleware",Design and Performance of DDS-based Middleware for Real- Time Control Systems,,,,,core
51181630,2016-01-01T00:00:00,,데이터 기반 설계기법 도입에 따른 원전 건설관리체계 개선방향 고찰 (A study on improvement of nuclear power plant construction system according to data-centric design technique introduction in Korea),,,[Daejeon],,core
21015568,2009-04-07,"We present the ADAMACH data centric dialog system, that allows to perform on- and offline mining of dialog context, speech recognition results and other system-generated representations, both within and across dialogs. The architecture implements a “fat pipeline” for speech and language processing. We detail how the approach integrates domain knowledge and evolving empirical data, based on a user study in the University Helpdesk domain. ",Persistent Information State in a Data-Centric Architecture ∗,,,,,core
103546219,2014,"IXA pipeline is a modular set of Natural Language Processing tools (or pipes) which provide easy access to NLP technology. It offers robust and efficient linguistic annotation to both researchers and non-NLP experts with the aim of lowering the barriers of using NLP technology either for research purposes or for small industrial developers and SMEs. IXA pipeline can be used “as is ” or exploit its modularity to pick and change different components. Given its open-source nature, it can also be modified and extended for it to work with other languages. This paper describes the general data-centric architecture of IXA pipeline and presents competitive results in several NLP annotations for English and Spanish",IXA Pipeline: Efficient and ready to use multilingual NLP tools,,,,,core
428286807,2020-01-01T00:00:00,"Abstract

The Internet of Things makes human activity data — what people do, how they move, how they socialise — an abundant resource. However, this rich and intimate perspective on people, which uniquely shape and characterise their behaviours, can have tremendous ethical implication if data is handled irresponsibly. Being personal, contextual and accessible, mobile devices are key facilitators of (ir)responsible collection and use of data. In this workshop, we will use the Future Workshop approach to develop a research agenda towards ethical data-centric design of intelligent behaviours. As part of this approach, we will (1) criticise the current mechanisms and infrastructure to frame ethical challenges, (2) fantasise on futures which support user and designer values, and (3) implement a research agenda for the MobileHCI community to emphasise the barriers to tackle. The outcomes of this workshop will foster ethical research and inspire the MobileHCI community",DatEthics:ethical data-centric design of intelligent behaviour,,,,,core
428660119,2014-01-01T00:00:00,"Big Data are becoming a new technology focus both in science and in industry and motivate technology shift to data centric architecture and operational models. There is a vital need to define the basic information/semantic models, architecture components and operational models that together comprise a so-called Big Data Ecosystem. This paper discusses a nature of Big Data that may originate from different scientific, industry and social activity domains and proposes improved Big Data definition that includes the following parts: Big Data properties (also called Big Data 5V: Volume, Velocity, Variety, Value and Veracity), data models and structures, data analytics, infrastructure and security. The paper discusses paradigm change from traditional host or service based to data centric architecture and operational models in Big Data. The Big Data Architecture Framework (BDAF) is proposed to address all aspects of the Big Data Ecosystem and includes the following components: Big Data Infrastructure, Big Data Analytics, Data structures and models, Big Data Lifecycle Management, Big Data Security. The paper analyses requirements to and provides suggestions how the mentioned above components can address the main Big Data challenges. The presented work intends to provide a consolidated view of the Big Data phenomena and related challenges to modern technologies, and initiate wide discussion",Defining Architecture Components of the Big Data Ecosystem,10.1109/cts.2014.6867550,,'Institute of Electrical and Electronics Engineers (IEEE)',,core
158321560,2017-05-01T00:00:00,"Middleware abstractions, or services, that can bridge the gap between the increasingly pervasive sensors and the sophisticated inference applications exist, but they lack the necessary resource-awareness to support high data-rate sensing modalities such as audio/video. This work therefore investigates the resource management problem in sensing services, with application in audio sensing. First, a modular, data-centric architecture is proposed as the framework within which optimal resource management is studied. Next, the guided-processing principle is proposed to achieve optimized trade-off between resource (energy) and (inference) performance.

On cascade-based systems, empirical results show that the proposed approach significantly improves the detection performance (up to 1.7x and 4x reduction in false-alarm and miss rate, respectively) for the same energy consumption, when compared to the duty-cycling approach. Furthermore, the guided-processing approach is also generalizable to graph-based systems. Resource-efficiency in the multiple-application setting is achieved through the feature-sharing principle. Once applied, the method results in a system that can achieve 9x resource saving and 1.43x improvement in detection performance in an example application.

Based on the encouraging results above, a prototype audio sensing service is built for demonstration. An interference-robust audio classification technique with limited training data would prove valuable within the service, so a novel algorithm with the desired properties is proposed. The technique combines AI-gram time-frequency representation and multidimensional dynamic time warping, and it outperforms the state-of-the-art using the prominent-region-based approach across a wide range of (synthetic, both stationary and transient) interference types and signal-to-interference ratios, and also on field recordings (with areas under the receiver operating characteristic and precision-recall curves being 91% and 87%, respectively)",Resource management in sensing services with audio applications,,https://core.ac.uk/download/158321560.pdf,,,core
26768209,2003-08-01T00:00:00Z,"Sensor networks, composed of large amount of micro-sensors, are considered promising, both in academic research and in real life applications. To ensure highly efficient communications between event observers and sensor network users, new infrastructures and algorithms are being developed. This paper describes Artery, a novel architecture that delivers queries and data between multiple observers and multiple mobile users. Simulation results show that Artery outperforms some major data dissemination algorithms",Artery: A Data-Centric Architecture for Wireless Sensor Networks,,,International Institute of Informatics and Cybernetics,"[{'title': None, 'identifiers': ['1690-4524', '1690-4532', 'issn:1690-4532', 'issn:1690-4524']}]",core
21858426,2012-05-19,"Abstract—Internet evolution has been recently related with some aspect of user empowerment, mostly in terms of content distribution, and this has been ultimately accelerated by the fast-paced introduction and expansion of wireless technologies. Hence, the Internet should start to be seen as a communications infrastructure able to support the integration of a myriad of embedded and personal wireless objects. This way a future Internet will support the interaction between users ’ social, physical and virtual sphere. This position paper aims to raise some discussion about the technology required to ensure an efficient interaction between the physical, social and virtual worlds by extending the Internet by means of interconnected objects. Namely, it is argued that an efficient interaction between the physical, social and virtual worlds requires the development of a data-centric architecture based on IP-driven opportunisitc networking able to make useful data available to people when and where they really need it, augmenting their social and environmental awareness. Index Terms—user-centric paradigm, data-centric architecture, IP-based opportunistic networking I",1 Social-driven Internet of Connected Objects,,,,,core
224831399,2017-04-27T00:00:00,"Allowing users to control access to their data is paramount for the success of the Internet of Things; therefore, it is imperative to ensure it, even when data has left the users' control, e.g. shared with cloud infrastructure. Consequently, we propose several state of the art mechanisms from the security and privacy research fields to cope with this requirement. 



To illustrate how each mechanism can be applied, we derive a data-centric architecture providing access control and privacy guaranties for the users of IoT-based applications. Moreover, we discuss the limitations and challenges related to applying the selected mechanisms to ensure access control remotely. Also, we validate our architecture by showing how it empowers users to control access to their health data in a quantified self use case",Addressing  Data-Centric Security Requirements for IoT-Based Systems,10.1109/SIoT.2016.007,,'Institute of Electrical and Electronics Engineers (IEEE)',,core
100191005,2010,"Building and debugging distributed software remains ex-tremely difficult. We conjecture that by adopting a data-centric approach to system design and by employing declar-ative programming languages, a broad range of distributed software can be recast naturally in a data-parallel program-ming model. Our hope is that this model can significantly raise the level of abstraction for programmers, improving code simplicity, speed of development, ease of software evo-lution, and program correctness. This paper presents our experience with an initial large-scale experiment in this direction. First, we used the Overlog language to implement a “Big Data ” analytics stack that is API-compatible with Hadoop and HDFS and provides com-parable performance. Second, we extended the system with complex distributed features not yet available in Hadoop, including high availability, scalability, and unique monitor-ing and debugging facilities. We present both quantitative and anecdotal results from our experience, providing some concrete evidence that both data-centric design and declara-tive languages can substantially simplify distributed systems programming","Boom Analytics: Exploring Data-Centric, Declarative Programming for the Cloud",,,,,core
155696685,2015,"Named Data Networking (NDN) is a data-centric architecture designed for the future Internet. Existing works show that NDN brings significant performance improvement for typical content-centric applications, and can also fit the mobile environment well. However, directly applying NDN to Vehicular Ad hoc NETworks (VANETs) is confronted with great challenges due to the high mobility of vehicles. Most applications in VANETs are relied on data dissemination mechanisms. Therefore, we aim to improve the performance of NDN packet forwarding for the efficient content delivery in urban VANET scenarios. Specifically, we introduce the geo-location information to the NDN forwarding plane, and propose a geo-based forwarding strategy to make NDN fit the urban VANETs. Simulation results show our strategy can achieve 27% ~ 75% higher request success ratio, and 40% ~ 80% lower delay compared with the default NDN strategy in urban scenarios with different vehicle densities. ? 2015 IEEE.EI2015-Ma",Boosting named data networking for efficient packet forwarding in urban VANET scenarios,10.1109/LANMAN.2015.7114718,,"21st IEEE International Workshop on Local and Metropolitan Area Networks, LANMAN 2015",,core
21729647,2010,"Building and debugging distributed software remains extremely difficult. We conjecture that by adopting a datacentric approach to system design and by employing declarative programming languages, a broad range of distributed software can be recast naturally in a data-parallel programming model. Our hope is that this model can significantly raise the level of abstraction for programmers, improving code simplicity, speed of development, ease of software evolution, and program correctness. This paper presents our experience with an initial largescale experiment in this direction. First, we used the Overlog language to implement a “Big Data ” analytics stack that is API-compatible with Hadoop and HDFS and provides comparable performance. Second, we extended the system with complex distributed features not yet available in Hadoop, including high availability, scalability, and unique monitoring and debugging facilities. We present both quantitative and anecdotal results from our experience, providing some concrete evidence that both data-centric design and declarative languages can substantially simplify distributed systems programming","Boom analytics: exploring data-centric, declarative programming for the cloud",,,,,core
76529845,2017,"Content-Centric Networking (CCN) represents an established candidate for the future Internet, proposing a routing architecture designed to elevate content to first class entity. Starting from the fact that the network usage has dramatically evolved towards content retrieval, CCN relies on an on-demand pull based mechanism to transfer data from the different sources to the heterogeneous consumers. This paradigm enhances the network in a number of ways, ranging from the newly introduced in-network caching capabilities to the benefits provided by the symmetric data routing adopted by CCN. In this renewed network scenario, we place our attention to those applications that do not perfectly fit the pull paradigm, stating that they need to be supported as well and proposing an effective way to achieve scalability on large scale push applications. We provide the following contributions: (i) we identify the functions that a data-centric architecture should support; (ii) propose and compare our solution with the state of the art framework designed for the specific problem of pushing data to content requesters; and (iii) evaluate their performance in terms of traffic generated and scalability achieved by simulating a real Internet Service Provider (ISP) topology and the realistic workload of a generic social network application",Push applications and dynamic content generation over content-centric networking,10.1002/dac.2964,,"John Wiley & Sons, Inc.",,core
224467831,2011-01-01T00:00:00,"Building system software is a notoriously complex and arduous endeavor.Developing tools and methodologies for practical system software engineeringhas long been an active area of research.  This thesis explores system softwaredevelopment through the lens of a declarative, data-centric programminglanguage that can succinctly express high-level system specifications and bedirectly compiled to executable code.  By unifying specification andimplementation, our approach avoids the common problem of implementationsdiverging from specifications over time.  In addition, we show that using adeclarative language often results in drastic reductions in code size (100× andmore) relative to procedural languages like Java and C++.  We demonstrate theseadvantages by implementing a host of functionalities at various levels of thesystem hierarchy, including network protocols, query optimizers, and schedulingpolicies.  In addition to providing a compact and optimized implementation, wedemonstrate that our declarative implementations often map very naturally totraditional specifications: in many cases they are line-by-line translations ofpublished pseudcode.We started this work with the hypothesis that declarative languages --originally developed for the purposes of data management and querying -- couldbe fruitfully adapted to the specification and implementation of core systeminfrastructure.  A similar argument had been made for networking protocols afew years earlier [61].  However, our goals were quite different: we wanted toexplore a broader range of algorithms and functionalities (dynamic programming,scheduling, program rewriting, and system auditing) that were part of complex,real-world software systems.  We identified two existing system components --query optimizers in a DBMS and task schedulers in a cloud computing system --that we felt would be better specified via a declarative language.  Given ourinterest in delivering real-world software, a key challenge was identifying theright system boundary that would permit meaningful declarative implementationsto coexist within existing imperative system architectures.  We found thatrelations were a natural boundary for maintaining the ongoing system state onwhich the imperative and declarative code was based, and provided an elegantway to model system architectures.This thesis explores the boundaries of declarative systems via two projects.We begin with Evita Raced; an extensible compiler for the Overlog language usedin our declarative networking system, P2.  Evita Raced is a metacompiler -- anOverlog compiler written in Overlog -- that integrates seamlessly with the P2dataflow architecture.  We first describe the minimalist design of Evita Raced,including its extensibility interfaces and its reuse of the P2 data model andruntime engine.  We then demonstrate that a declarative language like Overlogis well-suited to expressing traditional and novel query optimizations as wellas other program manipulations, in a compact and natural fashion.  FollowingEvita Raced, we describe the initial work in BOOM Analytics, which began as alarge-scale experiment at building ""cloud"" software in a declarative language.Specifically, we used the Overlog language to implement a ""Big Data"" analyticsstack that is API-compatible with the Hadoop MapReduce architecture andprovides comparable performance.  We extended our declarative version of Hadoopwith complex distributed features that remain absent in the stock Hadoop Javaimplementation, including alternative scheduling policies, online aggregation,continuous queries, and unique monitoring and debugging facilities.  We presentquantitative and anecdotal results from our experience, providing concreteevidence that both data-centric design and declarative languages cansubstantially simplify systems programming",Declarative Systems,,,"eScholarship, University of California",,core
159788924,2016-04,"Construction planning is carried out prior to the construction design it is being increasingly highlighted its importance in that it supports the effective basic orientation throughout the building projects, including the project cost forecasting, demand. The estimated project cost estimates are particularly mass-scale analysis and understanding of the site, and review applicable laws and regulations, which is primarily derived elements have to be in the planning stages of a fundamental element of the design outline. However, the requirements for the target for most of the architects Sizing Today, we&#39;re relying on the judgment of the comprehensive design conditions, such as building codes only experience and intuition can follow a lot of trouble to get work done. In this study, the architect and the purpose of the plug-in implementation of a knowledge-based BIM system center to perform the construction project feasibility study based on digital data. Architects through the plug can be can quickly create a 3D model of BIM-based according to the design requirements, through a system of a data structure as occurring in a process to estimate the feasibility information.��� ��������� ��������������� ������������ ��������������������� ���������������(15-AUDP-C067817-03)��� ������ ������ ���������������",An Implementation of the Feasibility Study Plug-in of Architectural Planning using Data-centric architecture: Focused on the Knowledge-based BIM System,,,������������������,"[{'title': None, 'identifiers': ['issn:2287-5786', '2287-5786']}]",core
212780742,2007-01-01T00:00:00,"Nous nous intéressons dans cet article à la gestion de l’évolution logicielle dans les 
processus pilotés par les modèles (MDE). Plus spécifiquement, nous tentons de hisser la 
gestion de l’évolution logicielle au niveau des spécifications. Nous examinons les défis 
conceptuels et techniques qui apparaissent lorsque  la gestion de l’évolution est considérée 
comme une problématique de premier ordre dans un processus d’ingénierie piloté par les 
modèles. Dans le contexte spécifique de la réalisation d’applications web, nous proposons un 
cadre formel s’organisant autour de : (i) une architecture pilotée par les données, (ii) un 
méta-modèle ciblant les applications web, (iii) un modèle de traçabilité permettant de gérer 
les évolutions des modèles et de vérifier la cohérence des différentes versions. Notre objectif 
est d’abstraire autant que possible la gestion de l’évolution et de la hisser au niveau du 
méta-modèle, de sorte que celle-ci reste générique.We focus on the evolution aspect of MDE, and more specifically on the design of 
web applications following a model-driven approach. In this context we address the issue of
managing software evolution at the specification level. We examine the conceptual and 
technical challenges that occur when trying to raise evolution management concerns as first-class MDE issues. Focusing on Web applications design, we propose a general framework 
which consists of (i) a data-centric architecture, (ii) an integrated meta-model to support 
specifications of such applications and (iii) a traceability model to manage evolutions and 
evaluate consistencies of applications’ versions. Our goal is to promote, as much a possible,
the traceability management at the meta-model level in order to make it generic.ou",Gestion de l'évolution des applications Web,,,,,core
90890561,2003-08-01T00:00:00Z,"Sensor networks, composed of large amount of micro-sensors, are considered promising, both in academic research and in real life applications. To ensure highly efficient communications between event observers and sensor network users, new infrastructures and algorithms are being developed. This paper describes Artery, a novel architecture that delivers queries and data between multiple observers and multiple mobile users. Simulation results show that Artery outperforms some major data dissemination algorithms",Artery: A Data-Centric Architecture for Wireless Sensor Networks,,,International Institute of Informatics and Cybernetics,"[{'title': None, 'identifiers': ['1690-4524', 'issn:1690-4524']}]",core
102576980,2015-08-26,"A data-centric architecture for collaboration environments uses XML to adapt shared data dynamically between devices with widely disparate capabilities. Expanding the Internet’s reach withwireless links and mobile terminalsestablishes an infrastructure that permits not only individual roaming but also, potentially, interactive collaboration in a more complex workspace. The classic example is an expert using a 3D CAD model on a workstation to collaborate with someone in the field using a handheld device. The possibilities for collaboration will become more elaborate with advances in visualization technologies for small portable devices (for example, see the MiniGL 3D graphics library from Digita",Adaptive Collaboration for Wired and Wireless Platforms,,,,,core
224546396,2020-01-01T00:00:00,"© USENIX Workshop on Hot Topics in Storage and File Systems, HotStorage 2015.All right reserved. The Internet of Things (IoT) represents a new class of applications that can benefit from cloud infrastructure. However, the current approach of directly connecting smart devices to the cloud has a number of disadvantages and is unlikely to keep up with either the growing speed of the IoT or the diverse needs of IoT applications. In this paper we explore these disadvantages and argue that fundamental properties of the IoT prevent the current approach from scaling. What is missing is a wellarchitected system that extends the functionality of the cloud and provides seamless interplay among the heterogeneous components in the IoT space. We argue that raising the level of abstraction to a data-centric design-focused around the distribution, preservation and protection of information-provides a much better match to the IoT. We present early work on such a distributed platform, called the Global Data Plane (GDP), and discuss how it addresses the problems with the cloud-centric architecture",The cloud is not enough: Saving IoT from the cloud,,,"eScholarship, University of California",,core
234909042,2017,"Content-Centric Networking (CCN) represents an established candidate for the future Internet, proposing a routing architecture designed to elevate content to first class entity. Starting from the fact that the network usage has dramatically evolved towards content retrieval, CCN relies on an on-demand pull based mechanism to transfer data from the different sources to the heterogeneous consumers. This paradigm enhances the network in a number of ways, ranging from the newly introduced in-network caching capabilities to the benefits provided by the symmetric data routing adopted by CCN. In this renewed network scenario, we place our attention to those applications that do not perfectly fit the pull paradigm, stating that they need to be supported as well and proposing an effective way to achieve scalability on large scale push applications. We provide the following contributions: (i) we identify the functions that a data-centric architecture should support; (ii) propose and compare our solution with the state of the art framework designed for the specific problem of pushing data to content requesters; and (iii) evaluate their performance in terms of traffic generated and scalability achieved by simulating a real Internet Service Provider (ISP) topology and the realistic workload of a generic social network application",Push applications and dynamic content generation over content-centric networking,10.1002/dac.2964,,'Wiley',,core
291790075,2017-05,"Middleware abstractions, or services, that can bridge the gap between the increasingly pervasive sensors and the sophisticated inference applications exist, but they lack the necessary resource-awareness to support high data-rate sensing modalities such as audio/video. This work therefore investigates the resource management problem in sensing services, with application in audio sensing. First, a modular, data-centric architecture is proposed as the framework within which optimal resource management is studied. Next, the guided-processing principle is proposed to achieve optimized trade-off between resource (energy) and (inference) performance.

On cascade-based systems, empirical results show that the proposed approach significantly improves the detection performance (up to 1.7x and 4x reduction in false-alarm and miss rate, respectively) for the same energy consumption, when compared to the duty-cycling approach. Furthermore, the guided-processing approach is also generalizable to graph-based systems. Resource-efficiency in the multiple-application setting is achieved through the feature-sharing principle. Once applied, the method results in a system that can achieve 9x resource saving and 1.43x improvement in detection performance in an example application.

Based on the encouraging results above, a prototype audio sensing service is built for demonstration. An interference-robust audio classification technique with limited training data would prove valuable within the service, so a novel algorithm with the desired properties is proposed. The technique combines AI-gram time-frequency representation and multidimensional dynamic time warping, and it outperforms the state-of-the-art using the prominent-region-based approach across a wide range of (synthetic, both stationary and transient) interference types and signal-to-interference ratios, and also on field recordings (with areas under the receiver operating characteristic and precision-recall curves being 91% and 87%, respectively)",Resource management in sensing services with audio applications,,,,,core
11463575,2005,Various architectures have been developed for wireless sensor networks. Many of them leave to the programmer important concepts as the way in which the inter-task communication and dynamic reconfigurations are addressed. In this paper we describe the characteristics of a new architecture we proposed - the data-centric architecture. This architecture offers an easy way of structuring the applications designed for wireless sensor nodes that confers them superior performances,Architectures for Wireless Sensor Networks,10.1201/9781420038163.ch33,https://core.ac.uk/download/pdf/11463575.pdf,,,core
103988265,2016-08-13,"Abstract-Sensor networks, composed of large amount of micro-sensors, are considered promising, both in academic research and in real life applications. To ensure highly efficient communications between event observers and sensor network users, new infrastructures and algorithms are being developed. This paper describes Artery, a novel architecture that delivers queries and data between multiple observers and multiple mobile users. Simulation results show that Artery outperforms some major data dissemination algorithms",Artery: A Data-Centric Architecture for Wireless Sensor Networks,,,,,core
473284099,2020-01-01T00:00:00,,Data-Centric Architecture,10.1016/B978-0-12-820790-1.00022-X,,'Elsevier BV',,core
21061800,2009-08-31,"Synchronization gained great importance in modern applications and allows mobility in the context of information technology. Users are not limited to one computer any more, but can take their data with them on a laptop. Two common architectures have been developed recently, the Data-Centric Architecture as well as the Service-Oriented Architecture. This paper compares two existing technologies for the implementation of a mobile client and introduces a new approach, developed based on the requirements of a major insurance company, the Context-Oriented Architecture. This approach allows detection and resolution of conflicts within the context in which the objects were changed, while still ensuring data correctness and consistency. Therefore two new synchronization concepts are introduced: the synchronization of complex objects and dialogue-sensitive synchronization. An application implementing this approach has been realized and successfully deployed. 1",A Context-Oriented Synchronization Approach,,,,,core
92648669,2005-01-01T00:00:00,Various architectures have been developed for wireless sensor networks. Many of them leave to the programmer important concepts as the way in which the inter-task communication and dynamic reconfigurations are addressed. In this paper we describe the characteristics of a new architecture we proposed - the data-centric architecture. This architecture offers an easy way of structuring the applications designed for wireless sensor nodes that confers them superior performances,Architectures for wireless sensor networks,10.1109/issnip.2005.1595552,,'Institute of Electrical and Electronics Engineers (IEEE)',,core
145154055,2017-03-27T00:00:00,"International audienceToday the cloud plays a central role in storing, processing , and distributing data. Despite contributing to the rapid development of various applications, including the IoT, the current centralized storage architecture has led into a myriad of isolated data silos and is preventing the full potential of holistic data-driven analytics for IoT data. In this abstract, we advocate a data-centric design for IoT with focus on resilience, sharing, and auditable protection of information. We introduce the initial design of our blockchain-based end-to-end encrypted data storage system. We enable a secure and persistent data management, by utilizing the blockchain as an auditable access control layer to a decentralized storage layer",Towards Blockchain-based Auditable Storage and Sharing of IoT Data,,https://core.ac.uk/download/145154055.pdf,HAL CCSD,,core
161999682,"July 7, 2018","Generally speaking, systems engineering (SE) tool-sets face a dilemma balancing power and accessibility. High-powered SE tools (MagicDraw, Cradle, Core, etc.) tend to be specialized and are available only to highly trained Systems Engineers, and/or through the use of a 'back room' developer team making the output products available to the broader team. On the other hand, highly accessible tools (MS Word, Excel, etc.) do not have the power to implement SE in a rigorous manner. NASA has to test all aspects of the new human-rated Orion Multi-Purpose Crew Vehicle spacecraft prior to its first crewed mission. The test program includes uncrewed launch abort flight tests to demonstrate the capability to save the crew in the event that a launch failure occurs. Orion's second abort flight test will be a low-altitude flight test known as ""Ascent Abort 2 (AA-2).""  This test is currently scheduled to be carried out at Cape Canaveral Air Force Station's Space Launch Complex 46 (SLC-46) in Florida in 2019. NASA's in-house AA-2 Crew Module and Separation Ring (CSR) Team is producing the crew module and separation ring. Operating jointly as both an Advanced Exploration Systems (AES) Project and an Orion Project, the CSR project charter includes development of innovative, streamlined and generally more efficient practices for creation of flight hardware and software. One result of this tasking has been development of a collaborative and data-centric systems engineering environment within the team's shared web environment (Microsoft SharePoint). Through the use of built-in, 'out of the box capabilities' present in MS SharePoint, the CSR Systems Engineering team has created (with some limited developer support) a data-centric architecture for the project's SE implementation, including functional and interface analysis, requirements development and management, risk management, verification planning and management, test results, and end item management. Data elements are linked between data structures so as to define and control relationships between item types, link requirements to parents and children, and link tests to the requirements that they verify. The overall project team integration is increased by also linking SE content to project management content over the project life cycle, including team communication, action items, configuration management, decisional and meeting materials, and life cycle reviews. This presentation will provide an overview of the collaborative SE environment, showing how it provides the power for a number of SE tasks while still providing the accessibility and transparency to allow the full project team to collaborate and succeed. Given the project phase, we'll be able to present a nearly full lifecycle discussion, from concept through verification and approaching delivery",Collaborative Systems Engineering in the Ascent Abort-2 Crew Module/Separation Ring Project,,https://core.ac.uk/download/pdf/161999682.pdf,,,core
224548333,2016-05-01T00:00:00,"The Internet of Things (IoT) represents a new class of applications that can benefit from cloud infrastructure. However, directly connecting smart devices to the cloud has multiple disadvantages and is unlikely to keep up with the growing speed of the IoT or the diverse needs of IoT applications. Here, the authors argue that fundamental IoT properties prevent the current approach from scaling. What's missing is a well-architected system extending cloud functionality and providing seamless interplay among heterogeneous components closer to the edge in the IoT space. Raising the level of abstraction to a data-centric design-focused around the distribution, preservation, and protection of information-better matches the IoT. To address such problems with the cloud-centric architecture, the authors present their early work on a distributed platform, the Global Data Plane",Toward a Global Data Infrastructure,,,"eScholarship, University of California",,core
21915200,2010,"Building and debugging distributed software remains extremely difficult. We conjecture that by adopting a datacentric approach to system design and by employing declarative programming languages, a broad range of distributed software can be recast naturally in a data-parallel programming model. Our hope is that this model can significantly raise the level of abstraction for programmers, improving code simplicity, speed of development, ease of software evolution, and program correctness. This paper presents our experience with an initial largescale experiment in this direction. First, we used the Overlog language to implement a “Big Data ” analytics stack that is API-compatible with Hadoop and HDFS and provides comparable performance. Second, we extended the system with complex distributed features not yet available in Hadoop, including high availability, scalability, and unique monitoring and debugging facilities. We present both quantitative and anecdotal results from our experience, providing some concrete evidence that both data-centric design and declarative languages can substantially simplify distributed systems programming","Analytics: exploring data-centric, declarative programming for the cloud",,,,,core
83858956,2017-05-14T00:00:00,"Advancement in information and communication technology (ICT) has given rise
to explosion of data in every field of operations. Working with the enormous
volume of data (or Big Data, as it is popularly known as) for extraction of
useful information to support decision making is one of the sources of
competitive advantage for organizations today. Enterprises are leveraging the
power of analytics in formulating business strategy in every facet of their
operations to mitigate business risk. Volatile global market scenario has
compelled the organizations to redefine their supply chain management (SCM). In
this paper, we have delineated the relevance of Big Data and its importance in
managing end to end supply chains for achieving business excellence. A Big
Data-centric architecture for SCM has been proposed that exploits the current
state of the art technology of data management, analytics and visualization.
The security and privacy requirements of a Big Data system have also been
highlighted and several mechanisms have been discussed to implement these
features in a real world Big Data system deployment in the context of SCM. Some
future scope of work has also been pointed out. Keyword: Big Data, Analytics,
Cloud, Architecture, Protocols, Supply Chain Management, Security, Privacy.Comment: 24 pages, 4 figures, 3 table",A Proposed Architecture for Big Data Driven Supply Chain Analytics,10.2139/ssrn.2795906,http://arxiv.org/abs/1705.04958,'Elsevier BV',,core
108487212,2016-09-26,"Abstract. Big Data are becoming a popular technology focus both in science and in industry and motivate technology shift to data centric architecture and operational models. Big Data is bringing a positive change in the decision making process of various business organizations.In this paper, MapReduce big data analysis methods, and with SQL server performance comparison, the experimental results show that, compared to SQL server, MapReduce method loads a small time, as the data set increases, the performance MapReduce approach is better. So MapReduce method has better scalability and speedup for large data processing applications. ",Analysis of the Big Data based on MapReduce,,,,,core
32550735,2009-08-12T00:00:00,"The space community, led by AFRL, started developing spacecraft plug and play concepts and standards in 2004 and has resulted in the Space Plug and play Avionics (SPA) Standards. AFRL has undertaken two efforts in small satellite development to both solidify the technology and to demonstrate the benefits. The Plug and Play Satellite (PnPSat) utilizes the SPA-S interface standard and demonstrated that rapid development, integration and testing is possible. The second effort is PnPSat-2 that uses the next generation of SPA components for a larger bus focused on ORS needs to make real the promise of custom performance at commodity prices. The SPA standard interface has proven critical to the development of design tools that both select (based upon performance requirements) and place (based upon restrictions such as mass and power balance) components. The Satellite Data Model (SDM) method of query and discovery enables the development of modular, single purpose applications that support autonomous flight software in a distributed computing system. The utilization of a data centric architecture (as opposed to component centric) insolates software developers from both specific hardware components and data network topology. The SPA standard interface reduces the need for many specialized test methods resulting in major reductions in test time. This paper will present the steps used in designing, building, and testing SPA PnP satellites and the current status of PnPSat and PnPSat-2",Plug and Play Spacecraft Evolution,,https://core.ac.uk/download/32550735.pdf,DigitalCommons@USU,,core
209016327,2007-01-01T00:00:00,,A data-centric architecture for data-driven spoken dialog systems,10.1109/ASRU.2007.4430168,,'Institute of Electrical and Electronics Engineers (IEEE)',,core
21015377,2007,"Data is becoming increasingly crucial for training and (self-) evaluation of spoken dialog systems (SDS). Data is used to train models (e.g. acoustic models) and is ‘forgotten’. Data is generated on-line from the different components of the SDS system, e.g. the dialog manager, as well as from the world it is interacting with (e.g. news streams, ambient sensors etc.). The data is used to evaluate and analyze conversational systems both on-line and off-line. We need to be able query such heterogeneous data for further processing. In this paper we present an approach with two novel components: first, an architecture for SDSs that takes a data-centric view, ensuring persistency and consistency of data as it is generated. The architecture is centered around a database that stores dialog data beyond the lifetime of individual dialog sessions, facilitating dialog mining, annotation, and logging. Second, we take advantage of the state-fullness of the data-centric architecture by means of a lightweight, reactive and inference-based dialog manager that itself is stateless. The feasibility of our approach has been validated within a prototype of a phone-based university help-desk application. We detail SDS architecture and dialog management, model, and data representation",A Data-Centric Architecture for Data-Driven Spoken Dialog Systems,,,,,core
461444533,2015-01-01T00:00:00,,A Study on data-centric design integrated system model development,10.2316/P.2015.831-013,,'ACTA Press',,core
102083773,2015-07-06,"Sensor networks, composed of large amount of micro-sensors, are considered promising, both in academic research and in real life applications. To ensure highly efficient communications between event observers and sensor network users, new infrastructures and algorithms are being developed. This paper describes Artery, a novel architecture that delivers queries and data between multiple observers and multiple mobile users. Simulation results show that Artery outperforms some major data dissemination algorithms",Artery: A data-centric architecture for wireless sensor networks,,,,,core
77233798,2016-10-21T00:00:00,"This paper describes the software architecture and design of the space segment, communication and ground segment software of the Kontur-2 project, which contributed to the realization of telepresent planetary exploration. The main research objectives in Kontur-2 were the development and in-flight verification of a space qualified two degree of freedom (DoF) force-feedback joystick (RJo) inside the Zvezda Service Module of the International Space Station (ISS), the implementation of telepresence technologies and the study of human performance when controlling a force feedback joystick in microgravity. The project was conducted from 2012 to 2015 by a consortium consisting of the German Aerospace Center (DLR), the Russian Federal Space Agency (ROSCOSMOS), The Russian State Scientific Center for Robotics and Technical Cybernetics (RTC), S. P. Korolev Rocket and Space Corporation Energia (RSC ”Energia”) and the Yuri A. Gagarin State Scientific Researchand- Testing Cosmonaut Training Center (GCTC). The DLR conducted two sets of experiments in which a cosmonaut on ISS used RJo to perform different tasks with robots located on-ground. The first set was conducted with a two DoF robot equipped with a camera system, a task board and torque sensors that allowed the cosmonaut to perceive forces caused by contacts with the environment. For the second set of experiments we used a humanoid robot to perform a tele-handshake and a cooperative task between the cosmonaut on ISS and colleagues at RTC in St. Petersburg.



To realize these experiments, the consortium developed onboard and on-ground software which will be described in this paper. The space segment software consists of the control software for RJo and user interfaces on a laptop to guide the cosmonaut efficiently through the experiments. We designed a state machine for these user interfaces to capture state changes during the experiment execution. This way we provided only relevant contextual information to the cosmonaut. On RJo, we deployed a component framework combining a data-centric architecture with a CCSDS Space Packet interface. Additionally, we designed the communication software for supporting a direct multi-channel connection between ground control and ISS using our own S-band radio equipment. During contact to ISS, the ground operators used the ground segment software at DLR for experiment support, supervision, maintenance and data logging. The visual feedback from the camera system required by the cosmonaut to perform the experiments was provided by a lowlatency video stream through a communication channel with very restricted bandwidth.



During 23 experiment sessions in 2015, the Kontur-2 software formed the basis of the successful completion of the experiments. Their results contributed to the fields of telepresence technologies and human factors",Software Architecture and Design of the Kontur-2 Mission,,https://core.ac.uk/download/77233798.pdf,,,core
