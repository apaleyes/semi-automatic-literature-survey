id,datePublished,description,journals,publisher,title,doi,downloadUrl,database
350943994,2020-01-01T00:00:00,"Driven by technological advances, growing amounts of available data, and an emergent need for participatory processes, landscape architecture is witnessing a moment of disruption whereby formerly separated areas of operation become increasingly connected. While distinctions between various aspects of the design process are diminishing, a need for a novel, more inclusive toolset arises. The ‘tangible table’ paradigm is an attempt at combining intuitive ways of physical modelling with data-driven design strategies and the interactive simulation of naturally occurring phenomena. Despite its existence for more than 20 years, tangible tables have mainly focused on very specific workflows and therefore have not found wider adoption in landscape architectural practice or education. We list the limitations of previous implementations and introduce a novel software solution aimed at popularizing tangible table setups. Our software is embedded in a widespread visual programming environment, which allows for straightforward augmentation of physical models with computational design tech-niques. Using a week-long PhD course as a case study, we demonstrate the usefulness of the proposed software and its potential applications to solving various landscape architectural challenges through increased emphasis on participatory processes.Peer reviewe","[{'title': None, 'identifiers': ['2367-4253', 'issn:2367-4253', 'issn:2511-624X', '2511-624x']}]",Wichmann Verlag im VDE Verlag GmbH,Bridging tangible and virtual realities : Computational procedures for data-informed participatory processes,10.14627/537690036,,core
475260525,2021-07-01T00:00:00,"Designing auction parameters for online industrial auctions is a complex problem due to highly heterogeneous items. Currently, online auctioneers rely heavily on their experts in auction design. The ability of predicting how well an auction will perform prior to the start comes in handy for auctioneers. If an item is expected to be a low-performing item, the auctioneer can take certain actions to influence the auction outcome. For instance, the starting selling price of the item can be modified, or the location where the item is displayed on the website can be changed to attract more attention. In this paper, we take a real-world industrial auction data set and investigate how we can improve upon the expert’s design using insights learned from data. More specifically, we first construct a classification model that predicts the expected performance of auctions. We propose a data driven auction design framework (called DDAD) that combines the expert’s knowledge with the learned prediction model, in order to find the best parameter values, i.e., starting price and display positions of the items, for a given new auction. The prediction model is evaluated, and the new design for several auctions is discussed and validated with the auction experts",,'Springer Science and Business Media LLC',Data driven design for online industrial auctions,10.1007/s10472-020-09722-2,,core
287552271,2019-12-11T00:00:00,,,'Springer Science and Business Media LLC',Data-driven design of metal–organic frameworks for wet flue gas CO<sub>2</sub> capture,10.1038/s41586-019-1798-7,,core
482192986,2021-01-01T00:00:00,"Orientador: Prof. Dr. Aguinaldo dos SantosDissertação (mestrado) - Universidade Federal do Paraná, Setor de Artes, Comunicação e
Design, Programa de Pós-Graduação em Design. Defesa : Curitiba, 28/05/2021Inclui referências: p. 138-153Resumo: A presente dissertação apresenta um estudo com característica exploratória, de natureza aplicada, por meio de uma abordagem fenomenológica e qualitativa, sobre o uso do Data- Driven Design em um briefing metaprojetual para promover comportamentos mais sustentáveis. Ao longo das últimas décadas, as inovações em tecnologias da informação e comunicação vêm proporcionando diversas transformações no mercado de consumo e alterando o comportamento dos usuários. Essas modificações ocorrem nos diferentes pontos da jornada de consumo, seja no modo como os usuários pesquisam, adquirem, utilizam, avaliam ou descartam produtos e serviços. Consequentemente, o aumento da quantidade de dados digitais (big data) e do volume de tráfego on-line tem sido exponencial. Por meio da análise de big data é possível obter novo e/ou melhor entendimento acerca do comportamento humano de modo a influenciá-lo. Entretanto, muitas dessas análises estão sendo utilizadas como instrumentos para estimular o consumo. Neste cenário, os comportamentos de consumo dos últimos 50 anos têm contribuído para os impactos negativos na sustentabilidade, como por exemplo, para o aumento da temperatura do planeta. Por outro lado, as investigações de big data também podem apresentar oportunidades para o Data-Driven Design para o Comportamento Sustentável, como a elaboração de briefings metaprojetuais de: produto; serviço; Sistemas de Produto+Serviço (PSS); políticas públicas. Diante disso, este estudo teve como objetivo propor Diretrizes para Briefing Metaprojetual de Data-Driven Design para o Comportamento Sustentável. Como estratégia para a condução da pesquisa utilizou-se um conjunto de métodos, distribuídos ao longo de cinco fases, contemplando: 1. Revisões Bibliográficas (Assistemática e Sistemática); 2. Estudo de Caso ex-post-facto; 3. e 4. Action Design Research (Design Science Research e Pesquisa-Ação); 5. Análise Cruzada. O desenvolvimento da dissertação contou com o apoio de variados parceiros, dentre eles: uma agência de business intelligence, uma empresa de tecnologia médica, um órgão da ONU, pesquisadores de Design e pesquisadores de Ciência de Dados. Através das quatro fases iniciais, foi possível apurar, compreender e analisar os conceitos, para posteriormente propor diretrizes. Na última fase, todas as diretrizes foram avaliadas, refinadas e formalizadas em Diretrizes Finais. As diretrizes visam oferecer a designers um referencial que viabilize a elaboração de briefings metaprojetuais, que por meio do big data possibilite a compreensão do perfil dos usuários e aponte a estratégia de Design para Comportamento Sustentável mais adequada.Abstract: This dissertation presents an exploratory study, of an applied nature, through a phenomenological and qualitative approach, on the use of Data-Driven Design in a briefing of meta-projects to promote more sustainable behaviors. In recent decades, innovations in information and communication technologies have brought about several transformations in the costumers market and changed the users' behavior. These changes occur at different points in the customer journey, whether in the way users search, buy, use, evaluate or discard products and services. Consequently, the amount of digital data (big data) and the volume of online traffic has been increasing exponentially. Through big data analytics, it is possible to gain a new and/or better understanding of human behavior to influence it. However, many of these analyzes are being used as instruments to encourage consumption. In this scenario, the consumption behavior of the last 50 years contributed to negative impacts on sustainability, such as the increase in the planet's temperature. On the other hand, big data investigations can also present opportunities for Data-Driven Design for Sustainable Behaviour, such as developing meta-project briefings for a product; service; Product+Service Systems (PSS); public policies. Therefore, this study aimed to propose Data-Driven Design for Sustainable Behaviour Meta-Project Briefing Guidelines. As a strategy for conducting the research, a set of methods was used, distributed in five phases: 1.?? Literature Reviews (Unsystematic and Systematic); 2. Ex post-facto case study; 3. and 4.?? Action Design Research (Design Science Research and Action Research); 5. Cross analysis.?? The dissertation development was supported by several partners, including a business?? intelligence agency, a medical technology company, a UN agency, design researchers, and?? data science researchers. Through the four initial phases, it was possible to know,?? understand and analyze the concepts, to later propose guidelines. In the last phase, all?? guidelines were evaluated, refined, and formalized in the Final Guidelines. The guidelines?? aim to offer designers a framework that enables the preparation of briefings for metaprojects, which, through big data, make it possible to understand the profile of users and?? point out the most appropriate Design for Sustainable Behaviour strategy",,,Data-Driven Design orientado ao comportamento sustentável : diretrizes para briefing metaprojetual,,https://core.ac.uk/download/482192986.pdf,core
327313304,2020-07-01T07:00:00,"A research-to-action collaboration sought to understand and respond to barriers to female genital fistula treatment in Nigeria and Uganda. This was guided by appreciative inquiry, a participatory approach for transformative programing with four phases: (1) inquire, (2) imagine, (3) innovate, and (4) implement. Through this process, partners designed and refined a treatment barrier reduction intervention using multiple communication channels to disseminate a consistent fistula screening algorithm and provide transportation vouchers to those screening positive. Partnership between an implementation organization, a research institution, and local community partners enabled data-driven design and patient-centered implementation to address specific barriers experienced by women",,'Informa UK Limited',Removing barriers to fistula care: Applying appreciative inquiry to improve access to screening and treatment in Nigeria and Uganda,10.1080/07399332.2019.1638924,,core
344939802,2020-06-27T07:00:00,"Electric hydrofoil surfboards are clean alternatives to jet skis. Electric hydrofoils generate no noise, wake or emissions in comparison. Electric hydrofoil (e-Foil) boards are fun to ride and have low environmental impact. Due to the electric power source they are not dependent on weather conditions how sailing, wind surfing and kite surfing are. Commercial implementations of electric hydrofoils are expensive. The goal of this project is to construct a electric hydrofoil at a reasonable price point. Our approach involves building analysis software to provide data-driven design insights and to build o of the work of the online DIY electric hydrofoil community (efoil.builders)",,Scholar Commons,Electric Hydrofoil and Analysis Software,,,core
480275937,2021-09-10T00:00:00,"Waste infrastructure is largely non-digital and resists mapping and datafication. Waste itself can be seen as material information, revealing of its creators, which is lost along with the material resources that are thrown away. Design and HCI can unlock this information. Most people’s engagement with waste begins and ends at the domestic dustbin, with minimal consideration of what is wasted and where it goes. When aggregated waste practices have significant sustainability impacts. Digital technologies designed to raise awareness of environmental issues compete for our finite cognitive capacity with the demands of everyday life. To address this challenge, this paper uses speculative design of domestic waste devices. These speculative ‘data objects’ build on work in speculative design, sustainable HCI, and waste infrastructure mapping. The aim of this pictorial is to provoke debate on digital technology’s ability to engage us with consumption and waste, resulting in behavior change and reduced environmental degradation",,'Springer Fachmedien Wiesbaden GmbH',OSKARRR:Data-driven Design Speculations For The Future of Domestic Waste,,https://core.ac.uk/download/480275937.pdf,core
387291635,2020-12-09T00:00:00,"The design of online algorithms has tended to focus on algorithms with
worst-case guarantees, e.g., bounds on the competitive ratio. However, it is
well-known that such algorithms are often overly pessimistic, performing
sub-optimally on non-worst-case inputs. In this paper, we develop an approach
for data-driven design of online algorithms that maintain near-optimal
worst-case guarantees while also performing learning in order to perform well
for typical inputs. Our approach is to identify policy classes that admit
global worst-case guarantees, and then perform learning using historical data
within the policy classes. We demonstrate the approach in the context of two
classical problems, online knapsack and online set cover, proving competitive
bounds for rich policy classes in each case. Additionally, we illustrate the
practical implications via a case study on electric vehicle charging",,,Data-driven Competitive Algorithms for Online Knapsack and Set Cover,,http://arxiv.org/abs/2012.05361,core
387309223,2021-01-18T00:00:00,"A popular way to accelerate the sampling of rare events in molecular dynamics
simulations is to introduce a potential that increases the fluctuations of
selected collective variables. For this strategy to be successful, it is
critical to choose appropriate variables. Here we review some recent
developments in the data-driven design of collective variables, with a focus on
the combination of Fisher's discriminant analysis and neural networks. This
approach allows to compress the fluctuations of metastable states into a
low-dimensional representation. We illustrate through several examples the
effectiveness of this method in accelerating the sampling, while also
identifying the physical descriptors that undergo the most significant changes
in the process.Comment: Communication presented at the annual congress of the Italian
  Physical Society (2020",,,"Training collective variables for enhanced sampling via neural networks
  based discriminant analysis",,http://arxiv.org/abs/2101.07085,core
200862936,2019-04-01T00:00:00,"The development of BIM pedagogical strategies within the Architecture, Engineering, and Construction disciplines is a topic of significant research. Several approaches and theoretical lenses, such as Project-Based Learning, constructivist pedagogy, experiential learning, and Bloom&#8217;s Taxonomy have been applied to guide pedagogical education. This paper presents the development and evaluation of an approach integrating these four perspectives that was developed within an Architectural Science undergraduate program. A data-driven design project was incorporated into the curriculum to give students opportunities to engage with BIM-based simulation (cost and energy) to guide their design studio project development. The pedagogical approach is discussed, along with refinements to this project based on early implementation. Four years of data are analyzed, consisting of 1325 design iterations and student feedback on the project. A critical evaluation of the project determined that it was highly effective to engage students at an advanced level - level 4 (Analyze) of Bloom&#8217;s Taxonomy was consistently achieved (over 96% of students) and two thirds of students also engaged meaningfully at Level 5 (Evaluate; 67%) and/or 6 (Create; 8%) &#8212; while developing a high degree of competence in the use of BIM","[{'title': 'Buildings', 'identifiers': ['2075-5309', 'issn:2075-5309']}]",'MDPI AG',Data-Driven Design as a Vehicle for BIM and Sustainability Education,10.3390/buildings9050103,,core
288596311,2019,"This paper addresses the problem of achieving high-performance dynamic control allocation for uncertain plants by exploiting a data-driven design of the annihilator for the underlying plant. Previous work revealed that an output invisible control allocator can be decomposed as the cascade interconnection of a steady-state optimizer and an annihilator, where the latter unit modulates the allocator outputs in such a way to render such signals undetectable from the plant output. Clearly, the critical role and challenging requirements imposed on the annihilator make it the source of the fragility of control allocation schemes in the presence of uncertainty; nonetheless this critical aspect can be (almost) completely circumvented by tuning the annihilator to the actual plant parameters, namely by envisioning a data-driven control allocation scheme. Relations are also highlighted between the present results and the concepts of moments and orthogonal moments of a plant at frequencies of interest, whose use and estimation have recently been the subject of increasing interest",,IEEE,Data-Driven Dynamic Control Allocation for Uncertain Redundant Plants,10.1109/CDC.2018.8619485,,core
472156754,2019-01-01T00:00:00,,,"'Association of Collegiate Schools of Architecture, Inc'",Composing Frankensteins:Data-Driven Design Assemblies through Graph-Based Deep Neural Networks,10.35483/ACSA.AM.107.90,,core
234573893,2019-09-01T07:00:00,"OBJECTIVE:
The purpose of this study was to determine whether an automated platform for evaluation selection and delivery would increase participation from surgical teaching faculty in submitting resident operative performance evaluations.  DESIGN:
We built a HIPAA-compliant, web-based platform to track resident operative assignments and to link embedded evaluation instruments to procedure type. The platform matched appropriate evaluations to surgeons\u27 scheduled procedures, and delivered multiple evaluation types, including Ottawa Surgical Competency Operating Room Evaluation (O-Score) evaluations and Operative Performance Rating System (OPRS) evaluations. Prompts to complete evaluations were made through a system of automatic electronic notifications. We compared the time spent in the platform to achieve evaluation completion. As a metric for the platform\u27s effect on faculty participation, we considered a task that would typically be infeasible without workflow optimization: the evaluator could choose to complete multiple, complementary evaluations for the same resident in the same case. For those cases with multiple evaluations, correlation was analyzed by Spearman rank test. Evaluation data were compared between PGY levels using repeated measures ANOVA.  SETTING:
The study took place at 4 general surgery residency programs: The University of Massachusetts Medical School-Baystate, the University of Connecticut School or Medicine, the University of Iowa Carver College of Medicine, and Maimonides Medical Center.  PARTICIPANTS:
From March 2017 to February 2019, the study included 70 surgical teaching faculty and 101 general surgery residents.  RESULTS:
Faculty completed 1230 O-Score evaluations and 106 OPRS evaluations. Evaluations were completed quickly, with a median time of 36 ± 18 seconds for O-Score evaluations, and 53 ± 51 seconds for OPRS evaluations. 89% of O-Score and 55% of OPRS evaluations were completed without optional comments within one minute, and 99% of O-Score and 82% of OPRS evaluations were completed within 2 minutes. For cases eligible for both evaluation types, attendings completed both evaluations on 74 of 221 (33%) of these cases. These paired evaluations strongly correlated on resident performance (Spearman coefficient = 0.84, p \u3c 0.00001). Both evaluation types stratified operative skill level by program year (p \u3c 0.00001).  CONCLUSIONS:
Evaluation initiatives can be hampered by the challenge of making multiple surgical evaluation instruments available when needed for appropriate clinical situations, including specific case types. As a test of the optimized evaluation workflow, and to lay the groundwork for future data-driven design of evaluations, we tested the impact of simultaneously delivering 2 evaluation instruments via a secure web-based education platform. We measured the evaluation completion rates of faculty surgeon evaluators when rating resident operative performance, and how effectively the results of evaluation could be analyzed and compared, taking advantage of a highly integrated management of the evaluative information",,Scholarly Commons @ Baystate Health,Education Management Platform Enables Delivery and Comparison of Multiple Evaluation Types,,,core
474897163,2021-01-01T00:00:00,"The smart city operation and management center with a hierarchical data-driven architecture has already become one of the most widely used solutions for smart cities in practice, solving the problems associated with data acquisition, data gathering and storage, data processing, and data application. At present, the construction of smart city operation and management center faces bottlenecks such as incomplete top-level design theory, the insufficient integration capability of software and hardware, the low efficiency of data collection and aggregation, and the lack of intelligence in data analysis and application. Aiming to address the above problems, this paper proposes a &#x2018;two-dimension, three-layer, and six-goal&#x2019; top-level design model for a smart city, with six principles for a smart city operational pattern, and focuses on three key technologies: (1) infrastructure integration and application, (2) multidimensional perception data collection and aggregation, and (3) intelligent data analysis and data service. Following the guidance of this model, Longgang District of Shenzhen has constructed a smart city operation and management center including integrated ICT infrastructure, an urban fine management system, and an intelligent urban data analysis and service system. The actual effects and quantitative improvements in the practical case show that the top-level design model of a smart city proposed in this paper has achieved successful results, and it thereby offers an applicability model of a smart city that can be referenced and replicated","[{'title': 'IEEE Access', 'identifiers': ['issn:2169-3536', '2169-3536']}]",'Institute of Electrical and Electronics Engineers (IEEE)',Modeling and Key Technologies of a Data-Driven Smart City System,10.1109/ACCESS.2021.3091716,,core
323402545,2020-09-15T00:00:00,"Data-driven design of mechanical metamaterials is an increasingly popular
method to combat costly physical simulations and immense, often intractable,
geometrical design spaces. Using a precomputed dataset of unit cells, a
multiscale structure can be quickly filled via combinatorial search algorithms,
and machine learning models can be trained to accelerate the process. However,
the dependence on data induces a unique challenge: An imbalanced dataset
containing more of certain shapes or physical properties can be detrimental to
the efficacy of data-driven approaches. In answer, we posit that a smaller yet
diverse set of unit cells leads to scalable search and unbiased learning. To
select such subsets, we propose METASET, a methodology that 1) uses similarity
metrics and positive semi-definite kernels to jointly measure the closeness of
unit cells in both shape and property spaces, and 2) incorporates Determinantal
Point Processes for efficient subset selection. Moreover, METASET allows the
trade-off between shape and property diversity so that subsets can be tuned for
various applications. Through the design of 2D metamaterials with target
displacement profiles, we demonstrate that smaller, diverse subsets can indeed
improve the search process as well as structural performance. By eliminating
inherent overlaps in a dataset of 3D unit cells created with symmetry rules, we
also illustrate that our flexible method can distill unique subsets regardless
of the metric employed. Our diverse subsets are provided publicly for use by
any designer",,'ASME International',"METASET: Exploring Shape and Property Spaces for Data-Driven
  Metamaterials Design",10.1115/1.4048629,http://arxiv.org/abs/2006.02142,core
479629355,2021-07-01T00:00:00,"To create products that are better fit for purpose, manufacturers require new methods for gaining insights into product experience in the wild at scale. “Chatty Factories” is a concept that explores the transformative potential of placing IoT-enabled data-driven systems at the core of design and manufacturing processes, aligned to the Industry 4.0 paradigm. In this paper, we propose a model that enables new forms of agile engineering product development via “chatty” products. Products relay their “experiences” from the consumer world back to designers and product engineers through the mediation provided by embedded sensors, IoT, and data-driven design tools. Our model aims to identify product “experiences” to support the insights into product use. To this end, we create an experiment to: (i) collect sensor data at 100 Hz sampling rate from a “Chatty device” (device with sensors) for six common everyday activities that drive produce experience: standing, walking, sitting, dropping and picking up of the device, placing the device stationary on a side table, and a vibrating surface; (ii) pre-process and manually label the product use activity data; (iii) compare a total of four Unsupervised Machine Learning models (three classic and the fuzzy C-means algorithm) for product use activity recognition for each unique sensor; and (iv) present and discuss our findings. The empirical results demonstrate the feasibility of applying unsupervised machine learning algorithms for clustering product use activity. The highest obtained F-measure is 0.87, and MCC of 0.84, when the Fuzzy C-means algorithm is applied for clustering, outperforming the other three algorithms applied","[{'title': 'Sensors', 'identifiers': ['issn:1424-8220', '1424-8220']}]",'MDPI AG',Unsupervised Learning for Product Use Activity Recognition: An Exploratory Study of a “Chatty Device”,10.3390/s21154991,,core
440581552,2019-06-01T00:00:00,"Data-driven design approaches based on deep learning have been introduced in nanophotonics to reduce time-consuming iterative simulations, which have been a major challenge. Here, we report the first use of conditional deep convolutional generative adversarial networks to design nanophotonic antennae that are not constrained to predefined shapes. For given input reflection spectra, the network generates desirable designs in the form of images; this allows suggestions of new structures that cannot be represented by structural parameters. Simulation results obtained from the generated designs agree well with the input reflection spectrum. This method opens new avenues toward the development of nanophotonics by providing a fast and convenient approach to the design of complex nanophotonic structures that have desired optical properties","[{'title': 'Nanophotonics', 'identifiers': ['2192-8614', '2192-8606', 'issn:2192-8614', 'issn:2192-8606']}]",'Walter de Gruyter GmbH',Designing nanophotonic structures using conditional deep convolutional generative adversarial networks,10.1515/nanoph-2019-0117,,core
387319181,2021-02-09T00:00:00,"We introduce a novel data-driven framework for the design of targeted gene
panels for estimating exome-wide biomarkers in cancer immunotherapy. Our first
goal is to develop a generative model for the profile of mutation across the
exome, which allows for gene- and variant type-dependent mutation rates. Based
on this model, we then propose a new procedure for estimating biomarkers such
as Tumour Mutation Burden and Tumour Indel Burden. Our approach allows the
practitioner to select a targeted gene panel of a prespecified size, and then
construct an estimator that only depends on the selected genes. Alternatively,
the practitioner may apply our method to make predictions based on an existing
gene panel, or to augment a gene panel to a given size. We demonstrate the
excellent performance of our proposal using an annotated mutation dataset from
1144 Non-Small Cell Lung Cancer patients.Comment: 21 pages, 10 figure",,,"Data-driven design of targeted gene panels for estimating immunotherapy
  biomarkers",,http://arxiv.org/abs/2102.04296,core
343637812,2020-01-01T00:00:00,,,'Institute of Electrical and Electronics Engineers (IEEE)',Machine Learning at the Edge: A Data-Driven Architecture with Applications to 5G Cellular Networks,10.1109/tmc.2020.2999852,,core
387880698,2020-01-01T00:00:00,"In this paper, we propose a novel sensor validation architecture, which performs sensor fault detection, isolation and accommodation (SFDIA). More specifically, a machine-learning based architecture is presented to detect faults in sensors measurements within the system, identify the faulty ones and replace them with estimated values. In our proposed architecture, sensor estimators based on neural networks are constructed for each sensor node in order to accommodate faulty measurements along with a classifier to determine the failure detection and isolation. Finally, numerical results are presented to confirm the effectiveness of the proposed architecture on a publicly-available air quality (AQ) chemical multi-sensor data-set",,'Institute of Electrical and Electronics Engineers (IEEE)',A Data-Driven Architecture for Sensor Validation Based on Neural Networks,,,core
475696546,2020-05-01T07:00:00,"For the 12 GeV upgrade of Jefferson Laboratory, a Silicon Vertex Tracker (SVT) has been designed for theCLAS12 spectrometer using single-sided microstrip sensors fabricated by Hamamatsu Photonics. The sensors have a graded angle design to minimize dead areas and a readout pitch of156 μm, with intermediate strips. Each double-sided SVT module hosts three daisy-chained sensors on each side with a full strip length of33 cm. There are 512 channels per module, read out by four Fermilab Silicon Strip Readout (FSSR2) chips, featuring data-driven architecture, mounted on a rigid–flex hybrid board. The modules are assembled in a barrel configuration using a unique cantilevered geometry to minimize the amount of material in the tracking volume. This paper is focused on the design, qualification of the performance, and experience in operating and commissioning the tracker during the first year of the data taking",,UR Scholarship Repository,The CLAS12 Silicon Vertex Tracker,,,core
480021211,2021-01-01T00:00:00,"Data-Driven Design (DDD) – это дизайн на основе данных, полученных в результате исследований. С приходом DDD усложнился анализ потребностей, интерфейсы стали персонализированными, дизайн стал ориентированным на бизнес-показатели, а профессия веб-дизайнера распалась на составляющие. Основное преимущество DDD-подхода состоит в том, что все дизайн-решения обоснованы, исключается элемент вкусовщины. Но DDD в чистом виде часто ведет к перегибам – «машинному» подходу при разработке продукта для людей. Наиболее успешные сервисы придерживаются несколько иного подхода – Data-Informed Design – дизайн с учетом данных, но без слепого подчинения им. Data-Driven Design (DDD) is the design based on research data. With the advent of DDD, needs analysis became more complex, interfaces became personalized, design began to be focused on business performance, and the web designer profession resolved into specializations. The main advantage of the DDD approach is that all design decisions are justified, the element of taste is excluded. But DDD in its purest form often leads to kinks – ""machine"" approach to product development. The most successful services take a bit different approach – Data-Informed Design – design with data in mind, but without blind obedience to it",,"БГУИР, РБ",Data-Driven approach to web design,,,core
275725174,2019-12-26T00:00:00,"We show that a neural network whose output is obtained as the difference of the outputs of two feedforward networks with exponential activation function in the hidden layer and logarithmic activation function in the output node (LSE networks) is a smooth universal approximator of continuous functions over convex, compact sets. By using a logarithmic transform, this class of networks maps to a family of subtraction-free ratios of generalized posynomials, which we also show to be universal approximators of positive functions over log-convex, compact subsets of the positive orthant. The main advantage of Difference-LSE networks with respect to classical feedforward neural networks is that, after a standard training phase, they provide surrogate models for design that possess a specific difference-of-convex-functions form, which makes them optimizable via relatively efficient numerical methods. In particular, by adapting an existing difference-of-convex algorithm to these models, we obtain an algorithm for performing effective optimization-based design. We illustrate the proposed approach by applying it to data-driven design of a diet for a patient with type-2 diabetes",,HAL CCSD,A Universal Approximation Result for Difference of log-sum-exp Neural Networks,,,core
491073645,2021-12-15T00:00:00,"Recent applications of machine learning (ML) reveal a noticeable shift from
its use for predictive modeling in the sense of a data-driven construction of
models mainly used for the purpose of prediction (of ground-truth facts) to its
use for prescriptive modeling. What is meant by this is the task of learning a
model that stipulates appropriate decisions about the right course of action in
real-world scenarios: Which medical therapy should be applied? Should this
person be hired for the job? As argued in this article, prescriptive modeling
comes with new technical conditions for learning and new demands regarding
reliability, responsibility, and the ethics of decision making. Therefore, to
support the data-driven design of decision-making agents that act in a rational
but at the same time responsible manner, a rigorous methodological foundation
of prescriptive ML is needed. The purpose of this short paper is to elaborate
on specific characteristics of prescriptive ML and to highlight some key
challenges it implies. Besides, drawing connections to other branches of
contemporary AI research, the grounding of prescriptive ML in a (generalized)
decision-theoretic framework is advocated",,,"Prescriptive Machine Learning for Automated Decision Making: Challenges
  and Opportunities",,http://arxiv.org/abs/2112.08268,core
323312234,2020-03-29T00:00:00,"This paper studies how to design abstractions of large-scale combinatorial optimization problems that can leverage existing state-of-the-art solvers in general purpose ways, and that are amenable to data-driven design. The goal is to arrive at new approaches that can reliably outperform existing solvers in wall-clock time. We focus on solving integer programs, and ground our approach in the large neighborhood search (LNS) paradigm, which iteratively chooses a subset of variables to optimize while leaving the remainder fixed. The appeal of LNS is that it can easily use any existing solver as a subroutine, and thus can inherit the benefits of carefully engineered heuristic approaches and their software implementations. We also show that one can learn a good neighborhood selector from training data. Through an extensive empirical validation, we demonstrate that our LNS framework can significantly outperform, in wall-clock time, compared to state-of-the-art commercial solvers such as Gurobi",,,A General Large Neighborhood Search Framework for Solving Integer Programs,,https://core.ac.uk/download/323312234.pdf,core
387312911,2021-01-26T00:00:00,"A new class of rare-earth-free permanent magnets is proposed. The parent
compound of this class is Co$_3$Mn$_2$Ge, and its discovery is the result of
first principles theory combined with experimental synthesis and
characterisation. The theory is based on a high-throughput/data-mining search
among materials listed in the ICSD database. From ab-initio theory of the
defect free material it is predicted that the saturation magnetization is 1.71
T, the uniaxial magnetocrystalline anisotropy is 1.44 MJ/m$^3$, and the Curie
temperature is 700 K. Co$_3$Mn$_2$Ge samples were then synthesized and
characterised with respect to structure and magnetism. The crystal structure
was found to be the MgZn$_2$-type, with partial disorder of Co and Ge on the
crystallographic lattice sites. From magnetization measurements a saturation
polarization of 0.86 T at 10 K was detected, together with a uniaxial
magnetocrystalline anisotropy constant of 1.18 MJ/m$^3$, and the Curie
temperature of $T_{\rm C}$ = 359 K. These magnetic properties make
Co$_3$Mn$_2$Ge a very promising material as a rare-earth free permanent magnet,
and since we can demonstrate that magnetism depends critically on the amount of
disorder of the Co and Ge atoms, a further improvement of the magnetism is
possible. From the theoretical works, a substitution of Ge by neighboring
elements suggest two other promising materials - Co$_3$Mn$_2$Al and
Co$_3$Mn$_2$Ga. We demonstrate here that the class of compounds based on
$T_3$Mn$_2$X (T = Co or alloys between Fe and Ni; X=Ge, Al or Ga) in the
MgZn$_2$ structure type, form a new class of rare-earth free permanent magnets
with very promising performance",,,Data-driven design of a new class of rare-earth free permanent magnets,,http://arxiv.org/abs/2101.10773,core
334894834,2019-12-19T00:00:00,"In radar systems, unimodular (or constant-modulus) waveform design plays an
important role in achieving better clutter/interference rejection, as well as a
more accurate estimation of the target parameters. The design of such sequences
has been studied widely in the last few decades, with most design algorithms
requiring sophisticated a priori knowledge of environmental parameters which
may be difficult to obtain in real-time scenarios. In this paper, we propose a
novel hybrid model-driven and data-driven architecture that adapts to the ever
changing environment and allows for adaptive unimodular waveform design. In
particular, the approach lays the groundwork for developing extremely low-cost
waveform design and processing frameworks for radar systems deployed in
autonomous vehicles. The proposed model-based deep architecture imitates a
well-known unimodular signal design algorithm in its structure, and can quickly
infer statistical information from the environment using the observed data. Our
numerical experiments portray the advantages of using the proposed method for
efficient radar waveform design in time-varying environments",,,Deep Radar Waveform Design for Efficient Automotive Radar Sensing,,http://arxiv.org/abs/1912.08180,core
334921588,2020-03-11T00:00:00,"Critical aspects of computational imaging systems, such as experimental
design and image priors, can be optimized through deep networks formed by the
unrolled iterations of classical model-based reconstructions (termed
physics-based networks). However, for real-world large-scale inverse problems,
computing gradients via backpropagation is infeasible due to memory limitations
of graphics processing units. In this work, we propose a memory-efficient
learning procedure that exploits the reversibility of the network's layers to
enable data-driven design for large-scale computational imaging systems. We
demonstrate our method on a small-scale compressed sensing example, as well as
two large-scale real-world systems: multi-channel magnetic resonance imaging
and super-resolution optical microscopy.Comment: 9 pages, 8 figures. See also relate NeurIPS 2019 presentation
  arXiv:1912.0509",,,Memory-efficient Learning for Large-scale Computational Imaging,,http://arxiv.org/abs/2003.05551,core
478130993,2021-05-01T15:46:34,"Recent advancements in computer technology have allowed for designers to have direct control over the production process through the help of computer-based tools, creating the possibility of a completely integrated design and manufacturing process. Over the last few decades, ""artificial intelligence"" (AI) techniques, such as machine learing and deep learning, have been topics of interest in computer-based design and manufacturing research fields. However, efforts to develop computer-based AI to handle big data in design and manufacturing have not yet been successful. This Special Issue aims to collect novel articles covering artificial intelligence-based design, manufacturing, and data-driven design. It will comprise academics, researchers, mechanical, manufacturing, production and industrial engineers and professionals related to engineering design and manufacturing",,'MDPI AG',Computer-Aided Manufacturing and Design,10.3390/books978-3-03943-135-9,,core
328359639,2020-01-01T00:00:00,"The paper presents a systematic literature review investigating definitions, uses, and application of data-driven design in the concept development process. The analysis shows a predominance of the use of text mining techniques on social media and online reviews to identify customers’ needs, not exploiting the opportunity granted by the increased accessibility of IoT in cyber-physical systems. The paper argues that such a gap limits the potential of capturing tacit customers’ needs and highlights the need to proactively plan and design for a transition toward data-driven design.Open access</p",,'Cambridge University Press (CUP)',Data-driven design in concept development : systematic review and missed opportunities,10.1017/dsd.2020.4,,core
480460325,2021-01-01T00:00:00,"This thesis considers the analysis and design of algorithms for the management and control of uncertain intelligent systems which are observable through (limited) online-accessible data. Examples include online equity trading systems under extreme price fluctuations, robotic systems moving in unknown environments, and transportation systems subject to uncertain drivers’ actions and other (accident) events.To ensure safe, reliable, and resilient system behaviors, this thesis studies various theoretical problem scenarios, which focus on reducing uncertainty with performance guarantees via the assimilation of streaming data, the data-driven design of control, and online learning of system models, resilient operations in uncertain environments, and anomaly detection.These formulations are largely rooted in two mechanisms: online optimization and distributionally robust optimization, where the first enables online-tractable formulations of the problem, and the latter accounts for systemic uncertainty with high confidence. Both approaches  are applicable beyond the particular systems of study, to virtually any type of dynamic system where sensitive data is progressively available and may be exploited to the advantage of management and control. This work is unique in that it brings together current tools in optimization, control of dynamical systems, data-based modeling and probability theory, significantly advancing the state of the art",,"eScholarship, University of California",Data-Driven Online Optimization and Control with Performance Guarantees,,,core
386165922,2020-12-23T00:00:00,"In a world concerned with the coronavirus pandemic, many governments do not know how to control the disease. Although there are several technologies that generate citizen data, transparency, and privacy are very important to ensure social engagement and more effectiveness in fighting the virus. This article analyzed some applications that contact tracing people or inform them about the disease. We selected the applications based on how they captured data, privacy issues, citizen participation, and the main challenges faced. Later, we created the app journey map to compare them and discovered the most used technology is Bluetooth, and the apps often have open source. However, these initiatives bring superficial insights and need to integrate with more complex data",,'UNISINOS - Universidade do Vale do Rio Dos Sinos',Citizen data-driven design for pandemic monitoring,10.4013/sdrj.2020.133.04,https://core.ac.uk/download/386165922.pdf,core
232203331,2019-09-30T00:00:00,"Background
One of the European Union directives indicates that 10% of all fuels must be bio-synthesized by 2020. In this regard, biobutanolnatively produced by clostridial strainsposes as a promising alternative biofuel. One possible approach to overcome the difficulties of the industrial exploration of the native producers is the expression of more suitable pathways in robust microorganisms such as Escherichia coli. The enumeration of novel pathways is a powerful tool, allowing to identify non-obvious combinations of enzymes to produce a target compound.

Results
This work describes the in silico driven design of E. coli strains able to produce butanol via 2-oxoglutarate by a novel pathway. This butanol pathway was generated by a hypergraph algorithm and selected from an initial set of 105,954 different routes by successively applying different filters, such as stoichiometric feasibility, size and novelty. The implementation of this pathway involved seven catalytic steps and required the insertion of nine heterologous genes from various sources in E. coli distributed in three plasmids. Expressing butanol genes in E. coli K12 and cultivation in High-Density Medium formulation seem to favor butanol accumulation via the 2-oxoglutarate pathway. The maximum butanol titer obtained was 85±1 mg L1 by cultivating the cells in bioreactors.

Conclusions
In this work, we were able to successfully translate the computational analysis into in vivo applications, designing novel strains of E. coli able to produce n-butanol via an innovative pathway. Our results demonstrate that enumeration algorithms can broad the spectrum of butanol producing pathways. This validation encourages further research to other target compounds.This study was supported by the Portuguese Foundation for Science and Technology (FCT) under the scope of a Ph.D. Grant (PD/BD/52366/2013) from MIT Portugal Program and the strategic funding of UID/BIO/04469 unit. Additional support was received by COMPETE 2020 (POCI-01-0145-FEDER-006684) and BioTecNorte operation (NORTE-01-0145-FEDER-000004) funded by the European Regional Development Fund under the scope of Norte2020-Programa Operacional Regional do Norte.

The authors also thank the Times New Roman project “Dynamics”, Ref. ERA-IB-2/0002/2014, funded by national funds through FCT/MCTES.

The genes thl, hbd, crt and adhE1 were kindly provided by Kristala L. Jones Prather from MIT.

The authors thank the project DDDeCaF - Bioinformatics Services for Data-Driven Design of Cell Factories and Communities, Ref. H2020-LEIT-BIO-2015-1 686070–1, funded by the European Commission and the Project LISBOA010145 FEDER007660 (Microbiologia Molecular, Estrutural e Celular) funded by FEDER funds through COMPETE2020 Programa Operacional Competitividade e Internacionalização (POCI) and by national funds through FCT Fundacao para a Ciencia e a Tecnologiainfo:eu-repo/semantics/publishedVersio","[{'title': 'Biotechnology for Biofuels', 'identifiers': ['1754-6834', 'issn:1754-6834']}]",'Springer Science and Business Media LLC',Discovery and implementation of a novel pathway for n-butanol production via 2-oxoglutarate,10.1186/s13068-019-1565-x,https://core.ac.uk/download/232203331.pdf,core
195731503,2019,"This paper addresses the problem of achieving high-performance dynamic control allocation for uncertain plants by exploiting a data-driven design of the annihilator for the underlying plant. Previous work revealed that an output invisible control allocator can be decomposed as the cascade interconnection of a steady-state optimizer and an annihilator, where the latter unit modulates the allocator outputs in such a way to render such signals undetectable from the plant output. Clearly, the critical role and challenging requirements imposed on the annihilator make it the source of the fragility of control allocation schemes in the presence of uncertainty; nonetheless this critical aspect can be (almost) completely circumvented by tuning the annihilator to the actual plant parameters, namely by envisioning a data-driven control allocation scheme. Relations are also highlighted between the present results and the concepts of moments and orthogonal moments of a plant at frequencies of interest, whose use and estimation have recently been the subject of increasing interest",,IEEE,Data-Driven Dynamic Control Allocation for Uncertain Redundant Plants,10.1109/CDC.2018.8619485,,core
388600655,2021-01-01T00:00:00,"Elastic boundary conditions play an important role in the buckling analysis of cylinders under compressive
loading. These structures are used widely in aerospace applications and are highly sensitive to geometrical,
material, loading, and boundary imperfections. In fact, the presence of these imperfections can lead to catastrophic failure. In 1968, NASA reported relations for obtaining the Knockdown Factor (KDF) based on an
empirical method that is valid for isotropic and orthotropic materials; however, these relations do not consider
the effect of elastic boundaries that can lead to highly conservative values of KDF. In design practice, a universal KDF of 0.65 has been used for recent designs by NASA, which may not be applicable to new types of structural configuration with different loading and boundary conditions. Therefore, there is a need for robust design
factors for future designs which reduce the dependency on testing during preliminary design phases and speeds
up the product development process. The availability of up‐to‐date and different KDF expressions for different
structural configurations would help engineers to design lighter structures with improved load carrying capacity and reliability. The main objective of this work is to identify the buckling load sensitivity of cylindrical
shells due to their boundary conditions and develop KDF relations considering elastic boundaries. To achieve
this goal, the effect of axial, radial and tangential support stiffness on a quasi‐isotropic cylinder under axial
compression is investigated. A data‐driven design approach is used to develop new KDF empirical relations
for a quasi‐isotropic cylinder on different elastic foundations. The accuracy of these relations is within 5%
for any elastic foundation considered",,'Elsevier BV',Design considerations for composite cylindrical shells on elastic foundations subject to compression buckling,,,core
391332715,2021-02-08T00:00:00,,,,Data-driven design of targeted gene panels for estimating immunotherapy biomarkers,,https://core.ac.uk/download/391332715.pdf,core
287505383,2019-12-11T00:00:00,,,'Springer Science and Business Media LLC',Data-driven design of metal–organic frameworks for wet flue gas CO<sub>2</sub> capture,10.1038/s41586-019-1798-7,,core
275552109,2019-12-11T00:00:00,,,'Organisation for Economic Co-Operation and Development  (OECD)',Data-driven design of metal-organic frameworks for wet flue gas CO<sub>2</sub> capture.,10.17863/CAM.47153,,core
339161471,2020-01-01T00:00:00,"While the global impact of plastic waste is increasingly concerning, the application of reused materials in the built environment remains little explored. This paper presents research into the reuse of plastic in architecture by means of computational design and robotic fabrication. Design possibilities using reclaimed plastic artefacts were explored by testing their structural stability and robotically modifying them in order to create a pavilion. While the design conceptualization started with the reclaimed material and the analysis of its potential, the digital workflow involved generative and performance- driven design, structural optimization and geometry generation for robotic fabrication.Architectural Engineerin",,'International Association for Automation and Robotics in Construction (IAARC)',Towards Circular Economy in Architecture by Means of Data-driven Design-to- Robotic-Production,10.22260/ISARC2020/0010,,core
478917768,2021-01-01T00:00:00,"A popular way to accelerate the sampling of rare events in molecular dynamics simulations is to introduce a potential that increases the fluctuations of selected collective variables. For this strategy to be successful, it is critical to choose appropriate variables. Here we review some recent developments in the data-driven design of collective variables, which combine Fisher’s discriminant analysis and neural networks. This approach allows to compress the fluctuations of metastable states into a low-dimensional representation. We illustrate through different applications the effectiveness of this method in accelerating the sampling, while also identifying the physical descriptors that undergo the most significant changes in the process",,Societa italiana di fisica,Training collective variables for enhanced sampling via neural networks based discriminant analysis,10.1393/ncc/i2021-21125-3,,core
333888347,2020-04-14T00:00:00,"Driven by technological advances, growing amounts of available data, and an emergent need for participatory processes, landscape architecture is witnessing a moment of disruption whereby formerly separated areas of operation become increasingly connected. While distinctions between various aspects of the design process are diminishing, a need for a novel, more inclusive toolset arises. The ‘tangible table’ paradigm is an attempt at combining intuitive ways of physical modelling with data-driven design strategies and the interactive simulation of naturally occurring phenomena. Despite its existence for more than 20 years, tangible tables have mainly focused on very specific workflows and therefore have not found wider adoption in landscape architectural practice or education. We list the limitations of previous implementations and introduce a novel software solution aimed at popularizing tangible table setups. Our software is embedded in a widespread visual programming environment, which allows for straightforward augmentation of physical models with computational design tech-niques. Using a week-long PhD course as a case study, we demonstrate the usefulness of the proposed software and its potential applications to solving various landscape architectural challenges through increased emphasis on participatory processes.Peer reviewe","[{'title': None, 'identifiers': ['2367-4253', 'issn:2367-4253', 'issn:2511-624X', '2511-624x']}]",Wichmann Verlag im VDE Verlag GmbH,Bridging tangible and virtual realities : Computational procedures for data-informed participatory processes,10.14627/537690036,,core
459159662,2021-10-25T00:00:00,"Attribute extrapolation in sample generation is challenging for deep neural
networks operating beyond the training distribution. We formulate a new task
for extrapolation in sequence generation, focusing on natural language and
proteins, and propose GENhance, a generative framework that enhances attributes
through a learned latent space. Trained on movie reviews and a computed protein
stability dataset, GENhance can generate strongly-positive text reviews and
highly stable protein sequences without being exposed to similar data during
training. We release our benchmark tasks and models to contribute to the study
of generative modeling extrapolation and data-driven design in biology and
chemistry.Comment: NeurIPS 202",,,Deep Extrapolation for Attribute-Enhanced Generation,,http://arxiv.org/abs/2107.02968,core
387317878,2021-02-04T00:00:00,"The need to recover high-dimensional signals from their noisy low-resolution
quantized measurements is widely encountered in communications and sensing. In
this paper, we focus on the extreme case of one-bit quantizers, and propose a
deep detector entitled LoRD-Net for recovering information symbols from one-bit
measurements. Our method is a model-aware data-driven architecture based on
deep unfolding of first-order optimization iterations. LoRD-Net has a
task-based architecture dedicated to recovering the underlying signal of
interest from the one-bit noisy measurements without requiring prior knowledge
of the channel matrix through which the one-bit measurements are obtained. The
proposed deep detector has much fewer parameters compared to black-box deep
networks due to the incorporation of domain-knowledge in the design of its
architecture, allowing it to operate in a data-driven fashion while benefiting
from the flexibility, versatility, and reliability of model-based optimization
methods. LoRD-Net operates in a blind fashion, which requires addressing both
the non-linear nature of the data-acquisition system as well as identifying a
proper optimization objective for signal recovery. Accordingly, we propose a
two-stage training method for LoRD-Net, in which the first stage is dedicated
to identifying the proper form of the optimization process to unfold, while the
latter trains the resulting model in an end-to-end manner. We numerically
evaluate the proposed receiver architecture for one-bit signal recovery in
wireless communications and demonstrate that the proposed hybrid methodology
outperforms both data-driven and model-based state-of-the-art methods, while
utilizing small datasets, on the order of merely $\sim 500$ samples, for
training",,'Institute of Electrical and Electronics Engineers (IEEE)',LoRD-Net: Unfolded Deep Detection Network with Low-Resolution Receivers,10.1109/TSP.2021.3117503,http://arxiv.org/abs/2102.02993,core
334848684,2019-08-19T00:00:00,"Symbolic regression (SR) is an emerging method for building analytical
formulas to find models that best fit data sets. Here, SR was used to guide the
design of new oxide perovskite catalysts with improved oxygen evolution
reaction (OER) activities. An unprecedentedly simple descriptor, {\mu}/t, where
{\mu} and t are the octahedral and tolerance factors, respectively, was
identified, which accelerated the discovery of a series of new oxide perovskite
catalysts with improved OER activity. We successfully synthesized five new
oxide perovskites and characterized their OER activities. Remarkably, four of
them, Cs0.4La0.6Mn0.25Co0.75O3, Cs0.3La0.7NiO3, SrNi0.75Co0.25O3, and
Sr0.25Ba0.75NiO3, outperform the current state-of-the-art oxide perovskite
catalyst, Ba0.5Sr0.5Co0.8Fe0.2O3 (BSCF). Our results demonstrate the potential
of SR for accelerating data-driven design and discovery of new materials with
improved properties",,,"Symbolic Regression Discovery of New Perovskite Catalysts with High
  Oxygen Evolution Reaction Activity",,http://arxiv.org/abs/1908.06778,core
380759084,2019-12-01T00:00:00,"Pythium irregulare is an oleaginous Oomycete able to accumulate large amounts of lipids, including Eicosapentaenoic acid (EPA). EPA is an important and expensive dietary supplement with a promising and very competitive market, which is dependent on fish-oil extraction. This has prompted several research groups to study biotechnological routes to obtain specific fatty acids rather than a mixture of various lipids. Moreover, microorganisms can use low cost carbon sources for lipid production, thus reducing production costs. Previous studies have highlighted the production of EPA by P. irregulare, exploiting diverse low cost carbon sources that are produced in large amounts, such as vinasse, glycerol, and food wastewater. However, there is still a lack of knowledge about its biosynthetic pathways, because no functional annotation of any Pythium sp. exists yet. The goal of this work was to identify key genes and pathways related to EPA biosynthesis, in P. irregulare CBS 494.86, by sequencing and performing an unprecedented annotation of its genome, considering the possibility of using wastewater as a carbon source.The genome sequencing, strain acquisition and preliminary experiments and data analysis were funded by the São Paulo Research Foundation (FAPESP) and Coordination for the Improvement of Higher Education Personnel (CAPES) (Grante: 2016/10562–4). The experiment performance, data collection, analysis and interpretation of data were supported by the Portuguese Foundation for Science and Technology (FCT) under the scope of the strategic funding of [UID/BIO/04469] unit and COMPETE 2020 [POCI01-0145-FEDER-006684] and BioTecNorte operation [NORTE-01-0145-FEDER000004] funded by the European Regional Development Fund under the scope of Norte2020 - Programa Operacional Regional do Norte. The authors thank the project DD-DeCaF - Bioinformatics Services for Data-Driven Design of Cell Factories and Communities, Ref. H2020-LEIT-BIO-2015-1 686070–1, funded by the European Commission.info:eu-repo/semantics/publishedVersio","[{'title': 'BMC Biotechnology', 'identifiers': ['1472-6750', 'issn:1472-6750']}]",'Springer Science and Business Media LLC',Genome-wide sequencing and metabolic annotation of Pythium irregulare CBS 494.86: understanding Eicosapentaenoic acid production,10.1186/s12896-019-0529-3,,core
223033324,2019-07-01T00:00:00,"Objectives: Effective secondary stroke prevention strategies are sub-optimally used. Novel development of interventions to enable healthcare professionals and stroke survivors to manage risk factors for stroke recurrence are required. We sought to engage key stakeholders in the design and evaluation of an intervention informed by a Learning Health System approach, to improve risk factor management and secondary prevention for stroke survivors with multimorbidity. Design: Qualitative, including focus groups, semi-structured interviews and usability evaluations. Data was audio-recorded, transcribed and coded thematically. Participants: Stroke survivors, carers, health and social care professionals, commissioners, policy makers and researchers. Setting: Stroke survivors were recruited from the South London Stroke Register; health and social care professionals through South London general practices and King’s College London (KCL) networks; carers, commissioners, policy-makers and researchers through KCL networks. Results: 53 stakeholders in total participated in focus groups, interviews and usability evaluations. Thirty-seven participated in focus groups and interviews, including stroke survivors and carers (N=11), health and social care professionals (N=16), commissioners and policy-makers (N=6) and researchers (N=4). Sixteen participated in usability evaluations, including stroke survivors (N=8) and general practitioners (GPs; N=8). Eight themes informed the collaborative design of DOTT (Deciding on Treatments Together), a decision aid integrated with the electronic health record system, to be used in primary care during clinical consultations between the healthcare professional and stroke survivor. DOTT aims to facilitate shared decision making on personalised treatments leading to improved treatment adherence and risk control. DOTT was found acceptable and usable among stroke survivors and GPs during a series of evaluations. Conclusions: Adopting a user-centred data-driven design approach informed an intervention that is acceptable to users and has the potential to improve patient outcomes. A future feasibility study and subsequent clinical trial will provide evidence of the effectiveness of DOTT in reducing risk of stroke recurrence","[{'title': 'BMJ Open', 'identifiers': ['2044-6055', 'issn:2044-6055']}]",'BMJ',Collaborative design of a decision aid for stroke survivors with multimorbidity: a qualitative study in the UK engaging key stakeholders,10.1136/bmjopen-2019-030385,,core
483914236,2021-01-01T00:00:00,"Orientador: Prof. Dr. Aguinaldo dos SantosDissertação (mestrado) - Universidade Federal do Paraná, Setor de Artes, Comunicação e
Design, Programa de Pós-Graduação em Design. Defesa : Curitiba, 28/05/2021Inclui referências: p. 138-153Resumo: A presente dissertação apresenta um estudo com característica exploratória, de natureza aplicada, por meio de uma abordagem fenomenológica e qualitativa, sobre o uso do Data- Driven Design em um briefing metaprojetual para promover comportamentos mais sustentáveis. Ao longo das últimas décadas, as inovações em tecnologias da informação e comunicação vêm proporcionando diversas transformações no mercado de consumo e alterando o comportamento dos usuários. Essas modificações ocorrem nos diferentes pontos da jornada de consumo, seja no modo como os usuários pesquisam, adquirem, utilizam, avaliam ou descartam produtos e serviços. Consequentemente, o aumento da quantidade de dados digitais (big data) e do volume de tráfego on-line tem sido exponencial. Por meio da análise de big data é possível obter novo e/ou melhor entendimento acerca do comportamento humano de modo a influenciá-lo. Entretanto, muitas dessas análises estão sendo utilizadas como instrumentos para estimular o consumo. Neste cenário, os comportamentos de consumo dos últimos 50 anos têm contribuído para os impactos negativos na sustentabilidade, como por exemplo, para o aumento da temperatura do planeta. Por outro lado, as investigações de big data também podem apresentar oportunidades para o Data-Driven Design para o Comportamento Sustentável, como a elaboração de briefings metaprojetuais de: produto; serviço; Sistemas de Produto+Serviço (PSS); políticas públicas. Diante disso, este estudo teve como objetivo propor Diretrizes para Briefing Metaprojetual de Data-Driven Design para o Comportamento Sustentável. Como estratégia para a condução da pesquisa utilizou-se um conjunto de métodos, distribuídos ao longo de cinco fases, contemplando: 1. Revisões Bibliográficas (Assistemática e Sistemática); 2. Estudo de Caso ex-post-facto; 3. e 4. Action Design Research (Design Science Research e Pesquisa-Ação); 5. Análise Cruzada. O desenvolvimento da dissertação contou com o apoio de variados parceiros, dentre eles: uma agência de business intelligence, uma empresa de tecnologia médica, um órgão da ONU, pesquisadores de Design e pesquisadores de Ciência de Dados. Através das quatro fases iniciais, foi possível apurar, compreender e analisar os conceitos, para posteriormente propor diretrizes. Na última fase, todas as diretrizes foram avaliadas, refinadas e formalizadas em Diretrizes Finais. As diretrizes visam oferecer a designers um referencial que viabilize a elaboração de briefings metaprojetuais, que por meio do big data possibilite a compreensão do perfil dos usuários e aponte a estratégia de Design para Comportamento Sustentável mais adequada.Abstract: This dissertation presents an exploratory study, of an applied nature, through a phenomenological and qualitative approach, on the use of Data-Driven Design in a briefing of meta-projects to promote more sustainable behaviors. In recent decades, innovations in information and communication technologies have brought about several transformations in the costumers market and changed the users' behavior. These changes occur at different points in the customer journey, whether in the way users search, buy, use, evaluate or discard products and services. Consequently, the amount of digital data (big data) and the volume of online traffic has been increasing exponentially. Through big data analytics, it is possible to gain a new and/or better understanding of human behavior to influence it. However, many of these analyzes are being used as instruments to encourage consumption. In this scenario, the consumption behavior of the last 50 years contributed to negative impacts on sustainability, such as the increase in the planet's temperature. On the other hand, big data investigations can also present opportunities for Data-Driven Design for Sustainable Behaviour, such as developing meta-project briefings for a product; service; Product+Service Systems (PSS); public policies. Therefore, this study aimed to propose Data-Driven Design for Sustainable Behaviour Meta-Project Briefing Guidelines. As a strategy for conducting the research, a set of methods was used, distributed in five phases: 1.?? Literature Reviews (Unsystematic and Systematic); 2. Ex post-facto case study; 3. and 4.?? Action Design Research (Design Science Research and Action Research); 5. Cross analysis.?? The dissertation development was supported by several partners, including a business?? intelligence agency, a medical technology company, a UN agency, design researchers, and?? data science researchers. Through the four initial phases, it was possible to know,?? understand and analyze the concepts, to later propose guidelines. In the last phase, all?? guidelines were evaluated, refined, and formalized in the Final Guidelines. The guidelines?? aim to offer designers a framework that enables the preparation of briefings for metaprojects, which, through big data, make it possible to understand the profile of users and?? point out the most appropriate Design for Sustainable Behaviour strategy",,,Data-Driven Design orientado ao comportamento sustentável : diretrizes para briefing metaprojetual,,,core
344884759,2020-01-01T00:00:00,"International audienceThe paper presents a four-layer framework for the application of data-driven design in a product innovation process. The framework builds on the Knowledge Value Stream and on the Product Value Streams of a product innovation process and indicates how data-driven activities shall be structured and organised in relation to the different phases of a model-based decision process. Visualisation is proposed as a communication enabler at the top of the framework to overcome the comprehensibility barrier between data science and engineering design models. The framework is implemented in the case study of a construction equipment encompassing the analysis of operational machine data and the experimentation of suitable visualisation techniques. Ultimately, a list of challenges for the implementation of data-driven design is presented, and the capability of the framework to support the transition toward data-driven design is discussed in relation to the emergence of product-service systems solutions",,'Inderscience Publishers',A framework for data-driven design in a product innovation process: data analysis and visualisation for model-based decision making,10.1504/IJPD.2020.106464,,core
427315752,2020-12-09T00:00:00,"The design of online algorithms has tended to focus on algorithms with worst-case guarantees, e.g., bounds on the competitive ratio. However, it is well-known that such algorithms are often overly pessimistic, performing sub-optimally on non-worst-case inputs. In this paper, we develop an approach for data-driven design of online algorithms that maintain near-optimal worst-case guarantees while also performing learning in order to perform well for typical inputs. Our approach is to identify policy classes that admit global worst-case guarantees, and then perform learning using historical data within the policy classes. We demonstrate the approach in the context of two classical problems, online knapsack and online set cover, proving competitive bounds for rich policy classes in each case. Additionally, we illustrate the practical implications via a case study on electric vehicle charging",,,Data-driven Competitive Algorithms for Online Knapsack and Set Cover,,https://core.ac.uk/download/427315752.pdf,core
327254603,2020-08-08T00:00:00,"With the achievement on the additive manufacturing, the mechanical properties
of architectured materials can be precisely designed by tailoring
microstructures. As one of the primary design objectives, the elastic isotropy
is of great significance for many engineering applications. However, the
prevailing experimental and numerical methods are normally too costly and
time-consuming to determine the elastic isotropy of architectured materials
with tens of thousands of possible microstructures in design space. The quick
mechanical characterization is thus desired for the advanced design of
architectured materials. Here, a deep learning-based approach is developed as a
portable and efficient tool to identify the elastic isotropy of architectured
materials directly from the images of their representative microstructures with
arbitrary component distributions. The measure of elastic isotropy for
architectured materials is derived firstly in this paper to construct a
database with associated images of microstructures. Then a convolutional neural
network is trained with the database. It is found that the convolutional neural
network shows good performance on the isotropy identification. Meanwhile, it
exhibits enough robustness to maintain the performance under fluctuated
material properties in practical fabrications. Moreover, the well-trained
convolutional neural network can be successfully transferred among different
types of architectured materials, including two-phase composites and porous
materials, which greatly enhance the efficiency of the deep learning-based
approach. This study can give new inspirations on the fast mechanical
characterization for the big-data driven design of architectured materials.Comment: 15 pages, 7 figures; Correct the citation in Ref.2",,,"Identifying the elastic isotropy of architectured materials based on
  deep learning method",,http://arxiv.org/abs/2008.00442,core
350944147,2020-04-14T00:00:00,"Driven by technological advances, growing amounts of available data, and an emergent need for participatory processes, landscape architecture is witnessing a moment of disruption whereby formerly separated areas of operation become increasingly connected. While distinctions between various aspects of the design process are diminishing, a need for a novel, more inclusive toolset arises. The ‘tangible table’ paradigm is an attempt at combining intuitive ways of physical modelling with data-driven design strategies and the interactive simulation of naturally occurring phenomena. Despite its existence for more than 20 years, tangible tables have mainly focused on very specific workflows and therefore have not found wider adoption in landscape architectural practice or education. We list the limitations of previous implementations and introduce a novel software solution aimed at popularizing tangible table setups. Our software is embedded in a widespread visual programming environment, which allows for straightforward augmentation of physical models with computational design tech-niques. Using a week-long PhD course as a case study, we demonstrate the usefulness of the proposed software and its potential applications to solving various landscape architectural challenges through increased emphasis on participatory processes.Peer reviewe","[{'title': None, 'identifiers': ['2367-4253', 'issn:2367-4253', 'issn:2511-624X', '2511-624x']}]",Wichmann Verlag im VDE Verlag GmbH,Bridging tangible and virtual realities : Computational procedures for data-informed participatory processes,10.14627/537690036,,core
343905884,2019-01-01T00:00:00,,,'Institute of Electrical and Electronics Engineers (IEEE)',A hybrid learning method for the data-driven design of linguistic dynamic systems,10.1109/JAS.2019.1911543,,core
200814544,2019-03-20T00:00:00,"Data-driven design approaches based on deep-learning have been introduced in
nanophotonics to reduce time-consuming iterative simulations which have been a
major challenge. Here, we report the first use of conditional deep
convolutional generative adversarial networks to design nanophotonic antennae
that are not constrained to a predefined shape. For given input reflection
spectra, the network generates desirable designs in the form of images; this
form allows suggestions of new structures that cannot be represented by
structural parameters. Simulation results obtained from the generated designs
agreed well with the input reflection spectrum. This method opens new avenues
towards the development of nanophotonics by providing a fast and convenient
approach to design complex nanophotonic structures that have desired optical
properties",,,"Designing nanophotonic structures using conditional-deep convolutional
  generative adversarial networks",,http://arxiv.org/abs/1903.08432,core
220154676,2019-05-29T07:00:00,"Previous applications to design processes intend to enhance a building’s schematic design using quantitative data. Therefore, most applications to the early design phases are passed by as simple overarching ideas informed by the designer and users’ knowledge. Although this is a preferred method of choice making, the knowledge used to inform conceptual and schematic design process can be limited. With the increase of computation in all major industries, a new increase in data to describe forms of infrastructure is required. These forms being objects to analyze their performance and potential, and active forms that can describe the disposition of urban space. Previous research into data driven design has worked its way into standardization and performance goals. However, the connection between active and object forms as a network of standards has yet to be introduced as a method of advising design. Meaning design has focused on creating a single object that seems to benefit the ecology. No attempt at connecting urban active data to object data has been made to benefit both forms equally, but only to preserve the status quo. The introduction of Machine learning algorithms has the capability to connect these complex forms and inform new designs. The application of machine learning algorithms advises the early phases of architectural design process by reviewing a manifold of data, privileging complex analogical connections, and simulating the designers informed symbolic choices.
Supervisor Professor Mark A. Hoistad, AI",,DigitalCommons@University of Nebraska - Lincoln,Machine Learning in Architecture: Connectionist Approach to Architectural Design,,https://core.ac.uk/download/220154676.pdf,core
222786515,2019-12-01T00:00:00,"Pythium irregulare is an oleaginous Oomycete able to accumulate large amounts of lipids, including Eicosapentaenoic acid (EPA). EPA is an important and expensive dietary supplement with a promising and very competitive market, which is dependent on fish-oil extraction. This has prompted several research groups to study biotechnological routes to obtain specific fatty acids rather than a mixture of various lipids. Moreover, microorganisms can use low cost carbon sources for lipid production, thus reducing production costs. Previous studies have highlighted the production of EPA by P. irregulare, exploiting diverse low cost carbon sources that are produced in large amounts, such as vinasse, glycerol, and food wastewater. However, there is still a lack of knowledge about its biosynthetic pathways, because no functional annotation of any Pythium sp. exists yet. The goal of this work was to identify key genes and pathways related to EPA biosynthesis, in P. irregulare CBS 494.86, by sequencing and performing an unprecedented annotation of its genome, considering the possibility of using wastewater as a carbon source.The genome sequencing, strain acquisition and preliminary experiments and data analysis were funded by the São Paulo Research Foundation (FAPESP) and Coordination for the Improvement of Higher Education Personnel (CAPES) (Grante: 2016/10562–4). The experiment performance, data collection, analysis and interpretation of data were supported by the Portuguese Foundation for Science and Technology (FCT) under the scope of the strategic funding of [UID/BIO/04469] unit and COMPETE 2020 [POCI01-0145-FEDER-006684] and BioTecNorte operation [NORTE-01-0145-FEDER000004] funded by the European Regional Development Fund under the scope of Norte2020 - Programa Operacional Regional do Norte. The authors thank the project DD-DeCaF - Bioinformatics Services for Data-Driven Design of Cell Factories and Communities, Ref. H2020-LEIT-BIO-2015-1 686070–1, funded by the European Commission.info:eu-repo/semantics/publishedVersio","[{'title': 'BMC Biotechnology', 'identifiers': ['1472-6750', 'issn:1472-6750']}]",'Springer Science and Business Media LLC',Genome-wide sequencing and metabolic annotation of Pythium irregulare CBS 494.86: understanding Eicosapentaenoic acid production,10.1186/s12896-019-0529-3,,core
228080561,2019-01-01T00:00:00,"\u3cp\u3eNow the design of energy system requires needowners to play an active role by using advanced technical solutions to improve their responsiveness, process adaptability and empower end-users. Although need-owners via Demand Response (DR) has gain sufficient strategic improvement in energy management recently, there are still some fundamental impediments to achieve a trade-off between demand flexibility scheduling and dispatch. To find a solution to the challenge, the paper introduces the steps of an agile development process for energy systems, refers to a co-creation of solutions based on co-existing technologies and iterative development, where needowners requirements and solutions evolve through collaboration between cross-functional intelligent agents. The proof-of-the-concept is investigated by agent-oriented simulation for a generic low-voltage network of the Netherlands, which encounters transformer congestion. Simulation results reveal a significant reduction in congestion over a year while confirming expected levels of performance.\u3c/p\u3",,'Institute of Electrical and Electronics Engineers (IEEE)',Agile development process and user-centric data driven design for an integrated energy system,,,core
286208185,2019-09-01T00:00:00,"Traditional methods of scheduling are mostly based on the use of pieces of information directly related to the performance of schedules, as for instance processing times, delivery dates, etc., assuming that the production system is operating normally. In the case of malfunctions, the literature concentrates on the ensuing corrective operations, like scheduling with machine breakdowns or under remanufacturing considerations. These event-driven approaches are mainly used in dynamic scheduling or rescheduling systems. Unlike those, Smart Manufacturing and Industry 4.0 production environments integrate the physical and decision-making aspects of manufacturing processes in order to achieve their decentralization and autonomy. On these grounds we propose a data-driven architecture for scheduling, in which the system has real time access to data. Then, scheduling decisions can be made ahead of time, on the basis of more information. This promising approach is based on the architecture of cyber-physical systems, with a data-driven engine that uses, in particular, Big Data techniques to extract vital information for Industry 4.0 systems.Fil: Rossit, Daniel Alejandro. Universidad Nacional del Sur. Departamento de Ingeniería; Argentina. Consejo Nacional de Investigaciones Científicas y Técnicas. Centro Científico Tecnológico Conicet - Bahía Blanca. Instituto de Matemática Bahía Blanca. Universidad Nacional del Sur. Departamento de Matemática. Instituto de Matemática Bahía Blanca; ArgentinaFil: Tohmé, Fernando Abel. Universidad Nacional del Sur. Departamento de Economía; Argentina. Consejo Nacional de Investigaciones Científicas y Técnicas. Centro Científico Tecnológico Conicet - Bahía Blanca. Instituto de Matemática Bahía Blanca. Universidad Nacional del Sur. Departamento de Matemática. Instituto de Matemática Bahía Blanca; ArgentinaFil: Frutos, Mariano. Universidad Nacional del Sur. Departamento de Ingeniería; Argentina. Consejo Nacional de Investigaciones Científicas y Técnicas. Centro Científico Tecnológico Conicet - Bahía Blanca. Instituto de Investigaciones Económicas y Sociales del Sur. Universidad Nacional del Sur. Departamento de Economía. Instituto de Investigaciones Económicas y Sociales del Sur; Argentin","[{'title': 'Journal of Industrial Information Integration', 'identifiers': ['2452-414x', 'issn:2452-414X']}]",'Elsevier BV',A data-driven scheduling approach to smart manufacturing,10.1016/j.jii.2019.04.003,https://core.ac.uk/download/286208185.pdf,core
478113970,2022-02-01T00:00:00,"In response to rapidly changing market and customer needs, product design and development (PDD) is evolving into a human-centred and data-driven design paradigm. The design environment gets more open often involving crowdsourcing and the design process becomes more complex, considering product family design along product whole lifecycle development, and needing more data support. Therefore, it is critical to effectively capture, share, and manage design-related information in such a complex design environment. From this perspective, it is a prerequisite to have a proper product design lifecycle information model (PDLIM) to guide information gathering, sharing and management. To the best of our knowledge, currently, there lacks such a PDLIM to support effective PDD, though digital twin (DT) technology shows a great potential of supporting product lifecycle information collection and management. In this paper, the overall structure of the proposed PDLIM is firstly developed to frame in all main product lifecycle stages and the corresponding key phases for structurally capturing and storing necessary data along a product lifecycle. Secondly, key design information items against the main product lifecycle stages and their corresponding key phases are explored from literature reviews and case study analyses. Thirdly, the necessity of the identified information items in the PDLIM is qualitatively evaluated by two case studies. Finally, the PDLIM is further evaluated by applying formal object-role modelling (ORM) to demonstrate how design information items are used and interacted in exemplary design interaction scenarios, and to approve that it can be formally described and managed as an information model. The evaluation results show that the PDLIM is feasible to be adapted in a crowdsourcing-combined PDD process for supporting design management, reviewing, quality control, and next round product redesign and improvement",,'Springer Science and Business Media LLC',Product design lifecycle information model (PDLIM),10.1007/s00170-021-07945-z,,core
388982586,2020-01-01T00:00:00,,,,Conveying Data-Driven Design Information To Users: An Exploratory Study On Transparency Between A Data-Driven Culture And The Public,,,core
286560714,2019-08-05T00:00:00,"International audienceOne of the main tasks of today's data-driven design is to learn customers' concerns from the feedback data posted on the internet, to drive smarter and more profitable decisions during product development. Feature-based opinion mining was first performed by the computer and design scientists to analyse online product reviews. In order to provide more sophisticated customer feedback analyses and to understand in a deeper way customer concerns about products, the authors propose an affordance-based online review analysis framework. This framework allows understanding how and in what condition customers use their products, how user preferences change over years and how customers use the product innovatively. An empirical case study using the proposed approach is conducted with the online reviews of Kindle e-readers downloaded from amazon.com. A set of innovation leads and redesign paths are provided for the design of next-generation e-reader. This study suggests that bridging data analytics with classical models and methods in design engineering can bring success for data-driven design",,'Cambridge University Press (CUP)',An Affordance-Based Online Review Analysis Framework,10.1017/dsi.2019.252,,core
370418100,2020-01-01T00:00:00,,,place:Genova,"A big web redesign. Data driven design research through
practice and implementation",,,core
327990504,2020-08-11T00:00:00,"Magnetic Resonance Imaging (MRI) has long been considered to be among the
gold standards of today's diagnostic imaging. The most significant drawback of
MRI is long acquisition times, prohibiting its use in standard practice for
some applications. Compressed sensing (CS) proposes to subsample the k-space
(the Fourier domain dual to the physical space of spatial coordinates) leading
to significantly accelerated acquisition. However, the benefit of compressed
sensing has not been fully exploited; most of the sampling densities obtained
through CS do not produce a trajectory that obeys the stringent constraints of
the MRI machine imposed in practice. Inspired by recent success of deep
learning based approaches for image reconstruction and ideas from computational
imaging on learning-based design of imaging systems, we introduce 3D FLAT, a
novel protocol for data-driven design of 3D non-Cartesian accelerated
trajectories in MRI. Our proposal leverages the entire 3D k-space to
simultaneously learn a physically feasible acquisition trajectory with a
reconstruction method. Experimental results, performed as a proof-of-concept,
suggest that 3D FLAT achieves higher image quality for a given readout time
compared to standard trajectories such as radial, stack-of-stars, or 2D learned
trajectories (trajectories that evolve only in the 2D plane while fully
sampling along the third dimension). Furthermore, we demonstrate evidence
supporting the significant benefit of performing MRI acquisitions using
non-Cartesian 3D trajectories over 2D non-Cartesian trajectories acquired
slice-wise",,,3D FLAT: Feasible Learned Acquisition Trajectories for Accelerated MRI,,http://arxiv.org/abs/2008.04808,core
478912515,2021-10-18T00:00:00,"In this paper we adapt KalmanNet, which is a recently pro-posed deep neural
network (DNN)-aided system whose architecture follows the operation of the
model-based Kalman filter (KF), to learn its mapping in an unsupervised manner,
i.e., without requiring ground-truth states. The unsupervised adaptation is
achieved by exploiting the hybrid model-based/data-driven architecture of
KalmanNet, which internally predicts the next observation as the KF does. These
internal features are then used to compute the loss rather than the state
estimate at the output of the system. With the capability of unsupervised
learning, one can use KalmanNet not only to track the hidden state, but also to
adapt to variations in the state space (SS) model. We numerically demonstrate
that when the noise statistics are unknown, unsupervised KalmanNet achieves a
similar performance to KalmanNet with supervised learning. We also show that we
can adapt a pre-trained KalmanNet to changing SS models without providing
additional data thanks to the unsupervised capabilities.Comment: 5 Pages, 5 Figures, Submitted to ICASSP 202",,,Unsupervised Learned Kalman Filtering,,http://arxiv.org/abs/2110.09005,core
286713582,2020-04-01T00:00:00,"Connected devices present new opportunities to advance design through data collection in the wild, similar to the way digital services evolve through analytics. However, it is still unclear how live data transmitted by connected devices informs the design of these products, going beyond performance optimisation to support creative practices. Design can be enriched by data captured by connected devices, from usage logs to environmental sensors, and data about the devices and people around them. Through a series of workshops, this paper contributes industry and academia perspectives on the future of data-driven product design. We highlight HCI challenges, issues and implications, including sensemaking and the generation of design insight. We further challenge current notions of data-driven design and envision ways in which future HCI research can develop ways to work with data in the design process in a connected, rich, human manner",,'Association for Computing Machinery (ACM)',Exploring the future of data-driven product design,10.1145/3313831.3376560,https://core.ac.uk/download/286713582.pdf,core
483839534,2021-06-01T00:00:00,"Classification and development of the deployable structures is an ongoing process that started at the end of 20th century and is getting more and more attention throughout 21st. With the development of the technology, constructive systems and materials, these categorizations changed – adding new typologies and excluding certain ones. This work is giving a critical review of the work done previously and on the change of the categories. The special interest is given to the pantographs (or scissor structures) and the Zeigler’s dome as the form of their application. It is noticeable that after its introduction in 1977, the dome was a part of the initial classification, but with the time it lost its place. The reason for this is the introduction of more efficient scissor dome structures. However, perhaps with the use of data-driven design, this dome can be optimized and become relevant again","[{'title': 'Curved and Layered Structures', 'identifiers': ['2353-7396', 'issn:2353-7396']}]",'Walter de Gruyter GmbH',Data-driven design of deployable structures: Literature review and multi-criteria optimization approach,10.1515/cls-2021-0022,,core
286808632,2020-01-30T09:40:38,"The Internet of Things creates opportunities to develop data-driven design methodologies for smart cities. However, effects rather than causes are often measured in complex urban systems, requiring robust data-interpretation methodologies. Additionally, effective monitoring of large urban components, such as civil infrastructure, often involves multiple sensor devices and invasive sensor systems. In these situations, the design of measurement systems is an important task. Usually, this task is carried out by engineers using only qualitative rules of thumb and experience. Recently, researchers have developed quantitative sensor-placement methodologies to maximize the information gain of measurement systems. Nonetheless, these methodologies are only weakly validated using field measurements due to the small amount of data collected and the difficulties comparing the predicted information gain with observations. This paper proposes a validation strategy for sensor-placement methodologies. In this strategy, predictions of both individual sensor and sensor-configuration performances are compared with observations using statistical tests and hypothesis testing. The validation procedure is illustrated through three full-scale-bridge case studies. This strategy helps engineers select an appropriate methodology to design measurement systems in order to optimize data collection using sensors",,'Institute of Electrical and Electronics Engineers (IEEE)',Strategy to validate sensor-placement methodologies in the context of sparse measurement in complex urban systems,10.1109/JSEN.2020.2969470,,core
479386536,2021-03-10T00:00:00,,,'Elsevier BV',A   life cycle oriented data-driven architecture for an advanced circular economy,10.1016/j.procir.2021.01.110,https://core.ac.uk/download/479386536.pdf,core
475040105,2021-12-06T00:00:00,"Mechanical cloaks are materials engineered to manipulate the elastic response
around objects to make them indistinguishable from their homogeneous
surroundings. Typically, methods based on material-parameter transformations
are used to design optical, thermal and electric cloaks. However, they are not
applicable in designing mechanical cloaks, since continuum-mechanics equations
are not form-invariant under general coordinate transformations. As a result,
existing design methods for mechanical cloaks have so far been limited to a
narrow selection of voids with simple shapes. To address this challenge, we
present a systematic, data-driven design approach to create mechanical cloaks
composed of aperiodic metamaterials using a large pre-computed unit cell
database. Our method is flexible to allow the design of cloaks with various
boundary conditions, multiple loadings, different shapes and numbers of voids,
and different homogeneous surroundings. It enables a concurrent optimization of
both topology and properties distribution of the cloak. Compared to
conventional fixed-shape solutions, this results in an overall better cloaking
performance, and offers unparalleled versatility. Experimental measurements on
3D-printed structures further confirm the validity of the proposed approach.
Our research illustrates the benefits of data-driven approaches in quickly
responding to new design scenarios and resolving the computational challenge
associated with multiscale designs of functional structures. It could be
generalized to accommodate other applications that require heterogeneous
property distribution, such as soft robots and implants design.Comment: Under revie",,,Mechanical Cloak via Data-Driven Aperiodic Metamaterial Design,,http://arxiv.org/abs/2107.13147,core
286384795,2020-01-02T01:25:17,"Limiting the increase of CO2 in the atmosphere is one of the largest challenges of our generation(1). Because carbon capture and storage is one of the few viable technologies that can mitigate current CO2 emissions(2), much effort is focused on developing solid adsorbents that can efficiently capture CO2 from flue gases emitted from anthropogenic sources(3). One class of materials that has attracted considerable interest in this context is metal-organic frameworks (MOFs), in which the careful combination of organic ligands with metal-ion nodes can, in principle, give rise to innumerable structurally and chemically distinct nanoporous MOFs. However, many MOFs that are optimized for the separation of CO2 from nitrogen(4-7) do not perform well when using realistic flue gas that contains water, because water competes with CO2 for the same adsorption sites and thereby causes the materials to lose their selectivity. Although flue gases can be dried, this renders the capture process prohibitively expensive(8,9). Here we show that data mining of a computational screening library of over 300,000 MOFs can identify different classes of strong CO2-binding sites-which we term `adsorbaphores'-that endow MOFs with CO2/N-2 selectivity that persists in wet flue gases. We subsequently synthesized two water-stable MOFs containing the most hydrophobic adsorbaphore, and found that their carbon-capture performance is not affected by water and outperforms that of some commercial materials. Testing the performance of these MOFs in an industrial setting and consideration of the full capture process-including the targeted CO2 sink, such as geological storage or serving as a carbon source for the chemical industry-will be necessary to identify the optimal separation material",,'Springer Science and Business Media LLC',Data-driven design of metal-organic frameworks for wet flue gas CO2 capture,10.1038/s41586-019-1798-7,,core
480053986,2021-01-01T00:00:00,"The paper presents a Model-Driven approach for Product-Service System (PSS) Design promoting an increased digitalization of the PSS design process based on the combination of data-driven design (DDD) activities and value-driven design (VDD) methods. The approach is the results of an 8-year long research profile named (omitted for blind review) featuring the collaboration between (omitted for blind review) and nine industrial companies, in the field of PSS Design. It combines VDD models and the supporting data-driven activities in the frame of PSS design and aligns with the product value stream and the knowledge value stream in the product innovation process as described by Kennedy et al. (2008). The paper provides a high-level overview of the approach describing the different stages and activities, and provides references to external scientific contributions for more exhaustive descriptions of the research rationale and validity. The approach is meant to ultimately drive the development and implementation of a simulation environment for cross-functional and multi-disciplinary decision making in PSS, named Model-Driven Decision Arena, describe in the concluding part of the paper.open access</p",,'Cambridge University Press (CUP)',MODEL-DRIVEN PRODUCT SERVICE SYSTEMS DESIGN : THE MODEL-DRIVEN DEVELOPMENT AND DECISION SUPPORT (MD3S) APPROACH,10.1017/pds.2021.475,,core
287784400,2020-02-27T00:00:00,"Materials science is the systematic study and development of materials and their properties. Materials informatics and data-driven materials science are umbrella terms for the scientific practice of systematically extracting knowledge from data produced in materials science. This practice differs from traditional scientific approaches in materials research by the volume of processed data and the more automated way information is extracted. This data-driven approach — sometimes referred to as the 4th paradigm of science — is largely driven by the use of modern hardware and software for data production and storage, the Open Science movement and the methodological developments in data mining and machine learning. 
This dissertation reviews how materials informatics can be effectively applied to accelerate materials science, focusing on computational, atomistic materials modelling. The topic is divided into two different areas: how the data-driven design and tools are being used to re-imagine the life-cycle of materials data and how machine learning, in particular, can be used to complement existing research methodologies in materials science. These topics are explored by investigating the historical development of materials informatics and by highlighting the modern tools and techniques.  
This discussion provides a guide for anyone interested in deploying these methods in their research and also covers some of the key challenges that the field of materials informatics still faces. After this overview, the original materials informatics research performed during the studies is summarized. First, the open-source software libraries developed for materials informatics are introduced. These libraries deal specifically with tasks related to the automated structural classification of complex atomistic geometries and the efficient description of materials for machine learning. Next, the studies related to materials discovery using data mining and machine learning are discussed. The first study leverages materials databases in the search for optimal coating materials for perovskite-based photovoltaics while the second study focuses on using machine learning for identifying catalytically active sites on nanoclusters.Materiaalitiede pyrkii ymmärtämään ja mallintamaan materiaalien ominaisuuksia ja valjastamaan näitä ominaisuuksia erilaisiin sovelluksiin. Materiaali-informatiikka ja datalähtöinen materiaalitiede ovat yläkäsitteitä käytännöille, joissa olemassaolevia tietomassoja hyödynnetään tehokkaasti materiaalituntemuksen edistämiseksi. Tämä eroaa perinteisistä tieteellisistä lähestymistavoista, sillä prosessoidun tiedon määrä on suurempi vaatien lähes täysin automatisoituja menetelmiä. Tätä datalähtöistä lähestymistapaa on myös kutsuttu tieteen neljänneksi paradigmaksi. Se syntyyn ovat vaikuttaneet kyky tuottaa ja tallentaa suuria tietomääriä modernin tietokonelaitteiston ja -ohjelmiston avulla, avoimen tieteen periaatteiden käyttöönotto sekä tiedon louhintaan ja koneoppimiseen käytettyjen menetelmien kehitys. 
Tässä väitöskirjassa tarkastellaan kuinka materiaali-informatiikkaa voidaan tehokkaasti soveltaa materiaalitieteen nopeuttamiseen keskittyen laskennalliseen, atomistiseen materiaalien mallintamiseen. Aihe on jaettu kahteen eri osa-alueeseen: miten datalähtöistä suunnittelua ja siihen liittyviä työkaluja käytetään materiaalitiedon elinkaaren uudelleenjärjestämiseen ja kuinka erityisesti koneoppimista voidaan käyttää olemassa olevien tutkimusmenetelmien täydentämiseksi. Näitä aiheita lähestytään tutkimalla materiaali-informatiikan historiallista kehitystä ja nostamalla esiin nykyaikaisia työkaluja ja tekniikoita. 
Tämä yhteenveto tarjoaa oppaan kaikille, jotka ovat kiinnostuneita näiden menetelmien käyttöönotosta tutkimuksessaan tuoden samalla esiin materiaali-informatiikan keskeisimpiä haasteita.Tämän yleiskatsauksen jälkeen esitellään opintojen aikana suoritettu alkuperäinen materiaalitutkimus. Aluksi käydään läpi materiaali-informaatiikkaa varten kehitetyt avoimen lähdekoodin ohjelmistokirjastot. Nämä kirjastot käsittelevät monimutkaisten atomististen geometrioiden automaattista rakenteellista luokittelua ja materiaaleja kuvaavan syötteen tehokasta muodostamista koneoppimista varten. Seuraavaksi esitellään tutkimukset, joissa tiedon louhintaa ja koneoppista käytetään uusien materiaalien etsimiseen kahdessa eri sovelluskohteessa. Ensimmäisessä tutkimuksessa hyödynnetään materiaalitietokantoja etsittäessä optimaalisia pinnoitemateriaaleja perovskiittipohjaisille aurinkokennoille, kun taas toisessa tutkimuksessa käytetään koneoppimista katalyyttisesti aktiivisten sijaintien tunnistamiseen nanoklustereissa",,'Springer Science and Business Media LLC',Materiaali-informatiikka: datalähtöinen suunnittelu ja koneoppiminen materiaalitieteen tukena,10.1038/s41524-018-0096-5,,core
429547556,2021-07-01T00:00:00,"Summary: Effective genetic diagnosis requires the correlation of genetic variant data with detailed phenotypic information. However, manual encoding of clinical data into machine-readable forms is laborious and subject to observer bias. Natural language processing (NLP) of electronic health records has great potential to enhance reproducibility at scale but suffers from idiosyncrasies in physician notes and other medical records. We developed methods to optimize NLP outputs for automated diagnosis. We filtered NLP-extracted Human Phenotype Ontology (HPO) terms to more closely resemble manually extracted terms and identified filter parameters across a three-dimensional space for optimal gene prioritization. We then developed a tiered pipeline that reduces manual effort by prioritizing smaller subsets of genes to consider for genetic diagnosis. Our filtering pipeline enabled NLP-based extraction of HPO terms to serve as a sufficient replacement for manual extraction in 92% of prospectively evaluated cases. In 75% of cases, the correct causal gene was ranked higher with our applied filters than without any filters. We describe a framework that can maximize the utility of NLP-based phenotype extraction for gene prioritization and diagnosis. The framework is implemented within a cloud-based modular architecture that can be deployed across health and research institutions","[{'title': None, 'identifiers': ['issn:2666-2477', '2666-2477']}]",'Elsevier BV',A data-driven architecture using natural language processing to improve phenotyping efficiency and accelerate genetic diagnoses of rare disorders,10.1016/j.xhgg.2021.100035,,core
490907639,2021-01-01T00:00:00,"In this study, a data-driven design method is proposed for a dual-rate system, where the sampling interval of a plant output is restricted and is an integer multiple of the holding interval of a control input. In our proposed method, single-rate virtual reference feedback tuning (S-VRFT), where the holding interval is the same as the sampling interval, is extended to the dual-rate virtual reference feedback tuning (D-VRFT) system. In D-VRFT, a controller is decided using a set of input/output data used in S-VRFT, and it is easy to extend S-VRFT to D-VRFT and implement D-VRFT. In this study, intersample oscillations caused in such a dual-rate control system is prevented because a weighting filter is introduced for penalizing the control input deviation between the sampling instants. The filter is designed as an integrator for weighting the low-frequency domain. The improvement in fast-tracking performance as well as the ripple-free property are demonstrated through both the numerical and experimental results","[{'title': 'IEEE Access', 'identifiers': ['issn:2169-3536', '2169-3536']}]",'Institute of Electrical and Electronics Engineers (IEEE)',Dual-Rate Data-Driven Virtual Reference Feedback Tuning: Improvement in Fast-Tracking Performance and Ripple-Free Design,10.1109/ACCESS.2021.3122234,,core
472219691,2020-01-01T00:00:00,,,'Informa UK Limited',Data-Driven Design,10.4324/9780429348051-12,,core
481324485,2021-02-25T00:00:00,"The latest technological advancements allow users to generate a large volume of data related to their experiences and needs. However, the absence of an advanced methodology that links the big data and the creative process prevents the effective use of the data and extracting all its potential and knowledge in this context, which is crucial in offering user-centred solutions. Incorporating data creatively and critically as design material can help us learn and understand user needs better. Therefore, design can bring deeper meaning to data, just as data can enhance design practice. Accordingly, this work raises a reflection on whether designers could appropriate the workflow of data science in order to integrate it into the research process in the creative process within a framework of user experience analysis. The proposed model: data-driven design model, enhances the exploratory design of problem space and assists in the creation of ideas during the conceptual design phase. In this way, this work offers an integrated vision, enhancing creativity in industrial design as an instrument for the achievement of the proper and necessary balance between intuition and reason, design, and science",,'Vilnius Gediminas Technical University',Creativity forward: a framework that integrates data analysis techniques to foster creativity within the creative process in user experience contexts,10.3846/cs.2021.12933,https://core.ac.uk/download/481324485.pdf,core
473627755,2020-01-01T00:00:00,,,'The Design Society',Data-driven design,10.35199/EPDE.2020.10,,core
483514221,2022-01-01T08:00:00,"In this paper, we present a novel data-driven design method for the human-robot interaction (HRI) system, where a given task is achieved by cooperation between the human and the robot. The presented HRI controller design is a two-level control design approach consisting of a task-oriented performance optimization design and a plant-oriented impedance controller design. The task-oriented design minimizes the human effort and guarantees the perfect task tracking in the outer-loop, while the plant-oriented achieves the desired impedance from the human to the robot manipulator end-effector in the inner-loop. Data-driven reinforcement learning techniques are used for performance optimization in the outer-loop to assign the optimal impedance parameters. In the inner-loop, a velocity-free filter is designed to avoid the requirement of end-effector velocity measurement. On this basis, an adaptive controller is designed to achieve the desired impedance of the robot manipulator in the task space. The simulation and experiment of a robot manipulator are conducted to verify the efficacy of the presented HRI design framework",,'Institute of Electrical and Electronics Engineers (IEEE)',Data-Driven Human-Robot Interaction Without Velocity Measurement using Off-Policy Reinforcement Learning,10.1109/JAS.2021.1004258,,core
441026828,2021-02-01T00:00:00,"The latest technological advancements allow users to generate a large volume of data related to their experiences and needs. However, the absence of an advanced methodology that links the big data and the creative process prevents the effective use of the data and extracting all its potential and knowledge in this context, which is crucial in offering user-centred solutions. Incorporating data creatively and critically as design material can help us learn and understand user needs better. Therefore, design can bring deeper meaning to data, just as data can enhance design practice. Accordingly, this work raises a reflection on whether designers could appropriate the workflow of data science in order to integrate it into the research process in the creative process within a framework of user experience analysis. The proposed model: data-driven design model, enhances the exploratory design of problem space and assists in the creation of ideas during the conceptual design phase. In this way, this work offers an integrated vision, enhancing creativity in industrial design as an instrument for the achievement of the proper and necessary balance between intuition and reason, design, and science","[{'title': 'Creativity Studies', 'identifiers': ['issn:2345-0487', '2345-0487', 'issn:2345-0479', '2345-0479']}]",'Vilnius Gediminas Technical University',Creativity forward: a framework that integrates data analysis techniques to foster creativity within the creative process in user experience contexts,10.3846/cs.2021.12933,https://core.ac.uk/download/441026828.pdf,core
389359924,2021-01-01T00:00:00,"peer-reviewedElastic boundary conditions play an important role in the buckling analysis of cylinders under compressive

loading. These structures are used widely in aerospace applications and are highly sensitive to geometrical,

material, loading, and boundary imperfections. In fact, the presence of these imperfections can lead to catastrophic failure. In 1968, NASA reported relations for obtaining the Knockdown Factor (KDF) based on an

empirical method that is valid for isotropic and orthotropic materials; however, these relations do not consider

the effect of elastic boundaries that can lead to highly conservative values of KDF. In design practice, a universal KDF of 0.65 has been used for recent designs by NASA, which may not be applicable to new types of structural configuration with different loading and boundary conditions. Therefore, there is a need for robust design

factors for future designs which reduce the dependency on testing during preliminary design phases and speeds

up the product development process. The availability of up‐to‐date and different KDF expressions for different

structural configurations would help engineers to design lighter structures with improved load carrying capacity and reliability. The main objective of this work is to identify the buckling load sensitivity of cylindrical

shells due to their boundary conditions and develop KDF relations considering elastic boundaries. To achieve

this goal, the effect of axial, radial and tangential support stiffness on a quasi‐isotropic cylinder under axial

compression is investigated. A data‐driven design approach is used to develop new KDF empirical relations

for a quasi‐isotropic cylinder on different elastic foundations. The accuracy of these relations is within 5%

for any elastic foundation considered",,'Elsevier BV',Design considerations for composite cylindrical shells on elastic foundations subject to compression buckling,10.1016/j.compstruct.2020.113176,https://core.ac.uk/download/389359924.pdf,core
328359633,2020-01-01T00:00:00,"Societies across the globe are facing many unprecedented challenges; climate change, pandemics, and resource depletion, just to name a few. These societal challenges, the 2030 Sustainable Development Agenda, and companies’ demands about knowledge and skills required from future employees have put pressure on academia to develop suitable education programmes in many disciplines, including product development and mechanical engineering. In this position paper, we present our work undertaken in phase-1 of the development of a new MSc programme in the field of product development and mechanical engineering at Blekinge Institute of Technology, aimed at addressing changing societal needs and demands of the future industry. We employ a generic design thinking approach, starting from key stakeholder needs with iterative execution of needfinding, benchmarking, and ideation. In these steps, we use several data collection and generation methods such as interviews, surveys, and workshops. The main outcome of phase-1 is the overall programme structure, consisting of three main focus streams — the engineering design core, three academic specializations (Product-Service Systems Design, Data-Driven Design, and Simulation- Driven Design), and the practical application profiling. Based on our experience of developing the overall programme structure, we offer recommendations for developing new programmes in this area.Open accessUtvecklingsprogram av Civilingenjörsprogram i Maskinteknik på Avancerad Niv",,'The Design Society',Shaping wicked problem solvers : innovating education programs through design thinking,10.35199/NORDDESIGN2020.26,,core
296249678,2020-01-01T00:00:00,"International audienceFor the 12 GeV upgrade of Jefferson Laboratory, a Silicon Vertex Tracker (SVT) has been designed for the CLAS12 spectrometer using single-sided microstrip sensors fabricated by Hamamatsu Photonics. The sensors have a graded angle design to minimize dead areas and a readout pitch of 156μm , with intermediate strips. Each double-sided SVT module hosts three daisy-chained sensors on each side with a full strip length of 33 cm. There are 512 channels per module, read out by four Fermilab Silicon Strip Readout (FSSR2) chips, featuring data-driven architecture, mounted on a rigid–flex hybrid board. The modules are assembled in a barrel configuration using a unique cantilevered geometry to minimize the amount of material in the tracking volume. This paper is focused on the design, qualification of the performance, and experience in operating and commissioning the tracker during the first year of the data taking",,'Elsevier BV',The CLAS12 Silicon Vertex Tracker,10.1016/j.nima.2020.163701,,core
395099855,2020-01-01T00:00:00,"The paper presents a four-layer framework for the application of data-driven design in a product innovation process. The framework builds on the Knowledge Value Stream and on the Product Value Streams of a product innovation process and indicates how data-driven activities shall be structured and organised in relation to the different phases of a model-based decision process. Visualisation is proposed as a communication enabler at the top of the framework to overcome the comprehensibility barrier between data science and engineering design models. The framework is implemented in the case study of a construction equipment encompassing the analysis of operational machine data and the experimentation of suitable visualisation techniques. Ultimately, a list of challenges for the implementation of data-driven design is presented, and the capability of the framework to support the transition toward data-driven

design is discussed in relation to the emergence of product-service systems solutions",,'Inderscience Publishers',A framework for data-driven design in a product innovation process: data analysis and visualisation for model-based decision making,10.1504/IJPD.2020.10028179,https://core.ac.uk/download/395099855.pdf,core
322856522,2020-04-28T00:00:00,"This Thesis describes an industrial procedure tailored to the company Unox S.p.A. for data analysis through multivariate statistical methodologies. Process variables are analysed for process understanding, data-driven design (creation of intuitive user-machine interface for improved user experience), process monitoring (anomalies detection during cooking process to ensure final product quality) and predictive maintenance (data-based equipment failure prediction for improved after-sale service)",,,Data analysis through multivariate statistical techniques: an industrial application,,https://core.ac.uk/download/322856522.pdf,core
234931251,2020,"Hierarchical clustering is an important tool for extracting information from data in a multi-resolution way. It is more meaningful if driven by data, as in the case of divisive algorithms, which split data until no more division is allowed. However, they have the drawback of the splitting threshold setting. The neural networks can address this problem, because they basically depend on data. The growing hierarchical GH-EXIN neural network builds a hierarchical tree in an incremental (data-driven architecture) and self-organized way. It is a top-down technique which defines the horizontal growth by means of an anisotropic region of influence, based on the novel idea of neighborhood convex hull. It also reallocates data and detects outliers by using a novel approach on all the leaves, simultaneously. Its complexity is estimated and an analysis of its user-dependent parameters is given. The advantages of the proposed approach, with regard to the best existing networks, are shown and analyzed, qualitatively and quantitatively, both in benchmark synthetic problems and in a real application (image recognition from video), in order to test the performance in building hierarchical trees. Furthermore, an important and very promising application of GH-EXIN in two-way hierarchical clustering, for the analysis of gene expression data in the study of the colorectal cancer is described",,'Elsevier BV',The GH-EXIN neural network for hierarchical clustering,10.1016/j.neunet.2019.07.018,,core
323787584,2020-03-29T00:00:00,"This paper studies how to design abstractions of large-scale combinatorial optimization problems that can leverage existing state-of-the-art solvers in general purpose ways, and that are amenable to data-driven design. The goal is to arrive at new approaches that can reliably outperform existing solvers in wall-clock time. We focus on solving integer programs, and ground our approach in the large neighborhood search (LNS) paradigm, which iteratively chooses a subset of variables to optimize while leaving the remainder fixed. The appeal of LNS is that it can easily use any existing solver as a subroutine, and thus can inherit the benefits of carefully engineered heuristic approaches and their software implementations. We also show that one can learn a good neighborhood selector from training data. Through an extensive empirical validation, we demonstrate that our LNS framework can significantly outperform, in wall-clock time, compared to state-of-the-art commercial solvers such as Gurobi",,,A General Large Neighborhood Search Framework for Solving Integer Programs,,https://core.ac.uk/download/323787584.pdf,core
443969942,2021-06-29T00:00:00,"Scientific and engineering problems often require the use of artificial
intelligence to aid understanding and the search for promising designs. While
Gaussian processes (GP) stand out as easy-to-use and interpretable learners,
they have difficulties in accommodating big datasets, categorical inputs, and
multiple responses, which has become a common challenge for a growing number of
data-driven design applications. In this paper, we propose a GP model that
utilizes latent variables and functions obtained through variational inference
to address the aforementioned challenges simultaneously. The method is built
upon the latent variable Gaussian process (LVGP) model where categorical
factors are mapped into a continuous latent space to enable GP modeling of
mixed-variable datasets. By extending variational inference to LVGP models, the
large training dataset is replaced by a small set of inducing points to address
the scalability issue. Output response vectors are represented by a linear
combination of independent latent functions, forming a flexible kernel
structure to handle multiple responses that might have distinct behaviors.
Comparative studies demonstrate that the proposed method scales well for large
datasets with over 10^4 data points, while outperforming state-of-the-art
machine learning methods without requiring much hyperparameter tuning. In
addition, an interpretable latent space is obtained to draw insights into the
effect of categorical factors, such as those associated with building blocks of
architectures and element choices in metamaterial and materials design. Our
approach is demonstrated for machine learning of ternary oxide materials and
topology optimization of a multiscale compliant mechanism with aperiodic
microstructures and multiple materials.Comment: Preprint submitted to Journal of Mechanical Desig",,,"Scalable Gaussian Processes for Data-Driven Design using Big Data with
  Categorical Factors",,http://arxiv.org/abs/2106.15356,core
483937227,2021-01-01T00:00:00,"A new class of rare-earth-free permanent magnets is proposed. The parent compound of this class is Co3Mn2Ge, and its discovery is the result of first principles theory combined with experimental synthesis and characterisation. The theory is based on a high-throughput/data-mining search among materials listed in the ICSD database. From ab-initio theory of the defect free material it is predicted that the saturation magnetization is 1.71 T, the uniaxial magnetocrystalline anisotropy is 1.44 MJ/m3, and the Curie temperature is 700 K. Co3Mn2Ge samples were then synthesized and characterised with respect to structure and magnetism. The crystal structure was found to be the MgZn2-type, with partial disorder of Co and Ge on the crystallographic lattice sites. From magnetization measurements a saturation polarization of 0.86 T at 10 K was detected, together with a uniaxial magnetocrystalline anisotropy constant of 1.18 MJ/m3, and the Curie temperature of TC = 359 K. These magnetic properties make Co3Mn2Ge a very promising material as a rare-earth free permanent magnet, and since we can demonstrate that magnetism depends critically on the amount of disorder of the Co and Ge atoms, a further improvement of the magnetism is possible. We demonstrate here that the class of compounds based on T3Mn2X (T = Co or alloys between Fe and Ni; X = Ge, Al or Ga) in the MgZn2 structure type, form a new class of rare-earth free permanent magnets with very promising performance",,'Elsevier BV',Data-driven design of a new class of rare-earth free permanent magnets,10.1016/j.actamat.2021.116913,,core
490759223,2021-01-01T00:00:00,"Designing auction parameters for online industrial auctions is a complex problem due to highly heterogeneous items. Currently, online auctioneers rely heavily on their experts in auction design. The ability of predicting how well an auction will perform prior to the start comes in handy for auctioneers. If an item is expected to be a low-performing item, the auctioneer can take certain actions to influence the auction outcome. For instance, the starting selling price of the item can be modified, or the location where the item is displayed on the website can be changed to attract more attention. In this paper, we take a real-world industrial auction data set and investigate how we can improve upon the expert’s design using insights learned from data. More specifically, we first construct a classification model that predicts the expected performance of auctions. We propose a data driven auction design framework (called DDAD) that combines the expert’s knowledge with the learned prediction model, in order to find the best parameter values, i.e., starting price and display positions of the items, for a given new auction. The prediction model is evaluated, and the new design for several auctions is discussed and validated with the auction experts.Accepted author manuscriptCyber Securit",,'Springer Science and Business Media LLC',Data driven design for online industrial auctions,10.1007/s10472-020-09722-2,,core
479365400,2021-07-01T00:00:00,"Summary Environmental and host‐associated microbial communities are complex ecosystems, of which many members are still unknown. Hence, it is challenging to study community dynamics and important to create model systems of reduced complexity that mimic major community functions. Therefore, we developed MiMiC, a computational approach for data‐driven design of simplified communities from shotgun metagenomes. We first built a comprehensive database of species‐level bacterial and archaeal genomes (n = 22 627) consisting of binary (presence/absence) vectors of protein families (Pfam = 17 929). MiMiC predicts the composition of minimal consortia using an iterative scoring system based on maximal match‐to‐mismatch ratios between this database and the Pfam binary vector of any input metagenome. Pfam vectorization retained enough resolution to distinguish metagenomic profiles between six environmental and host‐derived microbial communities (n = 937). The calculated number of species per minimal community ranged between 5 and 11, with MiMiC selected communities better recapitulating the functional repertoire of the original samples than randomly selected species. The inferred minimal communities retained habitat‐specific features and were substantially different from communities consisting of most abundant members. The use of a mixture of known microbes revealed the ability to select 23 of 25 target species from the entire genome database. MiMiC is open source and available at https://github.com/ClavelLab/MiMiC","[{'title': 'Microbial Biotechnology', 'identifiers': ['issn:1751-7915', '1751-7915']}]",'Wiley',MiMiC: a bioinformatic approach for generation of synthetic communities from metagenomes,10.1111/1751-7915.13845,,core
357602961,2020-04-24T00:00:00,"ABSTRACT Design optimization in the context of finite element modeling (FEM) and analysis (FEA) has been traditionally used to help designers determine optimal structural geometry and/or material property parameters according to objective functions of interest and necessary constraints. In the present paper it is attempted to generalize the design optimization methodology into a program synthesis technique for determining the code necessary to encapsulate the constitutive behavior of the material system required for generalized FEA applications. The core concept behind the methodology followed by our group in the past, has been the experimental identification of a dissipated energy density (DED) function for polymer matrix composites (PMCs) through a non-linear optimization scheme for determining the free coefficients of the sum of the basis functions that are used to construct the DED function and is based on the energy balance of the specimen under testing. The utilized testing generated massive amounts of experimental data that would be produced by exposing PMC specimens to multidimensional loading paths with the help of custom made multi-axial computer-controlled testing machines. The variety of custom environments utilized to implement the analytical and numerical details has often created difficulties in transferring our technology to end users in the design and material communities. The present implementation was greatly enabled by recent advances in finite element techniques and &quot;of the shelf&quot; design optimization integration technologies along with the parallel hardware and software evolution. The program synthesis lies on a process that automatically generates the code of a user material subroutine through minimization of the error between measured and simulated specimen behavior. The generated code can be subsequently used with any geometry and loading specification definable within the limits of the non-linear element library in commercial codes such as ANSYS and ABAQUS",,,DETC2002/CIE-34474 PROGRAM SYNTHESIS OF FEA CONSTITUTIVE BEHAVIOR MODULES THROUGH DATA DRIVEN DESIGN OPTIMIZATION,,https://core.ac.uk/download/357602961.pdf,core
480053862,2021-01-01T00:00:00,"The digitalization era has brought about unprecedented challenges for the manufacturing industries, pushing them to deliver solutions that encompass both product and service-related dimensions, known as Product-service Systems. This paper presents a number of lessons learned in the process of integrating the analysis of operational data as decision support in engineering design based on the empirical studies from two Swedish manufacturing companies operating in the construction machinery sector. The paper highlights the need to consider a five-dimensional perspective when collecting and analyzing data, encompassing data from the product, the service, the environment, the infrastructure, and the humans involved. Finally, a conceptual framework for data-driven design automation of Product-service Systems is proposed by leveraging the use of these data, introducing the concept of a Product-Service System Configurator as an enabler of design automation. The implementation of the proposed framework on multiple case studies in different industrial contexts shall be considered as the next step of the research.open access</p",,'Cambridge University Press (CUP)',Data-Driven Design Automation for Product-Service Systems Design : Framework and Lessons Learned from Empirical Studies.,10.1017/pds.2021.84,,core
347168420,2020-01-01T00:00:00,"International audienceThe paper presents a four-layer framework for the application of data-driven design in a product innovation process. The framework builds on the Knowledge Value Stream and on the Product Value Streams of a product innovation process and indicates how data-driven activities shall be structured and organised in relation to the different phases of a model-based decision process. Visualisation is proposed as a communication enabler at the top of the framework to overcome the comprehensibility barrier between data science and engineering design models. The framework is implemented in the case study of a construction equipment encompassing the analysis of operational machine data and the experimentation of suitable visualisation techniques. Ultimately, a list of challenges for the implementation of data-driven design is presented, and the capability of the framework to support the transition toward data-driven design is discussed in relation to the emergence of product-service systems solutions",,'Inderscience Publishers',A framework for data-driven design in a product innovation process: data analysis and visualisation for model-based decision making,10.1504/IJPD.2020.106464,,core
386107667,2020-12-11T00:00:00,"This paper explores how audiences engage with Netflix as an intermediary in their digital lives, and how Netflix, as it is designed, creates a highly constrained system for its users. The paper is based on a study of observed use and discussions with Netflix users. It explores the limitations that are designed into Netflix as a digital media platform, and how Netflix users engage with this system that obscures rather than clarifies the contents of the platform. The paper discusses examples of frustration, confusion, and misdirection that Netflix, as a heavily constrained system, cultivates. It argues that the thoughts, feelings, and desires of audiences are not reflected in the data-driven design of digital media platforms like Netflix. Instead, data are used by Netflix to design a personalized environment that acts as a set of blinders which constrain the agency of the audience through an interface designed to dazzle and disorient Netflix users",,SMID - Society of Media Researchers In Denmark,Netflix and the design of the audience: The homogenous constraints of data-driven personalization,,https://core.ac.uk/download/386107667.pdf,core
333888192,2020-01-01T00:00:00,"Driven by technological advances, growing amounts of available data, and an emergent need for participatory processes, landscape architecture is witnessing a moment of disruption whereby formerly separated areas of operation become increasingly connected. While distinctions between various aspects of the design process are diminishing, a need for a novel, more inclusive toolset arises. The ‘tangible table’ paradigm is an attempt at combining intuitive ways of physical modelling with data-driven design strategies and the interactive simulation of naturally occurring phenomena. Despite its existence for more than 20 years, tangible tables have mainly focused on very specific workflows and therefore have not found wider adoption in landscape architectural practice or education. We list the limitations of previous implementations and introduce a novel software solution aimed at popularizing tangible table setups. Our software is embedded in a widespread visual programming environment, which allows for straightforward augmentation of physical models with computational design tech-niques. Using a week-long PhD course as a case study, we demonstrate the usefulness of the proposed software and its potential applications to solving various landscape architectural challenges through increased emphasis on participatory processes.Peer reviewe","[{'title': None, 'identifiers': ['2367-4253', 'issn:2367-4253', 'issn:2511-624X', '2511-624x']}]",Wichmann Verlag im VDE Verlag GmbH,Bridging tangible and virtual realities : Computational procedures for data-informed participatory processes,10.14627/537690036,,core
388709891,2021-05-27T00:00:00,"In this paper, we present ""BIKED,"" a dataset comprised of 4500 individually
designed bicycle models sourced from hundreds of designers. We expect BIKED to
enable a variety of data-driven design applications for bicycles and support
the development of data-driven design methods. The dataset is comprised of a
variety of design information including assembly images, component images,
numerical design parameters, and class labels. In this paper, we first discuss
the processing of the dataset, then highlight some prominent research questions
that BIKED can help address. Of these questions, we further explore the
following in detail: 1) Are there prominent gaps in the current bicycle market
and design space? We explore the design space using unsupervised dimensionality
reduction methods. 2) How does one identify the class of a bicycle and what
factors play a key role in defining it? We address the bicycle classification
task by training a multitude of classifiers using different forms of design
data and identifying parameters of particular significance through
permutation-based interpretability analysis. 3) How does one synthesize new
bicycles using different representation methods? We consider numerous machine
learning methods to generate new bicycle models as well as interpolate between
and extrapolate from existing models using Variational Autoencoders. The
dataset and code are available at http://decode.mit.edu/projects/biked/",,,"BIKED: A Dataset and Machine Learning Benchmarks for Data-Driven Bicycle
  Design",,http://arxiv.org/abs/2103.05844,core
480035082,2021-01-01T00:00:00,"A new class of rare-earth-free permanent magnets is proposed. The parent compound of this class is Co3Mn2Ge, and its discovery is the result of first principles theory combined with experimental synthesis and characterisation. The theory is based on a high-throughput/data-mining search among materials listed in the ICSD database. From ab-initio theory of the defect free material it is predicted that the saturation magnetization is 1.71 T, the uniaxial magnetocrystalline anisotropy is 1.44 MJ/m3, and the Curie temperature is 700 K. Co3Mn2Ge samples were then synthesized and characterised with respect to structure and magnetism. The crystal structure was found to be the MgZn2-type, with partial disorder of Co and Ge on the crystallographic lattice sites. From magnetization measurements a saturation polarization of 0.86 T at 10 K was detected, together with a uniaxial magnetocrystalline anisotropy constant of 1.18 MJ/m3, and the Curie temperature of TC = 359 K. These magnetic properties make Co3Mn2Ge a very promising material as a rare-earth free permanent magnet, and since we can demonstrate that magnetism depends critically on the amount of disorder of the Co and Ge atoms, a further improvement of the magnetism is possible. We demonstrate here that the class of compounds based on T3Mn2X (T = Co or alloys between Fe and Ni; X = Ge, Al or Ga) in the MgZn2 structure type, form a new class of rare-earth free permanent magnets with very promising performance",,'Elsevier BV',Data-driven design of a new class of rare-earth free permanent magnets,10.1016/j.actamat.2021.116913,,core
478186910,2020-01-01T00:00:00,"Societies across the globe are facing many unprecedented challenges; climate change, pandemics, and resource depletion, just to name a few. These societal challenges, the 2030 Sustainable Development Agenda, and companies’ demands about knowledge and skills required from future employees have put pressure on academia to develop suitable education programmes in many disciplines, including product development and mechanical engineering. In this position paper, we present our work undertaken in phase-1 of the development of a new MSc programme in the field of product development and mechanical engineering at Blekinge Institute of Technology, aimed at addressing changing societal needs and demands of the future industry. We employ a generic design thinking approach, starting from key stakeholder needs with iterative execution of needfinding, benchmarking, and ideation. In these steps, we use several data collection and generation methods such as interviews, surveys, and workshops. The main outcome of phase-1 is the overall programme structure, consisting of three main focus streams — the engineering design core, three academic specializations (Product-Service Systems Design, Data-Driven Design, and Simulation- Driven Design), and the practical application profiling. Based on our experience of developing the overall programme structure, we offer recommendations for developing new programmes in this area.Open accessUtvecklingsprogram av Civilingenjörsprogram i Maskinteknik på Avancerad Niv",,'The Design Society',Shaping wicked problem solvers : innovating education programs through design thinking,10.35199/NORDDESIGN2020.26,,core
475605154,2021-06-04T00:00:00,"In this work, we propose a data-driven design pipeline for quick design exploration of performance and appearance guided alternatives for vehicle design. At the heart of our system is a machine learning-based generative design method to provide users with a set of diverse optimal design alternatives and an interactive design technique to induce users’ preference into the design exploration. The generative design method is the structure on two search process, qualitative and quantitative. To avoid the curse of dimensionality, the qualitative search process first builds up a lower-dimensional representation of a given design space, which is then explored using the unsupervised k-means clustering to synthesise a representative set of user-preferred designs. The quantitative search process explores the design space to find an optimal design in terms of performance criterion such as drag coefficient. To reduce the computational complexity, instead of evaluating drag via Computational Fluid Dynamics simulations, a surrogate model is developed to predict the drag coefficients. The designs generated after the generative design step are presented to the user at the interactive step, where potential regions of the design space are identified around the user-selected designs. Afterwards, a new design space is generated by removing the non-preferred regions, which helps to focus the computational efforts on the exploration of the user preferred regions of the design space for a design tailored to the user’s requirements. We demonstrated the performance of the proposed approach on a two-dimensional side silhouette of a sport-utility vehicle",,'Institute of Electrical and Electronics Engineers (IEEE)',A data-driven interactive system for aerodynamic and user-centred generative vehicle design,10.1109/ICAI52203.2021.9445243,,core
482229644,2023-01-01T00:00:00,,,Elsevier,Use of data-driven design for the development of knob-shaped handles in the context of impedance measurements,10.5445/IR/1000138842,,core
388365224,2021-03-06T00:00:00,"High-Performance Big Data Analytics (HPDA) applications are characterized by
huge volumes of distributed and heterogeneous data that require efficient
computation for knowledge extraction and decision making. Designers are moving
towards a tight integration of computing systems combining HPC, Cloud, and IoT
solutions with artificial intelligence (AI). Matching the application and data
requirements with the characteristics of the underlying hardware is a key
element to improve the predictions thanks to high performance and better use of
resources.
  We present EVEREST, a novel H2020 project started on October 1st, 2020 that
aims at developing a holistic environment for the co-design of HPDA
applications on heterogeneous, distributed, and secure platforms. EVEREST
focuses on programmability issues through a data-driven design approach, the
use of hardware-accelerated AI, and an efficient runtime monitoring with
virtualization support. In the different stages, EVEREST combines
state-of-the-art programming models, emerging communication standards, and
novel domain-specific extensions. We describe the EVEREST approach and the use
cases that drive our research.Comment: Paper accepted for presentation at the IEEE/EDAC/ACM Design,
  Automation and Test in Europe Conference and Exhibition (DATE 2021",,'Institute of Electrical and Electronics Engineers (IEEE)',"EVEREST: A design environment for extreme-scale big data analytics on
  heterogeneous platforms",10.23919/DATE51398.2021.9473940,http://arxiv.org/abs/2103.04185,core
149300675,2018-01-15T08:58:56Z,"<div>Because it provides a flexible architecture, the system offers the possibility to use</div><div>various application platforms as sources for the integration. The system is based on translation</div><div>functions (adapters) that provide interoperability with minimum implications for the</div><div>interacting systems.</div><div>The system was designed to work both as a service provider and a service consumer,</div><div>as it can both supply and request medical data from various systems. The portal services are</div><div>implemented using a service-oriented architecture by web services stored in repositories.</div><div>The applications that are based on a SOA environment can be configured to work both</div><div>as services exchanging data in point to point protocol and as a communication channel</div><div>between two entities that call a service provided by an entity that has the role of mediator or</div><div>broker. The letter can be seen as intermediary level that represents an “enterprise service bus”</div><div>(ESB) between service producers and consumers, offering messaging exchange services.</div",BRAIN Journal-A PROPOSED DATA DRIVEN ARCHITECTURE FOR CARDIOLOGY NETWORK APPLICATION-Figure 4. Portal Logical Architecture,10.6084/m9.figshare.5787213.v1,,,,core
192238000,2017,,Special Issue: Data-Driven Design (D3),10.1115/1.4037943,http://mechanicaldesign.asmedigitalcollection.asme.org/data/journals/jmdedb/936524/md_139_11_110301.pdf,ASME International,,core
93750601,2018-01-01T00:00:00,"In direct data-driven controller tuning, a mathematical model of the plant is not needed, as the control law is directly derived from experimental data. Because the most widely used data-driven techniques are based on the assumption that the underlying dynamics - albeit unknow - is linear, the performance of the resulting controller may not be acceptable with systems whose operating region vary along the time. In this paper, we discuss how to robustify linear data-driven design by exploiting the features of scenario optimization. More specifically, we carry out a modified version of the well known virtual reference feedback tuning approach where probabilistic performance guarantees are given also when the current operating condition is different from the one observed in the controller identification experiment. We validate the proposed approach on a vehicle stability control problem, via a thorough simulation campaign on a multibody simulator. The experimental results show the effectiveness of the proposed approach in a complex real-world setting",Robust direct data-driven controller tuning with an application to vehicle stability control,10.1002/rnc.3782,,'Wiley',,core
395004916,2017-09-01T00:00:00,"A cyber-physical system (CPS) is an integration of computation with physical processes whose behavior is defined by both computational and physical parts of the system. In this paper, we present a view of the challenges and opportunities for design automation of CPS. We identify a combination of characteristics that define the challenges unique to the design automation of CPS. We then present selected promising advances in depth, focusing on four foundational directions: combining model-based and data-driven design methods; design for human-in-the-loop systems; component-based design with contracts, and design for security and privacy. These directions are illustrated with examples from two application domains: smart energy systems and next-generation automotive systems","Design Automation of Cyber-Physical Systems: Challenges, Advances, and Opportunities",,,"eScholarship, University of California",,core
159217760,2018-01-01T00:00:00,"The paper discusses the role and the challenges of integrating Data-Driven Design (DDD) models in the product innovation process. Firstly, based on academic literature on the Product Innovation Value Streamsand on Model-Based Decision Supports, the paper highlights how and when the use of DDD models can support a more effective product innovation process. Secondly, it highlights a list of challenges to be considered for the development of new DDD models for decision support. Ultimately, those challenges are formalized in an evaluation matrix intended to guide the further development of DDD",Role and Challenges of Data-Driven Design in the Product Innovation Process,10.1016/j.ifacol.2018.08.455,,'Elsevier BV',,core
158324118,2017-12-01T00:00:00,"Millions of mobile apps are used by billions of users every day. Although the design of these apps play an important role in their adoption, the design process still remains complex and time intensive. At the same time, existing apps embody multiple solutions to numerous design problems faced by app developers. How do we make this design knowledge embedded in existing apps accessible to designers? And how can it help simplify the app design process?

This dissertation introduces interaction mining, a technique to capture the designs of mobile apps in a way that supports data-driven design applications. It presents systems that implement interaction mining for Android apps without requiring any access to their source code making it possible to design mine apps at an unprecedented scale. It presents Rico, the largest publicly available mobile app design repository to date. It discusses how such repositories created using interaction mining can be used to train models that enable applications such as keyword and example-based search interactions for mobile screens and user flows. It also presents zero-integration performance testing (ZIPT), a novel technique for testing app designs. It demonstrates how ZIPT can be used to help designers understand which examples to draw from in the early stages of the app design process and perform comparative testing at scale with low cost and effort in the later stages of the process",Interaction mining mobile apps,,https://core.ac.uk/download/158324118.pdf,,,core
160304987,2018-07-30T00:00:00Z,"DNA nucleobase sequence controls
the size of DNA-stabilized silver
clusters, leading to their well-known yet little understood sequence-tuned
colors. The enormous space of possible DNA sequences for templating
clusters has challenged the understanding of how sequence selects
cluster properties and has limited the design of applications that
employ these clusters. We investigate the genomic role of DNA sequence
for fluorescent silver clusters using a data-driven approach. Employing
rapid parallel silver cluster synthesis and fluorimetry, we determine
the fluorescence spectra of silver cluster products stabilized by
1432 distinct DNA oligomers. By applying pattern recognition algorithms
to this large experimental data set, we discover certain DNA base
patterns, or “motifs,” that correlate to silver clusters
with similar fluorescence spectra. These motifs are employed in machine
learning classifiers to predictively design DNA template sequences
for specific fluorescence color bands. Our method improves selectivity
of templates by 330% for silver clusters with peak emission wavelengths
beyond 660 nm. The discovered base motifs also provide physical insights
into how DNA sequence controls silver cluster size and color. This
predictive design approach for color of DNA-stabilized silver clusters
exhibits the potential of machine learning and data mining to increase
the precision and efficiency of nanomaterials design, even for a soft-matter-inorganic
hybrid system characterized by an extremely large parameter space","Fluorescence
Color by Data-Driven Design of Genomic
Silver Clusters",10.1021/acsnano.8b03404.s001,,,,core
232142182,2017-06-16T07:00:00,"Though the smart electrical grid promises many advantages in efficiency and reliability, the risks to consumer privacy have impeded its deployment. Researchers have proposed protecting privacy by aggregating user data before it reaches the utility, using techniques of homomorphic encryption to prevent exposure of unaggregated values. However, such schemes generally require users to trust in the correct operation of a single aggregation server. We propose two alternative systems based on secret sharing techniques that distribute this trust among multiple service providers, protecting user privacy against a misbehaving server. We also provide an extensive evaluation of the systems considered, comparing their robustness to privacy compromise, error handling, computational performance, and data transmission costs. We conclude that while all the systems should be computationally feasible on smart meters, the two methods based on secret sharing require much less computation while also providing better protection against corrupted aggregators. Building systems using these techniques could help defend the privacy of electricity customers, as well as customers of other utilities as they move to a more data-driven architecture",Smart Grid Privacy through Distributed Trust,,https://core.ac.uk/download/232142182.pdf,RIT Scholar Works,,core
189689997,2017,,Special Issue: Data-Driven Design (D3),10.1115/1.4037943,http://mechanicaldesign.asmedigitalcollection.asme.org/data/journals/jmdedb/936524/md_139_11_110301.pdf,ASME International,,core
467553851,2018-01-01T00:00:00,,DATA DRIVEN DESIGN SELECTION AND GENERATION - AN INDUSTRIAL CASE STUDY ON ELECTRIC MOTORS,10.21278/idc.2018.0223,,"'Faculty of Mechanical Engineering and Naval Architecture, Univ. of Zagreb'",,core
93621544,2017-01-01T00:00:00,"This SpringerBrief presents research results on QoE management schemes for mobile services, including user services, and resource allocation. Along with a review of the research literature, it offers a data-driven architecture for personalized QoE management in wireless networks. The primary focus is on introducing efficient personalized character extraction mechanisms, e.g., context-aware Bayesian graph model, and cooperative QoE management mechanisms. Moreover, in order to demonstrate in the effectiveness of the QoE model, a QoE measurement platform is described and its collected data examined. The brief concludes with a discussion of future research directions. The example mechanisms and the data-driven architecture provide useful insights into the designs of QoE management, and motivate a new line of thinking for users' satisfaction in future wireless networks",QoE management in wireless networks,10.1007/978-3-319-42454-5,,'Springer Science and Business Media LLC',,core
154944136,2018-03-02T15:53:44,"The objective of this dissertation is to develop data-driven frequency-domain methods for designing robust controllers through the use of convex optimization algorithms. Many of today's industrial processes are becoming more complex, and modeling accurate physical models for these plants using first principles may be impossible. Albeit a model may be available; however, such a model may be too complex to consider for an appropriate controller design. With the increased developments in the computing world, large amounts of measured data can be easily collected and stored for processing purposes. Data can also be collected and used in an on-line fashion. Thus it would be very sensible to make full use of this data for controller design, performance evaluation, and stability analysis. The design methods imposed in this work ensure that the dynamics of a system are captured in an experiment and avoids the problem of unmodeled dynamics associated with parametric models.  The devised methods consider robust designs for both linear-time-invariant (LTI) single-input-single-output (SISO) systems and certain classes of nonlinear systems.  In this dissertation, a data-driven approach using the frequency response function of a system is proposed for designing robust controllers with $\mathcal{H}_{\infty}$ performance. Necessary and sufficient conditions are derived for obtaining $\mathcal{H}_{\infty}$ performance while guaranteeing the closed-loop stability of a system. A convex optimization algorithm is formulated to obtain the controller parameters which ensure system robustness; the controller is robust with respect to the frequency-dependent uncertainties of the frequency response function. For a certain class of nonlinearities, the proposed method can be used to obtain a best-linear-approximation with an associated frequency-dependent uncertainty to guarantee the stability and performance for the underlying linear system that is subject to nonlinear distortions. The controller for this design scheme is presented as a ratio of two linearly-parameterized transfer functions; in this manner, the numerator and denominator of a controller are simultaneously optimized. With this construction, it can be shown that as the controller order increases, the solution to the convex problem converges to the global optimal solution of the $\mathcal{H}_{\infty}$ problem. This method is then extended to the 2-degree-of-freedom discrete-time controller where the necessary and sufficient conditions are imposed for multiple weighted sensitivity functions.  The concepts behind these design methods are then used to devise necessary and sufficient conditions for ensuring the closed-loop stability of systems with sector-bounded nonlinearities. The conditions are simple convex feasibility constraints which can be used to stabilize systems with multi-model uncertainty. Additionally, a method is proposed for obtaining $\mathcal{H}_{\infty}$ performance for systems with uncertain gains within these sectors. By convexifying the $\mathcal{H}_{\infty}$ problem, the global optimal solution to an approximate problem is obtained. For low-order controllers, the solution to this approximate problem may lead to solutions far from the optimal solution of the true $\mathcal{H}_{\infty}$ problem. Thus two methods are proposed to address this issue for low-order controllers. In one method, a non-convex problem is formulated which optimizes the basis function parameters of a controller while guaranteeing the stability of the closed-loop systems. In another method, a set of convex problems are solved in an iterative fashion to obtain the desired performance (which also guarantees the closed-loop stability of the system). With both methods, the local solution to the $\mathcal{H}_{\infty}$ problem for fixed-structure controllers is obtained. However, the convex problem is computationally tractable and can also consider $\mathcal{H}_2$ performance.  The effectiveness of the proposed method(s) is illustrated by considering several case studies that require robust controllers for achieving the desired performance. The main applicative work in this dissertation is with respect to a power converter control system at the European Organization for Nuclear Research (CERN) (which is used to control the current in a magnet to produce the desired field in controlling particle trajectories in particle accelerators). The proposed design methods are implemented in order to satisfy the challenging performance specifications set by the application while guaranteeing the system stability and robustness using data-driven design strategies",A Data-Driven Frequency-Domain Approach for Robust Controller Design via Convex Optimization,,,,,core
429523610,2018-09-25T00:00:00,"ABSTRACT: This paper presents High Modernism as a predecessor of today's discourse on evidencebased design. The 1920s and 1930s provide rich examples of promoting the relationship between research and design, as many modern protagonists claimed their designs resulted from analyzed data and expert input rather than historical reference or creative talent. Scientists, economists, engineers, and architects alike investigated problems such as hygiene conditions in housing and cities, human needs at work and home, construction mechanization, and traffic optimization as the basis and justification of spatial designs. As an example, this paper addresses the discourse on best solar orientation of housing, with the architect and urbanist Ludwig Hilberseimer as one of several proponents of this discourse, among them Walter Gropius, Ernst May, and Le Corbusier. Regarding solar studies, Hilberseimer's projects and writings can be divided into three phases. The first phase is marked by his famous 1920s renderings of the residential city and high-rise metropolis, which conform to the orientation recommendations by urban planners Richard Baumeister and Karl Hoepfner. The second phase spans Hilberseimer's teaching at the Bauhaus from 1929 to 1933, in which he contributed to the extensive solar studies for diverse housing types undertaken at the Bauhaus building department. A third phase, in which he applied the findings to ""settlement units” in linear city patterns, came to full fruition after 1938 when Hilberseimer started teaching at the Armour Institute, later renamed the Illinois Institute of Technology in Chicago. The case of solar studies in High Modernism and Hilberseimer's work in particular illuminate the challenges of relating research, performance-driven design, and actual building projects.
&nbsp;
KEYWORDS: evidence-based design, housing, hygiene, Durchsonnung, ""Licht Luft Sonne",Data-Driven Design in High Modernism: Ludwig Hilberseimer's Solar Orientation Studies,10.17831/rep:arcc,https://core.ac.uk/download/429523610.pdf,'Enquiry:  The ARCC Journal of Architectural Research',,core
190210022,2018-11-27T00:00:00,"Designing interactive products means creating complex mappings between inputs and outcomes, that is, between sensor data and external information and actuations in a context. Data is an essential “material” of design in this approach, which increasingly consists of real-time data streams. The more complex the data streams become, the more difficult it becomes to apply traditional design methods without dedicated support for (1) sketching and scaffolding “online” data, (2) scheduling and simulating data, and (3) recording and replaying data as needed. We need active environments that prototypes can be immersed in, such that they receive such data and can respond to them according to their intended and designed behavior",IoTSim: Designing Interactive Products with Synthetic Data: An exploration into data-driven design with comprehensive tool support,,,,,core
469043358,2018-01-01T00:00:00,,Robotic Fabrication of Segmented Shells: Integrated Data-Driven Design,10.22360/SimAUD.2018.SimAUD.020,,'Society for Modeling and Simulation International (SCS)',,core
97019099,2017-11-01T00:00:00,,Special Issue: Data-Driven Design (D3),10.1115/1.4037943,,'ASME International',,core
195365431,2018-01-01T00:00:00,"Designing interactive products means creating complex mappings between inputs and outcomes, that is, between sensor data and external information and actuations in a context. Data is an essential “material” of design in this approach, which increasingly consists of real-time data streams. The more complex the data streams become, the more difficult it becomes to apply traditional design methods without dedicated support for (1) sketching and scaffolding “online” data, (2) scheduling and simulating data, and (3) recording and replaying data as needed. We need active environments that prototypes can be immersed in, such that they receive such data and can respond to them according to their intended and designed behavior",IoTSim: Designing Interactive Products with Synthetic Data:An exploration into data-driven design with comprehensive tool support,,,,,core
156872734,2018-04-17T16:22:24,"Digital Thread offers the opportunity to use information generated across the product lifecycle to design the next generation of products. In this paper, we introduce a mathematical methodology that establishes the data-driven design and decision problem associated with Digital Thread. Our objectives are twofold: 1) Provide a mathematical definition of Digital Thread in the context of conceptual and preliminary design and establish a methodology for how information along the Digital Thread enters into the design problem as well how design decisions affect the Digital Thread. 2) Develop a data-driven design method that incorporates data from different sources from across the product life cycle. We illustrate aspects of our methodology through an example design of a structural fiber-steered composite component.United States. Air Force. Office of Scientific Research (Grant FA9550-16-1-0108)SUTD-MIT International Design Centre (IDC",Engineering Design with Digital Thread,10.2514/6.2018-0569,https://core.ac.uk/download/156872734.pdf,'American Institute of Aeronautics and Astronautics (AIAA)',,core
80308614,2017-07-09T00:00:00,"DOI : 10.1016/j.ifacol.2017.08.087International audienceThis paper emphasizes the design methodology for active tonal noise feedback cancellers starting from data collected on the system. To design such control systems, an accurate dynamic model of the system is necessary. Physical modeling can provide qualitative results but fails to yield enough accurate models for control design. The main point in the methodology is identification of primary path (noise propagation) and secondary path (compensation) models from data. The procedure is investigated in details starting with transfer functions' order estimations, continuing with parameters estimation and model's validation. The second aspect is the design of a noise canceller using the Internal Model Principle and the sensitivity function shaping in order to reduce the "" water-bed "" effect. The estimated model's quality for control design is illustrated by the experimental performance of a tonal noise feedback canceller implemented on a test bench",Data driven design of tonal noise feedback cancellers,,,HAL CCSD,,core
154988591,2018-04-09T00:00:00,"A frequency based data-driven control design considering mixed H2/H-infinity
control objectives is developed for multiple input-single output systems. The
main advantage of the data-driven control over the model-based control is its
ability to use the frequency response measurements of the controlled plant
directly without the need to identify a model for the plant. In the proposed
methodology, multiple sets of measurements can be considered in the design
process to accommodate variations in the system dynamics. The controller is
obtained by translating the mixed H2/H-infinity control objectives into a
convex optimization problem. The H-infinity norm is used to shape closed loop
transfer functions and guarantee closed loop stability, while the H2 norm is
used to constrain and/or minimize the variance of signals in the time domain.
  The proposed data-driven design methodology is used to design a track
following controller for a dual-stage HDD. The sensitivity decoupling
structure[16] is considered as the controller structure. The compensators
inside this controller structure are designed and compared by decoupling the
system into two single input-single-output systems as well as solving for a
single input-double output controller",Mixed H2/H-infinity Data-Driven Control Design for Hard Disk Drives,,http://arxiv.org/abs/1804.03298,,,core
226736010,2018-01-01T00:00:00,"Every day, thousands of pupils, students, employees, and hospital patients eat food outside their homes that is cooked far from the place of consumption. The food service industry is responsible for supplying this food to schools, hospitals, nurseries, as well as to company canteens. The design, control, and management of food service operations is challenging given the complexity of such multiple facility production networks and entails multidisciplinary perspectives and competences. Both production and logistics operations play crucial roles and significantly affect the service performance as long as food products are prepared within a facility, and as long as they are distributed to multiple consumption sites. Hence, there are many planning decisions (e.g. the definition of the production facility location, the allocation of task to resources and the scheduling of production jobs), that are handled at different stages by different actors, who often decide based on their own practical experience and barely adopt integrated decision-support systems.

A review of the literature shows that there is no integrated approach to support the design of food service production facilities, known as centralized kitchens (CEKIs). To facilitate such integration and assist food service managers to adopt quantitative and data-driven design approaches, this study proposes an original computer-based multidisciplinary decision-support tool for the design and configuration of a CEKI. The proposed tool aids decisions taken by multiple actors simultaneously through a set of interfaces driven by quantitative data that follow the logistical flow of materials throughout the CEKI (1), assesses performance indicators in a multidisciplinary dashboard (2), and implements what-if, multiple scenario analyses based on simulations (3). Graphical interfaces are designed to facilitate communication between the decision makers and the integration of data-driven analyses. The design of a new CEKI is used as a testbed for the decision-support tool. The real-world example highlights the interdependencies between issues and decisions and showcases how computer applications facilitate decision-making and improve communication between managers",Plant design and control in food service industry. A multi-disciplinary decision-support system,10.1016/j.compind.2018.09.007,,'Elsevier BV',,core
153378204,2018-05-15T00:00:00,"The expansion of programmatically-accessible materials data has cultivated
opportunities for data-driven approaches. Highly-automated frameworks like
AFLOW not only manage the generation, storage, and dissemination of materials
data, but also leverage the information for thermodynamic formability modeling,
such as the prediction of phase diagrams and properties of disordered
materials. In combination with standardized parameter sets, the wealth of data
is ideal for training machine learning algorithms, which have already been
employed for property prediction, descriptor development, design rule
discovery, and the identification of candidate functional materials. These
methods promise to revolutionize the path to synthesis and, ultimately,
transform the practice of traditional materials discovery to one of rational
and autonomous materials design.Comment: 8 pages, 2 figures, submitted to ""society magazine",Autonomous data-driven design of inorganic materials with AFLOW,,http://arxiv.org/abs/1803.05035,,,core
201170889,2018-12-01T00:00:00,"Today, interest in the analysis of cognitive activities related to creativity has become a critical interdisciplinary topic. The need for effective means for the use of data management and analysis in design is growing. As a tool to assist designers in the early stages of design, there have been discussed the effects of considering the integration of big data via the data-driven design model within the creative process of new product development. In this way, new perspectives are studied about how data and creativity science will involve the development of both design and creativity models",Supporting the creative process from data,10.23726/cij.2018.736,https://core.ac.uk/download/201170889.pdf,CERN,"[{'title': None, 'identifiers': ['2413-9505', 'issn:2413-9505']}]",core
83831706,2017-02-24T00:00:00,"The realistic modeling of STT-MRAM for the simulations of hybrid
CMOS/Spintronics devices in comprehensive simulation environments require a
full description of stochastic switching processes in state of the art
STT-MRAM. Here, we derive an analytical formulation that takes into account the
spin-torque asymmetry of the spin polarization function of magnetic tunnel
junctions studying. We studied its validity range by comparing the analytical
formulas with results achieved numerically within a full micromagnetic
framework. We also find that a reasonable fit of the probability density
function (PDF) of the switching time is given by a Pearson Type IV PDF. The
main results of this work underlines the need of data-driven design of STT-MRAM
that uses a full micromagnetic simulation framework for the statistical
proprieties PDF of switching processes","Description of statistical switching in perpendicular STT-MRAM within an
  analytical and numerical micromagnetic framework",,http://arxiv.org/abs/1702.07739,,,core
287591768,2017-09-01T00:00:00,"A cyber-physical system (CPS) is an integration of computation with physical processes whose behavior is defined by both computational and physical parts of the system. In this paper, we present a view of the challenges and opportunities for design automation of CPS. We identify a combination of characteristics that define the challenges unique to the design automation of CPS. We then present selected promising advances in depth, focusing on four foundational directions: combining model-based and data-driven design methods; design for human-in-the-loop systems; component-based design with contracts, and design for security and privacy. These directions are illustrated with examples from two application domains: smart energy systems and next-generation automotive systems","Design automation of cyber-physical systems: Challenges, advances, and opportunities",10.1109/TCAD.2016.2633961,,'Institute of Electrical and Electronics Engineers (IEEE)',,core
188198832,2017-01-01T00:00:00,,Towards an intelligent digital ecosystem - sustainable data-driven design futures,10.1002/9781119190691.ch10,http://hdl.handle.net/10536/DRO/DU:30112029,'Wiley',,core
93751832,2017-01-01T00:00:00,,Data-driven design of implicit force control for industrial robots,10.1109/icra.2017.7989268,,'Institute of Electrical and Electronics Engineers (IEEE)',,core
159192711,2017-04-24T00:00:00,"This paper presents a novel data-driven sigmoid-based PI for tracking of angular velocity of dc motor powered by a dc/dc buck converter. A global simultaneous perturbation stochastic approximation (GSPSA) is employed to ﬁnd the optimum sigmoid-based PI parameters such that the angular velocity error is minimized. The merit of the proposed approach is that it can produce fast PI parameter tuning without using any plant model by measuring the I/O data of the system. Moreover, the proposed PI parameters that are varied based on sigmoid function of angular velocity error has great potential in improving the control performance compared to the conventional PI controller. A well-known buck converter powered DC motor model is considered to validate our data-driven design. In addition, the performances of the proposed method are examined in terms of angular velocity trajectory tracking and duty cycle in comparison with other existing approaches. Numerical example shows that the data-driven sigmoid-based PI approach provides

better control performances as compared to existing methods",A Data-Driven Sigmoid-based PI Controller for Buck-Converter Powered DC Motor,,https://core.ac.uk/download/159192711.pdf,'Institute of Electrical and Electronics Engineers (IEEE)',,core
289101933,2018-01-01T00:00:00,"peer-reviewedThis article describes a developing creative practice whereby digital creative processes

adapted from mobile music making are used in the data driven design and subsequent

digital instantiation of ceramic vessels. First, related work in mobile music creation and

recent developments in the digital design and fabrication of ceramics frames the research

and puts it in a broad context. A pilot study is then detailed, concluding that although

largely successful, a number of areas of the process needed to be improved and refined.

The results of a further iteration of the process, consisting of the digital creation and

instantiation of location-specific vessels is presented, before the current state of the

research, where ceramic vessels are 3D printed, is outlined. We show that mobile phones

can become integral to a practical design process that allows the digital forms it creates to

be instantiated using 3D printing, and that these become high-quality, end-use artefacts.

The final section discusses what has been learned and contemplates how the described

practice will be developed yet further",Smartphone-based vase design: a developing creative practice,,https://core.ac.uk/download/289101933.pdf,ITERATIONS,,core
149300678,2018-01-15T08:35:59Z,"<div>Data integration has favored loosening the coupling between data. This may involve</div><div>providing a uniform query interface over a mediated schema (see figure 1), thus transforming</div><div>a query into specialized queries over the original databases. One can also term this process</div><div>""view-based query-answering"" because each of the data sources functions as a view over the</div><div>(nonexistent) mediated schema.</div",BRAIN Journal-A PROPOSED DATA DRIVEN ARCHITECTURE FOR CARDIOLOGY NETWORK APPLICATION-Figure 1. Schema for a data-integration solution,10.6084/m9.figshare.5787192.v1,,,,core
146467137,2018-01-01T00:00:00,"The infrastructure-as-code revolution in IT is also affecting database administration. With this practical book, developers, system administrators, and junior to mid-level DBAs will learn how the modern practice of site reliability engineering applies to the craft of database architecture and operations. Authors Laine Campbell and Charity Majors provide a framework for professionals looking to join the ranks of today’s database reliability engineers (DBRE).  You’ll begin by exploring core operational concepts that DBREs need to master. Then you’ll examine a wide range of database persistence options, including how to implement key technologies to provide resilient, scalable, and performant data storage and retrieval. With a firm foundation in database reliability engineering, you’ll be ready to dive into the architecture and operations of any modern database.  This book covers:      Service-level requirements and risk management     Building and evolving an architecture for operational visibility     Infrastructure engineering and infrastructure management     How to facilitate the release management process     Data storage, indexing, and replication     Identifying datastore characteristics and best use cases     Datastore architectural components and data-driven architecture",Database reliability engineering: designing and operating resilient database systems,,,O'Reilly,,core
198055245,2018-01-01T00:00:00,"To gain a first-mover advantage on the marketplace, manufacturers are striving to develop innovative products that meet the needs of a wide range of customers. Traditionally to support innovative design, the fuzzy concept stage has long been supported by heuristic design philosophies. In recent years, new supportive technologies have enabled concept generation based on the collection and reuse of existing data. Existing data can be collected from various sources; for example, customer reviews, historical data, or by studying existing products or other industrial assets such as production machines and tooling. Lately, the concept of Digital Twin (DT) has gained a wealth of attention as a means to construct a high-fidelity digital copy of a physical asset and to study its shape, position, gesture, status and motion. The common aim of the DT is to support the realistic model of system behavior that can support performance prediction and optimization. However, in providing sufficient support during the conceptual stages the realistic models become heavy and costly to adapt. While the emerging data-driven design approaches can be used to generate designs with alterations, there is a lack of support to generate and evaluate solutions during the conceptual stages. In this paper, a framework of a Digital Platform Twin (DPT) is proposed to fill this gap. In contrast to a sole high-fidelity digital representation, the DPT builds on abstracting multiple high-fidelity Digital Twins into a low- fidelity platform model, represented as a function model. The DPT framework proclaims the vision of supporting design engineers in the process of abstracting functionalities of existing assets, inserting new functionalities and technologies in the function structure to ultimately support the generation and evaluation of new functional concepts. To demonstrate the DPT framework, an automotive example is presented. We believe that reuse during platform concept development can be supported with the use of multiple DTs. To achieve this, a challenge is to practically realize the transcending in abstraction levels of the models: from Digital Twins to function model and from function model to geometry models. The transcending in abstraction levels is therefore a matter of future work",Towards Adopting Digital Twins to Support Design Reuse during Platform Concept Development,,,,,core
346164785,2017-09-01T07:00:00,"© 1982-2012 IEEE. A cyber-physical system (CPS) is an integration of computation with physical processes whose behavior is defined by both computational and physical parts of the system. In this paper, we present a view of the challenges and opportunities for design automation of CPS. We identify a combination of characteristics that define the challenges unique to the design automation of CPS. We then present selected promising advances in depth, focusing on four foundational directions: combining model-based and data-driven design methods; design for human-in-the-loop systems; component-based design with contracts, and design for security and privacy. These directions are illustrated with examples from two application domains: smart energy systems and next-generation automotive systems","Design Automation of Cyber-Physical Systems: Challenges, Advances, and Opportunities",10.1109/TCAD.2016.2633961,,'Institute of Electrical and Electronics Engineers (IEEE)',,core
345093641,2019-01-01T00:00:00,"This thesis investigates the relationship between graphic design and political campaigns with a focus on color and typography. The extent to which the general public identifies typeface and color palette characteristics is tested using surveys of college students. Findings from these surveys are used to select six color and typeface combinations ,  which are then designed and applied to a political campaign. Amazon MTurk is used to distribute these campaigns alongside surveys to five hundred individuals nationally. These surveys are designed to document the general public's perceptions of campaign design. Specifically ,  randomizing the release of campaigns across individuals reveals the relative influence of color and typeface on a campaign's signaling of political party and ideology. Surveys also document perceptions of kindness ,  trustworthiness ,  modernity and traditionality to these designed campaigns. The combination of graphic design ,  large-scale public dissemination and survey-based feedback introduces a data-driven design methodology that has the potential to improve and enrich the graphic design process for students ,  working designers and researchers. This research works in conjunction with a participatory installation that brings attention to creating design decisions and the influence of political design. The installation encourages involvement with the political process as participants create their own political campaign ephemera on a custom-designed application","You ,  the Candidate",,,,,core
327016156,2019-12-12T00:00:00,"Limiting the increase of CO2 in the atmosphere is one of the largest challenges of our generation1. Because carbon capture and storage is one of the few viable technologies that can mitigate current CO2 emissions2, much effort is focused on developing solid adsorbents that can efficiently capture CO2 from flue gases emitted from anthropogenic sources3. One class of materials that has attracted considerable interest in this context is metal–organic frameworks (MOFs), in which the careful combination of organic ligands with metal-ion nodes can, in principle, give rise to innumerable structurally and chemically distinct nanoporous MOFs. However, many MOFs that are optimized for the separation of CO2 from nitrogen4–7 do not perform well when using realistic flue gas that contains water, because water competes with CO2 for the same adsorption sites and thereby causes the materials to lose their selectivity. Although flue gases can be dried, this renders the capture process prohibitively expensive8,9. Here we show that data mining of a computational screening library of over 300,000 MOFs can identify different classes of strong CO2-binding sites—which we term ‘adsorbaphores’—that endow MOFs with CO2/N2 selectivity that persists in wet flue gases. We subsequently synthesized two water-stable MOFs containing the most hydrophobic adsorbaphore, and found that their carbon-capture performance is not affected by water and outperforms that of some commercial materials. Testing the performance of these MOFs in an industrial setting and consideration of the full capture process—including the targeted CO2 sink, such as geological storage or serving as a carbon source for the chemical industry—will be necessary to identify the optimal separation material",Data-driven design of metal–organic frameworks for wet flue gas CO<inf>2</inf> capture,,,,,core
398189793,2019-12-26T00:00:00,"We show that a neural network whose output is obtained as the difference of the outputs of two feedforward networks with exponential activation function in the hidden layer and logarithmic activation function in the output node (LSE networks) is a smooth universal approximator of continuous functions over convex, compact sets. By using a logarithmic transform, this class of networks maps to a family of subtraction-free ratios of generalized posynomials, which we also show to be universal approximators of positive functions over log-convex, compact subsets of the positive orthant. The main advantage of Difference-LSE networks with respect to classical feedforward neural networks is that, after a standard training phase, they provide surrogate models for design that possess a specific difference-of-convex-functions form, which makes them optimizable via relatively efficient numerical methods. In particular, by adapting an existing difference-of-convex algorithm to these models, we obtain an algorithm for performing effective optimization-based design. We illustrate the proposed approach by applying it to data-driven design of a diet for a patient with type-2 diabetes",A Universal Approximation Result for Difference of log-sum-exp Neural Networks,,,HAL CCSD,,core
149300677,2018-01-15T08:42:47Z,"<div>Figure 2 presents a general schematic overview of the medical informational system,</div><div>underlying the main roles in the system together with their interactions. From an architectural</div><div>point of view one can identify the following main components:</div><div>• Host systems, named local (medical data) production systems</div><div>• General Practitioner system</div><div>• Analysis Laboratory system</div><div>• Hospital system</div><div>• Client system (interface to remote devices)</div><div>• Local portal (regional, national) for medical assistance, and long term data storage</div",BRAIN Journal-A PROPOSED DATA DRIVEN ARCHITECTURE FOR CARDIOLOGY NETWORK APPLICATION-Figure 2. System General View,10.6084/m9.figshare.5787204.v1,,,,core
322778507,2019-01-01T00:00:00,"Switching linear models can be used to represent the behavior of hybrid, time-varying, and nonlinear systems, while generally providing a satisfactory trade-off between accuracy and complexity. Although several control design techniques are available for such models, the effect of modeling errors on the closed-loop performance has not been formally evaluated yet. In this paper, a data-driven synthesis scheme is thus introduced to design optimal switching controllers directly from data, without needing a model of the plant. In particular, the theory will be developed for piecewise affine controllers, which have proven to be effective in many real-world engineering applications. The performance of the proposed approach is illustrated on some benchmark simulation case studies",Direct data-driven design of switching controllers,10.1002/rnc.4821,,'Wiley',,core
222664432,2019-05-29T07:00:00,"Previous applications to design processes intend to enhance a building’s schematic design using quantitative data. Therefore, most applications to the early design phases are passed by as simple overarching ideas informed by the designer and users’ knowledge. Although this is a preferred method of choice making, the knowledge used to inform conceptual and schematic design process can be limited. With the increase of computation in all major industries, a new increase in data to describe forms of infrastructure is required. These forms being objects to analyze their performance and potential, and active forms that can describe the disposition of urban space. Previous research into data driven design has worked its way into standardization and performance goals. However, the connection between active and object forms as a network of standards has yet to be introduced as a method of advising design. Meaning design has focused on creating a single object that seems to benefit the ecology. No attempt at connecting urban active data to object data has been made to benefit both forms equally, but only to preserve the status quo. The introduction of Machine learning algorithms has the capability to connect these complex forms and inform new designs. The application of machine learning algorithms advises the early phases of architectural design process by reviewing a manifold of data, privileging complex analogical connections, and simulating the designers informed symbolic choices.
Supervisor Professor Mark A. Hoistad, AI",Machine Learning in Architecture: Connectionist Approach to Architectural Design,,https://core.ac.uk/download/222664432.pdf,DigitalCommons@University of Nebraska - Lincoln,,core
275910815,2019-12-26T00:00:00,"We show that a neural network whose output is obtained as the difference of the outputs of two feedforward networks with exponential activation function in the hidden layer and logarithmic activation function in the output node (LSE networks) is a smooth universal approximator of continuous functions over convex, compact sets. By using a logarithmic transform, this class of networks maps to a family of subtraction-free ratios of generalized posynomials, which we also show to be universal approximators of positive functions over log-convex, compact subsets of the positive orthant. The main advantage of Difference-LSE networks with respect to classical feedforward neural networks is that, after a standard training phase, they provide surrogate models for design that possess a specific difference-of-convex-functions form, which makes them optimizable via relatively efficient numerical methods. In particular, by adapting an existing difference-of-convex algorithm to these models, we obtain an algorithm for performing effective optimization-based design. We illustrate the proposed approach by applying it to data-driven design of a diet for a patient with type-2 diabetes",A Universal Approximation Result for Difference of log-sum-exp Neural Networks,,,HAL CCSD,,core
207817577,2017,,Special Issue: Data-Driven Design (D3),10.1115/1.4037943,http://mechanicaldesign.asmedigitalcollection.asme.org/data/journals/jmdedb/936524/md_139_11_110301.pdf,ASME International,,core
84328924,2018-03-21T00:00:00,"Pandeia is the exposure time calculator (ETC) system developed for the James
Webb Space Telescope (JWST) that will be used for creating JWST proposals. It
includes a simulation-hybrid Python engine that calculates the two-dimensional
pixel-by-pixel signal and noise properties of the JWST instruments. This allows
for appropriate handling of realistic point spread functions, MULTIACCUM
detector readouts, correlated detector readnoise, and multiple photometric and
spectral extraction strategies. Pandeia includes support for all the JWST
observing modes, including imaging, slitted/slitless spectroscopy, integral
field spectroscopy, and coronagraphy. Its highly modular, data-driven design
makes it easily adaptable to other observatories. An implementation for use
with WFIRST is also available",Pandeia: A Multi-mission Exposure Time Calculator for JWST and WFIRST,10.1117/12.2231768,http://arxiv.org/abs/1707.02202,'SPIE-Intl Soc Optical Eng',,core
144131139,2017-01-01T00:00:00,,DD-DeCaF: Data-Driven Design of Cell Factories and Communities,,https://core.ac.uk/download/144131139.pdf,Technical University of Denmark,,core
215712850,2018-12-21T08:00:00,"Autonomy and intelligence have been built into many of today’s mechatronic products, taking advantage of low-cost sensors and advanced data analytics technologies. Design of product intelligence (enabled by analytics capabilities) is no longer a trivial or additional option for the product development. The objective of this research is aimed at addressing the challenges raised by the new data-driven design paradigm for smart products development, in which the product itself and the smartness require to be carefully co-constructed.
A smart product can be seen as specific compositions and configurations of its physical components to form the body, its analytics models to implement the intelligence, evolving along its lifecycle stages. Based on this view, the contribution of this research is to expand the “Product Lifecycle Management (PLM)” concept traditionally for physical products to data-based products. As a result, a Smart Products Lifecycle Management (sPLM) framework is conceptualized based on a high-dimensional Smart Product Hypercube (sPH) representation and decomposition.
First, the sPLM addresses the interoperability issues by developing a Smart Component data model to uniformly represent and compose physical component models created by engineers and analytics models created by data scientists. Second, the sPLM implements an NPD3 process model that incorporates formal data analytics process into the new product development (NPD) process model, in order to support the transdisciplinary information flows and team interactions between engineers and data scientists. Third, the sPLM addresses the issues related to product definition, modular design, product configuration, and lifecycle management of analytics models, by adapting the theoretical frameworks and methods for traditional product design and development.
An sPLM proof-of-concept platform had been implemented for validation of the concepts and methodologies developed throughout the research work. The sPLM platform provides a shared data repository to manage the product-, process-, and configuration-related knowledge for smart products development. It also provides a collaborative environment to facilitate transdisciplinary collaboration between product engineers and data scientists","A Smart Products Lifecycle Management (sPLM) Framework - Modeling for Conceptualization, Interoperability, and Modularity",,https://core.ac.uk/download/215712850.pdf,SURFACE at Syracuse University,,core
478186752,2018-01-01T00:00:00,"The paper discusses the role and the challenges of integrating Data-Driven Design (DDD) models in the product innovation process. Firstly, based on academic literature on the Product Innovation Value Streamsand on Model-Based Decision Supports, the paper highlights how and when the use of DDD models can support a more effective product innovation process. Secondly, it highlights a list of challenges to be considered for the development of new DDD models for decision support. Ultimately, those challenges are formalized in an evaluation matrix intended to guide the further development of DDD",Role and Challenges of Data-Driven Design in the Product Innovation Process,10.1016/j.ifacol.2018.08.455,,'Elsevier BV',,core
151245888,2018-02-01T00:00:00,"We present a widely-used operations management model used in supply and
distribution planning, that is typically embedded in a periodic business
process that necessitates model modification and reuse. We consider three
alternative spreadsheet implementations, a data-driven design, a canonical
(textbook) design, and a novel (table-driven) technical design. We evaluate
each regarding suitability for accuracy, modification, analysis, and transfer.
We consider the degree of training and technical sophistication required to
utilize each design. The data-driven design provides insight into poor
spreadsheet practices by na\""ive modelers. The technical design can be modified
for new data and new structural elements without manual writing or editing of
cell formulas, thus speeding modification and reducing risk of error. The
technical design has potential for use with other classes of models. We
identify opportunities for future research.Comment: 12 Pages, 10 Colour Figure","Alternative Spreadsheet Model Designs for an Operations Management Model
  Embedded in a Periodic Business Process",,http://arxiv.org/abs/1802.00484,,,core
286807624,2019-07,"International audienceOne of the main tasks of today's data-driven design is to learn customers' concerns from the feedback data posted on the internet, to drive smarter and more profitable decisions during product development. Feature-based opinion mining was first performed by the computer and design scientists to analyse online product reviews. In order to provide more sophisticated customer feedback analyses and to understand in a deeper way customer concerns about products, the authors propose an affordance-based online review analysis framework. This framework allows understanding how and in what condition customers use their products, how user preferences change over years and how customers use the product innovatively. An empirical case study using the proposed approach is conducted with the online reviews of Kindle e-readers downloaded from amazon.com. A set of innovation leads and redesign paths are provided for the design of next-generation e-reader. This study suggests that bridging data analytics with classical models and methods in design engineering can bring success for data-driven design",An Affordance-Based Online Review Analysis Framework,10.1017/dsi.2019.252,,HAL CCSD,,core
185674447,2018-03-06T08:00:00,"Plants produce a variety of rare natural products which are used in our daily lives as flavors, fragrances, food ingredients, cosmetics, vitamins, pharmaceuticals and agricultural chemicals. Despite their intrinsic value, however, sourcing remains a bottleneck to more widespread use due to their low abundance in nature. Manus Bio has established an innovative platform technology for engineering microbial factories grounded in modular and data-driven design and developed a commercial organism which can produce a myriad of typically ultra-rare and costly ingredients used in our daily lives. These microbes are capable of converting carbon feedstock to the product at high yields and have been adapted to produce a mature pipeline of products, or  BioAssemblyLine.  To engineer our “BioAssemblyLine,” we integrate three core technologies - our proprietary Multivariate Modular Metabolic Engineering (MMME), Pathway Integrated Protein Engineering (PIPE) and Integrated Multivariate Omics Analysis (IMOA) platforms. In this presentation, we will highlight several important insights and guiding principles established to engineer our “BioAssemblyLine” microbial factories",An efficient commercial platform for microbial engineering of natural products,,https://core.ac.uk/download/185674447.pdf,ECI Digital Archives,,core
323015979,2018-01-01T00:00:00,"This article describes a developing creative practice whereby digital creative processes
adapted from mobile music making are used in the data driven design and subsequent
digital instantiation of ceramic vessels. First, related work in mobile music creation and
recent developments in the digital design and fabrication of ceramics frames the research
and puts it in a broad context. A pilot study is then detailed, concluding that although
largely successful, a number of areas of the process needed to be improved and refined.
The results of a further iteration of the process, consisting of the digital creation and
instantiation of location-specific vessels is presented, before the current state of the
research, where ceramic vessels are 3D printed, is outlined. We show that mobile phones
can become integral to a practical design process that allows the digital forms it creates to
be instantiated using 3D printing, and that these become high-quality, end-use artefacts.
The final section discusses what has been learned and contemplates how the described
practice will be developed yet further",Smartphone-based vase design: a developing creative practice,,,ITERATIONS,,core
286566490,2019-08-05T00:00:00,"International audienceOne of the main tasks of today's data-driven design is to learn customers' concerns from the feedback data posted on the internet, to drive smarter and more profitable decisions during product development. Feature-based opinion mining was first performed by the computer and design scientists to analyse online product reviews. In order to provide more sophisticated customer feedback analyses and to understand in a deeper way customer concerns about products, the authors propose an affordance-based online review analysis framework. This framework allows understanding how and in what condition customers use their products, how user preferences change over years and how customers use the product innovatively. An empirical case study using the proposed approach is conducted with the online reviews of Kindle e-readers downloaded from amazon.com. A set of innovation leads and redesign paths are provided for the design of next-generation e-reader. This study suggests that bridging data analytics with classical models and methods in design engineering can bring success for data-driven design",An Affordance-Based Online Review Analysis Framework,10.1017/dsi.2019.252,,'Cambridge University Press (CUP)',,core
298144489,2019,312 pages ; illustrations ; 24 c,Data visualisation : a handbook for data driven design,,,SAGE Publications,,core
372435174,2017-01-01T00:00:00,,Data-Driven Design of an Ebola Therapeutic,10.1016/j.procs.2017.05.127,,'Elsevier BV',,core
211981021,2018-02-15T15:02:17,"The objective of this dissertation is to develop data-driven frequency-domain methods for designing robust controllers through the use of convex optimization algorithms. Many of today's industrial processes are becoming more complex, and modeling accurate physical models for these plants using first principles may be impossible. With the increased developments in the computing world, large amounts of measured data can be easily collected and stored for processing purposes. Data can also be collected and used in an on-line fashion. Thus it would be very sensible to make full use of this data for controller design, performance evaluation, and stability analysis. The design methods imposed in this work ensure that the dynamics of a system are captured in an experiment and avoids the problem of unmodeled dynamics associated with parametric models. The devised methods consider robust designs for both linear-time-invariant (LTI) single-input-single-output (SISO) systems and certain classes of nonlinear systems. 

In this dissertation, a data-driven approach using the frequency response function of a system is proposed for designing robust controllers with H&infin; performance. Necessary and sufficient conditions are derived for obtaining H&infin; performance while guaranteeing the closed-loop stability of a system. A convex optimization algorithm is implemented to obtain the controller parameters which ensure system robustness; the controller is robust with respect to the frequency-dependent uncertainties of the frequency response function. For a certain class of nonlinearities, the proposed method can be used to obtain a best-linear-approximation with an associated frequency dependent uncertainty to guarantee the stability and performance for the underlying linear system that is subject to nonlinear distortions.

The concepts behind these design methods are then used to devise necessary and sufficient conditions for ensuring the closed-loop stability of systems with sector-bounded nonlinearities. The conditions are simple convex feasibility constraints which can be used to stabilize systems with multi-model uncertainty. Additionally, a method is proposed for obtaining H&infin; performance for an approximate model (i.e., describing function) of a sector-bounded nonlinearity. 

This work also proposes several data-driven methods for designing robust fixed-structure controllers with H&infin; performance. One method considers the solution to a non-convex problem, while another method convexifies the problem and implements an iterative algorithm to obtain the local solution (which can also consider H2 performance).

The effectiveness of the proposed method(s) is illustrated by considering several case studies that require robust controllers for achieving the desired performance. The main applicative work in this dissertation is with respect to a power converter control system at the European Organization for Nuclear Research (CERN) (which is used to control the current in a magnet to produce the desired field in controlling particle trajectories in accelerators). The proposed design methods are implemented in order to satisfy the challenging performance specifications set by the application while guaranteeing the system stability and robustness using data-driven design strategies",A Data-Driven Frequency-Domain Approach for Robust Controller Design via Convex Optimization,10.5075/epfl-thesis-8305,https://core.ac.uk/download/211981021.pdf,"Lausanne, EPFL",,core
132267761,2017-09,"Over the past few decades, digital technologies have played an increasingly substantial role in how we relate to our environment.
Through mobile devices, sensors, big data and ubiquitous computing amongst other digital technologies, our physical surroundings
have become augmented with intangible data, suggesting that architects of the future could start to view this increasingly digitally
saturated world around them as information-rich environments (McCullough 2013). The adoption of computational design and
digital fabrication processes has given architects and designers opportunities to design and fabricate architecture with unseen material
performance and precision. However, attempts to combine these tools with methods for navigating and integrating the vast amount of
available data into the design process have appeared slow and complicated. This research therefore proposes a method for data
capture and visualisation, which in spite of its infancy displays potentials to be used in projects ranging in scale from the urban to
interior evaluation of existing buildings. The working research question is as follows; “How can we develop a near real time data
capture and visualisation method that can be used across scales in architectural design processes?” Furthermore, we conclude by
hypothesising what such a process can bring to a architectural education and practice.status: publishe",Navigating the Intangible: Spatial-Data-Driven Design Modelling in Architecture,10.1007/978-981-10-6611-5,,Singapore,,core
158382153,2018-05-29T00:00:00,"Maximalism in art refers to drawing on and combining multiple different
sources for art creation, embracing the resulting collisions and heterogeneity.
This paper discusses the use of maximalism in game design and particularly in
data games, which are games that are generated partly based on open data. Using
Data Adventures, a series of generators that create adventure games from data
sources such as Wikipedia and OpenStreetMap, as a lens we explore several
tradeoffs and issues in maximalist game design. This includes the tension
between transformation and fidelity, between decorative and functional content,
and legal and ethical issues resulting from this type of generativity. This
paper sketches out the design space of maximalist data-driven games, a design
space that is mostly unexplored.Comment: 9 pages, 2 Figures, Accepted in ICCC 201",Data-driven Design: A Case for Maximalist Game Design,,http://arxiv.org/abs/1805.12475,,,core
232583514,2017-06-09T07:00:00,"Formulation is very important in drug delivery. The wrong formulation can render a drug product useless. The amount of preclinical (animal and in vitro) work that must be done before a new drug candidate can be tested in humans can be a problem. The cost of these cGxP studies is typically $3-$5 million. If the wrong drug product formulation is tested, new iterations of the formulation must be tested with additional costs.  Data-driven computational science can help reduce this cost. In the absence of existing human exposure, a battery of preclinical tests must be performed in at least two species before FDA will permit testing in humans. However, for many drugs (such as those beginning with natural products) there is a history of human exposure. In these cases, computer modeling of a population to determine human exposure may be adequate to permit phase 1 studies with a candidate formulation in humans.  The CDC’s National Health and Nutrition Examination Survey (NHANES) is a program of studies designed to assess the health and nutritional status of adults and children in the United States. The survey is unique in that it combines interviews and physical examinations including laboratory results. The NHANES database can be mined to determine exposure to a food additive, and early human formulation testing conducted at levels beneath those to which the US population is ordinarily exposed through food. These data can be combined with data mined from international chemical shipments to validate an exposure model. This paper describes the data driven formulation testing process using a new candidate Ebola treatment that, unlike vaccines, can be used after a person has contracted the disease. This drug candidate’s mechanism of action permits it to be potentially used against all strains of the virus, a characteristic that vaccines might not share",Data-Driven Design of an Ebola Therapeutic,,https://core.ac.uk/download/232583514.pdf,UKnowledge,,core
200857150,2019-05-01T00:00:00,"To improve the fault diagnosis performance for rotating machinery, an efficient, noise-resistant end-to-end deep learning (DL) algorithm is proposed based on the advantages of the wavelet packet transform in vibration signal processing (the capability to extract multiscale information and more spectral distribution features) and deep convolutional neural networks (good classification performance, data-driven design and high transfer-learning ability). First, a vibration signal is subjected to pyramid wavelet packet decomposition, and each sub-band coefficient is used as the input for each channel of a deep convolutional network (DCN). Then, based on the lightweight modeling requirements and techniques, a new DCN structure is designed for the fault diagnosis. The proposed algorithm is compared with the support vector machine algorithm and the published DL algorithms based on a bearing dataset produced by Case Western Reserve University. The experimental results show that the proposed algorithm is superior to the existing algorithms in terms of accuracy, memory space, computational complexity, noise resistance, and transfer performance, producing good results",A Lighted Deep Convolutional Neural Network Based Fault Diagnosis of Rotating Machinery,10.3390/s19102381,,'MDPI AG',"[{'title': 'Sensors', 'identifiers': ['issn:1424-8220', '1424-8220']}]",core
299933746,2019-10-22,"With the rise of ubiquitous technology, data-driven design, and the Internet of Things, our interactions and interfaces with technology are about to change dramatically, incorporating such emerging technologies as shape-changing interfaces, wearables, and movement-tracking apps. A successful interactive tool will allow the user to engage in a smooth, embodied, interaction, creating an intimate correspondence between users\u27 actions and system response. And yet, as Kristina Höök points out, current design methods emphasize symbolic, language-oriented, and predominantly visual interactions. In Designing with the Body, Höök proposes a qualitative shift in interaction design to an experiential, felt, aesthetic stance that encompasses the entire design and use cycle.

Höök calls this new approach soma design; it is a process that reincorporates body and movement into a design regime that has long privileged language and logic. Soma design offers an alternative to the aggressive, rapid design processes that dominate commercial interaction design; it allows (and requires) a slow, thoughtful process that takes into account fundamental human values. She argues that this new approach will yield better products and create healthier, more sustainable companies.

Höök outlines the theory underlying soma design and describes motivations, methods, and tools. She offers examples of soma design “encounters” and an account of her own design process. She concludes with “A Soma Design Manifesto,” which challenges interaction designers to “restart” their field?to focus on bodies and perception rather than reasoning and intellect",Designing with the Body: Somaesthetic Interaction Design,,,'MIT Press - Journals',,core
468462952,2018-01-01T00:00:00,,Data-driven design for civic participation,10.4324/9781315110332-5,,'Informa UK Limited',,core
154409882,2018-12-31T00:00:00,"This paper draws upon the example of High-Cost Short-Term Credit products accessed via digital interfaces and devices to examine practices of interface design and the operation of digitally mediated power. Utilising interviews with High-Cost Short-Term Credit website designers and users of these products, the paper shows how these interfaces are designed and tested to manage frictions: practical, affective or emotional contestations that interrupt or stop users from applying for these products and entering into credit and debt. We suggest that the key role of interface design is to manage these frictions by guiding action in such a way to minimise negative affective states at key thresholds of the application process. The management of friction is enabled by practices of data-driven design, where the contingency of human response is engineered through analytics in order to increase rates of application. Working through the example of High-Cost Short-Term Credit, the paper complicates a notion of control as a smooth or automatic operation of power, instead emphasising the necessity of both continuity and discontinuity as key to modulating action in a digital age. To understand the specificity of interface interactions and move beyond existing work on control, we offer a vocabulary of friction, thresholds and transitions","Digital interface design and power : friction, threshold, transition.",10.1177/0263775818767426,https://core.ac.uk/download/154409882.pdf,'SAGE Publications',"[{'title': 'Environment and Planning D Society and Space', 'identifiers': ['issn: 1472-3433', 'issn:0263-7758', '0263-7758', ' 1472-3433']}]",core
287623814,2019-12-11T00:00:00,"Limiting the increase of CO2 in the atmosphere is one of the largest challenges of our generation1. Because carbon capture and storage is one of the few viable technologies that can mitigate current CO2 emissions2, much effort is focused on developing solid adsorbents that can efficiently capture CO2 from flue gases emitted from anthropogenic sources3. One class of materials that has attracted considerable interest in this context is metal-organic frameworks (MOFs), in which the careful combination of organic ligands with metal-ion nodes can, in principle, give rise to innumerable structurally and chemically distinct nanoporous MOFs. However, many MOFs that are optimized for the separation of CO2 from nitrogen4-7 do not perform well when using realistic flue gas that contains water, because water competes with CO2 for the same adsorption sites and thereby causes the materials to lose their selectivity. Although flue gases can be dried, this renders the capture process prohibitively expensive8,9. Here we show that data mining of a computational screening library of over 300,000 MOFs can identify different classes of strong CO2-binding sites-which we term 'adsorbaphores'-that endow MOFs with CO2/N2 selectivity that persists in wet flue gases. We subsequently synthesized two water-stable MOFs containing the most hydrophobic adsorbaphore, and found that their carbon-capture performance is not affected by water and outperforms that of some commercial materials. Testing the performance of these MOFs in an industrial setting and consideration of the full capture process-including the targeted CO2 sink, such as geological storage or serving as a carbon source for the chemical industry-will be necessary to identify the optimal separation material",Data-driven design of metal-organic frameworks for wet flue gas CO2 capture.,,https://core.ac.uk/download/287623814.pdf,"eScholarship, University of California",,core
287504085,2019-05-31T00:00:00,,Aural Textiles. Hybrid practices for data-driven design.,10.1080/14606925.2019.1594982,,'Informa UK Limited',,core
222833117,2019-01-01T00:00:00,"Objectives: Effective secondary stroke prevention strategies are sub-optimally used. Novel development of interventions to enable healthcare professionals and stroke survivors to manage risk factors for stroke recurrence are required. We sought to engage key stakeholders in the design and evaluation of an intervention informed by a Learning Health System approach, to improve risk factor management and secondary prevention for stroke survivors with multimorbidity.Design: Qualitative, including focus groups, semi-structured interviews and usability evaluations. Data was audio-recorded, transcribed and coded thematically.Participants: Stroke survivors, carers, health and social care professionals, commissioners, policy makers and researchers.Setting: Stroke survivors were recruited from the South London Stroke Register; health and social care professionals through South London general practices and Kingâ��s College London (KCL) networks; carers, commissioners, policy-makers and researchers through KCL networks.Results: 53 stakeholders in total participated in focus groups, interviews and usability evaluations. Thirty-seven participated in focus groups and interviews, including stroke survivors and carers (N=11), health and social care professionals (N=16), commissioners and policy-makers (N=6) and researchers (N=4). Sixteen participated in usability evaluations, including stroke survivors (N=8) and general practitioners (GPs; N=8). Eight themes informed the collaborative design of DOTT (Deciding on Treatments Together), a decision aid integrated with the electronic health record system, to be used in primary care during clinical consultations between the healthcare professional and stroke survivor. DOTT aims to facilitate shared decision making on personalised treatments leading to improved treatment adherence and risk control. DOTT was found acceptable and usable among stroke survivors and GPs during a series of evaluations.Conclusions: Adopting a user-centred data-driven design approach informed an intervention that is acceptable to users and has the potential to improve patient outcomes. A future feasibility study and subsequent clinical trial will provide evidence of the effectiveness of DOTT in reducing risk of stroke recurrence",Collaborative design of a decision aid for stroke survivors with multimorbidity: a qualitative study in the UK engaging key stakeholders,10.1136/bmjopen-2019-030385,,'BMJ',,core
322677331,2019,"The practice of Industrial Design is typically defined as the design of products for mass manufacture. Whilst this is a traditional endeavour for the Industrial Designer, such a narrow definition does not accurately represent the new innovation landscapes in which contemporary practice is centred. Increasingly Industrial Designers are designing experiences and services that are mediated by tangible, but often non-physical, products. Sitting behind this are agendas for design that lie outside of the manufacturing concern such as, designing for emotion, for social impact, for improved health and well-being, or for pathways towards less unsustainable futures. In this work Industrial Designers draw on a range of methods and discourses that further distance them from manufacturing concerns including inclusive design, design for sustainability, and interaction and data-driven design. Traditional technical and pragmatic orientations are often set aside so that designer can innovate or deal with complexity through speculative and propositional design thinking. Of importance in this shift is the near universal mindset that design decisions ought not impart a negative impact on the environment or society, through an approach to practice that strives to make positive contributions to societal wellbeing. 
This paper examines the contestable meanings of Industrial Design defined by professional associations and challenged by designers and design theorists. It explores transitions of practice and the implications of such messaging and counter-messaging on the ways Industrial Design education can be understood; where continuously re-defining Industrial Design is itself critical to any pedagogy for future practice",Redefining industrial design: responding to emerging modes of practice,,,"Design Society, Institution of Engineering Designers (Glasgow, United Kingdom)",,core
160052369,2017-01-01T00:00:00,"Nowadays, progresses in the field of information and communication technology, science of materials,

building technology and design computing allow to imagine cutting edge buildings able to show innovative

performances in terms of adaptability and interaction with environmental conditions, as well as with human

activities and needs.

New methods and strategies and advanced computational tools allow the design high-performance building

skins.

This paper introduces a new methodology to design “eco-adaptive” envelopes. Furthermore, a new

computational tool, based on a visual algorithm, implements the aforementioned approach.

The purposes of the methodology includes the following operations:

- Evaluation of adaptive envelope's behaviors in terms of responsiveness with specific environmental

conditions. This research analyzed a number of realized study cases. The actual effectiveness of its adaptive

facades is evaluated by the comparison with standard systems.

- Design of “short term” or “long term” adaptive envelopes. In both cases, results are outputs of

optimized processes in which performances, morphologies and sizes are properly studied and tailored for

any specific context by considering the interactions among buildings and several environmental factors.

The results are outputs of digital analysis and simulations. The digital simulations are set by a multi-tools

computational platform, based on visual programming language, in which advanced modeling and building

energy software are, simultaneously, involved.

Both, the methodology and the instrument are applied to a pilot project. This project consists in an

architectural refurbishment and environmental retrofitting of an existing building in Rome: Ex Ministero delle

Finanze. In accordance with the aforementioned method, the new virtual façade is conceived as a “complex

adaptive system” which considers a number of inputs, stored in “open data infrastructure and platform”, to

adapt its morphology and behavior via a “data driven design” process",Eco-adaptive building skin: design methodology & computational tools for eco-adaptive envelopes,,,,,core
288586120,2017,"In this paper, a data-driven design of deadbeat controllers is proposed, which is later generalized in different ways to allow for trade-offs between convergence rate and control effort. The proposed design is then combined with recent work on data-driven output regulation using external models, and shown to provide very desirable responses",Data-driven deadbeat control with application to output regulation,10.1109/CDC.2017.8264604,,IEEE,,core
231681156,2018-01-01T00:00:00,"Maximalism in art refers to drawing on and combining
multiple different sources for art creation, embracing
the resulting collisions and heterogeneity. This paper
discusses the use of maximalism in game design
and particularly in data games, which are games that
are generated partly based on open data. Using Data
Adventures, a series of generators that create adventure
games from data sources such as Wikipedia and Open-
StreetMap, as a lens we explore several tradeoffs and
issues in maximalist game design. This includes the tension
between transformation and fidelity, between decorative
and functional content, and legal and ethical issues
resulting from this type of generativity. This paper
sketches out the design space of maximalist data-driven
games, a design space that is mostly unexplored.peer-reviewe",Data-driven design : a case for maximalist game design,,https://core.ac.uk/download/231681156.pdf,Association for Computational Creativity,,core
222586035,2018-01-01T00:00:00,"Introduction



Currently, the learning science community is exploring the use of data-driven design to improve K12 educational systems. These “continuous-improvement systems” aim to align strategic goals, outcome metrics and human-computer system processes to support improved learning outcomes. However, the learning science community has only begun to apply systemic design to practical implementation of these systems.



In this paper, we present several examples of data-driven design in K12 educational systems in order to identify aspects that can beneﬁt from systemic design. Through these case studies, we focus on three concepts: 1) systemic designers can ensure that the system is capable of measuring successful outcomes; 2) systemic designers can ensure that system optimization will improve intended outcomes while minimizing unintended consequences; and 3) systemic designers can portray what a future with these continuous improvement systems will be like to the educational community, before any resources are committed to building the technology.



Example #1: Ensure that the system is capable of measuring successful outcomes



Data can be used to inform system stakeholders about the success of designed systems; that is, how well outcome measures align with system intentions. For instance, after providing an instructional activity (lecture, small group, video, etc) in class, a teacher might assign their students an “exit ticket” quiz to assess whether the instructional activity was successful. These quizzes support data-driven decisions about how to spend time and effort in the classroom. Variations in student performance give teachers an understanding of the students who need greater attention and the learning objectives that need greater attention. Further, digital data from exit tickets or other formative assessments can be aggregated across teachers to provide school administrators with continuous insight into the areas of need, such as students or teachers who need additional help or learning objectives that are posing special challenges. Providers of digital instruction can then aggregate usage and performance across many schools in order to identify successful and unsuccessful usage patterns. Data-driven continuous improvement can occur at multiple levels (i.e., teacher, school & software provider) when systems are designed to generate valid outcome metrics of success (goal achievement).



Example #2: Ensure that system optimization will improve intended outcomes while minimizing unintended consequence



Success metrics can be used by human teams and AI systems to drive continuous improvement. However, the optimization of metrics can produce unintended consequences when chosen metrics are not fully aligned to intended outcomes and when feedback loops about metric suitability are impoverished. In this case study, an online educational game is designed with the goal of motivating students to practice math problems. After being deployed online, the game attracts several thousand students a day; these players are randomly assigned to different game design variations to observe how



the effects of different designs on key outcome metrics (e.g., duration of voluntary play). To investigate the role of AI in system design optimization, we implemented a UCB multi-armed bandit (a reinforcement learning AL/ML algorithm) to automatically test variations in the existing game parameter space (e.g., time limits, etc). The algorithm is designed to optimally balance the exploration of potential game designs with exploitation of the most successful designs; sometimes it will randomly search the game design space for conﬁgurations that maximize metrics (duration of voluntary play time) and sometimes it will deploy the most successful variations. While the algorithm worked as intended, the system “spun out of control” and primarily deployed malformed game designs that were maximizing the outcome metric but were misaligned with the original educational intent: the game variations were likely played for long periods of time because they were absurdly easy. This shows the pitfalls of having AI systems engage in automatic optimization without humans in the loop as a governing feedback system. Systemic designers need to design feedback systems to monitor system AI to ensure that outputs are meaningfully aligned to system intentions.



Example #3: Portray what the future will be like



Artiﬁcial intelligence has the potential to facilitate the work of teachers by reducing the effort required to use data to inform personalized instruction. However, AI can be intimidating or off-putting to teachers who do not understand its operation or intentions. In this case study, we deployed a teacher-facing recommendation system that uses reinforcement learning to continuously improve recommendation usefulness to teachers. To design a reinforcement learning AI system, there must be data representations of the system state, the space of possible actions and a reward signal tied to a success metric. In our case, the system state is student digital performance on learning activities, the action possibilities are the different digital items that teachers can next assign to a student and the reward signal occurs when teachers act upon a recommendation (i.e., when they assign those digital activities recommended by the system).



This system embodies two key elements that diverge from most existing work in “adaptive learning” or “intelligent tutoring systems.” First, the system emphasizes human-technology teamwork, in contrast to human replacement, so that teachers are empowered by the assistance of the AI. Secondly, the artiﬁcial intelligence is deliberately constructed as an aggregation of human intelligence: the system learns from the activity-assignment decisions that are made by thousands of other human teachers and aggregates them into artiﬁcially intelligent recommendations. To promote adoption of this system, a key role for systemic design is making the intended future vision accessible and attractive to teachers and other stakeholders. Systemic designers can help to engage humans to participate in the decision making by presenting a glimpse of what a data-driven future might be like in the classroom.



Conclusion



Across these case studies, we show how systemic design can aid diverse participants in the implementation of data-driven design and optimization. Systemic design insight can contribute to the negotiation of meaningful and robust metrics of success, to the construction of human-in-the-loop governance of AI systems and to the representation of potential futures. We expect designers to play a crucial role in taming the complexity of practical AI-human systems and aligning system outcomes to sustainable, humanistic values",Continuous improvement: How systems design can benefit the data-driven design community,,https://core.ac.uk/download/222586035.pdf,,,core
161399727,2018-01-01T00:00:00,"The collection, analysis, and interpretation of digital data has become an important factor for the provision of services. However, there is a lack of methodologies for using data analytics systematically in an end-to-end pro-cess for designing services. Therefore, in this paper, we develop a conceptual approach covering the innovation funnel from idea generation to market deployment. In particular, we describe how qualitative approaches alternate with quantitative approaches along the innovation process. We pay special attention to the design of data-driven value propositions including the analysis and modeling of the customer needs, a phase in which the concept of hidden needs and pains is applied. To conclude, we propose the development of a tool to support and industrialize the approach discussed in this paper",End-to-end methodological approach for the data-driven design of customer-centered digital services,10.1007/978-3-030-00713-3_16,,'Springer Science and Business Media LLC',,core
211161610,2019-01-01T00:00:00,"Designing auction parameters for online industrial auctions is a complex problem due to highly heterogeneous items. Currently, online auctioneers\u3cbr/\u3erely heavily on their experts in auction design. In this paper, we propose a data driven auction design framework that seamlessly combines prediction models and knowledge from experts into an optimization model. We show the proposed data driven approach improves upon the design from the experts for starting prices and display positions of items",Data driven design for online industrial auctions,,,,,core
334870329,2019-10-11T00:00:00,"During the production, distribution, and consumption of energy, a large
quantity of data is generated. For efficiently using of energy resources other
supplementary data such as building information, weather, and environmental
data etc. are also collected and used. All these energy data and relevant data
is published as linked data in order to enhance the reusability of data and
maximization of energy management services capability. However, the quality of
this linked data is questionable because of wear and tears of sensors,
unreliable communication channels, and highly diversification of data sources.
The provision of high-quality energy management services requires high quality
linked data, which reduces billing cost and improve the quality of the living
environment. Assessment and improvement methodologies for the quality of data
along with linked data needs to process very diverse data from highly diverse
data sources. Microservices based data-driven architecture has great
significance to processes highly diverse linked data with modularity,
scalability, and reliability. This paper proposed microservices based
architecture along with domain data and metadata ontologies to enhance and
assess energy-related linked data quality","Microservices based Linked Data Quality Model for Buildings Energy
  Management Services",,http://arxiv.org/abs/1910.06115,,,core
186297265,2019-06-18T00:00:00,"A key challenge in metasurface design is the development of algorithms that
can effectively and efficiently produce high performance devices. Design
methods based on iterative optimization can push the performance limits of
metasurfaces, but they require extensive computational resources that limit
their implementation to small numbers of microscale devices. We show that
generative neural networks can train from images of periodic,
topology-optimized metagratings to produce high-efficiency, topologically
complex devices operating over a broad range of deflection angles and
wavelengths. Further iterative optimization of these designs yields devices
with enhanced robustness and efficiencies, and these devices can be utilized as
additional training data for network refinement. In this manner, generative
networks can be trained, with a onetime computation cost, and used as a design
tool to facilitate the production of near-optimal, topologically-complex device
designs. We envision that such data-driven design methodologies can apply to
other physical sciences domains that require the design of functional elements
operating across a wide parameter space.Comment: 15 pages, 5 figure","Freeform Diffractive Metagrating Design Based on Generative Adversarial
  Networks",10.1021/acsnano.9b02371,http://arxiv.org/abs/1811.12436,'American Chemical Society (ACS)',,core
200610413,2018-11-27T00:00:00Z,"The
surface oxygen vacancy formation energy (<i>E</i><sub>Ovac</sub>) is an important parameter in determining the catalytic
activity of metal oxides. Estimating these energies can therefore
lead to data-driven design of promising catalyst candidates. In the
present study, we determine <i>E</i><sub>Ovac</sub> for
various insulating and semiconducting oxides. Statistical investigations
indicate that the band gap, bulk formation energy, and electron affinity
are factors that strongly influence <i>E</i><sub>Ovac</sub>. Electrons enter defect states after O desorption, and these states
can be in the valence band, mid-gap, or in the conduction band. Subsequent
adsorption of O<sub>2</sub>, NO, CO, CO<sub>2</sub>, and H<sub>2</sub> molecules on an O-deficient surface is also investigated. These
molecules become preferentially adsorbed at the defect sites, and <i>E</i><sub>Ovac</sub> is identified as the dominant factor that
determines the adsorption mode as well as a descriptor that shows
good correlation with the adsorption energy","Density Functional Theory Calculations of Oxygen Vacancy
Formation and Subsequent Molecular Adsorption on Oxide Surfaces",10.1021/acs.jpcc.8b11279.s001,,,,core
186332750,2019-04-12T00:00:00,This paper explores the developing co-creative relationships that arise through integrating digital making and data-driven processes as inspiration within collaborative distributed networks of design and making. It draws upon a year-long case study of landscape sound digital pattern design with a group of textile practitioners from across Scotland. The aim is to understand how these collective ‘hybrid ways of making’ between digital data-driven design and analogue maker impacts the overall democratisation of textile design and manufacturing and influences the makers’ practice,Aural Textiles. Hybrid practices for data-driven design,,https://core.ac.uk/download/186332750.pdf,,,core
160246237,2018-01-01T00:00:00,"Mathematical modeling is a key process to describe the behavior of biological networks. One of the most difficult challenges is to build models that allow quantitative predictions of the cells' states along time. Recently, this issue started to be tackled through novel in silico approaches, such as the reconstruction of dynamic models, the use of phenotype prediction methods, and pathway design via efficient strain optimization algorithms. The use of dynamic models, which include detailed kinetic information of the biological systems, potentially increases the scope of the applications and the accuracy of the phenotype predictions. New efforts in metabolic engineering aim at bridging the gap between this approach and other different paradigms of mathematical modeling, as constraint-based approaches. These strategies take advantage of the best features of each method, and deal with the most remarkable limitationthe lack of available experimental informationwhich affects the accuracy and feasibility of solutions. Parameter estimation helps to solve this problem, but adding more computational cost to the overall process. Moreover, the existing approaches include limitations such as their scalability, flexibility, convergence time of the simulations, among others. The aim is to establish a trade-off between the size of the model and the level of accuracy of the solutions. In this work, we review the state of the art of dynamic modeling and related methods used for metabolic engineering applications, including approaches based on hybrid modeling. We describe approaches developed to undertake issues regarding the mathematical formulation and the underlying optimization algorithms, and that address the phenotype prediction by including available kinetic rate laws of metabolic processes. Then, we discuss how these have been used and combined as the basis to build computational strain optimization methods for metabolic engineering purposes, how they lead to bi-level schemes that can be used in the industry, including a consideration of their limitations.This project has received funding from the European Union’s Horizon 2020 research and innovation program under grant agreement No 675585 (Marie-Curie Innovative Training Network SyMBioSys - Systematic Models for Biological Systems Engineering, the research and innovation program under grant No 686070 (DD-DeCaF - Bioinformatics Services for Data-Driven Design of Cell Factories and Communities) and the ERA-IB-2 network under the scope of the project DYNAMICS - Analysis and optimization of industrial microorganisms under dynamic process conditions (ERA-IB-2/0001/2014). This study was supported by the Portuguese Foundation for Science and Technology (FCT) under the scope of the strategic funding of UID/BIO/04469/2013 unit, and COMPETE 2020 (POCI-01-0145-FEDER-006684) and BioTecNorte operation (NORTE-01-0145-FEDER-000004) funded by the European Regional Development Fund under the scope of Norte2020 Programa Operacional Regional do Norte. First author, OK, is a Marie-Curie Early Stage Researcher at SilicoLife Lda. (Portugal).info:eu-repo/semantics/publishedVersio",A review of dynamic modeling approaches and their application in computational strain optimization for metabolic engineering,10.3389/fmicb.2018.01690,,'Frontiers Media SA',"[{'title': 'Frontiers in Microbiology', 'identifiers': ['issn:1664-302X', '1664-302x']}]",core
228082000,2019-09-05T00:00:00,"Background: As genome sequencing projects grow rapidly, the diversity of organisms with recently assembled
genome sequences peaks at an unprecedented scale, thereby highlighting the need to make gene functional
annotations fast and efficient. However, the (high) quality of such annotations must be guaranteed, as this is the
first indicator of the genomic potential of every organism.
Automatic procedures help accelerating the annotation process, though decreasing the confidence and reliability of
the outcomes. Manually curating a genome-wide annotation of genes, enzymes and transporter proteins function is
a highly time-consuming, tedious and impractical task, even for the most proficient curator. Hence, a semi-automated
procedure, which balances the two approaches, will increase the reliability of the annotation, while speeding up the
process. In fact, a prior analysis of the annotation algorithm may leverage its performance, by manipulating its
parameters, hastening the downstream processing and the manual curation of assigning functions to genes
encoding proteins.
Results: Here SamPler, a novel strategy to select parameters for gene functional annotation routines is presented. This
semi-automated method is based on the manual curation of a randomly selected set of genes/proteins. Then, in a
multi-dimensional array, this sample is used to assess the automatic annotations for all possible combinations of the
algorithm’s parameters. These assessments allow creating an array of confusion matrices, for which several metrics are
calculated (accuracy, precision and negative predictive value) and used to reach optimal values for the parameters.
Conclusions: The potential of this methodology is demonstrated with four genome functional annotations performed
in merlin, an in-house user-friendly computational framework for genome-scale metabolic annotation and model
reconstruction. For that, SamPler was implemented as a new plugin for the merlin tool.This study was supported by the Portuguese Foundation for Science and
Technology (FCT) under the scope of the strategic funding of [UID/BIO/
04469] unit and COMPETE 2020 [POCI-01-0145-FEDER-006684] and
BioTecNorte operation [NORTE-01-0145-FEDER-000004] funded by the
European Regional Development Fund under the scope of Norte2020 -
Programa Operacional Regional do Norte. The authors thank the project DDDeCaF - Bioinformatics Services for Data-Driven Design of Cell Factories and Communities, Ref. H2020-LEIT-BIO-2015-1 686070–1, funded by the European Commission.info:eu-repo/semantics/publishedVersio",SamPler - a novel method for selecting parameters for gene functional annotation routines,10.1186/s12859-019-3038-4,,'Springer Science and Business Media LLC',"[{'title': 'BMC Bioinformatics', 'identifiers': ['1471-2105', 'issn:1471-2105']}]",core
291792646,2017-12,"Millions of mobile apps are used by billions of users every day. Although the design of these apps play an important role in their adoption, the design process still remains complex and time intensive. At the same time, existing apps embody multiple solutions to numerous design problems faced by app developers. How do we make this design knowledge embedded in existing apps accessible to designers? And how can it help simplify the app design process?

This dissertation introduces interaction mining, a technique to capture the designs of mobile apps in a way that supports data-driven design applications. It presents systems that implement interaction mining for Android apps without requiring any access to their source code making it possible to design mine apps at an unprecedented scale. It presents Rico, the largest publicly available mobile app design repository to date. It discusses how such repositories created using interaction mining can be used to train models that enable applications such as keyword and example-based search interactions for mobile screens and user flows. It also presents zero-integration performance testing (ZIPT), a novel technique for testing app designs. It demonstrates how ZIPT can be used to help designers understand which examples to draw from in the early stages of the app design process and perform comparative testing at scale with low cost and effort in the later stages of the process",Interaction mining mobile apps,,,,,core
286266264,2019-12-26,"We show that a neural network whose output is obtained as the difference of the outputs of two feedforward networks with exponential activation function in the hidden layer and logarithmic activation function in the output node (LSE networks) is a smooth universal approximator of continuous functions over convex, compact sets. By using a logarithmic transform, this class of networks maps to a family of subtraction-free ratios of generalized posynomials, which we also show to be universal approximators of positive functions over log-convex, compact subsets of the positive orthant. The main advantage of Difference-LSE networks with respect to classical feedforward neural networks is that, after a standard training phase, they provide surrogate models for design that possess a specific difference-of-convex-functions form, which makes them optimizable via relatively efficient numerical methods. In particular, by adapting an existing difference-of-convex algorithm to these models, we obtain an algorithm for performing effective optimization-based design. We illustrate the proposed approach by applying it to data-driven design of a diet for a patient with type-2 diabetes",A Universal Approximation Result for Difference of log-sum-exp Neural Networks,,,HAL CCSD,,core
295501244,2018-09-01T00:00:00,"Data-driven design processes have been increasingly implemented in the training of new generations of architects and have been focused on BIM (Building Information Modeling) both to create and manage building documentation and in parametric design tools to generate complex geometries. At the same time the ability to collect data across the building life-cycle is exponentially growing but, although this digital data management could improve the design quality of buildings in terms of operational performance and user experience, there is still a lack of architects trained in integration and data analytics. 'The Building Data Library', an online platform of analytical 3D models of buildings, tries to solve this issue by applying Business Intelligence (BI) and Data Science (DS) tools to promote digital data management in order to make informed decisions beyond our own expertise and intuition. These kinds of databases will play a paramount role in a near future where Machine Learning (ML) will lead to the automation of many design processes",BI & Data Science for architects. ‘The Building Data Library’: an online platform to share and analyse building data,10.14198/EURAU18alicante,,'Universidad de Alicante Servicio de Publicaciones',,core
304158753,2018-07-16T00:00:00,"The aim of this research is to introduce a novel structural design process that allows architects and engineers to extend their typical design space horizon and thereby promoting the idea of creativity in structural design. The theoretical base of this work builds on the combination of structural form-finding and state-of-the-art machine learning algorithms. In the first step of the process, Combinatorial Equilibrium Modelling (CEM) is used to generate a large variety of spatial networks in equilibrium for given input parameters. In the second step, these networks are clustered and represented in a form-map through the implementation of a Self Organizing Map (SOM) algorithm. In the third step, the solution space is interpreted with the help of a Uniform Manifold Approximation and Projection algorithm (UMAP). This allows gaining important insights in the structure of the solution space. A specific case study is used to illustrate how the infinite equilibrium states of a given topology can be defined and represented by clusters. Furthermore, three classes, related to the non-linear interaction between the input parameters and the form space, are verified and a statement about the entire manifold of the solution space of the case study is made. To conclude, this work presents an innovative approach on how the manifold of a solution space can be grasped with a minimum amount of data and how to operate within the manifold in order to increase the diversity of solutions.ISSN:2518-658",Data-Driven Design: Exploring new Structural Forms using  Machine Learning and Graphic Statics,10.3929/ethz-b-000318167,,International Association for Shell and Spatial Structures (IASS),,core
250405075,2019-11-27T00:00:00,"El proceso de transporte agrícola involucra un sinnúmero de conceptos logísticos representados en una red de distribución, la cual debe ser gestionada con el fin de lograr una optimización global del proceso por medio de una reducción en los costos, disminución de tiempo y/o aumento del nivel de servicio. El presente proyecto desarrolla un modelo de optimización que minimiza los costos asociados al transporte agrícola de banano desde las fincas de la empresa XYZ, ubicadas en la zona bananera, hasta la Sociedad Portuaria de Santa Marta, para su posterior exportación. El proceso actual se lleva a cabo únicamente por medio del uso de camiones con capacidad de 20’ y contenedores tipo 40’ HC reefer, los cuales son asignados a cada finca dependiendo de su demanda total por día. Dicho esto, dentro del  alcance del proyecto se evaluó la posibilidad y rentabilidad de utilizar vehículos y configuraciones de vehículos con mayor capacidad de carga y menor costo de transporte por unidad, por ejemplo contenedores tipo 45’ HC PW reefer y bitrenes, de manera que se redujeran los costos significativamente; sin embargo, para ello fue necesario considerar ciertos aspectos que afectan la decisión final. Uno de estos aspectos, y sin duda el más relevante fue el estado en el que se encuentran las vías por las cuales deberían transitar los vehículos para llegar a las fincas dado que ello representa una limitación que define la posibilidad de ingresar o no a la finca directamente, de manera que sea innecesario el uso de transporte complementario.
El modelo propuesto muestra un mejor panorama en términos de costos, dado que se evidencia una reducción del 6% en comparación con el modelo inicial,  dadas las consideraciones  realizadas, reduciendo así el número de viajes a realizar y el costo por unidad transportada.The agricultural transport process involves several logistic concepts represented in a distribution network, which must be managed in order to achieve a global optimization of the process through a reduction in costs, reduction of time and / or increase of the service level. The present project develops an optimization model that minimizes the costs associated with the agricultural transport of bananas from the XYZ company farms, located in the Zona Bananera, to Sociedad Portuaria de Santa Marta, for subsequent export. The current process is carried out in the case of the means of using trucks with a capacity of 20 'and 40' HC reefer containers, which are assigned to each farm according to their total demand per day. That said, within the scope of the project, the possibility and profitability of using vehicles and vehicle configurations with greater load capacity and lower transport cost per unit, for example 45 'HC PW reefer containers and road trains, were evaluated, so that reduce costs significantly; however, it was necessary to consider certain aspects that affect the final decision. One of these aspects, and undoubtedly the most relevant was the state in which the roads through which vehicles travel to get to the farms are located since this represents a limitation that defines the possibility of entering or not entering the farm directly, so that the use of complementary transport is unnecessary. 
The proposed model shows a better outlook in terms of costs, given that there is a 6% reduction compared to the initial model, given the conclusions made, thus reducing the number of trips to be made and the cost per unit transported",Data-driven design for the interaction of an agricultural transport network planning with the selection of transport equipment and operations planning,,,"Barranquilla, Universidad del Norte, 2019",,core
333535180,2019-11-22T00:00:00,"This paper studies the data-driven design of variable speed limits for
highways subject to uncertainty, including unknown driver actions as well as
vehicle arrivals and departures. With accessibility to sample measurements of
the uncertain variables, we aim to find the set of speed limits that prevents
traffic congestion and an optimum vehicle throughput with high probability.
This results into the formulation of a stochastic optimization problem (P),
which is intractable due to the unknown distribution of the uncertainty
variables. By developing a distributionally robust optimization framework, we
present an equivalent and yet tractable reformulation of (P). Further, we
propose an efficient algorithm that provides suboptimal data-driven solutions
and guarantees congestion-free conditions with high probability. We employ the
resulting control method on a traffic simulator to illustrate the effectiveness
of this approach.Comment: Submitted to TAC, a prelimineary version appeared in arxiv:1810.11385
  or DOI: 10.23919/ECC.2019.879602","Data-driven Variable Speed Limit Design with Performance Guarantees for
  Highways",,http://arxiv.org/abs/1911.10184,,,core
377533595,2019-01-01T00:00:00,,Learning from humans how to grasp: a data-driven architecture for autonomous grasping with anthropomorphic soft hands,10.1109/LRA.2019.2896485,,'Institute of Electrical and Electronics Engineers (IEEE)',,core
211520347,2017-10-02T00:00:00,"With the advances in three-dimensional (3D) scanning and sensing technologies, massive human-related data are now available and create many applications in data-driven design. Similarity identification is one of basic problems in data-driven design and can facilitate many engineering applications and product paradigm such as quality control and mass customization. Therefore, reusing information can create unprecedented opportunities in advancing the theory, method, and practice of product design. To enable information reuse, different models have to be aligned so that their similarity can be identified. This alignment is commonly known as the global registration that finds an optimal rigid transformation to align two 3D shapes (scene and model) without any assumptions on their initial positions. The Super 4-Points Congruent Sets (S4PCS) is a popular algorithm used for this shape registration. While S4PCS performs the registration using a set of 4 coplanar points, we find that incorporating the volumetric information of the models can improve the robustness and the efficiency of the algorithm, which are particularly important for mass customization. In this paper, we propose a novel algorithm, Volumetric 4PCS (V4PCS), to extend the 4 coplanar points to non-coplanar ones for global registration, and theoretically demonstrate the computational complexity is significantly reduced. Experimental tests are conducted on a number of models such as tooth aligner and hearing aid to compare with S4PCS. The experimental results show that the proposed V4PCS can achieve a maximum of 20 times speedup and can successfully compute the valid transformation with very limited number of sample points. An application of the proposed method in mass customization is also investigated",V4PCS: Volumetric 4PCS Algorithm for Global Registration,10.1115/1.4037477,https://core.ac.uk/download/211520347.pdf,'ASME International',,core
200857639,2019-05-01T00:00:00,"Water pump control, prevalent in various industrial plants, such as wastewater treatment and steam generator facilities, plays a significant role in maintaining economic efficiency and stable plant operation. Due to its slow dynamics, strong nonlinearity, and various disturbances, it is also widely studied as a typical benchmark problem in process control. The current control strategies can be categorized into two aspects: one branch resorts to model-based design and the other to data-driven design. To merge the merits and overcome the deficiencies of each paradigm, this paper proposes a hybrid data-driven and model-assisted control strategy, namely modified active disturbance rejection control (MADRC). The model information regarding water dynamics is incorporated into an extended state observer (ESO), which is used to estimate and mitigate the limitations of slow dynamics, strong nonlinearity, and various disturbances by analyzing the real-time data. The tuning formula is given in terms of the desired closed-loop performance. It is shown that MADRC is able to produce a satisfactory control performance while maintaining a low sensitivity to the measurement noise under general parametric setting conditions. The simulation results verify the clear superiority of MADRC over the proportional-integral (PI) controller and the conventional ADRC, and the results also evidence its noise reduction effects. The experimental results agree well with the simulation results based on a water tank setup. The proposed MADRC approach is able to improve the control performance while reducing the actuator fluctuation. The results presented in this paper offer a promising methodology for the water control loops widely used in the water industry",Water Pump Control: A Hybrid Data-Driven and Model-Assisted Active Disturbance Rejection Approach,10.3390/w11051066,,'MDPI AG',"[{'title': 'Water', 'identifiers': ['issn:2073-4441', '2073-4441']}]",core
227335408,2019-08-01T00:00:00,"Now the design of energy system requires needowners to play an active role by using advanced technical solutions to improve their responsiveness, process adaptability and empower end-users. Although need-owners via Demand Response (DR) has gain sufficient strategic improvement in energy management recently, there are still some fundamental impediments to achieve a trade-off between demand flexibility scheduling and dispatch. To find a solution to the challenge, the paper introduces the steps of an agile development process for energy systems, refers to a co-creation of solutions based on co-existing technologies and iterative development, where needowners requirements and solutions evolve through collaboration between cross-functional intelligent agents. The proof-of-the-concept is investigated by agent-oriented simulation for a generic low-voltage network of the Netherlands, which encounters transformer congestion. Simulation results reveal a significant reduction in congestion over a year while confirming expected levels of performance",Agile development process and user-centric data driven design for an integrated energy system,10.1109/eeeic.2019.8783448,,'Institute of Electrical and Electronics Engineers (IEEE)',,core
76948417,2017-02-09T00:00:00,"A shared visual workspace and video in addition to voice are two functionalities or technologies which this thesis focuses on. What is clarified in this work is how these influence remote collaboration and conversational grounding in particular — where grounding refers to the pro-active process of seeking, creating and maintaining the shared meanings needed for conversational partners to communicate effectively. 



Additionally, this thesis clarifies how to support non-collocated synchronous mediated-collaboration around intelligence analytic tasks — away from traditional tasks that involve the identification or manipulation of physical objects which previous studies appear to favour.



This research is guided by these three primary research questions:



—RQ1) How can we expose aspects of conversational grounding in mediated communication involving different combinations of a video (showing a remote participant’s head and shoulder, and hands and work-area) and a fully shared visual workspace in addition to voice?



—RQ2) In relation to the negotiated process of grounding, how can we explain what is happening when parties are collaborating on an intelligence task using a fully shared visual workspace?



—RQ3) How can we design better fully shared visual workspace systems to support remote collaborative intelligence analysis tasks? 



Study1 — reported in Chapter 5, is an exploratory research which also serves as a groundwork for Study2. The findings there led to the formulation of more focused hypotheses later investigated in Study2. Further, the most significant contribution of the Study1 was the coding schema constructed for analysing the negotiation of common ground.



Chapter 6, 7, 8 make up Study2. A human-participant experiment was conducted using a 2 x 2 factorial between-subjects design with 2-person teams and four media manipulations namely: video, no video, shared visual workspace and no shared visual workspace. Conversational grounding effort is operationalized as the number of repair-episodes per min (that is repair rate). Results here indicate that teams using shared visual workspace have a lower repair rate than those teams with no access to shared visual workspace. This result is statistically significant.



Although teams using video equally had a lower repair rate than those teams not using video, this result was not statistically significant. This is consistent with prior research which found that a video showing a person’s face and shoulders is not terribly important in collaborative context. 



Results of another investigation demonstrate that regardless of the media condition, teams generally have a lower repair rate over time as the task progressed — this result was statistically significantly positive.



Additionally, assessments of a questionnaire item measuring improvements of mutual agreements and shared understanding over time, showed a statistically significantly difference between the shared visual workspace group and the no shared visual workspace group, as was the participant’s rating of the effectiveness of the medium for information sharing.



Results of a qualitative thematic analysis in Chapter 7 helps explain these statistical results and more. A conceptual process model of conversational grounding in shared visual workspace-mediated interaction is presented in Chapter 8.



The model also summarises the research findings. The discourse there offer useful implications and guidelines for moving beyond current theories and models of the negotiation of common ground. Equally, practical design recommendations for the design of shared visual workspaces are also discussed there.



Chapter 9, 10 reviews the research questions and considers how the research that has been presented addresses them, followed by a discussion of the contributions of the thesis, future work and conclusion.



Overall, this thesis delivers the following contributions:



—1) It advances existing knowledge silos and studies on media effects on conversational grounding — one of the ways it achieves that is by delivering a conceptual model framework for understanding conversational grounding processes in real-time remote collaborative intelligence analysis.



—2) It delivers a new coding schema for the analysis of the negotiation of conversational grounding in remote work. 



—3) It offers four data-driven design recommendations for good practical design of shared visual workspace groupware that better support more natural communicative nuances",Analyzing non-collocated synchronous shared visual workspace-mediated interaction and effects on conversational grounding. A study on collaborative intelligence analysis,,https://core.ac.uk/download/76948417.pdf,,,core
348700754,2019-01-01T00:00:00,© 2019 for this paper by its authors. Use permitted under the Creative Commons License Attribution 4.0 International (CC BY 4.0): https://creativecommons.org/licenses/by/4.0/.Final Published versio,Human and data-driven design fictions: : Entering the near-future zone,,https://core.ac.uk/download/348700754.pdf,CEUR-WS,"[{'title': 'Information Technology and Nanotechnology', 'identifiers': ['1613-0073', 'issn:1613-0073']}]",core
187164039,2019,"Soft hands are robotic systems that embed compliant elements in their mechanical design. This enables an effective adaptation with the items and the environment, and ultimately, an increase in their grasping performance. These hands come with clear advantages in terms of ease-to-use and robustness if compared with classic rigid hands, when operated by a human. However, their potential for autonomous grasping is still largely unexplored, due to the lack of suitable control strategies. To address this issue, in this letter, we propose an approach to enable soft hands to autonomously grasp objects, starting from the observations of human strategies. A classifier realized through a deep neural network takes as input the visual information on the object to be grasped, and predicts which action a human would perform to achieve the goal. This information is hence used to select one among a set of human-inspired primitives, which define the evolution of the soft hand posture as a combination of anticipatory action and touch-based reactive grasp. The architecture is completed by the hardware component, which consists of an RGB camera to look at the scene, a 7-DoF manipulator, and a soft hand. The latter is equipped with inertial measurement units at the fingernails for detecting contact with the object. We extensively tested the propose",Learning from humans how to grasp: a data-driven architecture for autonomous grasping with anthropomorphic soft hands,10.1109/LRA.2019.2896485,https://core.ac.uk/download/pdf/187164039.pdf,'Institute of Electrical and Electronics Engineers (IEEE)',,core
200538086,2019-01-26T04:55:39Z,"<p>Data driven design framework, outlining key considerations for game design form a pedagogical perspective  </p",DS6.UNDERSTANDING PEDAGOGICAL DESIGN REQUIREMENTS AND ITERATIVE EVALUATION (TEACHERS),10.5281/zenodo.2549542,,,,core
200814988,2019-03-21T00:00:00,"We propose a data-driven design method of perfect-reconstruction filterbank
(PRFB) for sound-source enhancement (SSE) based on deep neural network (DNN).
DNNs have been used to estimate a time-frequency (T-F) mask in the short-time
Fourier transform (STFT) domain. Their training is more stable when a simple
cost function as mean-squared error (MSE) is utilized comparing to some
advanced cost such as objective sound quality assessments. However, such a
simple cost function inherits strong assumptions on the statistics of the
target and/or noise which is often not satisfied, and the mismatch of
assumption results in degraded performance. In this paper, we propose to design
the frequency scale of PRFB from training data so that the assumption on MSE is
satisfied. For designing the frequency scale, the warped filterbank frame
(WFBF) is considered as PRFB. The frequency characteristic of learned WFBF was
in between STFT and the wavelet transform, and its effectiveness was confirmed
by comparison with a standard STFT-based DNN whose input feature is compressed
into the mel scale.Comment: 5 pages, to appear in IEEE ICASSP 2019 (Paper Code: AASP-P8.8,
  Session: Spatial Audio, Audio Enhancement and Bandwidth Extension","Data-driven design of perfect reconstruction filterbank for DNN-based
  sound source enhancement",,http://arxiv.org/abs/1903.08876,,,core
280589357,2017,,Special Issue: Data-Driven Design (D3),10.1115/1.4037943,http://mechanicaldesign.asmedigitalcollection.asme.org/data/journals/jmdedb/936524/md_139_11_110301.pdf,ASME International,,core
288846116,2019-07-01T00:00:00,"Data-driven design approaches based on deep learning have been introduced in nanophotonics to reduce time-consuming iterative simulations, which have been a major challenge. Here, we report the first use of conditional deep convolutional generative adversarial networks to design nanophotonic antennae that are not constrained to predefined shapes. For given input reflection spectra, the network generates desirable designs in the form of images; this allows suggestions of new structures that cannot be represented by structural parameters. Simulation results obtained from the generated designs agree well with the input reflection spectrum. This method opens new avenues toward the development of nanophotonics by providing a fast and convenient approach to the design of complex nanophotonic structures that have desired optical properties.11Ysciescopu",Designing nanophotonic structures using conditional deep convolutional generative adversarial networks,10.1515/nanoph-2019-0117,https://core.ac.uk/download/288846116.pdf,'Walter de Gruyter GmbH',"[{'title': 'Nanophotonics', 'identifiers': ['2192-8606', 'issn:2192-8606']}]",core
225537554,2019-04-01T07:00:00,"By the end of 2017, more than fifteen thousand homeless families with over twenty-three thousand children lived in shelters in New York City (Coalition for the homeless, Facts About Homelessness). Receiving education in a school, a daily activity for school age children, can easily become an unachievable thing for homeless children. Though many programs and acts are carried out to help these children, their educational situation is still severe.
Noticing the circumstance that homeless children are facing, I’m interested in the role that architecture can play in responding to homeless children’s educational concerns. When looking at the schools with high percentage of homeless children, it’s notable that most of these schools have family shelters nearby. Considering this as a point of departure, this thesis seeks to address the challenges of providing a quality education for homeless children broadening its architectural scope to the surrounding community.
In terms of the social and technical complexity of school design for homeless children, my inquiry is applying an evidence-based and data- driven design method to school design. The data relevant to this thesis will include social data on homeless children’s education concerns and technical data on building environment. Led by the collected data and the hypotheses based on evidence, the school design proposal aims at discovering opportunities to improve the quality of education and retain homeless children in school. Meanwhile, the process of the school design proposal will be complied into a textual and graphic documentation, which can serve as a design methodology reference for designers, architects and students",A School Design: for homeless children in NYC,,https://core.ac.uk/download/225537554.pdf,SURFACE at Syracuse University,,core
149300676,2018-01-15T08:52:49Z,"<div>Pentaho Data Integration represents a powerful tool that delivers means of extraction,</div><div>transformation and data load using an innovative, metadata-driven approach [20]. Because it</div><div>offers an intuitive, graphical, drag and drop design environment, and a highly scalable,</div><div>standards-based architecture, Pentaho Data Integration represents a reliable and cost effective</div><div>choice for organizations over traditional, proprietary ETL or data integration tools.</div><div><div>Pentaho Data Integration has implemented a metadata-driven approach where you</div><div>only specify the data you want integrated, but you do not specify the way you want it done.</div><div>One of the most important advantages of Pentaho is that one can create complex</div><div>transformations and jobs in a graphical, drag-and-drop environment without having to create</div><div>proprietary custom code that will work only with some proprietary application</div></div",BRAIN Journal-A PROPOSED DATA DRIVEN ARCHITECTURE FOR CARDIOLOGY NETWORK APPLICATION-Figure 3. Data Integration Sample,10.6084/m9.figshare.5787210.v1,,,,core
304616748,2019-01-01T00:00:00,,Data-Driven Design and Operation of Offshore Wind Structures,,,International Society of Offshore & Polar Engineers,,core
287550973,2019-05-31T00:00:00,,Aural Textiles. Hybrid practices for data-driven design.,10.1080/14606925.2019.1594982,,'Informa UK Limited',,core
429523675,2019-05-18T00:00:00,"This paper presents a new workflow to optimize a fixed shading device to reduce thermal loads so that performance and aesthetic can be balanced while exploring various shading forms and typologies during any stage of design. The south wall of a prototypical mid-rise office building zone per ASHRAE 189.1 criteria in Albuquerque, New Mexico is studied by extracting annual hourly heating and cooling data generated by Energy Plus. This new workflow is tested against other existing methods of shading device design in terms of performance and aesthetics. The workflow presented in this paper demonstrates the optimization of fixed shading devices for cooling and heating loads without limiting aesthetic options or the shading device typology at the beginning of the process. This workflow produces iterations that perform similarly in terms of energy savings so that a designer can select a shading device based on other criteria such as aesthetic concerns or constructability issues. The user can move between different shading typologies and add their own creative, artistic interpretations, while not being required to run many simulations after each design change. This paper demonstrates a process that is more in-line with the building design process. Foundational works in the field of other shading device design methods are included to provide a point of comparison between existing practice and the proposed workflow",Balancing Performance and Aesthetic:: Data- Driven Design for Fixed Shading Devices,,https://core.ac.uk/download/429523675.pdf,Architectural Research Centers Consortium,,core
231816947,2019-01-01T00:00:00,"A design space is the space of all potential design candidates. While the design space can be of any kind, this work focuses on exploring geometric design spaces, where geometric parameters are used to represent designs and will largely affect a given design's functionality or performance (e.g., airfoil, hull, and car body designs). By exploring the design space, we evaluate different design choices and look for desired solutions. However, a design space may have unnecessarily high dimensionality and implicit boundaries, which makes it difficult to explore. Also, if we synthesize new designs by randomly sampling design variables in the high-dimensional design space, there is high chance that the designs are not feasible, as there is correlation between feasible design variables. This dissertation introduces ways of capturing a compact representation (which we call a latent space) that describes the variability of designs, so that we can synthesize designs and explore design options using this compact representation instead of the original high-dimensional design variables. The main research question answered by this dissertation is: how does one effectively learn this compact representation from data and efficiently explore this latent space so that we can quickly find desired design solutions? The word ""quickly"" here means to eliminate or reduce the iterative ideation, prototyping, and evaluation steps in a conventional design process. This also reduces human intervention, and hence facilitates design automation.

This work bridges the gap between machine learning and geometric design in engineering. It contributes new pieces of knowledge within two topics: design space exploration and design synthesis. Specifically, the main contributions are:

1. A method for measuring the intrinsic complexity of a design space based on design data manifolds.

2. Machine learning models that incorporate prior knowledge from the domain of design to improve latent space exploration and design synthesis quality.

3. New design space exploration tools that expand the design space and search for desired designs in an unbounded space.

4. Geometrical design space benchmarks with controllable complexity for testing data-driven design space exploration and design synthesis",Data-Driven Geometric Design Space Exploration and Design Synthesis,10.13016/qwkq-qmtw,https://core.ac.uk/download/231816947.pdf,'Wiley',,core
195279297,2018-11-01T16:02:57,,Data-Driven Design of Ecofriendly Thermoelectric High-Entropy Sulfides,10.1021/acs.inorgchem.8b02379,,'American Chemical Society (ACS)',"[{'title': 'Inorganic Chemistry', 'identifiers': ['issn:0020-1669', '0020-1669']}]",core
265730120,2014,Hindawi Limited,Metric Learning Method Aided Data-Driven Design of Fault Detection Systems,10.1155/2014/974758,http://doi.org/10.1155/2014/974758,,,core
274560556,2016,MDPI AG,Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
224442315,2014-01-01T00:00:00,"eScholarship, University of California",A Story of Distributed Leadership at a Turnaround High School: Identifying Settings and Practices,,,"Urban high schools seldom achieve turnaround status. Many variables have been studied in relation to effective school turnaround; however, distributed leadership is a theory of leadership that has seldom been linked in the literature to school turnaround and sustainability. This study investigated the phenomenon of distributed leadership at a southern California urban high school, where indicators revealed that the site achieved turnaround status by moving out of Program Improvement over a ten-year period and by increasing college admission rates, even with multiple principal successions. This study contributes to the field of educational leadership and school improvement by informing how distributed leadership functioned across settings and practices. This unique case study targeted the settings and practices used by multiple stakeholders during the turnaround period. Leadership was characterized by influence and activities, not by roles of site members. Data were collected via in-depth interviews, which were coded by themes of distributed leadership: collegiality, trust, efficacy, autonomy, ownership, collaboration, data-driven design, interaction, teacher talk, emotional support, teacher learning, and a culture of caring. The findings showed that members of a school site took on leadership activities in various settings, influencing one another's' practice. Interview data revealed that teachers, administrators and staff worked in formal and informal settings to influence one another's beliefs and practices. Participants highlighted the importance of conditions that exist when leadership was distributed: ownership, autonomy, trust, and efficacy. These findings suggest that teachers and administrators at urban turnaround schools need to be aware of the differences between formal and informal settings and their effects on distribute leadership practices; by utilizing the unique opportunities each setting offers, learning outcomes for students can be improved and sustained over time",,core
204837393,2016-01-01T00:00:00,'MDPI AG',Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
282275757,2016,MDPI AG,Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
90119356,2016-01-01T00:00:00Z,Hindawi Limited,Management of Uncertainty by Statistical Process Control and a Genetic Tuned Fuzzy System,10.1155/2016/1548986,,"In food industry, bioprocesses like fermentation often are a crucial part of the manufacturing process and decisive for the final product quality. In general, they are characterized by highly nonlinear dynamics and uncertainties that make it difficult to control these processes by the use of traditional control techniques. In this context, fuzzy logic controllers offer quite a straightforward way to control processes that are affected by nonlinear behavior and uncertain process knowledge. However, in order to maintain process safety and product quality it is necessary to specify the controller performance and to tune the controller parameters. In this work, an approach is presented to establish an intelligent control system for oxidoreductive yeast propagation as a representative process biased by the aforementioned uncertainties. The presented approach is based on statistical process control and fuzzy logic feedback control. As the cognitive uncertainty among different experts about the limits that define the control performance as still acceptable may differ a lot, a data-driven design method is performed. Based upon a historic data pool statistical process corridors are derived for the controller inputs control error and change in control error. This approach follows the hypothesis that if the control performance criteria stay within predefined statistical boundaries, the final process state meets the required quality definition. In order to keep the process on its optimal growth trajectory (model based reference trajectory) a fuzzy logic controller is used that alternates the process temperature. Additionally, in order to stay within the process corridors, a genetic algorithm was applied to tune the input and output fuzzy sets of a preliminarily parameterized fuzzy controller. The presented experimental results show that the genetic tuned fuzzy controller is able to keep the process within its allowed limits. The average absolute error to the reference growth trajectory is 5.2 × 106 cells/mL. The controller proves its robustness to keep the process on the desired growth profile","[{'title': None, 'identifiers': ['1607-887x', 'issn:1607-887X', 'issn:1026-0226', '1026-0226']}]",core
245149803,2014-01-01T00:00:00,'Springer Science and Business Media LLC',Data-Driven Design of Fault Diagnosis Systems,10.1007/978-3-658-05807-4,,,,core
477674382,2014-11-06T00:00:00,,Dynamics of Data-Driven Design,10.7480/footprint.8.2,,"Digital technology has introduced in the last decades data-driven representational and generative methodologies based on principles such as parametric definition and algorithmic processing. In this context, the 15th Footprint issue examines the development of data-driven techniques such as digital drawing, modelling, and simulation with respect to their relationship to design.The dynamics between data-driven processes and design, as well as the impact of these processes on artistic and architectural production, is addressed in 5 papers from authors with diverse backgrounds in media studies, art, and architecture. From theoretical explorations discussing cultural swarming techniques and data-driven design representation and materialisation aspects to practical (artistic and architectural) experimentation, this issue indicates the increasing convergence of computational and material systems. Furthermore, it addresses the generation of multiple, emergent results from one and the same computational representation – results that may be realized virtually at the level of design conceptualization, physically at the level of production, and even operationally at the level of artefact or building use where users or the environment contribute to the emergence of multiple physical configurations and outcomes. Data-driven design thereby establishes an unprecedented design to production to operation feedback loop",,core
155590196,2015,iet control theory and applications,Data-driven design of two-degree-of-freedom controllers using reinforcement learning techniques,10.1049/iet-cta.2014.0156,,"Motivated by the successful application for feedback control, this study extends the study of reinforcement learning techniques to the design of two-degree-of-freedom controllers in the data-driven environment. Based on the residual generator based form of Youla parameterisation, all stabilising controllers are first interpreted in the feedback-feedforward situation with a Kalman filter-based residual generator acting as the core part. For the reference tracking problem, further discussions are conducted from the regulatory perspective and using the Q learning, recursive least squares methods and the policy iteration algorithm. The entire design is carried out as a two-stage process that separately achieves the optimal feedback and feedforward controllers. Finally, the effectiveness of the proposed approach is demonstrated with its application in the laboratory continuous stirred tank heater process. ? The Institution of Engineering and Technology 2015.SCI(E)EI0ARTICLEyy@mech.pku.edu.cn71011-1021",,core
231457020,2014-07-11T00:00:00,,Data driven design of an orthogonal wavelet with vanishing moments,,,,,core
251100283,2015-04-01T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',Low-rank approximation-based distributed node-specific signal estimation in a fully-connected wireless sensor network,10.1109/ICASSP.2015.7178489,,"© 2015 IEEE. In this paper, we consider the problem of distributed estimation of node-specific signals in a fully-connected wireless sensor network with multi-sensor nodes. The estimation relies on a data-driven design of a spatial filter, referred to as the generalized eigenvalue decomposition (GEVD)-based multi-channel Wiener filter (MWF). In non-stationary or low-SNR conditions, this GEVD-based MWF has been demonstrated to be more robust than the original MWF due to an inherent GEVD-based low-rank approximation of the sensor signal correlation matrix. In a centralized realization where a fusion center has access to all the nodes' sensor signal observations, the network-wide sensor signal correlation matrix and its low-rank approximation can be directly estimated from the sensor signals. However, in this paper we aim to avoid centralizing the sensor signal observations, in which case this network-wide correlation matrix cannot be estimated. We introduce a distributed algorithm which is able to significantly compress the broadcast signals while still converging to the centralized GEVD-based MWF as if each node would have access to all sensor signal observations.status: publishe","[{'title': None, 'identifiers': ['1520-6149', 'issn:1520-6149']}]",core
102830103,2015-10-24,,INAOE at CLEF 2006: Experiments in Spanish Question Answering,,,"This paper describes the system developed by the Language Technologies Lab at INAOE for the Spanish Question Answering task at CLEF 2006. The presented system is centered in a full data-driven architecture that uses machine learning and text mining techniques to identify the most probable answers to factoid and definition questions respectively. Its major quality is that it mainly relies on the use of lexical information and avoids applying any complex language processing re-source such as named entity classifiers, parsers or ontologies. Experimental results show that the proposed architecture can be a practical solution for monolingual question answering reaching an answer precision as high as 51%. ",,core
103223001,2015-11-04,,Can we beat Hadamard multiplexing? Data driven design and analysis for computational imaging systems,,,"Computational Imaging (CI) systems that exploit opti-cal multiplexing and algorithmic demultiplexing have been shown to improve imaging performance in tasks such as motion deblurring, extended depth of field, light field and hyper-spectral imaging. Design and performance analysis of many of these approaches tend to ignore the role of im-age priors. It is well known that utilizing statistical image priors significantly improves demultiplexing performance. In this paper, we extend the Gaussian Mixture Model as a data-driven image prior (proposed by Mitra et. al [19]) to under-determined linear systems and study compressive CI methods such as light-field and hyper-spectral imaging. Further, we derive a novel algorithm for optimizing multi-plexing matrices that simultaneously accounts for (a) sen-sor noise (b) image priors and (c) CI design constraints. We use our algorithm to design data-optimal multiplexing matrices for a variety of existing CI designs, and we use these matrices to analyze the performance of CI systems as a function of noise level. Our analysis gives new insight into the optimal performance of CI systems, and how this relates to the performance of classical multiplexing designs such as Hadamard matrices. 1",,core
154654446,2014,Hindawi,Metric learning method aided data-driven design of fault detection systems,10.1155/2014/974758,,"Published version of an article in the journal: Mathematical Problems in Engineering. Also available from the publisher at: http://dx.doi.org/10.1155/2014/974758Fault detection is fundamental to many industrial applications. With the development of system complexity, the number of sensors is increasing, which makes traditional fault detection methods lose efficiency. Metric learning is an efficient way to build the relationship between feature vectors with the categories of instances. In this paper, we firstly propose a metric learning-based fault detection framework in fault detection. Meanwhile, a novel feature extraction method based on wavelet transform is used to obtain the feature vector from detection signals. Experiments on Tennessee Eastman (TE) chemical process datasets demonstrate that the proposed method has a better performance when comparing with existing methods, for example, principal component analysis (PCA) and fisher discriminate analysis (FDA). © 2014 Guoyang Yan et al",,core
37025795,2015-01-01T08:00:00,'Sociological Research Online',Mesoscalarity: data polities and designed engagement,,,"The presentation will focus on three concepts for data-driven design which have emerged from research for PetaJakarta.org. We will outline the concept of mesoscalarity as a means to both describe and analyze the integrative approach to \u27big data\u27 (spatio-temporal data mining), \u27big crowdsourcing\u27 (interventive operations within data mining processes), and \u27small data\u27 (community-led data collection efforts). We will elaborate the concept of data polities by considering how design-driven institutional ethnography can locate potentials for organizations of various scales and capacities to reimagine the role of data collection and analysis as a means to enable institutional transformation, collaboration, and adaptation. We will consider how designed engagement enables both the formation and study of data polities while demanding a lithe, adaptive comportment to mesoscalarity and transferability across domains, geographies, and ecologies of practice",,core
76531788,2016,Elsevier,Data-driven design of two degree-of-freedom nonlinear controllers: The D2-IBC approach,10.1016/j.automatica.2016.05.010,,"In this paper, we introduce and discuss the Data-Driven Inversion-Based Control (D2-IBC) method for nonlinear control system design. The method relies on a two degree-of-freedom architecture, with a nonlinear controller and a linear controller running in parallel, and does not require any detailed physical knowledge of the plant to control. Specifically, we use input/output data to synthesize the controller by employing convex optimization tools. We show the effectiveness of the proposed approach on a benchmark simulation example, regarding control of the Duffing system",,core
278350940,2014,Hindawi Limited,Metric Learning Method Aided Data-Driven Design of Fault Detection Systems,10.1155/2014/974758,http://doi.org/10.1155/2014/974758,,,core
192646032,2014,Hindawi Limited,Metric Learning Method Aided Data-Driven Design of Fault Detection Systems,10.1155/2014/974758,https://core.ac.uk/download/pdf/192646032.pdf,,,core
44429965,2014-01-01T00:00:00,'Springer Science and Business Media LLC',Data-driven design of fault diagnosis systems: nonlinear multimode processes,10.1007/978-3-658-05807-4,,"In many industrial applications early detection and diagnosis of abnormal behavior of the plant is of great importance. During the last decades, the complexity of process plants has been drastically increased, which imposes great challenges in development of model-based monitoring approaches and it sometimes becomes unrealistic for modern large-scale processes. The main objective of Adel Haghani Abandan Sari is to study eﬃcient fault diagnosis techniques for complex industrial systems using process historical data and considering the nonlinear behavior of the process. To this end, diﬀerent methods are presented to solve the fault diagnosis problem based on the overall behavior of the process and its dynamics. Moreover, a novel technique is proposed for fault isolation and determination of the root-cause of the faults in the system, based on the fault impacts on the process measurements. Contents Process monitoring Fault diagnosis and fault-tolerant control Data-driven approaches and decision making Target Groups Graduate students and scientists of automatic control and process engineering Engineers in field of process control and monitoring, mechatronic About the Author Adel Haghani Abandan Sari is research assistant with Institute of Automation, university of Rostock. His research interests include data-driven process monitoring and fault-tolerant control with focus on large-scale industrial processes",,core
477983150,2014-11-06T00:00:00,,Dynamics of Data-Driven Design,10.7480/footprint.8.2,,"Digital technology has introduced in the last decades data-driven representational and generative methodologies based on principles such as parametric definition and algorithmic processing. In this context, the 15th Footprint issue examines the development of data-driven techniques such as digital drawing, modelling, and simulation with respect to their relationship to design.The dynamics between data-driven processes and design, as well as the impact of these processes on artistic and architectural production, is addressed in 5 papers from authors with diverse backgrounds in media studies, art, and architecture. From theoretical explorations discussing cultural swarming techniques and data-driven design representation and materialisation aspects to practical (artistic and architectural) experimentation, this issue indicates the increasing convergence of computational and material systems. Furthermore, it addresses the generation of multiple, emergent results from one and the same computational representation – results that may be realized virtually at the level of design conceptualization, physically at the level of production, and even operationally at the level of artefact or building use where users or the environment contribute to the emergence of multiple physical configurations and outcomes. Data-driven design thereby establishes an unprecedented design to production to operation feedback loop.ISBN 978-90-8594-056-2History & Complexit",,core
268414386,2014-11-06T00:00:00,Delft University of Technology,Intersecting Knowledge Fields and Integrating Data-Driven Computational Design en Route to Performance-Oriented and Intensely Local Architectures,10.7480/footprint.8.2.812,https://core.ac.uk/download/268414386.pdf,"This paper discusses research by design efforts in architectural education, focused on developing concepts and methods for the design of performance-oriented and intensely local architectures. The pursued notion of performance foregrounds the interaction between a given architecture and its local setting, with consequences not only for the design product but also for the related processes by which it is generated. Integrated approaches to data-driven computational design serve to generate such designs. The outlined approach shifts the focus of design attention away from the delivery of finite architectural objects and towards an expanded range of architecture-environment interactions that are registered, instrumentalised and modulated over time. This paper examines ongoing efforts in integrating specific architectural goals and approaches, computational data-driven design methods and generative design processes, based on a range of context-specific and often real-time data sets. The work discussed is produced in the context of the Research Centre for Architecture and Tectonics (RCAT) and the Advanced Computational Design Laboratory (ACDL) at the Oslo School of Architecture and Design",,core
150509533,2014-09-11T02:50:58Z,,A Data-Driven Design Evaluation Tool for Handheld Device Soft Keyboards,10.1371/journal.pone.0107070,,"<div><p>Thumb interaction is a primary technique used to operate small handheld devices such as smartphones. Despite the different techniques involved in operating a handheld device compared to a personal computer, the keyboard layouts for both devices are similar. A handheld device keyboard that considers the physical capabilities of the thumb may improve user experience. We developed and applied a design evaluation tool for different geometries of the QWERTY keyboard using a performance evaluation model. The model utilizes previously collected data on thumb motor performance and posture for different tap locations and thumb movement directions. We calculated a performance index (PI<sub>TOT</sub>, 0 is worst and 2 is best) for 663 designs consisting in different combinations of three variables: the keyboard's radius of curvature (R) (mm), orientation (O) (°), and vertical location on the screen (L). The current standard keyboard performed poorly (PI<sub>TOT</sub> = 0.28) compared to other designs considered. Keyboard location (L) contributed to the greatest variability in performance out of the three design variables, suggesting that designers should modify this variable first. Performance was greatest for designs in the middle keyboard location. In addition, having a slightly upward curve (R = −20 mm) and orientated perpendicular to the thumb's long axis (O = −20°) improved performance to PI<sub>TOT</sub> = 1.97. Poorest performances were associated with placement of the keyboard's spacebar in the bottom right corner of the screen (e.g., the worst was for R = 20 mm, O = 40°, L =  Bottom (PI<sub>TOT</sub> = 0.09)). While this evaluation tool can be used in the design process as an ergonomic reference to promote user motor performance, other design variables such as visual access and usability still remain unexplored.</p></div",,core
91717385,2014-11-01T00:00:00Z,Jap Sam Books,Data-Driven Design to Production and Operation,10.7480/footprint.8.2.807,,"<p>Digital technology has introduced in the last decades data-driven representational and generative methodologies based on principles such as parametric definition and algorithmic processing. In this context, the 15th Footprint issue examines the development of data-driven techniques such as digital drawing, modelling, and simulation with respect to their relationship to design. The data propelling these techniques may consist of qualitative or quantitative values and relations that are algorithmically processed. However, the focus here is not on each technique and its respective representational and generative aspects, but on the interface between these techniques and design conceptualisation, materialization, and use.</p","[{'title': None, 'identifiers': ['issn:1875-1490', '1875-1490', '1875-1504', 'issn:1875-1504']}]",core
268414381,2014-11-06T00:00:00,Delft University of Technology,Data-Driven Design to Production and Operation,10.7480/footprint.8.2.807,https://core.ac.uk/download/268414381.pdf,"Digital technology has introduced in the last decades data-driven representational and generative methodologies based on principles such as parametric definition and algorithmic processing. In this context, the 15th Footprint issue examines the development of data-driven techniques such as digital drawing, modelling, and simulation with respect to their relationship to design. The data propelling these techniques may consist of qualitative or quantitative values and relations that are algorithmically processed. However, the focus here is not on each technique and its respective representational and generative aspects, but on the interface between these techniques and design conceptualisation, materialization, and use",,core
33243526,2014-11-30T00:00:00,"TU Delft, Stichting Footprint",Introduction: Data-Driven Design to Production and Operation,,,Architectural Engineering +TechnologyArchitecture and The Built Environmen,,core
33237012,2014-04-22T00:00:00,Bertalanffy Center for the Study of Systems Science (BCSSS),Data-driven architectural production and operation,,,"Data-driven architectural production and operation as explored within Hyperbody rely heavily on system thinking implying that all parts of a system are to be understood in relation to each other. These relations are increasingly established bi-directionally so that data-driven architecture is not only produced (created or designed and fabricated) by digital means but also is incorporating digital, sensing-actuating mechanisms that enable real-time interaction with (natural and artificial) environments and users. Data-driven architectural production and operation exploit, in this context, the generative potential of process-oriented approaches wherein interactions between (human and non-human) agents and their (virtual and physical) environments have emergent properties that enable proliferation of hybrid architectural ecologies.Architectural Engineering +TechnologyArchitecture and The Built Environmen",,core
23936936,2014-02-04,,THE MURASAKI PROJECT: MULTILINGUAL NATURAL LANGUAGE UNDERSTANDING,,,"This paper describes a multilingual data extraction system under development for the Department of Defense (Do[)). The system, called Murasa.ki, processes Spanish and Japanese newspaper articles reporting AIDS disease statistics. Key to Murasaki&apos;s design is its language-independent and domain-independent architecture. The system consists of shared processing modules across the three languages it currently handles (English, Japanese, and Spanish), shared general and domain-specific knowledge bases, and separate data modules for language-specific knowledge such as grammars, lexicons, morphological data and discourse data. This data-driven architecture is crucial to the success of Murasaki as a languageindependent system; extending Murasaki to additional languages can be done for the most part merely by adding new data. Some of the data can be added with user-friendly tools, others by exploiting existing on-line data or by deriving relevant data from corpora. I",,core
272083948,2016,MDPI AG,Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
274741163,2016,MDPI AG,Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
265463060,2014,Hindawi Limited,Metric Learning Method Aided Data-Driven Design of Fault Detection Systems,10.1155/2014/974758,http://doi.org/10.1155/2014/974758,,,core
108713964,2016-10-01,,Soft Sensor Design for Estimation of SOFC Stack Temperatures and Oxygen-to-Carbon Ratio,,,"The life span of a solid oxide fuel cell (SOFC) stack depends on several factors, such as internal stack temperature and temperature gradients as well as the fuel gas oxygen-to-carbon (O/C) ratio. An excessive stack temperature generally accelerates the degradation, while large temperature gradients across the stack cause thermal stress, which leads to delamination. Too low O/C ratio inflicts carbon deposition, which quickly leads to stack breakage. Therefore, monitoring of these variables is of vital importance. Although direct sensing of temperatures within the stack as well as fuel gas composition in fuel stream is feasible, it is not desirable due to increased equipment cost. In this paper a data-driven design of soft sensors for minimal and maximal stack temperatures as well as the O/C ratio is presented. Dynamic and static models for stack temperature are identified from data and their performance is compared. The dynamic model is derived by means of the subspace identification, which results in a causal state-space model. The non-causal static model assumes that a combination of process variables at the stack inlet and outlet describe its internal condition. The estimator of O/C ratio is based on static relationships. The soft sensors are designed in such a way that adding extra inputs to the model yields no further increase in accuracy of the estimates. The empirical data required for modelling were obtained from a SOFC power generating unit. The results show that the reconstruction of all the relevant variables can be accomplished by simple linear regression models",,core
84891478,2014-01-01T00:00:00,'Hindawi Limited',Metric learning method aided data-driven design of fault detection systems,10.1155/2014/974758,,"Fault detection is fundamental to many industrial applications. With the development of system complexity, the number of sensors is increasing, which makes traditional fault detection methods lose efficiency. Metric learning is an efficient way to build the relationship between feature vectors with the categories of instances. In this paper, we firstly propose a metric learning-based fault detection framework in fault detection. Meanwhile, a novel feature extraction method based on wavelet transform is used to obtain the feature vector from detection signals. Experiments on Tennessee Eastman (TE) chemical process datasets demonstrate that the proposed method has a better performance when comparing with existing methods, for example, principal component analysis (PCA) and fisher discriminate analysis (FDA). © 2014 Guoyang Yan et al",,core
100097070,2014-12-01,,Data Driven Fault Detection and Isolation of a Wind Turbine Benchmark,,,"Abstract: This paper investigates data-driven fault detection and isolation (FDI) designs for a wind turbine benchmark problem. The benchmark is described by a SimuLink model, which contains nonlinear lookup tables and unknown wind disturbances. Based on classical FDI design methods, a linearization of the SimuLink model into a standard state-space form and describing the linearization errors as perturbations may be necessary. To avoid these difficult modeling procedures, this paper applies a data-driven design method, which produces FDI filters directly based on the simulated data from the benchmark SimuLink model. The fixed-value sensor faults therein are especially targeted. Moreover, we develop in this paper a new data-driven fault isolation scheme, via exploiting hardware redundancy in a plant. Based on this, a bank of robust data-driven detection filters are designed for the benchmark and implemented in parallel. The simulation results show the effectiveness of the applied data-driven scheme",,core
105959528,2016-09-12,,2013a) ‘Automatically recognizing facial indicators of frustration: a learning-centric analysis,,,"Abstract—Affective and cognitive processes form a rich substrate on which learning plays out. Affective states often influence progress on learning tasks, resulting in positive or negative cycles of affect that impact learning outcomes. Developing a detailed account of the occurrence and timing of cognitive-affective states during learning can inform the design of affective tutorial interventions. In order to advance understanding of learning-centered affect, this paper reports on a study to analyze a video corpus of computer-mediated human tutoring using an automated facial expression recognition tool that detects fine-grained facial movements. The results reveal three significant relationships between facial expression, frustration, and learning: 1) Action Unit 2 (outer brow raise) was negatively correlated with learning gain, 2) Action Unit 4 (brow lowering) was positively correlated with frustration, and 3) Action Unit 14 (mouth dimpling) was positively correlated with both frustration and learning gain. Additionally, early prediction models demonstrated that facial actions during the first five minutes were significantly predictive of frustration and learning at the end of the tutoring session. The results represent a step toward a deeper understanding of learning-centered affective states, which will form the foundation for data-driven design of affective tutoring systems. Keywords—affect; frustration; learning; computer-mediated tutoring; facial expression recognition; facial action units; intensity I",,core
265511201,2014,Hindawi Limited,Metric Learning Method Aided Data-Driven Design of Fault Detection Systems,10.1155/2014/974758,http://doi.org/10.1155/2014/974758,,,core
205387683,2014,Hindawi Limited,Metric Learning Method Aided Data-Driven Design of Fault Detection Systems,10.1155/2014/974758,https://core.ac.uk/download/pdf/205387683.pdf,,,core
234911081,2016,'Elsevier BV',Data-driven design of two degree-of-freedom nonlinear controllers: The D2-IBC approach,10.1016/j.automatica.2016.05.010,,"In this paper, we introduce and discuss the Data-Driven Inversion-Based Control (D2-IBC) method for nonlinear control system design. The method relies on a two degree-of-freedom architecture, with a nonlinear controller and a linear controller running in parallel, and does not require any detailed physical knowledge of the plant to control. Specifically, we use input/output data to synthesize the controller by employing convex optimization tools. We show the effectiveness of the proposed approach on a benchmark simulation example, regarding control of the Duffing system",,core
84072493,2016-01-01T00:00:00,'Elsevier BV',Online estimation of internal stack temperatures in solid oxide fuel cell power generating units,10.1016/j.jpowsour.2016.10.070,,"Thermal stress is one of the main factors affecting the degradation rate of solid oxide fuel cell (SOFC) stacks. In order to mitigate the possibility of fatal thermal stress, stack temperatures and the corresponding thermal gradients need to be continuously controlled during operation. Due to the fact that in future commercial applications the use of temperature sensors embedded within the stack is impractical, the use of estimators appears to be a viable option. In this paper we present an efficient and consistent approach to data-driven design of the estimator for maximum and minimum stack temperatures intended (i) to be of high precision, (ii) to be simple to implement on conventional platforms like programmable logic controllers, and (iii) to maintain reliability in spite of degradation processes. By careful application of subspace identification, supported by physical arguments, we derive a simple estimator structure capable of producing estimates with 3% error irrespective of the evolving stack degradation. The degradation drift is handled without any explicit modelling. The approach is experimentally validated on a 10&nbsp;kW SOFC system",,core
323101520,2016-01-01T00:00:00,University of Liverpool London Campus,Intelligent Data Driven Futures,,https://core.ac.uk/download/323101520.pdf,"As data-driven approaches are introducing and establishing a new set of economic, social and cultural values, we have started to question some of our age old assumptions, conceptions and practices about our built habitat. One of the most profound implications is the transformation of the AEC (Architecture, Engineering and Construction) industry from a document based to an information based business. Both the impact and scale of this transformation will become more dramatic with the increase in global data traﬃc two thirds of which is predicted to move on to cloud computing systems by 2016 (Cisco Global Cloud Index, 2011-2016). This implies the introduction of even more complex and diverse interactions (e.g. through internet of things) between buildings, infrastructures and humans. Such developments have already made significant impact in other industries and are likely to be a step change in how we build and operate in the near future. 
 
“Data” is not new to our industry, however what is new is the amount of data that is currently available to us and our improved capacity to share, capture, measure, compile, process and translate data into meaningful and actionable information. Although the potentials are vast, Architectural/Engineering practice and Construction sector are slow to adopt the data-driven approaches. 
 
The IDDF (Intelligent Data-Driven Design Futures) symposium brought together some of the world-leading thinkers, practitioners and innovators from the Built Environment and Urban Informatics research and practice to explore what “data-integrated” future might hold for our sector. The presentations and discussions challenged our “business as usual” mode of thinking and highlighted diverse insights and perspectives for more agile and adaptive solutions for the future, and in discovering sustainable modes of imagining, creating and working intelligently. With this document we aim to summarize the presentations and discussions, and highlight some of the diverse insights and perspectives we captured from this day-long symposiu",,core
253875660,2016,MDPI AG,Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
103150247,2015-11-03,,Second Level,,,"Part of the Architecture Commons This Article is brought to you for free and open access by the Architecture Program at DigitalCommons@University of Nebraska- Lincoln. It has been accepted for inclusion in Theses from the Architecture Program by an authorized administrator of DigitalCommons@University of Nebraska- Lincoln. Soflin, Zachary S., &quot;Data Driven Architecture &quot; (2012). Theses from the Architecture Program. Paper 134",,core
225891242,2014-01-01T00:00:00,'Hindawi Limited',Metric learning method aided data-driven design of fault detection systems,10.1155/2014/974758,https://core.ac.uk/download/225891242.pdf,"Published version of an article in the journal: Mathematical Problems in Engineering. Also available from the publisher at: http://dx.doi.org/10.1155/2014/974758Fault detection is fundamental to many industrial applications. With the development of system complexity, the number of sensors is increasing, which makes traditional fault detection methods lose efficiency. Metric learning is an efficient way to build the relationship between feature vectors with the categories of instances. In this paper, we firstly propose a metric learning-based fault detection framework in fault detection. Meanwhile, a novel feature extraction method based on wavelet transform is used to obtain the feature vector from detection signals. Experiments on Tennessee Eastman (TE) chemical process datasets demonstrate that the proposed method has a better performance when comparing with existing methods, for example, principal component analysis (PCA) and fisher discriminate analysis (FDA). © 2014 Guoyang Yan et al",,core
291668364,2016-01-01T00:00:00,'Academy of Traumatology',Data visualisation : a handbook for data driven design,,,"xvii, 347 p. : col. ill. ; 26 cm",,core
44526991,2016-01-01T00:00:00,'Springer Science and Business Media LLC',Design of video quality metrics with multi-way data analysis: a data driven approach,10.1007/978-981-10-0269-4,,"This book proposes a data-driven methodology using multi-way data analysis for the design of video-quality metrics. It also enables video- quality metrics to be created using arbitrary features. This data- driven design approach not only requires no detailed knowledge of the human visual system, but also allows a proper consideration of the temporal nature of video using a three-way prediction model, corresponding to the three-way structure of video. Using two simple example metrics, the author demonstrates not only that this purely data- driven approach outperforms state-of-the-art video-quality metrics, which are often optimized for specific properties of the human visual system, but also that multi-way data analysis methods outperform the combination of two-way data analysis methods and temporal pooling. ",,core
23886041,2014-01-31,,A NOVEL APPROACH LIVE STREAMING USING COOL STREAMING,,,"Abstract – A number of commercial peer-to-peer systems for live streaming have been introduced in recent years. The behavior of these popular systems has been extensively studied in several measurement papers. Due to the proprietary nature of these commercial systems, however, these studies have to rely on a “black-box” approach, where packet traces are collected from a single or a limited number of measurement points, to infer various properties of traffic on the control and data planes. Although such studies are useful to compare different systems from end-user’s perspective, it is difficult to intuitively understand the observed properties without fully reverse-engineering the underlying systems. In this paper we describe how cool streaming are used and We emphasize three salient features of this data-driven design: 1) easy to implement, as it does not have to construct and maintain a complex global structure; 2) efficient, as data forwarding is dynamically determined according to data availability while not restricted by specific directions; and 3) robust and resilient, as the partnerships enable adaptive and quick switching among multi-suppliers. Index Terms — IPTV, measurement, peer-to-peer technology, video streaming, live streaming, network architecture. I",,core
48841163,2015-03-19T07:00:00,ISU ReD: Research and eData,Unknown Threat Detection With Honeypot Ensemble Analsyis Using Big Datasecurity Architecture,,https://core.ac.uk/download/48841163.pdf,"The amount of data that is being generated continues to rapidly grow in size and complexity. Frameworks such as Apache Hadoop and Apache Spark are evolving at a rapid rate as organizations are building data driven applications to gain competitive advantages. Data analytics frameworks decomposes our problems to build applications that are more than just inference and can help make predictions as well as prescriptions to problems in real time instead of batch processes.
Information Security is becoming more important to organizations as the Internet and cloud technologies become more integrated with their internal processes. The number of attacks and attack vectors has been increasing steadily over the years. Border defense measures (e.g. Intrusion Detection Systems) are no longer enough to identify and stop attackers.
Data driven information security is not a new approach to solving information security; however there is an increased emphasis on combining heterogeneous sources to
gain a broader view of the problem instead of isolated systems. Stitching together multiple alerts into a cohesive system can increase the number of True Positives.
With the increased concern of unknown insider threats and zero-day attacks, identifying unknown attack vectors becomes more difficult. Previous research has shown that with as little as 10 commands it is possible to identify a masquerade attack against a user\u27s profile.
This thesis is going to look at a data driven information security architecture that relies on both behavioral analysis of SSH profiles and bad actor data collected from an SSH honeypot to identify bad actor attack vectors. Honeypots should collect only data from bad actors; therefore have a high True Positive rate. Using Apache Spark and Apache Hadoop we can create a real time data driven architecture that can collect and analyze new bad actor behaviors from honeypot data and monitor legitimate user accounts to create predictive and prescriptive models. Previously unidentified attack vectors can be cataloged for review",,core
155481047,2014,automatica,Data-driven realizations of kernel and image representations and their   application to fault detection and control system design,10.1016/j.automatica.2014.08.022,,"This paper deals with the data-driven design of observer-based fault detection and control systems. We first introduce the definitions of the data-driven forms of kernel and image representations. It is followed by the study of their identification. In the context of a fault-tolerant architecture, the design of observer-based fault detection, feed-forward and feedback control systems are addressed based on the data-driven realization of the kernel and image representations. Finally, the main results are demonstrated on the laboratory continuous stirred tank heater (CSTH) system. (C) 2014 Elsevier Ltd. All rights reserved.Automation &amp; Control SystemsEngineering, Electrical &amp; ElectronicSCI(E)EI1ARTICLEsteven.ding@uni-due.de; yy@mech.pku.edu.cn; yong.zhang@pku.edu.cn;   linlin.li@uni-due.de102615-26235","[{'title': None, 'identifiers': ['issn:0005-1098', '1873-2836', '0005-1098', 'issn:1873-2836']}]",core
240535816,2016-01-01T00:00:00,'MDPI AG',Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
240370126,2016-01-01T00:00:00,'MDPI AG',Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
274508839,2016,MDPI AG,Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
38536559,2014,Springer International Publishing Switzerland,Data-Driven Method for High Level Rendering Pipeline Construction,10.1007/978-3-319-08201-1_18,,"The paper describes a software methodology for the graphics pipeline extension. It is argued that common modern visualization techniques do not satisfy current visualization software development requirements adequately enough. The proposed approach is based on specialized formal language called visualization algebra. By invoking data-driven design principles inherited from the existing programmable pipeline technology, the technique has a potential to reduce visualization software development costs and build a way for further computer graphics pipeline automation",,core
89227610,2016-06-01T00:00:00Z,MDPI AG,Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,,"Data science or “data-driven research” is a research approach that uses real-life data to gain insight about the behavior of systems. It enables the analysis of small, simple as well as large and more complex systems in order to assess whether they function according to the intended design and as seen in simulation. Data science approaches have been successfully applied to analyze networked interactions in several research areas such as large-scale social networks, advanced business and healthcare processes. Wireless networks can exhibit unpredictable interactions between algorithms from multiple protocol layers, interactions between multiple devices, and hardware specific influences. These interactions can lead to a difference between real-world functioning and design time functioning. Data science methods can help to detect the actual behavior and possibly help to correct it. Data science is increasingly used in wireless research. To support data-driven research in wireless networks, this paper illustrates the step-by-step methodology that has to be applied to extract knowledge from raw data traces. To this end, the paper (i) clarifies when, why and how to use data science in wireless network research; (ii) provides a generic framework for applying data science in wireless networks; (iii) gives an overview of existing research papers that utilized data science approaches in wireless networks; (iv) illustrates the overall knowledge discovery process through an extensive example in which device types are identified based on their traffic patterns; (v) provides the reader the necessary datasets and scripts to go through the tutorial steps themselves","[{'title': None, 'identifiers': ['issn:1424-8220', '1424-8220']}]",core
91858780,2014-11-01T00:00:00Z,Jap Sam Books,Intersecting Knowledge Fields and Integrating Data-Driven Computational Design en Route to Performance-Oriented and Intensely Local Architectures,10.7480/footprint.8.2.812,,"<p>This paper discusses research by design efforts in architectural education, focused on developing concepts and methods for the design of performance-oriented and intensely local architectures. The pursued notion of performance foregrounds the interaction between a given architecture and its local setting, with consequences not only for the design product but also for the related processes by which it is generated. Integrated approaches to data-driven computational design serve to generate such designs. The outlined approach shifts the focus of design attention away from the delivery of finite architectural objects and towards an expanded range of architecture-environment interactions that are registered, instrumentalised and modulated over time. This paper examines ongoing efforts in integrating specific architectural goals and approaches, computational data-driven design methods and generative design processes, based on a range of context-specific and often real-time data sets. The work discussed is produced in the context of the Research Centre for Architecture and Tectonics (RCAT) and the Advanced Computational Design Laboratory (ACDL) at the Oslo School of Architecture and Design.</p","[{'title': None, 'identifiers': ['issn:1875-1490', '1875-1490', '1875-1504', 'issn:1875-1504']}]",core
100153622,2014-12-04,,Data Driven Design: Using Web Analytics to Improve Information Architectures,,,"Abstract — Web analytics, the practice of web traffic analysis, typically provides intelligence for marketers and executives responsible for proving Return On Investment (ROI). While valuable for proving ROI, web analytics ’ greatest potential lies in improving the online user experience. The use of web analytics to evaluate the online user experience is fueled by an increasing awareness of web analytics in general; however, the sharing of analytics data across units in an organization is not yet the business norm. When analytics data is shared with the design team, a subtler and more sophisticated user experience design can emerge. 1",,core
105895279,2016-09-11,,Four Chairs and All the Others- Eigenchair Data driven design,,,"Abstract. By contemplating on the Eigenchair project, we ponder upon strategies and concepts of designing by using information technologies. What are the potentials of data driven design? What happens with objects when they are abstracted and reduced to a set of data? The emphasis is no longer on the creation of physical objects, but on conceiving meta-objects in the possibility space. Furthermore, this enables us to manipulate with a whole population of objects, instead of a single object. How do we get this abstract system to relate to the real world? Information technologies have opened up a number of new ways of thinking about the world and the object and they, by far, surpassed the formally simplified expression in design and architecture. Based on intellectual heritage of history and culture, information technologies can, by utilizing and recycling various elements and information, explore the 21st century object",,core
248247648,2016,MDPI AG,Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
23861320,2014-01-30,,Usability Testing and the Relation of Clinical Information Systems to Patient Safety,,,"Background: The success of clinical information systems depends upon their effective integration into complex work systems involving distributed responsibility and decisionmaking. Human-computer interaction (HCI) deficiencies and mismatches between systems design and the structure of work create the potential for new paths to system failures (e.g., allergy lists not directly visible on a screen). The use of human factors methods is widespread in other industries and can predict some of these new failure paths, facilitating redesign to prevent accidents-in-the-making. This paper will discuss the application of scenario-based usability testing in clinical health care settings. Methods: Using scenario-based usability testing methods, we investigated point-of-care software technology (e.g., barcoded medication administration [BCMA] and wireless medication administration [WMA]) in an attempt to better understand the safety implications of HCI design decisions. The use of scenarios in usability testing focuses attention on specific aspects of the interface to identify pitfalls and system failures. The scenarios were developed after extensive ethnographic observation of the medical work with bar-coding software and the computerized order entry system (COES). Results: The paper lays out the methodology of scenario-based usability testing for use in health care. We were able to identify new paths to failures using this method and recommended the software to simplify and support the user’s tasks. Scenario-based testing also identified workplace performance trade-offs related to time and production pressures. Conclusion: Scenario-based usability testing is an important methodology that characterizes how humansoftware interaction contributes to success or failure in clinical system implementations. Usability testing can identify and promote data-driven design choices culled from practitioner use of the system in a busy work environment. Human factors knowledge of HCI design and its impact on human performance can advance safety in health care",,core
104830573,2016-08-22,,A Data-Driven Design Evaluation Tool for Handheld Device Soft Keyboards,,,"Thumb interaction is a primary technique used to operate small handheld devices such as smartphones. Despite the different techniques involved in operating a handheld device compared to a personal computer, the keyboard layouts for both devices are similar. A handheld device keyboard that considers the physical capabilities of the thumb may improve user experience. We developed and applied a design evaluation tool for different geometries of the QWERTY keyboard using a performance evaluation model. The model utilizes previously collected data on thumb motor performance and posture for different tap locations and thumb movement directions. We calculated a performance index (PITOT, 0 is worst and 2 is best) for 663 designs consisting in different combinations of three variables: the keyboard’s radius of curvature (R) (mm), orientation (O) (u), and vertical location on the screen (L). The current standard keyboard performed poorly (PITOT = 0.28) compared to other designs considered. Keyboard location (L) contributed to the greatest variability in performance out of the three design variables, suggesting that designers should modify this variable first. Performance was greatest for designs in the middle keyboard location. In addition, having a slightly upward curve (R =220 mm) and orientated perpendicular to the thumb’s long axis (O=220u) improved performance to PITOT = 1.97. Poorest performances were associated with placement of the keyboard’s spacebar in the bottom right corner of the screen (e.g., the worst was for R = 20 mm, O = 40u, L = Bottom (PITOT = 0.09)). While this evaluation tool can be used in the design process as an ergonomi",,core
272002897,2016,MDPI AG,Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
53810195,2015-01-01T00:00:00,'The Electrochemical Society',Soft Sensor Design for Estimation of SOFC Stack Temperatures and Oxygen-to-Carbon Ratio,10.1149/06801.2625ecst,,"The life span of a solid oxide fuel cell (SOFC) stack depends on several factors, such as internal stack temperature and temperature gradients as well as the fuel gas oxygen-to-carbon (O/C) ratio. An excessive stack temperature generally accelerates the degradation, while large temperature gradients across the stack cause thermal stress, which leads to delamination. Too low O/C ratio inflicts carbon deposition, which quickly leads to stack breakage. Therefore, monitoring of these variables is of vital importance. Although direct sensing of temperatures within the stack as well as fuel gas composition in fuel stream is feasible, it is not desirable due to increased equipment cost. In this paper a data-driven design of soft sensors for minimal and maximal stack temperatures as well as the O/C ratio is presented. Dynamic and static models for stack temperature are identified from data and their performance is compared. The dynamic model is derived by means of the subspace identification, which results in a causal state-space model. The non-causal static model assumes that a combination of process variables at the stack inlet and outlet describe its internal condition. The estimator of O/C ratio is based on static relationships. The soft sensors are designed in such a way that adding extra inputs to the model yields no further increase in accuracy of the estimates. The empirical data required for modelling were obtained from a SOFC power generating unit. The results show that the reconstruction of all the relevant variables can be accomplished by simple linear regression models",,core
162912441,2016-01-01T00:00:00,'Organisation for Economic Co-Operation and Development  (OECD)',Poster abstract: A data-driven design framework for urban slum housing - Case of Mumbai,10.17863/CAM.26508,https://core.ac.uk/download/162912441.pdf,"The current building assessment tools are limited to building performance analysis with respect to box models derived from the urban morphology of developed countries. Complex socio-technical issues associated with rapidly urbanizing cities like Mumbai are often missed. Here, we forward a conceptual framework for designing slum habitation adheres to norms of energy, health and environmental sustainability. This can enable in designing slum rehabilitation projects such that they are not only energy efficient, but are also acceptable to the occupants. This conceptual framework attempts to bridge the missing link currently existing in the early design stages of slum rehabilitation projects. The proof of the concept is a work currently in progress, hence, here, we only elaborate on the conceptual framework exemplified through three cases of slum rehabilitation houses in Mumbai",,core
23855909,2014-01-30,,"M.Sampath Kumar,",,,"Abstract:Many peer-to-peer systems have been deployed on a large scale to provide users with “live streaming”, that is Internet delivered real-time multimedia content, much as the traditional television service (to name a few, CoolStreaming,TVants and PPLive, UUSee are examples in case).All such systems are organized in an unstructured manner, with epidemic-style information exchanges: users decide who to interact with in an adaptive manner, on the basis of past experience, and decide which data blocks to exchange with their “logical neighbors ” by relying on simple, local rules. Despite their success, the performance of such unstructured systems is still poorly understood, especially in comparison of structured systems, such as Split Stream, the performance of which is relatively well understood in symmetric scenarios. In this paper, In this paper we describe how cool streaming are used and We emphasize three salient features of this data-driven design: 1) easy to implement, as it does not have to construct and maintain a complex global structure; 2) efficient, as data forwarding is dynamically determined according to data availability while not restricted by specific directions; and 3) robust and resilient, as the partnerships enable adaptive and quick switching among multi-suppliers",,core
24065941,2014-09-04,,A Dynamic Data-Driven Simulation Approach for Preventing Service Level Agreement Violations in Cloud Federation,,https://core.ac.uk/download/pdf/24065941.pdf,"The new possibility of accessing an infinite pool of computational resources at a drastically reduced price has made cloud computing popular. With the increase in its adoption and unpredictability of workload, cloud providers are faced with the problem of meeting their service level agreement (SLA) claims as demonstrated by large vendors such as Amazon and Google. Therefore, users of cloud resources are embracing the more promising cloud federation model to ensure service guarantees. Here, users have the option of selecting between multiple cloud providers and subsequently switching to a more reliable one in the event of a provider’s inability to meet its SLA. In this paper, we propose a novel dynamic data-driven architecture capable of realising resource provision in a cloud federation with minimal SLA violations. We exemplify the approach with the aid of case studies to demonstrate its feasibility. Keywords",,core
265386377,2014,Hindawi Limited,Metric Learning Method Aided Data-Driven Design of Fault Detection Systems,10.1155/2014/974758,http://doi.org/10.1155/2014/974758,,,core
265893163,2014,Hindawi Limited,Metric Learning Method Aided Data-Driven Design of Fault Detection Systems,10.1155/2014/974758,http://doi.org/10.1155/2014/974758,,,core
266178102,2014,Hindawi Limited,Metric Learning Method Aided Data-Driven Design of Fault Detection Systems,10.1155/2014/974758,http://doi.org/10.1155/2014/974758,,,core
29413016,2015-02-17T00:00:00,Henry Stewart Publications,Data-driven design — Using data on human behaviour and spatial configuration to inform better workplace design,,https://core.ac.uk/download/29413016.pdf,"Recent studies have shown that the majority of staff are dissatisfied with their workplace environment. At the same time, scientists are beginning to discover clearer and recurring patterns that show how the spatial design of a workplace affects staff satisfaction, well-being, exchange of information, communication and movement flows. This paper argues that insights from this body of research could be used to improve workplace design. It gives an overview of evidence-based and data-driven design as new emerging practices, which base design decisions on rigorously collected data. Using various case studies from Spacelab — a London-based practice — as an example, the paper shows how the typical needs of clients can be solved more profoundly by relying on data rather than intuition, opinion or office politics. The main insights include answers to the questions of how to fit more people into a space, whether everyone needs a desk, who should sit where, how to find the perfect property and how to establish the success of a project. In conclusion, the paper identifies key barriers for the further integration of research findings into design practice and suggests how they might be overcome in the future",,core
158741488,2016-09-23,,Data-enabled design for social change: two case studies,10.3390/fi8040046,,"Smartness in contemporary society implies the use of massive data to improve the experience of people with connected services and products. The use of big data to collect information about people’s behaviours opens a new concept of “user-centred design” where users are remotely monitored, observed and profiled. In this paradigm, users are considered as sources of information and their participation in the design process is limited to a role of data generators. There is a need to identify methodologies that actively involve people and communities at the core of ecosystems of interconnected products and services. Our contribution to designing for social innovation in ecosystems relies on developing new methods and approaches to transform data-driven design using a participatory and co-creative data-enabled design approach. To this end, we present one of the methods we have developed to design “smart” systems called Experiential Design Landscapes (EDL), and two sample projects, Social Stairs and [Y]our Perspective. Social Stairs faces the topic of behaviour change mediated by sensing technologies. [Y]our Perspective is a social platform to sustain processes of deliberative democracy. Both projects exemplify our approach to data-enabled design as a social proactive participatory design approach",,core
161156415,2014-09-11,Public Library of Science,A Data-Driven Design Evaluation Tool for Handheld Device Soft Keyboards,10.1371/journal.pone.0107070,,,,core
74312910,2016-01-01T00:00:00,'Elsevier BV',Data-driven design of two degree-of-freedom nonlinear controllers: The D2-IBC approach,10.1016/j.automatica.2016.05.010,,"In this paper, we introduce and discuss the Data-Driven Inversion-Based Control (D2-IBC) method for nonlinear control system design. The method relies on a two degree-of-freedom architecture, with a nonlinear controller and a linear controller running in parallel, and does not require any detailed physical knowledge of the plant to control. Specifically, we use input/output data to synthesize the controller by employing convex optimization tools. We show the effectiveness of the proposed approach on a benchmark simulation example, regarding control of the Duffing system",,core
102075658,2015-07-06,,THE MURASAKI PROJECT: MULTILINGUAL NATURAL LANGUAGE UNDERSTANDING,,,"This paper describes a multilingual data extraction system under development for the Department of Defense (Do[)). The system, called Murasa.ki, processes Spanish and Japanese newspaper a ticles reporting AIDS disease statistics. Key to Murasaki&apos;s design is its language-independent and domain-independent architecture. The system consists of shared processing modules across the three languages it currently handles (English, Japanese, and Spanish), shared general and domain-specific knowledge bases, and separate data modules for language-specific knowledge such as grammars, lexicons, morphological data and discourse data. This data-driven architecture is crucial to the success of Murasaki as a language-independent system; extending Murasaki to additional languages can be done for the most part merely by adding new data. Some of the data can be added with user-friendly tools, others by exploitin",,core
195357541,2016-01-01T00:00:00,Multidisciplinary Digital Publishing Institute (MDPI),Data-enabled design for social change: two case studies,,,"Smartness in contemporary society implies the use of massive data to improve the experience of people with connected services and products. The use of big data to collect information about people’s behaviours opens a new concept of “user-centred design” where users are remotely monitored, observed and profiled. In this paradigm, users are considered as sources of information and their participation in the design process is limited to a role of data generators. There is a need to identify methodologies that actively involve people and communities at the core of ecosystems of interconnected products and services. Our contribution to designing for social innovation in ecosystems relies on developing new methods and approaches to transform data-driven design using a participatory and co-creative data-enabled design approach. To this end, we present one of the methods we have developed to design “smart” systems called Experiential Design Landscapes (EDL), and two sample projects, Social Stairs and [Y]our Perspective. Social Stairs faces the topic of behaviour change mediated by sensing technologies. [Y]our Perspective is a social platform to sustain processes of deliberative democracy. Both projects exemplify our approach to data-enabled design as a social proactive participatory design approach. Smartness in contemporary society implies the use of massive data to improve the experience of people with connected services and products. The use of big data to collect information about people’s behaviours opens a new concept of “user-centred design” where users are remotely monitored, observed and profiled. In this paradigm, users are considered as sources of information and their participation in the design process is limited to a role of data generators. There is a need to identify methodologies that actively involve people and communities at the core of ecosystems of interconnected products and services. Our contribution to designing for social innovation in ecosystems relies on developing new methods and approaches to transform data-driven design using a participatory and co-creative data-enabled design approach. To this end, we present one of the methods we have developed to design “smart” systems called Experiential Design Landscapes (EDL), and two sample projects, Social Stairs and [Y]our Perspective. Social Stairs faces the topic of behaviour change mediated by sensing technologies. [Y]our Perspective is a social platform to sustain processes of deliberative democracy. Both projects exemplify our approach to data-enabled design as a social proactive participatory design approach",,core
297110994,2015,"John Wiley & Sons, Inc.","Data-driven design and construction : 25 strategies for capturing, analyzing, and applying building data",,,,,core
202000794,2015-12-31,Published by Elsevier Ltd.,Leveraging data Across the Building Lifecycle ,10.1016/j.proeng.2015.08.425,,"AbstractArchitects, engineers and contractors have been working with data for ages. What is new are the myriad ways they have to capture, analyze and apply the data that has been made readily available. Some practitioners and their organizations have balked at adding data to their repertoire, citing that they are unprepared to deal with data on top of everything else they have to contend with, including new technologies, work-processes and workflows. Data-centric organizations, on the other hand, have come to realize that capturing, engaging with, analyzing, and applying sustainability data in their projects is not “one more thing,” and have learned that to have the greatest impact, data cannot be added on top of an organization's on-going practices, but rather integrated into their pre-existing mind-sets and processes. This paper explores firms’ approaches and relationships to data, determining whether organizations are data-enabled, data-informed or data driven, or a hybrid, and how their approach can have an enormous influence on outcomes, especially where they pertain to sustainability. Likewise, many organizations remain document-centric, and are missing out on opportunities and greater gains that come with becoming data-centric. Innovative tools and insights to make the most of the data are already readily available. What has been missing, up until now, is an understanding of how others – academics and industry practitioners – are innovating behind the scenes to exploit these resources to great impact. Big data and predictive analytics are currently being leveraged across the globe to address wicked – complex and poorly defined – problems endemic of design and construction in the 21st century. Innovative results in leveraging data throughout the building lifecycle are a result of original research for a new book, “Data Driven Design and Construction: Strategies for Capturing, Analyzing and Applying Building Data,” (John Wiley & Sons, 2015.) Methods of Research: Because data driven design impacts so many facets of the building lifecycle, the research for this paper attempted to be as inclusive as possible. Using practice-based research and in-depth interviews with industry and academic leaders, the author relied on many sources, including first-hand interviews with 40 thought leaders in industry and education in the AECO industry who work day-to-day with data; with firm leaders and other industry executives at companies that range in size from sole proprietorships to large multinational organizations. The interviewee's responses were recorded, transcribed by the author, and condensed for publication",,core
253595533,2016,MDPI AG,Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
29534466,2015-05-08T00:00:00,,Direct identification of fault estimation filter for sensor faults,,http://arxiv.org/abs/1505.01958,"We propose a systematic method to directly identify a sensor fault estimation
filter from plant input/output data collected under fault-free condition. This
problem is challenging, especially when omitting the step of building an
explicit state-space plant model in data-driven design, because the inverse of
the underlying plant dynamics is required and needs to be stable. We show that
it is possible to address this problem by relying on a system-inversion-based
fault estimation filter that is parameterized using identified Markov
parameters. Our novel data-driven approach improves estimation performance by
avoiding the propagation of model reduction errors originating from
identification of the state-space plant model into the designed filter.
Furthermore, it allows additional design freedom to stabilize the obtained
filter under the same stabilizability condition as the existing model-based
system inversion. This crucial property enables its application to sensor
faults in unstable plants, where existing data-driven filter designs could not
be applied so far due to the lack of such stability guarantees (even after
stabilizing the closed-loop system). A numerical simulation example of sensor
faults in an unstable aircraft system illustrates the effectiveness of the
proposed new method.Comment: Extended version of the paper accepted by IFAC Safeprocess201",,core
154348022,2015-08-01T00:00:00,'Association for Computing Machinery (ACM)',Interactive robogami: data-driven design for 3D print and fold robots with ground locomotion,10.1145/2785585.2792556,,"The process of designing and programming a new robot requires expert knowledge and design skills that are often acquired over the course of many years. This makes design of new robots difficult for non-experienced users. In addition to design, physical realization of a robot is also time and labor intensive. We propose a new fabrication process for mechanical robots, called 3D print and fold, which combines 3D printing with origami fabrication methods. In our technique, robots are 3D printed as flat faces connected at joints and are then folded into their final shape. To help casual users design ground robots using our 3D print and fold technique, we present our Interactive Robogami system. The system leverages a database of examples created by expert roboticists. A composition tool allows users to create new designs by composing parts from the robots in this database. The system automatically ensures that the assembled robot is fabricable and that it can locomote forward while still giving creative freedom to users",,core
80777852,2016-06-15T00:00:00,,Intelligent Data-Driven Design Futures (Published Online),10.13140/RG.2.1.4850.5843,https://core.ac.uk/download/80777852.pdf,,,core
240162096,2016-01-01T00:00:00,'MDPI AG',Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
81118275,2015-12-31,'Elsevier BV',Leveraging data Across the Building Lifecycle ,10.1016/j.proeng.2015.08.425,https://core.ac.uk/download/pdf/81118275.pdf,"AbstractArchitects, engineers and contractors have been working with data for ages. What is new are the myriad ways they have to capture, analyze and apply the data that has been made readily available. Some practitioners and their organizations have balked at adding data to their repertoire, citing that they are unprepared to deal with data on top of everything else they have to contend with, including new technologies, work-processes and workflows. Data-centric organizations, on the other hand, have come to realize that capturing, engaging with, analyzing, and applying sustainability data in their projects is not “one more thing,” and have learned that to have the greatest impact, data cannot be added on top of an organization's on-going practices, but rather integrated into their pre-existing mind-sets and processes. This paper explores firms’ approaches and relationships to data, determining whether organizations are data-enabled, data-informed or data driven, or a hybrid, and how their approach can have an enormous influence on outcomes, especially where they pertain to sustainability. Likewise, many organizations remain document-centric, and are missing out on opportunities and greater gains that come with becoming data-centric. Innovative tools and insights to make the most of the data are already readily available. What has been missing, up until now, is an understanding of how others – academics and industry practitioners – are innovating behind the scenes to exploit these resources to great impact. Big data and predictive analytics are currently being leveraged across the globe to address wicked – complex and poorly defined – problems endemic of design and construction in the 21st century. Innovative results in leveraging data throughout the building lifecycle are a result of original research for a new book, “Data Driven Design and Construction: Strategies for Capturing, Analyzing and Applying Building Data,” (John Wiley & Sons, 2015.) Methods of Research: Because data driven design impacts so many facets of the building lifecycle, the research for this paper attempted to be as inclusive as possible. Using practice-based research and in-depth interviews with industry and academic leaders, the author relied on many sources, including first-hand interviews with 40 thought leaders in industry and education in the AECO industry who work day-to-day with data; with firm leaders and other industry executives at companies that range in size from sole proprietorships to large multinational organizations. The interviewee's responses were recorded, transcribed by the author, and condensed for publication",,core
108805289,2016-10-02,,Applying a Warfighter-Centric System Design,,,"ABSTRACT: This case study describes a user-centered system design process that was undertaken by a team of multidisciplinary engineers supporting the Joint Tactical Radio System Handheld, Manpack and Small Form Fit Program. Motivated by the need to manage the risk associated with designing a compact, software-programmable radio to meet the diverse needs of the joint forces, the team applied cognitive engineering methods at key points during the system development and demonstration phase of the acquisition process. To make sound, data-driven design decisions, the team conducted four research efforts with warfighters to understand their tactical communication needs and the impact that proposed designs would have on mission and individual perfor-mance. Key insights and lessons learned from the application of cognitive engineering methods during the process and their impact on system design are discussed",,core
274657179,2016,MDPI AG,Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
55850389,2016-01-01T00:00:00,'MDPI AG',Data-driven design of intelligent wireless networks: an overview and tutorial,10.3390/s16060790,https://core.ac.uk/download/55850389.pdf,"Data science or ""data-driven research"" is a research approach that uses real-life data to gain insight about the behavior of systems. It enables the analysis of small, simple as well as large and more complex systems in order to assess whether they function according to the intended design and as seen in simulation. Data science approaches have been successfully applied to analyze networked interactions in several research areas such as large-scale social networks, advanced business and healthcare processes. Wireless networks can exhibit unpredictable interactions between algorithms from multiple protocol layers, interactions between multiple devices, and hardware specific influences. These interactions can lead to a difference between real-world functioning and design time functioning. Data science methods can help to detect the actual behavior and possibly help to correct it. Data science is increasingly used in wireless research. To support data-driven research in wireless networks, this paper illustrates the step-by-step methodology that has to be applied to extract knowledge from raw data traces. To this end, the paper (i) clarifies when, why and how to use data science in wireless network research; (ii) provides a generic framework for applying data science in wireless networks; (iii) gives an overview of existing research papers that utilized data science approaches in wireless networks; (iv) illustrates the overall knowledge discovery process through an extensive example in which device types are identified based on their traffic patterns; (v) provides the reader the necessary datasets and scripts to go through the tutorial steps themselves",,core
103523053,2016-01-06,,Combining Social and Government Open Data for,,,"Abstract. In the last years, several research endeavors were launched aiming at involving popular social media platforms in electronic participation. These early endeavors seem to present some essential limitations related mainly to scalability and uptake. In order to avoid these limitations, we introduce a two-phased approach for supporting participatory decision-making based on the integration and analysis of social and government open data. The proposed approach is based on the literature related to the analysis of massive amounts of social data for future events prediction. In this paper we also present a Web data driven architecture for the implementation of the proposed approach. The architecture is based on the use of linked data paradigm as a layer that will enable integration of data from different sources. We anticipate that the proposed approach will (i) allow decision makers to understand and predict public opinion and reaction about specific decisions; and (ii) enable citizens to inadvertently contribute in decision-making",,core
240490357,2016-01-01T00:00:00,'MDPI AG',Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
248328323,2016,MDPI AG,Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
271913568,2016,MDPI AG,Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
271878209,2016,MDPI AG,Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
297618040,,"Jurnal Teknologi, Universiti Teknologi Malaysia",Cadangan prototaip sistem pengurusan maklumat ladang bagi petani kecil di Malaysia,,,"This paper introduces the process of developing web application of farm management information system (FMIS) for
smallholder farmers in Malaysia by using rapid application development (RAD) prototyping methodology in information system
research design. FMIS is important ICT solution to assist smallholder farmer to be more competitive in agriculture. The web
application requirement determined through extraction process using physical data-driven design system from Malaysia Good
Agriculture Practise (MyGAP) physical forms. Additionally, the functions and features of the system were determined through
several questionnaires which were distributed to 209 smallholder farmers located in Taman Kekal Pengeluaran Makanan
(TKPM) in Selangor. Selangor agricultural area together with smallholders farmers were chosen as respondents because
Selangor is the highest internet penetration state in Malaysia. Subsequently, the design and analysis of FMIS are constructed by
us including the database design, data flow design, system flow design and software development which was validated by
two other experienced system analysts. The software development process were using PHP web development tool called
Scriptcase version 8 which were taking less than 2 months to be completed. Furthermore, we also made a comparative study
of an existing system available in the market to give additional competitive value to the new development of FMIS in Malaysia.
The final developed FMIS is accessible through the official MyAgris website",,core
341352527,2015-01-01T00:00:00,'Elsevier BV',Data—Driven Design of a Fault Tolerant Fuzzy Controller for a Simulated Hydroelectric System,10.1016/j.ifacol.2015.09.672,,,,core
253676586,2016,MDPI AG,Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
254066369,2016,MDPI AG,Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
100931930,2015-01-02,,Data-Driven Design of Front-End Filter Ban,,,"Adverse environments not only corrupt speech signal by additive and convolutional noises, which can be successfully addressed by a number of suppression algorithms, but also affect the way how speech is produced. Speech production variations introduced by a speaker in reaction to a noisy background (Lombard effect) may result in a severe degradation of automatic speech recognition. This paper contributes to the solution of Lombard speech recog-nition issue by providing a robust filter bank for use in front-ends. It is shown that cepstral features derived from the proposed filter bank significantly outperform conventional cepstral features. Index Terms: robust speech recognition, Lombard effect, feature extraction, filter bank, data-driven desig",,core
188198074,2016-01-01T00:00:00,University of Liverpool,Intelligent data-driven design futures. International symposium,,http://hdl.handle.net/10536/DRO/DU:30112255,,,core
145030467,2017-06-16T07:00:00Z,RIT Scholar Works,Smart Grid Privacy through Distributed Trust,,,"Though the smart electrical grid promises many advantages in efficiency and reliability, the risks to consumer privacy have impeded its deployment. Researchers have proposed protecting privacy by aggregating user data before it reaches the utility, using techniques of homomorphic encryption to prevent exposure of unaggregated values. However, such schemes generally require users to trust in the correct operation of a single aggregation server. We propose two alternative systems based on secret sharing techniques that distribute this trust among multiple service providers, protecting user privacy against a misbehaving server. We also provide an extensive evaluation of the systems considered, comparing their robustness to privacy compromise, error handling, computational performance, and data transmission costs. We conclude that while all the systems should be computationally feasible on smart meters, the two methods based on secret sharing require much less computation while also providing better protection against corrupted aggregators. Building systems using these techniques could help defend the privacy of electricity customers, as well as customers of other utilities as they move to a more data-driven architecture",,core
149388138,2017-10-06T15:04:32Z,,BRAIN Journal - A Proposed Data Driven Architecture for Cardiology Network Application,10.6084/m9.figshare.5478499.v1,,"<i>Abstract</i><div><br></div><div><br></div><div>The paper presents a framework for a distributed medical system meant to bring a modern approach and inhance the quality of medical services offered to chronicle patients with cardio-vascular diseases, through the latest IT&C technologies. The proposed system provides online interaction between the main actors of a medical system: patients, doctors, medical entities (e.g. hospitals, clinics) and medical authorities (e.g. social services). With the aid of widely accepted medical standards, the system supplies storage for medical records and offers services for data integration between different kinds of healthcare applications and entities. The proposed ontological approach allows interchange of medical knowledge and best practices with conceptually organized patients’ records. The proposed solution allows computer assisted diagnoses and multi-criteria medical data analysis, with the possible extent of building a data warehouse for complex medical data mining.<br></div><div><br></div><div><br></div><div><b>Learn more at:</b></div><div><b>https://www.edusoft.ro/brain/index.php/brain/article/view/25</b><br></div",,core
162432704,2017-01-01T00:00:00,'Elsevier BV',Frequency-domain data-driven control design in the Loewner framework,10.1016/j.ifacol.2017.08.531,,"In this article, a direct data-driven design method, based on frequency-domain data, is proposed. The identification of the plant is skipped and the controller is designed directly from the measurements. The identification task is reported on a fixed-order controller using for the first time the Loewner approach, known for model approximation and reduction. The method is validated on two numerical examples including the control of an industrial hydroelectric generation plant, modelled by irrational equations",,core
272114393,2016,MDPI AG,Data-Driven Design of Intelligent Wireless Networks: An Overview and Tutorial,10.3390/s16060790,http://www.mdpi.com/1424-8220/16/6/790/pdf,,,core
108402367,2016-09-24,,Fränkle ”Background,,,"This paper describes the design and initial implementation of a modular framework for Clinical Decision Support Systems and highlights the need for medical device plug-and-play standards. The software handles the tasks of data acquisition and validation, visualization, and treatment management in order to enable the development of protocol guideline modules as “plug-ins ” to the framework. The system utilizes an asynchronous data-driven design to support real-time information flow and user interaction. All components of the framework are modular and easily extendible, allowing for new data sources, visualization methods, and protocols to be inserted. The system is configured by assigning each protocol a manager that handles decision communication with the rest of the framework. A set of classes has been created to allow communication between the different modules along with persistence of all data, decisions, and treatments to a database. The initial prototype is a Clinical Decision Support System focusing on the treatment of Traumatic Brain Injury",,core
54714231,2015-01-01T00:00:00,'Elsevier BV',Data-Driven Design of a Fault Tolerant Fuzzy Controller for a Simulated Hydroelectric System,10.1016/j.ifacol.2015.09.672,,"This paper proposes a data-driven approach oriented to the design of a fault tolerant fuzzy controller for regulating the speed of a Francis turbine included in a hydroelectric system simulated in the Matlab and Simulink environments. The nonlinear characteristics of hydraulic turbine and the inelastic water hammer effects are considered to simulate the dynamic process. This strategy is suggested for enhancing the regulator derivation that could represent an alternative to the standard controllers in typical hydroelectric systems. The controller development requires the knowledge of the dynamic model of the monitored system, which is achieved by means of a fuzzy modelling and identification scheme. This feature of the work, followed by the proposed solution relying on a data-driven approach, represents the key point when on-line implementations are considered for a viable application of the proposed scheme. Moreover, by means of this design scheme, the proposed strategy is also able to provide a fault tolerant controller. In particular, the fault tolerance properties are achieved by using a so-called passive approach. It is assumed that the fault considered in this work affects the electric servomotor used as governor. The performances of the fault tolerant fuzzy controller is compared to that of a PID regulator and an adaptive PID controller scheme already implemented for the simulated hydroelectric system",,core
23297301,2013-10-04,a multitasking and data-driven architecture for multi-agents simulation,ÉCOLE POLYTECHNIQUE FÉDÉRALE DE LAUSANNE POUR L&apos;OBTENTION DU GRADE DE DOCTEUR ÈS SCIENCES PAR,,,,,core
22278235,2013-02-02,"Advances in data mining and knowledge discovery have transformed the way Web sites are designed. However, while visual presentation is an intrinsic part of the Web, traditional data mining techniques ignore render-time page structures and their attributes. This paper introduces design mining for the Web: using knowledge discovery techniques to understand design demographics, automate design curation, and support data-driven design tools. This idea is manifest in Webzeitgeist, a platform for large-scale design mining comprising a repository of over 100,000 Web pages and 100 million design elements. This paper describes the principles driving design mining, the implementation of the Webzeitgeist architecture, and the new class of data-driven design applications it enables",Author Keywords,,,,,core
21009495,2009-02-03,"Fundamental issues are discussed pertinent to the problem of generic, scalable parallel computing. It is argued that a generic system should be a data-driven, bulk-synchronous one with scalable communications. A data-driven architecture adapted to patterns of massively-parallel computing is described, as well as compiler technology which infers data-distribution patterns as types in an advanced type system. ",Asyncrony in distributed parallel computing,,,,,core
55216509,2011-01-01T00:00:00,"In this paper, an algorithm for direct data-driven design of cascade control system

is proposed and analysed. The procedure is based on the Virtual Reference Feedback Tuning

(VRFT) approach but it allows to tune either the inner and the outer loops by means of a

single set of experimental data. The main differences between the standard VRFT and the

proposed approach are highlighted and analyzed. The design technique is finally applied on a

micro-positioning control problem for Electro-HydroStatic Actuators (EHSAs)",Fast tuning of cascade control systems,,10.3182/20110828-6-it-1002.02761,,,core
264039514,2013,,PromoterCAD: data-driven design of plant regulatory DNA,https://academic.oup.com/nar/article-pdf/41/W1/W569/16944755/gkt518.pdf,10.1093/nar/gkt518,Oxford University Press (OUP),,core
105022774,2013,"Synthetic promoters can control the timing, location and amount of gene expression for any organism. PromoterCAD is a web application for designing synthetic promoters with altered transcriptional regulation. We use a data-first approach, using pub-lished high-throughput expression and motif data from for Arabidopsis thaliana to guide DNA design. We demonstrate data mining tools for finding motifs related to circadian oscillations and tissue-specific expression patterns. PromoterCAD is built on the LinkData open platform for data publication and rapid web application develop-ment, allowing new data to be easily added, and the source code modified to add new function",PromoterCAD: data-driven design of plant regulatory DNA,,10.1093/nar/gkt518,,,core
153228653,2009-09-17T00:00:00,"The present article dedicates itself to fuzzy modelling
of data-inherent structures. In particular two main points are dealt
with: the introduction of a fuzzy modelling framework and the elaboration
of an automated, data-driven design strategy to model complex
data-inherent structures within this framework.
The innovation concerning the modelling framework lies in the
fact that it is consistently built around a single, generic type of parametrical
and convex membership function. In the first part of the
article this essential building block will be defined and its assets and
shortcomings will be discussed.
The novelty regarding the automated, data-driven design strategy
consist in the conservation of the modelling framework when modelling
complex (nonconvex) data-inherent structures. Instead of applying
current clustering methods the design strategy uses the inverse
of the data structure in order to created a fuzzy model solely based
on convex membership functions.
Throughout the article the whole model design process is illustrated,
section by section, with the help of an academic example",Parametric Fuzzy Modelling Framework for Complex Data-Inherent Structures,https://core.ac.uk/download/153228653.pdf,,Technische Universitat Chemnitz,,core
23543071,2013-12-12,"Abstract. This paper describes a QA system centered in a full data-driven architecture. It applies machine learning and text mining techniques to identify the most probable answers to factoid and definition questions respectively. Its major quality is that it mainly relies on the use of lexical information and avoids applying any complex language processing resources such as named entity classifiers, parsers and ontologies. Experimental results on the Spanish Question Answering task at CLEF 2006 show that the proposed architecture can be a practical solution for monolingual question answering by reaching a precision as high as 51%. ",Using Machine Learning and Text Mining in Question Answering,,,,,core
210419793,2013-01-01T00:00:00,,PromoterCAD: data-driven design of plant regulatory DNA,https://academic.oup.com/nar/article-pdf/41/W1/W569/16944755/gkt518.pdf,10.1093/nar/gkt518,'Oxford University Press (OUP)',,core
263819345,2013,,PromoterCAD: data-driven design of plant regulatory DNA,https://academic.oup.com/nar/article-pdf/41/W1/W569/16944755/gkt518.pdf,10.1093/nar/gkt518,Oxford University Press (OUP),,core
15353670,2010,"Architects and designers have often used computational design techniques in their design process, even without “computers”, from designing spaces which activate at the instant of the solstice sunrise, to creating geometrically complex and structurally innovative cathedrals. Designing with rules and variables can lead to solutions which satisfy the design criteria and may result in interesting and unanticipated models. Computational design is a process of designing and a way of thinking, contemporary tools can promote and enhance this process. Algorithmic and parametric modelling (and thinking) can be powerful processes in design, and particularly in working with complex geometry and addressing project constraints and analytical and data-driven design. This paper describes these methods and provides examples of their use on projects at Skidmore, Owings & Merrill","Algorithmic Modeling, Parametric Thinking: Computational Solutions to Design Problems",,,,,core
33798831,2011-02-24T00:00:00,"The thesis focuses on advanced methods of fault detection and diagnosis suitable for application in large-scale processes. The theory of fault diagnosis mainly comprises development of mathematical models for observing critical changes in the process under consideration. The so-called residual signal is used for the purpose of detecting abnormal events and diagnosing their nature.

For large-scale processes, it is difficult to build their models mathematically. Therefore, very often historical data from regular sensor measurements, event-logs and records are used to directly identify relationship between plant's input and output. On these lines, the thesis presents a data-driven design of fault detection systems which reduces the computation burden by identifying only the key components and not the entire process model itself.

The novel design method is also studied within the context of parameter varying systems. Since many processes undergo temporary fluctuation of their crucial parameters, which can not be ruled out as faults, the fault detection system must be able to adapt to these changes. This is realized in the thesis with two efficient algorithms, which are based on recursive identification techniques. 

The theoretical contribution in this thesis also revolves around improvising the novel data-drive design of fault detection systems. In other words, the identification procedure is optimized by reformulating it as “closed-loop” identification or identification of Kalman filter. Also, the algorithm is numerically optimized by using QR based decomposition technique.

The thesis also presents application results of different algorithms derived in this work. As benchmarks, the Tennessee Eastman chemical plant and the continuously stirred tank heater are considered. The novel algorithms are compared with the existing popular techniques from the literature.Die Arbeit konzentriert sich auf fortgeschrittene Methoden zur Fehlererkennung und Diagnose für den Einsatz in Mehrgrößen Systemen. Üblicherweise umfasst die Fehlerdiagnose Entwicklung von mathematischen Modellen zur Beobachtung der Veränderungen in den ursprünglichen Prozessen. Dabei wird ein so genanntes Residuensignal zur von Fehlern benutzt, welches im Fehlerfall einen Ausschlag zeigt.

Für Mehrgrößen Systeme, ist es im Allgemeinen schwierig, mathematische Modelle zu erstellen, die mathematisch abgeleitet werden können. Deshalb werden Daten aus dem Prozess, z.B. aus regelmäßigen Messungen, Event-Logs oder Records verwendet, um Beziehungen zwischen Prozess-Eingang und Ausgang abzubilden. Davon ausgehend werden in der vorliegenden Arbeit Verfahren entwickelt um ein Datenbasiertes Fehlererkennungssystem zu generieren, welches ohne Modelidentifikation arbeitet.

In dieser Arbeit wird das Problem der Datenbasierten Fehlererkennung weiter im Rahmen der so genannten Parameter Varianten Systeme untersucht. Da viele Prozesse vorübergehenden Parameterschwankungen unterliegen,  die nicht als Fehler ausgeschlossen werden können, muss das Fehlererkennung System in der Lage sein, die Veränderungen zu adaptieren. Ein solches lernendes Fehlererkennungssystem ist hier an Hand von zwei effizienten Algorithmen und mit rekursiver Identifikation realisiert.

Der Beitrag in dieser Arbeit ist auch ein modifiziertes, optimales Subraum Identifikation basiertes Entwurf. Darüber hinaus wird das Identifikationsverfahren auf die Hauptkomponenten beschränkt und das ursprüngliche Problem wird für die optimale Parameterschätzung als „Closed-Loop“ Identifikation oder Identifikation des Kalman Filters umformuliert. Die gesamte Konstruktion ist numerisch über eine  QR Zerlegung numerisch optimiert.

Die Arbeit stellt auch Ergebnisse der Applikation verschiedener Algorithmen vor. Als Versuchstand wurden das Tennessee Eastman Prozess und eine kontinuierlich gerührte Tankheizung verwendet. Die Algorithmen dieser Arbeit werden mit dem ursprünglichen und anderen Identifikationsverfahren verglichen",Subspace based data-driven designs of fault detection systems,https://core.ac.uk/download/33798831.pdf,,,,core
84503397,2013-01-01T00:00:00,"Articulatory data offers promising developments in our understanding of speech production and advances in speech technologies. However, it is more expensive and difficult to obtain than audio data, which means data collection must be carefully planned. This paper presents a method for designing an articulatory speech corpus comparable to the widely-used TIMIT corpus, for languages other than English, using Italian as a case study. This data-driven method searches freely-available online text corpora for a set of sentences that provide broad phonetic coverage, while still being small enough to be read in a single session, which is important given the often invasive nature of articulatory data collection. Sentences are first phonemically transcribed and scored based on negative log-likelihood of triphones, with sentences that have many rare triphones scoring higher. The search algorithm then finds sentences that have high scores, but also contain the most frequent triphones. Experiments show that the distribution of triphones in the automatically selected sentences is similar to that found in handconstructed sentence sets for English, such as TIMIT, and offers broader phonetic coverage than selecting random sets of sentence",Data-driven design of a sentence list for an articulatory speech corpus,,,International Speech and Communication Association,,core
160627779,2009-09-17T00:00:00,"The present article dedicates itself to fuzzy modelling
of data-inherent structures. In particular two main points are dealt
with: the introduction of a fuzzy modelling framework and the elaboration
of an automated, data-driven design strategy to model complex
data-inherent structures within this framework.
The innovation concerning the modelling framework lies in the
fact that it is consistently built around a single, generic type of parametrical
and convex membership function. In the first part of the
article this essential building block will be defined and its assets and
shortcomings will be discussed.
The novelty regarding the automated, data-driven design strategy
consist in the conservation of the modelling framework when modelling
complex (nonconvex) data-inherent structures. Instead of applying
current clustering methods the design strategy uses the inverse
of the data structure in order to created a fuzzy model solely based
on convex membership functions.
Throughout the article the whole model design process is illustrated,
section by section, with the help of an academic example",Parametric Fuzzy Modelling Framework for Complex Data-Inherent Structures,,,Technische Universitat Chemnitz,,core
22716518,2013-08-02,"The Web of Data has grown to a size of several billion triples and provides human interface opportunities and challenges beyond those of the traditional Web. Although Linked Data is now generated at a fast pace and very large scale, we observe that browsing and visualisation of Linked Data is still in its infancy. In parallel to the enormous boost in Linked Data, recent work on integrating 3D graphics capabilities into the W3C technology stack provides fresh momentum for an effort to extend the Web with 3D content and technologies. In light of the timid uptake and consumption of Linked Data by non-technical audiences, we make the case for Web3D-based user interfaces to the Web of Data and aim at promoting synergistic research in the Web3D and Web of Data communities. To that end, we describe a scenario that requires the combination of Linked Data from geospatial and encyclopedic data sources and the transformation of the combined Linked Data into a format amenable to Web3D rendering. Based on the scenario, we derive highlevel requirements and propose a Linked Data-driven design pattern based on REST architecture principles that satisfies the requirements. Our prototypical implementation shows that a combination of current Web technologies is sufficient to implement distributed application that ultimately arrive at Web3D renderings of Linked Data. Based on the experiments, we identify and discuss areas which require further research. 1",Towards Networked Linked Data-Driven Web3D Applications,,,,,core
22098964,2012-12-04,"The paper starts with a generic discussion on the cloud application services and security concerns then expands the concepts with 3 main data management approaches of multi-tenant data management. After that paper describes reference architecture including standard cloud computing taxonomy for meta-data driven architecture approach and a conceptual data model to support the architecture. At the end it incorporates a comparison between green field application verses existing application migration assessment for target Software as a Service (SaaS) environment. WHAT ARE THE CLOUD APPLICATION (SAAS) SERVICES? Now a days the availability of reliable high speed broadband Internet access, service-oriented architectures (SOAs), and the economic management driving a transition toward the delivery of Cloud applications-of dedicated on-premises applications are “Cloud applications or &quot;Software as a Service (SaaS) applications deliver software as a service over the Internet, eliminating the need to install and run the application on the customer&apos;s own computers and simplifying maintenance and support, and equipped with decomposable applications, managed services, shared hardware / software /admin resources and Web-based services”. It’s a paradigm shift which imposes a new set of technical challenges. Existing applicatio",Cloud application services (SaaS)  – Multi-Tenant Data Architecture,,,,,core
21155452,2010-03-13,"Abstract — The present article dedicates itself to fuzzy modelling of data–inherent structures. In particular two main points are dealt with: the introduction of a fuzzy modelling framework and the elaboration of an automated, data–driven design strategy to model complex data–inherent structures within this framework. The innovation concerning the modelling framework lies in the fact that it is consistently built around a single, generic type of parametrical and convex membership function. In the first part of the article this essential building block will be defined and its assets and shortcomings will be discussed. The novelty regarding the automated, data–driven design strategy consist in the conservation of the modelling framework when modelling complex (nonconvex) data–inherent structures. Instead of applying current clustering methods the design strategy uses the inverse of the data structure in order to created a fuzzy model solely based on convex membership functions. Throughout the article the whole model design process is illustrated, section by section, with the help of an academic example",IFSA-EUSFLAT 2009 Parametric Fuzzy Modelling Framework for Complex Data–Inherent Structures,,,,,core
81999742,2012-12-31,"AbstractThe new possibility of accessing an infinite pool of computational resources at a drastically reduced price has made cloud computing popular. With the increase in its adoption and unpredictability of workload, cloud providers are faced with the problem of meeting their service level agreement (SLA) claims as demonstrated by large vendors such as Amazon and Google. Therefore, users of cloud resources are embracing the more promising cloud federation model to ensure service guarantees. Here, users have the option of selecting between multiple cloud providers and subsequently switching to a more reliable one in the event of a provider's inability to meet its SLA. In this paper, we propose a novel dynamic data-driven architecture capable of realising resource provision in a cloud federation with minimal SLA violations. We exemplify the approach with the aid of case studies to demonstrate its feasibility",A Dynamic Data-Driven Simulation Approach for Preventing Service Level Agreement Violations in Cloud Federation ,https://core.ac.uk/download/pdf/81999742.pdf,10.1016/j.procs.2012.04.126,Published by Elsevier B.V.,,core
23508407,2013-12-06,"Abstract. The performance of a supply chain depends critically on the coordinating actions and decisions undertaken by the trading partners. The sharing of product and process information plays a central role in the coordination and is a key driver for the success of the supply chain. In this paper we propose the concept of “Linked pedigrees ”- linked datasets, that enable the sharing of traceability information of products as they move along the supply chain. We present a distributed and decentralised, linked data driven architecture that consumes real time supply chain linked data to generate linked pedigrees. We then present a communication protocol to enable the exchange of linked pedigrees among trading partners. We exemplify the utility of linked pedigrees by illustrating examples from the perishable goods logistics supply chain. ",Consuming Linked data in Supply Chains: Enabling data visibility via Linked Pedigrees,,,,,core
146492122,2013-01-01T00:00:00,"Cloud computing urges the need for novel on-demand approaches, where the Quality of Service (QoS) requirements of cloud-based services can dynamically and adaptively evolve at runtime as Service Level Agreement (SLA) and environment changes. Given the unpredictable, dynamic and on-demand nature of the cloud, it would be unrealistic to assume that optimal QoS can be achieved at design time. As a result, there is an increasing need for dynamic and self- adaptive QoS optimization solutions to respond to dynamic changes in SLA and the environment. In this context, we posit that the challenge of self-adaptive QoS optimization encompasses two dynamics, which are related to QoS sensitivity and conflicting objectives at runtime. We propose novel design of a dynamic data-driven architecture for optimizing QoS influenced by those dynamics. The architecture leverages on DDDAS primitives by employing distributed simulations and symbiotic feedback loops, to dynamically adapt decision making metaheuristics, which optimizes for QoS tradeoffs in cloud-based systems. We use a scenario to exemplify and evaluate the approach",Dynamic QoS optimization architecture for cloud-based DDDAS,https://core.ac.uk/download/146492122.pdf,10.1016/j.procs.2013.05.357,'Elsevier BV',,core
21523681,2011-10-29,"A data driven multi-channel Time-to-Digital Converter (TDC) circuit with programmable resolution (25ps- 800ps bin) has been implemented in a 0.25um CMOS technology. An on-chip PLL is used for clock multiplication up to 320MHz from an external 40MHz reference. A 32 element Delay Locked Loop (DLL) performs time interpolation down to 98ps. Finally, finer time interpolation is obtained using an on-chip R-C delay line. Time measurements are processed and buffered in a data driven architecture based on time tags. This results in a highly flexible triggered or non-triggered TDC, which can be used in many different applications. I",A data driven high performance Time to Digital Converter,,,,,core
23454794,2013-11-28,"Abstract—Realistic design and evaluation of vehicular mobility has been particularly challenging due to a lack of large-scale real-world measurements in the research community. Current mobility models and simulators rely on artificial scenarios, random connectivity, and use small and biased samples. In this paper, we perform a combined study to learn the structure and connectivity of urban streets and modeling and characterization of vehicular traffic densities on them. Our dataset is a collection of 154 thousand routes and 12 million vehicular mobility images from 730 online web cameras located in four different cities. First, our study shows that driving routes and visiting locations of cities demonstrate power law distribution, indicating a planned or recently designed road infrastructure. Second, we represent cities by network graphs in which nodes are camera locations and edges are urban streets that connect the nodes. Such representation exhibits small world properties with short path lengths and large clustering coefficient. Third, traffic densities show 80 % temporal correlation during several hours of a day. Finally, modeling these densities against known theoretical distributions show less than 5 % deviation for Log-logistic and Gamma distribution. We believe this work will provide a much-needed contribution to the research community for realistic and data-driven design and evaluation of vehicular networks. I",Modeling and Characterization of Urban Vehicular Mobility using Web Cameras,,,,,core
34060958,2012,"Realistic design and evaluation of vehicular mobility has been particularly challenging due to a lack of large-scale real-world measurements in the research community. Current mobility models and simulators rely on artificial scenarios and use small and biased samples. To overcome these challenges, we introduce a novel framework for large-scale monitoring, analysis, modeling, and visualization of vehicular traffic using freely available online webcams. We follow a data-driven approach that examine six metropolitan regions' more than 800 locations and 25 million vehicular mobility records around the world. Initial analysis of traffic densities show 80% temporal correlation during various hours of a day. The modeling of empirical traffic densities against known theoretical models show less than 5% deviation for heavy-tailed distributions such as Weibull. We believe this framework and the dataset provide a much-needed contribution to the research community for realistic and data-driven design and evaluation of vehicular networks. © 2012 ACM",A framework for realistic vehicular network modeling using planet-scale public webcams,,10.1145/2307836.2307840,,,core
71295702,2013-12-01,"For the 12 GeV upgrade, the CLAS12 experiment has designed a Silicon Vertex Tracker (SVT) using single sided microstrip sensors fabricated by Hamamatsu. The sensors have graded angle design to minimize dead areas and a readout pitch of 156{micro}m, with intermediate strip. Double sided SVT module hosts three daisy-chained sensors on each side with a full strip length of 33 cm. There are 512 channels per module read out by four Fermilab Silicon Strip Readout (FSSR2) chips featuring data driven architecture, mounted on a rigid-flex hybrid. Modules are assembled on the barrel using unique cantilevered geometry to minimize the amount of material in the tracking volume. Design and performance of the SVT modules are presented, focusing on results of electrical measurements",Performance of the CLAS12 Silicon Vertex Tracker modules,,10.1016/j.nima.2013.06.077,Thomas Jefferson National Accelerator Facility (U.S.),,core
449399714,2009-01-01T00:00:00,,A Data-Driven Architecture for Remote Control of Sensors over a Wireless Sensor Network and the Internet,,10.1109/I-SPAN.2009.67,'Institute of Electrical and Electronics Engineers (IEEE)',,core
80234846,2010,"The results obtained by the Slim5 collaboration on a low material budget tracking silicon demonstrator put on a 12 GeV/c proton test beam at CERN are reported. Inside a reference telescope, two different and innovative detectors were placed for careful tests. The first was a 4k-Pixel Matrix of Deep N Well MAPS, developed in a 130 nm CMOS Technology, square pixels 50 pm wide, thinned down to 100 mu m and equipped with a digital sparsified readout running up to 50 MHz. The other was a high resistivity double sided silicon detector, 200 mu m thick, with short strips with 50 mu m pitch at 45 degrees angle to the detector's edge. The detectors were equipped with dedicated fast readout architectures performing on-chip data sparsification and providing the timing information for the hits. The criteria followed in the design of the pixel sensor and of the pixel readout architecture will be reviewed. Preliminary measurements of the pixel charge collection, track detection efficiencies and resolutions of pixel and strip sensors are discussed./// The data driven architecture of the readout chips has been fully exploited in the test beam by a data acquisition system able to collect on electronic board up to 2.5 Million events per second before triggering. By using a dedicated Associative Memory board, we were able to perform a level 1 trigger system, with minimal latency, identifying cleanly tracks traversing the detectors. System architecture and main performances are shown. (C) 2009 Elsevier B.V. All rights reserved",Beam-test results of 4k pixel CMOS MAPS and high resistivity striplet detectors equipped with digital sparsified readout in the Slim5 low mass silicon demonstrator,,10.1016/j.nima.2009.10.035,'Elsevier BV',,core
226645513,2012-01-01T00:00:00,"This paper proposes a fuzzy modelling and identification approach oriented to the design of a fault tolerant fuzzy controller for regulating both the pitch angle and the reference torque of a wind turbine benchmark. This strategy has been suggested for enhancing the regulator design that could represent an alternative to the standard switching controller,  already implemented in the wind turbine test system. The controller project requires the knowledge of a dynamic model of the wind turbine, which is achieved by means of a fuzzy modelling and identification scheme.
On the other hand, the proposed fuzzy controller structure is straightforward and easy to implement with respect to different strategies proposed in literature. Moreover, by exploiting the fuzzy identification procedure, the proposed strategy is also able to provide a fault tolerant controller. In this way, the fault tolerance properties are thus achieved by using a so called passive scheme. The results obtained with the designed fuzzy controller are compared to those of a switching controller already implemented for the wind turbine benchmark",Data-Driven Design of Fuzzy Logic Fault Tolerant Control for a Wind Turbine Benchmark,,10.3182/20120829-3-MX-2028.00036,'Elsevier BV',,core
55232848,2013-01-01T00:00:00,"The spread of active braking controllers on vehicles

with significant mechanical differences and on low-cost products asks for control design approaches which offer easy and fast calibration and re-tuning capabilities. This task is made difficult by the use of model-based control approaches which heavily rely on specific vehicle dynamics descriptions. To address these issues, this brief paper proposes a data-driven approach to active braking

control design, grounded on the virtual reference feedback tuning (VRFT) approach complemented with a data-driven nonlinear compensator. The effectiveness of the proposed approach is assessed both on a full-fledged multibody simulator and on a tire-in-the-loop experimental facility",Data-Driven Design of Braking Control Systems,,10.1109/TCST.2011.2171965,'Institute of Electrical and Electronics Engineers (IEEE)',,core
280937888,2013,,PromoterCAD: data-driven design of plant regulatory DNA,https://academic.oup.com/nar/article-pdf/41/W1/W569/16944755/gkt518.pdf,10.1093/nar/gkt518,Oxford University Press (OUP),,core
206573110,2013,,Automotive engine FDI by application of an automated model-based and data-driven design methodology,https://core.ac.uk/download/pdf/206573110.pdf,10.1016/j.conengprac.2012.12.006,Elsevier BV,,core
376532146,2012-01-01T08:00:00,"This presentation shows the way VCU Libraries leveraged data from heatmaps, user research and search logs to inform design decisions for its discovery search engine",Data-driven design decisions for discovery interfaces,,,VCU Scholars Compass,,core
226098658,2010-01-01T00:00:00,"The results obtained by the Slim5 collaboration on a low material budget tracking silicon demonstrator put on a 12 GeV/c proton test beam at CERN are reported. Inside a reference telescope, two different and innovative detectors were placed for careful tests. The first was a 4k-Pixel Matrix of Deep N Well MAPS, developed in a 130 nm CMOS Technology, square pixels 50 pm wide, thinned down to 100 mu m and equipped with a digital sparsified readout running up to 50 MHz. The other was a high resistivity double sided silicon detector, 200 mu m thick, with short strips with 50 mu m pitch at 45 degrees angle to the detector's edge. The detectors were equipped with dedicated fast readout architectures performing on-chip data sparsification and providing the timing information for the hits. The criteria followed in the design of the pixel sensor and of the pixel readout architecture will be reviewed. Preliminary measurements of the pixel charge collection, track detection efficiencies and resolutions of pixel and strip sensors are discussed./// The data driven architecture of the readout chips has been fully exploited in the test beam by a data acquisition system able to collect on electronic board up to 2.5 Million events per second before triggering. By using a dedicated Associative Memory board, we were able to perform a level 1 trigger system, with minimal latency, identifying cleanly tracks traversing the detectors. System architecture and main performances are shown. (C) 2009 Elsevier B.V. All rights reserved. RI Forti, Francesco/H-3035-2011; Neri, Nicola/G-3991-2012; Fabbri, Laura/H-3442-2012; Gabrielli, Alessandro/H-4931-2012; Villa, Mauro/C-9883-2009; Dalla Betta, Gian-Franco/I-1783-2012; Ratti, Lodovico/I-8836-2012; Giorgi, Filippo Maria/I-7602-201",Beam-test results of 4k pixel CMOS MAPS and high resistivity striplet detectors equipped with digital sparsified readout in the Slim5 low mass silicon demonstrator,,10.1016/j.nima.2009.10.035,'Elsevier BV',,core
357219647,2011-01-01T00:00:00,"Abstract Large telescopes are characterized by a high level of distribution of control-related tasks and will feature diverse data flow patterns and large ranges of sampling frequencies; there will often be no single, fixed serverclient relationship between the control tasks. The architecture is also challenged by the task of integrating heterogeneous subsystems which will be delivered by multiple different contractors. Due to the high number of distributed components, the control system needs to effectively detect errors and faults, impede their propagation, and accurately mitigate them in the shortest time possible, enabling the service to be restored. The presented Data-Driven Architecture is based on a decentralized approach with an end-to-end integration of disparate, independently-developed software components. These components employ a high-performance standardsbased communication middle-ware infrastructure, based on the Data Distribution Service. A set of rules and principles, based on JPL&apos;s State Analysis method and architecture, are use to constrain component-tocomponent interactions, where the Control System and System Under Control are clearly separated. State Analysis provides a model-based process for capturing system and software requirements and design, greatly reducing the gap between the requirements on software specified by systems engineers and the implementation by software engineers. The method and architecture has been field tested at the Very Large Telescope, where it has been integrated into an operational system",Towards a State Based Control Architecture for Large Telescopes: Laying a Foundation at the VLT,,,,,core
204059814,2012-12-31,"AbstractThe new possibility of accessing an infinite pool of computational resources at a drastically reduced price has made cloud computing popular. With the increase in its adoption and unpredictability of workload, cloud providers are faced with the problem of meeting their service level agreement (SLA) claims as demonstrated by large vendors such as Amazon and Google. Therefore, users of cloud resources are embracing the more promising cloud federation model to ensure service guarantees. Here, users have the option of selecting between multiple cloud providers and subsequently switching to a more reliable one in the event of a provider's inability to meet its SLA. In this paper, we propose a novel dynamic data-driven architecture capable of realising resource provision in a cloud federation with minimal SLA violations. We exemplify the approach with the aid of case studies to demonstrate its feasibility",A Dynamic Data-Driven Simulation Approach for Preventing Service Level Agreement Violations in Cloud Federation ,,10.1016/j.procs.2012.04.126,Published by Elsevier B.V.,,core
147980680,2012-03-15T13:02:20,This paper deals with direct data-driven design of model-reference controllers whose number of parameters is constrained. Input-output (I/O) sparse controllers are introduced and proposed as an alternative to low-order controller tuning. The optimal I/O sparse controller is shown to be never worse than the optimal low-order controller with the same number of parameters and a suited design procedure based on convex optimization is derived. The theoretical concepts are illustrated by means of a benchmark simulation example,Direct data-driven design of sparse controllers,,,"New York, IEEE",,core
17047387,2013-01-01T08:00:00,"High-performance, energy-efficient buildings require a different design approach than conventional buildings. Building performance predictions, use of simulations and modeling, research-based and data-driven design process are the key elements in the design of high-performance buildings. This article discusses relationships between building performance simulations and design, as well as the role of building performance research in architectural practice",Building Simulations and High-Performance Buildings Research: Use of Building Information Modeling (BIM) for Integrated Design and Analysis,,,SelectedWorks,,core
54849999,2013-01-01T00:00:00,"The Centre for Innovation in Information Visualization and Data-Driven Design (CIVDDD) is a Big Data research project collaboration funded by the Ontario Research Fund — Research Excellence (ORF-RE). Research collaborators in the project include York University, OCAD University, the University of Toronto, and private sector partners (PSPs) to develop the next generation of data discovery, design, analytics, and visualization techniques for new computational tools, representational strategies, and interfaces. As the preeminent research hub for information analytics and scientific visualization in Ontario, CIVDDD has fifteen research teams in the four theme areas of Bioinformatics and Medical Applications, Interactive Visualization, Textual Visualization, and Scientific Visualization. The Workshop included a brief overview of CIVDDD research by the Principal Investigator Dr. Amir Asif, followed by three CIVDDD team presentations and demonstrations related to CASCON 2013 themes. These included: Graph Analytics and Biological Network Structures (Big Data and Cloud Computing), Social Media Data Visualization (Social Computing), and Dynamic Carbon Mapping in Urban Environments (Mobile Computing). Each Workshop presentation contained academic researchers and their private sector partner research collaborators. Each presentation was followed by a demonstration of the research application or visualization, and Q&A. An open discussion concluded the Workshop",CIVDDD collaborative research in big data analytics and visualization,,,IBM Corp.,,core
41216047,2013-01-01T00:00:00,"Fault detection and isolation (FDI) in automotive diesel engines is important in order to achieve and guarantee low exhaust emissions, high vehicle uptime, and efficient repair and maintenance. This paper illustrates how a set of general methods for model-based sequential residual generation and data-driven statistical residual evaluation can be combined into an automated design methodology. The automated design methodology is then utilized to create a complete FDI-system for an automotive diesel engine. The performance of the obtained FDI-system is evaluated using measurements from road drives and engine test-bed experiments. The overall performance of the FDI-system is good in relation to the required design effort. In particular no specific tuning of the FDI-system, or any adaption of the design methodology, was needed. It is illustrated how estimations of the statistical powers of the fault detection tests in the FDI-system can be used to further increase the performance, specifically in terms of fault isolability.Funding Agencies|Scania||VINNOVA (Swedish Governmental Agency for Innovation Systems)||</p",Automotive engine FDI by application of an automated model-based and data-driven design methodology,,10.1016/j.conengprac.2012.12.006,'Elsevier BV',,core
155685713,2012,"In this paper, a scheme for the design of a fault-tolerant control architecture using process data is proposed, whose core is an observer-based realization of the Youla parameterization of all stabilization controllers. The realization of a fault-tolerant control scheme based on the proposed architecture is demonstrated on a benchmark process. ? 2012 IFAC.EI",Data-driven design of fault-tolerant control systems,,10.3182/20120829-3-MX-2028.00125,,,core
22561923,2013-07-16,"Advances in data mining and knowledge discovery have transformed the way Web sites are designed. However, while visual presentation is an intrinsic part of the Web, traditional data mining techniques ignore render-time page structures and their attributes. This paper introduces design mining for the Web: using knowledge discovery techniques to understand design demographics, automate design curation, and support data-driven design tools. This idea is manifest in Webzeitgeist, a platform for large-scale design mining comprising a repository of over 100,000 Web pages and 100 million design elements. This paper describes the principles driving design mining, the implementation of the Webzeitgeist architecture, and the new class of data-driven design applications it enables",Author Keywords,,,,,core
304316572,2010,"The results obtained by the Slim5 collaboration on a low material budget tracking silicon demonstrator put on a 12 GeV/c proton test beam at CERN are reported. Inside a reference telescope, two different and innovative detectors were placed for careful tests. The first was a 4k-Pixel Matrix of Deep N Well MAPS, developed in a 130 nm CMOS Technology, square pixels 50um wide, thinned down to 100um and equipped with a digital sparsified readout running up to 50 MHz. The other was a high resistivity double sided silicon detector, 200um thick, with short strips with 50um pitch at 45 degree angle to the detector's edge. The detectors were equipped with dedicated fast readout architectures performing on-chip data sparsification and providing the timing information for the hits. The criteria followed in the design of the pixel sensor and of the pixel readout architecture will be reviewed. Preliminary measurements of the pixel charge collection, track detection efficiencies and resolutions of pixel and strip sensors are discussed.

The data driven architecture of the readout chips has been fully exploited in the test beam by a data acquisition system able to collect on electronic board up to 2.5 Million events per second before triggering. By using a dedicated Associative Memory board, we were able to perform a level 1 trigger system, with minimal latency, identifying cleanly tracks traversing the detectors. System architecture and main performances are shown",Beam-test results of 4k pixel CMOS MAPS and high resistivity striplet detectors equipped with digital sparsified readout in the Slim5 low mass silicon demonstrator,,10.1016/j.nima.2009.10.035,,,core
244583715,2013,,PromoterCAD: data-driven design of plant regulatory DNA,https://academic.oup.com/nar/article-pdf/41/W1/W569/16944755/gkt518.pdf,10.1093/nar/gkt518,Oxford University Press (OUP),,core
154879431,2012-01-01T00:00:00,Engineering and Applied Science,Data-Driven Design of a Dexterous Robotic Microsurgery System,,10.1115/1.4026758.,'ASME International',"[{'title': 'Journal of Medical Devices', 'identifiers': ['1932-6181', 'issn:1932-6181']}]",core
144704777,2010-04-10,"ABSTRACT

The paper presents a framework for a distributed medical system meant to bring a modern approach and enhance the quality of medical services offered to patients with chronic cardio-vascular diseases, via the latest IT&C technologies. The proposed system provides online interaction between the main actors of a medical system: patients, doctors, medical entities (e.g. hospitals, clinics) and medical authorities (e.g. social services). With the aid of widely accepted medical standards, the system supplies storage for medical records and offers services for data integration between different kinds of healthcare applications and entities. The proposed ontological approach allows for the interchange of medical knowledge and best practices with conceptually organized patients’ records. The proposed solution allows computer assisted diagnoses and multi-criteria medical data analysis, with the possible extent of building a data warehouse for complex medical data mining",BRAIN Journal -  A Proposed Data Driven Architecture for Cardiology Network Application,,10.5281/zenodo.1036373,,,core
55224966,2011-01-01T00:00:00,,Noniterative data-driven design of multivariable controllers,,10.1109/cdc.2011.6160388,,,core
19090132,2013-12-16T19:55:35,"textPre-tests and post tests were used to assess the effectiveness of an engineering high school unit on experimental design and data driven design.  The engineering data acquisition unit examined in this report used project based learning to teach the design of an engineering experiment and data driven design as part of the engineering design process.  The project consists of the design of a building that can safely withstand an earthquake.  Students construct, test and collect data on baseline buildings, with and without load using a shaker table and data acquisition.  Students' then design experiments to evaluate design modifications that will meet the customer's needs.  Overall, although the number of participants was limited, the survey instruments indicated that understanding of experimental design improved among high school students participating in the unit.  Based on this pilot implementation of survey instruments, some of the survey questions were clarified.Science and Mathematics Educatio",Design of an engineering experiment and data driven design in secondary education,https://core.ac.uk/download/19090132.pdf,,,,core
480800086,2012-05-01T07:00:00,"Asynchronous design is an alternative to the more widely used synchronous design which allows for the elimination of a global clock network and associated design issues such as clock skew. Uncle is a toolflow that provides automated assistance for transforming a synchronous system specified in Verilog RTL to an asynchronous system. With assistance from Uncle an asynchronous delay-insensitive microprocessor is implemented using NULL Convention Logic (NCL) and verified to function properly. An advantage of asynchronous design is that it can be data-driven. Data-driven design allows specific blocks of logic to only be active when they are needed. Data-driven design is implemented to bypass parts of the asynchronous microprocessor. These parts included the ALU and the peripheral hardware multiplier. This resulted in a reduction of total power consumed and an increase in speed. Overall, it was concluded that asynchronous design with Uncle was a viable alternative to synchronous design",Asynchronous Design Investigation for a 16-Bit Microprocessor,https://core.ac.uk/download/480800086.pdf,,Scholars Junction,,core
54849988,2011-01-01T00:00:00,"OCAD University's strategic plan Living in the Age of Imagination places a priority on focusing the lenses of art, design and media on contemporary issues and practices outside of the traditional boundaries of art and design. This has resulted in a myriad of innovative curriculum and research initiatives of specific relevance to HCI. For example in concert with led partner York University, the University of Toronto and a set of industrial partners OCAD University has created the Centre for Innovation in Information Visualization and Data Driven Design (CIV/DDD), a research hub for the development of next-generation data visualization techniques and their underlying information processing and communication technologies (ICT). This centre is the focus of this talk. The idea was that by bringing an unprecedented number of interdisciplinary artists, designers, media makers, humanist analysts and social scientists into the research partnership we would develop new paradigms of data enquiry, user-centered visualization models, and information processing and display technologies",Artists & designers: An experiment in data visualization,,10.1145/2069618.2069651,'Association for Computing Machinery (ACM)',,core
54699645,2012-01-01T00:00:00,"This paper proposes a fuzzy modelling and identification approach oriented to the design of a fault tolerant fuzzy controller for regulating both the pitch angle and the reference torque of a wind turbine benchmark. This strategy has been suggested for enhancing the regulator design that could represent an alternative to the standard switching controller, already implemented in the wind turbine test system. The controller project requires the knowledge of a dynamic model of the wind turbine, which is achieved by means of a fuzzy modelling and identification scheme. On the other hand, the proposed fuzzy controller structure is straightforward and easy to implement with respect to different strategies proposed in literature. Moreover, by exploiting the fuzzy identification procedure, the proposed strategy is also able to provide a fault tolerant controller. In this way, the fault tolerance properties are thus achieved by using a so–called passive scheme. The results obtained with the designed fuzzy controller are compared to those of a switching controller already implemented for the wind turbine benchmark",Data–Driven Design of Fuzzy Logic Fault Tolerant Control for a Wind Turbine Benchmark,,10.3182/20120829-3-MX-2028.00036,'Elsevier BV',,core
188077957,2012-05-04T07:00:00,"There is a change in the paradigm of architecture and the approach toward the development of forms. A change that strives to get past the shallow ascetic of Post modernism and its view of architects as the generators of forms whose priority is appearance not performance. This change continues the movement away from the shallow facade of Post modernism toward a priority of performance and accuracy in architecture. By this, I mean an architecture that serves its users better, and attempts to accurately address the issues & needs of the user.
While performance based design is not a new concept, it can be applied in a way never possible before. The age of computation in architecture and its part that it plays in the design process is continually changing. It continues to become less a tool used to draw and more a integral part in the development of design and the direct form of architecture. With the quick implementation of these tools into specific bits and pieces of the design process there is still a gap between its current uses and its potential. This potential is what this project strives to explore. In a world moving away from shallow ascetic and toward performative space, how can architects produce a more accurate & performative architecture? The answer lies in the information we have access to and what it can tell us about our users and our context. For the better we know our users and context, the better we are poised to produce a quality architectural product",Data Driven Architecture,https://core.ac.uk/download/188077957.pdf,,DigitalCommons@University of Nebraska - Lincoln,,core
226045838,2010,"The results obtained by the Slim5 collaboration on a low material budget tracking silicon demonstrator put on a 12 GeV/c proton test beam at CERN are reported. Inside a reference telescope, two different and innovative detectors were placed for careful tests. The first was a 4k-Pixel Matrix of Deep N Well MAPS, developed in a 130 nm CMOS Technology, square pixels 50um wide, thinned down to 100um and equipped with a digital sparsified readout running up to 50 MHz. The other was a high resistivity double sided silicon detector, 200um thick, with short strips with 50um pitch at 45∘ angle to the detector's edge. The detectors were equipped with dedicated fast readout architectures performing on-chip data sparsification and providing the timing information for the hits. The criteria followed in the design of the pixel sensor and of the pixel readout architecture will be reviewed. Preliminary measurements of the pixel charge collection, track detection efficiencies and resolutions of pixel and strip sensors are discussed.

The data driven architecture of the readout chips has been fully exploited in the test beam by a data acquisition system able to collect on electronic board up to 2.5 Million events per second before triggering. By using a dedicated Associative Memory board, we were able to perform a level 1 trigger system, with minimal latency, identifying cleanly tracks traversing the detectors. System architecture and main performances are shown",Beam-test results of 4k pixel CMOS MAPS and high resistivity striplet detectors equipped with digital sparsified readout in the Slim5 low mass silicon demonstrator,,10.1016/j.nima.2009.10.035,,,core
155600610,2011,"Motivated by the increasing needs in the process industry for designing fault tolerant feedback control systems based on process data, data-driven design of feedback control systems with embedded residual generation is addressed. For this purpose, an extended internal model control (EIMC) structure aiming at accessing the residuals embedded in control loop is first proposed. Based on the identification of the so-called parity subspace and a well-established mapping between the parity vector and the solution of the Luenberger equations, a direct design scheme of EIMC from process data is developed. The achieved results are illustrated by an academic example. ? 2011 IEEE.EI",An approach to data-driven design of feedback control systems with embedded residual generation,,10.1109/CDC.2011.6160771,,,core
144864726,2010-04-15,"ABSTRACT

 

The paper presents a framework for a distributed medical system meant to bring a modern approach and inhance the quality of medical services offered to chronicle patients with cardio-vascular diseases, through the latest IT&C technologies. The proposed system provides online interaction between the main actors of a medical system: patients, doctors, medical entities (e.g. hospitals, clinics) and medical authorities (e.g. social services). With the aid of widely accepted medical standards, the system supplies storage for medical records and offers services for data integration between different kinds of healthcare applications and entities. The proposed ontological approach allows interchange of medical knowledge and best practices with conceptually organized patients’ records. The proposed solution allows computer assisted diagnoses and multi-criteria medical data analysis, with the possible extent of building a data warehouse for complex medical data mining",BRAIN Journal - A Proposed Data Driven Architecture for Cardiology Network Application,,10.5281/zenodo.1012250,,,core
395007099,2014-01-01T00:00:00,"Structural health monitoring (SHM) systems provide real-time damage and performance information for civil, aerospace, and other high-capital or life-safety critical structures. Conventional data processing involves pre-processing and extraction of low-dimensional features from in situ time series measurements. The features are then input to a statistical pattern recognition algorithm to perform the relevant classification or regression task necessary to facilitate decisions by the SHM system. Traditional design of signal processing and feature extraction algorithms can be an expensive and time-consuming process requiring extensive system knowledge and domain expertise. Genetic programming, a heuristic program search method from evolutionary computation, was recently adapted by the authors to perform automated, data-driven design of signal processing and feature extraction algorithms for statistical pattern recognition applications. The proposed method, called Autofead, is particularly suitable to handle the challenges inherent in algorithm design for SHM problems where the manifestation of damage in structural response measurements is often unclear or unknown. Autofead mines a training database of response measurements to discover information-rich features specific to the problem at hand. This study provides experimental validation on three SHM applications including ultrasonic damage detection, bearing damage classification for rotating machinery, and vibration-based structural health monitoring. Performance comparisons with common feature choices for each problem area are provided demonstrating the versatility of Autofead to produce significant algorithm improvements on a wide range of problems. © 2014 IOP Publishing Ltd",Structural health monitoring feature design by genetic programming,,,"eScholarship, University of California",,core
290278714,2014,"The paper describes a software methodology for the graphics pipeline extension. It is argued that common modern visualization techniques do not satisfy current visualization software development requirements adequately enough. The proposed approach is based on specialized formal language called visualization algebra. By invoking data-driven design principles inherited from the existing programmable pipeline technology, the technique has a potential to reduce visualization software development costs and build a way for further computer graphics pipeline automation",Data-Driven Method for High Level Rendering Pipeline Construction,,,Springer International Publishing Switzerland,,core
28951217,2014-10-01T14:27:41,"Thumb interaction is a primary technique used to operate small handheld devices such as smartphones. Despite the different techniques involved in operating a handheld device compared to a personal computer, the keyboard layouts for both devices are similar. A handheld device keyboard that considers the physical capabilities of the thumb may improve user experience. We developed and applied a design evaluation tool for different geometries of the QWERTY keyboard using a performance evaluation model. The model utilizes previously collected data on thumb motor performance and posture for different tap locations and thumb movement directions. We calculated a performance index (PITOT, 0 is worst and 2 is best) for 663 designs consisting in different combinations of three variables: the keyboard's radius of curvature (R) (mm), orientation (O) (°), and vertical location on the screen (L). The current standard keyboard performed poorly (PITOT = 0.28) compared to other designs considered. Keyboard location (L) contributed to the greatest variability in performance out of the three design variables, suggesting that designers should modify this variable first. Performance was greatest for designs in the middle keyboard location. In addition, having a slightly upward curve (R = −20 mm) and orientated perpendicular to the thumb's long axis (O = −20°) improved performance to PITOT = 1.97. Poorest performances were associated with placement of the keyboard's spacebar in the bottom right corner of the screen (e.g., the worst was for R = 20 mm, O = 40°, L = Bottom (PITOT = 0.09)). While this evaluation tool can be used in the design process as an ergonomic reference to promote user motor performance, other design variables such as visual access and usability still remain unexplored",A Data-Driven Design Evaluation Tool for Handheld Device Soft Keyboards,https://core.ac.uk/download/28951217.pdf,10.1371/journal.pone.0107070.,'Public Library of Science (PLoS)',"[{'title': 'PLoS ONE', 'identifiers': ['issn:1932-6203', '1932-6203']}]",core
23359381,2012,"Medical workflow during doctor-patient consultations is rapidly changing due to the introduction of technologies such as electronic medical records (EMR). This transition has a significant impact on the quality of doctor-patient interactions, resulting in increased cognitive load on doctors, and lowered patient satisfaction. The UCSD DCOG-HCI lab at UCSD is developing a novel interactive medical workspace using “off-the-shelf ” tools such as the Kinect and commercially available projectors and webcams. The goal is to create a workspace that seamlessly combines the interaction of physical and digital documents on a shared desktop, enables collaboration between the doctor and patient, and aids in patient engagement and education. To ensure a data-driven design, we are also developing a separate tool to aid in recording, analysis and annotation of rich multimodal data. Data annotation is labor-intensive and time consuming. Simplifying and automating this task with supportive technology will allow for easier analysis and a quicker turnaround of design iterations",Augmenting Medical Workspaces with Kinect-based Interfaces,,,,,core
244841519,2013,,PromoterCAD: data-driven design of plant regulatory DNA,https://academic.oup.com/nar/article-pdf/41/W1/W569/16944755/gkt518.pdf,10.1093/nar/gkt518,Oxford University Press (OUP),,core
264194994,2013,,PromoterCAD: data-driven design of plant regulatory DNA,https://academic.oup.com/nar/article-pdf/41/W1/W569/16944755/gkt518.pdf,10.1093/nar/gkt518,Oxford University Press (OUP),,core
50696713,2014-05,,Data‐driven design for learning:multimodality as a service,https://core.ac.uk/download/pdf/50696713.pdf,,,,core
155585214,2010,"Net primary productivity (NPP) estimation is an important study field of global change and terrestrial ecosystem. Here, we present an integrated modeling and analysis framework for researching climate change using NPP as an ecosystem indicator. It&apos;s brings together remote sensing, GIS and an ecosystem simulation model without requiring users to have any knowledge of any other specific software. Satellite data driven architecture can play a positive role in understanding the climate change and carbon cycles from regional to global scales. The benefit of the framework is that it provides complete spatial coverage and high temporal resolution, versus plot samples from which it may be difficult to provide an overall assessment for large-scale study. Recent advances in service-oriented architectures are allowing us to share of model results by geospatial services and create distributed applications needed for the collaborative research. Multi-layer approaches allow the framework more flexible and easy to extend. New datasets and models can be integrated for use in the development of new applications. A preliminary system based on the framework was carried out for monitoring the dynamic changes of terrestrial ecosystem NPP in China. State-of-the art processing algorithms was developed based on light-use efficiency model (Carnegie-Ames-Stanford Approach (CASA) model). Fraction of photosynthetically active radiation absorbed by vegetation (FPAR) is a linear function of Normalized Difference Vegetation Index (NDVI) and Simple Ratio vegetation index (SR). We combined the method of NDVI and SR together to compute the FPAR of China. And then, the NPP time-series of Chinese terrestrial vegetation is built. The System is capable of querying, retrieving, and visualizing datasets with heterogeneous formats and the spatio-temporal analysis revealed the relationship between NPP and climatic change in China. These results supported national trends of NPP in relation to lag effects of climate.Computer Science, Information SystemsEngineering, Electrical &amp;    ElectronicEICPCI-S(ISTP)",An Integrated Spatio-Temporal Modeling and Analysis Framework for   Climate Change Research,,10.1109/GEOINFORMATICS.2010.5567735,,,core
241882313,2014-01-01T00:00:00,,Data-driven Design of Fault Diagnosis and Fault-tolerant Control Systems,,10.1007/978-1-4471-6410-4,'Springer Science and Business Media LLC',,core
51286581,2012-01-01T08:00:00,"This presentation shows the way VCU Libraries leveraged data from heatmaps, user research and search logs to inform design decisions for its discovery search engine",Data-driven design decisions for discovery interfaces,https://core.ac.uk/download/51286581.pdf,,VCU Scholars Compass,,core
17264640,2012-05-04T07:00:00,"There is a change in the paradigm of architecture and the approach toward the development of forms. A change that strives to get past the shallow ascetic of Post modernism and its view of architects as the generators of forms whose priority is appearance not performance. This change continues the movement away from the shallow facade of Post modernism toward a priority of performance and accuracy in architecture. By this, I mean an architecture that serves its users better, and attempts to accurately address the issues & needs of the user.
While performance based design is not a new concept, it can be applied in a way never possible before. The age of computation in architecture and its part that it plays in the design process is continually changing. It continues to become less a tool used to draw and more a integral part in the development of design and the direct form of architecture. With the quick implementation of these tools into specific bits and pieces of the design process there is still a gap between its current uses and its potential. This potential is what this project strives to explore. In a world moving away from shallow ascetic and toward performative space, how can architects produce a more accurate & performative architecture? The answer lies in the information we have access to and what it can tell us about our users and our context. For the better we know our users and context, the better we are poised to produce a quality architectural product",Data Driven Architecture,https://core.ac.uk/download/17264640.pdf,,DigitalCommons@University of Nebraska - Lincoln,,core
153352633,2014-07-11,"We present a framework to design an orthogonal wavelet with compact support and vanishing moments, tuned to a given application. This is achieved by optimizing a criterion, such that a prototype signal, which is characteristic for the application, becomes sparse in the wavelet domain. This approach is beneficial for compression and detection purposes. A parameterization is developed for which orthogonality and compact support are built in, and in terms of which we can express the vanishing moment conditions conveniently. The ap- proach is developed for critically sampled wavelet transforms as well as for the stationary wavelet transform. Several examples illustrate the methods",Data driven design of an orthogonal wavelet with vanishing moments,,,,,core
79323981,2014-11-30,,Introduction: Data-Driven Design to Production and Operation,,,"TU Delft, Stichting Footprint",,core
90457418,2014-01-01T00:00:00Z,"Fault detection is fundamental to many industrial applications. With the development of system complexity, the number of sensors is increasing, which makes traditional fault detection methods lose efficiency. Metric learning is an efficient way to build the relationship between feature vectors with the categories of instances. In this paper, we firstly propose a metric learning-based fault detection framework in fault detection. Meanwhile, a novel feature extraction method based  on wavelet transform is used to obtain the feature vector from detection signals. Experiments on Tennessee Eastman (TE)  chemical process datasets demonstrate that the proposed method has a better performance when comparing with existing methods, for example, principal component analysis (PCA) and fisher discriminate analysis (FDA)",Metric Learning Method Aided Data-Driven Design of Fault Detection Systems,,10.1155/2014/974758,Hindawi Limited,"[{'title': None, 'identifiers': ['issn:1024-123X', '1024-123x', '1563-5147', 'issn:1563-5147']}]",core
155427063,2014,"In this paper, regarding the observer form of the well-known Youla parameterization, the controller design and optimization are exhibited with an integrated residual access. To better reveal this philosophy, the feedback control loop is interpreted on the basis of the observer-based residual generator. The next main attention is drawn to the generation of residuals, the design of a deadbeat controller for system stabilization both in the data-driven environment, and later the optimal adaptive realization of a dynamic system that translates residuals into compensatory control inputs to meet certain performance specifications. Towards these goals, numerical algorithms are summarized, and for the issues of controller optimization, the reinforcement learning algorithm is introduced using only measured input-output and residual signals. In addition, the effectiveness of developed schemes for industrial applications is also illustrated by experimental studies on a laboratory continuous stirred tank heater (CSTH) process.http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcApp=PARTNER_APP&SrcAuth=LinksAMR&KeyUT=WOS:000337123000063&DestLinkType=FullRecord&DestApp=ALL_WOS&UsrCustomerID=8e1609b174ce4e31116a60747a720701Automation &amp; Control SystemsEngineering, Electrical &amp; ElectronicInstruments &amp; InstrumentationSCI(E)EI6ARTICLEyong.zhang@pku.edu.cn; yy@mech.pku.edu.cn; steven.ding@uni-due.de;   linlin.li@uni-due.de116409-64176",Data-Driven Design and Optimization of Feedback Control Systems for   Industrial Applications,,10.1109/TIE.2014.2301757,ieee transactions on industrial electronics,"[{'title': None, 'identifiers': ['issn:0278-0046', '0278-0046', '1557-9948', 'issn:1557-9948']}]",core
225887125,2012-01-01T00:00:00,"Published version of an article from the journal: Mathematical Problems in Engineering. Also available from the publisher:http://dx.doi.org/10.1155/2012/832836This paper presents an approach for data-driven design of fault diagnosis system. The proposed fault diagnosis scheme consists of an adaptive residual generator and a bank of isolation observers, whose parameters are directly identified from the process data without identification of complete process model. To deal with normal variations in the process, the parameters of residual generator are online updated by standard adaptive technique to achieve reliable fault detection performance. After a fault is successfully detected, the isolation scheme will be activated, in which each isolation observer serves as an indicator corresponding to occurrence of a particular type of fault in the process. The thresholds can be determined analytically or through estimating the probability density function of related variables. To illustrate the performance of proposed fault diagnosis approach, a laboratory-scale three-tank system is finally utilized. It shows that the proposed data-driven scheme is efficient to deal with applications, whose analytical process models are unavailable. Especially, for the large-scale plants, whose physical models are generally difficult to be established, the proposed approach may offer an effective alternative solution for process monitoring",Data-driven adaptive observer for fault diagnosis,https://core.ac.uk/download/225887125.pdf,10.1155/2012/832836,'Hindawi Limited',,core
34060971,2012,"Realistic design and evaluation of vehicular mobility has been particularly challenging due to a lack of large-scale real-world measurements in the research community. Current mobility models and simulators rely on artificial scenarios, random connectivity, and use small and biased samples. In this paper, we perform a combined study to learn the structure and connectivity of urban streets and modeling and characterization of vehicular traffic densities on them. Our dataset is a collection of 154 thousand routes and 12 million vehicular mobility images from 730 online web cameras located in four different cities. First, our study shows that driving routes and visiting locations of cities demonstrate power law distribution, indicating a planned or recently designed road infrastructure. Second, we represent cities by network graphs in which nodes are camera locations and edges are urban streets that connect the nodes. Such representation exhibits small world properties with short path lengths and large clustering coefficient. Third, traffic densities show 80% temporal correlation during several hours of a day. Finally, modeling these densities against known theoretical distributions show less than 5% deviation for Log-logistic and Gamma distribution. We believe this work will provide a much-needed contribution to the research community for realistic and data-driven design and evaluation of vehicular networks. © 2012 IEEE",Modeling and Characterization of Urban Streets' Vehicular Mobility using Web Cameras,,10.1109/INFCOMW.2012.6193503,,"[{'title': None, 'identifiers': ['2159-4228', 'issn:2159-4228']}]",core
245041180,2013,,PromoterCAD: data-driven design of plant regulatory DNA,https://academic.oup.com/nar/article-pdf/41/W1/W569/16944755/gkt518.pdf,10.1093/nar/gkt518,Oxford University Press (OUP),,core
455389799,2013-01-01T00:00:00,,Data-driven design process in adoption of marking menus for large scale software,,10.1145/2468356.2468757,'Association for Computing Machinery (ACM)',,core
55217591,2012-01-01T00:00:00,"This paper presents an extension of the Virtual Reference Feedback Tuning (VRFT) methodology dedicated to linear time-delay systems with known delay and unknown dynamics. The standard VRFT is not well suited for systems with dominant time-delay as it yields high order controllers. The proposed direct approach, relying on a Smith Predictor structure, guarantees the same level of performance as the standard VRFT but with lower order controllers. The joint direct data-driven design of the controller and the predictor is facilitated by the introduction of an ad-hoc optimization initialization. Effectiveness and robustness to uncertainty in the time-delay estimation are shown in a vehicle dynamics control problem",Direct Data Driven Control of Linear Time-Delay Systems,,10.1002/asjc.387,'Wiley',,core
23261933,2013-09-30,"Advances in data mining and knowledge discovery have transformed the way Web sites are designed. However, while visual presentation is an intrinsic part of the Web, traditional data mining techniques ignore render-time page structures and their attributes. This paper introduces design mining for the Web: using knowledge discovery techniques to understand design demographics, automate design curation, and support data-driven design tools. This idea is manifest in Webzeitgeist, a platform for large-scale design mining comprising a repository of over 100,000 Web pages and 100 million design elements. This paper describes the principles driving design mining, the implementation of the Webzeitgeist architecture, and the new class of data-driven design applications it enables",Author Keywords,,,,,core
23273862,2013-10-01,"Large telescopes are characterized by a high level of distribution of control-related tasks and will feature diverse data flow patterns and large ranges of sampling frequencies; there will often be no single, fixed serverclient relationship between the control tasks. The architecture is also challenged by the task of integrating heterogeneous subsystems which will be delivered by multiple different contractors. Due to the high number of distributed components, the control system needs to effectively detect errors and faults, impede their propagation, and accurately mitigate them in the shortest time possible, enabling the service to be restored. The presented Data-Driven Architecture is based on a decentralized approach with an end-to-end integration o",TOWARDS A STATE BASED CONTROL ARCHITECTURE FOR LARGE TELESCOPES: LAYING A FOUNDATION AT THE VLT,,,,,core
100142548,2014-12-04,Automotive engine FDI by application of an automated model-based and data-driven design methodolog,Automotive engine fdi by application of an automated model-based and data-driven design methodology. Control Engineering Practice,,,,,core
148452216,2013-01-01T00:00:00,"Fault detection and isolation (FDI) in automotive diesel engines is important in order to achieve and guarantee low exhaust emissions, high vehicle uptime, and efficient repair and maintenance. This paper illustrates how a set of general methods for model-based sequential residual generation and data-driven statistical residual evaluation can be combined into an automated design methodology. The automated design methodology is then utilized to create a complete FDI-system for an automotive diesel engine. The performance of the obtained FDI-system is evaluated using measurements from road drives and engine test-bed experiments. The overall performance of the FDI-system is good in relation to the required design effort. In particular no specific tuning of the FDI-system, or any adaption of the design methodology, was needed. It is illustrated how estimations of the statistical powers of the fault detection tests in the FDI-system can be used to further increase the performance, specifically in terms of fault isolability.Funding Agencies|Scania||VINNOVA (Swedish Governmental Agency for Innovation Systems)||</p",Automotive engine FDI by application of an automated model-based and data-driven design methodology,,10.1016/j.conengprac.2012.12.006,'Elsevier BV',,core
371941427,2014-01-01T00:00:00,,Data-Driven Design of Sliding Mode Controllers for Ferroelectric Actuators,,10.3182/20140824-6-ZA-1003.01034,'Elsevier BV',,core
30912643,2012-01-01T00:00:00,"This paper presents an approach for data-driven design of fault diagnosis system. The proposed fault diagnosis scheme consists of an adaptive residual generator and a bank of isolation observers, whose parameters are directly identified from the process data without identification of complete process model. To deal with normal variations in the process, the parameters of residual generator are online updated by standard adaptive technique to achieve reliable fault detection performance. After a fault is successfully detected, the isolation scheme will be activated, in which each isolation observer serves as an indicator corresponding to occurrence of a particular type of fault in the process. The thresholds can be determined analytically or through estimating the probability density function of related variables. To illustrate the performance of proposed fault diagnosis approach, a laboratory-scale three-tank system is finally utilized. It shows that the proposed data-driven scheme is efficient to deal with applications, whose analytical process models are unavailable. Especially, for the large-scale plants, whose physical models are generally difficult to be established, the proposed approach may offer an effective alternative solution for process monitoring",Data-driven adaptive observer for fault diagnosis,https://core.ac.uk/download/30912643.pdf,,'Hindawi Limited',,core
54699643,2012-01-01T00:00:00,"This paper proposes a fuzzy modelling and identification approach oriented to the
design of a PI fuzzy controller for regulating both the pitch angle and the reference torque of a
wind turbine model. This strategy has been suggested for enhancing the regulator design that
could represent an alternative to the standard switching controller, already implemented in the
wind turbine test system. The controller project requires the knowledge of the dynamic model
of the wind turbine, which is achieved by means of a fuzzy modelling and identification scheme.
On the other hand, the proposed PI fuzzy controller structure is straightforward and easy to
implement with respect to different strategies proposed in literature. Moreover, by means of
these design procedures, the proposed strategy is also able to provide a robust and reliable
controller. The results obtained with the designed PI fuzzy controller are compared to those of
a switching controller already implemented for the wind turbine benchmark",Data-Driven Design of a PI Fuzzy Controller for a Wind Turbine Simulated Model,,10.3182/20120328-3-IT-3014.00113,'Elsevier BV',,core
364994533,2012-01-01T00:00:00,,Data-Driven Design of Model-based Fault Diagnosis Systems,,10.3182/20120710-4-SG-2026.00105,'Elsevier BV',,core
369365279,2012-01-01T00:00:00,,Data—Driven Design of a PI Fuzzy Controller for a Wind Turbine Simulated Model,,10.3182/20120328-3-IT-3014.00113,'Elsevier BV',,core
21340961,2010-12-27,"Abstract. In this article, we discuss the motivation for a novel style of tutorial dialogue system that emphasizes reflection in a simulation based exploratory learning environment called CyclePad, which was developed in order to offer students practice at design and optimization of thermodynamic cycles. We argue that while typical forms of exploration support offered in simulation based learning environments are meant to encourage the development of good exploration process skills, the instantiation of these typical forms of support in CyclePad are not sufficient, primarily because students don’t choose to use them. We present a preliminary cognitive task analysis of design exploration tasks using CyclePad. Using this cognitive task analysis, we analyze data collected in two waves of formal data collection. Finally, we conclude with some system desiderata derived from our analysis as well as discussion of directions for continued experimental investigations related to tutor style",CycleTalk: Data driven design of support for simulation based learning,,,,,core
79322413,2014-04-22,"Data-driven architectural production and operation as explored within Hyperbody rely heavily on system thinking implying that all parts of a system are to be understood in relation to each other. These relations are increasingly established bi-directionally so that data-driven architecture is not only produced (created or designed and fabricated) by digital means but also is incorporating digital, sensing-actuating mechanisms that enable real-time interaction with (natural and artificial) environments and users. Data-driven architectural production and operation exploit, in this context, the generative potential of process-oriented approaches wherein interactions between (human and non-human) agents and their (virtual and physical) environments have emergent properties that enable proliferation of hybrid architectural ecologies",Data-driven architectural production and operation,,,Bertalanffy Center for the Study of Systems Science (BCSSS),,core
103951514,2011,"In the present paper we focus on demonstrating the use of design optimization for the constitutive characterization of anisotropic material systems such as polymer matrix compos-ites, with or without damage. All approaches are based on the availability of experimental data originating from mechatronic material testing systems that can expose specimens to multidi-mensional loading paths and can automate the acquisition of data representing the excitation and response behavior of the specimens involved. Material characterization is achieved by minimizing the difference between experimentally measured and analytically computed system responses as described by strain fields and surface strain energy densities. A one dimensional model is presented first to elucidate the design optimization for the general non-linear constitutive response. Small and large strain formulations based on strain energy density decomposi-tions are developed and utilized for determining the constitutive behavior of composite materials. Examples based on both syn-thetic and actual data demonstrate the successful application of design optimization for constitutive characterization",Overview of constitutive response characterization for composite materials via data-driven design optimization,,,,,core
224448455,2014-01-01T00:00:00,"Both inside corporations and in self-organized online communities, globally distributed groups of thousands of people now collaborate together on design projects over the Internet. This changes the nature of product design, creating potential for new levels of innovation and product development speed\textemdash for example, developing vehicle designs in less than four months, or implementing new business models for urban revitalization in less than a year. However, the plethora of information created by these communities comes with a price: individuals cannot process all of it in a reasonable time frame. Without a means of harnessing their collective efforts, collaborative design communities can never reach their full potential as engines of design innovation and development. To address this problem, this dissertation applies techniques from data science and machine learning to % understand how designers can more effectively navigate and use this vast quantity of information in answer to the following central question:How can online design communities effectively use the design data they generate to help manage their operations and improve their designs?Specifically, it presents examples around particular design communities (OpenIDEO and HCD Connect), and some of the challenges they face: How do you maintain a sustainable and creative design community without centralized command? How do designers locate the most relevant or creative inspirations out of thousands of ideas? How do novice designers use the community to learn what design methods are appropriate for a given problem? How can you scaffold novice designers within a community so that they can meaningfully contribute without requiring full expert knowledge? By framing these real-world problems through the lens of Network Analysis, the Maximum Coverage Problem, and Recommender Systems, this dissertation demonstrates how modern machine learning techniques can ameliorate the issues community members face in practice.From an computational perspective, it finds that the complexity of solving many distributed design tasks necessitates not only looking at a design itself, but also how it is situated in a human community; human relationships play as big a part in predicting a design's success as the content of the design itself. From a human perspective, data-assisted techniques can adapt to human behavior in ways that improve the collaborative structure of large teams, the relevance of methods used for design problems, and the number and variety of ideas that need to be explored by a designer. The dissertation's findings imply that customizing data science techniques to take advantage of the socially embedded nature of design benefits designers and scientists alike, not only by making design teams more effective but also by providing deeper insight into how humans design the way they do. They point to a future where data-driven design tools are not just a means to an end, but a critical part of how we understand our own needs and creations; where science can be applied, not just to the creation, but to the process of creation",Collaborative Design Informatics: Leveraging Data to Make Design Teams Better,,,"eScholarship, University of California",,core
154603445,2012,"Published version of an article from the journal: Mathematical Problems in Engineering. Also available from the publisher:http://dx.doi.org/10.1155/2012/832836This paper presents an approach for data-driven design of fault diagnosis system. The proposed fault diagnosis scheme consists of an adaptive residual generator and a bank of isolation observers, whose parameters are directly identified from the process data without identification of complete process model. To deal with normal variations in the process, the parameters of residual generator are online updated by standard adaptive technique to achieve reliable fault detection performance. After a fault is successfully detected, the isolation scheme will be activated, in which each isolation observer serves as an indicator corresponding to occurrence of a particular type of fault in the process. The thresholds can be determined analytically or through estimating the probability density function of related variables. To illustrate the performance of proposed fault diagnosis approach, a laboratory-scale three-tank system is finally utilized. It shows that the proposed data-driven scheme is efficient to deal with applications, whose analytical process models are unavailable. Especially, for the large-scale plants, whose physical models are generally difficult to be established, the proposed approach may offer an effective alternative solution for process monitoring",Data-driven adaptive observer for fault diagnosis,,10.1155/2012/832836,Hindawi Publishing,,core
54170433,2010,,Data-driven design of fuzzy classification rules with semantic cointension,,10.1109/fuzzy.2010.5584063,'Institute of Electrical and Electronics Engineers (IEEE)',,core
280075905,2013,,Automotive engine FDI by application of an automated model-based and data-driven design methodology,http://liu.diva-portal.org/smash/get/diva2:525421/FULLTEXT01,10.1016/j.conengprac.2012.12.006,Elsevier BV,,core
23296138,2013-10-04,"The Web of Data has grown to a size of several billion triples and provides human interface opportunities and challenges beyond those of the traditional Web. Although Linked Data is now generated at a fast pace and very large scale, we observe that browsing and visualisation of Linked Data is still in its infancy. In parallel to the enormous boost in Linked Data, recent work on integrating 3D graphics capabilities into the W3C technology stack provides fresh momentum for an effort to extend the Web with 3D content and technologies. In light of the timid uptake and consumption of Linked Data by non-technical audiences, we make the case for Web3D-based user interfaces to the Web of Data and aim at promoting synergistic research in the Web3D and Web of Data communities. To that end, we describe a scenario that requires the combination of Linked Data from geospatial and encyclopedic data sources and the transformation of the combined Linked Data into a format amenable to Web3D rendering. Based on the scenario, we derive highlevel requirements and propose a Linked Data-driven design pattern based on REST architecture principles that satisfies the requirements. Our prototypical implementation shows that a combination of current Web technologies is sufficient to implement distributed application that ultimately arrive at Web3D renderings of Linked Data. Based on the experiments, we identify and discuss areas which require further research. 1",Towards Networked Linked Data-Driven Web3D Applications,,,,,core
26169034,2010-04-01T00:00:00Z,"The paper presents a framework for a distributed medical system meant to bring a modern approach and inhance the quality of medical services offered to chronicle patients with cardio-vascular diseases, through the latest IT&amp;amp;C technologies. The proposed system provides online interaction between the main actors of a medical system: patients, doctors, medical entities (e.g. hospitals, clinics) and medical authorities (e.g. social services). With the aid of widely accepted medical standards, the system supplies storage for medical records and offers services for data integration between different kinds of healthcare applications and entities. The proposed ontological approach allows interchange of medical knowledge and best practices with conceptually organized patients&amp;rsquo; records. The proposed solution allows computer assisted diagnoses and multi-criteria medical data analysis, with the possible extent of building a data warehouse for complex medical data mining. &lt;br /&gt",A Proposed Data Driven Architecture for Cardiology Network Application,,,EduSoft publishing,"[{'title': None, 'identifiers': ['2067-3957', 'issn:2067-3957']}]",core
42388396,2014-04-26T00:00:00,"We present Gesture Mapper, an application for digital musical instrument designers to rapidly prototype mappings from performer gestures to sound synthesis parameters. Prior work [2] has shown that using interactive supervised learning to generate mappings from user-generated examples can be more efficient and effective than users writing mapping functions in code. In this work, we explore new ways to improve on data-driven design of interactive systems, specifically by proposing new mechanisms for rapid exploration and comparison of multiple alternative mappings. We present a conceptual structure for interactive mappings, a basic framework for generating mappings from more diverse types of user-specified constraints than are supported by supervised learning, and the new Gesture Mapper user interface for mapping exploration and comparison",Improving Data-driven Design and Exploration of Digital Musical Instruments,https://core.ac.uk/download/42388396.pdf,10.1145/2559206.2581327,'Association for Computing Machinery (ACM)',,core
265475094,2014,,Metric Learning Method Aided Data-Driven Design of Fault Detection Systems,http://doi.org/10.1155/2014/974758,10.1155/2014/974758,Hindawi Limited,,core
304304088,2011,"In this paper, an algorithm for direct data-driven design of cascade control system is proposed and analysed. The procedure is based on the Virtual Reference Feedback Tuning (VRFT) approach but it allows to tune either the inner and the outer loops by means of a single set of experimental data. The main differences between the standard VRFT and the proposed approach are highlighted and analyzed. The design technique is finally applied on a micro-positioning control problem for Electro-HydroStatic Actuators (EHSAs)",Fast Tuning of Cascade Control Systems,,10.3182/20110828-6-IT-1002.02761,,,core
203880301,2014-09-11,,A Data-Driven Design Evaluation Tool for Handheld Device Soft Keyboards,,10.1371/journal.pone.0107070,Public Library of Science,,core
224448715,2014-01-01T00:00:00,"With the advent of RNA sequencing and other high- throughput molecular assays, RNA biology has recently transitioned from careful curation of single-hypothesis experiments to data-driven design of multi-hypothesis investigations. Fortunately, statistical advances and increasingly powerful computers have given rise to machine learning, a computational framework which can automatically distill perpetually growing datasets into predictive models of fundamental cellular and disease processes. Finally, recent advances in microfluidics have enabled the efficient capture and interrogation of individual cells by a variety of molecular assays. My research bridges theses fields by introducing predictive statistical models of RNA abundance and processing in single cells to uncover new insights into the regulation of RNA editing and splicing and their effects on cellular differentiation. This dissertation collects my contributions in single-cell and statistical genomics, from low-level details of data analysis to high-level principles of cellular identity and diversity. My early contributions concentrate on building error models of RNA sequencing data in order to extract biologically-relevant signals from experimental noise and sampling biases inherent in high-throughput sequencing technologies. Specifically, I describe statistical models of RNA splicing and editing that are robust to noise from PCR duplicates or sequencing errors and to uneven sampling from incomplete reverse transcription or cDNA fragmentation biases. I then evaluate the models' self- consistency and compare their accuracy relative to a gold standard. With a solid statistical foundation for sequencing data analysis established, my latest contributions focus on developing principled methods of constructing and evaluating compelling biological hypotheses in collaboration with domain experts. Specifically, I describe a Bayesian model of A-to-I RNA editing whose high specificity helped resolve the functional difference between the catalytically-active RNA binding protein ADR-2, and its inactive homolog ADR-1. In another collaboration, I used machine learning to resolve a long-standing question in immunology regarding the asymmetric specification of T cells into two functionally distinct lineages. Here, through one of the first applications of single-cell gene expression analysis of the immune system, I demonstrate that pathogen-activated T cells undergo an early bifurcation into effector- and memory-fated populations and help identify the genes whose asymmetric expression drive this phenomenon. Together all of these contributions establish a principled statistical framework for experimental design and analysis which integrates both hypothesis- and data-driven models to validate new findings and uncover novel principles of RNA biolog",Statistical models for RNA biology : from single nucleotides to single cells,,,"eScholarship, University of California",,core
38922644,2011-01-01T08:00:00,"Most U.S. energy usage is for electricity production and vehicle transportation, two interdependent infrastructures. The strength and number of the interdependencies will increase rapidly as hybrid electric transportation systems, including plug-in hybrid electric vehicles and hybrid electric trains, become more prominent. There are several new energy supply technologies reaching maturity, accelerated by public concern over global warming.
The National Energy and Transportation Planning Tool (NETPLAN) is the implementation of the long-term investment and operation model for the transportation and energy networks. An evolutionary approach with underlying fast linear optimization are in place to determine the solutions with the best investment portfolios in terms of cost, resiliency and sustainability, i.e., the solutions that form the Pareto front.
The popular NSGA-II algorithm is used as the base for the multiobjective optimization and metrics are developed for to evaluate the energy and transportation portfolios. An integrating approach to resiliency is presented, allowing the evaluation of high-consequence events, like hurricanes or widespread blackouts. A scheme to parallelize the multiobjective solver is presented, along with a decomposition method for the cost minimization program. The modular and data-driven design of the software is presented. The modeling tool is applied in a numerical example to optimize the national investment in energy and transportation in the next 40 years",A multiobjective optimization approach to the operation and investment of the national energy and transportation systems,https://core.ac.uk/download/38922644.pdf,,Iowa State University Digital Repository,,core
55216513,2011-01-01T00:00:00,"The design of an active stability control system for twowheeled

vehicles is a fully open problem and it constitutes a

challenging task due to the complexity of two-wheeled vehicles

dynamics and the strong interaction between the vehicle and the

driver. This paper describes and compares two different methods,

a model-based and a data-driven approach, to tune a Multi-

Input-Multi-Output controller which allows to enhance the safety

while guaranteeing a good driving feeling. The two strategies are

tested on a multibody motorcycle simulator on challenging maneuvers

such as kick-back and strong braking while cornering at

high speed",A comparison between model-based and data-driven design of an active stability control system for two-wheeled vehicles,,10.1115/dscc2011-5934,,,core
62876088,2012-05-01T07:00:00,"This study implemented an exploratory mixed-methods design to better understand how the characteristics of a principal, specifically the strategies, behaviors, and actions, lead to the perception of empowerment as perceived by the teachers themselves.
An expert panel identified three highly successful principals assigned to elementary schools within a large urban district. Each was the principal of the school for a minimum of 4 years that utilized and sustained a shared-governance structure. Site observations at the schools, as evidenced by principal supervisors, indicated a successful governance structure, strong educational focus, and a sustained data-driven design for school improvement.
The teachers at each of the highly successful principals\u27 schools were surveyed for both qualitative and quantitative data from two survey instruments. Teachers responded to open-ended questions designed to identify specific characteristics of the principals\u27 that contributed to their sense of empowerment. Teachers also responded to statements to explore the overall schools\u27 governance in the areas of: decision-making, professional growth, status, self-efficacy, autonomy, and impact. Both instruments were compared across schools to determine emergent themes of characteristics and overall empowerment among the schools.
Embedded in reform initiatives is the concept of teacher empowerment as a means to increase the effectiveness of a school as an organization. If sustaining shared governance models and ensuring teachers are an integral part of the solutions to school reform, then determining what actions successful principals engage in, and how those actions influence a teacher\u27s sense of empowerment would be valuable information for practicing school administrators. What are the characteristics of successful principals that lead to the perception of teacher empowerment?
By looking at schools in a large urban school district, this study provides insight into how teachers perceive `empowerment\u27 and their contributions to the school in the areas of decision-making, professional growth, status, self-efficacy, autonomy, and impact. It also identifies specific characteristics, strategies, and practices of principals that contribute to teachers\u27 sense of empowerment.
The study revealed principals\u27 characteristics, strategies, and behaviors significantly affected teachers\u27 feelings, thinking, and behaviors and their perceptions of empowerment across six dimensions of empowerment: Decision Making, Professional Growth, Status, Self-Efficacy, Autonomy, and Impact (Short, 1991)","Empowering Teachers: Characteristics, Strategies, and Practices of Successful Principals",https://digitalscholarship.unlv.edu/cgi/viewcontent.cgi?article=2560&amp;context=thesesdissertations,,Digital Scholarship@UNLV,,core
130239189,2013-09-19T00:00:00,"By contemplating on the Eigenchair project, we ponder upon strategies and concepts of designing by using information technologies. What are the potentials of data driven design? What happens with objects when they are abstracted and reduced to a set of data? The emphasis is no longer on the creation of physical objects, but on conceiving meta-objects in the possibility space. Furthermore, this enables us to manipulate with a whole population of objects, instead of a single object. How do we get this abstract system to relate to the real world? Information technologies have opened up a number of new ways of thinking about the world and the object and they, by far, surpassed the formally simplified expression in design and architecture. Based on intellectual heritage of history and culture, information technologies can, by utilizing and recycling various elements and information, explore the 21st century object",Four Chairs and All the Others - Eigenchair,,,,,core
11461067,2004,"DCOS is a Data Centric lightweight Operating System for embedded devices. Despite limited energy and hardware resources, it supports a data driven architecture with provisions for dynamic loadable Modules. It combines these with Real-Time provisions based on Earliest Deadline First with a simple but smart resource handling mechanism. We will give an overview of the capabilities of DCOS and we will describe the basics of the main mechanisms","University of Twente, Centre for Telematics and Information Technology (CTIT)","DCOS, a real-time light-weight Data Centric Operating System",https://core.ac.uk/download/pdf/11461067.pdf,,,core
23500173,1993,"A pixel array has been proposed which features a completely data driven architecture. A pixel cell has been designed that has been optimized for this readout. It retains the features of preceding designs which allow low noise operation, time stamping, analog signal processing, XY address recording, ghost elimination and sparse data transmission. The pixel design eliminates a number of problems inherent in previous designs, by the use of sampled data techniques, destructive readout, and current mode output drivers. This architecture and pixel design is directed at applications such as a forward spectrometer at the SSC, an e+e- B factory at SLAC, and fixed target experiments at FNAL",,(E/I) PROGRESS ON THE DESIGN OF A DATA PUSH ARCHITECTURE FOR AN ARRAY OF OPTIMIZED TIME TAGGING PIXELS,,,,core
23464770,1998,"In this paper, we introduce a method of designing optimal time}frequency detectors from training samples, which is potentially of great bene&quot;t when few a priori information on the nonstationary signal to be detected is available. However, achieving good performance with data-driven detectors requires matching their complexity to the available amount of training samples: receivers with a too large number of adjustable parameters often exhibit a poor generalization performance whereas those with an insu$cient complexity cannot learn all the information available in the design set. Then, using the principle of structural risk minimization proposed by Vapnik, we introduce procedures which provide powerful tools for tuning the complexity of generalized linear detectors and improving their performance. Next, these methods are successfully experimented on simulated and real data, with linear detectors operating in the time}frequency domain: it is in such high-dimensional feature spaces that procedures of deriving reduced-bias receivers from training samples are of prime necessity. Finally, we show that our methodology may o!er a helpful support for designing detectors in many applications of current interest, such as biomedical engineering and complex system",,Data-driven design and complexity control of time}frequency detectors,,,,core
23074446,1999,"A 16-channel digital TDC chip has been built for the DIRC Cherenkov counter of the BaBar experiment at the SLAC B-factory (Stanford, USA). The binning is 0.5 ns, the conversion time 32 ns and the full-scale 32 µs. The data driven architecture integrates channel buffering and selective readout of data falling within a programmable time window. The time measuring scale is constantly locked to the phase of the (external) clock. The linearity is better than 80 ps rms. The dead time loss is less than 0.1 % for incoherent random input at a rate of 100 kHz on each channel. At such a rate the power dissipation is less than 100 mW. The die size is 36 mm 2. ",,A 16-Channel Digital TDC Chip with Internal Buffering and Selective Readout for the DIRC,,,,core
24583415,2008-02-07,"DATA DRIVEN DESIGN AND SIMULATION SYSTEM BASED ON XML Implementing a highly flexible manufacturing approach, like mass customization manufacturing, demands an integrated design and simulation system. This system must be able to cope with difficult issues such as a high level of product variety, uncertainty in the product demand forecast, and the reconfiguration of manufacturing resources to support the introduction and integration of new manufacturing capabilities. In this paper, a datadriven design and simulation system to support flexible manufacturing is presented. A neutral model of shop information, based on the eXtensible Markup Language, is used to describe the important information about the manufacturing facilities and processes, to configure simulation models and to exchange data between simulation and other manufacturing applications. When demand changes, the simulation model can be quickly modified to perform analysis according to the new demand. Manufacturing capabilities and production processes can be adjusted, layout reconfigured, and resources reassigned according to the analysis results. ",,Proceedings of the 2003 Winter Simulation Conference,,,,core
450226493,2004-01-01T00:00:00,,'Springer Science and Business Media LLC',Data Driven Design Optimization Methodology Development and Application,,10.1007/978-3-540-24688-6_97,,core
265981496,,,'American Chemical Society (ACS)',Data-Driven Design of Ecofriendly Thermoelectric High-Entropy Sulfides,,10.1021/acs.inorgchem.8b02379,,core
337131423,,,'Institute of Electrical and Electronics Engineers (IEEE)',Data-Driven Design of a Cascaded Observer for Battery State of Health Estimation,,10.1109/TIA.2018.2851231,,core
336054907,,,'Springer Science and Business Media LLC',Data-driven design of metal–organic frameworks for wet flue gas CO2 capture,,10.1038/s41586-019-1798-7,,core
339086378,,,'Informa UK Limited',Aural Textiles. Hybrid practices for data-driven design.,,10.1080/14606925.2019.1594982,,core
11458862,2004,"DCOS is a Data Centric lightweight Operating System for embedded devices. Despite limited energy and hardware resources, it supports a data driven architecture with provisions for dynamic loadable Modules. It combines these with Real-Time provisions based on Earliest Deadline First with a simple but smart resource handling mechanism. We will give an overview of the capabilities of DCOS and we will describe the basics of the main mechanisms",ACTA Press,"DCOS, a Real-Time Light-weight Data Centric Operating System",https://core.ac.uk/download/pdf/11458862.pdf,,,core
22943986,2000,"Although HMM is widely used for on-line handwriting recognition, there is no simple and wellestablished method of designing the HMM topology. We propose a data-driven systematic method to design HMM topology. Data samples in a single pattern class are structurally simplified into a sequence of straight-line segments, and then these simplified representations of the samples are clustered. An  HMM is constructed for each of these clusters, by assigning a state to each straight-line segments. Then the resulting multiple models of the class are combined to form an architecture of a multiple parallel-path HMM, which behaves as a single HMM. To avoid excessive growing of the number of the states,  parameter tying is applied in that structural similarity among patterns is reflected. Experiments on on-line Hangul recognition showed about 19 % of error reductions, compared to the intuitive design method.  Keywords: On-line handwriting recognition, hidden Markov model, data-driven topology desig..",World Scientific Publishing Company,Data-driven Design of HMM Topology for On-Line Handwriting Recognition,,,,core
24506935,2005,"Abstract — This paper presents DONet, a Data-driven Overlay Network for live media streaming. The core operations in DONet are very simple: every node periodically exchanges data availability information with a set of partners, and retrieves unavailable data from one or more partners, or supplies available data to partners. We emphasize three salient features of this data-driven design: 1) easy to implement, as it does not have to construct and maintain a complex global structure; 2) efficient, as data forwarding is dynamically determined according to data availability while not restricted by specific directions; and 3) robust and resilient, as the partnerships enable adaptive and quick switching among multi-suppliers. We show through analysis that DONet is scalable with bounded delay. We also address a set of practical challenges for realizing DONet, and propose an efficient member- and partnership management algorithm, together with an intelligent scheduling algorithm that achieves real-time and continuous distribution of streaming contents. We have extensively evaluated the performance of DONet over the PlanetLab. Our experiments, involving almost all the active PlanetLab nodes, demonstrate that DONet achieves quite good streaming quality even under formidable network conditions. Moreover, its control overhead and transmission delay are both kept at low levels. An Internet-based DONet implementation, called Cool-Streaming v.0.9, was released on May 30, 2004, which has attracted over 30000 distinct users with more than 4000 simultaneously being online at some peak times. We discuss the key issues toward designing CoolStreaming in this paper, and present several interesting observations from these large-scale tests; in particular, the larger the overlay size, the better the streaming quality it can deliver. I",,Coolstreaming/donet: A data-driven overlay network for peer-to-peer live media streaming,,,,core
474125066,,,'Springer Science and Business Media LLC',Participative Method to Identify Data-Driven Design Use Cases,,10.1007/978-3-030-62807-9_54,,core
427628015,,,'Elsevier BV',Preface to the special issue on machine learning and data-driven design of materials issue in computational materials science,,10.1016/j.commatsci.2021.110452,,core
429274387,,,'Elsevier BV',Data-driven design of fault detection and isolation method for distributed homogeneous systems,,10.1016/j.jfranklin.2021.04.016,,core
287830579,,"Ubiquitous and pervasive computing holds great potential in the domain of Product-Service Systems to introduce a model-driven paradigm for decision support. Data-driven design is often discussed as a critical enabler for developing simulation models that comprehensively explore the PSS design space for complex systems, linking of performances to customer and provider value. Emerging from the findings of two empirical studies conducted in collaboration with multinational manufacturing companies in the business-to-business market, this paper defines a data-driven framework to support engineering teams in exploring, early in the design process, the available design space for Product-Service Systems from a value perspective. Verification activities show that the framework and modeling approach is considered to fill a gap when it comes to stimulating value discussions across functions and organizational roles, as well as to grow a clearer picture of how different disciplines contribute to the creation of value for new solutions","Blekinge Tekniska Högskola, Institutionen för maskinteknik",A data-driven design framework for early stage PSS design exploration,,,,core
357606199,2007-01-01T00:00:00,"Abstract-This paper introduces a multiple-access coding technique that is tailored to solve average consensus problems efficiently in wireless networks. We propose a novel data driven architecture which grants channel access to nodes based on their local data values. We analyze the performance of the scheme in the presence of quantization errors and noise. We show that our scheme is unbiased with respect to quantized consensus algorithms, it achieves good MSE performance, and it can be configured to provide a speedup in the convergence rate. The amount of speedup achieved is a function of |Q k | which indicates the number of quantization bins used to represent the state variables exchanged during the computation",,"A scalable wireless communication architecture for average consensus,” in",,,,core
23808953,1997,"In many practical signal detection problems, the detectors have to designed from training data. Due to limited training data, which is usually the case, it is imperative to exploit some inherent signal structure for reliable detector design. The signals of interest in a variety of applications manifest such structure in the form of nuisance parameters. However, data-driven design of detectors by exploiting nuisance parameters is virtually impossible in general due to two major difficulties: identifying the appropriate nuisance parameters, and estimating the corresponding detector statistics. We address this problem by using recent results that relate joint signal representations (JSRs), such as time-frequency and time-scale representations, to quadratic detectors for a wide variety of nuisance parameters. We propose a general data-driven framework that: 1) identifies the appropriate nuisance parameters from an arbitrarily chosen finite set, and 2) estimates the second-order statistics ..",,Data-Driven Time-Frequency and Time-Scale Detectors,,10.1117/12.279514,,core
2449186,1999-02-10T00:00:00,"A 16-channel digital TDC chip has been built for the DIRC Cherenkov counter
of the BaBar experiment at the SLAC B-factory (Stanford, USA). The binning is
0.5 ns, the conversion time 32 ns and the full-scale 32 mus. The data driven
architecture integrates channel buffering and selective readout of data falling
within a programmable time window. The time measuring scale is constantly
locked to the phase of the (external) clock. The linearity is better than 80 ps
rms. The dead time loss is less than 0.1% for incoherent random input at a rate
of 100 khz on each channel. At such a rate the power dissipation is less than
100 mw. The die size is 36 mm2.Comment: Latex, 18 pages, 13 figures (14 .eps files), submitted to NIM ",'Elsevier BV',"A 16-channel Digital TDC Chip with internal buffering and selective
  readout for the DIRC Cherenkov counter of the BABAR experiment",http://arxiv.org/abs/hep-ex/9902015,10.1016/S0168-9002(99)00453-2,,core
426934303,,,'Elsevier BV',A data-driven architecture using natural language processing to improve phenotyping efficiency and accelerate genetic diagnoses of rare disorders,,10.1016/j.xhgg.2021.100035,,core
25394828,1998-10-02T00:00:00,"The implementation of a 1 st level vertex trigger for LHC-B is particularly difficult due to the high ( 1 MHz ) input data rate. With ca. 350 silicon hits per event, both the R strips and Phi strips of the detectors produce a total of ca 2 Gbyte/s zero-suppressed da ta.1 note succeeds to the ideas to use R-phi coordinates for fast integer linefinding in programmable hardware, as described in LHB note 97-006. For an implementation we propose a FPGA preprocessing stage operating at 1 MHz with the benefit to substantially reduce the amount of data to be transmitted to the CPUs and to liberate a large fraction of CPU time. Interconnected via 4 Gbit/s SCI technol-ogy 2 , a shared memory system can be built which allows to perform data driven eventbuilding with, or without preprocessing. A fully data driven architecture between source modules and destination memories provides a highly reliable memory-to-memory transfer mechanism of very low latency. The eventbuilding is performed via associating events at the source with unique destination addresses which are derived from the event numbers. Subevents from phi-sectors are auto-routed to their destination buffer which is part of the memory of the CPU farm. The synchronization and buffer management for such a system is described. The data volumes for phi buffer readout can be reduced to 30little latency and can coexist with the primary stream of R-data.",,Vertex trigger implementation using shared memory technology,,,,core
430036848,,,'Elsevier BV',Mechanical and thermodynamic data-driven design of Al-Co-Cr-Fe-Ni multi-principal element alloys,,10.1016/j.mtcomm.2021.102096,,core
469843416,,,'Institute of Electrical and Electronics Engineers (IEEE)',Data-driven Design of Perfect Reconstruction Filterbank for DNN-based Sound Source Enhancement,,10.1109/ICASSP.2019.8683861,,core
188086854,2006-01-01T08:00:00,"This study was designed to investigate teacher perceptions related to the quality of professional development being provided within six Ohio districts following active participation in a statewide initiative focused on the implementation of standards-based education. Two themes were developed for study. The first related to the degree to which teachers rated the quality of staff development based on the National Staff Development Council\u27s Standards for Staff Development (2001). For purposes of this study, professional development was categorized by Levels of Investment: (a) Level I included 620 teachers representing twenty-three schools in the six districts; (b) Level II included teacher leaders who had received specialized training to lead reform; and (c) Level III included 12/23 schools that had implemented professional learning teams with common-planning time as the primary model of staff development. Survey methodology was employed and results from the analysis of the NSDC Standards Assessment Inventory (2004) revealed: (a) teachers engaged in Level I Investment identified two standards at a significant level of implementation (context - leadership; content - equity); (b) teacher leaders (Level II Investment) identified one standard at a negative level (context - leadership); (c) teachers engaged in professional learning teams (Level III Investment) rated seven standards at a high degree of implementation (context - learning communities; process - collaboration, data-driven, design, evaluation; content - equity and quality teaching). Multivariate multiple regression analysis was used to explore impact of combined Level II and Level III investment. Teachers receiving professional development at these two levels identified 10 of the 12 standards at a significant level of implementation. The second theme sought to determine whether participation in a statewide initiative had impacted systemic change. The district with the longest history of professional learning teams had the highest reported level of impact on knowledge and skills at three levels of the system: district, school and classroom. In addition, two districts that had implemented professional learning teams reported the highest level of capacity for sustainability of reform efforts at the school-level",DigitalCommons@University of Nebraska - Lincoln,High-quality professional development: Teacher perceptions of practice within six Ohio districts engaged in standards -based reform,,,,core
468126538,,,'Institute of Electrical and Electronics Engineers (IEEE)',Comparison of Two Performance Optimization Approaches for Data-Driven Design of Fault-Tolerant Control Systems,,10.1109/ISIE.2018.8433657,,core
92018308,2004-11-01T00:00:00,"DCOS is a Data Centric lightweight Operating System for embedded devices. Despite limited energy and hardware resources, it supports a data driven architecture with provisions for dynamic loadable Modules. It combines these with Real-Time provisions based on Earliest Deadline First with a simple but smart resource handling mechanism. We will give an overview of the capabilities of DCOS and we will describe the basics of the main mechanisms",'ACTA Press',"DCOS, a Real-Time Light-weight Data Centric Operating System",,,,core
338914571,,,'ASME International',Dynamic Data-Driven Design of Lean Premixed Combustors for Thermoacoustically Stable Operations,,10.1115/1.4037307,,core
336385788,,,'IOS Press',A fast learning method for data-driven design of interval type-2 fuzzy logic system,,10.3233/JIFS-16799,,core
339082088,,,'ASME International',Data-Driven Design Space Exploration and Exploitation for Design for Additive Manufacturing,,10.1115/1.4043587,,core
338883132,,,'ASME International',Data-Driven Design Optimization for Composite Material Characterization,,10.1115/1.3595561,,core
46798043,1999-01-01T00:00:00,"A 16-channel digital TDC chip has been built for the DIRC Cherenkov counter of the BaBar experiment at the SLAC B-factory (Stanford, USA). The binning is 0.5 ns, the conversion time 32 ns and the full-scale 32 mus. The data driven architecture integrates channel buffering and selective readout of data falling within a programmable time window. The time measuring scale is constantly locked to the phase of the (external) clock. The linearity is better than 80 ps rms. The dead time loss is less than 0.1% for incoherent random input at a rate of 100 khz on each channel. At such a rate the power dissipation is less than 100 mw. The die size is 36 mm2",'Elsevier BV',A 16-channel digital TDC chip,,,,core
24246371,1999,"this paper, the basics of Conceptual Information Systems and conceptual scales are provided in Section 2. For a conceptual scale, there is always a trade-off between its size and its soundness with respect to future updates of the database. There are two approaches of designing conceptual scales: data-driven design and theory-driven design. In theory-driven design, knowledge about the application domain is used to exclude impossible combinations of attributes. This keeps the conceptual scales small -- and their concept lattices easier to interpret. Theory-driven design is only applicable if there is enough knowledge about which types of objects may occur in the database. If this information is missing, the diagrams may become unnecessarily large. The second approach is called data-driven design. If there is no (or only few) knowledge available, the scales are designed to fit the actual data only, and not to conform to all possible updates of the database. If an update violates the structure of the scale, the user is warned, and the scale has to be redesigned. Hence, data-driven design is not applicable if the database is frequently updated.  A more general approach than conceptual scaling is presented in [5]: (datadriven)  logical scaling. Instead of using conceptual scales, it uses the terminology of a formal language like Description Logic for extracting information. Logical scaling is shortly recalled in Section 2. While data-driven logical scaling has the advantage of a more powerful language for defining scales, it has the same drawbacks as data-driven design of ordinary conceptual scales. In Section 3, we introduce theory-driven logical scaling  which combines both efforts. It determines typical objects and excludes all combinations of attributes which cannot occ..",,Theory-driven Logical Scaling,,,,core
10836938,,"Tyt. z nagłówka.Pozostali autorzy artykułu: Lawrence E. Lach, Weimin Xiao, Juan M. LopezReferences p.151-152.Dostępny również w wersji drukowanej.ABSTRACT: Virtual Prototyping (VP) is a data-driven design process that promotes both knowledge reuse and innovation. High-profile applications in the automotive and aerospace industries have demonstrated its potential to significantly reduce prototype cycles, time to market, and total product cost. This paper addresses VP as a specialized application of Decision-Support Systems, and discusses common requirements for engineering design tools, as well as requirements specific to the design of electronic products, such as mobile phones. Motorola Labs' test bed for VP is introduced in terms of its open, agent-based architecture utilizing Java CORBA. One of the key principles of the VP System is the reuse of expert knowledge across multiple engineering domains. This is highlighted via several use cases, showing that the system can function not only as an Intranet-accessible repository of model services but also as an integral part of decision-making within the native CAD environment.  KEYWORDS: Distributed Decision-Support, Virtual Prototyping, CAE",,A Distributed Decision-Support System for Virtual Prototyping,,,,core
350818703,1995-01-01T00:00:00,,'Elsevier BV',Active Data-Driven Design Using Dynamic Product Models,,10.1016/S0007-8506(07)62286-0,,core
468677598,,,'Springer Science and Business Media LLC',Data-Driven Design Optimization for Industrial Products,,10.1007/978-3-030-01641-8_9,,core
105865297,2002,Data driven	design	of	an	ANN/HMM	system	for on-line unconstrained	handwritten	character recognitio,,Data Driven Design of an ANN/HMM System for On-line Unconstrained Handwritten Character Recognition,,,,core
337765601,,,'Cambridge University Press (CUP)',Data-driven design of inorganic materials with the Automatic Flow Framework for Materials Discovery,,10.1557/mrs.2018.207,,core
371744,2008-02-01T00:00:00,"In this paper, two approaches for the incremental data-driven learning of one of the most effective fuzzy model, namely of so-called Takagi-Sugeno type, are compared. The algorithms that realize these approaches include not only adaptation of linear parameters in fuzzy systems appearing in the rule consequents, but also incremental learning and evolution of premise parameters appearing in the membership functions (i.e. fuzzy sets) in sample mode together with a rule learning strategy. In this sense the proposed methods are applicable for fast model training tasks in various industrial processes, whenever there is a demand of online system identification in order to apply models representing nonlinear system behaviors to system monitoring, online fault detection or open-loop control. An evaluation of the incremental learning algorithms are included at the end of the paper, where a comparison between conventional batch modelling methods for fuzzy systems and the incremental learning methods demonstrated in this paper is made with respect to model qualities and computation time. This evaluation is based on high dimensional data coming from an industrial measuring process as well as from a known source on the Internet, which underlines the usage of the new method for fast online identification tasks. (c) Taylor and Fransis Group (to appear in International Journal on General Systems",'Informa UK Limited',A Comparative Study of two Approaches for Data-Driven Design of Evolving Fuzzy Systems: eTS and FLEXFIS,,10.1080/03081070701500059,,core
468491250,,,'Springer Science and Business Media LLC',Lessons Learned from a Multi-year Initiative to Integrate Data-Driven Design Using BIM into Undergraduate Architectural Education,,10.1007/978-3-030-00220-6_103,,core
91987934,2004-10,"DCOS is a Data Centric lightweight Operating System for embedded devices. Despite limited energy and hardware resources, it supports a data driven architecture with provisions for dynamic loadable Modules. It combines these with Real-Time provisions based on Earliest Deadline First with a simple but smart resource handling mechanism. We will give an overview of the capabilities of DCOS and we will describe the basics of the main mechanisms",Centre for Telematics and Information Technology (CTIT),"DCOS, a real-time light-weight Data Centric Operating System",,,,core
282847074,,,'BMJ',Paving the COWpath: data-driven design of pediatric order sets,,10.1136/amiajnl-2013-002316,,core
339069305,,,'Elsevier BV',Utilizing text mining and Kansei Engineering to support data-driven design automation at conceptual design stage,,10.1016/j.aei.2018.11.002,,core
22613236,2000,,World Scientific Publishing Company,Data driven Design of HMM Topology for On-Line Handwriting Recognition,,,,core
461015568,,,'Institute of Electrical and Electronics Engineers (IEEE)',Data-driven design and implementation of an alternately adaptive residual generator for Hammerstein systems,,10.1109/ChiCC.2015.7260619,,core
100193034,2006,"Abstract. Virtual Prototyping (VP) is a data-driven design process that promotes both knowledge reuse and innovation. High-profile applications in the automotive and aerospace industries have demonstrated its potential to significantly reduce prototype cycles, time to market, and total product cost. This paper addresses VP as a specialized application of Decision-Support Systems, and discusses common requirements for engineering design tools, as well as requirements specific to the design of electronic products, such as mobile phones. Motorola Labs ’ test bed for VP is introduced in terms of its open, agent-based architecture utilizing Java CORBA. One of the key principles of the VP System is the reuse of expert knowledge across multiple engineering domains. This is highlighted via several use cases, showing that the system can function not only as an Intranet-accessible repository of model services but also as an integral part of decision-making within the native CAD environment",,A Distributed Decision-Support System for Virtual Prototyping,,,,core
109038612,2005,"Background: The success of clinical information systems depends upon their effective integration into complex work systems involving distributed responsibility and decisionmaking. Human-computer interaction (HCI) deficiencies and mismatches between systems design and the structure of work create the potential for new paths to system failures (e.g., allergy lists not directly visible on a screen). The use of human factors methods is widespread in other industries and can predict some of these new failure paths, facilitating redesign to prevent accidents-in-the-making. This paper will discuss the application of scenario-based usability testing in clinical health care settings. Methods: Using scenario-based usability testing methods, we investigated point-of-care software technology (e.g., barcoded medication administration [BCMA] and wireless medication administration [WMA]) in an attempt to better understand the safety implications of HCI design decisions. The use of scenarios in usability testing focuses attention on specific aspects of the interface to identify pitfalls and system failures. The scenarios were developed after extensive ethnographic observation of the medical work with bar-coding software and the computerized order entry system (COES). Results: The paper lays out the methodology of scenario-based usability testing for use in health care. We were able to identify new paths to failures using this method and recommended the software to simplify and support the user’s tasks. Scenario-based testing also identified workplace performance trade-offs related to time and production pressures. Conclusion: Scenario-based usability testing is an important methodology that characterizes how human-software interaction contributes to success or failure in clinical system implementations. Usability testing can identify and promote data-driven design choices culled from practitioner use of the system in a busy work environment. Human factors knowledge of HCI design and its impact on human performance can advance safety in health care",,Usability testing and the relation of clinical information systems to patient safety,,,,core
12858261,2004-01-01,"Microsoft, Motorola, Siemens, Hitachi, IAPR, NICI, IUF
Although HMM is widely used for on­line handwriting recognition, there is no simple and well­established way of designing the HMM topology. We propose a data­driven systematic method to design HMM topology. Data samples in a single pattern class are structurally simplified into a sequence of straight­line segments, and then these simplified representations of the samples are clustered. An HMM is constructed for each of these clusters, by assigning a state to each straight­line segments. Then the resulting multiple models of the class are combined to form an architecture of a multiple parallel­path HMM, which behaves as a single HMM. To avoid excessive growing of the number of the states, parameter tying is applied in that structural similarity among patterns is reflected. Experiments on on­line Hangul recognition showed about 19% of error reductions, compared to the previous intuitive design methods.",Nijmegen: International Unipen Foundation,DATA DRIVEN DESIGN OF HMM TOPOLOGY FOR ON­LINE HANDWRITING RECOGNITION,,,,core
22614589,1993,"The paper examines the problem of dataflow graph partitioning aiming to improve the efficiency of macro-dataflow computing on a hybrid control/data driven architecture. The partitioning consists of dataflow graph synchronization and scheduling of the synchronous graph. A new scheduling algorithm, called Global Arc Minimization (GAM), is introduced. The performance of the GAM algorithm is evaluated relative to some other known heuristic methods for static scheduling. When interprocessor communication delays are taken into account, the GAM algorithm achieves better performance on the simulated hybrid architecture.  Keywords: Macro dataflow, ring architecture, program partitioning, synchronization,  scheduling.  ?  This work has been supported by Ministry of Science and Technology of the Republic of Slovenia under Grant Number J2-1133.  This report will appear in the Journal of Computing and Information Technology 1(1):47-- 55, 1993.  Technical Report CSD-93-7 February 1993 1 Introduction..",,Program Partitioning for a Control/Data Driven Computer,,,,core
20640962,2007-05-03T12:37:00,"The expansion of 3D real-time simulations (3DRTS) into millions of homes together with the technical progress of computers hardware force to approach software developments for 3DRTS from different perspectives. From an historical standpoint, 3DRTS started principally as homebrew developments. The underlined consequences are the lack of standardization for producing such applications. Nowadays, computers hardware can reproduce close to photo-realism 3D images within interactive environments. This was made possible with the continuous improvements in computers hardware. During many years, the hardware evolution was following vertical speed-up improvements, by increasing CPU clocks speed and memory bandwidth. Today, we are reaching the limits of this approach from a power consumption, heat, and intrinsic materials characteristics perspectives. As an outcome, the next-generation of computer hardware and home consoles are presenting multitasking architectures. This obliges to re-think software development for 3DRTS, moving from the serial and single-threaded approach to a concurrent design. We explore conceptual designs handling the current scale and complexity offered by 3DRTS developments by adopting stronger engineering practices. This is needed to control the underlined complexity and rising developments costs. The direct consequence of being able to generate highly detailed virtual worlds is to involve more deeply artists and designers in the development process. We propose mechanisms that free developers from common low-levels problematic, such as memory management or data synchronization issues. Our architecture relies on extending the Component Based Development (CBD) model for multitasking architectures. This obliges to define specific patterns either directly inspired by other fields in computer science or dedicated for 3DRTS. This includes promoting multi-layer design where the low-level routines are tightly connected to computer hardware by describing the importance of conceiving hardware-oblivious systems. This is important, as memory bandwidth is becoming the principal bottleneck in current applications. Another fundamental aspect consists to move from the single iterative global loop commonly found in single-threaded systems, by incorporating mechanisms for balancing the workflow more accurately. If those optimizations and evolutions are required for assuring efficient real-time performance, they do not allow non-programmers to interact with the system with ease. Our method consists to promote high-level languages and concurrent model relying on Microthreads. This gives the ability to develop and execute scripts in a multitasking environment without the common C/C++ issues. This is primordial to let designers experiment with ideas in a safer and efficient environment. This will leads to adopt the data-driven paradigm to control agents in our simulations, by clearly separating the logic and data layers. This offer better flexibility and reduce the existence of simulation specific code. In addition, we illustrate that the best technology and designs have a limited meaning, if they do not come with a complete production pipeline for managing and controlling simulation assets. This also affects fine tuning parameters where different hardware may perform better in some areas or worse in other. Finally, different use-cases demonstrate the strong and weakness aspects of our approach.L'intégration de simulations 3D temps réel dans des millions de foyers associés avec les progrès techniques dans le matériel informatique force d'approcher la conception de logiciels sous d'autres angles. D'un point de vue historique, le développement d'applications 3D temps réel a principalement débuté au travers de développements individuels. La conséquence directe est le manque de standardisation pour la production de telles applications. De nos jours, les ordinateurs sont capables de reproduire des images 3D photo réalistes dans des environnements interactifs. Cela a été possible grâce au développement continu du matériel informatique. Durant des années, l'évolution du matériel suivait une amélioration verticale en augmentant la fréquence des processeurs ainsi que des transfert des données. Aujourd'hui, nous atteignons les limites de cette approche pour des raisons de consommation d'énergie, de dégagement de chaleur, ainsi que des caractéristiques intrinsèques des matériaux. En conséquence, les futures générations de PCs et de consoles de jeux présentent une architecture multi-tâches. Ceci oblige à re-penser le processus de développement pour les applications 3D temps réel, en modifiant l'approche classique et sérielle, par une approche concurrente. Nous explorons les concepts permettant de manager la taille et la complexité des applications 3D temps réel en adoptant de plus strictes méthodes d'ingénierie. Ceci est absolument nécessaire pour contrôler, à la fois la complexité et les coûts de développements. La conséquence directe étant d'être en mesure de générer des mondes virtuels détaillés afin d'intégrer les artistes et designers dans le processus de développement. Nous proposons des mécanismes qui libèrent les développeurs des habituels problèmes de bas niveaux, tels que la gestion de la mémoire ou la synchronisation des données. Notre architecture repose dans l'extension du modèle ""Component Based Development"" (CBD) pour des architectures multi-tâches. Ceci requière de définir des patrons spécifiques, soit directement inspirés d'autres domaines ou directement dédiés aux applications 3D temps réel. Ceci inclut aussi de promouvoir un design multicouche ou les fonctions de bas niveaux sont directement connectées aux matériels en décrivant l'importance de concevoir des systèmes capables d'exploiter le matériel à disposition. Ceci est primordial, car les transferts de données sont le principal goulet d'étranglement dans les applications actuelles. Un autre aspect fondamental consiste à ne plus se reposer sur une approche itérative en y incorporant des mécanismes pour répartir les tâches. Si toutes ces optimisations et évolutions sont requises pour assurer des performances optimales, elles ne permettent pas aux personnes non qualifiées d'interagir facilement avec le système. Notre méthode consiste à promouvoir des langages de hauts niveaux ainsi que des modèles de programmations concurrentes basées sur le concept de Microthreads. Cela offre l'opportunité de développer et d'exécuter des scripts dans un environnent multi-tâches en évitant les problèmes du C/C++. C'est primordial pour permettre aux designers d'expérimenter leurs idées dans un environnement sécurisé et efficace. Ceci entraîne l'adoption de méthodes permettant le contrôle des personnages virtuels aux travers des données, en séparant la logique et les données. Cela accroît la flexibilité et réduit l'existence de code spécifique à une simulation. De plus, nous illustrons que les meilleures technologies et designs, n'ont qu'un intérêt limité, sans l'accompagnement d'outils de productions efficaces. Ceci inclut des outils de paramétrisations permettant d'adapter les simulations aux différents matériaux existants. Finalement, certains exemples démontrent les points forts et faibles de notre approche",,A multitasking and data-driven architecture for multi-agents simulations,,,,core
148195744,2004,,s.n.,DATA DRIVEN DESIGN OF HMM TOPOLOGY FOR ON­LINE HANDWRITING RECOGNITION,https://core.ac.uk/download/pdf/148195744.pdf,,,core
24716903,2008-04-02,"Abstract—Motion trajectories provide rich spatio-temporal information about an object’s activity. This paper presents novel classification algorithms for recognizing object activity using object motion trajectory. In the proposed classification system, trajectories are segmented at points of change in curvature and the subtrajectories are represented by their Principal Component Analysis (PCA) coefficients. We first present a framework to robustly estimate the multivariate probability density function (PDF) based on PCA coefficients of the subtrajectories using Gaussian Mixture Models (GMM). We show that GMM-based modeling alone cannot capture the temporal relations and ordering between underlying entities. To address this issue, we use Hidden Markov Models (HMM) with a data-driven design in terms of number of states and topology (e.g. left-right versus ergodic). Experiments using a database of over 5700 complex trajectories (obtained from UCI-KDD data archives and Columbia University Multimedia Group) subdivided into 85 different classes demonstrate the superiority of our proposed HMM-based scheme using PCA coefficients of subtrajectories in comparison with other techniques in the literature",,Object trajectory-based activity classification and recognition using hidden Markov models,,,,core
92429298,2004-01-01T00:00:00,"Although HMM is widely used for on­line handwriting recognition, there is no simple and well­established way of designing the HMM topology. We propose a data­driven systematic method to design HMM topology. Data samples in a single pattern class are structurally simplified into a sequence of straight­line segments, and then these simplified representations of the samples are clustered. An HMM is constructed for each of these clusters, by assigning a state to each straight­line segments. Then the resulting multiple models of the class are combined to form an architecture of a multiple parallel­path HMM, which behaves as a single HMM. To avoid excessive growing of the number of the states, parameter tying is applied in that structural similarity among patterns is reflected. Experiments on on­line Hangul recognition showed about 19% of error reductions, compared to the previous intuitive design methods",s.n.,DATA DRIVEN DESIGN OF HMM TOPOLOGY FOR ON­LINE HANDWRITING RECOGNITION,,,,core
108680548,2007,"Abstract — This paper introduces a multiple-access coding technique that is tailored to solve average consensus problems efficiently in wireless networks. We propose a novel data driven architecture which grants channel access to nodes based on their local data values. We analyze the performance of the scheme in the presence of quantization errors and noise. We show that our scheme is unbiased with respect to quantized consensus algorithms, it achieves good MSE performance, and it can be configured to provide a speedup in the convergence rate. The amount of speedup achieved is a function of |Qk | which indicates the number of quantization bins used to represent the state variables exchanged during the computation. I",,A scalable wireless communication architecture for average consensus,,10.1109/cdc.2007.4434859,,core
92318950,2007,"Enterprises increasingly demand IT support for the coordination of their engineering processes, which often consist of hundreds up to thousands of sub-processes. From a technical viewpoint, these sub-processes have to be concurrently executed and synchronized considering numerous interdependencies. So far, this coordination has mainly been accomplished manually, which has resulted in errors and inconsistencies. In order to deal with this problem, we have to better understand the interdependencies between the subprocesses to be coordinated. In particular, we can benefit from the fact that sub-processes are often correlated to the assembly of a product (represented by a product data structure). This information can be utilized for the modeling and execution of so-called data-driven process structures. In this paper, we present the COREPRO demonstrator that supports the data-driven modeling of these process structures. The approach explicitly establishes a close linkage between product data structures and engineering processes",IEEE Computer Society,Data-driven Design of Engineering Processes with COREPROModeler,,10.1109/wetice.2007.136,,core
101537840,2007,"Enterprises increasingly demand IT support for the co-ordination of their engineering processes, which often con-sist of hundreds up to thousands of sub-processes. From a technical viewpoint, these sub-processes have to be concur-rently executed and synchronized considering numerous in-terdependencies. So far, this coordination has mainly been accomplished manually, which has resulted in errors and inconsistencies. In order to deal with this problem, we have to better understand the interdependencies between the sub-processes to be coordinated. In particular, we can benefit from the fact that sub-processes are often correlated to the assembly of a product (represented by a product data struc-ture). This information can be utilized for the modeling and execution of so-called data-driven process structures. In this paper, we present the COREPRO demonstrator that supports the data-driven modeling of these process struc-tures. The approach explicitly establishes a close linkage between product data structures and engineering processes. 1",,F.: Data-driven design of engineering processes with COREPROModeler,,,,core
101392656,2007,"experiment and simulation in a concurrent integrated software system to achieve better designs in a shorter time. The data obtained from experiment and simulation dynamically guide and redirect the design optimization process in real or near-real time, and therefore realize the full potential of the Dynamic Data Driven Applications Systems concept. This paper describes the DDDOM software system developed using the Perl and Perl/Tk programming languages. The paper also presents the first results of the application of the DDDOM to the multi-objective de-sign optimization of a submerged subsonic inlet at zero angle of attack and sideslip. ",,Application of Data Driven Design Optimization Methodology to a Multi-Objective Design Optimization Problem. To appear,,,,core
100030472,2006,"Abstract. In this article, we discuss the motivation for a novel style of tutorial dialogue system that emphasizes reflection in a simulation based exploratory learning environment called CyclePad, which was developed in order to offer students practice at design and optimization of thermodynamic cycles. We argue that while typical forms of exploration support offered in simulation based learning environments are meant to encourage the development of good exploration process skills, the instantiation of these typical forms of support in CyclePad are not sufficient, primarily because students don&apos;t choose to use them. We present a preliminary cognitive task analysis of design exploration tasks using CyclePad. Using this cognitive task analysis, we analyze data collected in two waves of formal data collection. Finally, we conclude with some system desiderata derived from our analysis as well as discussion of directions for continued experimental investigations related to tutor style",,CycleTalk: Data driven design of support for simulation based learning,,,,core
24385440,2008-01-29,"Implementing a highly flexible manufacturing approach, like mass customization manufacturing, demands an integrated design and simulation system. This system must be able to cope with difficult issues such as a high level of product variety, uncertainty in the product demand forecast, and the reconfiguration of manufacturing resources to support the introduction and integration of new manufacturing capabilities. In this paper, a data-driven design and simulation system to support flexible manufacturing is presented. A neutral model of shop information, based on the eXtensible Markup Language, is used to describe the important information about the manufacturing facilities and processes, to configure simulation models and to exchange data between simulation and other manufacturing applications. When demand changes, the simulation model can be quickly modified to perform analysis according to the new demand. Manufacturing capabilities and production processes can be adjusted, layout reconfigured, and resources reassigned according to the analysis results",,Proceedings of the 2003 Winter Simulation Conference,,,,core
101608226,2007,"Enterprises increasingly demand IT support for the co-ordination of their engineering processes, which often con-sist of hundreds up to thousands of sub-processes. From a technical viewpoint, these sub-processes have to be concur-rently executed and synchronized considering numerous in-terdependencies. So far, this coordination has mainly been accomplished manually, which has resulted in errors and inconsistencies. In order to deal with this problem, we have to better understand the interdependencies between the sub-processes to be coordinated. In particular, we can benefit from the fact that sub-processes are often correlated to the assembly of a product (represented by a product data struc-ture). This information can be utilized for the modeling and execution of so-called data-driven process structures. In this paper, we present the COREPRO demonstrator that supports the data-driven modeling of these process struc-tures. The approach explicitly establishes a close linkage between product data structures and engineering processes. 1",,F.: Data-driven design of engineering processes with COREPROModeler,,,,core
102184968,2005,,,What is Data Driven Design?...................................................................1 Advantages of Data Driven Design...........................................................1 Code Reuse........................................................,,,,core
102915151,2003,Abstract. Engineering design optimization using concurrent integrated experiment and simulation is a Dynamic Data Driven Application Sys-tem (DDDAS) wherein remote experiment and simulation can be syn-ergistically utilized in real-time to achieve better designs in less time than conventional methods. The paper describes the Data Driven Design Optimization Methodology (DDDOM) being developed for engineering design optimization,Springer-Verlag,Data driven design optimization methodology: A dynamic data driven application system,,10.1007/3-540-44864-0_34,,core
53768082,2008-01-01T00:00:00,"The wind power production spreading, also aided by the transition from constant to variable speed operation, involves the development of efficient control systems to improve the effectiveness of wind systems. This paper presents a data-driven design methodology able to generate a Takagi–Sugeno–Kang (TSK) fuzzy model for maximum energy extraction from variable speed wind turbines. In order to obtain the TSK model, fuzzy clustering methods for partitioning the input–output space, combined with genetic algorithms (GA), and recursive least-squares (LS) optimization methods for model parameter adaptation are used.
The implemented TSK fuzzy model, as confirmed by some simulation results on a doubly fed induction generator connected to a power system, exhibits high speed of computation, low memory occupancy, fault tolerance and learning capability",,A fuzzy controller for maximum energy extraction from variable speed wind power generation systems,,10.1016/j.epsr.2007.09.004,,core
15350434,1999,"This paper is the result of several years of research by the Authors into the new field of generative design, as applied to urbanism. Its purpose is to formulate a concept of parametric urbanism and data-driven urban design, and how it departs from existing concepts of urban analysis and resulting design methods. This paper first gives a definition and description of the notion of generative urban design, and its relevance to current the practice of architecture and global political, sociological and economic developments. The difference between dogmatic forms of urban design and new parametric research methods is explained, and the Authors argue the fundamental relevance of using examples of post-colonial large-scale projects. In support of this, the Authors explore the widening field of research into parametric and data-driven architecture and urban design and the history of rule-based and evolutionary design methodologies. The paper illustrates examples of successful research in the field of parametric and rule-based urban design, by the Authors as well as colleagues within the field. It surveys the Authorsi work done at the Architectural Association School of Architecture, at the Hong Kong Polytechnic University School of Design, as well as in practice and research-oriented consultancy. The projects illustrated support the thesis of parametric urbanism by showing its power and versatility when applied to very large-scale projects, in particular within the Peopleis Republic of China",,Parametric Urbanism: Explorations in Generative Urban Design,,,,core
34019925,2005,"This paper presents DONet, a Data-driven Overlay Network for live media streaming. The core operations in DONet are very simple: every node periodically exchanges data availability information with a set of partners, and retrieves unavailable data from one or more partners, or supplies available data to partners. We emphasize three salient features of this data-driven design: 1) easy to implement, as it does not have to construct and maintain a complex global structure; 2) efficient, as data forwarding is dynamically determined according to data availability while not restricted by specific directions; and 3) robust and resilient, as the partnerships enable adaptive and quick switching among multi-suppliers. We show through analysis that DONet is scalable with bounded delay. We also address a set of practical challenges for realizing DONet, and propose an efficient member- and partnership management algorithm, together with an intelligent scheduling algorithm that achieves real-time and continuous distribution of streaming contents. We have extensively evaluated the performance of DONet over the PlanetLab. Our experiments, involving almost all the active PlanetLab nodes, demonstrate that DONet achieves quite good streaming quality even under formidable network conditions. Moreover, its control overhead and transmission delay are both kept at low levels. An Internet-based DONet implementation, called CoolStreaming v.0.9, was released on May 30, 2004, which has attracted over 30000 distinct users with more than 4000 simultaneously being online at some peak times. We discuss the key issues toward designing CoolStreaming in this paper, and present several interesting observations from these large-scale tests; in particular, the larger the overlay size, the better the streaming quality it can deliver. © 2005 IEEE",,CoolStreaming/DONet: A data-driven overlay network for peer-to-peer live media streaming,,,"[{'title': None, 'identifiers': ['issn:0743-166X', '0743-166x']}]",core
67309387,,[[abstract]]平衡計分卡不單只是一個衡量系統，更是一個管理系統，能讓企業組織清楚定義其遠景和策略並將它們轉成實際的行動來實踐。此外，它能提供有關內部企業流程及外部成果的迴饋資訊，以持續不斷地改進策略績效及成果。但推行平衡計分卡需管理龐大的關鍵績效指標，而在各個關鍵績效指標間更存在著一系列複雜的因果關係；Meta data 可用於描述資源特性，對於處理複雜之資料關係，提供了一個最佳的實作選擇。本篇論文提出以Meta data 導向之平衡計分卡系統，我們將說明此技術架構和組件、提出一些應用情境、並討論其功能和未來方向,臺中健康暨管理學院,Meta Data-Driven Design for Balanced Scorecard System,https://core.ac.uk/download/67309387.doc,,,core
18194840,2006-01-01T08:00:00,"This study was designed to investigate teacher perceptions related to the quality of professional development being provided within six Ohio districts following active participation in a statewide initiative focused on the implementation of standards-based education. Two themes were developed for study. The first related to the degree to which teachers rated the quality of staff development based on the National Staff Development Council\u27s Standards for Staff Development (2001). For purposes of this study, professional development was categorized by Levels of Investment: (a) Level I included 620 teachers representing twenty-three schools in the six districts; (b) Level II included teacher leaders who had received specialized training to lead reform; and (c) Level III included 12/23 schools that had implemented professional learning teams with common-planning time as the primary model of staff development. Survey methodology was employed and results from the analysis of the NSDC Standards Assessment Inventory (2004) revealed: (a) teachers engaged in Level I Investment identified two standards at a significant level of implementation (context - leadership; content - equity); (b) teacher leaders (Level II Investment) identified one standard at a negative level (context - leadership); (c) teachers engaged in professional learning teams (Level III Investment) rated seven standards at a high degree of implementation (context - learning communities; process - collaboration, data-driven, design, evaluation; content - equity and quality teaching). Multivariate multiple regression analysis was used to explore impact of combined Level II and Level III investment. Teachers receiving professional development at these two levels identified 10 of the 12 standards at a significant level of implementation. The second theme sought to determine whether participation in a statewide initiative had impacted systemic change. The district with the longest history of professional learning teams had the highest reported level of impact on knowledge and skills at three levels of the system: district, school and classroom. In addition, two districts that had implemented professional learning teams reported the highest level of capacity for sustainability of reform efforts at the school-level",DigitalCommons@University of Nebraska - Lincoln,High-quality professional development: Teacher perceptions of practice within six Ohio districts engaged in standards -based reform,,,,core
21021395,1993,"This paper describes a new discourse module within our multilingual NLP system. Because of  its unique data-driven architecture, the discourse module is language-independent. Moreover, the use of hierarchically organized multiple knowledge sources makes the module robust and trainable using discourse-tagged corpora. Separating discourse phenomena from knowledge sources makes the discourse module easily extensible to additional phenomena",,A Language-Independent Anaphora Resolution System For Understanding Multilingual Texts,,10.3115/981574.981595,,core
22935607,2008,"The high level of heterogeneity between linguistic annotations usually complicates the interoperability of processing modules within an NLP pipeline. In this paper, a framework for the interoperation of NLP components, based on a data-driven architecture, is presented. Here, ontologies of linguistic annotation are employed to provide a conceptual basis for the tag-set neutral processing of linguistic annotations. The framework proposed here is based on a set of structured OWL ontologies: a reference ontology, a set of annotation models which formalize different annotation schemes, and a declarative linking between these, specified separately. This modular architecture is particularly scalable and flexible as it allows for the integration of different reference ontologies of linguistic annotations in order to overcome the absence of a consensus for an ontology of linguistic terminology. Our proposal originates from three lines of research from different fields: research on annotation type systems in UIMA; the ontological architecture OLiA, originally developed for sustainable documentation and annotation-independent corpus browsing, and the ontologies of the OntoTag model, targeted towards the processing of linguistic annotations in Semantic Web applications. We describe how UIMA annotations can be backed up by ontological specifications of annotation schemes as in the OLiA model, and how these are linked to the OntoTag ontologies, which allow for further ontological processing. 1",,Ontology-based interface specifications for a NLP pipeline architecture,,,,core
22722911,2000,"this paper, we are focusing on two design parameters, i.e., the number of states in HMM and the number of models for a class. Despite its importance, relatively little attention has been paid to the design of HMM topology. So far, suggested methods include intuition-based manual decision with empirical adjustment [3, 4], data-driven method by inferring the structural model of Markov network from a finite set of samples [5], and automatic state splitting method by maximum likelihood criterion [6]",World Scientific Publishing Company,Data Driven Design Of Hmm Topology For On-Line Handwriting Recognition,,,,core
23264590,2007-11-22,"The Decoupled Data-Driven (D  3  ) architecture has shown promising results from performance evaluations based upon simulations. This paper provides performance evaluations of the D  3  architecture through the formulation and analysis of a stochastic model. The model is validated by comparing the simulation and model output results. After model validation, various input parameters are varied and the performance of the architecture is evaluated. The model is based upon a closed queueing network and utilizes the concepts of available parallelism and virtual queues in order to be reduced to a Markovian system. Experiments with varying amounts of computation engine threadlengths and communication latencies indicate a high degree of tolerance with respect to exploited parallelism.  1 Introduction  The dataflow model of computation promises to exploit parallelism through asynchronous instruction execution on the basis of operand availability. Several different architectural approaches have ..",,Performance Evaluation of a Data Driven Architecture,,,,core
446261891,1992-01-01T00:00:00,,'Institute of Electrical and Electronics Engineers (IEEE)',A Data-driven Architecture For Rapid Prototyping Of High Throughput Dsp Algorithms,,10.1109/VLSISP.1992.641055,,core
293679638,2005-01-01T00:00:00,,IEEE Operations Center,Consistency control in data-driven design automation environments,,,,core
9660935,2005-06-22T00:00:00,"In this paper two approaches for the incremental data-driven learning of one of the most effective fuzzy model, namely of so-called Takagi-Sugeno type, are compared. The algorithms that realise these approaches include not only adaptation of linear parameters in fuzzy systems appearing in the rule consequents, but also incremental learning and evolution of premise parameters appearing in the membership functions (i.e. fuzzy sets) in sample mode together with a rule learning strategy. In this sense the proposed methods are applicable for fast model training tasks in various industrial processes, whenever there is a demand of online system identification in order to apply models representing nonlinear system behaviors to system monitoring, online fault detection or open-loop control. An evaluation of the incremental learning algorithms are included at the end of the paper, where a comparison between conventional batch modelling methods for fuzzy systems and the incremental learning methods demonstrated in this paper is made with respect to model qualities and computation time. This evaluation is based on high dimensional data coming from an industrial measuring process as well as from a known source on the Internet, which underlines the usage of the new method for fast online identification tasks",'Institute of Electrical and Electronics Engineers (IEEE)',Two approaches to data-driven design of evolving fuzzy systems: eTS and FLEXFIS,,10.1109/NAFIPS.2005.1548502,,core
11468213,2007,"Enterprises increasingly demand IT support for the coordination of their engineering processes, which often consist of hundreds up to thousands of sub-processes. From a technical viewpoint, these sub-processes have to be concurrently executed and synchronized considering numerous interdependencies.
So far, this coordination has mainly been accomplished manually, which has resulted in errors and inconsistencies. In order to deal with this problem, we have to better understand the interdependencies between the subprocesses to be coordinated. In particular, we can benefit from the fact that sub-processes are often correlated to the assembly of a product (represented by a product data structure). This information can be utilized for the modeling and execution of so-called data-driven process structures. In this paper, we present the COREPRO demonstrator that supports the data-driven modeling of these process structures. The approach explicitly establishes a close linkage between product data structures and engineering processes",IEEE Computer Society Press,Data-driven Design of Engineering Processes with COREPROModeler,https://core.ac.uk/download/pdf/11468213.pdf,10.1109/wetice.2007.4407191,,core
20865106,2003,Abstract. Engineering design optimization using concurrent integrated experiment and simulation is a Dynamic Data Driven Application System (DDDAS) wherein remote experiment and simulation can be synergistically utilized in real-time to achieve better designs in less time than conventional methods. The paper describes the Data Driven Design Optimization Methodology (DDDOM) being developed for engineering design optimization,Springer-Verlag,Data driven design optimization methodology: A dynamic data driven application system,,,,core
24278412,2007-11-22,"The Decoupled Data-Driven (D  3  ) architecture has shown promising results from performance evaluations based upon simulations. This paper provides performance evaluations of the D  3  architecture through the formulation and analysis of a stochastic model. The model is validated by comparing the simulation and model output results. After model validation, various input parameters are varied and the performance of the architecture is evaluated. The model is based upon a closed queueing network and utilizes the concepts of available parallelism and virtual queues in order to be reduced to a Markovian system. Experiments with varying amounts of computation engine threadlengths and communication latencies indicate a high degree of tolerance with respect to exploited parallelism. 1 Introduction  The dataflow model of computation promises to exploit parallelism through asynchronous instruction execution on the basis of operand availability. Several different architectural approaches have b..",,Performance Evaluation of a Data Driven Architecture,,,,core
24438551,2008-02-06,"Abstract. In this article, we discuss the motivation for a novel style of tutorial dialogue system that emphasizes reflection in a simulation based exploratory learning environment called CyclePad, which was developed in order to offer students practice at design and optimization of thermodynamic cycles. We argue that while typical forms of exploration support offered in simulation based learning environments are meant to encourage the development of good exploration process skills, the instantiation of these typical forms of support in CyclePad are not sufficient, primarily because students don’t choose to use them. We present a preliminary cognitive task analysis of design exploration tasks using CyclePad. Using this cognitive task analysis, we analyze data collected in two waves of formal data collection. Finally, we conclude with some system desiderata derived from our analysis as well as discussion of directions for continued experimental investigations related to tutor style",,CycleTalk: Data Driven Design of Support for Simulation Based Learning,,,,core
195383281,"May 12, 2008","This paper addresses the efforts undertaken and the technology deployed to aggregate and distribute the metadata characterizing the real-time operations associated with NASA Earth Observing Systems (EOS) high-rate front-end systems and the science data collected at multiple ground stations and forwarded to the Goddard Space Flight Center for level 0 processing. Station operators, mission project management personnel, spacecraft flight operations personnel and data end-users for various EOS missions can retrieve the information at any time from any location having access to the internet. The users are distributed and the EOS systems are distributed but the centralized metadata accessed via an external web server provide an effective global and detailed view of the enterprise-wide events as they are happening. The data-driven architecture and the implementation of applied middleware technology, open source database, open source monitoring tools, and external web server converge nicely to fulfill the various needs of the enterprise. The timeliness and content of the information provided are key to making timely and correct decisions which reduce project risk and enhance overall customer satisfaction. The authors discuss security measures employed to limit access of data to authorized users only",,"Web Monitoring of EOS Front-End Ground Operations, Science Downlinks and Level 0 Processing",https://core.ac.uk/download/pdf/195383281.pdf,,,core
161675102,2009-09-17,"The present article dedicates itself to fuzzy modelling
of data-inherent structures. In particular two main points are dealt
with: the introduction of a fuzzy modelling framework and the elaboration
of an automated, data-driven design strategy to model complex
data-inherent structures within this framework.
The innovation concerning the modelling framework lies in the
fact that it is consistently built around a single, generic type of parametrical
and convex membership function. In the first part of the
article this essential building block will be defined and its assets and
shortcomings will be discussed.
The novelty regarding the automated, data-driven design strategy
consist in the conservation of the modelling framework when modelling
complex (nonconvex) data-inherent structures. Instead of applying
current clustering methods the design strategy uses the inverse
of the data structure in order to created a fuzzy model solely based
on convex membership functions.
Throughout the article the whole model design process is illustrated,
section by section, with the help of an academic example",Technische Universität Chemnitz,Parametric Fuzzy Modelling Framework for Complex Data-Inherent Structures,,,,core
280949256,2002-01-01T00:00:00,,'Institute of Electrical and Electronics Engineers (IEEE)',Data driven design of an ANN/HMM system for on-line unconstrained handwritten character recognition,,10.1109/ICMI.2002.1166984,,core
24453052,2006,"... led to the increased complexity in computing systems. The systems are thus becoming increasingly more complex with growing number of heterogeneous software and hardware components, increasingly more difficult to monitor, manage and maintain. As a result, it is not a trivial task to provide high performance, high dependability, and high manageability for such computing systems. In this paper, we first present an integrated data-driven architecture for computing system management and then present a case study on Autonomic System Manager: a software system we developed that is currently being used by the system and network administrators of School of Computing and Information Sciences (SCIS) at Florida International University (FIU)",,Data Mining for Autonomic System Management: A Case Study at Fiu-scis,,,,core
24704232,2008-04-01,"Abstract—Motion trajectories provide rich spatiotemporal information about an object’s activity. This paper presents novel classification algorithms for recognizing object activity using object motion trajectory. In the proposed classification system, trajectories are segmented at points of change in curvature, and the subtrajectories are represented by their principal component analysis (PCA) coefficients. We first present a framework to robustly estimate the multivariate probability density function based on PCA coefficients of the subtrajectories using Gaussian mixture models (GMMs). We show that GMM-based modeling alone cannot capture the temporal relations and ordering between underlying entities. To address this issue, we use hidden Markov models (HMMs) with a data-driven design in terms of number of states and topology (e.g., left-right versus ergodic). Experiments using a database of over 5700 complex trajectories (obtained from UCI-KDD data archives and Columbia University Multimedia Group) subdivided into 85 different classes demonstrate the superiority of our proposed HMM-based scheme using PCA coefficients of subtrajectories in comparison with other techniques in the literature. Index Terms—Activity recognition, Gaussian mixture models (GMMs), hidden Markov models (HMMs), trajectory modeling",,Object trajectory-based activity classification and recognition using hidden Markov models,,,,core
364517049,2005-01-01T00:00:00,,'Elsevier BV',SUBSPACE METHOD AIDED DATA-DRIVEN DESIGN OF OBSERVER BASED FAULT DETECTION SYSTEMS,,10.3182/20050703-6-CZ-1902.01830,,core
24418868,2005,"This paper presents DONet, a Data-driven Overlay Network for live media streaming. The core operations in DONet are very simple: every node periodically exchanges data availability information with a set of partners, and retrieves unavailable data from one or more partners, or supplies available data to partners. We emphasize three salient features of this data-driven design: 1) easy to implement, as it does not have to construct and maintain a complex global structure; 2) efficient, as data forwarding is dynamically determined according to data availability while not restricted by specific directions; and 3) robust and resilient, as the partnerships enable adaptive and quick switching among multi-suppliers. We show through analysis that DONet is scalable with bounded delay. We also address a set of practical challenges for realizing DONet, and propose an efficient member- and partnership management algorithm, together with an intelligent scheduling algorithm that achieves real-time and continuous distribution of streaming contents",,CoolStreaming/DONet: A Data-driven Overlay Network for Peer-to-Peer Live Media Streaming,,,,core
24670046,2008-04-01,"Abstract — Motion trajectories provide rich spatio-temporal information about an object’s activity. Developing scalable activity recognition algorithms based on this high dimensionality cue is an extremely challenging task. This paper presents novel classification algorithms for recognizing object activity using object motion trajectory. The trajectory information can be obtained using a tracking algorithm on data streams available from a range of devices including motion sensors, video cameras, haptic devices, etc. In the proposed classification system, trajectories are segmented at points of change in curvature and the subtrajectories are represented by their Principal Component Analysis (PCA) coefficients. We first present a framework to robustly estimate the multivariate probability density function (PDF) based on PCA coefficients of the subtrajectories using Gaussian Mixture Models (GMM). We show that GMM-based modeling alone cannot capture the temporal relations and ordering between underlying entities. To address this issue, we use Hidden Markov Models (HMM) with a data-driven design in terms of number of states and topology (e.g. left-right versus ergodic). Different classes of object motions are modeled by a Continuous HMM (i.e. state observations are drawn from a continuous PDF) per class, where the state PDFs are represented by GMMs. Experiments using a database of over 5700 complex trajectories (obtained from UCI-KDD data archives and Columbia University Vision Group) subdivided into 85 different classes demonstrate the superiority of our proposed HMM-based scheme using PCA coefficients of subtrajectories in comparison with other techniques in the literature",,"Models, Gaussian Mixture",,,,core
20713859,1998,"Fundamental issues are discussed pertinent to the problem of generic, scalable parallel computing. It is argued that a generic system should be a data-driven, bulk-synchronous one with scalable communications. We show that data-driven architectures can be achieved without any loss of the efficiency found RISC-based microprocessors. We also show how this data-driven architecture can be adapted to patterns of massivelyparallel computing and how this can be supported by compiler technology which infers data-distribution patterns as types in an advanced type system. This paper will look at asynchrony as used at many different scales in parallel computing, from the chi",,Asynchrony in Parallel Computing – A question of Scale,,,,core
100596688,2007,"Abstract: The complexity of Enterprise Information Systems can be overwhelming to users, yet they are an often over-looked domain for usability research. To better understand the ways in which users interact with these systems, we have designed an infrastructure for input logging that is built upon a data model relating system compo-nents, user inputs, and tasks. This infrastructure is aware of user representations, task representations, and the history of user interactions. The interface components themselves log user inputs, so that timing data and action events are automatically aligned and are linked to specific tasks. The knowledge gained about user interactions at varying levels of granularity, ranging from keystroke analysis to higher-level task performance, is a valuable resource for both assessing and enhancing system usability. ",,A data-driven design for deriving usability metrics,,,,core
102664185,1999,"Abstract. Conceptual Information Systems unfold the conceptual struc-ture of data stored in relational databases. In the design phase of the system, conceptual hierarchies have to be created which describe dier-ent aspects of the data. In this paper, we describe two principal ways of designing such conceptual hierarchies, data driven design and theory driven design, and discuss advantages and drawbacks. The central part of the paper shows how Attribute Exploration, a knowledge acquisition tool developed by B. Ganter can be applied for narrowing the gap between both approaches",Springer,Acquiring Expert Knowledge for the Design of Conceptual,,,,core
154902455,2008-01-01T00:00:00,"The wind power production spreading, also aided by the transition from constant to variable speed operation, involves the development of efficient control systems to improve the effectiveness of power production systems. This paper presents a data-driven design methodology able to generate a Takagi-Sugeno-Kang (TSK) fuzzy model for maximum energy extraction from variable speed wind turbines. In order to obtain the TSK model, fuzzy clustering methods for partitioning the input-output space, combined with genetic algorithms, and recursive least-squares optimization methods for model parameter adaptation are used. The implemented TSK fuzzy model, as confirmed by some simulation results on a doubly fed induction generator connected to a power system, exhibits high speed of computation, low memory occupancy, fault tolerance, and learning capability. Â© 2008 IEEE",'Institute of Electrical and Electronics Engineers (IEEE)',Designing an adaptive fuzzy controller for maximum wind energy extraction,,10.1109/TEC.2007.914164,,core
22636098,2006,"Adverse environments not only corrupt speech signal by additive and convolutional noises, which can be successfully addressed by a number of suppression algorithms, but also affect the way how speech is produced. Speech production variations introduced by a speaker in reaction to a noisy background (Lombard effect) may result in a severe degradation of automatic speech recognition. This paper contributes to the solution of Lombard speech recognition issue by providing a robust filter bank for use in front-ends. It is shown that cepstral features derived from the proposed filter bank significantly outperform conventional cepstral features. Index Terms: robust speech recognition, Lombard effect, feature extraction, filter bank, data-driven desig",,Data-driven design of front-end filter bank for Lombard speech recognition,,,,core
20998529,2009-02-02,"This paper is dedicated to data driven design method for a hybrid ANN / HMM based handwriting recognition system. On one hand, a data driven designed neural modelling of handwriting primitives is proposed. ANNs are firstly used as state models in a HMM primitive divider that associates each signal frame with an ANN by minimizing the accumulated prediction error. Then, the neural modelling is realized by training each network on its own frame set. Organizing these two steps in an EM algorithm, precise primitive models are obtained. On the other hand, a data driven systematic method is proposed for HMM topology inference task. All possible prototypes of a pattern class are firstly merged into several clusters by a Tabu search aided clustering algorithm. Then a multiple parallel-path HMM is constructed for the pattern class. Experiments prove an 8 % recognition improvement with a saving of 50 % of system resources, compared to an intuitively designed referential ANN / HMM system. 1",,Data Driven Design of an ANN/HMM System for On-line Unconstrained Handwritten Character Recognition,,,,core
299373399,2007-06-01T00:00:00,"Enterprises increasingly demand IT support for the coordination of their engineering processes, which often consist of hundreds up to thousands of sub-processes. From a technical viewpoint, these sub-processes have to be concurrently executed and synchronized considering numerous interdependencies.

So far, this coordination has mainly been accomplished manually, which has resulted in errors and inconsistencies. In order to deal with this problem, we have to better understand the interdependencies between the subprocesses to be coordinated. In particular, we can benefit from the fact that sub-processes are often correlated to the assembly of a product (represented by a product data structure). This information can be utilized for the modeling and execution of so-called data-driven process structures. In this paper, we present the COREPRO demonstrator that supports the data-driven modeling of these process structures. The approach explicitly establishes a close linkage between product data structures and engineering processes",'Institute of Electrical and Electronics Engineers (IEEE)',Data-driven Design of Engineering Processes with COREPRO-Modeler,https://core.ac.uk/download/299373399.pdf,10.1109/WETICE.2007.136,,core
199642562,1991-11-01T00:00:00,"International Telemetering Conference Proceedings / November 04-07, 1991 / Riviera Hotel and Convention Center, Las Vegas, NevadaThe Multi-Stream Data-Driven Telemetry System (MSDDTS) is a new generation system in China developed by Beijing Research Institute of Telemetry (BRIT) for high bit rate, multi-stream data acquisition, processing and display. Features of the MSDDTS include: .Up to 4 data streams; .Data driven architecture; .Multi-processor for parallel processing; .Modular, Configurable, expandable and programmable; .Stand-along capability; .And, external control by host computer. This paper addresses three very important aspects of the MSDDTS. First, the system architecture is discussed. Second, three basic models of the system configuration are described. The third shows the future development of the system.International Foundation for TelemeteringProceedings from the International Telemetering Conference are made available by the International Foundation for Telemetering and the University of Arizona Libraries. Visit http://www.telemetry.org/index.php/contact-us if you have questions about items in this collection",International Foundation for Telemetering,MULTI-STREAM DATA-DRIVEN TELEMETRY SYSTEM,,,"[{'title': None, 'identifiers': ['0884-5123', 'issn:0884-5123', 'issn:0074-9079', '0074-9079']}]",core
21020356,1999,"Conceptual Information Systems unfold the conceptual structure  of data stored in relational databases. In the design phase of the  system, conceptual hierarchies have to be created which describe different  aspects of the data. In this paper, we describe two principal ways  of designing such conceptual hierarchies, data driven design and theory  driven design, and discuss advantages and drawbacks. The central part of  the paper shows how Attribute Exploration, a knowledge acquisition tool  developed by B. Ganter can be applied for narrowing the gap between  both approaches",Springer,Acquiring Expert Knowledge for the Design of Conceptual Information Systems,,10.1007/3-540-48775-1_17,,core
20863644,2008-12-03,"DCOS is a Data Centric lightweight Operating System for embedded devices. Despite limited energy and hardware resources, it supports a data driven architecture with provisions for dynamic loadable Modules. It combines these with Real-Time provisions based on Earliest Deadline First with a simple but smart resource handling mechanism. We will give an overview of the capabilities of DCOS and we will describe the basics of the main mechanisms 1",,"DCOS, A REAL-TIME LIGHT-WEIGHT DATA CENTRIC OPERATING SYSTEM",,,,core
100219759,1997,"We describe use of Linear Discriminant Analysis (LDA) for data-driven automatic design of RASTA-like lters. The LDA applied to rather long segments of time trajectories of critical-band energies yields FIR lters to be applied to these time trajectories in the feature extraction module. Fre-quency responses of the rst three discriminant vectors are in principle consistent with the ad hoc designed RASTA, delta and double-delta lters. On a connected digit task the new features outperform the original RASTA processing. 1",,Data-driven design of RASTA-like filters,,,,core
147916631,2006-04-24T06:59:09,"The expansion of 3D real-time simulations (3DRTS) into millions of homes together with the technical progress of computers hardware force to approach software developments for 3DRTS from different perspectives. From an historical standpoint, 3DRTS started principally as homebrew developments. The underlined consequences are the lack of standardization for producing such applications. Nowadays, computers hardware can reproduce close to photo-realism 3D images within interactive environments. This was made possible with the continuous improvements in computers hardware. During many years, the hardware evolution was following vertical speed-up improvements, by increasing CPU clocks speed and memory bandwidth. Today, we are reaching the limits of this approach from a power consumption, heat, and intrinsic materials characteristics perspectives. As an outcome, the next-generation of computer hardware and home consoles are presenting multitasking architectures. This obliges to re-think software development for 3DRTS, moving from the serial and single-threaded approach to a concurrent design. We explore conceptual designs handling the current scale and complexity offered by 3DRTS developments by adopting stronger engineering practices. This is needed to control the underlined complexity and rising developments costs. The direct consequence of being able to generate highly detailed virtual worlds is to involve more deeply artists and designers in the development process. We propose mechanisms that free developers from common low-levels problematic, such as memory management or data synchronization issues. Our architecture relies on extending the Component Based Development (CBD) model for multitasking architectures. This obliges to define specific patterns either directly inspired by other fields in computer science or dedicated for 3DRTS. This includes promoting multi-layer design where the low-level routines are tightly connected to computer hardware by describing the importance of conceiving hardware-oblivious systems. This is important, as memory bandwidth is becoming the principal bottleneck in current applications. Another fundamental aspect consists to move from the single iterative global loop commonly found in single-threaded systems, by incorporating mechanisms for balancing the workflow more accurately. If those optimizations and evolutions are required for assuring efficient real-time performance, they do not allow non-programmers to interact with the system with ease. Our method consists to promote high-level languages and concurrent model relying on Microthreads. This gives the ability to develop and execute scripts in a multitasking environment without the common C/C++ issues. This is primordial to let designers experiment with ideas in a safer and efficient environment. This will leads to adopt the data-driven paradigm to control agents in our simulations, by clearly separating the logic and data layers. This offer better flexibility and reduce the existence of simulation specific code. In addition, we illustrate that the best technology and designs have a limited meaning, if they do not come with a complete production pipeline for managing and controlling simulation assets. This also affects fine tuning parameters where different hardware may perform better in some areas or worse in other. Finally, different use-cases demonstrate the strong and weakness aspects of our approach","Lausanne, EPFL",A multitasking and data-driven architecture for multi-agents simulations,https://core.ac.uk/download/147916631.pdf,10.5075/epfl-thesis-3545,,core
229296196,2007-10-11T00:00:00,"Virtual Prototyping (VP) is a data-driven design process that promotes both knowledge reuse and innovation. High-profile applications in the automotive and aerospace industries have demonstrated its potential to significantly reduce prototype cycles, time to market, and total product cost. This paper addresses VP as a specialized application of Decision-Support Systems, and discusses common requirements for engineering design tools, as well as requirements specific to the design of electronic products, such as mobile phones. Motorola Labs' test bed for VP is introduced in terms of its open, agent-based architecture utilizing Java CORBA. One of the key principles of the VP System is the reuse of expert knowledge across multiple engineering domains. This is highlighted via several use cases, showing that the system can function not only as an Intranet-accessible repository of model services but also as an integral part of decision-making within the native CAD environment",'AGHU University of Science and Technology Press',A Distributed Decision-Support System for Virtual Prototyping,https://core.ac.uk/download/229296196.pdf,10.7494/dmms.2007.1.2.137,,core
81372427,1993-01-01T00:00:00,"The paper examines the problem of dataflow graph partitioning aiming to improve the efficiency of macro-dataflow computing on a hybrid control/data driven architecture. The partitioning consists of dataflow graph synchronization and scheduling of the synchronous graph. A new scheduling algorithm, called Global Arc Minimization (GAM), is introduced. The performance of the GAM algorithm is evaluated relative to some other known heuristic methods for static scheduling. When interprocessor communication delays are taken into account, the GAM algorithm achieves better performance on the simulated hybrid architecture",SRCE - University Computing Centre,Program Partitioning for a Control/Data Driven Computer,https://core.ac.uk/download/81372427.pdf,,,core
