id,type,publication,publisher,publication_date,database,title,url,abstract,domain
10.1016/j.eswa.2021.116203,Journal,Expert Systems with Applications,scopus,2022-03-15,sciencedirect,Semantic segmentation based stereo visual servoing of nonholonomic mobile robot in intelligent manufacturing environment,https://api.elsevier.com/content/abstract/scopus_id/85119331942,"In the interest of developing an intelligent manufacturing environment with an agile, efficient, and optimally utilized transportation system, mobile robots need to achieve a certain level of autonomy as they play an important role in carrying out transportation tasks. Bearing this in mind, in the paper we propose a novel stereo visual servoing method for nonholonomic mobile robot control based on semantic segmentation. Semantic segmentation provides a rich body of information required for an adequate decision-making process in a clustered, dynamic, and ever-changing manufacturing environment. The innovative idea behind the new visual servoing system is to utilize semantic information of the scene for visual servoing, as well as for other mobile robot tasks, such as obstacle avoidance, scene understanding, and simultaneous localization and mapping. Semantic segmentation is carried out by exploiting fully convolutional neural networks. The new visual servoing algorithm utilizes an intensity-based image registration procedure, which results in the image transformation matrix. The transformation matrix encompasses the relations of images taken at the current and desired pose, and that information is directly used for visual servoing. The developed algorithm is deployed on our own developed wheeled differential drive mobile robot RAICO (Robot with Artificial Intelligence based COgnition). The experimental evaluation is carried out in the 3D simulation environment and in the laboratory model of the real manufacturing environment. The experimental results show that the accuracy of the proposed approach is improved when compared to the state-of-the-art approaches while being robust to the partial occlusions of the scene and illumination changes.",multimedia
10.1016/j.resconrec.2021.106022,Journal,"Resources, Conservation and Recycling",scopus,2022-03-01,sciencedirect,Using computer vision to recognize composition of construction waste mixtures: A semantic segmentation approach,https://api.elsevier.com/content/abstract/scopus_id/85118570774,"Timely and accurate recognition of construction waste (CW) composition can provide yardstick information for its subsequent management (e.g., segregation, determining proper disposal destination). Increasingly, smart technologies such as computer vision (CV), robotics, and artificial intelligence (AI) are deployed to automate waste composition recognition. Existing studies focus on individual waste objects in well-controlled environments, but do not consider the complexity of the real-life scenarios. This research takes the challenges of the mixture and clutter nature of CW as a departure point and attempts to automate CW composition recognition by using CV technologies. Firstly, meticulous data collection, cleansing, and annotation efforts are made to create a high-quality CW dataset comprising 5,366 images. Then, a state-of-the-art CV semantic segmentation technique, DeepLabv3+, is introduced to develop a CW segmentation model. Finally, several training hyperparameters are tested via orthogonal experiments to calibrate the model performance. The proposed approach achieved a mean Intersection over Union (mIoU) of 0.56 in segmenting nine types of materials/objects with a time performance of 0.51 s per image. The approach was found to be robust to variation of illumination and vehicle types. The study contributes to the important problem of material composition recognition, formalizing a deep learning-based semantic segmentation approach for CW composition recognition in complex environments. It paves the way for better CW management, particularly in engaging robotics, in the future. The trained models are hosted on GitHub, based on which researchers can further finetune for their specific applications.",multimedia
10.1016/j.ymssp.2021.108284,Journal,Mechanical Systems and Signal Processing,scopus,2022-02-15,sciencedirect,Real-time model calibration with deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85112506465,"The real-time, and accurate inference of model parameters is of great importance in many scientific and engineering disciplines that use computational models (such as a digital twin) for the analysis and prediction of complex physical processes. However, fast and accurate inference for processes of complex systems cannot easily be achieved in real-time with state-of-the-art methods under noisy real-world conditions with the requirement of a real-time response. The primary reason is that the inference of model parameters with traditional techniques based on optimization or sampling often suffers from computational and statistical challenges, resulting in a trade-off between accuracy and deployment time. In this paper, we propose a novel framework for inference of model parameters based on reinforcement learning. The proposed methodology is demonstrated and evaluated on two different physics-based models of turbofan engines. The experimental results demonstrate that the proposed methodology outperforms all other tested methods in terms of speed and robustness, with high inference accuracy.",multimedia
10.1016/j.cose.2021.102539,Journal,Computers and Security,scopus,2022-02-01,sciencedirect,Deep face fuzzy vault: Implementation and performance,https://api.elsevier.com/content/abstract/scopus_id/85119176199,"Biometric technologies, especially face recognition, have become an essential part of identity management systems worldwide. In deployments of biometrics, secure storage of biometric information is necessary in order to protect the users’ privacy. In this context, biometric cryptosystems are designed to meet key requirements of biometric information protection enabling a privacy-preserving storage and comparison of biometric data, e.g. feature vectors extracted from facial images. Until now, biometric cryptosystems have hardly been applied to state-of-the-art biometric recognition systems utilizing deep convolutional neural networks.
                  This work investigates the application of a well-known biometric cryptosystem, i.e. the improved fuzzy vault scheme, to facial feature vectors extracted through deep convolutional neural networks. To this end, a feature transformation method is introduced which maps fixed-length real-valued deep feature vectors to integer-valued feature sets. As part of said feature transformation, a detailed analysis of different feature quantisation and binarisation techniques is conducted. At key binding, obtained feature sets are locked in an unlinkable improved fuzzy vault. For key retrieval, the efficiency of different polynomial reconstruction techniques is investigated. The proposed feature transformation method and template protection scheme are agnostic of the biometric characteristic and, thus, can be applied to virtually any biometric features computed by a deep neural network. In experiments, an unlinkable improved deep face fuzzy vault-based template protection scheme is constructed employing features extracted with a state-of-the-art deep convolutional neural network trained with the additive angular margin loss (ArcFace). For the best configuration, a false non-match rate below 1% at a false match rate of 0.01%, is achieved in cross-database experiments on the FERET and FRGCv2 face databases. On average, a security level of up to approximately 28 bits is obtained. This work presents an effective face-based fuzzy vault scheme providing privacy protection of facial reference data as well as digital key derivation from face.",multimedia
10.1016/j.eswa.2021.116073,Journal,Expert Systems with Applications,scopus,2022-02-01,sciencedirect,Efficient machine learning approach for volunteer eye-blink detection in real-time using webcam,https://api.elsevier.com/content/abstract/scopus_id/85117617175,"The progressive diminishment of motor capacities due to Amyotrophic Lateral Sclerosis (ALS) causes a severe communication deficit. The development of Alternative Communication software aids ALS patients in overcoming communication issues and the detection of communication signals plays a big role in this task. In this paper, volunteer eye-blinking is proposed as human–computer interaction signal and an intelligent Computer Vision detector was built for handling the captured data in real-time using a generic webcam. The eye-blink detection was treated as an extension of the eye-state classification, and the base pipeline used is delineated as follows: face detection, face alignment, region-of-interest (ROI) extraction, and eye-state classification. Furthermore, this pipeline was complemented with auxiliary models: a rotation compensator, a ROIs evaluator, and a moving average filter. Two new datasets were created: the Youtube Eye-state Classification (YEC) dataset, built from the AVSpeech dataset by extracting face images; and the Autonomus Blink Dataset (ABD), built completely as a result of the present work. The YEC allowed training the eye-classification task; ABD was specifically idealized taking into consideration volunteer eye-blinking detection. The proposed models, a Convolutional Neural Network (CNN) and a Support Vector Machine (SVM), were trained by the YEC dataset and performance evaluation experiments for both models were conducted across different databases: CeW, ZJU, Eyeblink, Talking Face (public datasets) and ABD. The impact of the proposed auxiliary models was evaluated and the CNN and SVM models were compared for the eye-state classification task. Promising results were obtained: 97.44% accuracy for the eye-state classification task on the CeW dataset and 92.63% F1-Score for the eye-blink detection task on the ABD dataset.",multimedia
10.1016/j.future.2021.08.030,Journal,Future Generation Computer Systems,scopus,2022-02-01,sciencedirect,A wearable-based posture recognition system with AI-assisted approach for healthcare IoT,https://api.elsevier.com/content/abstract/scopus_id/85115908462,"Human posture recognition is a challenging task in the medical healthcare industry, when pursuing intelligence, accuracy, security, privacy, and efficiency, etc. Currently, the main posture recognition methods are captured-behaviors-based visual image analysis and wearable devices-based signal analysis. However, these methods suffer from issues such as high misjudgment rate, high-cost and low-efficiency. To address these issues, we propose a collaborative AI-IoT-based solution (namely, WMHPR) that embeds with advanced AI-assisted approach. In WMHPR, we propose the multi-posture recognition (MPR), an offline algorithm is implemented on wearable hardware, to identify posture based on multi-dimensions data. Meanwhile, an AI-based algorithm running on the cloud server (online), named Cascade-AdaBoosting-CART (CACT), is proposed to further enhance the reliability and accuracy of MPR. We recruit 20 volunteers for real-life experiments to evaluate the effectiveness, and the results show our solution is significantly outstanding in terms of accuracy and reliability while comparing with other typical algorithms.",multimedia
10.1016/j.inffus.2021.09.004,Journal,Information Fusion,scopus,2022-02-01,sciencedirect,Multimodal Earth observation data fusion: Graph-based approach in shared latent space,https://api.elsevier.com/content/abstract/scopus_id/85115401406,"Multiple and heterogenous Earth observation (EO) platforms are broadly used for a wide array of applications, and the integration of these diverse modalities facilitates better extraction of information than using them individually. The detection capability of the multispectral unmanned aerial vehicle (UAV) and satellite imagery can be significantly improved by fusing with ground hyperspectral data. However, variability in spatial and spectral resolution can affect the efficiency of such dataset's fusion. In this study, to address the modality bias, the input data was projected to a shared latent space using cross-modal generative approaches or guided unsupervised transformation. The proposed adversarial networks and variational encoder-based strategies used bi-directional transformations to model the cross-domain correlation without using cross-domain correspondence. It may be noted that an interpolation-based convolution was adopted instead of the normal convolution for learning the features of the point spectral data (ground spectra). The proposed generative adversarial network-based approach employed dynamic time wrapping based layers along with a cyclic consistency constraint to use the minimal number of unlabeled samples, having cross-domain correlation, to compute a cross-modal generative latent space. The proposed variational encoder-based transformation also addressed the cross-modal resolution differences and limited availability of cross-domain samples by using a mixture of expert-based strategy, cross-domain constraints, and adversarial learning. In addition, the latent space was modelled to be composed of modality independent and modality dependent spaces, thereby further reducing the requirement of training samples and addressing the cross-modality biases. An unsupervised covariance guided transformation was also proposed to transform the labelled samples without using cross-domain correlation prior. The proposed latent space transformation approaches resolved the requirement of cross-domain samples which has been a critical issue with the fusion of multi-modal Earth observation data. This study also proposed a latent graph generation and graph convolutional approach to predict the labels resolving the domain discrepancy and cross-modality biases. Based on the experiments over different standard benchmark airborne datasets and real-world UAV datasets, the developed approaches outperformed the prominent hyperspectral panchromatic sharpening, image fusion, and domain adaptation approaches. By using specific constraints and regularizations, the network developed was less sensitive to network parameters, unlike in similar implementations. The proposed approach illustrated improved generalizability in comparison with the prominent existing approaches. In addition to the fusion-based classification of the multispectral and hyperspectral datasets, the proposed approach was extended to the classification of hyperspectral airborne datasets where the latent graph generation and convolution were employed to resolve the domain bias with a small number of training samples. Overall, the developed transformations and architectures will be useful for the semantic interpretation and analysis of multimodal data and are applicable to signal processing, manifold learning, video analysis, data mining, and time series analysis, to name a few.",multimedia
10.1016/j.aej.2021.06.024,Journal,Alexandria Engineering Journal,scopus,2022-02-01,sciencedirect,"Automatic diagnosis of COVID-19 disease using deep convolutional neural network with multi-feature channel from respiratory sound data: Cough, voice, and breath",https://api.elsevier.com/content/abstract/scopus_id/85109458695,"The problem of respiratory sound classification has received good attention from the clinical scientists and medical researcher’s community in the last year to the diagnosis of COVID-19 disease. The Artificial Intelligence (AI) based models deployed into the real-world to identify the COVID-19 disease from human-generated sounds such as voice/speech, dry cough, and breath. The CNN (Convolutional Neural Network) is used to solve many real-world problems with Artificial Intelligence (AI) based machines. We have proposed and implemented a multi-channeled Deep Convolutional Neural Network (DCNN) for automatic diagnosis of COVID-19 disease from human respiratory sounds like a voice, dry cough, and breath, and it will give better accuracy and performance than previous models. We have applied multi-feature channels such as the data De-noising Auto Encoder (DAE) technique, GFCC (Gamma-tone Frequency Cepstral Coefficients), and IMFCC (Improved Multi-frequency Cepstral Coefficients) methods on augmented data to extract the deep features for the input of the CNN. The proposed approach improves system performance to the diagnosis of COVID-19 disease and provides better results on the COVID-19 respiratory sound dataset.",multimedia
10.1016/j.apacoust.2021.108439,Journal,Applied Acoustics,scopus,2022-01-15,sciencedirect,"CAMNet: A controllable acoustic model for efficient, expressive, high-quality text-to-speech",https://api.elsevier.com/content/abstract/scopus_id/85116891718,"Spoken language is becoming one of the key components of human–machine interaction, both to send information to the machine – e.g. voice control – and to receive from it – e.g. virtual assistants. In this scenario, text-to-speech (TTS) models have become an essential artificial intelligence capacity. Even though this interaction can be based on neutral style speech, generating speech with different styles, pitches and speaking rates may improve user experience. With this in view, this paper presents CAMNet, a controllable acoustic model for efficient, expressive, high-quality TTS. CAMNet is based on deep convolutional TTS (DCTTS), a state-of-art acoustic model which is efficient and produces neutral speech. DCTTS was first adapted to generate Bark cepstrum acoustic features in order to integrate well with the LPCNet (linear prediction coefficient) neural vocoder and to remove the reduction factor which demanded the presence of an upsampling network before the vocoder – i.e. the CAMNet output can be directly fed into LPCNet. Next, style transfer functionality was added by means of a novel characterisation of the prosodic information from the Bark cepstrum acoustic features and a new approach to inject this information into the convolutional layers. Finally, controllability is provided via a variational auto-encoder module which creates a smoothed disentangled latent space which allows interpolation and extrapolation of reference styles as well as independent and simultaneous control of two generative factors: pitch and speaking rate. Moreover, this controllability is implemented using a simple offset-based approach. To sum up, CAMNet is an efficient acoustic model which provides a simple but consistent controllability on coarse-grained expression, pitch and speaking rate while still providing high-quality synthesised speech.",multimedia
10.1016/j.jobe.2021.103571,Journal,Journal of Building Engineering,scopus,2022-01-01,sciencedirect,An integrated building energy performance evaluation method: From parametric modeling to GA-NN based energy consumption prediction modeling,https://api.elsevier.com/content/abstract/scopus_id/85119285403,"Building energy performance evaluation, as an important process in a sustainable building design, has important consequences for global energy conservation and environmental protection. The traditional methods to perform this evaluation are usually time-consuming and computationally complex, and have high requirements for designers’ professional knowledge on architectural physics and software operation skills. To solve these problems and provide rapid, user-friendly, and more accurate prediction results, this study presents an efficient building energy performance evaluation method which integrates building information modeling, energy simulation, and energy consumption prediction together. This method follows a three-stage research framework: Stage 1 proposes a rapid 3D building energy modeling process according to the parameterized setting, Stage 2 generates numerous simulation results automatically by EnergyPlus, and Stage 3 develops the user-friendly building energy consumption prediction model with the help of the Genetic Algorithm-Neural Network (GA-NN) and provides the energy performance level of the building design after the prediction. A case study is carried out to present the overall process and verify the accuracy of the proposed three-stage building energy performance evaluation method. This study contributes to the improvement of both the extensive dataset establishment and the operational efficiency of building energy consumption prediction. It can provide designers with a real-time, user-friendly, and reliable building energy consumption prediction tool and an energy performance assessment basis in the design phase of construction projects.",multimedia
10.1016/j.compind.2021.103556,Journal,Computers in Industry,scopus,2022-01-01,sciencedirect,C-Ports: A proposal for a comprehensive standardization and implementation plan of digital services offered by the “Port of the Future”,https://api.elsevier.com/content/abstract/scopus_id/85118477493,"In this paper we address the topic of a possible path to standardize the ICT services expected to be delivered by the so-called “Port of the Future”. How the most relevant technologies and Information Systems are used by the Port Communities for their businesses is discussed together with a detailed analysis of the on-going actions carried on by Standard Setting Organizations. Considering the examples given by the C-ITS Platform and the C-Roads programme at EU level, a proposal of contents to be considered in a comprehensive standardization action is given. The innovation services are therefore grouped into four bundles: (i) Vessel & Marine Navigation, (ii) e-Freight & (Intermodal) Logistics, (iii) Passenger Transport, (iv) Environmental sustainability. The standardized version of these applications will be finally labeled as C-Port services. Alongside the standardization plan, a proposal for ranking the ports on the basis of a specially-defined C-Port vector is discussed with the purpose of addressing the well-known lack of consensus around the mathematical definition of the Smart Port Index. Considering the good practice and the background offered by the Port of Livorno in terms of innovation actions, the prospected final user applications are then labeled as Day 1, Day 1.5, and Day 2 services in consideration of the technical and commercial gaps to be filled. As a case study about the evolution in the C-Port vector experienced by the Port of Livorno in the last years will also be discussed.",multimedia
10.1016/j.eswa.2021.115973,Journal,Expert Systems with Applications,scopus,2022-01-01,sciencedirect,Deep correlation mining for multi-task image clustering,https://api.elsevier.com/content/abstract/scopus_id/85116928779,"Multi-task clustering (MTC) aims to enhance the performance of each individual task by leveraging the correlation information among them. Existing MTC algorithms usually first extract the feature representations of each task and then learn the relationships among multiple tasks for clustering. However, the multi-task correlations are not embedded into the feature learning in existing MTC. In addition, many real applications, such as image clustering, always perform visual feature extraction and clustering assignment separately, which often results in local optimal clustering resolutions. In this study, an end-to-end MTC framework, named Deep correlation mining for Multi-Task image Clustering (DMTC), is proposed to explore multi-task correlations and conduct image clustering simultaneously. Specifically, DMTC consists of two sub-networks: a between-task network (B-net) and a within-task network (W-net), which learn the correlations among multiple tasks and the relationships in each individual task, respectively, based on a deep convolutional network. To optimize B-net, an optimization procedure is proposed as follows: (1) DMTC builds a pseudo-graph to discover similar samples among tasks and obtain the positive pairs of possible related tasks. (2) A discriminator is designed to calculate the mutual information between the deep and shallow representations of related tasks, which can estimate the relatedness between each pair of related tasks. After that, the trained parameters in B-net are transferred to the within-task networks (W-net) as their initialized parameters, in which the above optimization procedure is performed again to obtain the final cluster partition by end-to-end training. Experimental results on NUS-Wide, Caltech-256, Cifar-100 and Pascal VOC demonstrate that our proposed DMTC method
                        1
                     
                     
                        1
                        The source code is available in https://github.com/Xiaoqiang-Yan/DMTC.
                     compares favorably to the state-of-the-art methods.",multimedia
10.1016/j.autcon.2021.103996,Journal,Automation in Construction,scopus,2022-01-01,sciencedirect,Implementation experiments on convolutional neural network training using synthetic images for 3D pose estimation of an excavator on real images,https://api.elsevier.com/content/abstract/scopus_id/85116888055,"Remote and descriptive visualization of spatio-temporal information of excavator activities may increase awareness about jobsite hazards and operational performance in earthwork operations. One of the emerging approaches to collect this information is to extract the 3D pose of an excavator from the video frames using a convolutional neural network (CNN). However, this method requires labeling the training datasets, which are difficult to prepare because of conditions unsuitable for installing the motion capture sensors. This study investigates the performance of a CNN for estimating the 3D pose when trained on a synthetic dataset. In particular, a kinematic constraint is proposed to update the model parameters efficiently during training. The results show that the proposed method estimated the 3D poses of a real excavator with an average pose error of 9.63°. Hence, the proposed data augmentation method could help address the training data issues and improves the learning of real data complexity.",multimedia
10.1016/j.sigpro.2021.108317,Journal,Signal Processing,scopus,2022-01-01,sciencedirect,Selective fixed-filter active noise control based on convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85114690529,"Active noise control (ANC) technology is increasingly ubiquitous in wearable audio devices, or hearables. Owing to its low computational complexity, high robustness, and exemplary performance in dealing with dynamic noise, the fixed-coefficient control filter strategy plays a central role in portable ANC implementation. Unlike its traditional adaptive counterpart, the fixed-filter strategy is unable to attain optimal noise reduction for different types of noise. Hence, we propose a selective fixed-filter ANC method based on a simplified two-dimensional convolution neural network (2D CNN), which is implemented on a co-processor (e.g., in a mobile phone), to derive the most suitable control filter for different noise types. To further reduce classification complexity, we designed a lightweight one-dimensional CNN (1D CNN), which can directly classify noise types in time domain. A numerical simulation based on measured paths in headphones demonstrates the proposed algorithm’s efficacy in attenuating real-world non-stationary noise over conventional adaptive algorithms.",multimedia
10.1016/j.csl.2021.101275,Journal,Computer Speech and Language,scopus,2022-01-01,sciencedirect,Feature learning for efficient ASR-free keyword spotting in low-resource languages,https://api.elsevier.com/content/abstract/scopus_id/85113158279,"We consider feature learning for a computationally efficient method of keyword spotting that can be applied in severely under-resourced settings. The objective is to support humanitarian relief programmes by the United Nations (UN) in parts of Africa in which almost no language resources are available. To allow a keyword spotting system to be rapidly developed in such a language, we rely on a small and easily-compiled set of isolated keywords. Using the isolated keywords as templates, we apply dynamic time warping (DTW) to a much larger corpus of in-domain but untranscribed speech. The resulting DTW alignment scores are used to train a convolutional neural network (CNN) which is orders of magnitude more computationally efficient than DTW and therefore suitable for real-time application. We optimise this ASR-free neural network keyword spotting procedure by identifying acoustic features that provide robust performance in this almost zero-resource setting. First, we consider the benefits of incorporating information from well-resourced but unrelated languages by incorporating a multilingual bottleneck feature (BNF) extractor. Next, we consider using features extracted from an autoencoder (AE) trained on in-domain but untranscribed data. Finally, we consider features obtained from a correspondence autoencoder (CAE) which is initialised with the AE and subsequently fine-tuned on the small set of in-domain labelled data. Experiments in South African English and Luganda, a low-resource language, demonstrate that, on their own, both the BNF and CAE features can achieve a 5% relative performance improvement over baseline MFCCs. However, by using BNFs as input to the CAE, even better performance is achieved, resulting in a more than 27% relative improvement over MFCCs in ROC area-under-the-curve (AUC) and more than twice as many top-10 retrievals. We also show that, using these features, the CNN-DTW keyword spotter performs almost as well as the DTW keyword spotter while comfortably outperforming a baseline CNN trained only on the keyword templates. We conclude that a CNN-DTW keyword spotter using BNF-derived CAE features represents a computationally efficient approach with very competitive performance that is suited to rapid deployment in a severely under-resourced scenario.",multimedia
10.1016/j.petrol.2021.109332,Journal,Journal of Petroleum Science and Engineering,scopus,2022-01-01,sciencedirect,End-to-end neural network approach to 3D reservoir simulation and adaptation,https://api.elsevier.com/content/abstract/scopus_id/85112357560,"Reservoir simulation and adaptation (also known as history matching) are typically considered as separate problems. While a set of models are aimed at the solution of the forward simulation problem assuming all initial geological parameters are known, the other set of models adjust geological parameters under the fixed forward simulation model to fit production data. This results in many difficulties for both reservoir engineers and developers of new efficient computation schemes. We present a unified approach to reservoir simulation and adaptation problems. A single neural network model allows a forward pass from initial geological parameters of the 3D reservoir model through dynamic state variables to well’s production rates and backward gradient propagation to any model inputs and variables. The model fitting and geological parameters adaptation both become the optimization problem over specific parts of the same neural network model. Standard gradient-based optimization schemes can be used to find the optimal solution. Using real-world oilfield model and historical production rates we demonstrate that the suggested approach allows reservoir simulation and history matching with a benefit of several orders of magnitude simulation speed-up. Finally, to propagate this research we open-source a Python-based framework DeepField that allows standard processing of reservoir models and reproducing the approach presented in this paper.",multimedia
10.1016/j.comnet.2021.108513,Journal,Computer Networks,scopus,2021-12-09,sciencedirect,VCMaker: Content-aware configuration adaptation for video streaming and analysis in live augmented reality,https://api.elsevier.com/content/abstract/scopus_id/85117423121,"The emergence of edge computing has enabled mobile Augmented Reality (AR) on edge servers. We notice that the video configurations, i.e., frames per second (fps) and resolution, significantly affect the key metrics such as detection accuracy, data transmission latency and energy consumption in real AR application. Besides the time-varying bandwidth, we observe that the video contents, such as moving velocities of target objects, have remarkable impacts on the configuration selection. In addition, we take the energy consumption on data transmission into consideration. In this paper, we propose VCMaker, a system that generates video configuration decisions using reinforcement learning (RL). VCMaker trains a neural network model that selects configuration for future video chunks based on the collected observations. Rather than rely on any pre-programmed models, VCMaker learns to make configuration decisions solely through empirical observations of the resulting performances of historical decisions. In addition, we leverage the dynamic Region of Interest (RoI) encoding and motion vector-based object detection mechanisms to advance VCMaker. We implemented VCMaker and conducted extensive evaluations. The results show that VCMaker achieves a 20.5%–32.8% higher detection accuracy, and 25.2%–45.7% lower energy consumption than several state-of-the-art schemes.",multimedia
10.1016/j.knosys.2021.107504,Journal,Knowledge-Based Systems,scopus,2021-12-05,sciencedirect,Diacritics generation and application in hate speech detection on Vietnamese social networks,https://api.elsevier.com/content/abstract/scopus_id/85115945453,"One of the challenging problems in text processing is diacritics generation where one needs to generate diacritic marks for non-accented text. With an ever increasing amount of informal text without accents such as short text messages, emails or blog posts on social media, a software system which is capable of generating diacritic marks accurately is very useful and necessary in many situations. This paper presents an approach to improve the accuracy of diacritics generation for Vietnamese text. We propose two novel deep learning models which leverage a plausible conceptual representation for the phonetic structure of Vietnamese syllables. Experimental results on real-world datasets show that our models achieve a significant improvement as compared to the state-of-the-art methods for diacritics generation. We also demonstrate that the proposed models can be applied efficiently to improve the accuracy of hate speech detection on Vietnamese social networks.",multimedia
10.1016/j.ecoinf.2021.101475,Journal,Ecological Informatics,scopus,2021-12-01,sciencedirect,Automated feature-specific tree species identification from natural images using deep semi-supervised learning,https://api.elsevier.com/content/abstract/scopus_id/85119019677,"Prior work on plant species classification predominantly focuses on building models from isolated plant attributes. Hence, there is a need for tools that can assist in species identification in the natural world. We present a novel and robust two-fold approach capable of identifying trees in a real-world natural setting. Additionally, we leverage unlabelled data through deep semi-supervised learning and demonstrate superior performance to supervised learning. Our single-GPU implementation for feature recognition uses minimal annotated data and achieves accuracies of 93.96% and 93.11% for leaves and bark, respectively. Further, we extract feature-specific datasets of 50 species by employing this technique. Finally, our semi-supervised species classification method attains 94.04% top-5 accuracy for leaves and 83.04% top-5 accuracy for bark.",multimedia
10.1016/j.compeleceng.2021.107550,Journal,Computers and Electrical Engineering,scopus,2021-12-01,sciencedirect,An Improved Deep-Layer Architecture for Real-Time End-to-End Person Recognition System,https://api.elsevier.com/content/abstract/scopus_id/85118358766,"Surveillance of human activities in real time has drawn tremendous attention in the field of research. As manual monitoring of surveillance videos is expensive and prone to error, automation of surveillance is preferred. Person recognition is one of the fundamental problems related to automation of surveillance. It is defined as the system that generates correspondence between two images captured by different cameras at different times. Matching of probe image with the people in the surveillance video is really challenging due to variations in background, costume of people, pose, camera views, lighting, etc. A deep-learning-based end–end person recognition system is proposed to suit the real-world environment. This paper discusses the architecture of proposed system with the issues encountered during the implementation. Experiments were conducted based on different situations to illustrate the results of the proposed system with suitable evaluation metric. CUHK03 dataset was used for experiment. Real-time data were collected and tested to prove the robustness of the proposed system.",multimedia
10.1016/j.seta.2021.101561,Journal,Sustainable Energy Technologies and Assessments,scopus,2021-12-01,sciencedirect,Artificial intelligence assisted technoeconomic optimization scenarios of hybrid energy systems for water management of an isolated community,https://api.elsevier.com/content/abstract/scopus_id/85115424775,"Water is an essential resource demanded worldwide and it is quite debatable owing to the economic, political, and energy characteristics of any region. Off-grid water filtration plants are an alternative for communities where transportation of freshwater becomes a real challenge due to a lack of infrastructure for the water potabilization processes. For such potable water filtration plants, hybrid renewable energy systems (HRES) can be a viable solution to meet their energy demand meanwhile providing a sustainable water solution.
                  The main contribution of this work is the unique methodology, which starts with a sizing procedure of various hybrid energy systems using a commercial software “Hybrid Optimization of Multiple Energy Resources (HOMER)” and spreadsheet algorithms, followed by a “Non-dominating Sorting Genetic Algorithm II (NSGA-II)” based multiobjective optimization. Single-objective optimization scenarios contain photovoltaic installation capacity, wind turbines, diesel generators, and battery energy storage systems including Pb-acid (Lead-acid), Li-ion (Lithium-ion), and AGM (Absorbent Glass Mat) technologies as design variables to maximize the cost of electricity or net-present-cost. Multiobjective optimization also involved environmental (CO2 emissions i.e. carbon dioxide emissions) and water cost indices as an additional packet to single-objective optimization scenarios. Afterward, a multicriteria decision-making tool using “The Order of Preference by Similarity to Ideal Solution (TOPSIS)” is applied on the Pareto front to attain the final optimization results. The analysis is further explored in depth by generating digital twins (surrogate or meta model) of HRES data using artificial intelligence techniques (artificial neural network and group-method-of-data-handling). Furthermore, calculus and statistical sensitivity analysis assist in the identification of the significant variables in the design procedure. In summary, the technical contribution of this work can be divided into two sections. The first one is the design of a hybrid energy system for the water management of an isolated community of the indigenous Mayan region of Yucatan, Mexico, which has never been considered before. Secondly, the technical contribution is related to the usage of environmental emissions as an objective function, which is not considered in the traditional design of hybrid energy systems by the software HOMER. Environmental emission as an objective function is not considered while designing a hybrid energy system in commerical softwares like HOMER, in fact, HOMER provides a list of environmental impacts but it is a secondary outcome as a result of technoeconomic optimization.
                  Analysis of results between HOMER pro and spreadsheet has shown conformity, reporting that the optimal case consists of a photovoltaic system, diesel generator, and Li-ion technology of battery storage with capacities of ∼17 kW, ∼5kW, and 44–48 kWh, respectively, corresponding to a net present cost ranging from 70,000 United States Dollars (USD) to 79,000 USD and a cost of electricity ranging from 0.205 to 0.229 USD/kWh. The achievements obtained with multiobjective optimization indicate that the cost of electricity and net present cost can be further reduced by 0.86 % and 0.73 %, respectively, at a decrement of only 0.4% of the renewable fraction as compared to the single objective optimization scenario. It is concluded that multiobjective optimization provides an add-in feature to HOMER by using environmental emissions as an objective function.
                  The design procedure and adapted methodology can be useful to promote sustainable development in the statewide context and can provide a scientific justification to national energy policymakers.",multimedia
10.1016/j.compedu.2021.104338,Journal,Computers and Education,scopus,2021-12-01,sciencedirect,"Evaluation of four digital tools and their perceived impact on active learning, repetition and feedback in a large university class",https://api.elsevier.com/content/abstract/scopus_id/85115167061,"Large university classes often face challenges in enhancing active learning, repetition and feedback in the classroom which are essential for promoting student learning. In this study, we evaluated the implementation of digital tools (lecture recordings, question tool, classroom response system and virtual reality) regarding their perceived impact on active learning, repetition, and feedback in a large university class. The study applied a mixed methods design and collected data from a survey (95 students) and focus groups (11 students). The results show that students enjoyed using the tools because they enriched the lecture. However, students perceived differences regarding the impacts on active learning, repetition, and feedback. The perceived impacts of the classroom response system and the lecture recordings were rated high whereas the perceived impacts of the question tool and the VR modules were rated lower. Recommendations on how to use these digital tools in large classroom settings are provided.",multimedia
10.1016/j.ijcci.2021.100321,Journal,International Journal of Child-Computer Interaction,scopus,2021-12-01,sciencedirect,Augmented reality applications for K-12 education: A systematic review from the usability and user experience perspective,https://api.elsevier.com/content/abstract/scopus_id/85110498058,"In the past two decades, we have witnessed soaring efforts in applying Augmented Reality (AR) technology in education. Several systematic literature reviews (SLRs) were conducted to study AR educational applications (AREAs) and associated methodologies, primarily from the pedagogical rather than from the human–computer interaction (HCI) perspective. These reviews vary in goal, scale, scope, technique, outcome and quality. To bridge the gaps identified in these SLRs, ours is to meet fourfold objectives: to ground the analysis deeper in the usability and user experience (UX) core concepts and methods; to study the learning effect and usability/UX of AREAs and their relations by learner age; to reflect on the prevailing SLR process and propose improvement; to draw implications for the future development of AREAs. Our searches in four databases returned 714 papers of which 42, together with 7 from three existing SLRs, were included in the final analysis. Several intriguing findings have been identified: (i) the insufficient grounding in usability/UX frameworks indicates that there seems a disconnection between the HCI and technology-enhanced learning community; (ii) a lack of innovative AR-specific usability/UX evaluation methods and the continuing reliance on questionnaire may hamper the advances of AREAs; (iii) the learner age seems not a significant factor in determining the perceived usability and UX or the learning effect of AREAs; (iv) a limited number of studies at home suggests the missed opportunity of mobilizing parents to support children to deploy AREAs in different settings; (v) the number of AREAs for children with special needs remains disappointedly low; (vi) the threat of predatory journals to the quality of bibliometric sources amplifies the need for a robust approach to the quality assessment for SLR and transparency of interim results. Implications of these issues for future research and practice on AREAs are drawn.",multimedia
10.1016/j.future.2021.06.033,Journal,Future Generation Computer Systems,scopus,2021-12-01,sciencedirect,Detecting malicious behavior in social platforms via hybrid knowledge- and data-driven systems,https://api.elsevier.com/content/abstract/scopus_id/85109435960,"Among the wide variety of malicious behavior commonly observed in modern social platforms, one of the most notorious is the diffusion of fake news, given its potential to influence the opinions of millions of people who can be voters, consumers, or simply citizens going about their daily lives. In this paper, we implement and carry out an empirical evaluation of a version of the recently-proposed NetDER architecture for hybrid AI decision-support systems with the capability of leveraging the availability of machine learning modules, logical reasoning about unknown objects, and forecasts based on diffusion processes. NetDER is a general architecture for reasoning about different kinds of malicious behavior such as dissemination of fake news, hate speech, and malware, detection of botnet operations, prevention of cyber attacks including those targeting software products or blockchain transactions, among others. Here, we focus on the case of fake news dissemination on social platforms by three different kinds of users: non-malicious, malicious, and botnet members. In particular, we focus on three tasks: (i) determining who is responsible for posting a fake news article, (ii) detecting malicious users, and (iii) detecting which users belong to a botnet designed to disseminate fake news. Given the difficulty of obtaining adequate data with ground truth, we also develop a testbed that combines real-world fake news datasets with synthetically generated networks of users and fully-detailed traces of their behavior throughout a series of time points. We designed our testbed to be customizable for different problem sizes and settings, and make its code publicly available to be used in similar evaluation efforts. Finally, we report on the results of a thorough experimental evaluation of three variants of our model and six environmental settings over the three tasks. Our results clearly show the effects that the quality of knowledge engineering tasks, the quality of the underlying machine learning classifier used to detect fake news, and the specific environmental conditions have on smart policing efforts in social platforms.",multimedia
10.1016/j.eswa.2021.115498,Journal,Expert Systems with Applications,scopus,2021-12-01,sciencedirect,Real-time human pose estimation on a smart walker using convolutional neural networks,https://api.elsevier.com/content/abstract/scopus_id/85109217957,"Rehabilitation is important to improve quality of life for mobility-impaired patients. Smart walkers are a commonly used solution that should embed automatic and objective tools for data-driven human-in-the-loop control and monitoring. However, present solutions focus on extracting few specific metrics from dedicated sensors with no unified full-body approach. We investigate a general, real-time, full-body pose estimation framework based on two RGB+D camera streams with non-overlapping views mounted on a smart walker equipment used in rehabilitation. Human keypoint estimation is performed using a two-stage neural network framework. The 2D-Stage implements a detection module that locates body keypoints in the 2D image frames. The 3D-Stage implements a regression module that lifts and relates the detected keypoints in both cameras to the 3D space relative to the walker. Model predictions are low-pass filtered to improve temporal consistency. A custom acquisition method was used to obtain a dataset, with 14 healthy subjects, used for training and evaluating the proposed framework offline, which was then deployed on the real walker equipment. An overall keypoint detection error of 3.73 pixels for the 2D-Stage and 44.05 mm for the 3D-Stage were reported, with an inference time of 26.6 ms when deployed on the constrained hardware of the walker. We present a novel approach to patient monitoring and data-driven human-in-the-loop control in the context of smart walkers. It is able to extract a complete and compact body representation in real-time and from inexpensive sensors, serving as a common base for downstream metrics extraction solutions, and Human-Robot interaction applications. Despite promising results, more data should be collected on users with impairments, to assess its performance as a rehabilitation tool in real-world scenarios.",multimedia
10.1016/j.eswa.2021.115343,Journal,Expert Systems with Applications,scopus,2021-11-30,sciencedirect,A framework for 3D tracking of frontal dynamic objects in autonomous cars,https://api.elsevier.com/content/abstract/scopus_id/85108361303,"Both recognition and 3D tracking of frontal dynamic objects are crucial problems in an autonomous vehicle, while depth estimation as an essential issue becomes a challenging problem using a monocular camera. Since both camera and objects are moving, the issue can be formed as a structure from motion (SFM) problem. In this paper, to elicit features from an image, the YOLOv3 approach is utilized beside an OpenCV tracker. Subsequently, to obtain the lateral and longitudinal distances, a nonlinear SFM model is considered alongside a state-dependent Riccati equation (SDRE) filter and a newly developed observation model. Additionally, a switching method in the form of switching estimation error covariance is proposed to enhance the robust performance of the SDRE filter. The stability analysis of the presented filter is conducted on a class of discrete nonlinear systems. Furthermore, the ultimate bound of estimation error caused by model uncertainties is analytically obtained to investigate the switching significance. Simulations are reported to validate the performance of the switched SDRE filter. Finally, real-time experiments are performed through a multi-thread framework implemented on a Jetson TX2 board, while radar data is used for the evaluation.",multimedia
10.1016/j.neucom.2021.09.008,Journal,Neurocomputing,scopus,2021-11-20,sciencedirect,Fast intent prediction of multi-cyclists in 3D point cloud data using deep neural networks,https://api.elsevier.com/content/abstract/scopus_id/85115024624,"Inferring the intended actions of road-sharing users with autonomous ground vehicles in particularly vulnerable ones like cyclists is considered one of the tough tasks facing the wide-spread deployment of autonomous ground vehicles. One of the main reasons for that is the scarcity of the available datasets for that task due to the difficulty in obtaining those datasets in real environments. In this work, we first propose a pipeline that can synthetically produce 3D LiDAR data of cyclists hand-signalling a set of intended actions that are commonly done in real environments. Given the synthetically-produced labelled 3D LiDAR data sequences, we trained a framework that can simultaneously detect, track and give predictions about the intended actions of multi-cyclists in the scene on time. The proposed framework was evaluated using both synthetic and real data from a physical 3D LiDAR sensor. Our proposed framework has scored competitive and robust results in both synthetic and real environments with 88% in 
                        
                           
                              
                                 F
                              
                              
                                 1
                              
                           
                        
                      measure with higher frame per second rate (12.9 FPS) than the 3D LiDAR sensor frame rate (10 Hz).",multimedia
10.1016/j.neucom.2021.08.115,Journal,Neurocomputing,scopus,2021-11-20,sciencedirect,HuRAI: A brain-inspired computational model for human-robot auditory interface,https://api.elsevier.com/content/abstract/scopus_id/85114916023,"The deep learning era endows immense opportunities for ubiquitous robotic applications by leveraging big data generated from widespread sensors and ever-growing computing capability. While the growing demands for natural human-robot interaction (HRI) as well as concerns for energy efficiency, real-time performance, and data security motive novel solutions. In this paper, we present a brain-inspired spiking neural network (SNN) based Human-Robot Auditory Interface, namely HuRAI. The HuRAI integrates the voice activity detection, speaker localization and voice command recognition systems into a unified framework that can be implemented on the emerging low-power neuromorphic computing (NC) devices. Our experimental results demonstrate superior modeling capabilities of SNNs, achieving accurate and rapid prediction for each task. Moreover, the energy efficiency analysis reveals a compelling prospect, with up to three orders of magnitude energy savings, over the equivalent artificial neural networks that running on the state-of-the-art Nvidia graphics processing unit (GPU). Therefore, integrating the algorithmic power of large-scale SNN models and the energy efficiency of NC devices offers an attractive solution for real-time, low-power robotic applications.",multimedia
10.1016/j.enconman.2021.114790,Journal,Energy Conversion and Management,scopus,2021-11-15,sciencedirect,Data-augmented sequential deep learning for wind power forecasting,https://api.elsevier.com/content/abstract/scopus_id/85115990326,"Accurate wind power forecasting plays a critical role in the operation of wind parks and the dispatch of wind energy into the power grid. With excellent automatic pattern recognition and nonlinear mapping ability for big data, deep learning is increasingly employed in wind power forecasting. However, salient realities are that in-situ measured wind data are relatively expensive and inaccessible and correlation between steps is omitted in most multistep wind power forecasts. This paper is the first time that data augmentation is applied to wind power forecasting by systematically summarizing and proposing both physics-oriented and data-oriented time-series wind data augmentation approaches to considerably enlarge primary datasets, and develops deep encoder-decoder long short-term memory networks that enable sequential input and sequential output for wind power forecasting. The proposed augmentation techniques and forecasting algorithm are deployed on five turbines with diverse topographies in an Arctic wind park, and the outcomes are evaluated against benchmark models and different augmentations. The main findings reveal that on one side, the average improvement in RMSE of the proposed forecasting model over the benchmarks is 33.89%, 10.60%, 7.12%, and 4.27% before data augmentations, and increases to 40.63%, 17.67%, 11.74%, and 7.06%, respectively, after augmentations. The other side unveils that the effect of data augmentations on prediction is intricately varying, but for the proposed model with and without augmentations, all augmentation approaches boost the model outperformance from 7.87% to 13.36% in RMSE, 5.24% to 8.97% in MAE, and similarly over 12% in QR90. Finally, data-oriented augmentations, in general, are slightly better than physics-driven ones.",multimedia
10.1016/j.cmpb.2021.106460,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-11-01,sciencedirect,Multi-Modality guidance based surgical navigation for percutaneous endoscopic transforaminal discectomy,https://api.elsevier.com/content/abstract/scopus_id/85118353932,"Objective
                  Fluoroscopic guidance is a critical step for the puncture procedure in percutaneous endoscopic transforaminal discectomy (PETD). However, two-dimensional observations of the three-dimensional anatomic structure suffer from the effects of projective simplification. To accurately assess the spatial relations between the patient vertebra tissues and puncture needle, a considerable number of fluoroscopic images from different orientations need to be acquired by the surgeons. This process significantly increases the radiation risk for both the patient and surgeons.
               
                  Methods
                  In this paper, we propose an augmented reality (AR) surgical navigation system for PETD based on multi-modality information, which contains fluoroscopy, optical tracking, and depth camera. To register the fluoroscopic image with the intraoperative video, we design a lightweight non-invasive fiducial with markers and detect the markers based on the deep learning method. It can display the intraoperative video fused with the registered fluoroscopic images. We also present a self-adaptive calibration and transformation method between a 6-DOF optical tracking device and a depth camera, which are in different coordinate systems.
               
                  Results
                  With the substantially reduced frequency of fluoroscopy imaging, the system can accurately track and superimpose the virtual puncture needle on fluoroscopy images in real-time. From operating theatre in vivo animal experiments, the results illustrate that the system average positioning accuracy can reach 1.98mm and the orientation accuracy can reach 1.19
                        
                           
                           ∘
                        
                     . From the clinical validation results, the system significantly lower the frequency of fluoroscopy imaging (42.7%) and reduce the radiation risk for both the patient and surgeons.
               
                  Conclusion
                  Coupled with the user study, both the quantitative and qualitative results indicate that our navigation system has the potential to be highly useful in clinical practice. Compared with the existing navigation systems, which are usually equipped with a variety of large and high-cost medical equipments, such as O-arm, cone-beam CT, and robots, our navigation system does not need special equipment and can be implemented with common equipment in the operating room, such as C-arm, desktop, etc., even in small hospitals.",multimedia
10.1016/j.jmapro.2021.09.048,Journal,Journal of Manufacturing Processes,scopus,2021-11-01,sciencedirect,Joint active search and neuromorphic computing for efficient data exploitation and monitoring in additive manufacturing,https://api.elsevier.com/content/abstract/scopus_id/85117322411,"The recent integration of imaging technology with additive manufacturing (AM) leads to the plethora of in-process and high-dimensional data. Machine learning (ML) methods have been implemented to improve understanding of defect formation in AM-built parts and controlling process variability in real-time. However, modern ML methods, in particular deep neural networks, are empowered by massive high-quality labeled data, which are limited in AM due to the following reasons: First, large data labeling is often tedious, costly, and requires substantial human efforts with considerable expertise. Second, the performance of the learning methods depends to a great extent on the presence of positive data instances (i.e., defective) as they are more informative for monitoring. Third, the rare positives result in a severe imbalanced dataset poses critical challenges in training ML methods designed with the assumption that the input contains an equal number of instances from each class. In this research, we propose novel annotation and learning with limited number of data through the integration of active search and hyperdimensional computing (HDC). The active search is developed to benefit from a single bandit model to learn about the data distribution (exploration) while sampling from the regions potentially containing more positives (exploitation). HDC is introduced as an alternative computing method that mimics important brain functionalities and encodes data with high-dimensional vectors, thereby enabling single-pass learning with just a few samples. Experimental results on a real-world case study of drag link joint build show the proposed model locates the rare positives thoroughly and detects lack of fusion defects with the accuracy of 89.58%, in 3.221 ± 0.029 second training time and with only 66 sample data. The joint active search and neuromorphic computing framework is shown to have strong potentials for general applications in a diverse set of domains with in-situ imaging data.",multimedia
10.1016/j.addma.2021.102328,Journal,Additive Manufacturing,scopus,2021-11-01,sciencedirect,In situ infrared temperature sensing for real-time defect detection in additive manufacturing,https://api.elsevier.com/content/abstract/scopus_id/85115355988,"Melt pool temperature is a critical parameter for the majority of additive manufacturing processes. Monitoring of the melt pool temperature can facilitate the real-time detection of various printing defects such as voids, over-extrusion, filament breakage, clogged nozzle, etc. that occur either naturally or as the result of malicious hacking activity. This study uses an in situ, multi-sensor approach for monitoring melt pool temperature in which non-contact infrared temperature sensors with customized field of view move along with the extruder of a fused deposition modeling-based printer and sense melt pool temperature from a very short working distance regardless of its X-Y translational movements. A statistical method for defect detection is developed and utilized to identify temperature deviations caused by intentionally implemented defects. Effective detection for multiple defect types and sizes is demonstrated using both a simple L-shaped test geometry and a more complex industry standard test article. Strengths and limitations of this approach are presented, and the potential for expansion via more advanced data analysis techniques such as machine learning are discussed.",multimedia
10.1016/j.patrec.2021.07.023,Journal,Pattern Recognition Letters,scopus,2021-11-01,sciencedirect,Empowering Knowledge Distillation via Open Set Recognition for Robust 3D Point Cloud Classification,https://api.elsevier.com/content/abstract/scopus_id/85114122217,"Real-world scenarios pose several challenges to deep learning based computer vision techniques despite their tremendous success in research. Deeper models provide better performance, but are challenging to deploy and knowledge distillation allows us to train smaller models with minimal loss in performance. A model also has to deal with open set samples from classes outside the ones it was trained on and should be able to identify them as unknown samples while classifying the known ones correctly. Finally, most existing image recognition research focuses only on using two-dimensional snapshots of the three-dimensional real world objects. In this work, we attempt to bridge these three research fields, which have been developed independently until now, despite being deeply interrelated in practice. We propose a joint knowledge distillation and open set recognition training methodology for three-dimensional object recognition. We demonstrate the effectiveness of the proposed method via various experiments on how it allows us to obtain a much smaller model, which takes a minimal hit in performance while being capable of open set recognition for 3D point cloud data.",multimedia
10.1016/j.cie.2021.107621,Journal,Computers and Industrial Engineering,scopus,2021-11-01,sciencedirect,Deep deterministic policy gradient algorithm for crowd-evacuation path planning,https://api.elsevier.com/content/abstract/scopus_id/85113275288,"In existing evacuation methods, the large number of pedestrians and the complex environment will affect the efficiency of evacuation. Therefore, we propose a hierarchical evacuation method based on multi-agent deep reinforcement learning (MADRL) to solve the above problem. First, we use a two-level evacuation mechanism to guide evacuations, the crowd is divided into leaders and followers. Second, in the upper level, leaders perform path planning to guide the evacuation. To obtain the best evacuation path, we propose the efficient multi-agent deep deterministic policy gradient (E-MADDPG) algorithm for crowd-evacuation path planning. E-MADDPG algorithm combines learning curves to improve the fixed experience pool of MADDPG algorithm and uses high-priority experience playback strategy to improve the sampling strategy. The improvement increases the learning efficiency of the algorithm. Meanwhile we extract pedestrian motion trajectories from real motion videos to reduce the state space of algorithm. Third, in the bottom layer, followers use the relative velocity obstacle (RVO) algorithm to avoid collisions and follow leaders to evacuate. Finally, experimental results illustrate that the E-MADDPG algorithm can improve path planning efficiency, while the proposed method can improve the efficiency of crowd evacuation.",multimedia
10.1016/j.aquaeng.2021.102192,Journal,Aquacultural Engineering,scopus,2021-11-01,sciencedirect,"An integrated framework of sensing, machine learning, and augmented reality for aquaculture prawn farm management",https://api.elsevier.com/content/abstract/scopus_id/85112001426,"The rapid growth of prawn farming on an international scale will play an important role in meeting the protein requirements of an expanding global population. Efficient management of the commercial ponds for healthy production of prawns is the key mantra of success in this industry. It is a necessity to maintain the water quality parameters in these ponds within specific ranges to create an ideal environment of optimal growth of healthy prawns. The current practice of water quality data collection and their usage for decision making on most farms is not efficient and does not take full advantage of the latest technologies. The research presented in this paper aimed at addressing this problem by systematic investigation and development of an integrated framework where (i) modern sensors were investigated for their suitability and deployed for continuous monitoring of the water quality variables in prawn ponds; (ii) novel machine learning models were investigated based on collected data and deployed to accurately forecast pond status over next 24 h. This provides farmers insight into upcoming situations and take necessary measures to avoid catastrophic situations; and (iii) augmented reality-based visualisation methods were investigated for improved data capture process and efficient decision making through real-time interactive interfaces. The paper presents the integrated framework as well as the details of sensing, machine learning, and augmented reality components. We found that (i) YSI EXO2 Multi-Sonde is the best sensor for continuous monitoring of prawn ponds; (ii) ForecastNet (our developed machine learning model) provides best forecasting results with symmetric mean absolute percentage error of 6.1 %, 9.6 %, and 8.5 % for dissolved oxygen, pH, and temperature; and (iii) augmented reality-based interactive interface achieves accuracy as high as 89.2 % for management decisions with at least 41 % less time. The experience of the project as presented in this paper can act as a guide for researchers as well as prawn farmers to take advantage of latest sensors, machine learning algorithms and augmented reality tools.",multimedia
10.1016/j.actaastro.2021.07.012,Journal,Acta Astronautica,scopus,2021-11-01,sciencedirect,"A review of space surgery - What have we achieved, current challenges, and future prospects",https://api.elsevier.com/content/abstract/scopus_id/85110745640,"Major surgical events/incidents onboard are rare but can be catastrophic to any mission. National Aeronautics and Space Administration (NASA) uses the Integrated Medical Model (IMM) to develop an integrated, quantified, evidence-based decision support tool useful for crew health and mission planners to assess risk and design medical systems. In 2017, the IMM of the NASA Human Research Program included a list of 100 medical conditions that could be anticipated during space flight. Of those conditions, 27 are expected to need surgical treatment. Consequently, there has been a continuing interest in surgical capabilities for exploration space flight. The surgical system capabilities aboard all space stations and analogue flights have been designed and implemented with an emphasis on stabilisation, medical evacuation, and ATLS capabilities. However, with future missions to the Moon and Mars, evacuation is not a possibility and astronauts will need to troubleshoot, adapt, and self-administer complex surgical care autonomously.
                  This narrative review aims to examine the published work on surgical care in space, discuss the inherent challenges, and identify scope for future studies. The review evaluates and analyses results from several landmark experiments covering important technical aspects such as basic surgical skills, laparoscopic surgery, robotic surgery, and tele surgery. Relevant studies for the review were identified from the MEDLINE, PubMed, and EMBASE databases. Eligible studies were published between 1960 and June 2021 and were identified using the terms “space surgery”, “microgravity”, “zero gravity”, “weightlessness”, “parabolic flight”, “neutral buoyancy”, and “spaceflight”. Only articles in English were selected and references cited in the selected publications were followed up and included where appropriate. Documents available in the public domain and/or archives of National Space agencies were also included. The search yielded a total of 86 hits including review articles, commentaries, studies, meeting summaries and technical reports submitted to National Space agencies. Results were then filtered for eligible papers relevant to this narrative review. Challenges on a long-duration mission will be unique, unlike anything we have faced so far in the last 60 years of space travel. Despite the progress in space surgery in the last 40 years, there are several challenges to achieving a fully functional surgical care system on any mission outside Low Earth Orbit. The microgravity environment presents unique challenges related to altered physiology as well as mechanics and techniques pertinent to surgical care. Some of the challenges include but are not limited to crew selection, role of prophylactic surgery, adaptation to zero gravity, lack of ground support, training and maintenance of surgical skills and limitation of weight and volume for hardware. Ultrasound imaging, 3D printing and AI-based surgical assistance coupled with robotic surgery have shown promise, but their real efficacy and functionality remains to be tested.",multimedia
10.1016/j.jhlste.2020.100275,Journal,"Journal of Hospitality, Leisure, Sport and Tourism Education",scopus,2021-11-01,sciencedirect,Industry 4.0 technologies in tourism education: Nurturing students to think with technology,https://api.elsevier.com/content/abstract/scopus_id/85092173436,"The Industry 4.0 revolution is bringing major transformations in the tourism systems design suitable for technologically oriented consumers. Indeed, methods and technologies introduced by Big Data, Automation, Virtual and augmented reality, Robotics and ICT well fit with the Tourism 4.0 paradigm. However, tourism students are not yet trained on techniques, issues and methods related to the Industry 4.0 framework.
                  Hence, relying on a careful examination of the literature on tourism market trends linked to the offer of innovative technological services, we identified conceptual, methodological, technological and practical skills to be developed in an academic curriculum for Tourism Science students. Learning path were focused on: i) processes of data acquisition from social media, ii) data analysis using Machine Learning techniques and iii) data design into significant elements useful to implement communication systems in the tourism field.
               
                  Results
                  showed that the most of participants achieved a medium-high evaluation for the implementation of the communication systems, applying appropriately techniques and tools learned along the course. Furthermore, the high percentage of students satisfaction registered in relation to the course, revealed that students enjoyed this experience. Outcomes reflects the acquisition and the awareness of those skills that will enable students to be conscious protagonists of their role in tourism 4.0.",multimedia
10.1016/j.comnet.2021.108394,Journal,Computer Networks,scopus,2021-10-24,sciencedirect,MDCHD: A novel malware detection method in cloud using hardware trace and deep learning,https://api.elsevier.com/content/abstract/scopus_id/85113134197,"With the development of cloud computing, more and more enterprises and institutes have deployed important computing tasks and data into virtualization environments. Virtualization security has become very important for cloud computing. When an attacker controls a victim’s virtual machine, he (or she) may launch malware for malicious purpose in that virtual machine. To defend against malware attacks in the cloud, many virtualization-based approaches are proposed. However, the existing methods suffer from limitations in terms of transparency and performance cost. To address these issues, we propose MDCHD, a novel malware detection solution for virtualization environments. This method first utilizes the Intel Processor Trace (IPT) mechanism to collect the run-time control flow information of the target program. Then, it converts the control flow information into color images. By doing so, we can utilize a CNN-based deep learning method to identify malware from the images. To improve the performance of our detection mechanism, we leverage Lamport’s ring buffer algorithm. In this way, the control flow information collector and security checker can work concurrently. The evaluation shows that our approach can achieve acceptable detection accuracy with a minimal performance cost.",multimedia
10.1016/j.neucom.2021.06.070,Journal,Neurocomputing,scopus,2021-10-07,sciencedirect,Direct training of hardware-friendly weight binarized spiking neural network with surrogate gradient learning towards spatio-temporal event-based dynamic data recognition,https://api.elsevier.com/content/abstract/scopus_id/85109440989,"The spiking neural network (SNN)-based neuromorphic hardware has been extensively studied in dynamic information processing. However, there is still a lack of training algorithms to drive or support the implementation of compact spatio-temporal neuromorphic hardware; and the existing neuromorphic hardware uses excessive on-chip memory to store parameters, which limits its neuron and synapse scale. Here, we introduce a hardware-friendly weight binarized spiking neural network (BSNN) to efficiently recognize the spatio-temporal event-based data. The neuron of the spike response model (SRM) is used in BSNN due to its rich spatio-temporal characteristics. In the training process, a surrogate gradient method is used to replace the derivative of the spike train, and the weights are binarized. Moreover, combined with the spiking characteristics of SNN (i.e., the input/output of SNN and the communications of neurons in SNN are binary spikes), it is possible to replace the hardware-expensive matrix–vector multiplication (MVM) with the hardware-friendly “Signed AND” operation during inference, which is favored for constructing compact neuromorphic hardware. The trained BSNN has competitive recognition accuracies of 99.52% and 62.1%, 97.57%, and 90.35% on the dynamic images dataset N-MNIST and DVS-CIFAR10, dynamic gestures dataset DvsGesture, and dynamic audio dataset N-TIDIGITS18, respectively, which are related to human vision or hearing. The proposed compact SNN training method paves the way for real-time dynamic information processing oriented hardware-saving and power-efficient neuromorphic hardware.",multimedia
10.1016/j.probengmech.2021.103173,Journal,Probabilistic Engineering Mechanics,scopus,2021-10-01,sciencedirect,Machine learning based digital twin for stochastic nonlinear multi-degree of freedom dynamical system,https://api.elsevier.com/content/abstract/scopus_id/85117922944,"The potential of digital twin technology is immense, specifically in the infrastructure, aerospace, and automotive sector. However, practical implementation of this technology is not at an expected speed, specifically because of lack of application-specific details. In this paper, we propose a novel digital twin framework for stochastic nonlinear multi-degree of freedom (MDOF) dynamical systems. The proposed digital twin has four modules — (a) a physics-based nominal model, (b) a data collection module, (c) algorithm for real-time update of the digital twin and (d) module for predicting future state. The modules for real-time update and prediction are based on the so-called gray-box modeling approach, and utilizes both physics based and data driven frameworks; this enables the proposed digital twin to generalize and predict future responses. The gray box modeling framework used within the digital twin is developed by coupling Bayesian filtering and machine learning algorithm. Although, the proposed digital twin can be used with any machine learning regression algorithm, we have used Gaussian process in this study. Performance of the proposed approach is illustrated using two examples. Results obtained indicate the applicability and excellent performance of the proposed digital twin framework.",multimedia
10.1016/j.ascom.2021.100502,Journal,Astronomy and Computing,scopus,2021-10-01,sciencedirect,Exploring and interrogating astrophysical data in virtual reality,https://api.elsevier.com/content/abstract/scopus_id/85116926035,"Scientists across all disciplines increasingly rely on machine learning algorithms to analyse and sort datasets of ever increasing volume and complexity. Although trends and outliers are easily extracted, careful and close inspection will still be necessary to explore and disentangle detailed behaviour, as well as identify systematics and false positives. We must therefore incorporate new technologies to facilitate scientific analysis and exploration. Astrophysical data is inherently multi-parameter, with the spatial-kinematic dimensions at the core of observations and simulations. The arrival of mainstream virtual-reality (VR) headsets and increased GPU power, as well as the availability of versatile development tools for video games, has enabled scientists to deploy such technology to effectively interrogate and interact with complex data. In this paper we present development and results from custom-built interactive VR tools, called the iDaVIE suite, that are informed and driven by research on galaxy evolution, cosmic large-scale structure, galaxy–galaxy interactions, and gas/kinematics of nearby galaxies in survey and targeted observations. In the new era of Big Data ushered in by major facilities such as the SKA and LSST that render past analysis and refinement methods highly constrained, we believe that a paradigm shift to new software, technology and methods that exploit the power of visual perception, will play an increasingly important role in bridging the gap between statistical metrics and new discovery. We have released a beta version of the iDaVIE software system that is free and open to the community.",multimedia
10.1016/j.artmed.2021.102151,Journal,Artificial Intelligence in Medicine,scopus,2021-10-01,sciencedirect,Optimizing the setting of medical interactive rehabilitation assistant platform to improve the performance of the patients: A case study,https://api.elsevier.com/content/abstract/scopus_id/85114984743,"Tele-rehabilitation is an alternative to the conventional rehabilitation service that helps patients in remote areas to access a service that is practical in terms of logistics and cost, in a controlled environment. It includes the usage of mobile phones or other wireless devices that are applied to rehabilitation exercises. Such applications or software include exercises in the form of virtual games, treatment monitoring based on the rehabilitation progress and data analysis. However, nowadays, physiotherapists use a default profiling setting for patients carrying out rehabilitation, due to lack of information. Medical Interactive Rehabilitation Assistant (MIRA) is a computer-based (virtual reality) rehabilitation platform. The profile setting includes: a level of difficulty, percentage of tolerance and maximum range. To the best of our knowledge, there is a lack of optimization in the parameter values setting of MIRA exergames that could enhance patients' performance. Generally, non-optimal profile setting leads to reduced effectiveness. Therefore, this study aims to develop a method that optimizes the profile setting of each patient according to the estimated (desired) optimal results. The proposed method is developed using unsupervised and supervised machine learning techniques. We use Self-Organizing Map (SOM) to cluster patient records into several distinct clusters. K-fold cross validation is applied to construct the prediction models. Classification And Regression Tree (CART) is utilized to predict the patient's optimal input setting for playing the MIRA games. The combination of these techniques seems to improve the efficiency of the standard (default) way in predicting the optimal settings for exergames. To evaluate the proposed method, we conduct an experiment with data collected from a rehabilitation center. We use three metrics to quantify the quality of the results: R-squared (R2), Mean Absolute Error (MAE) and Root Mean Square Error (RMSE). The results of experimental analysis demonstrate that the proposed method is effective in predicting the adequate parameter setting in MIRA platform. The method has potential to be implemented as an intelligent system for MIRA prediction in healthcare. Moreover, the method could be extended to similar platforms for which data is available to train our method on.",multimedia
10.1016/j.forsciint.2021.110979,Journal,Forensic Science International,scopus,2021-10-01,sciencedirect,Real time object-based video forgery detection using YOLO (V2),https://api.elsevier.com/content/abstract/scopus_id/85114833221,"Video forgery detection is a challenging task nowadays due to fake video forwarding. Copy-Move type of attack is especially mostly practiced to tamper with the original contents of a video or an image. Copy-Move attack mainly deals with object-based video forgery. Traditional methods are quiet slow and not strong enough to detect complex Copy-Move attacks. So, automatic tamper detection in videos related to speed and accuracy is a challenging task. This paper proposes a new approach for the detection of Copy-Move attack in passive blind videos. Object-based forgery detection approach is implemented using fast and real-time object detector “You Only Look Once -Version 2″:YOLO (V2). The system is trained on the benchmark dataset videos for the automatic detection of forged objects within the video with a 0.99 confidence score. Trained YOLO (V2) model is accurately able to classify and localize the forged and non-forged objects within the given input video. The results and experimental analysis demonstrates that the proposed YOLO (V2) model achieved excellent results for detecting plain and complex Copy-Move attacks such as scaling, rotation, flipping. The performance excellent for object-based forgery detection for speed and accuracy than existing similar state-of-art deep learning approaches.",multimedia
10.1016/j.compeleceng.2021.107381,Journal,Computers and Electrical Engineering,scopus,2021-10-01,sciencedirect,Deep learning based offloading for mobile augmented reality application in 6G,https://api.elsevier.com/content/abstract/scopus_id/85114036751,"Mobile Augmented Reality (MAR) applications are fast becoming popular with the growth in use of smartphones and smart wearable devices. Apart from gaming, MAR finds useful application in any field for attractive visualization of the environment. The computer vision algorithms used in MAR applications are both data and computation extensive which renders them difficult to use in delay sensitive applications, given the present network scenario. But the network standard 6G expected to be deployed around 2030 is supposed to operate at a GHz to THz frequency. This will increase the bandwidth of the network in manifolds and can support the seamless real time transfer of the multimedia data. The article proposes to divide the various phases of an MAR application into sequential and parallel tasks and attempts to offload the task to the nearby devices with the help of Deep Reinforcement Algorithm (DRL) depending on transmission, task and energy constraints.",multimedia
10.1016/j.aei.2021.101393,Journal,Advanced Engineering Informatics,scopus,2021-10-01,sciencedirect,A real-time vehicle detection and a novel vehicle tracking systems for estimating and monitoring traffic flow on highways,https://api.elsevier.com/content/abstract/scopus_id/85113660129,"Real-time highway traffic monitoring systems play a vital role in road traffic management, planning, and preventing frequent traffic jams, traffic rule violations, and fatal road accidents. These systems rely entirely on online traffic flow info estimated from time-dependent vehicle trajectories. Vehicle trajectories are extracted from vehicle detection and tracking data obtained by processing road-side camera images. General-purpose object detectors including Yolo, SSD, EfficientNet have been utilized extensively for real-time object detection task, but, in principle, Yolo is preferred because it provides a high frame per second (FPS) performance and robust object localization functionality. However, this algorithm’s average vehicle classification accuracy is below 57%, which is insufficient for traffic flow monitoring. This study proposes improving the vehicle classification accuracy of Yolo, and developing a novel bounding box (Bbox)-based vehicle tracking algorithm. For this purpose, a new vehicle dataset is prepared by annotating 7216 images with 123831 object patterns collected from highway videos. Nine machine learning-based classifiers and a CNN-based classifier were selected. Next, the classifiers were trained via the dataset. One out of ten classifiers with the highest accuracy was selected to combine to Yolo. This way, the classification accuracy of the Yolo-based vehicle detector was increased from 57% to 95.45%. Vehicle detector 1 (Yolo) and vehicle detector 2 (Yolo + best classifier), and the Kalman filter-based tracking as vehicle tracker 1 and the Bbox-based tracking as vehicle tracker 2 were applied to the categorical/total vehicle counting tasks on 4 highway videos. The vehicle counting results show that the vehicle counting accuracy of the developed approach (vehicle detector 2 + vehicle tracker 2) was improved by 13.25% and this method performed better than the other 3 vehicle counting systems implemented in this study.",multimedia
10.1016/j.media.2021.102171,Journal,Medical Image Analysis,scopus,2021-10-01,sciencedirect,Automatic skull defect restoration and cranial implant generation for cranioplasty,https://api.elsevier.com/content/abstract/scopus_id/85111529504,"A fast and fully automatic design of 3D printed patient-specific cranial implants is highly desired in cranioplasty - the process to restore a defect on the skull. We formulate skull defect restoration as a 3D volumetric shape completion task, where a partial skull volume is completed automatically. The difference between the completed skull and the partial skull is the restored defect; in other words, the implant that can be used in cranioplasty. To fulfill the task of volumetric shape completion, a fully data-driven approach is proposed. Supervised skull shape learning is performed on a database containing 167 high-resolution healthy skulls. In these skulls, synthetic defects are injected to create training and evaluation data pairs. We propose a patch-based training scheme tailored for dealing with high-resolution and spatially sparse data, which overcomes the disadvantages of conventional patch-based training methods in high-resolution volumetric shape completion tasks. In particular, the conventional patch-based training is applied to images of high resolution and proves to be effective in tasks such as segmentation. However, we demonstrate the limitations of conventional patch-based training for shape completion tasks, where the overall shape distribution of the target has to be learnt, since it cannot be captured efficiently by a sub-volume cropped from the target. Additionally, the standard dense implementation of a convolutional neural network tends to perform poorly on sparse data, such as the skull, which has a low voxel occupancy rate. Our proposed training scheme encourages a convolutional neural network to learn from the high-resolution and spatially sparse data. In our study, we show that our deep learning models, trained on healthy skulls with synthetic defects, can be transferred directly to craniotomy skulls with real defects of greater irregularity, and the results show promise for clinical use. Project page: https://github.com/Jianningli/MIA.",multimedia
10.1016/j.patrec.2021.06.020,Journal,Pattern Recognition Letters,scopus,2021-10-01,sciencedirect,Bangla Sign alphabet recognition with zero-shot and transfer learning,https://api.elsevier.com/content/abstract/scopus_id/85111317099,"Bangla, being the fifth most spoken language in the world has its own distinct sign language with two methods (one-handed and two-handed) of representation. However, a standard automatic recognition system of Bangla sign language (BdSL) is still to be achieved. Though widely studied and explored by researchers in the past years, certain unaddressed issues like identifying unseen signs and both types of BdSL or lack of evaluation of the models in versatile environmental conditions demarcate the real-world implementation of the automatic recognition of BdSL. To find a probable solution to the shortcomings in the existing works, this paper proposes two approaches based on conventional transfer learning and contemporary Zero-shot learning (ZSL) for automatic BdSL alphabet recognition of both seen and unseen data. The performance of the proposed system is evaluated for both types of Bangla sign representations as well as on a large dataset with 35,149 images from over 350 subjects, varying in terms of backgrounds, camera angle, light contrast, skin tone, hand size, and orientation. For the ZSL approach, a new semantic descriptor dedicated to BdSL is created and a split of the dataset into seen and unseen classes is proposed. Our model achieved 68.21%, 91.57%, and 54.34% of harmonic mean accuracy, seen accuracy, and zero-shot accuracy with six unseen classes respectively. For the transfer learning-based approach, we found pre-trained DenseNet201 architecture to be the best performing feature extractor and Linear Discriminant Analysis as the best classifier with an overall accuracy of 93.68% on the large dataset after conducting quantitative experimentation on 18 CNN architectures and 21 classifiers. The satisfactory result from our models supports its very probative potential to serve extensively for the hearing and speaking impaired community.",multimedia
10.1016/j.rcot.2021.06.036,Journal,Revue de Chirurgie Orthopedique et Traumatologique,scopus,2021-10-01,sciencedirect,Virtual preoperative planning of acetabular fractures using patient-specific biomechanical simulation: A case-control study,https://api.elsevier.com/content/abstract/scopus_id/85110536437,"Introduction
                  Le premier modèle biomécanique patient-spécifique pour la planification de la réduction chirurgicale des fractures de l’acétabulum a été developpé dans notre institution. Aucune étude antérieure n’a encore démontré son efficacité en terme de réduction chirurgicale, de durée opératoire et de saignement opératoire. L’objectif principal de cette étude cas-témoin était : 1) d’évaluer l’effet de la simulation préopératoire par simulateur biomécanique patient-spécifique sur la durée opératoire et le saignement peropératoire ; 2) d’évaluer l’effet de la simulation préopératoire par simulateur biomécanique patient-spécifique sur la qualité de la réduction.
               
                  Methode
                  Tous les patients opérés entre janvier 2019 et juin 2019 après planification par simulation biomécanique étaient inclus dans cette étude cas-témoin. Chaque patient inclus était apparié à 2 patients issus de notre base de données (2015–2018) selon des critères d’âge et de variété fracturaire. Les données DICOM étaient extraites des scanners haute-résolutions préopératoires pour construire un modèle tridimensionnel de la fracture par segmentation semi-automatique. Un modèle biomécanique était construit pour simuler virtuellement les différentes étapes de la réduction chirurgicale. La chirurgie était ensuite réalisée conformément aux données de la simulation. La durée opératoire, les pertes sanguines, les résultats radiologiques et les complications peropératoires étaient enregistrés, analysés et comparés.
               
                  Resultats
                  Trente patients étaient inclus, 10 dans le groupe simulation et 20 dans le groupe témoin. Les deux groupes étaient comparables en termes d’âge, de délai accident-chirugie, de variétés fracturaires et d’approche chirurgicale. La durée opératoire moyenne était significativement réduite dans le groupe simulation : 113min±33 (60–180) versus 196±32 (60–260) (p
                     =0,01). La perte sanguine moyenne était significativement réduite dans le groupe simulation : 505mL±189 (100–750) versus 745mL±130 (200–850) (p
                     <0,01). En revanche, aucune différence significative n’était retrouvée concernant les résultats radiologiques, selon les critères de Matta, bien qu’une réduction anatomique était obtenue pour 9 patients du groupe simulation (90 %) versus 12 patients du groupe témoin (60 %) (p
                     =0,26). Une complication neurologique postopératoire était enregistrée dans le groupe témoin (déficit sensitif du nerf cutané latéral de cuisse).
               
                  Conclusion
                  Cette étude confirme les résultats prometteurs de la planification préopératoire en chirurgie traumatologique de l’acétabulum à partir d’une simulation biomécanique patient-spécifique ainsi que sa faisabilité en routine clinique. En permettant une meilleure compréhension de la fracture et de son comportement, elle permet une réduction de la durée et du saignement peropératoires.
               
                  Niveau de preuve
                  III ; étude cas-témoin.",multimedia
10.1016/j.asoc.2021.107644,Journal,Applied Soft Computing,scopus,2021-10-01,sciencedirect,Production scheduling in industrial mining complexes with incoming new information using tree search and deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85109174667,"Industrial mining complexes have implemented digital technologies and advanced sensors to monitor and gather real-time data about their different operational aspects, starting from the supply of materials from the mineral deposits involved to the products provided to customers. However, technologies are not available to respond in real-time to the incoming new information to adapt the short-term production schedule of a mining complex. A short-term production schedule determines the daily/weekly/monthly sequence of extraction, the destination of materials and utilization of processing streams. This paper presents a novel self-learning artificial intelligence algorithm for mining complexes that learns, from its own experience, to adapt the short-term production scheduling decisions by responding to incoming new information. The algorithm plays the game of short-term production scheduling on its own using a Monte Carlo tree search to train a deep neural network agent that adapts the short-term production schedule with incoming new information. The deep neural network agent evaluates the short-term production scheduling decisions and, in parallel, performs searches using the Monte Carlo tree search to generate experiences. The experiences are then used to train the agent. The agent improves the strength of the tree search, which results in an even stronger self-play to generate better experiences. An application of the proposed algorithm at a real-world copper mining complex shows its exceptional performance to adapt the 13-week short-term production schedule almost in real-time. The adapted production schedule successfully meets the different production requirements and makes better use of the processing capabilities, while also increasing copper concentrate production by 7% and cash flows by 12% compared to the initial production schedule. A video of the proposed algorithm can be found at https://youtu.be/_gSbzxMc_W8.",multimedia
10.1016/j.eswa.2021.115081,Journal,Expert Systems with Applications,scopus,2021-10-01,sciencedirect,Utilizing 3D joints data extracted through depth camera to train classifiers for identifying suicide bomber,https://api.elsevier.com/content/abstract/scopus_id/85105277236,"Safety and security of humans is an important concern in every aspect. With the advancement in engineering, sciences, and technology (unfortunately) new methods to harm humans have also been introduced. At the same time, scientists are paying attention to the security aspects by developing new software and hardware gadgets. In comparison to the system level security, the safety/security of human beings is more important. Suicide bombing is one such nuisance that is still an open challenge for the world to detect before it is triggered. This work deals with the identification of a suicide bomber using a 3D depth camera and machine learning techniques. This work utilizes the skeletal data provided by the 3D depth camera to identify a bomber wearing a suicide jacket. The prediction is based on real-time 3D posture data of the body joints obtained through the depth camera. Using a comprehensive experimental design, a dataset is created consisting of 20 joints information obtained from 120 participants. The dataset records this for each of the participants with and without wearing a suicide jacket. Experiments are performed with the suicide jacket bearing 10- to 20-kg weight. Simulations are performed using 3D spatial features of the participants' body in four ways: full body joints (20 joints), upper-half of the body (above the spine base of the skeleton), 20 joints with 15 frames, and 20 joints with 20 frames. It is observed that 15 to 20 frames are sufficient to identify a suspected suicide bomber. The proposed framework utilize four classifiers to identify vulnerability of a subject to be a suicide bomber. Results show that the proposed framework is capable of identifying a suicide bomber with an average accuracy of 92.30%.",multimedia
10.1016/j.cofs.2021.03.014,Journal,Current Opinion in Food Science,scopus,2021-10-01,sciencedirect,Novel digital technologies implemented in sensory science and consumer perception,https://api.elsevier.com/content/abstract/scopus_id/85104656313,"New and emerging digital technologies have been implemented in sensory science, which minimize subjectivity and biases in data acquisition and interpretation compared to traditional methods. These technologies have enabled the incorporation of physiological and emotional responses of panelists elicited by food, beverage, and packaging stimuli through accurate and unbiased information from different sensor technologies. This review focused on recent advances of digital technologies used for sensory science, such as (i) software for sensory science, (ii) integration of biometrics to assess physiological and emotional responses of panelists, (iii) incorporation of virtual, augmented, and mixed reality, and (iv) sensor technology (electronic noses and tongues) for sensory analysis. Rapid data acquisition and results’ interpretation could open the way to automation and implementation of Artificial Intelligence that could revolutionize the food and beverage industries. It also presents a proposed framework for integrating and implementing digital technologies through the food chain from farm/manufacturing facilities to the palate.",multimedia
10.1016/j.jocs.2021.101429,Journal,Journal of Computational Science,scopus,2021-09-01,sciencedirect,Automatic shape detection of ice crystals,https://api.elsevier.com/content/abstract/scopus_id/85113834380,"Clouds have a crucial impact on the energy balance of the Earth-Atmosphere system. They can cool the system by partly reflecting or scattering of the incoming solar radiation (albedo effect); moreover, thermal radiation as emitted from the Earth's surface can be absorbed and partly re-emitted by clouds leading to a warming of the atmosphere (greenhouse effect). The effectiveness of both effects crucially depends on the size and the shape of a cloud's particulate constituents, i.e. liquid water droplets or solid ice crystals. For studying cloud microphysics, in situ measurements on board of aircraft are commonly used. An important class of measurement techniques comprises optical array probes (OAPs) as developed since the 1970s [13]. While water droplets can be assumed as spherical, the shape and size of ice particles are highly variable. The currently used analysis methods to determine the particles’ size from OAP detection do rarely consider shape details or fine structures of ice particles, which may lead to artificial biases in the results.
                  In this paper, we present two new computational analysis methods, combined in an hybrid approach, for an automatic classification of ice particles and water droplets. The first method computes the principal components of a cloud particle and uses them to determine an ellipse, which can then be used to filter for spherical particles. The second method uses convolutional neural networks (CNNs) for the classification of columns and rosettes, respectively. Although we currently only classify these two particle types with CNNs, the presented method can be easily adapted for the classification of other particle types. The particularity of our method is that we use a virtual data set to pre-train the networks, which are then further trained with a smaller amount of manually classified real cloud particles in a fine tuning step. We evaluated our models on a small data set of real cloud particles and in a final field test on OAP image data that was not previously classified. The precision of this field test was better than 81% and ranged up to 98%, demonstrating that the new methods are suitable for providing profound shape classifications of cloud particle images obtained by OAP measurements. All methods we describe in this paper have been implemented in Python and C and are fully open source. Code and documentation are available on Github (https://github.com/lcsgrlch/oap).",multimedia
10.1016/j.ejcon.2021.06.005,Journal,European Journal of Control,scopus,2021-09-01,sciencedirect,A machine-learning approach to synthesize virtual sensors for parameter-varying systems,https://api.elsevier.com/content/abstract/scopus_id/85111527441,"This paper introduces a novel model-free approach to synthesize virtual sensors for the estimation of dynamical quantities that are unmeasurable at runtime but are available for design purposes on test benches. After collecting a dataset of measurements of such quantities, together with other variables that are also available during on-line operations, the virtual sensor is obtained using machine learning techniques by training a predictor whose inputs are the measured variables and the features extracted by a bank of linear observers fed with the same measures. The approach is applicable to infer the value of quantities such as physical states and other time-varying parameters that affect the dynamics of the system. The proposed virtual sensor architecture — whose structure can be related to the Multiple Model Adaptive Estimation framework — is conceived to keep computational and memory requirements as low as possible, so that it can be efficiently implemented in embedded hardware platforms.
                  The effectiveness of the approach is shown in different numerical examples, involving the estimation of the scheduling parameter of a nonlinear parameter-varying system, the reconstruction of the mode of a switching linear system, and the estimation of the state of charge (SoC) of a lithium-ion battery.",multimedia
10.1016/j.compmedimag.2021.101956,Journal,Computerized Medical Imaging and Graphics,scopus,2021-09-01,sciencedirect,Automated three-dimensional vessel reconstruction based on deep segmentation and bi-plane angiographic projections,https://api.elsevier.com/content/abstract/scopus_id/85111016853,"Automated three-dimensional (3D) blood vessel reconstruction to improve vascular diagnosis and therapeutics is a challenging task in which the real-time implementation of automatic segmentation and specific vessel tracking for matching artery sequences is essential. Recently, a deep learning-based segmentation technique has been proposed; however, existing state-of-the-art deep architectures exhibit reduced performance when they are employed using real in-vivo imaging because of serious issues such as low contrast and noise contamination of the X-ray images. To overcome these limitations, we propose a novel methodology composed of the de-haze image enhancement technique as pre-processing and multi-level thresholding as post-processing to be applied to the lightweight multi-resolution U-shaped architecture. Specifically, (1) bi-plane two-dimensional (2D) vessel images were extracted simultaneously using the deep architecture, (2) skeletons of the vessels were computed via a morphology operation, (3) the corresponding skeleton structure between image sequences was matched using the shape-context technique, and (4) the 3D centerline was reconstructed using stereo geometry. The method was validated using both in-vivo and in-vitro models. The results show that the proposed technique could improve the segmentation quality, reduce computation time, and reconstruct the 3D skeleton automatically. The algorithm accurately reconstructed the phantom model and the real mouse vessel in 3D in 2 s. Our proposed technique has the potential to allow therapeutic micro-agent navigation in clinical practice, thereby providing the 3D position and orientation of the vessel.",multimedia
10.1016/j.cmpb.2021.106275,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-09-01,sciencedirect,Automatic left ventricle volume calculation with explainability through a deep learning weak-supervision methodology,https://api.elsevier.com/content/abstract/scopus_id/85110223057,"Background and objective
                  Magnetic resonance imaging is the most reliable imaging technique to assess the heart. More specifically there is great importance in the analysis of the left ventricle, as the main pathologies directly affect this region. In order to characterize the left ventricle, it is necessary to extract its volume. In this work we present a neural network architecture that is capable of directly estimating the left ventricle volume in short axis cine Magnetic Resonance Imaging in the end-diastolic frame and provide a segmentation of the region which is the basis of the volume calculation, thus offering explainability to the estimated value.
               
                  Methods
                  The network was designed to directly target the volumes to estimate, not requiring any labeled segmentation on the images. The network was based on a 3D U-net with extra layers defined in a scanning module that learned features like the circularity of the objects and the volumes to estimate in a weakly-supervised manner. The only targets defined were the left ventricle volumes and the circularity of the object detected through the estimation of the π value derived from its shape. We had access to 397 cases corresponding to 397 different subjects. We randomly selected 98 cases to use as test set.
               
                  Results
                  The results show a good match between the real and estimated volumes in the test set, with a mean relative error of 8% and a mean absolute error of 9.12 ml with a Pearson correlation coefficient of 0.95. The derived segmentations obtained by the network achieved Dice coefficients with a mean value of 0.79.
               
                  Conclusions
                  The proposed method is capable of obtaining the left ventricle volume biomarker in the end-diastole and offer an explanation of how it obtains the result in the form of a segmentation mask without the need of segmentation labels to train the algorithm, making it a potentially more trustworthy method for clinicians and a way to train neural networks more easily when segmentation labels are not readily available.",multimedia
10.1016/j.oceaneng.2021.109435,Journal,Ocean Engineering,scopus,2021-09-01,sciencedirect,An enhanced CNN-enabled learning method for promoting ship detection in maritime surveillance system,https://api.elsevier.com/content/abstract/scopus_id/85109195594,"The accurate and real-time detection of moving ships has become an essential component in maritime video surveillance, leading to enhanced traffic safety and security. With the rapid development of artificial intelligence, it becomes feasible to develop intelligent techniques to promote ship detection results in maritime applications. In this work, we propose to develop an enhanced convolutional neural network (CNN) to improve ship detection under different weather conditions. To be specific, the learning and representation capacities of our network are promoted by redesigning the sizes of anchor boxes, predicting the localization uncertainties of bounding boxes, introducing the soft non-maximum suppression, and reconstructing a mixed loss function. In addition, a flexible data augmentation strategy with generating synthetically-degraded images is presented to enlarge the volume and diversity of original dataset to train learning-based ship detection methods. This strategy is capable of making our CNN-based detection results more reliable and robust under adverse weather conditions, e.g., rain, haze, and low illumination. Experimental results under different monitoring conditions demonstrate that our method significantly outperforms other competing methods (e.g., SSD, Faster R-CNN, YOLOv2 and YOLOv3) in terms of detection accuracy, robustness and efficiency. The ship detection results under poor imaging conditions have also been implemented to demonstrate the superior performance of our learning method.",multimedia
10.1016/j.oceaneng.2021.109433,Journal,Ocean Engineering,scopus,2021-09-01,sciencedirect,Dynamic Positioning using Deep Reinforcement Learning,https://api.elsevier.com/content/abstract/scopus_id/85109148012,"This paper demonstrates the implementation and performance testing of a Deep Reinforcement Learning based control scheme used for Dynamic Positioning of a marine surface vessel. The control scheme encapsulated motion control and control allocation by using a neural network, which was trained on a digital twin without having any prior knowledge of the system dynamics, using the Proximal Policy Optimization learning algorithm. By using a multivariate Gaussian reward function for rewarding small errors between the vessel and the various setpoints, while encouraging small actuator outputs, the proposed Deep Reinforcement Learning based control scheme showed good positioning performance while being energy efficient. Both simulations and model scale sea trials were carried out to demonstrate performance compared to traditional methods, and to evaluate the ability of neural networks trained in simulation to perform on real life systems.",multimedia
10.1016/j.ijcip.2021.100452,Journal,International Journal of Critical Infrastructure Protection,scopus,2021-09-01,sciencedirect,Adversarial attacks and mitigation for anomaly detectors of cyber-physical systems,https://api.elsevier.com/content/abstract/scopus_id/85107972529,"The threats faced by cyber-physical systems (CPSs) in critical infrastructure have motivated research into a multitude of attack detection mechanisms, including anomaly detectors based on neural network models. The effectiveness of anomaly detectors can be assessed by subjecting them to test suites of attacks, but less consideration has been given to adversarial attackers that craft noise specifically designed to deceive them. While successfully applied in domains such as images and audio, adversarial attacks are much harder to implement in CPSs due to the presence of other built-in defence mechanisms such as rule checkers (or invariant checkers). In this work, we present an adversarial attack that simultaneously evades the anomaly detectors and rule checkers of a CPS. Inspired by existing gradient-based approaches, our adversarial attack crafts noise over the sensor and actuator values, then uses a genetic algorithm to optimise the latter, ensuring that the neural network and the rule checking system are both deceived. We implemented our approach for two real-world critical infrastructure testbeds, successfully reducing the classification accuracy of their detectors by over 50% on average, while simultaneously avoiding detection by rule checkers. Finally, we explore whether these attacks can be mitigated by training the detectors on adversarial samples.",multimedia
10.1016/j.sysarc.2021.102183,Journal,Journal of Systems Architecture,scopus,2021-09-01,sciencedirect,Memory-efficient deep learning inference with incremental weight loading and data layout reorganization on edge systems,https://api.elsevier.com/content/abstract/scopus_id/85107073021,"Pattern recognition applications such as face recognition and agricultural product detection have drawn a rapid interest on Cyber–Physical–Social-Systems (CPSS). These CPSS applications rely on the deep neural networks (DNN) to conduct the image classification. However, traditional DNN inference models in the cloud could suffer from network delay fluctuations and privacy leakage problems. In this regard, current real-time CPSS applications are preferred to be deployed on edge-end embedded devices. Constrained by the computing power and memory limitations of edge devices, improving the memory management efficacy is the key to improving the quality of service for model inference. First, this study explored the incremental loading strategy of model weights for the model inference. Second, the memory space at runtime is optimized through data layout reorganization from the spatial dimension. In particular, the proposed schemes are orthogonal to existing models. Experimental results demonstrate that the proposed approach reduced the memory consumption by 61.05% without additional inference time overhead.",multimedia
10.1016/j.asoc.2021.107465,Journal,Applied Soft Computing,scopus,2021-09-01,sciencedirect,Click-event sound detection in automotive industry using machine/deep learning,https://api.elsevier.com/content/abstract/scopus_id/85105315919,"In the automotive industry, despite the robotic systems on the production lines, factories continue employing workers in several custom tasks getting for semi-automatic assembly operations. Specifically, the assembly of electrical harnesses of engines comprises a set of connections between electrical components. Despite the task is easy to perform, employees tend not to notice that a few components are not being connected properly due to physical fatigue provoked by repetitive tasks. This yields a low quality of the assembly production line and possible hazards. In this work, we propose a sound detection system based on machine/deep learning (ML/DL) approaches to identify click sounds produced when electrical harnesses are connected. The purpose of this system is to count the number of connections properly made and to feedback to the employees. We collect and release a public dataset of 25,000 click sounds of 25 ms length at 22 kHz during three months of assembly operations in an automotive production line located in Mexico. Then, we design an ML/DL-based methodology for click sound detection of assembled harnesses under real conditions of a noisy environment (noise level ranging from 
                        
                           −
                           16
                           .
                           67
                        
                      dB to 
                        
                           −
                           12
                           .
                           87
                        
                      dB) including other machinery sounds. Our best ML/DL model (i.e., a combination between five acoustic features and an optimized convolutional neural network) is able to detect click sounds in a real assembly production line with an accuracy of 
                        
                           94
                           .
                           55
                           ±
                           0
                           .
                           83
                        
                      %. To the best of our knowledge, this is the first time a click sounds detection system in assembling electrical harnesses of engines for giving feedback to the workers is proposed and implemented in a real-world automotive production line. We consider this work valuable for the automotive industry on how to apply ML/DL approaches for improving the quality of semi-automatic assembly operations.",multimedia
10.1016/j.neuroimage.2021.118206,Journal,NeuroImage,scopus,2021-08-15,sciencedirect,"Joint super-resolution and synthesis of 1 mm isotropic MP-RAGE volumes from clinical MRI exams with scans of different orientation, resolution and contrast",https://api.elsevier.com/content/abstract/scopus_id/85106551066,"Most existing algorithms for automatic 3D morphometry of human brain MRI scans are designed for data with near-isotropic voxels at approximately 1 mm resolution, and frequently have contrast constraints as well-typically requiring T1-weighted images (e.g., MP-RAGE scans). This limitation prevents the analysis of millions of MRI scans acquired with large inter-slice spacing in clinical settings every year. In turn, the inability to quantitatively analyze these scans hinders the adoption of quantitative neuro imaging in healthcare, and also precludes research studies that could attain huge sample sizes and hence greatly improve our understanding of the human brain. Recent advances in convolutional neural networks (CNNs) are producing outstanding results in super-resolution and contrast synthesis of MRI. However, these approaches are very sensitive to the specific combination of contrast, resolution and orientation of the input images, and thus do not generalize to diverse clinical acquisition protocols – even within sites. In this article, we present SynthSR, a method to train a CNN that receives one or more scans with spaced slices, acquired with different contrast, resolution and orientation, and produces an isotropic scan of canonical contrast (typically a 1 mm MP-RAGE). The presented method does not require any preprocessing, beyond rigid coregistration of the input scans. Crucially, SynthSR trains on synthetic input images generated from 3D segmentations, and can thus be used to train CNNs for any combination of contrasts, resolutions and orientations without high-resolution real images of the input contrasts. We test the images generated with SynthSR in an array of common downstream analyses, and show that they can be reliably used for subcortical segmentation and volumetry, image registration (e.g., for tensor-based morphometry), and, if some image quality requirements are met, even cortical thickness morphometry. The source code is publicly available at https://github.com/BBillot/SynthSR.",multimedia
10.1016/j.jbi.2021.103848,Journal,Journal of Biomedical Informatics,scopus,2021-08-01,sciencedirect,Face mask detection using deep learning: An approach to reduce risk of Coronavirus spread,https://api.elsevier.com/content/abstract/scopus_id/85109043381,"Effective strategies to restrain COVID-19 pandemic need high attention to mitigate negatively impacted communal health and global economy, with the brim-full horizon yet to unfold. In the absence of effective antiviral and limited medical resources, many measures are recommended by WHO to control the infection rate and avoid exhausting the limited medical resources. Wearing a mask is among the non-pharmaceutical intervention measures that can be used to cut the primary source of SARS-CoV2 droplets expelled by an infected individual. Regardless of discourse on medical resources and diversities in masks, all countries are mandating coverings over the nose and mouth in public. To contribute towards communal health, this paper aims to devise a highly accurate and real-time technique that can efficiently detect non-mask faces in public and thus, enforcing to wear mask. The proposed technique is ensemble of one-stage and two-stage detectors to achieve low inference time and high accuracy. We start with ResNet50 as a baseline and applied the concept of transfer learning to fuse high-level semantic information in multiple feature maps. In addition, we also propose a bounding box transformation to improve localization performance during mask detection. The experiment is conducted with three popular baseline models viz. ResNet50, AlexNet and MobileNet. We explored the possibility of these models to plug-in with the proposed model so that highly accurate results can be achieved in less inference time. It is observed that the proposed technique achieves high accuracy (98.2%) when implemented with ResNet50. Besides, the proposed model generates 11.07% and 6.44% higher precision and recall in mask detection when compared to the recent public baseline model published as RetinaFaceMask detector. The outstanding performance of the proposed model is highly suitable for video surveillance devices.",multimedia
10.1016/j.ijdrr.2021.102397,Journal,International Journal of Disaster Risk Reduction,scopus,2021-08-01,sciencedirect,Twitter chirps for Syrian people: Sentiment analysis of tweets related to Syria Chemical Attack,https://api.elsevier.com/content/abstract/scopus_id/85108873548,"Purpose
                  The sentiment analysis of tweets provides information about peoples’ attitudes and perceptions towards an event. The current study showcases the role of Twitter in a crisis by analyzing the nature of tweets and the sentiments expressed by the Twitter-sphere during and after the “Khan Shaykhun Syria Chemical Attack.""
               
                  Methodology
                  A total of 13,156 tweets posted in English on Twitter during the first 27 days of the attack were downloaded and considered for the study. The content analysis of the tweets was done manually, and accordingly, the sentiments of the tweets were highlighted through eight broader categories. Furthermore, to visualize the positive, negative, and neutral sentiments of the tweets, the Orange Data 
                     M
                     ining Software, a powerful toolkit for machine learning, data mining, and data visualization, was used. VOSviewer (a software tool used for creating maps based on network data and for visualizing and exploring the maps) was also used to visualize the word frequency of the tweets.
               
                  Findings
                  Twitter is primarily used for situational awareness and acts as an emotional, social support system by sharing sentiments. 35.71% of the tweets are associated with ""
                     sharing news and information"" , with just 2.12% ""
                     supporting the government"". People mostly retweet the tweets that “criticize the government,” with an average retweet count of 15.84, followed by the ones “evincing emotions” (12.21). However, tweets that “raise questions” (3.32) and “provide suggestions” (2.51) fail to gain the attention of too many tweeter users, thus having less impact. People mostly like the tweets that “
                     support 
                     government” and “evince emotions,” with such tweets on an average receiving 9.89 and 8.37 likes, respectively. Individuals post a large number of tweets (10,137; 77.05%), followed by news channels (1157; 8.79%) and organizations of varied nature (950; 7.22%). However, 912 (6.93%) tweets are posted by users of anonymous nature. Text and text with images form most tweets contributing to 8061 (61.27%) and 3137 (23.84%) of the total tweet count. However, none of the tweets contain video only, and just 3 (0.02%) tweets embed only images. Text-video and text-image formats are highly re-tweeted and liked. It is evident that 53.70% of the tweets (n = 7065) reflect negative sentiments, while 12.67% (n = 1667) emulate positive sentiments and, 33.63% (n = 4424) showcase a neutral perception about the attack. One can visualize the U.S.A. among the top tweeting countries with the highest percentage of positive sentiments, followed by Canada and Israel. Turkey outscores all the countries in terms of negative tweets, followed by Syria and U.K. However, in terms of neutral tweets, Germany ranks first, followed by Iran and Canada. The tweets pour mainly for the first few days, indicating the concern of users for the victims. Later on, a declining trend of tweets is witnessed. “idlib”, “Syria”, “Syria chemical attack,” and “Assad” are the leading words used more than a thousand times in the tweets.
               
                  Research implications
                  The current study adds to the growing body of knowledge to the existing literature on Twitter and its use to narrowcast situational awareness during crisis episodes. One of the implications of the study is that the news agencies highly exploit the sharing side of Twitter during disasters by communicating real-time and unique information, create situational awareness, and connect to the digital audience. Twitter acts as an emotional outlet that facilitates the mining of condensed varied reactions towards an event to frame disaster response strategies and provides a sociological understanding of social media use during the crisis by the victims and viewers.
               
                  Originality
                  The study represents the sentiments of the Twitter-sphere towards the “Syria Chemical Attack.""",multimedia
10.1016/j.ghir.2021.101408,Journal,Growth Hormone and IGF Research,scopus,2021-08-01,sciencedirect,Digital technologies to improve the precision of paediatric growth disorder diagnosis and management,https://api.elsevier.com/content/abstract/scopus_id/85107315211,"Paediatric disorders of impaired linear growth are challenging to manage, in part because of delays in the identification of pathological short stature and subsequent referral and diagnosis, the requirement for long-term therapy, and frequent poor adherence to treatment, notably with human growth hormone (hGH). Digital health technologies hold promise for improving outcomes in paediatric growth disorders by supporting personalisation of care, from diagnosis to treatment and follow up. The value of automated systems in monitoring linear growth in children has been demonstrated in Finland, with findings that such a system is more effective than a traditional manual system for early diagnosis of abnormal growth. Artificial intelligence has potential to resolve problems of variability that may occur during analysis of growth information, and augmented reality systems have been developed that aim to educate patients and caregivers about growth disorders and their treatment (such as injection techniques for hGH administration). Adherence to hGH treatment is often suboptimal, which negatively impacts the achievement of physical and psychological benefits of the treatment. Personalisation of adherence support necessitates capturing individual patient adherence data; the use of technology to assist with this is exemplified by the use of an electronic injection device, which shares real-time recordings of the timing, date and dose of hGH delivered to the patient with the clinician, via web-based software. The use of an electronic device is associated with high levels of adherence to hGH treatment and improved growth outcomes. It can be anticipated that future technological advances, coupled with continued ‘human interventions’ from healthcare providers, will further improve management of paediatric growth disorders.",multimedia
10.1016/j.cmpb.2021.106168,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-08-01,sciencedirect,Semi-AI and Full-AI digitizer: The ways to digitalize visual field big data,https://api.elsevier.com/content/abstract/scopus_id/85106865896,"Background and objective
                  Glaucoma is one of the major diseases that cause blindness, which is incurable and irreversible, and it is essential to detect glaucoma vision deficits in treatment and check the progression of vision disorders in advance. In order to minimize the risk of glaucoma, it is necessary not only to diagnose and observe glaucoma but also to predict prognosis via indicators from Visual Field (VF) tests. However, information from the VF test cannot be directly used in clinical studies because most medical institutions store VF test sheets in Portable Document Format (PDF) or image files in different standards.
               
                  Methods
                  We developed AI-based real-time VF big data digitizing systems that digitalize VF test images in real-time in two ways; Semi-AI and Full-AI digitizer. The Semi-AI digitizer detects the VF text area with actual coordinates derived from mouse handler system. Full-AI digitizer detects the VF text area with Faster Region Based Convolutional Neural Networks (RCNN). After detecting the text area, both systems extract texts with Recurrent Neural Network based Optical Character Recognition. Semi-AI and Full-AI digitizer post-processes the extracted text results with in-system algorithm and out-of-system algorithm, respectively.
               
                  Results
                  Both systems used 325,310 VF test sheets from a tertiary hospital and extracted a total of 5,530,270 texts. From the 100 randomly selected VF sheets, 3,400 texts were used for the validation. Semi-AI and Full-AI digitizer showed 0.993 and 0.983 of accuracy, respectively.
               
                  Conclusion
                  This study demonstrates the effectiveness of AI applications in detecting text areas and the different implementation methodologies of the post-processing process. In detecting text area, Semi-AI may be better than Full-AI digitizer in terms of system speed and human labor labeling if the number of types to be classified is small. However, Full-AI digitizer is recommended because it allows detecting text area regardless of resolution and size of the VF sheets, as the types of real-world VF test sheets cannot be predicted, and the types become more unpredictable when extended to multi-hospital studies. For Post-preprocessing, Semi-AI methodology is recommended because Semi-AI produced higher results with less effort and considered the convenience of researchers by implementing them as in-system.",multimedia
10.1016/j.coastaleng.2021.103919,Journal,Coastal Engineering,scopus,2021-08-01,sciencedirect,Satellite optical imagery in Coastal Engineering,https://api.elsevier.com/content/abstract/scopus_id/85106393729,"This Short Communication provides a Coastal Engineering perspective on present and emerging capabilities of satellite optical imagery, including real-world applications that can now be realistically implemented from the desktop. Significantly, at the vast majority of locations worldwide, satellite remote sensing is currently the only source of information to complement much more limited in-situ instrumentation for land and sea mapping, monitoring and measurement. Less well recognised is that publicly available, routinely sampled and now easily accessible optical imagery covering virtually every position along the world's coastlines already spans multiple decades. In the past five years the common obstacles of (1) limited access to high-performance computing and (2) specialist remote sensing technical expertise, have been largely removed. The emergence of several internet-accessible application programming interfaces (APIs) now enable applied users to access petabytes of satellite imagery along with the necessary tools and processing power to extract, manipulate and analyse information of practical interest. Following a brief overview and timeline of civilian Earth observations from space, satellite-derived shorelines (SDS) and satellite-derived bathymetry (SDB) are used to introduce and demonstrate some of the present real-world capabilities of satellite optical imagery most relevant to coastal professionals and researchers. These practical examples illustrate the use of satellite imagery to monitor and quantify both engineered and storm-induced coastline changes, as well as the emerging potential to obtain seamless topo/bathy surveys along coastal regions. Significantly, timescales of satellite-derived changes at the coast can range from decades to days, with spatial scales of interest extending from individual project sites up to unprecedented regional and global studies. While we foresee the uptake and routine use of satellite-derived information becoming quickly ubiquitous within the Coastal Engineering profession, on-ground observations are – and in our view will remain - fundamentally important. Compared to precision in-situ instrumentation, present intrinsic limitations of satellites are their relatively low rates of revisit and decimetre spatial accuracy. New satellite advances including ‘video from space’ and the potential to combine Earth observation with numerical and data-driven coastal models through assimilation and artificial intelligence are advances that we foresee will have future major impact in Coastal Engineering.",multimedia
10.1016/j.cag.2021.04.035,Journal,Computers and Graphics (Pergamon),scopus,2021-08-01,sciencedirect,DIMNet: Dense implicit function network for 3D human body reconstruction,https://api.elsevier.com/content/abstract/scopus_id/85105858338,"In recent years, with the improvement of artificial intelligence technology, it has become possible to reconstruct high-precision 3D human body models based on ordinary RGB images. The current 3D human body reconstruction technology requires complex external equipment to scan all angles of the human body, which is complicated to be implemented and cannot be popularized. In order to solve this problem, this paper applies deep learning models on reconstructing 3D human body based on monocular images. First of all, this paper uses Stacked Hourglass network to perform convolution operations on monocular images collected from different views. Then Multi-Layer Perceptrons (MLPs) are used to decode the encoded high-level images. The feature codes in the two views(main and side) are fused, and the interior and exterior points are classified by the fusion features, so as to obtain the corresponding 3D occupancy field. At last, the Marching Cube algorithm is used for 3D reconstruction with a specific threshold and then we use Laplace smoothing algorithm to remove artifacts. This paper proposes a dense sampling strategy based on the important joint points of the human body, which has a certain optimization effect on the realization of high-precision 3D reconstruction. The performance of the proposed scheme has been validated on the open source datasets, MGN dataset and the THuman dataset, provided by Tsinghua University. The proposed scheme can reconstruct features such as clothing folds, color textures, and facial details,and has great potential to be applied in different applications.",multimedia
10.1016/j.buildenv.2021.107929,Journal,Building and Environment,scopus,2021-08-01,sciencedirect,MOOSAS – A systematic solution for multiple objective building performance optimization in the early design stage,https://api.elsevier.com/content/abstract/scopus_id/85105785192,"There is great potential for building performance optimization (BPO) in the early design stage, but there is still a lack of methods, algorithms, and tools to support the BPO process in this stage. Through a comprehensive review, this study identified three critical issues that affect the implementation of the BPO process in the early design stage: model integration, real-time performance analysis, and interactive optimization design. This study provides a systematic solution to these three critical issues. In terms of model integration, a feature-based and graph-based 3D building space recognition algorithm is proposed to automatically convert the computer-aided design (CAD model) into a computer-aided engineering model (CAE model). In terms of real-time performance analysis, a simplified physical method, an HPC-accelerated method, and an AI-based method are explored, and a real-time energy modeling module and a real-time daylighting analysis module are developed. In terms of the interactive optimization design, a preference-based multi-objective BPO design algorithm that can consider user preferences is proposed to make full use of the decision-making ability of humans and the computing power of machines and significantly improve the optimization efficiency and result satisfaction. Based on the systematic solution, a multi-objective BPO design software, MOOSAS, is developed. MOOSAS allows real-time performance feedback, dynamic parameter analysis, and interactive optimization, supporting the BPO process in the early design stage. The innovations of this study are as follows: first, this study proposes a systematic solution to the three critical issues of the BPO process, i.e., model integration, real-time performance analysis, and interactive optimization design; second, this study develops a multi-objective BPO design software (MOOSAS) for the early design stage.",multimedia
10.1016/j.apacoust.2021.108068,Journal,Applied Acoustics,scopus,2021-08-01,sciencedirect,Convolutional neural network trained with synthetic pseudo-images for detecting an acoustic source,https://api.elsevier.com/content/abstract/scopus_id/85103956231,"We report a detection method of an acoustic source by the convolutional neural network (CNN) that utilizes analytic predictions of sound radiation. The analytic predictions with various source conditions are implemented to effectively collect a large-annotated training dataset, allowing straightforward utilizations of the CNN in the acoustic domain. The data conversion from the synthetic audio signals into the pseudo-images is presented to secure compatibility with actual audio signals in terms of the direction of angle (DOA) estimation. Our source localization network fully trained with the synthetic pseudo-images were verified with various source conditions in a semi-reverberant room. The verifications demonstrate remarkable robustness and noise resistance to estimate the DOA regardless of source conditions. Moreover, considering our network has implemented a small number of short-time audio signals (i.e., three audio signals for 0.1 s), the proposed algorithm can be a breakthrough in a real-time tracking of the acoustic source by hybridizing analytical and data-driven approaches.",multimedia
10.1016/j.enbuild.2021.110967,Journal,Energy and Buildings,scopus,2021-07-15,sciencedirect,"A non-intrusive approach for fault detection and diagnosis of water distribution systems based on image sensors, audio sensors and an inspection robot",https://api.elsevier.com/content/abstract/scopus_id/85104453372,"Fault diagnosis is important to maintain the normal operation of air-conditioning systems, reduce the energy consumption in buildings, and increase the service life of air-conditioning system equipment. We present a novel approach for fault detection and diagnosis system that relies on image and audio sensors and relevant algorithms.
                  This paper proposes a fault diagnosis algorithm based on a robot that can automatically capture audio and image signals from microphone arrays and cameras during inspection in a chiller room. It includes audio- and image-based fault diagnosis algorithms. The validity of the algorithm combined with sensors is verified using data from actual equipment in a chiller room.
                  The audio-based algorithm, which can monitor the abnormal sound of pumps to detect faults, utilizes Fourier transform, a finite impulse response digital filter, and an autoregressive integrated moving average model. We analyze the frequency domain of the pump signal and set the appropriate threshold to monitor abnormal signals based on the fitted model. Meanwhile, the image-based algorithms are divided into three sections to achieve three functions: 1) an AlexNet convolutional neural network is modified to classify the images of the chiller room equipment obtained by the visible light camera; 2) image morphology methods and trigonometric functions are used to read the dials’ indicators acquired by the visible light camera; and 3) optical character recognition is used to obtain the highest temperature value in the infrared image of the pump captured by the infrared camera, which helps maintenance staff verify the operation of the pump and detect faults as soon as possible.
                  These diagnostic algorithms are non-intrusive, low cost, and easy to deploy. Combined with real-time data collection from the sensors on the robot, the algorithms can effectively improve the intelligence of the equipment room and allocate human resources more reasonably.",multimedia
10.1016/j.procs.2021.06.077,Conference Proceeding,Procedia Computer Science,scopus,2021-07-01,sciencedirect,Digital transformation as a new paradigm of economic policy,https://api.elsevier.com/content/abstract/scopus_id/85112599973,"This study analyzes the conceptual provisions related to solving problems related to the introduction of digital technologies and the formation of a digital economy based on them, reveals the dynamics of digital transformation and its impact on business processes and the interaction of states, business and civil society in the context of modern economic policy. We reviewed the policy of the Russian state in terms of overcoming both the existing and potential economic consequences of the COVID-19 pandemic based on published expert assessments. Our results confirmed that overcoming the current turbulent state of the digital economy in Russia requires: firstly, the development of digital entrepreneurship or the digital sector as the “core” of the digital economy, where digital technologies are created; secondly, the removal of restrictions on the movement of resources caused by the COVID-19 pandemic, as a result of the consistent implementation of a coordinated strategy for the digitalization of the economy, based on global cooperation in the field of economic policy; third, the process of reproduction of the social product, where production - distribution – exchange - consumption interact, should take place at the level of world standards; fourth, to introduce the “digital style”in economic policy through building technological chains and diversified connections; fifth, to develop artificial intelligence, the essence of which is to“break” the matrix of habitual life in order to launch a large-scale virtual program of a new being of humanity, spurred by the COVID-19 pandemic.",multimedia
10.1016/j.microrel.2021.114134,Journal,Microelectronics Reliability,scopus,2021-07-01,sciencedirect,Towards virtual twin for electronic packages in automotive applications,https://api.elsevier.com/content/abstract/scopus_id/85106914513,"The piezoresistive silicon based stress sensor has the potential to be part of the Digital Twin implementation in automotive electronics. One solution to enforce reliability in digital twins is the use of Machine Learning (ML). One or more physical parameters are being monitored, while other parameters are projected with surrogate models, just like virtual sensors. Piezo-resistive stress sensors are employed to measure the internal stresses of electronic packages, an Acquisition Unit (AU) to read out sensor data and a Raspberry Pi to perform evaluation. Accelerated tests in air thermal chamber are performed to get time series data of the stress sensor signals, with which we can know better about how delamination develops inside the package. In this study stress measurements are performed in several electronic packages during the delamination. The delamination is detected by the stress sensor due to the continuous change of the stiffness and the local boundary conditions causing the stresses to change. Although, the stress change in multiple cells can give enough information if it is delaminated or not, its delamination area location is unknown. Surrogate models built upon Neural Networks (NN) and Finite Element Method (FEM) are developed to predict the out of plane stresses at the delaminated layer. FEM simulation models are calibrated with Moiré measurements and validated at the component and PCB level with stress difference measurements. Simulation delamination areas are constructed based on the Scanning Acoustic Microscope (SAM) images, and are also validated with the equivalent stress measurements. In the end the surrogate model is predicting the out of plane stress in the adhesive layer. The results show good correlation when compared to the SAM images.",multimedia
10.1016/j.isprsjprs.2021.04.006,Journal,ISPRS Journal of Photogrammetry and Remote Sensing,scopus,2021-07-01,sciencedirect,Aerial scene understanding in the wild: Multi-scene recognition via prototype-based memory networks,https://api.elsevier.com/content/abstract/scopus_id/85106241924,"Aerial scene recognition is a fundamental visual task and has attracted an increasing research interest in the last few years. Most of current researches mainly deploy efforts to categorize an aerial image into one scene-level label, while in real-world scenarios, there often exist multiple scenes in a single image. Therefore, in this paper, we propose to take a step forward to a more practical and challenging task, namely multi-scene recognition in single images. Moreover, we note that manually yielding annotations for such a task is extraordinarily time- and labor-consuming. To address this, we propose a prototype-based memory network to recognize multiple scenes in a single image by leveraging massive well-annotated single-scene images. The proposed network consists of three key components: 1) a prototype learning module, 2) a prototype-inhabiting external memory, and 3) a multi-head attention-based memory retrieval module. To be more specific, we first learn the prototype representation of each aerial scene from single-scene aerial image datasets and store it in an external memory. Afterwards, a multi-head attention-based memory retrieval module is devised to retrieve scene prototypes relevant to query multi-scene images for final predictions. Notably, only a limited number of annotated multi-scene images are needed in the training phase. To facilitate the progress of aerial scene recognition, we produce a new multi-scene aerial image (MAI) dataset. Experimental results on variant dataset configurations demonstrate the effectiveness of our network. Our dataset and codes are publicly available
                        1
                     
                     
                        1
                        
                           https://github.com/Hua-YS/Prototype-based-Memory-Network.
                     .",multimedia
10.1016/j.compbiomed.2021.104450,Journal,Computers in Biology and Medicine,scopus,2021-07-01,sciencedirect,A comprehensive review and analysis of supervised-learning and soft computing techniques for stress diagnosis in humans,https://api.elsevier.com/content/abstract/scopus_id/85105598718,"Stress is the most prevailing and global psychological condition that inevitably disrupts the mood and behavior of individuals. Chronic stress may gravely affect the physical, mental, and social behavior of victims and consequently induce myriad critical human disorders. Herein, a review has been presented where supervised learning (SL) and soft computing (SC) techniques used in stress diagnosis have been meticulously investigated to highlight the contributions, strengths, and challenges faced in the implementation of these methods in stress diagnostic models. A three-tier review strategy comprising of manuscript selection, data synthesis, and data analysis was adopted. The issues in SL strategies and the potential possibility of using hybrid techniques in stress diagnosis have been intensively investigated. The strengths and weaknesses of different SL (Bayesian classifier, random forest, support vector machine, and nearest neighbours) and SC (fuzzy logic, nature-inspired, and deep learning) techniques have been presented to obtain clear insights into these optimization strategies. The effects of social, behavioral, and biological stresses have been highlighted. The psychological, biological, and behavioral responses to stress have also been briefly elucidated. The findings of the study confirmed that different types of data/signals (related to skin temperature, electro-dermal activity, blood circulation, heart rate, facial expressions, etc.) have been used in stress diagnosis. Moreover, there is a potential scope for using distinct nature-inspired computing techniques (Genetic Algorithm, Particle Swarm Optimization, Ant Colony Optimization, Whale Optimization Algorithm, Butterfly Optimization, Harris Hawks Optimizer, and Crow Search Algorithm) and deep learning techniques (Deep-Belief Network, Convolutional-Neural Network, and Recurrent-Neural Network) on multimodal data compiled using behavioral testing, electroencephalogram signals, finger temperature, respiration rate, pupil diameter, galvanic-skin-response, and blood pressure. Likewise, there is a wider scope to investigate the use of SL and SC techniques in stress diagnosis using distinct dimensions such as sentiment analysis, speech recognition, handwriting recognition, and facial expressions. Finally, a hybrid model based on distinct computational methods influenced by both SL and SC techniques, adaption, parameter tuning, and the use of chaos, levy, and Gaussian distribution may address exploration and exploitation issues. However, factors such as real-time data collection, bias, integrity, multi-dimensional data, and data privacy make it challenging to design precise and innovative stress diagnostic systems based on artificial intelligence.",multimedia
10.1016/j.patrec.2021.04.002,Journal,Pattern Recognition Letters,scopus,2021-07-01,sciencedirect,A novel feature extractor for human action recognition in visual question answering,https://api.elsevier.com/content/abstract/scopus_id/85104626539,"Recognizing and classifying human actions in video clips is a powerful technology for surveillance applications. However, most of the state-of-the-art approaches for this task lack the possibility of being implemented in real-time applications without causing a critical delay. Thus, we propose a fast method to human action recognition for visual question answering, based on a novel feature extractor developed by us, 2D pose estimation, and machine learning techniques. Our extractor obtains features based on distances, angles, and positions of detected anatomical keypoints. We used the UCF101 dataset that corresponds to 13,320 videos with realistic human actions, collected from YouTube, for our work evaluation. The proposed feature extractor, combined with the Complement Naive Bayes classifier, reached a mean Average Precision (
                        
                           m
                           A
                           P
                        
                     ) of 
                        
                           62.03
                           %
                        
                      and processed 5.26 frames per second, proving to be faster than most methods while achieving a decent 
                        
                           m
                           A
                           P
                        
                     .",multimedia
10.1016/j.echo.2021.02.017,Journal,Journal of the American Society of Echocardiography,scopus,2021-07-01,sciencedirect,Recurrence of Functional Versus Organic Mitral Regurgitation After Transcatheter Mitral Valve Repair: Implications from Three-Dimensional Echocardiographic Analysis of Mitral Valve Geometry and Left Ventricular Dilation for a Point of No Return,https://api.elsevier.com/content/abstract/scopus_id/85104366994,"Background
                  MitraClip implantation has become the standard transcatheter mitral valve repair (TMVR) technique for severe mitral regurgitation (MR). However, approximately one third of patients have poor outcomes, with MR recurrence at follow-up. The aim of this study was to investigate whether quantitative analysis of mitral valve (MV) geometry on three-dimensional (3D) echocardiography can identify geometric parameters associated with the recurrence of severe functional MR (FMR) versus organic MR (OMR) at 6-month follow-up after TMVR using the MitraClip.
               
                  Methods
                  Sixty-one patients with severe FMR (n = 45) or OMR (n = 16) who underwent transesophageal 3D echocardiography before and 6 months after TMVR were retrospectively analyzed. MV geometry was quantified using 3D echocardiography software. Vena contracta area (VCA) at 6-month follow-up was used to define two outcome groups: patients with good results with VCA < 0.6 cm2 (MR < 0.6) and those with MR recurrence with VCA ≥ 0.6 cm2 (MR ≥ 0.6).
               
                  Results
                  MR recurrence was found in 34% of all study patients (21 of 61). In patients with FMR, significant differences between MR < 0.6 and MR ≥ 0.6 were found at baseline for tenting index (1.13 vs 1.23, P = .004), tenting volume (2.8 vs 4.0 ml, P = .04), indexed left ventricular (LV) end-diastolic volume (68.0 vs 99.9 ml/m2, P = .001), and VCA (0.71 vs 1.00 cm2, P = .003); no significant parameters of MR recurrence were found in patients with OMR. Multivariate analysis identified indexed LV end-diastolic volume as the strongest independent determinant of MR recurrence. Receiver operating characteristic analysis identified a tenting index of 1.185 (area under the curve 0.79) and indexed LV end-diastolic volume of 88 ml/m2 (area under the curve 0.76) to best discriminate between MR < 0.6 and MR ≥ 0.6.
               
                  Conclusions
                  MR recurrence after TMVR in patients with FMR is associated with advanced LV dilation and MV tenting before TMVR, which provides clinical implications for a point of no return beyond which progressive LV dilation with MV geometry dilation and tethering cannot be effectively prevented by TMVR. In contrast, no significant determinants of MR recurrence and progressive MV annular dilation could be identified in patients with OMR.",multimedia
10.1016/j.bspc.2021.102605,Journal,Biomedical Signal Processing and Control,scopus,2021-07-01,sciencedirect,Framework for Real-Time Detection and Identification of possible patients of COVID-19 at public places,https://api.elsevier.com/content/abstract/scopus_id/85103689201,"The novel Corona Virus (COVID-19) has become the reason for the world to declare it as a global pandemic, which has already taken many lives from all around the world. This pandemic has become a disaster since the spreading rate from person to person is incredibly high and many techniques have come forth to aid in stopping the infection. Although various types of methods have been put into implementation, the search and suggestions of new approaches to reduce the increasing rate of infection will never come to an end until a vaccine terminates this pandemic. This study focuses on proposing a new framework that is based on Deep Learning algorithms for recognizing the COVID-19 cases, mostly in public places. The algorithms include Background Subtraction for extracting the foreground of thermal images from thermal videos generated by Thermal Cameras through the Thermal Imaging process and the Convolutional Neural Network for detecting people infected with the virus. This automated prototype works in a real-time scenario that helps identify people with the disease and will try to trace it while separating them from having any other contact. This proposal intends to achieve a satisfying growth in determining the real cases of COVID-19 and minimize the spreading rate of this virus to the max, ultimately avoiding more deaths.",multimedia
10.1016/j.compenvurbsys.2021.101628,Journal,"Computers, Environment and Urban Systems",scopus,2021-07-01,sciencedirect,Flood depth mapping in street photos with image processing and deep neural networks,https://api.elsevier.com/content/abstract/scopus_id/85103680478,"Many parts of the world experience severe episodes of flooding every year. In addition to the high cost of mitigation and damage to property, floods make roads impassable and hamper community evacuation, movement of goods and services, and rescue missions. Knowing the depth of floodwater is critical to the success of response and recovery operations that follow. However, flood mapping especially in urban areas using traditional methods such as remote sensing and digital elevation models (DEMs) yields large errors due to reshaped surface topography and microtopographic variations combined with vegetation bias. This paper presents a deep neural network approach to detect submerged stop signs in photos taken from flooded roads and intersections, coupled with Canny edge detection and probabilistic Hough transform to calculate pole length and estimate floodwater depth. Additionally, a tilt correction technique is implemented to address the problem of sideways tilt in visual analysis of submerged stop signs. An in-house dataset, named BluPix 2020.1 consisting of paired web-mined photos of submerged stop signs across 10 FEMA regions (for U.S. locations) and Canada is used to evaluate the models. Overall, pole length is estimated with an RMSE of 17.43 and 8.61 in. in pre- and post-flood photos, respectively, leading to a mean absolute error of 12.63 in. in floodwater depth estimation. Findings of this research are sought to equip jurisdictions, local governments, and citizens in flood-prone regions with a simple, reliable, and scalable solution that can provide (near-) real time estimation of floodwater depth in their surroundings.",multimedia
10.1016/j.neunet.2021.02.008,Journal,Neural Networks,scopus,2021-07-01,sciencedirect,Residual Neural Network precisely quantifies dysarthria severity-level based on short-duration speech segments,https://api.elsevier.com/content/abstract/scopus_id/85102061061,"Recently, we have witnessed Deep Learning methodologies gaining significant attention for severity-based classification of dysarthric speech. Detecting dysarthria, quantifying its severity, are of paramount importance in various real-life applications, such as the assessment of patients’ progression in treatments, which includes an adequate planning of their therapy and the improvement of speech-based interactive systems in order to handle pathologically-affected voices automatically. Notably, current speech-powered tools often deal with short-duration speech segments and, consequently, are less efficient in dealing with impaired speech, even by using Convolutional Neural Networks (CNNs). Thus, detecting dysarthria severity-level based on short speech segments might help in improving the performance and applicability of those systems. To achieve this goal, we propose a novel Residual Network (ResNet)-based technique which receives short-duration speech segments as input. Statistically meaningful objective analysis of our experiments, reported over standard Universal Access corpus, exhibits average values of 21.35% and 22.48% improvement, compared to the baseline CNN, in terms of classification accuracy and F1-score, respectively. For additional comparisons, tests with Gaussian Mixture Models and Light CNNs were also performed. Overall, the values of 98.90% and 98.00% for classification accuracy and F1-score, respectively, were obtained with the proposed ResNet approach, confirming its efficacy and reassuring its practical applicability.",multimedia
10.1016/j.csl.2020.101180,Journal,Computer Speech and Language,scopus,2021-07-01,sciencedirect,Identification of related languages from spoken data: Moving from off-line to on-line scenario,https://api.elsevier.com/content/abstract/scopus_id/85098984452,"The accelerating flow of information we encounter around the world today makes many companies deploy speech recognition systems that, to an ever-growing extent, process data on-line rather than off-line. These systems, e.g., for real-time 24/7 broadcast transcription, often work with input-stream data containing utterances in more than one language. This multilingual data can correctly be transcribed in real-time only if the language used is identified with just a small latency for each input frame. For this purpose, a novel approach to on-line spoken language identification is proposed in this work. Its development is documented within a series of consecutive experiments starting in the off-line mode for 11 Slavic languages, going through artificially prepared multilingual data for the on-line scenario, and ending with real bilingual TV programs containing utterances in mutually similar Czech and Slovak. The resulting scheme that we propose operates frame-by-frame; it takes in a multilingual stream of speech frames and outputs a stream of the corresponding language labels. It utilizes a weighted finite-state transducer as a decoder, which smooths the output from a language classifier fed by multilingual and augmented bottleneck features. An essential factor from the accuracy point of view is that these features, as well as the classifier itself, are based on deep neural network architectures that allow the modeling of long-term time dependencies. The obtained results show that our scheme allows us to determine the language spoken in real-world bilingual TV shows with an average latency of around 2.5 seconds and with an increase in word error rate by a mere 2.9% over the reference 18.1% value yielded by using manually prepared language labels.",multimedia
10.1016/j.hpb.2020.11.005,Journal,HPB,scopus,2021-07-01,sciencedirect,"Prediction of remnant liver volume using 3D simulation software in patients undergoing R1vasc parenchyma-sparing hepatectomy for multiple bilobar colorectal liver metastases: reliability, clinical impact, and learning curve",https://api.elsevier.com/content/abstract/scopus_id/85098644721,"Background
                  Assessment of the future liver remnant (FLR) is routinely performed before major hepatectomy. In R1-vascular one-stage hepatectomy (R1vasc-OSH), given the multiplanar dissection paths, the FLR is not easily predictable. Preoperative 3D-virtual casts may help. We evaluated the predictability of the FLR using the 3D-virtual cast in the R1vasc-OSH for multiple bilobar colorectal liver metastases (CLM).
               
                  Methods
                  Thirty consecutive patients with multiple bilobar CLMs scheduled for R1vasc-OSH were included. Predicted and real-FLRs were compared. Propensity score-matched analysis was used to determine the impact of 3D-virtual cast on postoperative complications.
               
                  Results
                  Median number of CLM and resection areas were 12 (4–33) and 3 (1–8). Median predicted-FLR was 899 ml (558–1157) and 60% (42–85), while for the real-FLR 915 ml (566–1777) and 63% (43–87). Median discrepancy between predicted and real-FLR was −0.6% (p = 0.504), indicating a slight tendency to underestimate the FLR. The difference was more evident in more than 12 CLMs (p = 0.013). A discrepancy was not evident according to the number of resection areas (p = 0.316). No mortality occurred. Patients in virtual-group had lower major complications compared to nonvirtual-group (0% vs 18%, p-value 0.014).
               
                  Conclusion
                  FLR estimation based on 3D-analysis is feasible, provides a safe surgery and represents a promising method in planning R1vasc-OSH for patients with multiple bilobar CLMs.",multimedia
10.1016/j.comnet.2021.108017,Journal,Computer Networks,scopus,2021-06-19,sciencedirect,Unsupervised packet-based anomaly detection in virtual networks,https://api.elsevier.com/content/abstract/scopus_id/85103789016,"The enormous number of network packets transferred in modern networks together with the high speed of transmissions hamper the implementation of successful IT security mechanisms. In addition, virtual networks create highly dynamic and flexible environments which differ widely from well-known infrastructures of the past decade. Network forensic investigation that aims at the detection of covert channels, malware usage or anomaly detection is faced with new problems and is thus a time-consuming, error-prone and complex process. Machine learning provides advanced techniques to perform this work faster, more precise and, simultaneously, with fewer errors. Depending on the learning technique, algorithms work nearly without any interaction to detect relevant events in the transferred network packets. Current algorithms work well in static environments, but the highly dynamic environments of virtual networks create additional events which might confuse anomaly detection algorithms. This paper analyzes highly flexible networks and their inherent on-demand changes like the migration of virtual machines, SDN-programmability or user customization and the resulting effect on the detection rate of anomalies in the environment. Our research shows the need for adapted pre-processing of the network data and improved cooperation between IT security and IT administration departments.",multimedia
10.1016/j.treng.2021.100068,Journal,Transportation Engineering,scopus,2021-06-01,sciencedirect,Real-time traffic quantization using a mini edge artificial intelligence platform,https://api.elsevier.com/content/abstract/scopus_id/85111397458,"Traffic analysis is dependent on reliable and accurate datasets that quantify the vehicle composition, speed and traffic density over a long period of time. The utilisation of big data is required if equitable and efficient transportation networks are to be realised for smart, interconnected cities of the future. The rapid and widespread adoption of digital twins, IoT (Internet of Things), artificial intelligence and mini edge computing technologies serve as the catalyst to rapidly develop and deploy smart systems for real-time data acquisition of traffic in and around urban and metropolitan areas. This paper presents a proof of concept of a mini edge computing platform for real-time edge processing, which serves as a digital twin of a multi-lane freeway located in Pretoria, South Africa. Video data acquired from an Unmanned Aerial Vehicle (UAV) is processed using a neural network architecture designed for real-time object detection tracking of vehicles. The implementation successfully counted vehicles (cars and trucks) together with an estimation of the speed of each detected vehicle. These results compare favourably to the ground truth data with vehicle counting accuracies of 5% realised. Detection of sparse motorcycles and pedestrians were less than optimal. This proof of concept can be easily scaled and deployed over a wide geographic area. Integration of these cyber-physical assets can be incorporated into existing video monitoring systems or fused with optical sensors as a single data acquisition system.",multimedia
10.1016/j.addma.2021.101961,Journal,Additive Manufacturing,scopus,2021-06-01,sciencedirect,Deep representation learning for process variation management in laser powder bed fusion,https://api.elsevier.com/content/abstract/scopus_id/85105695571,"Laser Powder Bed Fusion (LPBF) is an additive manufacturing process where laser power is applied to fuse the spread powder and fabricate industrial parts in a layer by layer fashion. Despite its great promise in fabrication flexibility, print quality has long been a major barrier for its widespread implementation. Traditional offline post-manufacturing inspections to detect the defects in finished products are expensive and time-consuming and thus cannot be applied in real-time monitoring and control. In-situ monitoring methods by relying on the in-process sensor data, on the other hand, can provide viable alternatives to aid with the online detection of anomalies during the process. Given the crucial importance of melt pool characteristics to the quality of final products, this paper provides a framework to process the melt pool images by a configuration of Convolutional Auto-Encoder (CAE) neural networks. The network’s corresponding bottleneck layer learns a deep yet low-dimensional representation from melt pools while preserving the spatial correlation and complex features intrinsic in the images. As opposed to the manual annotation of data by X-ray imaging or destructive tests, an agglomerative clustering algorithm is applied to these representations to automatically extract the anomalies and annotate the data accordingly. A control charting scheme based on Hotelling’s T
                     2 and S
                     2 statistics is then developed to monitor the process’s stability by keeping track of the learned representations and residuals obtained from the reconstruction of original images. Testing the proposed methodology on the collected data from an experimental build demonstrates that the method can extract a set of complex features that are inextricable otherwise by using hand-crafted feature engineering methods. Moreover, through extensive numerical studies, it is shown that the proposed feature extraction and statistical process monitoring scheme is capable of detecting the anomalies in real-time with accuracy and F
                     1 score of about 95% and 82%, respectively.",multimedia
10.1016/j.cmpb.2021.106112,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-06-01,sciencedirect,A Novel Marker Detection System for People with Visual Impairment Using the Improved Tiny-YOLOv3 Model,https://api.elsevier.com/content/abstract/scopus_id/85105690340,"Background and Objective
                  Daily activities such as shopping and navigating indoors are challenging problems for people with visual impairment. Researchers tried to find different solutions to help people with visual impairment navigate indoors and outdoors.
               
                  Methods
                  We applied deep learning to help visually impaired people navigate indoors using markers. We propose a system to help them detect markers and navigate indoors using an improved Tiny-YOLOv3 model. A dataset was created by collecting marker images from recorded videos and augmenting them using image processing techniques such as rotation transformation, brightness, and blur processing. After training and validating this model, the performance was tested on a testing dataset and on real videos.
               
                  Results
                  The contributions of this paper are: (1) We developed a navigation system to help people with visual impairment navigate indoors using markers; (2) We implemented and tested a deep learning model to detect Aruco markers in different challenging situations using Tiny-YOLOv3; (3) We implemented and compared several modified versions of the original model to improve detection accuracy. The modified Tiny-YOLOv3 model achieved an accuracy of 99.31% in challenging conditions and the original model achieved an accuracy of 96.11 %.
               
                  Conclusion
                  The training and testing results show that the improved Tiny-YOLOv3 models are superior to the original model.",multimedia
10.1016/j.compag.2021.106156,Journal,Computers and Electronics in Agriculture,scopus,2021-06-01,sciencedirect,A system for automatic rice disease detection from rice paddy images serviced via a Chatbot,https://api.elsevier.com/content/abstract/scopus_id/85104652334,"A LINE Bot System to diagnose rice diseases from actual paddy field images was developed and presented in this paper. It was easy-to-use and automatic system designed to help rice farmers improve the rice yield and quality. The targeted images were taken from the actual paddy environment without special sample preparation. We used a deep learning neural networks technique to detect rice diseases from the images. We developed an object detection model training and refinement process to improve the performance of our previous research on rice leave diseases detection. The process was based on analyzing the model’s predictive results and could be repeatedly used to improve the quality of the database in the next training of the model. The deployment model for our LINE Bot system was created from the selected best performance technique in our previous paper, YOLOv3, trained by refined training data set. The performance of the deployment model was measured on 5 target classes and found that the Average True Positive Point improved from 91.1% in the previous paper to 95.6% in this study. Therefore, we used this deployment model for Rice Disease LINE Bot system. Our system worked automatically real-time to suggest primary diagnosis results to the users in the LINE group, which included rice farmers and rice disease specialists. They could communicate freely via chat. In the real LINE Bot deployment, the model’s performance was measured by our own defined measurement Average True Positive Point and was found to be an average of 78.86%. The system was fast and took only 2–3 s for detection process in our system server.",multimedia
10.1016/j.sysarc.2021.102139,Journal,Journal of Systems Architecture,scopus,2021-06-01,sciencedirect,Tracking and analysing social interactions in dairy cattle with real-time locating system and machine learning,https://api.elsevier.com/content/abstract/scopus_id/85104583225,"There is a need for reliable and efficient methods for monitoring the activity and social behaviour in cows, in order to optimise management in modern dairy farms. This research presents an embedded system that could track individual cows using Ultra-wideband technology. At the same time, social interactions between individuals around the feeding area were analysed with a computer vision module. Detections of the dairy cows’ negative and positive interactions were performed on foreground video stream using a Long-term Recurrent Convolution Networks model. The sensor fusion system was implemented and tested on seven dairy cows during 45 days in an experimental dairy farm. The system performance was evaluated at the feeding area. The real-time locating system based on Ultra-wideband technology reached an accuracy with mean error 0.39 m and standard deviation 0.62 m. The accuracy of detecting the affiliative and agonistic social interactions reached 93.2%. This study demonstrates a potential system for monitoring social interactions between dairy cows.",multimedia
10.1016/j.micpro.2021.103988,Journal,Microprocessors and Microsystems,scopus,2021-06-01,sciencedirect,Computer simulation of urban garden landscape design based on FPGA and neural network,https://api.elsevier.com/content/abstract/scopus_id/85099498199,"Digital Landscape is a combination of the system and the computer software and hardware system of a high simulation model. The author analyzes the application of computer simulation in landscape design and value analysis of a city garden. In the computer-aided design, the importance of digitizing information in the landscape design process, mainly human and the interaction of computer, is reflected in the digital model's creation and multimedia performance, becoming more and more evident. To form a two-dimensional or three-dimensional spatial data, to realize real-time, statistical Analysis, using the human living environment, multi-dimensional, efficient, and humane, and environmental landscape plan to more rational and practical, used the computer simulation techniques. Effective use of urban rainwater, to reduce the flooding of urban areas, it is possible to alleviate the water crisis, the organic combination of rainwater can be used in the course of the construction of the urban landscape as well as make-up landscape, visual beautification has optimized the ecosystem, and from many rainwater utilization functions; These functions in landscape design, rainwater garden, It can be realized the rooftop garden, and the city's green. The construction and sustainable economy and the promotion of the ecological park's social development will positively sign. Suitable for rainwater regulation, water (recovery) is stored—Computer-Aided Design (CAD) green space. Technical measures save of suggestions for practical application of the square: innovation and new of space design, new artificial wetland system, and garden rainwater in the application of the regulation (population) storage system design of the water-saving of these to the sustainable development of such new square of rainwater adjustment (group) storage system design and urban landscape environment. It is useful for the application of technology.",multimedia
10.1016/j.bpg.2020.101722,Journal,Best Practice and Research: Clinical Gastroenterology,scopus,2021-06-01,sciencedirect,Striving for quality improvement: can artificial intelligence help?,https://api.elsevier.com/content/abstract/scopus_id/85099293210,"Artificial intelligence (AI) is of keen interest for global health development as potential support for current human shortcomings. Gastrointestinal (GI) endoscopy is an excellent substrate for AI, since it holds the genuine potential to improve quality in GI endoscopy and overall patient care by improving detection and diagnosis guiding the endoscopists in performing endoscopy to the highest quality standards. The possibility of large data acquisitioning to refine algorithms makes implementation of AI into daily practice a potential reality. With the start of a new era adopting deep learning, large amounts of data can easily be processed, resulting in better diagnostic performances. In the upper gastrointestinal tract, research currently focusses on the detection and characterization of neoplasia, including Barrett’s, squamous cell and gastric carcinoma, with an increasing amount of AI studies demonstrating the potential and benefit of AI–augmented endoscopy. Deep learning applied to small bowel video capsule endoscopy also appears to enhance pathology detection and reduce capsule reading time. In the colon, multiple prospective trials including five randomized trials, showed a consistent improvement in polyp and adenoma detection rates, one of the main quality indicators in endoscopy. There are however potential additional roles for AI to assist in quality improvement of endoscopic procedures, training and therapeutic decision making. Further large-scale, multicenter validation trials are required before AI–augmented diagnostic gastrointestinal endoscopy can be integrated into our routine clinical practice.",multimedia
10.1016/j.knosys.2021.106918,Journal,Knowledge-Based Systems,scopus,2021-05-23,sciencedirect,Intelligent human action recognition using an ensemble model of evolving deep networks with swarm-based optimization,https://api.elsevier.com/content/abstract/scopus_id/85102146279,"Automatic interpretation of human actions from realistic videos attracts increasing research attention owing to its growing demand in real-world deployments such as biometrics, intelligent robotics, and surveillance. In this research, we propose an ensemble model of evolving deep networks comprising Convolutional Neural Networks (CNNs) and bidirectional Long Short-Term Memory (BLSTM) networks for human action recognition. A swarm intelligence (SI)-based algorithm is also proposed for identifying the optimal hyper-parameters of the deep networks. The SI algorithm plays a crucial role for determining the BLSTM network and learning configurations such as the learning and dropout rates and the number of hidden neurons, in order to establish effective deep features that accurately represent the temporal dynamics of human actions. The proposed SI algorithm incorporates hybrid crossover operators implemented by sine, cosine, and tanh functions for multiple elite offspring signal generation, as well as geometric search coefficients extracted from a three-dimensional super-ellipse surface. Moreover, it employs a versatile search process led by the yielded promising offspring solutions to overcome stagnation. Diverse CNN–BLSTM networks with distinctive hyper-parameter settings are devised. An ensemble model is subsequently constructed by aggregating a set of three optimized CNN–BLSTM​ networks based on the average prediction probabilities. Evaluated using several publicly available human action data sets, our evolving ensemble deep networks illustrate statistically significant superiority over those with default and optimal settings identified by other search methods. The proposed SI algorithm also shows great superiority over several other methods for solving diverse high-dimensional unimodal and multimodal optimization functions with artificial landscapes.",multimedia
10.1016/j.ijcard.2021.01.035,Journal,International Journal of Cardiology,scopus,2021-05-15,sciencedirect,Application of cardiac computed tomographic imaging and fluoroscopy fusion for guiding left atrial appendage occlusion,https://api.elsevier.com/content/abstract/scopus_id/85101317960,"Objective
                  Evaluate the value of 3D computed tomography (CT) and CT-integrating fluoroscopy for procedural guidance during WATCHMAN implantation.
               
                  Methods
                  This observational study compared the clinical and procedural parameters for LAAO with and without fusion imaging. Forty-one pairs of patients—matched by procedure month and with or without the use of the image fusion system—were enrolled. Using the image fusion Advanced Workstation 4.6 software (GE Healthcare), we identified the 3D cardiac anatomy and safe zones for septal punch. The LAA orifice anatomy outlines were then projected onto the real-time fluoroscopy image during the procedure to guide all the steps of LAAO.
               
                  Results
                  The use of image fusion significantly reduced the procedural time, compared to the time required for the control group (44.73 ± 20.03 min vs. 63.73 ± 26.10 min, respectively; P < 0.001). When compared to the standard procedure, the use of image fusion significantly reduced both the total radiation dose (448.80 ± 556.35 mGy vs. 798.42 ± 616.34 mGy; P = 0.004) and dose area product (DAP) (38.03 ± 47.15 Gy∙cm2 vs. 67.66 ± 52.23 Gy∙cm2, P = 0.004). Corresponding to the radiation dose, the contrast volume was also reduced (67.32 ± 18.65 vs. 90.98 ± 25.03 ml; P = 0.0004). During short-term follow-up at 6 months, there was only one femoral hematoma and incomplete LAA sealing (>3 mm) in either group.
               
                  Conclusions
                  Automated real-time integration of cardiac CT and fluoroscopy is feasible, safe, and applicable in LAAO. It may significantly reduce the radiation exposure, procedure duration, and volume of contrast media. Following these results, the potential of merging reconstructed 3D CT scans with real-time coronary angiography should be fully exploited in LAAO.",multimedia
10.1016/j.eswa.2020.114533,Journal,Expert Systems with Applications,scopus,2021-05-15,sciencedirect,Dynamic learning framework for epileptic seizure prediction using sparsity based EEG Reconstruction with Optimized CNN classifier,https://api.elsevier.com/content/abstract/scopus_id/85098953605,"The World Health Organization (WHO) recently stated that epilepsy affects nearly 65 million people of the world population. Early forecast of the oncoming seizures is of paramount importance in saving the life of epileptic patients. This paper demonstrates a phase transition-based seizure prediction approach from multi-channel scalp electroencephalogram (EEG) recordings. The primary focus of this work is to discriminate the seizure and seizure-free EEG signals by learning the dynamics of preictal, interictal and ictal period. We propose an adaptive optimization approach using non-linear conjugate gradient technique in conjunction with Sparsity based EEG Reconstruction (SER) and three-dimensional Optimized Convolutional Neural Network (3D OCNN) classifier, based on Fletcher Reeves (FR) algorithm. Sparsity based artifact removal approach along with a 3D OCNN classifier, classifies the various states of seizures. FR algorithm is deployed with the deep neural network architecture to accelerate the convergence rate and to reduce the complexity of the proposed non-linear model. The Principle Component Analysis (PCA) algorithm replacing the Singular Value Decomposition (SVD) in the K-SVD algorithm, further reduces the time and complexity of the pre-processing stage. We further propose a Phase Transition based Kullback-Leibler divergence (PTB-KL) predictor for obtaining the Optimal Seizure Prediction Horizon (OSPH). The proposed model is evaluated using three diverse databases such as CHB-MIT, NINC and SRM respectively. Empirical results on the three EEG databases of 300 recordings outperforms the state-of-art approaches with an accuracy score of 0.98, sensitivity score of 0.99 and False Prediction Rate (FPR) of 0.07 FP/h. Statistical assessment of the proposed predictor gains an OSPH of about 1.1 h prior to the seizure onset. Experimental results prove that the phase transition-based seizure prediction approach is a promising one for accurate real-time prediction of epilepsy using scalp EEG data.",multimedia
10.1016/j.comnet.2021.107955,Journal,Computer Networks,scopus,2021-05-08,sciencedirect,Elastic Computing Resource Virtualization Method for a Service-centric Industrial Internet of Things,https://api.elsevier.com/content/abstract/scopus_id/85102477910,"The industrial Internet of Things (IIoT) enables the interconnection of machines, devices, resources, and computing technologies to improve the reliability of manufacturing services. The role of Software-Defined Networks (SDNs) and Network Function Virtualization (NFV) are exploited in the IIoT environment to ensure effective management and computing resource utilization. Based on the SDN and NFV paradigms, this article introduces a novel elastic computing resource virtualization (ECRV) method to improve the flexibility of resource management in the IIoT. The need for virtualization is obtained by identifying the control and process platforms used in industrial task management. Support vector machine-based classification learning is used to achieve balanced identification, and prevents unnecessary distribution of limited resources, Support vector machine helps to retain flexibility in task control processes that use available industrial resources. By separating the process and control platforms, service dissemination is improved and backlogs in task processing are decreased. The proposed method could provide flexible virtualization and reduces the service response time and task failure.",multimedia
10.1016/j.cjca.2020.12.009,Journal,Canadian Journal of Cardiology,scopus,2021-05-01,sciencedirect,Digital Health Approaches for the Assessment and Optimisation of Hypertension Care Provision,https://api.elsevier.com/content/abstract/scopus_id/85104335482,"Although many aspects of our lives have been transformed by digital innovation, widespread adoption of digital health advancements within the health care sector in general, and for hypertension care specifically, has been limited. However, it is likely that, over the next decade, material increases in the uptake of digital health innovations for hypertension care delivery will be seen. In this narrative review, we summarise those innovations thought to have the greatest chance for impact in the next decade. These include provision of virtual care combined with home blood pressure (BP) telemonitoring, use of digital registries and protocolised care, leveraging continuous BP measurement to collect vast amounts of individual and population-based BP data, and adoption of digital therapeutics to provide low-cost scalable interventions for patients with or at risk for hypertension. Of these, home BP telemonitoring is likely the most ready for implementation, but it needs to be done in a way that enables efficient guideline-concordant care in a cost-effective manner. In addition, efforts must be focused on implementing digital health solutions in a manner that addresses the major challenges to digital adoption. This entails ensuring that innovations are accessible, usable, secure, validated, evidence based, cost-effective, and integrated into the electronic systems that are already used by patients or providers. Increasing the use of broader digital innovations such as artificial/augmented intelligence, data analytics, and interactive voice response is also critically important. The digital revolution holds substantial promise, but success will depend on the ability of collaborative stakeholders to adopt and implement innovative, usable solutions.",multimedia
10.1016/j.evopsy.2021.03.006,Journal,Evolution Psychiatrique,scopus,2021-05-01,sciencedirect,"From Digital Identity to Connected Personality, From Augmented Diagnostician to Virtual Caregiver: What Are the Challenges for the Psychology and the Psychiatry of the Future?",https://api.elsevier.com/content/abstract/scopus_id/85104125089,"Objectifs
                  Qui sommes-nous devenus, citoyens, patients, praticiens ? En quoi les moyens de communications et l’informatisation de notre société modifient-ils, intègrent-ils nos identités ? L’intelligence artificielle comprendrait-elle bientôt plus justement l’être humain dont elle s’émanciperait ?
               
                  Matériel et méthodes
                  Cheminons à partir de la lexicologie pour tenter de saisir, via le point de vue de la philosophie, l’identité contemporaine vers la notion d’« identité numérique » dont les incidents psychologiques normaux ou pathologiques entraînent ce que nous définissons « la personnalité numérique ». Puis, posant les bases d’une psychologie de l’identité contemporaine, nous envisageons comment « la psychologie » et « la psychiatrie » actuelles considèrent « la personnalité » du patient et, en retour, comment elles se définissent du point du vue du « praticien en ligne » ou du « chercheur connecté ».
               
                  Résultats
                  En échange de son utilisation « gratuite », l’action de l’internaute sur le Web 2.0 produit du contenu et alimente des bases de données, déclaratives ou non. En perte d’intimité au fur et à mesure que « ses » données ne lui appartiennent plus, l’identité du citoyen se décompose en fonctions des supports digitaux : site de rencontre amical, plateforme de liens amoureux, blog concernant un loisir ou un voyage, etc. Par le même mouvement, l’identité numérique se compose en autre-soi possédant une part d’intelligence artificielle pourvoyeuse de capacité d’existence propre. Plutôt que deux entités parallèlement différentiables, réelle ou augmentée, naît une identité hybride « réalistiquo-virtuelle ». Quelles conséquences normales ou pathologiques chez l’être humain ? Les tendances sociétales post-modernes issues du digital ou y trouvant expression peuvent entraîner, chez un individu donné, une exacerbation des traits de personnalité préalablement existants, voire des symptômes. Parallèlement, il arrive que les moyens de communication moderne deviennent une aide pour expérimenter le monde, majorer l’estime de soi, rêver favorablement ses phantasmes, se confier plus facilement à des « inconnu(e)s », etc. Mais dans tous les cas, chez le sujet souffrant, ou ne souffrant pas, préalablement à sa surexposition, de maladie neuropsychiatrique ou de trouble psychopathologique, il s’avère aujourd’hui scientifiquement documenté que la confrontation numérique accrue induit des atteintes neuropsychiques massives (affaiblissement de la mémoire de travail, des capacités d’attention et de concentration, des aptitudes à construire des opérations cognitives élaborées, etc.). Sur le plan psychopathologique, plutôt que la terminologie de « trouble de l’identité » ou une notion de « co-identités », le terme d’« identité trouble » nous paraît le mieux rendre compte de cette mutation du « moi » où la frontière entre réalité et virtualités s’amenuise : la dissociation prévaut. L’homme post-moderne et ses objets connectés ne font plus qu’un, mais cet « uniforme » apparaît constitué d’un patchwork de confettis identificatoires plus ou moins accolés, sans réelle harmonisation d’ensemble. La personnalité commune se marque d’hyperexpressivité et d’hyperémotivité, au détriment de la possibilité de contrôle des affects et du développement des capacités d’introspection. Contre le risque du vide, tend à se développer une contra-phobie par l’ordiphone, par l’objet lui-même, par la possibilité de contacter en permanence ses proches si nécessaire, et en retour rester toujours « disponible », ce qui alimente une forme d’égocentrisme addictogène. Résulte de ses évolutions, globalement dans la société, un affaiblissement des capacités langagières, et ainsi de réflexion, y compris pour l’espace clinique et scientifique.
               
                  Discussion
                  Pour les domaines de la psychologie et de la psychiatrie, s’associent actuellement deux évolutions : une velléité d’« objectivité-scientificité » et une numérisation de la relation patient–soignant. Du côté de la « science », la médecine objective « factuelle » s’intéresse de plus en plus à la pathologie aux dépens du sujet en souffrance, confondant signe et symptôme, glissant jusqu’à un niveau moléculaire, très en-deçà du patient, vers une psychiatrie ou une psychologie « post-clinique ». Qu’on veuille la promouvoir ou l’anéantir, du côté du clinicien ou du chercheur, la « subjectivité » est devenue un signifiant à la mode pour le domaine de la santé psychique. Ce retour actuel du « subjectif » prospère sur une sorte de peur de la subjectivité depuis la fin de la seconde guerre mondiale qui avait entraîné la nosographie américaine vers les « objectifs » des DSM (Manuel Diagnostique et Statistique des Troubles Psychiques publié par l’American Psychiatric Association depuis 1952). Mais plutôt qu’une connaissance validable, et/ou invariable concernant tel ou tel trouble psychique, le changement, la relativité des entités nosographiques d’une version à l’autre du manuel traduit, en miroir, la subjectivité d’une époque, ce que nous appelons « subjectivité sociétale ». Autant qu’elle témoigne de notre temps, la révolution bio-numérique s’imposera probablement dans une future édition de la nosographie : la validité diagnostique devrait se majorer par la définition précise de marqueurs biologiques et/ou neuroradiologiques, si ceux-ci participent à construire une théorie étiopathogénique des phénomènes psychiques observés. Cette orientation reste toutefois balbutiante : outre l’infime nombre de biomarqueurs identifiés, et surtout utilisables en pratique quotidienne, leurs liens de causalité ou de conséquentialité avec les symptômes ou le processus morbide restent le plus souvent incertains autant qu’ils sont fort divers et interreliés. Le chercheur en neurosciences vise à mesurer et analyser une multitude de données, intégrant en particulier les mimiques et les émotions authentifiables par caméra thermique, les mouvements des segments des corps et dynamiques des regards enregistrables par des capteurs, la standardisation des voix et des discours pour analyse par logiciel informatique de la prosodie, des signifiants employés, de la syntaxe… le tout s’intégrant dans un phénotypage digital de la souffrance. Pourra-t-on bientôt parler, en remplacement du psychologue ou du psychiatre, de « diagnosticien augmenté » ?
               
                  Conclusion
                  Apparaît-il actuellement hasardeux de faire confiance à un thérapeute entièrement virtuel… expérience déjà lancée il y a plus de 50 ans ! L’être humain est un « être de sens », or, selon le modèle de la clinique traumatique, le surgissement du tout-numérique peut entraîner un « effondrement du sens » générateur d’une tendance à la dissociation de la personnalité. Accordant le rétablissement des liens entre émotions, affects, comportements et cognitions, le langage parlé atténue puis fait disparaître la dissociation. Guidée par le praticien, cette parole thérapeutique est parfois qualifiée de « maïeutique », du nom de la science de l’accouchement : elle construit synchroniquement à son essence la pensée, et une prise de conscience de celle-ci, plutôt qu’elle n’en rendrait compte secondairement. Il s’agit d’une réinterprétation causale d’un sens compris ou plutôt « attribué » singulièrement par le sujet, après-coup, le passé revisité dans l’instant noue une synthèse, le hasard est transformé en destin. Le sujet qui parle réélabore son histoire vers une reconstruction sémantique, une densification de ses réseaux de signification. Reconquérant son être par la création d’un discours, de méandres véridiques comme fictionnels, la narration, voire la poétisation, offre l’illusion ponctuelle d’une meilleure cohérence, toujours relative, illusoire La parole thérapeutique et le discours sur celle-ci restent en devenir, inachevés, incertains autant que vivants, caractérisant une « post-psychothérapie », c’est-à-dire une psychothérapie et non pas une technique rééducative qui se trouverait figée dans des objectifs connus à l’avance. Les notions de faits et de réalité sont ici secondaires, non pas au sens de l’objectif, ni même du subjectif, mais du second degré, puis d’autres degrés successifs ou imbriqués portant l’effort intellectuel. Vers l’apaisement, si nous voulions amener la réflexion à son paroxysme, nous pourrions avancer qu’il suffirait de donner « n’importe quel sens », d’en choisir un quel qu’il soit, du côté du patient ou du praticien, sans qu’il ne soit nécessairement le même, témoignage d’une construction intersubjective formellement invalide.
               
                  Objectives
                  Who have we become, as citizens, patients, practitioners? How do the means of communication and the computerization of our society, its digitization, modify and integrate our identities? Can we assume that artificial intelligence will soon have a more accurate understanding of the human being from whom it will have emancipated itself?
               
                  Materials and methods
                  We move from lexicology to try to grasp, from the point of view of philosophy, a contemporary identity that is moving towards the notion of a “digital identity” whose normal or pathological psychological incidents lead to what we define as “the digital personality.” Then, laying the foundations for a contemporary psychology of identity, we consider how current “psychology” and “psychiatry” view the patient's “personality” and, in turn, how they define themselves from the point of view of “the patient,” or, inversely, from the point of view of the “online practitioner” or “connected researcher.”
               
                  Results
                  In exchange for its “free” use, the Internet user's action on Web 2.0 produces content and feeds databases, whether this is declared or not. Users’ privacy is lost, as “their” data no longer belongs to them; and citizens’ identity is broken down into digital media functions: a site for meeting friends, a dating platform, a blog about hobbies or travel, etc. At the same time, digital identity is made up of an other-self, including a part of artificial intelligence that provides capacity for its own existence. Rather than two parallel, differentiable entities, real or augmented, a “realistic-virtual” hybrid identity is born. What are the normal or pathological consequences for humans? Postmodern societal trends emerging from or finding expression in the digital can lead to an exacerbation of previously existing personality traits, or even symptoms, in a given individual. At the same time, it happens that the modern means of communication become an aid to experience the world, to increase self-esteem, to dream favorably about one's fantasies, to confide more easily in “strangers,” etc. But in all cases, in the subject suffering, or not suffering, prior to his overexposure, from a neuropsychiatric disease or a psychopathological disorder, it now turns out to be scientifically documented that the increased numerical confrontation induces massive neuropsychic damage (weakening working memory, attention and concentration skills, skills in constructing sophisticated cognitive operations, etc.). On the psychopathological level, rather than the terminology of “identity disorder” or a notion of “co-identities,” the term “identity elusive"" seems to us to best account for this mutation of the “me” where the border between reality and virtualities is shrinking: dissociation prevails. The postmodern human and its connected objects become one, but this “uniformity” appears to be made up of a patchwork of identifying confetti more or less joined together, without a real overall harmonization. The common personality is marked by hyperexpressiveness and hyperemotivity, to the detriment of the possibility of controlling affects and the development of introspective capacities. Against the risk of a vacuum, a contra-phobia tends to develop through the smartphone, by the object itself, by the possibility of constantly contacting relatives if necessary, and in return always remaining “available,” which fuels a form of addicting self-centeredness. The result of these developments, for society in general, is a weakening of language skills, and thus of reflection, including in the clinical and scientific space.
               
                  Discussion
                  For the areas of psychology and psychiatry, two developments are currently associated: a desire for “objectivity-scientificity” and a digitization of the patient–caregiver relationship. On the side of “science,” objective “factual” medicine is increasingly interested in pathology at the expense of the suffering subject, confusing sign and symptom, sliding down to a molecular level, far below the patient, towards psychiatry or postclinical psychology. Whether we want to promote it or destroy it, on the side of the clinician or the researcher, “subjectivity” has become a fashionable signifier in the field of mental health. This current return of the “subjective” thrives on a kind of fear of subjectivity present since the end of World War II, which had led American nosography towards the “objectives” of the DSM (Diagnostic and Statistical Manual of Mental Disorders, published by the American Psychiatric Association since 1952). But rather than a verifiable and/or invariable knowledge concerning a particular psychic disorder, the changes and the relativity of nosographic entities from one version of the manual to another provides us with a mirror image of the subjectivity of an era, which we propose to call “societal subjectivity.” As much as it is a product of our time, the bio-digital revolution will probably impose itself in a future edition of nosography: the diagnostic validity should be increased by the precise definition of biological and/or neuroradiological markers, if these participate in building an etiopathogenic theory of observed psychic phenomena. This orientation remains in its infancy, however: in addition to the tiny number of identified biomarkers, and above all, those that are usable in daily practice, their causal or consequential links with symptoms or with the morbid process remain most often uncertain, inasmuch as they are diverse and interrelated. The neuroscience researcher aims to measure and analyze a multitude of data, integrating, in particular, mimicry and emotions authenticated by thermal camera; movements of body segments and gaze dynamics recorded by sensors; the standardization of voices and speeches for computer software analysis of prosody, used signifiers, syntax… all of which is integrated into a digital phenotyping of suffering. Will we soon be able to speak, replacing the psychologist or the psychiatrist, of an “augmented diagnostician?”.
               
                  Conclusion
                  Does it currently appear risky to trust an entirely virtual therapist… an experiment already launched more than 50 years ago! The human being is a “being of meaning,” yet, according to the model of trauma, the emergence of the all-digital can lead to a “collapse of meaning,” generating a tendency to personality dissociation. Granting the reestablishment of the links between emotions, affects, behaviors, and cognitions, spoken language attenuates dissociation, then makes it disappear. Guided by the practitioner, this therapeutic word is sometimes qualified as “maieutics,” from the name of the science of childbirth: it builds thought synchronously to its essence, and an awareness of it, rather than nondisclosure, would account for it secondarily. It is a causal reinterpretation of a meaning understood or rather “attributed” singularly by the subject, after the fact: the past revisited in the present moment creates a synthesis, and chance is transformed into fate. The speaking subject re-elaborates her/his story towards a semantic reconstruction, a densification of her/his networks of signification. Reclaiming one's being by the creation of a discourse, of veridical as well as fictional meanders, narration, even poetization, offers the punctual illusion of a better coherence, always relative, illusory… Therapeutic speech and discourse about such speech–these are still being made, unfinished, uncertain, and alive. These are the characteristics of what we could a “post-psychotherapy,” that is, a psychotherapy and not a re-educational technique whose objectives would be fixed and known in advance. The notions of facts and reality are secondary here, not in the sense of the objective, nor even of the subjective, but of the second degree, then of other successive or overlapping degrees that require intellectual effort. Moving towards appeasement, if we wanted to bring the reflection to its paroxysm, we could advance that it would be enough to give “any meaning,” whatever it may be. This would apply both to the patient and to the practitioner, without each party's meaning necessarily being the same: a testimony to a formally invalid intersubjective construction.",multimedia
10.1016/j.ecoinf.2021.101268,Journal,Ecological Informatics,scopus,2021-05-01,sciencedirect,The Peruvian Amazon forestry dataset: A leaf image classification corpus,https://api.elsevier.com/content/abstract/scopus_id/85103308612,"Forest census allows getting precise data for logging planning and elaboration of the forest management plan. Species identification blunders carry inadequate forest management plans and high risks inside forest concessions. Hence, an identification protocol prevents the exploitation of non-commercial or endangered timber species. The current Peruvian legislation allows the incorporation of non-technical experts, called “materos”, during the identification. Materos use common names given by the folklore and traditions of their communities instead of formal ones, which generally lead to misclassifications. In the real world, logging companies hire materos instead of botanists due to cost/time limitations. Given such a motivation, we explore an end-to-end software solution to automatize the species identification. This paper introduces the Peruvian Amazon Forestry Dataset, which includes 59,441 leaves samples from ten of the most profitable and endangered timber-tree species. The proposal contemplates a background removal algorithm to feed a pre-trained CNN by the ImageNet dataset. We evaluate the quantitative (accuracy metric) and qualitative (visual interpretation) impacts of each stage by ablation experiments. The results show a 96.64% training accuracy and 96.52% testing accuracy on the VGG-19 model. Furthermore, the visual interpretation of the model evidences that leaf venations have the highest correlation in the plant recognition task.",multimedia
10.1016/j.jneumeth.2021.109126,Journal,Journal of Neuroscience Methods,scopus,2021-05-01,sciencedirect,Virtual EEG-electrodes: Convolutional neural networks as a method for upsampling or restoring channels,https://api.elsevier.com/content/abstract/scopus_id/85102457338,"Background
                  In clinical practice, EEGs are assessed visually. For practical reasons, recordings often need to be performed with a reduced number of electrodes and artifacts make assessment difficult. To circumvent these obstacles, different interpolation techniques can be utilized. These techniques usually perform better for higher electrode densities and values interpolated at areas far from electrodes can be unreliable. Using a method that learns the statistical distribution of the cortical electrical fields and predicts values may yield better results.
               
                  New Method
                  Generative networks based on convolutional layers were trained to upsample from 4 or 14 channels or to dynamically restore single missing channels to recreate 21-channel EEGs. 5,144 h of data from 1,385 subjects of the Temple University Hospital EEG database were used for training and evaluating the networks.
               
                  Comparison with Existing Method
                  The results were compared to spherical spline interpolation. Several statistical measures were used as well as a visual evaluation by board certified clinical neurophysiologists. Overall, the generative networks performed significantly better. There was no difference between real and network generated data in the number of examples assessed as artificial by experienced EEG interpreters whereas for data generated by interpolation, the number was significantly higher. In addition, network performance improved with increasing number of included subjects, with the greatest effect seen in the range 5–100 subjects.
               
                  Conclusions
                  Using neural networks to restore or upsample EEG signals is a viable alternative to spherical spline interpolation.",multimedia
10.1016/j.autcon.2021.103634,Journal,Automation in Construction,scopus,2021-05-01,sciencedirect,Attention-guided analysis of infrastructure damage with semi-supervised deep learning,https://api.elsevier.com/content/abstract/scopus_id/85101541960,"Routine visual inspection is essential to maintain adequate safety and serviceability of civil infrastructures. Computer vision and machine learning based software techniques are becoming recognized methods that can potentially help the inspectors analyze the physical and functional condition of infrastructures from images and/or videos of the region of interest. More recently, deep learning approaches have been shown robust in identifying damages; yet these methods require precisely labeled large amount of training data for high accuracy complementary to visual assessment of inspectors. Especially in image segmentation operations, in which damages are subtracted from the image background for further analysis, there is a strong need to localize the damaged region prior to segmentation operation. However, available segmentation methods mostly focus on the latter step (i.e., delineation), and mis-localization of damaged regions causes accuracy drops. Inspired by the superiority of human cognitive system, where recognizing objects is simpler and more efficient than machine learning algorithms, which are superior to human in local tasks, this paper describes a novel method to dramatically improve the accuracy of the damage quantification (detection + segmentation) using an attention-guided technique. In the proposed method, a fast object detection model, Single Shot Detector (SSD) trained on VGG-16 base classifier architecture, performs a real-time crack and spall detection while working interactively with the human inspector to ensure recognition of the region of interest is well-performed. Upon the inspector's verification, happening in real-time, the detected damage region is used for damage segmentation for further analysis. This initial region of interest selection drastically lowers the computational cost, required amount of training data and reduces number of outliers. For optimal performance, a modified version of SegNet architecture was used for damage segmentation. Based on various performance criteria, the proposed attention-guided infrastructure damage analysis technique provides 30% more precision with a very minor sacrifice in computational speed compared to analysis without using attention guide.",multimedia
10.1016/j.robot.2021.103735,Journal,Robotics and Autonomous Systems,scopus,2021-05-01,sciencedirect,Accurate and real-time human-joint-position estimation for a patient-transfer robot using a two-level convolutional neutral network,https://api.elsevier.com/content/abstract/scopus_id/85101411793,"Human-joint-position estimation is crucial for patient-transfer robots. However, high accuracy and real-time property are difficult to achieve simultaneously. To tackle the problem, we develop a new convolutional neural network (CNN), containing two levels of subnetworks, to fuse the information in color and depth images. The first-level subnetwork generates two-dimensional (2D) human joint positions from a color image by the part-affinity-fields method. The second-level subnetwork estimates 3D human-joint positions from 2D ones and corresponding depth images. Here, strong feature-extraction function of the CNN may suppress the negative effect caused by invalid information in depth images. Meanwhile, all the estimations are implemented with the 2D CNNs, which may cause higher time-efficiency than 3D ones (mostly used in previous studies). To assess the validity, first we employed the CNN to estimate human joint positions, and obtained the accuracy and speed of respectively 90.3% and 210 ms (implemented with an affordable processing unit). Then we applied the CNN to a dual-arm nursing-care robot and found that the accuracy and processing speed satisfied the requirements in practical usage; these validated the effectiveness of our proposal and provided a new approach to generate 3D-human-joint positions through information fusion of color and depth images.",multimedia
10.1016/j.media.2021.101990,Journal,Medical Image Analysis,scopus,2021-05-01,sciencedirect,VR-Caps: A Virtual Environment for Capsule Endoscopy,https://api.elsevier.com/content/abstract/scopus_id/85101407908,"Current capsule endoscopes and next-generation robotic capsules for diagnosis and treatment of gastrointestinal diseases are complex cyber-physical platforms that must orchestrate complex software and hardware functions. The desired tasks for these systems include visual localization, depth estimation, 3D mapping, disease detection and segmentation, automated navigation, active control, path realization and optional therapeutic modules such as targeted drug delivery and biopsy sampling. Data-driven algorithms promise to enable many advanced functionalities for capsule endoscopes, but real-world data is challenging to obtain. Physically-realistic simulations providing synthetic data have emerged as a solution to the development of data-driven algorithms. In this work, we present a comprehensive simulation platform for capsule endoscopy operations and introduce VR-Caps, a virtual active capsule environment that simulates a range of normal and abnormal tissue conditions (e.g., inflated, dry, wet etc.) and varied organ types, capsule endoscope designs (e.g., mono, stereo, dual and 360
                        
                           
                           ∘
                        
                      camera), and the type, number, strength, and placement of internal and external magnetic sources that enable active locomotion. VR-Caps makes it possible to both independently or jointly develop, optimize, and test medical imaging and analysis software for the current and next-generation endoscopic capsule systems. To validate this approach, we train state-of-the-art deep neural networks to accomplish various medical image analysis tasks using simulated data from VR-Caps and evaluate the performance of these models on real medical data. Results demonstrate the usefulness and effectiveness of the proposed virtual platform in developing algorithms that quantify fractional coverage, camera trajectory, 3D map reconstruction, and disease classification. All of the code, pre-trained weights and created 3D organ models of the virtual environment with detailed instructions how to setup and use the environment are made publicly available at https://github.com/CapsuleEndoscope/VirtualCapsuleEndoscopy and a video demonstration can be seen in the supplementary videos (Video-I).",multimedia
10.1016/j.image.2021.116200,Journal,Signal Processing: Image Communication,scopus,2021-05-01,sciencedirect,Modelling spatio-temporal ageing phenomena with deep Generative Adversarial Networks,https://api.elsevier.com/content/abstract/scopus_id/85100999804,"Deterioration modelling of ageing phenomena on materials is an actively researched topic in computer graphics and vision, with a wide range of applications in domains such as cultural heritage, game programming, material science and virtual reality. As a result significant progress has been accomplished and existing methods are able to produce visually pleasing results that appear realistic. However, there is a very limited connection to comprehensive measurements that actually capture the ageing process of a material. This paper focuses on this gap, aiming to provide a link between physical measurements and deterioration modelling. Based on extensive measurements of texture and surface geometry of artificially aged reference materials, a Deep Learning (DL) framework is proposed that models spatio-temporal variations on the 3D surface geometry and the 2D colour–image appearance. Concretely, the problem of material degradation over time is formulated as an 2D/3D material-to-material translation problem, where the goal is, given an input material and a target degradation time, to output the degraded material at that time. At the core of the method lies a modified conditional Generative Adversarial Network (cGAN), which maps input materials to degraded materials over time. In order to train and deploy the proposed cGAN model, proper data parameterization and augmentation steps are introduced. As shown through extensive experimentation on real data coming from materials commonly found in artwork and from actual artworks, the proposed approach produces high quality results.",multimedia
10.1016/j.ssci.2021.105190,Journal,Safety Science,scopus,2021-05-01,sciencedirect,Beirut explosion 2020: A case study for a large-scale urban blast simulation,https://api.elsevier.com/content/abstract/scopus_id/85100545374,"In the face of continued global urbanization, cities are challenged to satisfy increasing standards in terms of quality of life, environmental conditions, safety, security, health, economic growth and mobility. The concept of “smart cities” aims at utilising advanced technologies, artificial intelligence and high computational capacity to increase their resilience and improve the services provided to the citizens. Computation-based numerical simulations have been essentially used to estimate the effects of explosion events in urban environments in terms of both structural damage and human casualties. These provide urban planners and decision makers with valuable information for vulnerability assessment and aid developing prevention or mitigation solutions. In this article, we present a framework to generate a 3D large-scale urbanistic finite element model, where the desired geospatial data are extracted from the open-source world map OpenStreetMap. The model is used to simulate blast wave propagation effects in a wide urban area taking into account the reflections at building surfaces via a sophisticated Fluid-Structure interaction technique integrated in the EUROPLEXUS explicit finite element method software. The explosion in the Port of Beirut in Lebanon, which took place on the 4th of August 2020, was remarkable for the large amount of explosive material causing considerable damage to surrounding structures and a high number of deaths and injured. Such characteristics make the event suitable for assessing the performance of the proposed computational approach in a widely exposed (by the blast wave) urban zone.",multimedia
10.1016/j.entcom.2021.100404,Journal,Entertainment Computing,scopus,2021-05-01,sciencedirect,Using gestural emotions recognised through a neural network as input for an adaptive music system in virtual reality,https://api.elsevier.com/content/abstract/scopus_id/85100077108,"In this article, a head gesture recognition system is developed in order to identify emotional inputs and provide them to an adaptive music system (LitSens) in virtual reality applications, improving virtual presence in the process. Two iterations of this system, both founded on neural networks, are presented: the first one is based on a multi-layer perceptron, whereas the second one consists of a hybrid one-dimensional convolutional neural network. In both cases, the system is able to recognise fear by analysing head gestures. Whereas the first implementation is quicker when recognising this emotion, the second one is slower, but much more accurate, which makes it a better option overall for soundtrack adaptation. An experiment is then detailed, aimed towards validating the behaviour of a gestural recogniser when detecting fear in players. The results achieved through this validation are generally positive, but evince the need for an improvement in terms of system responsiveness.",multimedia
10.1016/j.surg.2020.09.040,Journal,Surgery (United States),scopus,2021-05-01,sciencedirect,The future surgical training paradigm: Virtual reality and machine learning in surgical education,https://api.elsevier.com/content/abstract/scopus_id/85097383738,"Surgical training has undergone substantial change in the last few decades. As technology and patient complexity continues to increase, demands for novel approaches to ensure competency have arisen. Virtual reality systems augmented with machine learning represents one such approach. The ability to offer on-demand training, integrate checklists, and provide personalized, surgeon-specific feedback is paving the way to a new era of surgical training. Machine learning algorithms that improve over time as they acquire more data will continue to refine the education they provide. Further, fully immersive simulated environments coupled with machine learning analytics provide real-world training opportunities in a safe atmosphere away from the potential to harm patients. Careful implementation of these technologies has the potential to increase access and improve quality of surgical training and patient care and are poised to change the landscape of current surgical training. Herein, we describe the current state of virtual reality coupled with machine learning for surgical training, future directions, and existing limitations of this technology.",multimedia
10.1016/j.preteyeres.2020.100900,Journal,Progress in Retinal and Eye Research,scopus,2021-05-01,sciencedirect,"Digital technology, tele-medicine and artificial intelligence in ophthalmology: A global perspective",https://api.elsevier.com/content/abstract/scopus_id/85093916279,"The simultaneous maturation of multiple digital and telecommunications technologies in 2020 has created an unprecedented opportunity for ophthalmology to adapt to new models of care using tele-health supported by digital innovations. These digital innovations include artificial intelligence (AI), 5th generation (5G) telecommunication networks and the Internet of Things (IoT), creating an inter-dependent ecosystem offering opportunities to develop new models of eye care addressing the challenges of COVID-19 and beyond. Ophthalmology has thrived in some of these areas partly due to its many image-based investigations. Tele-health and AI provide synchronous solutions to challenges facing ophthalmologists and healthcare providers worldwide. This article reviews how countries across the world have utilised these digital innovations to tackle diabetic retinopathy, retinopathy of prematurity, age-related macular degeneration, glaucoma, refractive error correction, cataract and other anterior segment disorders. The review summarises the digital strategies that countries are developing and discusses technologies that may increasingly enter the clinical workflow and processes of ophthalmologists. Furthermore as countries around the world have initiated a series of escalating containment and mitigation measures during the COVID-19 pandemic, the delivery of eye care services globally has been significantly impacted. As ophthalmic services adapt and form a “new normal”, the rapid adoption of some of telehealth and digital innovation during the pandemic is also discussed. Finally, challenges for validation and clinical implementation are considered, as well as recommendations on future directions.",multimedia
10.1016/j.smhl.2021.100191,Journal,Smart Health,scopus,2021-04-01,sciencedirect,Inferring food types through sensing and characterizing mastication dynamics,https://api.elsevier.com/content/abstract/scopus_id/85107633513,"Unhealthy dietary structure leads to the prevalence of some chronic diseases, such as obesity, diabetes, and heart disease. Automatic food type recognition helps nutritionists and medical professionals understand patients’ nutritional contents, provide accurate and personalized treatments, and evaluate therapeutic effects. Existing wearable sensor-based methods take advantage of microphone, electromyography (EMG), and piezoelectric sensors embedded in the wearable devices. However, these sensors are either easily impacted by ambient acoustic noise or intrusive and uncomfortable to wear. We observe that each type of food has its own intrinsic properties, such as hardness, elasticity, fracturability, adhesiveness, and size. Different food properties result in different mastication dynamics. In this paper, we present the first effort in using wearable motion sensors to sense mastication dynamics and infer food types accordingly. We specifically define six mastication dynamics parameters to represent these food properties. They are chewing speed, the number of chews, chewing time, chewing force, chewing cycle duration and skull vibration. We embed motion sensors in a headband and deploy the sensors on the temporalis muscles to sense mastication dynamics accurately and less intrusively. In addition, we extract 65 hand-crafted features from each chewing sequence to explicitly characterize the mastication dynamics using motion sensor data. A real-world evaluation dataset of 11 food categories (20 types of food in total) is collected from 15 human subjects. The average recognition accuracy of these 15 human subjects is 82.3%. The accuracy of a single human subject is up to 93.3%.",multimedia
10.1016/j.bioorg.2021.104719,Journal,Bioorganic Chemistry,scopus,2021-04-01,sciencedirect,Flavonoids from Pterogyne nitens as Zika virus NS2B-NS3 protease inhibitors,https://api.elsevier.com/content/abstract/scopus_id/85101244114,"Although the widespread epidemic of Zika virus (ZIKV) and its neurological complications are well-known there are still no approved drugs available to treat this arboviral disease or vaccine to prevent the infection. Flavonoids from Pterogyne nitens have already demonstrated anti-flavivirus activity, although their target is unknown. In this study, we virtually screened an in-house database of 150 natural and semi-synthetic compounds against ZIKV NS2B-NS3 protease (NS2B-NS3p) using docking-based virtual screening, as part of the OpenZika project. As a result, we prioritized three flavonoids from P. nitens, quercetin, rutin and pedalitin, for experimental evaluation. We also used machine learning models, built with Assay Central® software, for predicting the activity and toxicity of these flavonoids. Biophysical and enzymatic assays generally agreed with the in silico predictions, confirming that the flavonoids inhibited ZIKV protease. The most promising hit, pedalitin, inhibited ZIKV NS2B-NS3p with an IC50 of 5 μM. In cell-based assays, pedalitin displayed significant activity at 250 and 500 µM, with slight toxicity in Vero cells. The results presented here demonstrate the potential of pedalitin as a candidate for hit-to-lead (H2L) optimization studies towards the discovery of antiviral drug candidates to treat ZIKV infections.",multimedia
10.1016/j.compbiomed.2021.104282,Journal,Computers in Biology and Medicine,scopus,2021-04-01,sciencedirect,A contactless method to measure real-time finger motion using depth-based pose estimation,https://api.elsevier.com/content/abstract/scopus_id/85101090835,"Background
                  Finger mobility plays a crucial role in everyday living and is a leading indicator during hand rehabilitation and assistance tasks. Depth-based hand pose estimation is a potentially low-cost solution for the clinical and home-based measurement of symptoms of limited human finger motion.
               
                  Objective
                  The purpose of this study was to achieve the contactless measurement of finger motion based on depth-based hand pose estimation using Azure Kinect depth cameras and transfer learning, and to evaluate the accuracy in comparison with a three-dimensional motion analysis (3DMA) system.
               
                  Methods
                  Thirty participants performed a series of tasks during which their hand motions were measured concurrently using the Azure Kinect and 3DMA systems. We propose a simple and effective approach to achieving real-time hand pose estimations from single depth images using ensemble convolutional neural networks trained by a transfer learning strategy. Algorithms to calculate the finger joint motion angles are presented by tracking the locations of the 24 hand joints. To demonstrate their potential, the Azure-Kinect-based 3D finger motion measurement system and algorithms are experimentally verified through comparison with a camera-based 3DMA system, which is the gold standard.
               
                  Results
                  Our results revealed that the Azure-Kinect-based hand pose estimation system produced highly correlated measurements of hand joint coordinates. Our method achieved excellent performance in terms of the fraction of good frames ( 
                        
                           >
                           80
                           %
                        
                     ) when the error thresholds were larger than approximately 2 cm, and the range of mean error distance was 0.23
                        
                           −
                           −
                        
                     1.05 cm. For joint angles, the Azure Kinect and 3DMA systems had comparable inter-trial reliability (ICC2,1 ranging from 0.89 to 0.97) and excellent concurrent validity, with Pearsons r-values 
                        
                           >
                           0.90
                        
                      for most measurements (range: 0.88
                        
                           −
                           −
                        
                     0.97). The 95
                        
                           %
                        
                      BlandAltman limits of agreement were narrow enough for the Azure Kinect to be considered a valid tool for the measurement of all reported joint angles of the index finger and thumb in pinching. Moreover, our method runs in real time at over 45 fps.
               
                  Conclusion
                  The results of this study suggest that the proposed method has the capacity to measure the performance of fine motor skills.",multimedia
10.1016/j.engappai.2021.104189,Journal,Engineering Applications of Artificial Intelligence,scopus,2021-04-01,sciencedirect,Analysis of the sensitivity of the End-Of-Turn Detection task to errors generated by the Automatic Speech Recognition process,https://api.elsevier.com/content/abstract/scopus_id/85100988795,"An End-Of-Turn Detection Module (EOTD-M) is an essential component of automatic Spoken Dialogue Systems. The capability of correctly detecting whether a user’s utterance has ended or not improves the accuracy in interpreting the meaning of the message and decreases the latency in the answer. Usually, in dialogue systems, an EOTD-M is coupled with an Automatic Speech Recognition Module (ASR-M) to transmit complete utterances to the Natural Language Understanding unit. Mistakes in the ASR-M transcription can have a strong effect on the performance of the EOTD-M. The actual extent of this effect depends on the particular combination of ASR-M transcription errors and the sentence featurization techniques implemented as part of the EOTD-M. In this paper we investigate this important relationship for an EOTD-M based on semantic information and particular characteristics of the speakers (speech profiles). We introduce an Automatic Speech Recognition Simulator (ASR-SIM) that models different types of semantic mistakes in the ASR-M transcription as well as different speech profiles. We use the simulator to evaluate the sensitivity to ASR-M mistakes of a Long Short-Term Memory network classifier trained in EOTD with different featurization techniques. Our experiments reveal the different ways in which the performance of the model is influenced by the ASR-M errors. We corroborate that not only is the ASR-SIM useful to estimate the performance of an EOTD-M in customized noisy scenarios, but it can also be used to generate training datasets with the expected error rates of real working conditions, which leads to better performance.",multimedia
10.1016/j.bspc.2021.102444,Journal,Biomedical Signal Processing and Control,scopus,2021-04-01,sciencedirect,A novel autonomous learning framework to enhance sEMG-based hand gesture recognition using depth information,https://api.elsevier.com/content/abstract/scopus_id/85100728034,"Hand gesture recognition using surface electromyography (sEMG) has been one of the most efficient motion analysis techniques in human–computer interaction in the last few decades. In particular, multichannel sEMG techniques have achieved stable performance in hand gesture recognition. However, the general solution of collecting and labeling large data manually leads to time-consuming implementation. A novel learning method is therefore needed to facilitate efficient data collection and preprocessing. In this paper, a novel autonomous learning framework is proposed to integrate the benefits of both depth vision and EMG signals, which automatically label the class of collected EMG data using depth information. It then utilizes a multiple layer neural network (MNN) classifier to achieve real-time recognition of the hand gestures using only the sEMG. The overall framework is demonstrated in an augmented reality application by the recognition of 10 hand gestures using the Myo armband and an HTC VIVE PRO. The results show prominent performance by introducing depth information for real-time data labeling.",multimedia
10.1016/j.neunet.2020.12.008,Journal,Neural Networks,scopus,2021-04-01,sciencedirect,A bioinspired angular velocity decoding neural network model for visually guided flights,https://api.elsevier.com/content/abstract/scopus_id/85099840547,"Efficient and robust motion perception systems are important pre-requisites for achieving visually guided flights in future micro air vehicles. As a source of inspiration, the visual neural networks of flying insects such as honeybee and Drosophila provide ideal examples on which to base artificial motion perception models. In this paper, we have used this approach to develop a novel method that solves the fundamental problem of estimating angular velocity for visually guided flights. Compared with previous models, our elementary motion detector (EMD) based model uses a separate texture estimation pathway to effectively decode angular velocity, and demonstrates considerable independence from the spatial frequency and contrast of the gratings. Using the Unity development platform the model is further tested for tunnel centering and terrain following paradigms in order to reproduce the visually guided flight behaviors of honeybees. In a series of controlled trials, the virtual bee utilizes the proposed angular velocity control schemes to accurately navigate through a patterned tunnel, maintaining a suitable distance from the undulating textured terrain. The results are consistent with both neuron spike recordings and behavioral path recordings of real honeybees, thereby demonstrating the model’s potential for implementation in micro air vehicles which have only visual sensors.",multimedia
10.1016/j.engstruct.2020.111798,Journal,Engineering Structures,scopus,2021-04-01,sciencedirect,Adaptive neuro-fuzzy and simple adaptive control methods for full three-dimensional coupled buildings subjected to bi-directional seismic excitations,https://api.elsevier.com/content/abstract/scopus_id/85099825213,"Attenuation of three-dimensional coupled buildings under bi-directional seismic excitations using semi-active control devices is pursued in this paper. Multiple magneto-rheological (MR) dampers are employed to connect two adjacent buildings at multiple levels for real-time control of the structural responses. The MR dampers are managed by adaptive neuro-fuzzy inference systems (ANFIS) and simple adaptive control (SAC) methods so a comparison between the performance of both controllers can be made. The displacement feedback type is used for both control methods to design the closed-loop action. The structural system modeled as two three-dimensional buildings connected by frame elements in which the MR dampers are implemented. The equations of motions of the three-dimensional model are formulated by assuming that each floor diaphragm is rigid in its own plane but flexible in the vertical coordinate. Each link is assumed to have three degrees-of-freedom two translational and one rotational at its ends. The adaptive neuro-fuzzy inference system is designed based on Sugeno-type model. Seven triangular membership functions are chosen to fuzzify the input crisp data in the fuzzy logic controller. The training data for ANFIS are generated by the Linear Quadratic Regulator (LQR) under white-noise disturbance. For the simple adaptive controller, LQR is also used to generate the desired trajectories of the reference-model. Numerical simulations are carried out for both symmetrical and asymmetrical coupled buildings under eleven pairs of major earthquakes. The results show that both ANFIS and SAC can deal very successfully with modeling complexities associated with full three-dimensional models subjected to multi-excitations. In terms of seismic responses reduction, both methods have shown a great potential in enhancing the structural performance under seismic activities.",multimedia
10.1016/j.adhoc.2021.102438,Journal,Ad Hoc Networks,scopus,2021-04-01,sciencedirect,Low data regimes in extreme climates: Foliage penetration personnel detection using a wireless network-based device-free sensing approach,https://api.elsevier.com/content/abstract/scopus_id/85099780457,"As far as low-cost deployment is concerned, wireless network-based device-free sensing (DFS) is of great interest and has successfully demonstrated the feasibility in Foliage penetration (FOPEN) target recognition. The classification accuracy of this technology is known to dramatically decrease in extreme climates where the received signals tend to be severely attenuated; while deep learning approaches have boosted performance, they only perform effectively when trained with large amounts of labeled data. Consequently, it is still unknown how to ensure reasonable detection accuracy in extreme climates where sufficient samples are difficult to obtain. To address this concern, we adopt two special measures for performance enhancement in this paper. One measure is to employ higher-order spectral (HOS) analysis to transform the time-domain signals into the bispectrum image representations, so that the shift to an image classification task could provide the advantage of using the existing Convolutional Neural Network (CNN) models. More importantly, the immunity of the approach against the unwanted clutters in foliage environments can be improved. The other one is to present an end-to-end Deep Learning Data Augmentation and Classification (DLDAC) model comprised of a Deep Convolutional Generative Adversarial Network (for data augmentation) and a SqueezeNet CNN backbone (for target classification), which can improve the classifier performance by using the augmented data on-the-fly. Thus, the negative impacts of low data regimes in extreme climates can be considerably accommodated. To evaluate the effectiveness of the proposed approach, comprehensive experiments are conducted on a real FOPEN dataset collected by impulse-radio ultra-wideband (IR-UWB) transceivers under three severe weather conditions. The experimental results demonstrate that even when only 300 training samples are taken for each type of target under every weather condition, the average classification accuracy of the proposed approach is still better than 92% in terms of distinguishing between human and other targets.",multimedia
10.1016/j.neunet.2020.12.022,Journal,Neural Networks,scopus,2021-04-01,sciencedirect,Quantization Friendly MobileNet (QF-MobileNet) Architecture for Vision Based Applications on Embedded Platforms,https://api.elsevier.com/content/abstract/scopus_id/85099004865,"Deep Neural Networks (DNNs) have become popular for various applications in the domain of image and computer vision due to their well-established performance attributes. DNN algorithms involve powerful multilevel feature extractions resulting in an extensive range of parameters and memory footprints. However, memory bandwidth requirements, memory footprint and the associated power consumption of models are issues to be addressed to deploy DNN models on embedded platforms for real time vision-based applications. We present an optimized DNN model for memory and accuracy for vision-based applications on embedded platforms. In this paper we propose Quantization Friendly MobileNet (QF-MobileNet) architecture. The architecture is optimized for inference accuracy and reduced resource utilization. The optimization is obtained by addressing the redundancy and quantization loss of the existing baseline MobileNet architectures. We verify and validate the performance of the QF-MobileNet architecture for image classification task on the ImageNet dataset. The proposed model is tested for inference accuracy and resource utilization and compared to the baseline MobileNet architecture. The inference accuracy of the proposed QF-MobileNetV2 float model attained 73.36% and the quantized model has 69.51%. The MobileNetV3 float model attained an inference accuracy of 68.75% and the quantized model has 67.5% respectively. The proposed model saves 33% of time complexity for QF-MobileNetV2 and QF-MobileNetV3 models against the baseline models. The QF-MobileNet also showed optimized resource utilization with 32% fewer tunable parameters, 30% fewer MAC’s operations per image and reduced inference quantization loss by approximately 5% compared to the baseline models. The model is ported onto the android application using TensorFlow API. The android application performs inference on the native devices viz. smartphones, tablets and handheld devices. Future work is focused on introducing channel-wise and layer-wise quantization schemes to the proposed model. We intend to explore quantization aware training of DNN algorithms to achieve optimized resource utilization and inference accuracy.",multimedia
10.1016/j.media.2020.101942,Journal,Medical Image Analysis,scopus,2021-04-01,sciencedirect,Automated interpretation of congenital heart disease from multi-view echocardiograms,https://api.elsevier.com/content/abstract/scopus_id/85098981556,"Congenital heart disease (CHD) is the most common birth defect and the leading cause of neonate death in China. Clinical diagnosis can be based on the selected 2D key-frames from five views. Limited by the availability of multi-view data, most methods have to rely on the insufficient single view analysis. This study proposes to automatically analyze the multi-view echocardiograms with a practical end-to-end framework. We collect the five-view echocardiograms video records of 1308 subjects (including normal controls, ventricular septal defect (VSD) patients and atrial septal defect (ASD) patients) with both disease labels and standard-view key-frame labels. Depthwise separable convolution-based multi-channel networks are adopted to largely reduce the network parameters. We also approach the imbalanced class problem by augmenting the positive training samples. Our 2D key-frame model can diagnose CHD or negative samples with an accuracy of 95.4%, and in negative, VSD or ASD classification with an accuracy of 92.3%. To further alleviate the work of key-frame selection in real-world implementation, we propose an adaptive soft attention scheme to directly explore the raw video data. Four kinds of neural aggregation methods are systematically investigated to fuse the information of an arbitrary number of frames in a video. Moreover, with a view detection module, the system can work without the view records. Our video-based model can diagnose with an accuracy of 93.9% (binary classification), and 92.1% (3-class classification) in a collected 2D video testing set, which does not need key-frame selection and view annotation in testing. The detailed ablation study and the interpretability analysis are provided.
                  The presented model has high diagnostic rates for VSD and ASD that can be potentially applied to the clinical practice in the future. The short-term automated machine learning process can partially replace and promote the long-term professional training of primary doctors, improving the primary diagnosis rate of CHD in China, and laying the foundation for early diagnosis and timely treatment of children with CHD.",multimedia
10.1016/j.patcog.2020.107801,Journal,Pattern Recognition,scopus,2021-04-01,sciencedirect,Neural random subspace,https://api.elsevier.com/content/abstract/scopus_id/85098974683,"The random subspace method, also known as the pillar of random forests, is good at making precise and robust predictions. However, there is as yet no straightforward way to combine it with deep learning. In this paper, we therefore propose Neural Random Subspace (NRS), a novel deep learning based random subspace method. In contrast to previous forest methods, NRS enjoys the benefits of end-to-end, data-driven representation learning, as well as pervasive support from deep learning software and hardware platforms, hence achieving faster inference speed and higher accuracy. Furthermore, as a non-linear component to be encoded into Convolutional Neural Networks (CNNs), NRS learns non-linear feature representations in CNNs more efficiently than contemporary, higher-order pooling methods, producing excellent results with negligible increase in parameters, floating point operations (FLOPs) and real running time. Compared with random subspaces, random forests and gradient boosting decision trees (GBDTs), NRS demonstrates superior performance on 35 machine learning datasets. Moreover, on both 2D image and 3D point cloud recognition tasks, integration of NRS with CNN architectures achieves consistent improvements with only incremental cost.",multimedia
10.1016/j.cpc.2020.107779,Journal,Computer Physics Communications,scopus,2021-04-01,sciencedirect,Mammography and breast tomosynthesis simulator for virtual clinical trials,https://api.elsevier.com/content/abstract/scopus_id/85098176202,"Computer modeling and simulations are increasingly being used to predict the clinical performance of x-ray imaging devices in silico, and to generate synthetic patient images for training and testing of machine learning algorithms. We present a detailed description of the computational models implemented in the open source GPU-accelerated Monte Carlo x-ray imaging simulation code MC-GPU. This code, originally developed to simulate radiography and computed tomography, has been extended to replicate a commercial full-field digital mammography and digital breast tomosynthesis (DBT) device. The code was recently used to image 3000 virtual breast models with the aim of reproducing in silico a clinical trial used in support of the regulatory approval of DBT as a replacement of mammography for breast cancer screening. The updated code implements a more realistic x-ray source model (extended 3D focal spot, tomosynthesis acquisition trajectory, tube motion blurring) and an improved detector model (direct-conversion Selenium detector with depth-of-interaction effects, fluorescence tracking, electronic noise and anti-scatter grid). The software uses a high resolution voxelized geometry model to represent the breast anatomy. To reduce the GPU memory requirements, the code stores the voxels in memory within a binary tree structure. The binary tree is an efficient compression mechanism because many voxels with the same composition are combined in common tree branches while preserving random access to the phantom composition at any location. A delta scattering ray-tracing algorithm which does not require computing ray-voxel interfaces is used to minimize memory access. Multiple software verification and validation steps intended to establish the credibility of the implemented computational models are reported. The software verification was done using a digital quality control phantom and an ideal pinhole camera. The validation was performed reproducing standard bench testing experiments used in clinical practice and comparing with experimental measurements. A sensitivity study intended to assess the robustness of the simulated results to variations in some of the input parameters was performed using an in silico clinical trial pipeline with simulated lesions and mathematical observers. We show that MC-GPU is able to simulate x-ray projections that incorporate many of the sources of variability found in clinical images, and that the simulated results are robust to some uncertainty in the input parameters. Limitations of the implemented computational models are discussed.
               
                  Program summary
                  
                     Program title: MCGPU_VICTRE
                  
                     CPC Library link to program files: 
                     https://doi.org/10.17632/k5x2bsf27m.1
                  
                  
                     Licensing provisions: CC0 1.0
                  
                     Programming language: C (with NVIDIA CUDA extensions)
                  
                     Nature of problem: The health risks associated with ionizing radiation impose a limit to the amount of clinical testing that can be done with x-ray imaging devices. In addition, radiation dose cannot be directly measured inside the body. For these reasons, a computational replica of an x-ray imaging device that simulates radiographic images of synthetic anatomical phantoms is of great value for device evaluation. The simulated radiographs and dosimetric estimates can be used for system design and optimization, task-based evaluation of image quality, machine learning software training, and in silico imaging trials.
                  
                     Solution method: Computational models of a mammography x-ray source and detector have been implemented. X-ray transport through matter is simulated using Monte Carlo methods customized for parallel execution in multiple Graphics Processing Units. The input patient anatomy is represented by voxels, which are efficiently stored in the video memory using a new binary tree structure compression mechanism.",multimedia
10.1016/j.ymssp.2020.107398,Journal,Mechanical Systems and Signal Processing,scopus,2021-04-01,sciencedirect,1D convolutional neural networks and applications: A survey,https://api.elsevier.com/content/abstract/scopus_id/85095978325,"During the last decade, Convolutional Neural Networks (CNNs) have become the de facto standard for various Computer Vision and Machine Learning operations. CNNs are feed-forward Artificial Neural Networks (ANNs) with alternating convolutional and subsampling layers. Deep 2D CNNs with many hidden layers and millions of parameters have the ability to learn complex objects and patterns providing that they can be trained on a massive size visual database with ground-truth labels. With a proper training, this unique ability makes them the primary tool for various engineering applications for 2D signals such as images and video frames. Yet, this may not be a viable option in numerous applications over 1D signals especially when the training data is scarce or application specific. To address this issue, 1D CNNs have recently been proposed and immediately achieved the state-of-the-art performance levels in several applications such as personalized biomedical data classification and early diagnosis, structural health monitoring, anomaly detection and identification in power electronics and electrical motor fault detection. Another major advantage is that a real-time and low-cost hardware implementation is feasible due to the simple and compact configuration of 1D CNNs that perform only 1D convolutions (scalar multiplications and additions). This paper presents a comprehensive review of the general architecture and principals of 1D CNNs along with their major engineering applications, especially focused on the recent progress in this field. Their state-of-the-art performance is highlighted concluding with their unique properties. The benchmark datasets and the principal 1D CNN software used in those applications are also publicly shared in a dedicated website. While there has not been a paper on the review of 1D CNNs and its applications in the literature, this paper fulfills this gap.",multimedia
10.1016/j.eswa.2020.114177,Journal,Expert Systems with Applications,scopus,2021-04-01,sciencedirect,MLT-DNet: Speech emotion recognition using 1D dilated CNN based on multi-learning trick approach,https://api.elsevier.com/content/abstract/scopus_id/85095833511,"Speech is the most dominant source of communication among humans, and it is an efficient way for human–computer interaction (HCI) to exchange information. Nowadays, speech emotion recognition (SER) is an active research area that plays a crucial role in real-time applications. In this era, the SER system has lacked real-time speech processing. To address this problem, we propose an end-to-end real-time SER model that is based on a one-dimensional dilated convolutional neural network (DCNN). Our model used a multi-learning strategy to parallel extract spatial salient emotional features and learn long term contextual dependencies from the speech signals. We used residual blocks with a skip connection (RBSC) module, in order to find a correlation, the emotional cues, and the sequence learning (Seq_L) module, to learn the long term contextual dependencies in the input features. Furthermore, we used a fusion layer to concatenate these learned features for the final emotion recognition task. Our model structure is quite simple, and it is capable of automatically learning salient discriminative features from the speech signals. We evaluated our model using benchmark IEMOCAP and EMO-DB datasets and obtained a high recognition accuracy, which were 73% and 90%, respectively. The experimental results indicated the significance and the efficiency of our proposed model have shown excessive assistance with the implementation of a real-time SER system. Hence, our model is capable of processing original speech signals for the emotion recognition that utilizes lightweight dilated CNN architecture that implements the multi-learning trick (MLT) approach.",multimedia
10.1016/j.neucom.2020.10.097,Journal,Neurocomputing,scopus,2021-03-21,sciencedirect,3D-RVP: A method for 3D object reconstruction from a single depth view using voxel and point,https://api.elsevier.com/content/abstract/scopus_id/85097471582,"Three-dimensional object reconstruction technology has a wide range of applications such as augment reality, virtual reality, industrial manufacturing and intelligent robotics. Although deep learning-based 3D object reconstruction technology has developed rapidly in recent years, there remain important problems to be solved. One of them is that the resolution of reconstructed 3D models is hard to improve because of the limitation of memory and computational efficiency when deployed on resource-limited devices. In this paper, we propose 3D-RVP to reconstruct a complete and accurate 3D geometry from a single depth view, where R, V and P represent Reconstruction, Voxel and Point, respectively. It is a novel two-stage method that combines a 3D encoder-decoder network with a point prediction network. In the first stage, we propose a 3D encoder-decoder network with residual learning to output coarse prediction results. In the second stage, we propose an iterative subdivision algorithm to predict the labels of adaptively selected points. The proposed method can output high-resolution 3D models by increasing a small number of parameters. Experiments are conducted on widely used benchmarks of a ShapeNet dataset in which four categories of models are selected to test the performance of neural networks. Experimental results show that our proposed method outperforms the state-of-the-arts, and achieves about 
                        
                           2.7
                           %
                        
                      improvement in terms of the intersection-over-union metric.",multimedia
10.1016/j.medidd.2021.100081,Journal,Medicine in Drug Discovery,scopus,2021-03-01,sciencedirect,Peptides in chemical space,https://api.elsevier.com/content/abstract/scopus_id/85104918401,"Peptides, defined as sequences of amino acids up to approximately 50 residues in length, represent an extremely large reservoir of potentially bioactive compounds, referred to here as the peptide chemical space. Recent advances in computer hardware and software have led to a wide application of computational methods to explore this chemical space. Here, we review different in silico approaches including structure-based design, genetic algorithms, and machine learning. We also review the use of molecular fingerprints to sample virtual libraries and to visualize the peptide chemical space. Finally, we present an overview of the known peptide chemical space in form of an interactive map representing 40,531 peptides collected from eleven open-access peptide and peptide-containing databases, accessible at https://tm.gdb.tools/map4/peptide_databases_tmap/. These peptides are displayed as TMAP (Tree-Map) according to their molecular fingerprint similarity computed using MAP4, a MinHashed atom pair fingerprint well suited to analyze large molecules.",multimedia
10.1016/j.clineuro.2021.106524,Journal,Clinical Neurology and Neurosurgery,scopus,2021-03-01,sciencedirect,Clinical application of Myelopathy-hand Functional Evaluation System in evaluating the postoperative hand motor function for myelopathy patients,https://api.elsevier.com/content/abstract/scopus_id/85100619463,"Objective
                  Recovery of hand motor function after surgical treatment in myelopathy patients is commonly observed. Accurate evaluation of postoperative hand function contributes to assessing the efficacy of surgical treatment. However, no objective and effective evaluation method has been widely accepted in clinical practice. Therefore, the study aimed to explore the value of Myelopathy-hand Functional Evaluation System (MFES) in assessing the postoperative hand function for myelopathy patients.
               
                  Material and method
                  MFES mainly consist of a pair of wise-gloves and a computer with software. One hundred and thirty myelopathy patients were included and all of them received optimal surgery treatment. The Japanese Orthopaedic Association (JOA) scores were marked at preoperative and at 6 months after surgery. All patients were asked to perform the 10-s grip and release test, and the hand movements were simulated and converted into waveforms by MFES. The waveform parameters were measured and analyzed.
               
                  Results
                  The JOA scores and the number of grip-and-release (G–R) cycles significantly increased after surgery. Correspondingly, the waveforms of ulnar three fingers were significantly higher and narrower, along with the significantly declined average time per cycle in postoperative. The a/b ratio (Wave height/wave width) of five fingers were significantly higher in postoperative than that in preoperative. Based on the improvement rate of a/b, the excellent and good rate of surgical outcomes was 62.30 %, which was significantly higher than that (47.69 %) based on the improvement rate of JOA scores (P = 0.019).
               
                  Conclusion
                  MFES is an effective assessment tool in evaluating the postoperative hand function for myelopathy patients.",multimedia
10.1016/j.berh.2021.101662,Journal,Best Practice and Research: Clinical Rheumatology,scopus,2021-03-01,sciencedirect,Managing patients using telerheumatology: Lessons from a pandemic,https://api.elsevier.com/content/abstract/scopus_id/85100105533,"The coronavirus disease 2019 (COVID-19) pandemic has presented unique challenges to rheumatology provision. Measures to control the pandemic have limited face-to-face contact with rheumatology healthcare professionals. One innovation has been the widespread adoption of telerheumatology to assist in the care of patients with rheumatic and musculoskeletal diseases, building on an existing evidence base in rheumatology. Widespread adoption has only occurred following the COVID-19 pandemic. We discuss the evidence supporting telerheumatology adoption prior to the pandemic, and outline several innovative approaches used to assist in the care of rheumatology patients that have been introduced. Alongside the advantages of these interventions, we discuss the limitations and regulatory challenges. Advances must be balanced, considering wider issues of equity of access, implementation, adoption, and sustainability of telerheumatology post-pandemic. We propose it is not ‘if’, but ‘how’ rheumatologists embrace newer telerheumatology technology, outlining practice points and future research agenda.",multimedia
10.1016/j.scs.2020.102692,Journal,Sustainable Cities and Society,scopus,2021-03-01,sciencedirect,SSDMNV2: A real time DNN-based face mask detection system using single shot multibox detector and MobileNetV2,https://api.elsevier.com/content/abstract/scopus_id/85098782261,"Face mask detection had seen significant progress in the domains of Image processing and Computer vision, since the rise of the Covid-19 pandemic. Many face detection models have been created using several algorithms and techniques. The proposed approach in this paper uses deep learning, TensorFlow, Keras, and OpenCV to detect face masks. This model can be used for safety purposes since it is very resource efficient to deploy. The SSDMNV2 approach uses Single Shot Multibox Detector as a face detector and MobilenetV2 architecture as a framework for the classifier, which is very lightweight and can even be used in embedded devices (like NVIDIA Jetson Nano, Raspberry pi) to perform real-time mask detection. The technique deployed in this paper gives us an accuracy score of 0.9264 and an F1 score of 0.93. The dataset provided in this paper, was collected from various sources, can be used by other researchers for further advanced models such as those of face recognition, facial landmarks, and facial part detection process.",multimedia
10.1016/j.micpro.2020.103745,Journal,Microprocessors and Microsystems,scopus,2021-03-01,sciencedirect,Face detection based on open Cl design and image processing technology,https://api.elsevier.com/content/abstract/scopus_id/85098654717,"Face detection is a system that automatically recognizes facial expressions. Extract our structure and describe its function of the contours of the eyebrows, eyes and mouth with elastic rectangles. This manual facial features are an improvement over the hybrid mask model method. For some have to reduce the recognition time and define the accuracy of the relevant cognition. Then, these vectors determine the network, which is being used to implement user facial expression and neural interactions. In short, FEID (Facial Expression Image Database) information is used in this study to determine face and face identification. 96.2% of test results and 92.8% of the FEID database show that personal facial recognition tests and official member face recognition can be approved. Face recognition 97.4% of FEID samples were widely recognized. Real-time face detection is a new method using a variety of computations. This algorithm uses the Local Binary Format (LBF) as a face detection feature vector. Code used using OpenCL units. Illumination is the use of irreversible gamma correction or Gaussian variations of different illumination conditions creating strong protocols. This implementation has proven to be faster compared to previous co-executions.",multimedia
10.1016/j.micpro.2020.103753,Journal,Microprocessors and Microsystems,scopus,2021-03-01,sciencedirect,Simulation of swimming sports image recognition based on multi-core processor and dynamic image sampling,https://api.elsevier.com/content/abstract/scopus_id/85098562935,"Human understanding of human movement is one of the most important areas of research activities. In recent years, the use of RGB-D movement recognition data has raised concerns. With artificial intelligence development, the depth of learning technology has made great success in computer vision. A variety of application scenarios and real-time constraints computer vision applications spurred on computer architecture conducted extensive research. These studies take advantage of image processing algorithms and computer vision functions to maximize and improve efficiency through the hardware's scalability. Growth, programmable computing power, and multi-core architecture's potential to accelerate parallel image processing and computer vision algorithms provide a broad prospect. Conduct a new study to discover the unique attributes of three computer vision algorithms that are widely used and determine the optimal computing architecture for each algorithm. Advantages of parallel processing hardware to provide modern programmable graphics data and the thread of instructions, which is significantly faster than the standard CPU implementation.",multimedia
10.1016/j.cogsys.2020.10.008,Journal,Cognitive Systems Research,scopus,2021-03-01,sciencedirect,A bioinspired model of short-term satiety of hunger influenced by food properties in virtual creatures,https://api.elsevier.com/content/abstract/scopus_id/85097584008,"The behavior of the human is continually changed as a consequence of various drives which human is predisposed also of your survival instinct. Among the basic drives of the human, there are the physiological needs and is precisely the hunger that motivates the food intake to get the energy that the body requires via food. The regulation of hunger allows to stop the food intake by means of the homeostatic and hedonic control which are influenced by the food properties. The process that consists of ending the food intake is known as short-term satiety and is important because it limits the amount of food intake; Otherwise, an over-consumed affect the organism functioning negatively. In this paper, we propose a conceptual model for the generation of short-term satiety behaviors based on neuroscientific evidence for virtual creatures. The conceptual model proposed is implemented in a distributed system-a virtual creature endowed with this implementation is placed in a virtual environment to analyze its behavior. The analysis shows how the virtual creature modifies its hunger level (behavior) based on food’s properties. The results show the execution of the process when the creature interacts with the environment.",multimedia
10.1016/j.cogsys.2020.11.002,Journal,Cognitive Systems Research,scopus,2021-03-01,sciencedirect,Earthquake disaster avoidance learning system using deep learning,https://api.elsevier.com/content/abstract/scopus_id/85097539429,"The popularity of deep learning has influenced the field of surveillance and human safety. We adopt the advantages of deep learning techniques to recognize potentially harmful objects inside living rooms, offices, and dining rooms during earthquakes. In this study, we propose an educational system to teach earthquake risks using indoor object recognition based on deep learning algorithms. The system is based on the You Look Only Once (YOLO) deployed on our cloud-based server named Earthquake Situation Learning System (ESLS) for the detection of harmful objects associated with risk tags. ESLS is trained on our own indoor images dataset. The user interacts with the ESLS server through video or image files, and the object detection algorithm using YOLO recognizes the indoor objects with associated risk tags. Results show that the service time of ESLS is low enough to serve it to users in 0.8 s on average, including processing and communication times. Furthermore, the accuracy of the harmful object detection is 96% in the general indoor lighting situation. The results show that the proposed ESLS is applicable to real service for teaching the earthquake disaster avoidance.",multimedia
10.1016/j.jobe.2020.101970,Journal,Journal of Building Engineering,scopus,2021-03-01,sciencedirect,The construction workers’ preference and acceptance of innovations in data provision: A stated choice experiment study in the Netherlands,https://api.elsevier.com/content/abstract/scopus_id/85097058802,"Building information modeling (BIM) and Augmented Reality (AR) have many potential benefits if it can be implemented on the construction site. However, the adoption is very limited so far. Till now, construction workers get information mostly in a paper-based format, which is an obstacle for innovation implementation on site. To identify which forms of data provision are more preferred, and which attributes would influence construction workers’ acceptance of innovations on-site, this paper reports the results of two stated choice experiments using discrete choice methods. A total of 160 valid respondents were recruited from construction sites in the Netherlands to complete an online experiment. The mixed logit (ML) model was estimated to unravel construction workers’ preferences. The results show that construction workers are willing to accept new forms of data provision and new technologies in general. They are more likely to accept innovation if there is enough guidance.",multimedia
10.1016/j.future.2020.10.011,Journal,Future Generation Computer Systems,scopus,2021-03-01,sciencedirect,Human action identification by a quality-guided fusion of multi-model feature,https://api.elsevier.com/content/abstract/scopus_id/85094321431,"Human motion recognition has become an active research area in the field of computer vision due to its wide range of implementations in domains of video monitoring, virtual reality, human–machine interaction. Dealing with the problem that the RGB images cannot provide enough depth information, a multi-modal depth neural network based on joint cost function is proposed for human motion recognition. In the architecture, the features of the RGB video frames are extracted by the 3D CNN architecture while the characteristics of human motion recognition in the SSDDI graphics utilizing depth map are extracted by the LSTM. Moreover, the model utilizes joint cost function including the cross-entropy loss and the distance constraint between the feature space of training samples and their center values within each category. The experimental results on the MSR Action 3D datasets suggest that the proposed model demonstrates a higher accuracy rate than do the other competing models.",multimedia
10.1016/j.icte.2020.07.008,Journal,ICT Express,scopus,2021-03-01,sciencedirect,Real-time license plate detection for non-helmeted motorcyclist using YOLO,https://api.elsevier.com/content/abstract/scopus_id/85089865524,"Nowadays, detection of license plate (LP) for non-helmeted motorcyclist has become mandatory to ensure the safety of the motorcyclists. This paper presents the real-time detection of LP for non-helmeted motorcyclist using the real-time object detector YOLO (You Only Look Once). In this proposed approach, a single convolutional neural network was deployed to automatically detect the LP of a non-helmeted motorcyclist from the video stream. The centroid tracking method with a horizontal reference line was used to eliminate the false positive generated by the helmeted motorcyclist as they leave the video frames. The overall LP detection rate was 98.52%.",multimedia
10.1016/j.ijom.2020.07.025,Journal,International Journal of Oral and Maxillofacial Surgery,scopus,2021-03-01,sciencedirect,Feasibility of virtual surgical simulation in the head and neck region for soft tissue reconstruction using free flap: a comparison of preoperative and postoperative volume measurement,https://api.elsevier.com/content/abstract/scopus_id/85089486283,"In the head and neck region, preoperative evaluation of the free flap volume is challenging. The current study validated preoperative three-dimensional (3D) virtual surgical simulation for soft tissue reconstruction by assessing flap volume and evaluated fat and muscle volume changes at follow-up in 13 head and neck cancer patients undergoing anterolateral craniofacial resection. Patients received 3D virtual surgical simulation, and the volume of the planned defects was estimated by surgical simulation. Following en bloc resection of the tumor, the defect in the skull base was covered using a rectus abdominis myocutaneous flap. Following surgery, computed tomography scans were acquired at day 1 and at 6 and 12 months. Virtual planned defect was on average 227 ml (range, 154–315) and was 10% smaller than the actual flap volume in patients without skin involvement of the tumor. Between day 1 and 12 months post-surgery, the volume of fat and muscle tissue in the free flap dropped by 9% and 58%, respectively. Our results indicate that 3D virtual surgical simulation provides essential information in determining the accurate volume of the required free flap for surgical defect repair and may thus help improve surgical planning and functional and esthetic outcome.",multimedia
10.1016/j.neuron.2020.11.021,Journal,Neuron,scopus,2021-02-17,sciencedirect,Using deep reinforcement learning to reveal how the brain encodes abstract state-space representations in high-dimensional environments,https://api.elsevier.com/content/abstract/scopus_id/85099151634,"Humans possess an exceptional aptitude to efficiently make decisions from high-dimensional sensory observations. However, it is unknown how the brain compactly represents the current state of the environment to guide this process. The deep Q-network (DQN) achieves this by capturing highly nonlinear mappings from multivariate inputs to the values of potential actions. We deployed DQN as a model of brain activity and behavior in participants playing three Atari video games during fMRI. Hidden layers of DQN exhibited a striking resemblance to voxel activity in a distributed sensorimotor network, extending throughout the dorsal visual pathway into posterior parietal cortex. Neural state-space representations emerged from nonlinear transformations of the pixel space bridging perception to action and reward. These transformations reshape axes to reflect relevant high-level features and strip away information about task-irrelevant sensory features. Our findings shed light on the neural encoding of task representations for decision-making in real-world situations.",multimedia
10.1016/j.abb.2020.108730,Journal,Archives of Biochemistry and Biophysics,scopus,2021-02-15,sciencedirect,Artificial intelligence in the early stages of drug discovery,https://api.elsevier.com/content/abstract/scopus_id/85098095696,"Although the use of computational methods within the pharmaceutical industry is well established, there is an urgent need for new approaches that can improve and optimize the pipeline of drug discovery and development. In spite of the fact that there is no unique solution for this need for innovation, there has recently been a strong interest in the use of Artificial Intelligence for this purpose. As a matter of fact, not only there have been major contributions from the scientific community in this respect, but there has also been a growing partnership between the pharmaceutical industry and Artificial Intelligence companies. Beyond these contributions and efforts there is an underlying question, which we intend to discuss in this review: can the intrinsic difficulties within the drug discovery process be overcome with the implementation of Artificial Intelligence? While this is an open question, in this work we will focus on the advantages that these algorithms provide over the traditional methods in the context of early drug discovery.",multimedia
10.1016/j.ins.2020.08.099,Journal,Information Sciences,scopus,2021-02-04,sciencedirect,Linearly augmented real-time 4D expressional face capture,https://api.elsevier.com/content/abstract/scopus_id/85091116255,"Personalised 3D face creation has always been a hot topic in the computer vision community. Many methods have been proposed including the statistic model, the non-rigid registration and high-end depth acquisition equipment. However, in practical applications, those existing methods still have their own limitations. For example, the performance of the statistic model-based methods highly depends on the generality of the pre-trained statistic model; the non-rigid registration based methods are sensitive to the quality of input data; the high-end equipment-based methods are less able to be popularised due to the expensive equipment costs; the deep learning-based methods can only perform well if proper training data provided for the target domain, and require GPU for better performance. To this end, this paper presents an adaptive template augmented method that can automatically obtain a personalised 4D facial modelling only using a consumer-grade device. The noisy data from such a cheap device are well handled. The whole process consists of a series of linear solutions and can be achieved in real-time for online processing only based on the CPU computation on a laptop. There is no constraint nor complex operation required by the proposed method. No additional time-consumptive pre- or post-processing for the personalisation is needed. Comparisons against several existing methods demonstrate the superiority of the proposed method.",multimedia
10.1016/j.cageo.2020.104642,Journal,Computers and Geosciences,scopus,2021-02-01,sciencedirect,Real-time water level monitoring using live cameras and computer vision techniques,https://api.elsevier.com/content/abstract/scopus_id/85098225043,"Characterizing urban hydrographs during rain storms, hurricanes, and river floods is important to decrease loss of lives and assist emergency responders with mapping disruptions to operation of major cities. High water marks, stream gages, and rapidly deployed instrumentation are the current state-of-practice for hydrological data during a flood event. The objective of this study was to develop technology that can provide accurate and timely flood hydrographs while harnessing the Big Data generated from videos and images. In particular, levels are predicted from images by using reference objects as a scale. The novelty of this work involved leveraging object-based image analysis (OBIA), which used image segmentation training algorithms to differentiate areas of images or videos. In particular, the deep learning-based semantic segmentation technique was trained using images from an MIT database along with images compiled from traffic cameras and the experiments and a case study. The fully convolutional network was used for image segmentation and subsequent object labeling. This algorithm was applied to a laboratory and two field experiments before demonstration at Buffalo Bayou in Houston, TX during Hurricane Harvey. The laboratory and field experiments indicated that the image segmentation technique was reproducible and accurate from a controlled environment to rain storms and localized flooding in small streams on the LSU campus. Moreover, the segmentation algorithm successfully estimated flood levels in Buffalo Bayou in downtown Houston, Texas during Hurricane Harvey. This signifies that if time-lapse imagery is available, this algorithm- and program-estimated water elevations can provide insight to the hydrograph and spatial inundation during flooding from rainstorms or hurricanes.",multimedia
10.1016/j.micpro.2020.103562,Journal,Microprocessors and Microsystems,scopus,2021-02-01,sciencedirect,Application of 3Ds Max and virtual reality technology in 3D submarine scene modeling,https://api.elsevier.com/content/abstract/scopus_id/85097355006,"With the advancement and augmented reality innovation, its applications are getting increasingly far-reaching. The 3D show innovation appropriate to this work is the checking of submarine pipelines. It is a basic database “submarine pipeline” that reconstructs the submarine pipeline, shows a PC in a virtual scene of the submarine pipeline dependent on augmented reality, and encompasses submarine topography displays related data. And associated terrain and landscape integrated database engine “using rendering with 3D graphics Surveillance and collection of submarine pipelines. Similarly, mappings can mainly use their derivatives in 2D map views with GIS software digital elevation models (such as tilt or shadow grids). As a result, submarine research lacks an on-site research phase of classic works on land, allowing clear visualization and appreciation of the study subject. Development of traditional educational theories based on FPGAs and neural networks (NN). A summary of your experience when taught. In reality, it's easy to find a universal educational model.",multimedia
10.1016/j.ijmedinf.2020.104348,Journal,International Journal of Medical Informatics,scopus,2021-02-01,sciencedirect,Towards effective machine learning in medical imaging analysis: A novel approach and expert evaluation of high-grade glioma ‘ground truth’ simulation on MRI,https://api.elsevier.com/content/abstract/scopus_id/85097334964,"Purpose/objective(s)
                  Gliomas are uniformly fatal brain tumours with significant neurological and quality of life detriment to patients. Improvement in outcomes has remained largely unchanged in nearly 20 years. MRI (magnetic resonance imaging) is often used in diagnosis and management. Machine learning analyses of large-scale MRI data are pivotal in advancing the diagnosis, management and improve outcomes in neuro-oncology. A common challenge to robust machine learning approaches is the lack of large ‘ground truth’ datasets in supervised learning for building classification and prediction models. The creation of these datasets relies on human-expert input and is time-consuming and subjective error-prone, limiting effective machine learning applications. Simulation of mechanistic aspects such as geometry, location and physical properties of brain tumours can generate large-scale ground-truth datasets allowing for comparison of analysis techniques in clinical applications. We aimed to develop a transparent and convenient method for building ‘ground truth’ presentations of simulated glioma lesions on anatomical MRI.
               
                  Materials/methods
                  The simulation workflow was created using the Feature Manipulation Engine (FME®), a data integration platform specializing in the spatial data processing. By compiling and integrating FME’s functions to read, integrate, transform, validate, save, and display MRI data, and experimenting with ways to manipulate the parameters concerning location, size, shape, and signal intensity with the presentations of glioma, we were able to generate simulated appearances of high-grade gliomas on gadolinium-based high-resolution 3D T1-weighted MRI (1 mm3). Data of patients with canonical high-grade tumours were used as real-world tumours for validating the accuracy of the simulation. Twenty raters who are experienced with brain tumour interpretation on MRI independently completed a survey, designed to distinguish simulated and real-world brain tumours. Sensitivity and specificity were calculated for assessing the performance of the approach with the binary classification of simulated vs real-world tumours. Correlation and regression were used in run time analysis, assessing the software toolset’s efficiency in producing different numbers of simulated lesions. Differences in the group means were examined using the non-parametric Kruskal-Wallis test.
               
                  Results
                  The simulation method was developed as an interpretable and useful workflow for the easy creation of tumour simulations and incorporation into 3D MRI. A linear increase in the running time and memory usage was observed with an increasing number of generated lesions. The respondents' accuracy rate ranged between 33.3 and 83.3 %. The sensitivity and specificity were low for a human expert to differentiate simulated lesions from real gliomas (0.43 and 0.58) or vice versa (0.65 and 0.62). The mean scores ranking the real-world gliomas did not differ between the simulated and real tumours.
               
                  Conclusion
                  The reliable and user-friendly software method can allow for robust simulation of high-grade glioma on MRI. Ongoing research efforts include optimizing the workflow for generating glioma datasets as well as adapting it to simulating additional MRI brain changes.",multimedia
10.1016/j.future.2020.09.001,Journal,Future Generation Computer Systems,scopus,2021-02-01,sciencedirect,Formal approach to thwart against drone discovery attacks: A taxonomy of novel 3D obfuscation mechanisms,https://api.elsevier.com/content/abstract/scopus_id/85091758369,"The pervasive capabilities and myriad of mission performance abilities of Unmanned (Combat) Aerial Vehicles (UAVs/UCAVs) have exponentially grown their deployment possibilities in the recent past. Advancements in artificial intelligence, sensing technologies and autonomous guidance, navigation and control capabilities have further fueled wide-scale deployments of UAVs, both for military and commercial applications, ranging from autonomous air taxis and cargo deliveries to intelligence surveillance, reconnaissance, and combat missions. Most of these applications consume Global Navigation Satellite System (GNSS) based location information for their services, which is also shared in real-time with ground control stations and centralized service operators, often using insecure communication channels. This limitation has significantly raised the location privacy concerns of aerial vehicles, deployed to conduct user-centric, safety-critical and localization-sensitive operations. A compromise of location privacy of a UAV can pose serious threats, including stalking, theft or damage of UAV/payload or even use of GNSS-guided munitions. These emerging threats call for robust and trust-worthy solutions for preserving the location privacy of aerial vehicles.
                  This paper proposes a novel obfuscation-based mechanism to safeguard location information against privacy attacks. Our proposed solution conceals actual information by transmitting modified location parameters, either after diluting their accuracy or by fabricating deceptive trajectories for a known eavesdropper. Based on these two broad categories, defined as Attenuation and Deception-based obfuscation techniques respectively, we also present a novel taxonomy of 3D obfuscation mechanisms, supported by formal descriptions of underlying operators. The operators can be used independently or in conjunction to satisfy diverse mission-specific obfuscation profiles. The proposed operators have been practically implemented and evaluated using a customizable obfuscator deployed over a Global Positioning System (GPS) guided UAV. The field experiments validate the efficacy, security and deployability of the proposed solution against location-privacy threats.",multimedia
10.1016/j.eswa.2020.113994,Journal,Expert Systems with Applications,scopus,2021-02-01,sciencedirect,Recognizing activities of daily living from UWB radars and deep learning,https://api.elsevier.com/content/abstract/scopus_id/85091642318,"Since years, the number of seniors increases while, at the same time, we observe a diminution of the potential support ratio. In order to overcome this limitation, solutions emerged, such as smart homes and wearable devices. Smart homes integrate sensors, actuators, and artificial intelligence to assist seniors in their everyday life. One of the objectives is to recognize the activities of everyday life. This recognition aims to provide the right assistance at the right moment and gives some autonomy to seniors. However, it is a complex task (a significant quantity of different sensors, hardware implementation), and the number of solutions (combinations between approaches, for example, video-based HAR and wearable sensors-based HAR) that exist is important. In this paper, we propose to perform the activity recognition from three ultra-wideband (UWB) radars, deep learning models, and a voting system. Also, all the experiments have been conducted in a real apartment and are composed of 15 different activities. The presented solution is simple compared to the literature since we exploit only one type of sensor. Finally, we obtained promising results with our approach. Indeed, the classification rate reaches 90% and more in some cases.",multimedia
10.1016/j.rcim.2020.102029,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2021-02-01,sciencedirect,Towards manufacturing robotics accuracy degradation assessment: A vision-based data-driven implementation,https://api.elsevier.com/content/abstract/scopus_id/85088120602,"In this manuscript we report on a vision-based data-driven methodology for industrial robot health assessment. We provide an experimental evidence of the usefulness of our methodology on a system comprised of a 6-axis industrial robot, two monocular cameras and five binary squared fiducial markers. The fiducial marker system permits to accurately track the deviation of the end-effector along a fixed non-trivial trajectory. Moreover, we monitor the trajectory deflection using three gradually increasing weights attached to the end-effector. When the robot is loaded with the maximum allowed payload, a deviation of 0.77mm is identified in the Z-coordinate of the end-effector. Tracing trajectory information, we train five supervised learning regression models. Such models are afterwards used to predict the deviation of the end-effector, using the pose estimation provided by the visual tracking system. As a result of this study, we show that this procedure is a stable, robust, rigorous and reliable tool for robot trajectory deviation estimation and it even allows to identify the mechanical element producing non-kinematic errors.",multimedia
10.1016/j.ejso.2020.04.010,Journal,European Journal of Surgical Oncology,scopus,2021-02-01,sciencedirect,Peroperative personalised decision support and analytics for colon cancer surgery- Short report,https://api.elsevier.com/content/abstract/scopus_id/85083856433,"Advanced instrumentation whether robotic or non-robotic- hasn't itself made for better surgery as all critical measures of operative success depend still on intraoperative surgeon judgement and decision-making. Computer assisted surgery, or digital surgery, refers to the combination of technology with real-time data during an operation and is often assumed to need new hardware platforms to become a reality. However, methods to support personalised surgical endeavour exist now and can be deployed today within standard laparoscopic paradigms. Here we describe in detail the rationale for the deployment of such assistance for surgical step-advancement in our current practice evolution from traditional proximal colon cancer resection to complete mesocolic excision focussing on personalised 3d anatomical display, intraoperative, quantificative fluorescence assessment of intracorporeal anastomoses and postoperative digital feedback to enable reflection and identify areas of technical improvement.",multimedia
10.1016/j.compeleceng.2021.107570,Journal,Computers and Electrical Engineering,scopus,2021-01-01,sciencedirect,A social media-based over layer on the edge for handling emergency-related events,https://api.elsevier.com/content/abstract/scopus_id/85118991700,"Online Social Networks (OSNs), together with messaging services are tools for the exchange of entertainment-related information. However, they represent virtual environments capable of providing relevant information related to emergency or criminal events. Thanks to the simple way of using OSNs in combination to modern ubiquitous Internet of Things (IoT) smart devices, the generation and exploitation of such information is made available to users in real-time even more easily. Unfortunately, its reuse has not been taken into consideration yet due to the lack of specific models and related software tools. In this context, the paper presents a social media-based over layer for supporting the monitoring, detection, computation and information sharing of social media information related to emergency scenarios centered on smartphones and text mining techniques. The proposal is assessed through two different case studies, by evaluating the performances of different classifiers and by showing the logic of the functionalities of the related apps.",multimedia
10.1016/j.aap.2021.106473,Journal,Accident Analysis and Prevention,scopus,2021-01-01,sciencedirect,Mining patterns of autonomous vehicle crashes involving vulnerable road users to understand the associated factors,https://api.elsevier.com/content/abstract/scopus_id/85118989110,"Autonomous or automated vehicles (AVs) have the potential to improve traffic safety by eliminating majority of human errors. As the interest in AV deployment increases, there is an increasing need to assess and understand the expected implications of AVs on traffic safety. Until recently, most of the literature has been based on either survey questionnaires, simulation analysis, virtual reality, or simulation to assess the safety benefits of AVs. Although few studies have used AV crash data, vulnerable road users (VRUs) have not been a topic of interest. Therefore, this study uses crash narratives from four-year (2017–2020) of AV crash data collected from California to explore the direct and indirect involvement of VRUs. The study applied text network and compared the text classification performance of four classifiers - Support Vector Machine (SVM), Naïve Bayes (NB), Random Forest (RF), and Neural Network (NN) and associated performance metrics to attain the objective. It was found that out of 252 crashes, VRUs were, directly and indirectly, involved in 23 and 12 crashes, respectively. Among VRUs, bicyclists and scooterists are more likely to be involved in the AV crashes directly, and bicyclists are likely to be at fault, while pedestrians appear more in the indirectly involvements. Further, crashes that involve VRUs indirectly are likely to occur when the AVs are in autonomous mode and are slightly involved minor damages on the rear bumper than the ones that directly involve VRUs. Additionally, feature importance from the best performing classifiers (RF and NN) revealed that crosswalks, intersections, traffic signals, movements of AVs (turning, slowing down, stopping) are the key predictors of the VRUs-AV related crashes. These findings can be helpful to AV operators and city planners.",multimedia
10.1016/j.dcan.2021.09.002,Journal,Digital Communications and Networks,scopus,2021-01-01,sciencedirect,RFID-based 3D human pose tracking: A subject generalization approach,https://api.elsevier.com/content/abstract/scopus_id/85118155761,"Three-dimensional (3D) human pose tracking has recently attracted increased attention in the computer vision field. Real-time pose tracking is highly useful in various domains such as video surveillance, somatosensory games, and human-computer interaction. However, vision-based pose tracking techniques usually raise privacy concerns, making human pose tracking without vision data usage an important problem. Thus, we propose using Radio Frequency Identification (RFID) as a pose tracking technique via a low-cost wearable sensing device. Although our prior work illustrated how deep learning could transfer RFID data into real-time human poses, generalization for different subjects remains challenging. This paper proposes a subject-adaptive technique to address this generalization problem. In the proposed system, termed Cycle-Pose, we leverage a cross-skeleton learning structure to improve the adaptability of the deep learning model to different human skeletons. Moreover, our novel cycle kinematic network is proposed for unpaired RFID and labeled pose data from different subjects. The Cycle-Pose system is implemented and evaluated by comparing its prototype with a traditional RFID pose tracking system. The experimental results demonstrate that Cycle-Pose can achieve lower estimation error and better subject generalization than the traditional system.",multimedia
10.1016/j.procs.2021.08.095,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,SODA: A real-time simulation framework for object detection and analysis in smart manufacturing,https://api.elsevier.com/content/abstract/scopus_id/85116946450,"For modern manufacturing firms, automation has already become a norm but constantly needs to be improved as firms still face strong demand to increase their productivity. This can be achieved by reducing dependability on manpower, reaching lean and even unmanned production and this is where some of the standards of Industry 4.0 come in useful, not to mention: Machine Vision, Image Recognition or Machine Learning. In our paper, we present SODA – our approach to build a flexible ML and AI enabled framework for object detection, analysis, and simulation. The framework is designed to support a development process of solutions requiring real-time analysis of images of different types of moving objects on a conveyor belt. In our work we discuss architectural challenges of the developed framework as well as the basic components of the system. We do also provide information on how to use the framework and present a sample implementation of an actual system employing some of the machine learning methods.",multimedia
10.1016/j.procs.2021.08.091,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Towards accessibility in education through smart speakers. An ontology based approach,https://api.elsevier.com/content/abstract/scopus_id/85116916475,"As the world changes, so does the future of our students. In this respect, the evolution of the technology comes up with specific environments for educational purpose. Building smart learning environments supported by e-learning platforms is an important area of research in education domain within our days. The evolution of these smart learning environments is justified by some events (Covid19) that force students to learn remotely.
                  The paper proposes a formalisation using ontology for providing an inclusive approach of universities’ websites, having as instance a software application component using Alexa smart speaker, that currently remains at a design level, which integrates different services (Amazon Web Services, Microsoft Services) for a proper virtual environment platform, for both students and teachers. It addresses the main concerns of the current educational system and provides a smart solution through the use of Artificial Intelligence based tools. The proposed approach not only achieves unifying data and knowledge-share mechanisms in a remotely mode, but it brings also a good learning experience, increasing the effectiveness and the efficiency of the learning process.",multimedia
10.1016/j.procs.2021.09.233,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,A note on the applications of artificial intelligence in the hospitality industry: Preliminary results of a survey,https://api.elsevier.com/content/abstract/scopus_id/85116885410,"Intelligent technologies are widely implemented in different areas of modern society but specific approaches should be applied in services. Basic relationships refer to supporting customers and people responsible for services offering for these customers. The aim of the paper is to analyze and evaluate the state-of-the art of artificial intelligence (AI) applications in the hospitality industry. Our findings show that the major deployments concern in-person customer services, chatbots and messaging tools, business intelligence tools powered by machine learning, and virtual reality & augmented reality. Moreover, we performed a survey (n = 178), asking respondents about their perceptions and attitudes toward AI, including its implementation within a hotel space. The paper attempts to discuss how the hotel industry can be motivated by potential customers to apply selected AI solutions. In our opinion, these results provide useful insights for understanding the phenomenon under investigation. Nevertheless, since the results are not conclusive, more research is still needed on this topic. Future studies may concern both qualitative and quantitative methods, devoted to developing models that: a) quantify the potential benefits and risks of AI implementations, b) determine and evaluate the factors affecting the AI adoption by the customers, and c) measure the user (guest) experience of the hotel services, fueled by AI-based technologies.",multimedia
10.1016/j.avsg.2021.05.010,Journal,Annals of Vascular Surgery,scopus,2021-01-01,sciencedirect,Feasibility of the Application of Holographic Augmented Reality in Endovascular Surgery Using Microsoft HoloLens Head-Mounted Display,https://api.elsevier.com/content/abstract/scopus_id/85110411894,"Objectives
                  Advances in virtual, augmented (AR) and mixed reality have led to the development of wearable technologies including head mounted displays (HMD). The aim of this study was to investigate the feasibility to use HMD during endovascular surgery.
               
                  Methods
                  We propose an adaptation of AR-HMD using Microsoft HoloLens. Software was developed to enable visualization of the vascular system during endovascular procedures. A video was performed to present an overview of the device and show its use in real conditions.
               
                  Results
                  The device allowed a successful visualization of perioperative angiography during peripheral angioplasty, carotid angioplasty and aortic aneurysm endovascular repair. The device was operated on voice command, preserving the environment sterility.
               
                  Conclusion
                  This video illustrated the feasibility of the application of holographic AR during endovascular intervention and brings perspectives to use artificial-intelligence derived tools for image-guided surgery.",multimedia
10.1016/j.procir.2021.05.031,Conference Proceeding,Procedia CIRP,scopus,2021-01-01,sciencedirect,Artificial intelligence enhanced interaction in digital twin shop-floor,https://api.elsevier.com/content/abstract/scopus_id/85107885361,"As an enabling technology for smart manufacturing, digital twin has been widely applied in manufacturing shop-floor. A great deal of research focuses on the key issues in implementing digital twin shop-floor (DTS), including scheduling, production planning, fault diagnosis and prognostics. However, DTS puts forward higher requirements in terms of real-time interaction. Artificial intelligence (AI), as an effective approach to improve the intelligence of the physical shop-floor, provides a new method to meet the above requirements. In this paper, a framework of AI-enhanced DTS in interaction is proposed. AI-enhanced DTS improves the real-time interaction through predictive control. The implementation mechanism of AI-enhanced interaction in DTS is also presented in detail. Enabling technologies for interaction in DTS are introduced at last.",multimedia
10.1016/j.csbj.2021.05.043,Journal,Computational and Structural Biotechnology Journal,scopus,2021-01-01,sciencedirect,Screening of world approved drugs against highly dynamical spike glycoprotein of SARS-CoV-2 using CaverDock and machine learning,https://api.elsevier.com/content/abstract/scopus_id/85107709300,"The new severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) causes pathological pulmonary symptoms. Most efforts to develop vaccines and drugs against this virus target the spike glycoprotein, particularly its S1 subunit, which is recognised by angiotensin-converting enzyme 2. Here we use the in-house developed tool CaverDock to perform virtual screening against spike glycoprotein using a cryogenic electron microscopy structure (PDB-ID: 6VXX) and the representative structures of five most populated clusters from a previously published molecular dynamics simulation. The dataset of ligands was obtained from the ZINC database and consists of drugs approved for clinical use worldwide. Trajectories for the passage of individual drugs through the tunnel of the spike glycoprotein homotrimer, their binding energies within the tunnel, and the duration of their contacts with the trimer’s three subunits were computed for the full dataset. Multivariate statistical methods were then used to establish structure-activity relationships and select top candidate for movement inhibition. This new protocol for the rapid screening of globally approved drugs (4359 ligands) in a multi-state protein structure (6 states) showed high robustness in the rate of finished calculations. The protocol is universal and can be applied to any target protein with an experimental tertiary structure containing protein tunnels or channels. The protocol will be implemented in the next version of CaverWeb (https://loschmidt.chemi.muni.cz/caverweb/) to make it accessible to the wider scientific community.",multimedia
10.1016/j.nicl.2021.102707,Journal,NeuroImage: Clinical,scopus,2021-01-01,sciencedirect,icobrain ms 5.1: Combining unsupervised and supervised approaches for improving the detection of multiple sclerosis lesions,https://api.elsevier.com/content/abstract/scopus_id/85107640291,"Multiple sclerosis (MS) is a chronic autoimmune, inflammatory neurological disease of the central nervous system. Its diagnosis nowadays commonly includes performing an MRI scan, as it is the most sensitive imaging test for MS. MS plaques are commonly identified from fluid-attenuated inversion recovery (FLAIR) images as hyperintense regions that are highly varying in terms of their shapes, sizes and locations, and are routinely classified in accordance to the McDonald criteria. Recent years have seen an increase in works that aimed at development of various semi-automatic and automatic methods for detection, segmentation and classification of MS plaques. In this paper, we present an automatic combined method, based on two pipelines: a traditional unsupervised machine learning technique and a deep-learning attention-gate 3D U-net network. The deep-learning network is specifically trained to address the weaker points of the traditional approach, namely difficulties in segmenting infratentorial and juxtacortical plaques in real-world clinical MRIs. It was trained and validated on a multi-center multi-scanner dataset that contains 159 cases, each with T1 weighted (T1w) and FLAIR images, as well as manual delineations of the MS plaques, segmented and validated by a panel of raters. The detection rate was quantified using lesion-wise Dice score. A simple label fusion is implemented to combine the output segmentations of the two pipelines. This combined method improves the detection of infratentorial and juxtacortical lesions by 14% and 31% respectively, in comparison to the unsupervised machine learning pipeline that was used as a performance assessment baseline.",multimedia
10.1016/j.mex.2021.101378,Journal,MethodsX,scopus,2021-01-01,sciencedirect,An FPGA-based IP for recognizing violence against children,https://api.elsevier.com/content/abstract/scopus_id/85106383581,"We present in this paper an FPGA-based IP for recognizing most common violent actions against children (VACR IP). VACR IP uses only skeleton joints data as inputs to keep the privacy of people inside their homes or in the schools. The proposed hardware achieved a detection rate of 97.72%, processing speed 761FPS, and a latency value equals to 2.79msec using a 50MHz system clock.
                  In sum, this research method presents:
                        
                           •
                           First FPGA-based IP for recognizing most common child abuses without any privacy breach of people real images by using only skeleton joints data.
                        
                        
                           •
                           The IP can detect the violence and the type of the violent action.
                        
                        
                           •
                           The IP can be embedded in complete systems to be installed in schools by school psychologists and counselors.",multimedia
10.1016/j.procir.2021.01.115,Conference Proceeding,Procedia CIRP,scopus,2021-01-01,sciencedirect,Development of a Decision Support System for 3D Printing Processes based on Cyber Physical Production Systems,https://api.elsevier.com/content/abstract/scopus_id/85102637852,"3D printing, an additive manufacturing (AM) technology, potentially provides sustainability advantages such as less waste generation, lightweight geometries, reduced material and energy consumption, lower inventory waste, etc. This paper proposes a decision support system for the 3D printing process based on Cyber Physical Production System (CPPS). The user is enabled to dynamically assess the carbon footprint based on the energy and material usage for their 3D printed object. A CPPS framework for the environmental sustainability of the 3D printing process is presented, which supports the derivation of improved strategies for product design and production. A physical world for 3D printing is used with the internet of things (IoT) devices like sensor node, webcam, smart plugs, and raspberry pi to host printer Management Software (PMS) for real-time monitoring and control of material and energy consumption during the printing process. Experiments have been conducted based on Taguchi L9 orthogonal array with polylactic Acid (PLA) as a filament material to estimate the product-related manufacturing energy consumption with the carbon footprint. The proposed framework can be effectively used by the users to supports the decision-making process for saving resources and energy; and minimizing the effect on the environment.",multimedia
10.1016/j.procir.2021.01.010,Conference Proceeding,Procedia CIRP,scopus,2021-01-01,sciencedirect,Analysis of Barriers to Industry 4.0 adoption in Manufacturing Organizations: An ISM Approach,https://api.elsevier.com/content/abstract/scopus_id/85102622489,"Industry 4.0 has enabled technological integration of cyber physical systems and internet based communication in manufacturing value creation processes. As of now, many people use it as a collective term for advanced technologies, i.e. advanced robotics, artificial intelligence, machine learning, big data analytics, cloud computing, smart sensors, internet of things, augmented reality, etc. This substantially improves flexibility, quality, productivity, cost, and customer satisfaction by transforming existing centralized manufacturing systems towards digital and decentralized one. Despite having potential benefits of industry 4.0, the organizations are facing typical obstacles and challenges in adopting new technologies and successful implementation in their business models. This paper aims to identify potential barriers which may hinder the implementation of industry 4.0 in manufacturing organizations. The identified barriers, through comprehensive literature review and on the basis of opinions collected from industry experts, are: poor value-chain integration, cyber-security challenges, uncertainty about economic benefits, lack of adequate skills in workforce, high investment requirements, lack of infrastructure, jobs disruptions, challenges in data management and data quality, lack of secure standards and norms, and resistance to change. Interpretive Structural Modeling (ISM) is used to establish relationships among these barriers to develop a hierarchical model and MICMAC analysis for further classification of identified barriers for better understanding. An analysis of driving and dependence of the barriers may help in clear understanding of these for successful implementation of Industry 4.0 practices in the organizations.",multimedia
10.1016/j.procs.2021.01.348,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Procedure model for the development and launch of intelligent assistance systems,https://api.elsevier.com/content/abstract/scopus_id/85101779152,"The paper analyses the current state of knowledge on approaches for the practical implementation of machine learning based assistance systems for production planning and control.
                  A concept of a procedure model for application-oriented projects in the field of industrial series production is proposed. It focusses on order sequencing and machine allocation in a real time production environment. As part of an application-oriented research project, a use case is referenced. In this paper, a first conceptual approach is presented, using the example of an industrial production of printed circuit boards.
                  In the following steps, practical suitability is checked on the basis of the practical reference, conclusions are drawn and the methodology will be developed further. The aim is a generally valid procedure model for industrial series production.",multimedia
10.1016/j.procs.2021.01.065,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Implementation of Real-Time Speech Separation Model Using Time-Domain Audio Separation Network (TasNet) and Dual-Path Recurrent Neural Network (DPRNN),https://api.elsevier.com/content/abstract/scopus_id/85101750391,"The purpose of this research is to develop a model that is able to perform real-time speaker independent multi-talker speech separation task in time-domain using Time-Domain Audio Separation Network (TasNet) and Dual-Path Recurrent Neural Network (DPRNN). This research will conduct experiments on some RNN architectures, number of batch size, and optimizers as hyper-parameters in order to implement TasNet and DPRNN. This research also try to analyze the impact of these hyperparameters setup on model performance. The expected result of this research is a more accurate model and lower latency to complete speaker independent multi-talker speech separation task in real-time than previous research model.",multimedia
10.1016/j.tige.2020.09.001,Journal,Techniques and Innovations in Gastrointestinal Endoscopy,scopus,2021-01-01,sciencedirect,Training for Advanced Endoscopic Imaging in Gastrointestinal Diseases,https://api.elsevier.com/content/abstract/scopus_id/85100680745,"Advanced endoscopic imaging is an emerging field in endoscopy practice, especially in optical diagnosis. Current technologies like virtual chromoendoscopy and small-field technologies allow visualization of subtle changes in mucosal and vascular patterns that are predictive of histology. The limiting factor in broadly utilizing these techniques is training and the need for reliable detection of these subtleties. This review provides the current evidence and limitations of training in advanced endoscopic imaging, and future directions of learning. A literature search was performed on PubMed and Medline through March 2020 with relevant keywords as advanced endoscopic imaging, training, and learning. References of relevant articles were screened for additional literature. Several didactic and web-based education programs are developed for training in virtual chromoendoscopy, autofluorescence imaging, confocal laser endomicroscopy, and volumetric laser endomicroscopy. Studies and post-hoc analysis on learning curves showed relatively steep learning curves after training, and web-based education seems to be as valuable as in-person didactic training for most techniques. However, consistent performance on expert level after training has not yet been demonstrated. Most advanced endoscopic imaging techniques are learned within a reasonable timeframe. Future efforts to enhance training and implementation of these techniques should focus on developing standardized and broadly incorporated training programs. The future role of artificial intelligence-assistance in advanced endoscopy and training has to be elucidated.",multimedia
10.1016/j.patrec.2020.09.032,Journal,Pattern Recognition Letters,scopus,2021-01-01,sciencedirect,Gradient clustering algorithm based on deep learning aerial image detection,https://api.elsevier.com/content/abstract/scopus_id/85098118591,"In recent years, computer vision, especially deep learning, has been widely used in various fields. Through the deep learning aerial image detection gradient clustering algorithm automatic recognition, it can solve the limitations of manual shooting by humans, can shoot from a high altitude to a panoramic view of a specific area, and provide a more comprehensive solution. The traditional forest resource management and management work is mainly carried out by forestry personnel to carry out a large number of investigations and investigations on the forest. This method not only consumes a lot of manpower and material resources, but also does not have real-time nature. It is difficult to deal with all kinds of forest management. Problems, causing unnecessary losses. In this regard, this paper proposes an aerial image change detection algorithm based on H-KFCM, and designs related experiments to verify and demonstrate the performance of the algorithm. In this paper, we conduct a parallel study based on deep learning on the gradient clustering algorithm of deep learning in aerial image processing. By using CUDA (Compute Unified Device Architecture) to perform large-scale parallel processing of aerial data. Can greatly shorten the time to obtain results, improve the efficiency of relevant personnel. Experiment analysis. It can be seen from the results that the deep learning parallelization program implemented in this paper has a faster calculation speed and uses less time in high-resolution images, and has a good acceleration ratio compared to the CPU.",multimedia
10.1016/j.psychres.2020.113585,Journal,Psychiatry Research,scopus,2021-01-01,sciencedirect,"Digital Gaming Interventions in Psychiatry: Evidence, Applications and Challenges",https://api.elsevier.com/content/abstract/scopus_id/85097734134,"Human evolution has regularly intersected with technology. Digitalization of various services has brought a paradigm shift in consumerism. Treading this path, mental health practice has gradually moved to Digital Mental Health Interventions (DMHI), to improve service access and delivery. Applied games are one such innovation that has gained recent popularity in psychiatry. Based on the principles of gamification, they target psychosocial and cognitive domains, according to the deficits in various psychiatric disorders. They have been used to deliver cognitive behaviour therapy, cognitive training and rehabilitation, behavioural modification, social motivation, attention enhancement, and biofeedback. Research shows their utility in ADHD, autistic spectrum disorders, eating disorders, post-traumatic stress, impulse control disorders, depression, schizophrenia, dementia, and even healthy aging. Virtual reality and artificial intelligence have been used in conjunction with gaming interventions to improvise their scope. Even though these interventions hold promise in engagement, ease of use, reduction of stigma, and bridging the mental-health gap, there are pragmatic challenges, especially in developing countries. These include network quality, infrastructure, feasibility, socio-cultural adaptability, and potential for abuse. Keeping this in the background, this review summarizes the scope, promise, and evidence of digital gaming in psychiatric practice, and highlights the potential caveats in their implementation.",multimedia
10.1016/j.compag.2020.105908,Journal,Computers and Electronics in Agriculture,scopus,2021-01-01,sciencedirect,Advance research in agricultural text-to-speech: the word segmentation of analytic language and the deep learning-based end-to-end system,https://api.elsevier.com/content/abstract/scopus_id/85097635082,"Agricultural Text-to-Speech (TTS) has attracted increasingly more attention. The application of agricultural TTS and its problems are analyzed in this paper, and the traditional framework of the TTS system and its key technologies, i.e., text analysis, rhythm generation and speech synthesis are discussed. Furthermore, two advancements in agricultural TTS, the word segmentation of analytic language and the deep learning-based end-to-end TTS system, are detailed summarized. Based on the characteristics of agriculture, some appealing research directions are pointed out: how to improve the training speed and synthesis speed of the deep learning models is still the focus; the study on the approaches of weakly-supervised learning in TTS is in fancy; and research on the real-time and high-quality speech synthesis that can be deployed in mobile devices is a key point of agricultural TTS research.",multimedia
10.1016/j.neunet.2020.10.016,Journal,Neural Networks,scopus,2021-01-01,sciencedirect,Adversarial symmetric GANs: Bridging adversarial samples and adversarial networks,https://api.elsevier.com/content/abstract/scopus_id/85096199166,"Generative adversarial networks have achieved remarkable performance on various tasks but suffer from training instability. Despite many training strategies proposed to improve training stability, this issue remains as a challenge. In this paper, we investigate the training instability from the perspective of adversarial samples and reveal that adversarial training on fake samples is implemented in vanilla GANs, but adversarial training on real samples has long been overlooked. Consequently, the discriminator is extremely vulnerable to adversarial perturbation and the gradient given by the discriminator contains non-informative adversarial noises, which hinders the generator from catching the pattern of real samples. Here, we develop adversarial symmetric GANs (AS-GANs) that incorporate adversarial training of the discriminator on real samples into vanilla GANs, making adversarial training symmetrical. The discriminator is therefore more robust and provides more informative gradient with less adversarial noise, thereby stabilizing training and accelerating convergence. The effectiveness of the AS-GANs is verified on image generation on CIFAR-10, CIFAR-100, CelebA, and LSUN with varied network architectures. Not only the training is more stabilized, but the FID scores of generated samples are consistently improved by a large margin compared to the baseline. Theoretical analysis is also conducted to explain why AS-GAN can improve training. The bridging of adversarial samples and adversarial networks provides a new approach to further develop adversarial networks.",multimedia
10.1016/j.scs.2020.102582,Journal,Sustainable Cities and Society,scopus,2021-01-01,sciencedirect,Towards the sustainable development of smart cities through mass video surveillance: A response to the COVID-19 pandemic,https://api.elsevier.com/content/abstract/scopus_id/85096158767,"Sustainable smart city initiatives around the world have recently had great impact on the lives of citizens and brought significant changes to society. More precisely, data-driven smart applications that efficiently manage sparse resources are offering a futuristic vision of smart, efficient, and secure city operations. However, the ongoing COVID-19 pandemic has revealed the limitations of existing smart city deployment; hence; the development of systems and architectures capable of providing fast and effective mechanisms to limit further spread of the virus has become paramount. An active surveillance system capable of monitoring and enforcing social distancing between people can effectively slow the spread of this deadly virus. In this paper, we propose a data-driven deep learning-based framework for the sustainable development of a smart city, offering a timely response to combat the COVID-19 pandemic through mass video surveillance. To implementing social distancing monitoring, we used three deep learning-based real-time object detection models for the detection of people in videos captured with a monocular camera. We validated the performance of our system using a real-world video surveillance dataset for effective deployment.",multimedia
10.1016/j.ajo.2020.07.020,Journal,American Journal of Ophthalmology,scopus,2021-01-01,sciencedirect,Lightweight Learning-Based Automatic Segmentation of Subretinal Blebs on Microscope-Integrated Optical Coherence Tomography Images,https://api.elsevier.com/content/abstract/scopus_id/85092610123,"Purpose
                  Subretinal injections of therapeutics are commonly used to treat ocular diseases. Accurate dosing of therapeutics at target locations is crucial but difficult to achieve using subretinal injections due to leakage, and there is no method available to measure the volume of therapeutics successfully administered to the subretinal location during surgery. Here, we introduce the first automatic method for quantifying the volume of subretinal blebs, using porcine eyes injected with Ringer's lactate solution as samples.
               
                  Design
                  Ex vivo animal study.
               
                  Methods
                  Microscope-integrated optical coherence tomography was used to obtain 3D visualization of subretinal blebs in porcine eyes at Duke Eye Center. Two different injection phases were imaged and analyzed in 15 eyes (30 volumes), selected from a total of 37 eyes. The inclusion/exclusion criteria were set independently from the algorithm-development and testing team. A novel lightweight, deep learning–based algorithm was designed to segment subretinal bleb boundaries. A cross-validation method was used to avoid selection bias. An ensemble-classifier strategy was applied to generate final results for the test dataset.
               
                  Results
                  The algorithm performs notably better than 4 other state-of-the-art deep learning–based segmentation methods, achieving an F1 score of 93.86 ± 1.17% and 96.90 ± 0.59% on the independent test data for entry and full blebs, respectively.
               
                  Conclusion
                  The proposed algorithm accurately segmented the volumetric boundaries of Ringer's lactate solution delivered into the subretinal space of porcine eyes with robust performance and real-time speed. This is the first step for future applications in computer-guided delivery of therapeutics into the subretinal space in human subjects.",multimedia
10.1016/j.wasman.2020.09.032,Journal,Waste Management,scopus,2021-01-01,sciencedirect,Detecting glass and metal in consumer trash bags during waste collection using convolutional neural networks,https://api.elsevier.com/content/abstract/scopus_id/85092313671,"We present a proof-of-concept method to classify the presence of glass and metal in consumer trash bags. With the prevalent utilization of waste collection trucks in municipal solid waste management, the aim of this method is to help pinpoint the locations where waste sorting quality is below accepted standards, making it possible and more efficient to develop tailored procedures that can improve the waste sorting quality in areas with the most urgent needs. Using trash bags containing various amounts of glass and metal, in addition to common waste found in households, we use a combination of sound recording and a beat-frequency oscillation metal detector as inputs to a machine learning algorithm to identify the occurrence of glass and metal in trash bags. A custom-built test rig was developed to mimic a real waste collection truck, which was used to test different sensors and build the datasets. Convolutional neural networks were trained for the classification task, achieving accuracies of up to 98%. These promising results support this method’s potential implementation in real waste collection trucks, enabling location-specific and long-term monitoring of consumer waste sorting quality, which can provide decision support for waste management systems, and research on consumer behavior.",multimedia
10.1016/j.cmpb.2020.105779,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-01-01,sciencedirect,A modular and scalable computational framework for interactive immersion into imaging data with a holographic augmented reality interface,https://api.elsevier.com/content/abstract/scopus_id/85092219783,"Background and objective
                  Modern imaging scanners produce an ever-growing body of 3D/4D multimodal data requiring image analytics and visualization of fused images, segmentations, and information. For the latter, augmented reality (AR) with head-mounted displays (HMDs) has shown potential. This work describes a framework (FI3D) for interactive immersion with data, integration of image processing and analytics, and rendering and fusion with an AR interface.
               
                  Methods
                  The FI3D was designed and endowed with modules to communicate with peripherals, including imaging scanners and HMDs, and to provide computational power for data acquisition and processing. The core of FI3D is deployed to a dedicated computational unit that performs the computationally demanding processes in real-time, and the HMD is used as a display output peripheral and an input peripheral through gestures and voice commands. FI3D offers user-made processing and analysis dedicated modules. Users can customize and optimize these for a particular workflow while incorporating current or future libraries.
               
                  Results
                  The FI3D framework was used to develop a workflow for processing, rendering, and visualization of CINE MRI cardiac sets. In this version, the data were loaded from a remote database, and the endocardium and epicardium of the left ventricle (LV) were segmented using a machine learning model and transmitted to a HoloLens HMD to be visualized in 4D. Performance results show that the system is capable of maintaining an image stream of one image per second with a resolution of 512 × 512. Also, it can modify visual properties of the holograms at 1 update per 16 milliseconds (62.5 Hz) while providing enough resources for the segmentation and surface reconstruction tasks without hindering the HMD.
               
                  Conclusions
                  We provide a system design and framework to be used as a foundation for medical applications that benefit from AR visualization, removing several technical challenges from the developmental pipeline.",multimedia
10.1016/j.vehcom.2020.100303,Journal,Vehicular Communications,scopus,2021-01-01,sciencedirect,Intelligent super-fast Vehicle-to-Everything 5G communications with predictive switching between mmWave and THz links,https://api.elsevier.com/content/abstract/scopus_id/85091713015,"With the incoming of 5G communications, Vehicular Networks have the hope to achieve ultra-high data transmission rate with extremely low end-to-end delay. However, the dynamic nature of transportation traffic and increased data bandwidth demands are the major obstacles to achieve high transmission rate in Vehicular-to-Anything (V2X) Networks. To overcome these obstacles, this paper presents a novel Software Defined Networking (SDN)-controlled and Cognitive Radio (CR)-enabled V2X routing approach to achieve ultra-high data rate, by using predictive V2X routing that supports the intelligent switching between two 5G technologies: millimeter-wave (mmWave) and terahertz (THz). To improve the network management, Road Side units (RSUs) are used to segregate the V2X network into different clusters. Stability-aware clustering (SAC) scheme is also used for cluster formations. Our intelligent V2X is based on three features enabled machine learning approach: (1) To predict future 3D positions of the vehicles in the Cluster Heads (CHs) using Deep Neural Network with Extended Kalman Filter (DNN-EKF) algorithm for real-time, high-resolution prediction. (2) For THz communications, 0.3 THz to 3 THz band is selected for short-distance super-fast data transmissions. The THz band detection is performed by the CR-enabled Road Side Units (cRSUs). A Genetic Algorithm (GA)-based Improved Fruit Fly (GA-IFF) scheme is proposed to achieve an optimal route selection in THz communications. (3) In mmWave-based V2X communications, optimal beam selection is performed by the multi-type2 fuzzy inference system (M-T2FIS). By using these three intelligent designs approaches, we are able to achieve ultrahigh- rate and minimized transmission delay for short-range (in THz bands) and middle-range (in mmWave) communications. Finally, the proposed SDN-controlled, CR-enabled V2X Network is modeled and tested for performance evaluations with the metrics of delivery ratio, routing delay, protocol overhead, and data rate.",multimedia
10.1016/bs.adcom.2020.08.013,Book Series,Advances in Computers,scopus,2021-01-01,sciencedirect,Empowering digital twins with blockchain,https://api.elsevier.com/content/abstract/scopus_id/85090745248,"A digital twin is an exact digital/logical/cyber/virtual representation/replica of any tangible physical system or process. And the digital twin runs on a competent IT infrastructure (say, cloud centers). In essence, a digital twin is typically a software program that takes various real-world data about a ground-level physical system as prospective inputs and produces useful outputs in the form of insights. The outputs generally are the value-adding and decision-enabling predictions or simulations of how that physical system will act on those inputs. These help in quickly and easily realizing highly optimized and organized products with less cost and risk.
                  The manufacturing industry had embraced the digital twin technology long time back to be modern in their operations, outputs, and offerings. The distinct contributions of the digital twin paradigm, since then, have gone up significantly with the seamless synchronization with a number of pioneering technologies such as the Internet of Things (IoT), artificial intelligence (AI), big and streaming data analytics, data lakes, software-defined cloud environments, blockchain, etc. With the concept of cyber physical systems (CPS) is being adopted and adapted widely and wisely, complicated yet sophisticated electronics devices at the ground level are being blessed with their corresponding digital twins. The digital twins enable data scientists and system designers to optimize a number of things including process excellence, knowledge discovery and dissemination in time, better system design, robust verification and validation, etc. In the recent past, with the flourishing of the blockchain technology, the scope for digital twins has gone up remarkably. This unique combination is bound to produce additional competencies and fresh use cases for enterprises. This chapter is to explain how they integrate and initiate newer opportunities to be grabbed and gained for a better tomorrow.",multimedia
10.1016/j.jmsy.2020.06.012,Journal,Journal of Manufacturing Systems,scopus,2021-01-01,sciencedirect,"A digital twin to train deep reinforcement learning agent for smart manufacturing plants: Environment, interfaces and intelligence",https://api.elsevier.com/content/abstract/scopus_id/85087690907,"Filling the gaps between virtual and physical systems will open new doors in Smart Manufacturing. This work proposes a data-driven approach to utilize digital transformation methods to automate smart manufacturing systems. This is fundamentally enabled by using a digital twin to represent manufacturing cells, simulate system behaviors, predict process faults, and adaptively control manipulated variables. First, the manufacturing cell is accommodated to environments such as computer-aided applications, industrial Product Lifecycle Management solutions, and control platforms for automation systems. Second, a network of interfaces between the environments is designed and implemented to enable communication between the digital world and physical manufacturing plant, so that near-synchronous controls can be achieved. Third, capabilities of some members in the family of Deep Reinforcement Learning (DRL) are discussed with manufacturing features within the context of Smart Manufacturing. Trained results for Deep Q Learning algorithms are finally presented in this work as a case study to incorporate DRL-based artificial intelligence to the industrial control process. As a result, developed control methodology, named Digital Engine, is expected to acquire process knowledges, schedule manufacturing tasks, identify optimal actions, and demonstrate control robustness. The authors show that integrating a smart agent into the industrial platforms further expands the usage of the system-level digital twin, where intelligent control algorithms are trained and verified upfront before deployed to the physical world for implementation. Moreover, DRL approach to automated manufacturing control problems under facile optimization environments will be a novel combination between data science and manufacturing industries.",multimedia
10.1016/j.gsf.2020.04.003,Journal,Geoscience Frontiers,scopus,2021-01-01,sciencedirect,Deep learning based classification of rock structure of tunnel face,https://api.elsevier.com/content/abstract/scopus_id/85084431673,"The automated interpretation of rock structure can improve the efficiency, accuracy, and consistency of the geological risk assessment of tunnel face. Because of the high uncertainties in the geological images as a result of different regional rock types, as well as in-situ conditions (e.g., temperature, humidity, and construction procedure), previous automated methods have limited performance in classification of rock structure of tunnel face during construction. This paper presents a framework for classifying multiple rock structures based on the geological images of tunnel face using convolutional neural networks (CNN), namely Inception-ResNet-V2 (IRV2). A prototype recognition system is implemented to classify 5 types of rock structures including mosaic, granular, layered, block, and fragmentation structures. The proposed IRV2 network is trained by over 35,000 out of 42,400 images extracted from over 150 sections of tunnel faces and tested by the remaining 7400 images. Furthermore, different hyperparameters of the CNN model are introduced to optimize the most efficient algorithm parameter. Among all the discussed models, i.e., ResNet-50, ResNet-101, and Inception-v4, Inception-ResNet-V2 exhibits the best performance in terms of various indicators, such as precision, recall, F-score, and testing time per image. Meanwhile, the model trained by a large database can obtain the object features more comprehensively, leading to higher accuracy. Compared with the original image classification method, the sub-image method is closer to the reality considering both the accuracy and the perspective of error divergence. The experimental results reveal that the proposed method is optimal and efficient for automated classification of rock structure using the geological images of the tunnel face.",multimedia
10.1016/j.neuron.2020.09.020,Journal,Neuron,scopus,2020-12-09,sciencedirect,A Platform for Brain-wide Volumetric Functional Ultrasound Imaging and Analysis of Circuit Dynamics in Awake Mice,https://api.elsevier.com/content/abstract/scopus_id/85095408822,"Imaging large-scale circuit dynamics is crucial to understanding brain function, but most techniques have a limited depth of field. Here, we describe volumetric functional ultrasound imaging (vfUSI), a platform for brain-wide vfUSI of hemodynamic activity in awake head-fixed mice. We combined a high-frequency 1,024-channel 2D-array transducer with advanced multiplexing and high-performance computing for real-time 3D power Doppler imaging at a high spatiotemporal resolution (220 × 280 × 175 μm3, up to 6 Hz). We developed a standardized software pipeline for registration, segmentation, and temporal analysis in 268 individual brain regions based on the Allen Mouse Common Coordinate Framework. We demonstrated the high sensitivity of vfUSI under multiple experimental conditions, and we successfully imaged stimulus-evoked activity when only a few trials were averaged. We also mapped neural circuits in vivo across the whole brain during optogenetic activation of specific cell types. Moreover, we identified the sequential activation of sensory-motor networks during a grasping water-droplet task.",multimedia
10.1016/j.comnet.2020.107573,Journal,Computer Networks,scopus,2020-12-09,sciencedirect,AI-enabled mobile multimedia service instance placement scheme in mobile edge computing,https://api.elsevier.com/content/abstract/scopus_id/85091771160,"Leveraging cloud infrastructure to the mobile edge computing helps the mobile users to get real time multimedia services in Fifth Generation (5G) network system. To ensure higher Quality-of-Experience (QoE), faster migration of mobile multimedia service instances is required to cope up with user mobility. By deploying the mobile multimedia service instances proactively in multiple edge nodes (ENs) helps the users to get higher QoE. However, excessive deployment of service replicas might increase the cost of the overall network. To establish trade-off between these two conflicting objectives, we have formulated the problem as a Multi-objective Integer Linear Programming (MILP) by integrating the users’ path prediction model. This problem is proven to be an NP-hard one for large networks, thus we develop an artificial intelligence (AI) based meta-heuristic Binary Particle Swarm Optimization (BPSO) algorithm to achieve near-optimal solution within polynomial time. The performance analysis results show the significant performance improvement in terms of QoE and user satisfaction as compared to other state-of-the-art works.",multimedia
10.1016/j.comnet.2020.107496,Journal,Computer Networks,scopus,2020-12-09,sciencedirect,A survey on the computation offloading approaches in mobile edge computing: A machine learning-based perspective,https://api.elsevier.com/content/abstract/scopus_id/85090841979,"With the rapid developments in emerging mobile technologies, utilizing resource-hungry mobile applications such as media processing, online Gaming, Augmented Reality (AR), and Virtual Reality (VR) play an essential role in both businesses and entertainments. To soften the burden of such complexities incurred by fast developments of such serving technologies, distributed Mobile Edge Computing (MEC) has been developed, aimed at bringing the computation environments near the end-users, usually in one hop, to reach predefined requirements. In the literature, offloading approaches are developed to connect the computation environments to mobile devices by transferring resource-hungry tasks to the near servers. Because of some rising problems such as inherent software and hardware heterogeneity, restrictions, dynamism, and stochastic behavior of the ecosystem, the computation offloading issues consider as the essential challenging problems in the MEC environment. However, to the best of the author's knowledge, in spite of its significance, in machine learning-based (ML-based) computation offloading mechanisms, there is not any systematic, comprehensive, and detailed survey in the MEC environment. In this paper, we provide a review on the ML-based computation offloading mechanisms in the MEC environment in the form of a classical taxonomy to identify the contemporary mechanisms on this crucial topic and to offer open issues as well. The proposed taxonomy is classified into three main fields: Reinforcement learning-based mechanisms, supervised learning-based mechanisms, and unsupervised learning-based mechanisms. Next, these classes are compared with each other based on the essential features such as performance metrics, case studies, utilized techniques, and evaluation tools, and their advantages and weaknesses are discussed, as well. Finally, open issues and uncovered or inadequately covered future research challenges are argued, and the survey is concluded.",multimedia
10.1016/j.psychres.2020.113558,Journal,Psychiatry Research,scopus,2020-12-01,sciencedirect,Accuracy of machine learning-based prediction of medication adherence in clinical research,https://api.elsevier.com/content/abstract/scopus_id/85096703550,"Medication non-adherence represents a significant barrier to treatment efficacy. Remote, real-time measurement of medication dosing can facilitate dynamic prediction of risk for medication non-adherence, which in-turn allows for proactive clinical intervention to optimize health outcomes. We examine the accuracy of dynamic prediction of non-adherence using data from remote real-time measurements of medication dosing. Participants across a large set of clinical trials (n = 4,182) were observed via a smartphone application that video records patients taking their prescribed medication. The patients’ primary diagnosis, demographics, and prior indication of observed adherence/non-adherence were utilized to predict (1) adherence rates ≥ 80% across the clinical trial, (2) adherence ≥ 80% for the subsequent week, and (3) adherence the subsequent day using machine learning-based classification models. Empirically observed adherence was demonstrated to be the strongest predictor of future adherence/non-adherence. Collectively, the classification models accurately predicted adherence across the trial (AUC = 0.83), the subsequent week (AUC = 0.87) and the subsequent day (AUC = 0.87). Real-time measurement of dosing can be utilized to dynamically predict medication adherence with high accuracy.",multimedia
10.1016/j.pnucene.2020.103540,Journal,Progress in Nuclear Energy,scopus,2020-12-01,sciencedirect,A RELAP5-3D/LSTM model for the analysis of drywell cooling fan failure,https://api.elsevier.com/content/abstract/scopus_id/85092639333,"A RELAP5-3D/LSTM model was created to analyze the failures of two drywell cooling fans at a nuclear power plant. A total of four fan coil units (FCUs) each comprised of a water-cooled heat exchanger and a centrifugal fan located in the drywell provide cooling via a closed nitrogen loop to the primary containment of the boiling water reactor. A Reactor Excursion and Leak Analysis Program (RELAP5-3D) thermal hydraulic model was created to simulate the steady-state normal operation of the FCUs. Historical data from the plant Process Information (PI) system was synchronized in time for a total of 33 Plant Management Information System (PMIS) tags per FCU representing: (1) the temperatures at various locations within the drywell, (2) inlet, outlet, and dewpoint temperatures at the FCUs, (3) reactor power, and (4) water coolant flowrate and temperature. Because the inlet temperature sensor for the two fans that failed did not provide consistent data prior to the failures, a long short-term memory (LSTM) recurrent neural network was trained to predict the FCU inlet temperature history based upon the states of the other valid PMIS points. RELAP5-3D simulations were performed using the measured FCU inlet temperatures, as well as the LSTM-generated temperatures, and the resulting FCU outlet temperatures were compared. The simulation results using the measured and predicted FCU inlet temperature were shown to be within 7.35% and 5.16%, respectively, of the values reported by the PI system. Thus, a viable approach has been demonstrated to predict the expected FCU outlet temperature. By comparing real-time measurements of FCU outlet temperature with predictions such as those presented here, off-normal operation can be readily detected. The use of RELAP5-3D with the LSTM results was successfully implemented to prototype a physics-based anomaly detection model for the drywell FCUs.",multimedia
10.1016/j.neuroimage.2020.117367,Journal,NeuroImage,scopus,2020-12-01,sciencedirect,Modeling an auditory stimulated brain under altered states of consciousness using the generalized ising model,https://api.elsevier.com/content/abstract/scopus_id/85090914104,"Propofol is a short-acting medication that results in decreased levels of consciousness and is used for general anesthesia. Although it is the most commonly used anesthetic in the world, much remains unknown about the mechanisms by which it induces a loss of consciousness. Characterizing anesthesia-induced alterations to brain network activity might provide a powerful framework for understanding the neural mechanisms of unconsciousness.
                  The aim of this work was to model brain activity in healthy brains during various stages of consciousness, as induced by propofol, in the auditory paradigm. We used the generalized Ising model (GIM) to fit the empirical fMRI data of healthy subjects while they listened to an audio clip from a movie. The external stimulus (audio clip) is believed to be at least partially driving a synchronization process of the brain activity and provides a similar conscious experience in different subjects. In order to observe the common synchronization among the subjects, a novel technique called the inter subject correlation (ISC) was implemented.
                  We showed that the GIM—modified to incorporate the naturalistic external field—was able to fit the empirical task fMRI data in the awake state, in mild sedation, in deep sedation, and in recovery, at a temperature T* which is well above the critical temperature. To our knowledge this is the first study that captures human brain activity in response to real-life external stimuli at different levels of conscious awareness using mathematical modeling. This study might be helpful in the future to assess the level of consciousness of patients with disorders of consciousness and help in regaining their consciousness.",multimedia
10.1016/j.patcog.2020.107530,Journal,Pattern Recognition,scopus,2020-12-01,sciencedirect,Fast and incremental algorithms for exponential semi-supervised discriminant embedding,https://api.elsevier.com/content/abstract/scopus_id/85087975546,"In various pattern classification problems, semi-supervised learning methods have shown its effectiveness in utilizing unlabeled data to yield better performance than some supervised and unsupervised learning methods. Semi-supervised discriminant embedding (SDE) is a semi-supervised extension of local discriminant embedding (LDE). However, when dealing with high dimensional data, SDE often suffers from the small-sample-size (SSS) problem. In order to settle this problem, an exponential semi-supervised discriminant embedding (ESDE) method was proposed in [F. Dornaika, Y. EI Traboulsi. Matrix exponential based semi-supervised discriminant embedding for image classification, Pattern Recognition, 61 (2017): 92–103], which makes use of the tool of matrix exponential. Despite its high discriminative ability, the computational overhead of ESDE is very large for high dimensional data. In order to cure this drawback, the first contribution of this paper is to propose a fast implementation on the ESDE method. The key is to equivalently transform the large matrix problem of size d into a much smaller one of size n, where d is the data dimension and n is the number of training samples, with d ≫ n in practice. On the other hand, in many real world applications, it is likely that whole labeled training set is unavailable beforehand, and the training data is obtained incrementally. Many incremental semi-supervised learning methods have been proposed to deal with this problem, to the best of our knowledge, however, there are no incremental algorithms for matrix exponential discriminant methods till now. To fill in this gap, the second contribution of this paper is to propose incremental ESDE algorithms for incremental learning problems. Numerical experiments on some real-world data sets show the numerical behavior of the proposed algorithms.",multimedia
10.1016/j.neunet.2020.08.012,Journal,Neural Networks,scopus,2020-12-01,sciencedirect,Latent Dirichlet allocation based generative adversarial networks,https://api.elsevier.com/content/abstract/scopus_id/85083895792,"Generative adversarial networks have been extensively studied in recent years and powered a wide range of applications, ranging from image generation, image-to-image translation, to text-to-image generation, and visual recognition. These methods typically model the mapping from latent space to image with single or multiple generators. However, they have obvious drawbacks: (i) ignoring the multi-modal structure of images, and (ii) lacking model interpretability. Importantly, the existing methods mostly assume one or more generators can cover all image modes even if we do not know the structure of data. Thus, mode dropping and collapse often take place along with GANs training. Despite the importance of exploring the data structure in generation, it has been almost unexplored. In this work, aiming at generating multi-modal images and interpreting model explicitly, we explore the theory on how to integrate GANs with data structure prior, and propose latent Dirichlet allocation based generative adversarial networks (LDAGAN). This framework is extended to combine with a variety of state-of-the-art single-generator GANs and achieves improved performance. Extensive experiments on synthetic and real datasets demonstrate the efficacy of LDAGAN for multi-modal image generation. An implementation of LDAGAN is available at https://github.com/Sumching/LDAGAN.",multimedia
10.1016/j.jns.2020.117081,Journal,Journal of the Neurological Sciences,scopus,2020-11-15,sciencedirect,New technologies and Amyotrophic Lateral Sclerosis – Which step forward rushed by the COVID-19 pandemic?,https://api.elsevier.com/content/abstract/scopus_id/85090005531,"Amyotrophic Lateral Sclerosis (ALS) is a fast-progressive neurodegenerative disease leading to progressive physical immobility with usually normal or mild cognitive and/or behavioural involvement. Many patients are relatively young, instructed, sensitive to new technologies, and professionally active when developing the first symptoms. Older patients usually require more time, encouragement, reinforcement and a closer support but, nevertheless, selecting user-friendly devices, provided earlier in the course of the disease, and engaging motivated carers may overcome many technological barriers. ALS may be considered a model for neurodegenerative diseases to further develop and test new technologies. From multidisciplinary teleconsults to telemonitoring of the respiratory function, telemedicine has the potentiality to embrace other fields, including nutrition, physical mobility, and the interaction with the environment. Brain-computer interfaces and eye tracking expanded the field of augmentative and alternative communication in ALS but their potentialities go beyond communication, to cognition and robotics. Virtual reality and different forms of artificial intelligence present further interesting possibilities that deserve to be investigated. COVID-19 pandemic is an unprecedented opportunity to speed up the development and implementation of new technologies in clinical practice, improving the daily living of both ALS patients and carers.
                  The present work reviews the current technologies for ALS patients already in place or being under evaluation with published publications, prompted by the COVID-19 pandemic.",multimedia
10.1016/j.jbi.2020.103590,Journal,Journal of Biomedical Informatics,scopus,2020-11-01,sciencedirect,A virtual reality methodology for cardiopulmonary resuscitation training with and without a physical mannequin,https://api.elsevier.com/content/abstract/scopus_id/85092735575,"Background
                  Cardiopulmonary resuscitation (CPR) is an emergency procedure that can increase survival after a cardiac arrest. Performing CPR effectively requires both procedural knowledge and manual skills. Traditional CPR training methodology includes lessons led by instructors and supervised practice on mannequins, thus requiring considerable resources.
               
                  Objective
                  This paper proposes a new methodology for low-cost CPR training based on virtual reality (VR) with and without the addition of a physical mannequin. Moreover, it describes an experimental evaluation of the methodology that assessed gain in manual skills during training, transfer of procedural knowledge and manual skills in a final assessment, and changes in self-efficacy with three measurements over time (pre-training, post-training, and post-assessment).
               
                  Methods
                  We implemented a VR application that supports the proposed methodology, and can thus be used with or without a mannequin. The experimental evaluation involved 30 participants who tried CPR in VR twice, performing two repetitions of 30 chest compressions per trial. Half participants tried the VR application with the mannequin and half without it. Final assessment required all participants to perform CPR on the mannequin without the assistance of VR. To assess self-efficacy, participants filled in a questionnaire at the three times of measurement.
               
                  Results
                  Mixed-design ANOVAs showed effects of repetition, effects of group, or interaction between the two variables on manual skills assessed during training. In the final assessment, participants in both groups correctly remembered most of the steps of the procedure. ANOVAs revealed differences between the two groups only in pressure-related skills (better with mannequin) and in the number of wrong steps added to the procedure (better without mannequin). Mixed-design ANOVA showed a self-efficacy increase in both groups after training, which was maintained after final assessment.
               
                  Conclusions
                  The proposed VR methodology for CPR training has a positive effect on procedural knowledge, manual skills, and self-efficacy, with as well as without the physical mannequin. Trials on a mannequin are required to understand the correct pressure for chest compression. This supports the adoption of the proposed VR methodology to reduce instructor and mannequin time required to teach CPR to trainees.",multimedia
10.1016/j.cie.2020.106868,Journal,Computers and Industrial Engineering,scopus,2020-11-01,sciencedirect,Simulation in industry 4.0: A state-of-the-art review,https://api.elsevier.com/content/abstract/scopus_id/85091194972,"Simulation is a key technology for developing planning and exploratory models to optimize decision making as well as the design and operations of complex and smart production systems. It could also aid companies to evaluate the risks, costs, implementation barriers, impact on operational performance, and roadmap toward Industry 4.0. Although several advances have been made in this domain, studies that systematically characterize and analyze the development of simulation-based research in Industry 4.0 are scarce. Therefore, this study aims to investigate the state-of-the-art research performed on the intersecting area of simulation and the field of Industry 4.0. Initially, a conceptual framework describing Industry 4.0 in terms of enabling technologies and design principles for modeling and simulation of Industry 4.0 scenarios is proposed. Thereafter, literature on simulation technologies and Industry 4.0 design principles is systematically reviewed using the preferred reporting items for systematic reviews and meta-analyses (PRISMA) methodology. This study reveals an increasing trend in the number of publications on simulation in Industry 4.0 within the last four years. In total, 10 simulation-based approaches and 17 Industry 4.0 design principles were identified. A cross-analysis of concepts and evaluation of models’ development suggest that simulation can capture the design principles of Industry 4.0 and support the investigation of the Industry 4.0 phenomenon from different perspectives. Finally, the results of this study indicate hybrid simulation and digital twin as the primary simulation-based approaches in the context of Industry 4.0.",multimedia
10.1016/j.nedt.2020.104592,Journal,Nurse Education Today,scopus,2020-11-01,sciencedirect,Communication skills training using virtual reality: A descriptive qualitative study,https://api.elsevier.com/content/abstract/scopus_id/85090743102,"Background
                  Modern medical pedagogical strategies are shifting toward the use of virtual patient simulations.
               
                  Objective
                  This study aims to examine students' users' attitudes and experiences and clinical facilitators' perspectives on student performances in the clinical setting post-virtual patient training.
               
                  Design
                  A descriptive qualitative study design was used.
               
                  Setting
                  Nursing faculty at a local university in Singapore.
               
                  Participants
                  24 nursing undergraduates and six clinical facilitators.
               
                  Methods
                  This study is a follow-up of an experimental study on the Virtual Counseling Application Using Artificial Intelligence (VCAAI). The study took place from the academic year 2017/2018 ended in November 2019. Focus group discussions and individual interviews were conducted. All interviews and focus group discussions were audiotaped, transcribed verbatim, and analyzed using thematic analysis.
               
                  Results
                  Two overarching themes (students' virtual patient user experience and clinical facilitators' evaluations of students' clinical communication skills) comprising six themes were generated. Themes under students' user experience included: 1) attitudes toward virtual patient training, 2) virtual patient's role in student development, and 3) enhanced features and implementation suggestions. Themes under clinical facilitators' evaluations included: 1) insights on students' communication skills and 2) approaches to improve communication skills. An overlapping theme titled ‘value of technology in teaching communication’ comprised of mutual feedback from both students and clinical facilitators. Early implementation, continued accessibility, enhancing realism and technological improvements to the VCAAI were listed as key areas for program improvement, while increased situational sensitivity and language training are recommended to further enhance students' communication skills.
               
                  Conclusion
                  The mixed attitudes toward virtual patient interactions and recognitions of the benefits of virtual patient simulations suggest the potential effectiveness of the use of virtual patients in teaching effective nursing communication skills. However, the lack of authenticity and other limitations need to be addressed before official implementations of such trainings with virtual patients to undergraduate nursing curricula.",multimedia
10.1016/j.robot.2020.103624,Journal,Robotics and Autonomous Systems,scopus,2020-11-01,sciencedirect,Associated Reality: A cognitive Human–Machine Layer for autonomous driving,https://api.elsevier.com/content/abstract/scopus_id/85089815046,"Advanced Driver Assistance Systems (ADAS) and Automated and Autonomous Vehicles (AV) are cooperative systems and processes that use: artificial intelligence, cognitive methods, cloud technologies, cooperative vehicle-to-everything-communications (V2X), software–hardwareplatforms, sensor platforms and incipient intelligent transport infrastructures, to get self-driving systems and smart connected mobility services. This paper, to support automated driving systems (assisted, semi-autonomous and fully autonomous vehicles), introduces a cognitive layer called Associated Reality to enhance the involved information, knowledge and communication processes. The architecture defined includes an augmented Local Dynamic Map, with complementary layers, and an augmented Graph Database, with complementary semantic–cognitive relations, for the considered purpose, in cooperative human–machine and machine–machine systems. Virtual augmented landmarks are defined to improve the connectivity and intelligence of the involved spatial-information systems. Different structure landmarks and sequence landmarks (which includes regular, repetitive and periodic landmarks) are defined, categorized and used in diverse visual localization and mapping scenarios, for autonomous driving. In this paper, it is also shown, as a proof-of-concept for vehicle localization and mapping in road tunnels, the visual detection of different sequences of periodic luminaires, using YOLO v3 for the corresponding LED lights detection, or a specific alternative procedure developed with very low computational cost.",multimedia
10.1016/j.neunet.2020.07.028,Journal,Neural Networks,scopus,2020-11-01,sciencedirect,Compressing 3DCNNs based on tensor train decomposition,https://api.elsevier.com/content/abstract/scopus_id/85089391288,"Three-dimensional convolutional neural networks (3DCNNs) have been applied in many tasks, e.g., video and 3D point cloud recognition. However, due to the higher dimension of convolutional kernels, the space complexity of 3DCNNs is generally larger than that of traditional two-dimensional convolutional neural networks (2DCNNs). To miniaturize 3DCNNs for the deployment in confining environments such as embedded devices, neural network compression is a promising approach. In this work, we adopt the tensor train (TT) decomposition, a straightforward and simple in situ training compression method, to shrink the 3DCNN models. Through proposing tensorizing 3D convolutional kernels in TT format, we investigate how to select appropriate TT ranks for achieving higher compression ratio. We have also discussed the redundancy of 3D convolutional kernels for compression, core significance and future directions of this work, as well as the theoretical computation complexity versus practical executing time of convolution in TT. In the light of multiple contrast experiments based on VIVA challenge, UCF11, UCF101, and ModelNet40 datasets, we conclude that TT decomposition can compress 3DCNNs by around one hundred times without significant accuracy loss, which will enable its applications in extensive real world scenarios.",multimedia
10.1016/j.sigpro.2020.107717,Journal,Signal Processing,scopus,2020-11-01,sciencedirect,Fast and efficient implementation of image filtering using a side window convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85088128229,"Convolutional neural networks (CNNs) designed for object recognition have been successfully applied to low-level tasks such as image filtering. However, these networks are usually very large which occupy large memory space and demand very high computational capacity. This makes them unsuitable for real time low-level applications on smart and portable devices with limited memory and computational capacities. In this paper, we specifically design a novel CNN, side window convolutional neural network (SW-CNN), for the fast and efficient implementation of image filtering. In SW-CNN, a new convolutional strategy, called side kernel convolution (SKC) is proposed which aligns the side or corner of the convolutional window with the pixels under processing to preserve edges during convolution. By combining SKC and the representational power of CNNs, SW-CNN can learn various image-filtering tasks very effectively. Compared to the state-of-the-art networks, the superiority of SW-CNN includes three aspects. First, the number of learnable parameters is reduced by 96%. Second, the memory consumption is reduced to 50%. Third, the running time is decreased to 50%. Results of extensive experiments demonstrate that SW-CNN not only has good performance on implementing various edge-preserving filters, but also has the adaptability and flexibility on other low-level image processing applications.",multimedia
10.1016/j.future.2020.06.017,Journal,Future Generation Computer Systems,scopus,2020-11-01,sciencedirect,PPCensor: Architecture for real-time pornography detection in video streaming,https://api.elsevier.com/content/abstract/scopus_id/85087196994,"Convolutional neural network (CNN) models are typically composed of several gigabytes of data, requiring dedicated hardware and significant processing capabilities for proper handling. In addition, video-detection tasks are typically performed offline, and each video frame is analyzed individually, meaning that the video’s categorization (class assignment) as normal or pornographic is only complete after all the video frames have been evaluated. This paper proposes the Private Parts Censor (PPCensor), a CNN-based architecture for transparent and near real-time detection and obfuscation of pornographic video frame regions. Our contribution is two-fold. First, the proposed architecture is the first that addresses the detection of pornographic content as an object detection problem. The objective is to apply user-friendly content filtering such that an inevitable false positive will obfuscate only regions (objects) within the video frames instead of blocking the entire video. Second, the PPCensor architecture is deployed on dedicated hardware, and real-time detection is deployed using a video-oriented streaming proxy. If a pornographic video frame is identified in the video, the system can hide pornographic content (private parts) in real time without user interaction or additional processing on the user’s device. Based on more than 50,000 objects labeled manually, the evaluation results show that the PPCensor is capable of detecting private parts in near real time for video streaming. Compared to cutting-edge CNN architectures for image classification, PPCensor achieved similar results, but operated in real time. In addition, when deployed on a desktop computer, PPCensor handled up to 35 simultaneous connections without the need for additional processing on the end-user device.",multimedia
10.1016/j.petrol.2020.107509,Journal,Journal of Petroleum Science and Engineering,scopus,2020-11-01,sciencedirect,"Design and construction of the knowledge base system for geological outfield cavities classifications: An example of the fracture-cavity reservoir outfield in Tarim basin, NW China",https://api.elsevier.com/content/abstract/scopus_id/85087076723,"Tahe oilfield, located in NW Tarim Basin, is one of the largest and most difficult fracture cavity reservoirs in the world. Different fracture cavities, different generated mechanisms, and different oil production capacities. In order to study the significant parameters that can characterize the categories of facture-cavity. This research adopted outfield manual measurement, 3D digital modeling technique to obtain characterization parameters. According to experienced geological survey, typical outcrops were selected, then scanned by UAV (Unmanned aerial vehicle). Consequently, 3D digital models, including real coordinates and parameter information, were established by Agisoft Photoscan. Through geological testing results, various combination characteristic patterns of relative categories were analyzed. By using digital measure tool, combined with manually measured data, the parameters were extracted from the 3D digital model (DM). Then an initial geological database was established. For furtherly analyzing the database, the mathematic statistics methods of multiple linear regression (MLR), neural network technique (NNT) and discriminative classification technique (DCT) were applied. Using software of SPSS statistics 17.0, more than 200 groups of geological data (various categories of fracture-cavity) were optimally processed. Consequently, the significant characteristic parameters were interpreted to determine diverse categories. The results showed that: (1) cavity width, height, fracture length and cavity aspect ratio were significant parameters to classify runoff cavity categories. (2) Fault-controlled cavities could be accurately classified by fracture length and fracture density. (3) The main cavity categories could be distinguished by cavity width, cavity height and fracture density. Performances of the approach have been examined with 10 percentages of the samples, and a good agreement performed in the simulated results, and anastomosis rate was more than 80%. The researched results have critical guiding significance to evaluate types of fracture-cavity, develop and explore of fracture-cavity reservoirs. The construction technique of knowledge base can be applied for diverse fracture-cavity reservoirs in the various formations in different areas in the world.",multimedia
10.1016/j.cels.2020.08.016,Journal,Cell Systems,scopus,2020-10-21,sciencedirect,Fast and Flexible Protein Design Using Deep Graph Neural Networks,https://api.elsevier.com/content/abstract/scopus_id/85092248944,"Protein structure and function is determined by the arrangement of the linear sequence of amino acids in 3D space. We show that a deep graph neural network, ProteinSolver, can precisely design sequences that fold into a predetermined shape by phrasing this challenge as a constraint satisfaction problem (CSP), akin to Sudoku puzzles. We trained ProteinSolver on over 70,000,000 real protein sequences corresponding to over 80,000 structures. We show that our method rapidly designs new protein sequences and benchmark them in silico using energy-based scores, molecular dynamics, and structure prediction methods. As a proof-of-principle validation, we use ProteinSolver to generate sequences that match the structure of serum albumin, then synthesize the top-scoring design and validate it in vitro using circular dichroism. ProteinSolver is freely available at http://design.proteinsolver.org and https://gitlab.com/ostrokach/proteinsolver. A record of this paper’s transparent peer review process is included in the Supplemental Information.",multimedia
10.1016/j.patrec.2020.09.009,Journal,Pattern Recognition Letters,scopus,2020-10-01,sciencedirect,Depth occlusion perception feature analysis for person re-identification,https://api.elsevier.com/content/abstract/scopus_id/85091652908,"Person re-identification (ReID) has achieved significant improvement under the setting of matching two holistic person images. However, persons are easily occluded by the various objects and other persons in real-world scenarios, making Person ReID a challenging task. In this paper, we propose a novel method named Pose-Driven Visibility Model (PDVM) to effectively solve the degradation of recognition performance caused by occlusion. Firstly, we extract non-occluded human body features through pose estimation, pay attention to the salient features of non-human parts through self-attention mechanism, and obtains the final feature representation after the combination. Secondly, we more accurately locate person body parts by utilizing the detected human keypoints in different occlusion situations, effectively reducing the impact of unalignment and realizing better matching for persons. We implement extensive experiments on Occluded-DukeMTMC and Partial-REID. Our proposed method achieves state of the art performances which reaches 53.0% Rank-1 accuracy on Occluded-DukeMTMC dataset and ablation analysis also verify the effectiveness of our method. 2020 Elsevier Ltd. All rights reserved",multimedia
10.1016/j.jvcir.2020.102912,Journal,Journal of Visual Communication and Image Representation,scopus,2020-10-01,sciencedirect,A survey on analysis and implementation of state-of-the-art haze removal techniques,https://api.elsevier.com/content/abstract/scopus_id/85091202375,"Haze is a poor-quality state described by the opalescent appearance of the atmosphere which reduces the visibility. It is caused by high concentrations of atmospheric air pollutants, such as dust, smoke and other particles that scatter and absorb sunlight. The poor visibility can result in the failure of multiple computer vision applications such as smart transport systems, image processing, object detection, surveillance etc. One of the major issues in the field of image processing is the restoration of images that are corrupted due to different degradations. Typically, the images or videos captured in the outside environment have low contrast, colour fade and restricted visibility due to suspended particles of the atmosphere that directly influence the image quality. This can cause difficulty in identifying the objects in the captured hazy images or frames. To address this problem, several image dehazing techniques have been developed in the literature, each of which has its own advantages and limitations, but effective image restoration remains a challenging task. In recent times, various learning (Machine learning & Deep learning) based methods greatly condensed the drawbacks of manual design of haze related features and reduces the difficulty in efficient restoration of images with less computational time and cost. The current state-of-the-art methods for haze free images, mainly from the last decade, are thoroughly examined in this survey. Moreover, this paper systematically summarizes the hardware implementations of various haze removal methods in real time. It is with the hope that this current survey acts as a reference for researchers in this scientific area and to provide a direction for future improvements based on current achievements.",multimedia
10.1016/j.jobcr.2020.07.015,Journal,Journal of Oral Biology and Craniofacial Research,scopus,2020-10-01,sciencedirect,Present and future of artificial intelligence in dentistry,https://api.elsevier.com/content/abstract/scopus_id/85088647471,"The last decennary has marked as the breakthrough in the advancement of technology with evolution of artificial intelligence, which is rapidly gaining the attention of researchers across the globe. Every field opted artificial intelligence with huge enthusiasm and so the field of dental science is no exception. With huge increases in patient documented information and data this is the need of the hour to use intelligent software to compile and save this data. From the basic step of taking a patient's history to data processing and then to extract the information from the data for diagnosis, artificial intelligence has many applications in dental and medical science. While in no case artificial intelligence can replace the role of a dental surgeon but it is important to be acquainted with the scope to amalgamate this advancement of technology in future for betterment of dental practice.",multimedia
10.1016/j.ijleo.2020.165205,Journal,Optik,scopus,2020-10-01,sciencedirect,Pattern recognition based on pulse scanning imaging and convolutional neural network for vibrational events in Φ-OTDR,https://api.elsevier.com/content/abstract/scopus_id/85087790249,"Feature extraction method of a phase-sensitive optical time-domain reflectometer distributed optical fiber vibration detection system requires a priori knowledge. A lack of feature evaluation methods leads to a low pattern recognition accuracy. Traditional pattern recognition methods cannot be widely applied. This paper presents the implementation of a deep learning-based method to identify vibration signal categories. First, the vibration signal was reconstructed in the time and space domain, which is regarded as a pulse scanning image. Secondly, moving average was used to reduce noise, and seeking the signal envelope surface as an image sample. Finally, the image sample was inputted into the trained convolutional neural network (CNN) to obtain recognition results. Experiments showed that the phase-sensitive optical time-domain reflectometer pulse scanning imaging pattern recognition method based on deep learning proposed in this paper improved recognition accuracy while ensuring recognition efficiency. The algorithm is easy to implement and apply and satisfies the requirements of real-time online monitoring.",multimedia
10.1016/j.cmpb.2020.105643,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-10-01,sciencedirect,High accurate lightweight deep learning method for gesture recognition based on surface electromyography,https://api.elsevier.com/content/abstract/scopus_id/85087496227,"Background and objectives
                  Surface Electromyography (sEMG) is used mostly for neuromuscular diagnosis, assistive technology, physical rehabilitation, and human-computer interactions. Achieving a precise and lightweight method along with low latency for gesture recognition is still a real-life challenge, especially for rehabilitation and assistive robots. This work aims to introduce a highly accurate and lightweight deep learning method for gesture recognition.
               
                  Methods
                  High-density sEMG, unlike sparse sEMG, does not require accurate electrode placement and provides more physiological information. Then we apply high-density sEMG, which, according to previous studies, leads to sEMG images. In this study, we introduce the Sensor-Wise method, which has a higher capability to extract features compared to the sEMG image method due to its high compatibility with the nature of sEMG signals and the structure of convolutional networks.
               
                  Results
                  The proposed method, because of its optimal structure with only two hidden layers and its high compatibility, has shown no sign of overfitting and was able to reach an accuracy of almost 100% (99.99%) when it was evaluated by CapgMyo DB-a database through 96 electrodes. Using this method, even with 16 electrodes, we were able to reach an accuracy of 99.8%, which was higher than the accuracies reported in the previous studies. Additionally, the method was evaluated by the CSL-HDEMG database, where the accuracy reached 99.55%. Previous studies either introduced expensive computational methods with overfitting or reported lower accuracies compared to this study.
               
                  Conclusions
                  The Sensor- Wise method has high compatibility with the nature of sEMG signals and the structure of convolutional networks. The high accuracy and lightweight structure of this method with only two hidden layers make it a proper option for hardware implementation.",multimedia
10.1016/j.ast.2020.105965,Journal,Aerospace Science and Technology,scopus,2020-10-01,sciencedirect,Towards a PDE-based large-scale decentralized solution for path planning of UAVs in shared airspace,https://api.elsevier.com/content/abstract/scopus_id/85086828428,"Recently, there has been a tremendous increase of interest in utilizing Unmanned Aerial Vehicles (UAVs) for a number of civilian applications. With this increased interest, it is imperative that these UAVs are able to operate in shared airspace for enhanced efficiency. Multi-UAV systems are inherently safety-critical systems, which means that safety guarantees must be made to ensure no undesirable configurations, such as collisions, occur. This paper proposes a decentralized method based on a Partial Differential Equation (PDE) to generate collision-free 3D trajectories for multiple UAVs operating in a shared airspace. This method exploits the dynamical properties of multi-phase fluids flowing through a porous medium by modeling the porosity values as a function of the risk of collision. To highlight the feasibility for on-board implementation, we propose propose a machine learning technique for obtaining computationally efficient solutions of the PDE describing flow movements in porous medium. This method has been compared via a simulation study to two other path planning strategies, centralized and sequential planning, and the advantages of this method are presented. Furthermore, results from an experiment using three UAVs have been presented to demonstrate the applicability of the proposed method to real-world implementation.",multimedia
10.1016/j.cmpb.2020.105532,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-10-01,sciencedirect,COVID-19 identification in chest X-ray images on flat and hierarchical classification scenarios,https://api.elsevier.com/content/abstract/scopus_id/85085953358,"Background and Objective:The COVID-19 can cause severe pneumonia and is estimated to have a high impact on the healthcare system. Early diagnosis is crucial for correct treatment in order to possibly reduce the stress in the healthcare system. The standard image diagnosis tests for pneumonia are chest X-ray (CXR) and computed tomography (CT) scan. Although CT scan is the gold standard, CXR are still useful because it is cheaper, faster and more widespread. This study aims to identify pneumonia caused by COVID-19 from other types and also healthy lungs using only CXR images.
                  
                     Methods:In order to achieve the objectives, we have proposed a classification schema considering the following perspectives: i) a multi-class classification; ii) hierarchical classification, since pneumonia can be structured as a hierarchy. Given the natural data imbalance in this domain, we also proposed the use of resampling algorithms in the schema in order to re-balance the classes distribution. We observed that, texture is one of the main visual attributes of CXR images, our classification schema extract features using some well-known texture descriptors and also using a pre-trained CNN model. We also explored early and late fusion techniques in the schema in order to leverage the strength of multiple texture descriptors and base classifiers at once.
                  To evaluate the approach, we composed a database, named RYDLS-20, containing CXR images of pneumonia caused by different pathogens as well as CXR images of healthy lungs. The classes distribution follows a real-world scenario in which some pathogens are more common than others.
                  
                     Results:The proposed approach tested in RYDLS-20 achieved a macro-avg F1-Score of 0.65 using a multi-class approach and a F1-Score of 0.89 for the COVID-19 identification in the hierarchical classification scenario.
                  
                     Conclusions:As far as we know, the top identification rate obtained in this paper is the best nominal rate obtained for COVID-19 identification in an unbalanced environment with more than three classes. We must also highlight the novel proposed hierarchical classification approach for this task, which considers the types of pneumonia caused by the different pathogens and lead us to the best COVID-19 recognition rate obtained here.",multimedia
10.1016/j.jksuci.2018.09.019,Journal,Journal of King Saud University - Computer and Information Sciences,scopus,2020-10-01,sciencedirect,Classification and reconstruction algorithms for the archaeological fragments,https://api.elsevier.com/content/abstract/scopus_id/85054012203,"The ancient pottery is often found in archaeological sites in a broken state, especially when those pieces of unknown organisms and irregular fragments, may take years of hard work, especially in the case of loss of some pieces or require hard work and experienced archaeologists. So this problem is divided into two major tasks the first of which is the Classification of Archaeological Fragments into similar groups (CAF) and the second one is the Reconstruction of each group into the original Archaeological Objects (RAO). To solve this problem, a method has been proposed, which exploits the color and texture properties of the surfaces of the fragments. Furthermore, the reconstruction of archaeological fragments in 3D geometry is an important problem in pattern recognition. Therefore, this research has implemented the algorithms to reconstruct real datasets using Neural Networks. The challenge of this work is to reconstruct the objects without previous knowledge about the part that should start the assembly; this greatly helps to avoid the presence of gaps created due to missing artifact fragments. The study utilizes the geometric features of the fragments as important features to reconstruct the objects by classifying their fragments using a Neural Network model.",multimedia
10.1016/j.neucom.2020.04.018,Journal,Neurocomputing,scopus,2020-09-24,sciencedirect,Residue Number System-Based Solution for Reducing the Hardware Cost of a Convolutional Neural Network,https://api.elsevier.com/content/abstract/scopus_id/85086393278,"Convolutional neural networks (CNNs) represent deep learning architectures that are currently used in a wide range of applications, including computer vision, speech recognition, time series analysis in finance, and many others. At the same time, CNNs are very demanding in terms of the hardware and time cost of a computing system, which considerably restricts their practical use, e.g., in embedded systems, real-time systems, and mobile volatile devices. The goal of this paper is to reduce the resources required to build and operate CNNs. To achieve this goal, a CNN architecture based on Residue Number System (RNS) and the new Chinese Remainder Theorem with fractions is proposed. The new architecture gives an efficient solution to the main problem of RNSs associated with restoring the number from its residues, which determines the main contribution to the CNN structure. In accordance with the results of hardware simulation on Kintex7 xc7k70tfbg484-2 FPGA, the use of RNS in the convolutional layer of a neural network reduces hardware cost by 32.6% compared to the traditional approach based on the binary number system. In addition, the use of the proposed hardware-software architecture reduces the average image recognition time by 37.06% compared to the software implementation.",multimedia
10.1016/j.echo.2020.04.019,Journal,Journal of the American Society of Echocardiography,scopus,2020-09-01,sciencedirect,Geometry of Tricuspid Valve Apparatus in Patients with Mitral Regurgitation due to Fibroelastic Deficiency versus Barlow Disease: A Real-Time Three-dimensional Transesophageal Echocardiography Study,https://api.elsevier.com/content/abstract/scopus_id/85089790709,"Background
                  Tricuspid valve (TV) geometry gained attention when the prognostic significance of tricuspid regurgitation (TR) was determined. However, the TV geometric characteristics in Barlow disease (BD) have not been elucidated. This study aimed to clarify the difference in TV morphology between BD and fibroelastic deficiency (FED) and the effect of its geometry on residual TR after tricuspid annuloplasty (TAP) using three-dimensional (3D) transesophageal echocardiography.
               
                  Methods
                  Based on the mitral valve (MV) morphology defined by 3D transesophageal echocardiography, 106 patients with degenerative MV disease were classified into BD (n = 42) and FED (n = 64). Three-dimensional images of the TV were analyzed using a quantification software to compare the geometrical parameters. Among them, 35 patients (17 with BD and 18 with FED) underwent concomitant TAP during MV surgery, and the residual TR after TAP was evaluated within 1 month.
               
                  Results
                  TV annulus area, billowing height, and billowing volume were greater in BD than in FED (10.8 ± 2.9 vs 9.2 ± 2.4 cm2, 4.6 ± 1.6 vs 2.3 ± 1.1 mm, and 1.3 ± 0.8 vs 0.3 ± 0.3 mL; all P < .01). In contrast, TV tenting height and tenting volume were smaller in BD than in FED (2.6 ± 1.5 vs 4.4 ± 2.4 mm and 0.3 ± 0.4 vs 0.9 ± 1.0 mL; both P < .01). These morphologic differences in TV were similar to those in MV. There was a strong correlation between MV billowing volume and TV billowing volumes (R = 0.83, P < .01). The prevalence of significant residual TR after TAP was greater in BD than in FED (35% vs 0%, P < .01). Moderate correlations between TV billowing height and volume and residual TR after TAP were observed (R = 0.47 and 0.49, respectively, both P < .01).
               
                  Conclusions
                  Patients with BD exhibited larger TV annulus area and billowing than FED patients. These results suggest that degenerative changes in the TV apparatus in BD patients are similar to that seen in the MV apparatus. These findings should be taken into consideration when a TV surgery is required.",multimedia
10.1016/j.rser.2020.109920,Journal,Renewable and Sustainable Energy Reviews,scopus,2020-09-01,sciencedirect,Virtual testbed for model predictive control development in district cooling systems,https://api.elsevier.com/content/abstract/scopus_id/85086021217,"Recently, with increasing cooling demands, district cooling has assumed an important role as it is more efficient than stand-alone cooling systems. District cooling reduces the environmental impact and promotes the use of renewable sources. Earlier studies to optimise the production plants of district cooling systems were focused primarily on plants with compressor chillers and thermal energy storage devices. Although absorption chillers are crucial for integrating renewable sources into these systems, very few studies have considered them from the cooling perspective. In this regard, this paper presents the progress and results of the implementation of a virtual testbed based on a digital twin of a district cooling production plant with both compressor and absorption chillers. The aim of this study, carried out within the framework of INDIGO, a European Union-funded project, was (i) to develop a reliable model that can be used in a model predictive controller and (ii) to simulate the plant using this controller. The production plant components, which included absorption and compressor chillers, as well as cooling towers, were built using the equation-based Modelica programming language, and were calibrated using information from the manufacturer, together with real operation data. The remainder of the plant was modelled in Python. To integrate the Modelica models into the Python environment, a combination of machine learning techniques and state-space representation models was used. With these techniques, models with a high computational speed were obtained, which were suitable for real-time applications. These models were then used to build a model predictive control for the production plant to minimise the primary energy usage. The improvements in the control and the resultant energy savings achieved were compared with a baseline case working on a standard cascade control. Energy savings up to 50% were obtained in the simulation-based experiments.",multimedia
10.1016/j.trgeo.2020.100374,Journal,Transportation Geotechnics,scopus,2020-09-01,sciencedirect,Morphological reconstruction method of irregular shaped ballast particles and application in numerical simulation of ballasted track,https://api.elsevier.com/content/abstract/scopus_id/85085755974,"To quantitatively investigate the morphological features of railway ballast, a new statistical index, Curvature Index (CI), was presented. With a set of 584 digitized railway ballast particles obtained through 3D scanning, the statistical distribution functions of CI and existing global shape indices (i.e., long axis, middle axis, short axis and sphericity index) were obtained. Then, based on Proper Orthogonal Decomposition (POD) and Radial Basis Function (RBF) Neural Network, a new shape reconstruction method was proposed to generate an arbitrary number of ballast particles that met the desired probability density distribution of morphological indices. And based on local curvature distribution on particle surface, a new simplification algorithm was implemented to reduce the number of contour points of each particle to no more than 31 on the premise of preserving global and local morphological features, which improved the efficiency of numerical simulations. These methods were used to reconstruct and simplify the arbitrary shapes of gravel ballast particles. Then, a DEM-FEM coupling model of ballasted track-subgrade was established by applying the regenerated ballast particles to analyze the contact stress at the ballast-soil interface. The numerical simulations can effectively reflect the contact stress distributions resulted from laboratory tests, which further confirmed that the reconstruction of the ballast particles reflected the morphological characteristics of real ballast.",multimedia
10.1016/j.neunet.2020.05.022,Journal,Neural Networks,scopus,2020-09-01,sciencedirect,DLPNet: A deep manifold network for feature extraction of hyperspectral imagery,https://api.elsevier.com/content/abstract/scopus_id/85085583989,"Deep learning has received increasing attention in recent years and it has been successfully applied for feature extraction (FE) of hyperspectral images. However, most deep learning methods fail to explore the manifold structure in hyperspectral image (HSI). To tackle this issue, a novel graph-based deep learning model, termed deep locality preserving neural network (DLPNet), was proposed in this paper. Traditional deep learning methods use random initialization to initialize network parameters. Different from that, DLPNet initializes each layer of the network by exploring the manifold structure in hyperspectral data. In the stage of network optimization, it designed a deep-manifold learning joint loss function to exploit graph embedding process while measuring the difference between the predictive value and the actual value, then the proposed model can take into account the extraction of deep features and explore the manifold structure of data simultaneously. Experimental results on real-world HSI datasets indicate that the proposed DLPNet performs significantly better than some state-of-the-art methods.",multimedia
10.1016/j.microc.2020.105038,Journal,Microchemical Journal,scopus,2020-09-01,sciencedirect,A smartphone-based rapid quantitative detection platform for lateral flow strip of human chorionic gonadotropin with optimized image algorithm,https://api.elsevier.com/content/abstract/scopus_id/85085341749,"Colloidal gold immunochromatographic test strip has been widely used as a rapid, simple and low-cost correct detection technology. However, its detection is often qualitative or semi-quantitative, which limits its clinical application to some extent. Herein, a portable test strip quantitative detection device based on smartphone to detect human chorionic gonadotropin (HCG) is developed. In experiment, a colloidal gold HCG detection strip based on antigen antibody immune response is constructed, and the quantitative results of three different image processing methods on the same strip detection are compared, including the threshold processing algorithm based on location information, the RGB color component extraction algorithm and the grayscale projection value processing algorithm, the results show that the last algorithm can realize the best recognition of the region of interest of strip. The mobile phone application software (App) based on this design shows that the detection limit of constructed colloidal gold HCG strip is 3 ng/mL with a linear range of 6–300 ng/mL. The detection result of real urine sample is consistent with the spiked concentration (R2 = 0.988), indicating that the concentration of HCG can be accurately measured in urine with this method, presenting the potential for instant diagnosis.",multimedia
10.1016/j.compind.2020.103226,Journal,Computers in Industry,scopus,2020-09-01,sciencedirect,Perspective on holonic manufacturing systems: PROSA becomes ARTI,https://api.elsevier.com/content/abstract/scopus_id/85085261123,"Looking back at 30 years of research into holonic manufacturing systems, these explorations made a lasting scientific contribution to the overall architecture of intelligent manufacturing systems. Most notably, holonic architectures are defined in terms of their world-of-interest (Van Brussel et al., 1998). They do not have an information layer, a communication layer, etc. Instead, they have components that relate to real-world assets (e.g. machine tools) and activities (e.g. assembly). And, they mirror and track the structure of their world-of-interest, which allows them to scale and adapt accordingly.
                  This research has wandered around, at times learning from its mistakes, and progressively carved out an invariant structure while it translated and applied scientific insights from complex-adaptive systems theory (e.g. autocatalytic sets) and from bounded rationality (e.g. holons). This paper presents and discusses the outcome of these research efforts.
                  At the top level, the holonic structure distinguishes intelligent beings (or digital twins) from intelligent agents. These digital twins inherit the consistency from reality, which they mirror. They are intelligent beings when they reflect what exists in the world without imposing artificial limitations in this reality. Consequently, a conflict with a digital twin is a conflict with reality.
                  In contrast, intelligent agents typically transform NP-hard challenges into computations with low-polynomial complexity. Unavoidably, this involves arbitrariness (e.g. don’t care choices). Likewise, relying on case-specific properties, to ensure an outcome in polynomial time, usually renders the validity of an agent’s choices both short-lived and situation-dependent. Here, intelligent agents create conflicts by imposing limitations of their own making in their world-of-interest.
                  Real-world smart systems are aggregates comprising both intelligent beings and intelligent agents. They are performers. Inside these performers, digital twins may constitute the foundations, supporting walls, support beams and pillars because these intelligent beings are protected by their real-world counterpart. Further refining the top-level of this architecture, a holonic structure enables these digital twins to shadow their real-world counterpart whenever it changes, adapts and evolves.
                  In contrast, the artificial limitations, imposed by the intelligent agents, cannot be allowed to build up inertia, which would hamper the undoing of arbitrary or case-specific limitations. To this end, performers explicitly manage the rights over their assets. Revoking such rights from a limitation-imposing agent will free the assets. This will be at the cost of reduced services from the agent. When other service providers rely on this agent, their services may be affected as well; that’s how the inertia builds up and how harmful legacy is created. Thus, the services of digital twins are to be preferred over the services of an intelligent agent by developers of holonic manufacturing systems.
                  Finally, digital twins corresponding to the decision making in the world-of-interest (a non-physical asset) allow to mirror the world-of-interest in a predictive mode (in addition to track and trace). It allows to generate short-term forecasts while preserving the benefits of intelligent beings. These twins are the intentions of the decision-making intelligent agents. Evidently, when intentions change, the forecasts needs to be regenerated (i.e. tracking the corresponding reality by the twin). This advanced feature can be deployed in a number of configurations (cf. annex).",multimedia
10.1016/j.ipm.2020.102275,Journal,Information Processing and Management,scopus,2020-09-01,sciencedirect,Joint deep feature learning and unsupervised visual domain adaptation for cross-domain 3D object retrieval,https://api.elsevier.com/content/abstract/scopus_id/85084544371,"With the widespread application of 3D capture devices, diverse 3D object datasets from different domains have emerged recently. Consequently, how to obtain the 3D objects from different domains is becoming a significant and challenging task. The existing approaches mainly focus on the task of retrieval from the identical dataset, which significantly constrains their implementation in real-world applications. This paper addresses the cross-domain object retrieval in an unsupervised manner, where the labels of samples from source domain are provided while the labels of samples from target domain are unknown. We propose a joint deep feature learning and visual domain adaptation method (Deep-VDA) to solve the cross-domain 3D object retrieval problem by the end-to-end learning. Specifically, benefiting from the advantages of deep learning networks, Deep-VDA employs MVCNN for deep feature extraction and domain alignment for unsupervised domain adaptation. The framework can enable the statistical and geometric shift between domains to be minimized in an unsupervised manner, which is accomplished by preserving both common and unique characteristics of each domain. Deep-VDA can improve the robustness of object features from different domains, which is important to maintain remarkable retrieval performance.",multimedia
10.1016/j.apergo.2020.103138,Journal,Applied Ergonomics,scopus,2020-09-01,sciencedirect,A novel vision-based real-time method for evaluating postural risk factors associated with musculoskeletal disorders,https://api.elsevier.com/content/abstract/scopus_id/85084118643,"Real-time risk assessment for work-related musculoskeletal disorders (MSD) has been a challenging research problem. Previous methods such as using depth cameras suffered from limited visual range and wearable sensors could cause intrusiveness to the workers, both of which are less feasible for long-run on-site applications. This document examines a novel end-to-end implementation of a deep learning-based algorithm for rapid upper limb assessment (RULA). The algorithm takes normal RGB images as input and outputs the RULA action level, which is a further division of RULA grand score. Lifting postures collected in laboratory and posture data from Human 3.6 (a public human pose dataset) were used for training and evaluating the algorithm. Overall, the algorithm achieved 93% accuracy and 29 frames per second efficiency for detecting the RULA action level. The results also indicate that using data augmentation (a strategy to diversify the training data) can significantly improve the robustness of the model. The proposed method demonstrates its high potential for real-time on-site risk assessment for the prevention of work-related MSD. A demo video can be found at https://github.com/LLDavid/RULA_2DImage.",multimedia
10.1016/j.heliyon.2020.e04667,Journal,Heliyon,scopus,2020-08-01,sciencedirect,Effects of mobile augmented reality apps on impulse buying behavior: An investigation in the tourism field,https://api.elsevier.com/content/abstract/scopus_id/85089806662,"Many of today's online services are designed specifically to encourage impulse buying. Moreover, many studies have shown that with the assistance of Mobile Augmented Reality, retailers have the potential to significantly improve their sales. However, the effects of Mobile AR on consumer impulse buying behavior have yet to be examined, particularly in the tourism field. Consequently, the present study integrates the Technology Acceptance Model (TAM), Stimulus-Organism-Response (SOR) framework, and flow theory to examine the effects of Mobile AR apps on tourist impulse buyingbehavior. The research model is implemented using an online questionnaire, with the results analyzed by Partial-Least-Squares Structural Equation Modeling (PLS-SEM) approach. The results obtained from 479 valid samples show that the characteristics of Mobile AR apps play an important role in governing tourist behavior in making unplanned purchases. In particular, as the utility, ease-of-use, and interactivity of the apps increase, the perceived enjoyment and satisfaction of the user also increase and give rise to a stronger impulse buying behavior. The results also reveal a mediating effect of the flow experience on the relationship between the perceived ease of use of the Mobile AR app and the user satisfaction in using the app. Overall, the findings presented in this study provide a useful source of reference for Mobile AR app developers, retailers, and tourism marketers in better understanding users' preferences for Mobile AR apps and strengthening their impulse buying behavior in the tourism context as a result.",multimedia
10.1016/j.dcan.2020.07.003,Journal,Digital Communications and Networks,scopus,2020-08-01,sciencedirect,Security and privacy in 6G networks: New areas and new challenges,https://api.elsevier.com/content/abstract/scopus_id/85088789808,"With the deployment of more and more 5g networks, the limitations of 5g networks have been found, which undoubtedly promotes the exploratory research of 6G networks as the next generation solutions. These investigations include the fundamental security and privacy problems associated with 6G technologies. Therefore, in order to consolidate and solidify this foundational research as a basis for future investigations, we have prepared a survey on the status quo of 6G security and privacy. The survey begins with a historical review of previous networking technologies and how they have informed the current trends in 6G networking. We then discuss four key aspects of 6G networks – real-time intelligent edge computing, distributed artificial intelligence, intelligent radio, and 3D intercoms – and some promising emerging technologies in each area, along with the relevant security and privacy issues. The survey concludes with a report on the potential use of 6G. Some of the references used in this paper along and further details of several points raised can be found at: security-privacyin5g-6g.github.io.",multimedia
10.1016/j.jbi.2020.103483,Journal,Journal of Biomedical Informatics,scopus,2020-08-01,sciencedirect,Agents and robots for collaborating and supporting physicians in healthcare scenarios,https://api.elsevier.com/content/abstract/scopus_id/85087202709,"Monitoring patients through robotics telehealth systems is an interesting scenario where patients’ conditions, and their environment, are dynamic and unknown variables. We propose to improve telehealth systems’ features to include the ability to serve patients with their needs, operating as human caregivers. The objective is to support the independent living of patients at home without losing the opportunity to monitor their health status. Application scenarios are several, and they spread from simple clinical assisting scenarios to an emergency one. For instance, in the case of a nursing home, the system would support in continuously monitoring the elderly patients. In contrast, in the case of an epidemic diffusion, such as COVID-19 pandemic, the system may help in all the early triage phases, significantly reducing the risk of contagion. However, the system has to let medical assistants perform actions remotely such as changing therapies or interacting with patients that need support. The paper proposes and describes a multi-agent architecture for intelligent medical care. We propose to use the beliefs-desires-intentions agent architecture, part of it is devised to be deployed in a robot. The result is an intelligent system that may allow robots the ability to select the most useful plan for unhandled situations and to communicate the choice to the physician for his validation and permission.",multimedia
10.1016/j.cie.2020.106585,Journal,Computers and Industrial Engineering,scopus,2020-08-01,sciencedirect,Deep learning-based mobile augmented reality for task assistance using 3D spatial mapping and snapshot-based RGB-D data,https://api.elsevier.com/content/abstract/scopus_id/85086575779,"This paper proposes a new deep learning-based mobile AR for intelligent task assistance by conducting 3D spatial mapping without pre-registration using AR markers, which can match virtual AR objects to their corresponding physical objects automatically and accurately using single snapshot-based RGB-D data. Firstly, the proposed approach applies a deep learning-based instance segmentation method to the snapshot-based RGB-D data to detect real object instances and to segment their surrounding regions in 3D point cloud data. Then, an iterative closest point (ICP) algorithm is used to perform a 3D spatial mapping between the segmented point cloud of the real object and its corresponding virtual model. Therefore, the virtual information can be seamlessly and automatically synchronized with its corresponding real object. To prove the effectiveness of the proposed method, we performed comparative experiments quantitatively and qualitatively, which evaluated the accuracy, basic task performance, and usability. Experimental results verify that the proposed deep learning-based 3D spatial mapping approach is more accurate and more suitable for mobile AR-based visualization and interaction than previous studies. We have also implemented several applications in actual working situations, which verifies the applicability and extensibility of the proposed approach.",multimedia
10.1016/j.comnet.2020.107276,Journal,Computer Networks,scopus,2020-07-20,sciencedirect,Near-optimal and learning-driven task offloading in a 5G multi-cell mobile edge cloud,https://api.elsevier.com/content/abstract/scopus_id/85084697840,"With development well underway, 5G is envisioned as an enabler of lighting fast mobile services, such as virtual reality, augmented reality, live video analytics, and etc. In particular, multi-cell Mobile Edge Clouds (MEC) with 5G base stations endowed with computing capability are able to promote the Quality of Services (QoS) of mobile users by executing tasks in the edge cloud. Due to the varying 5G network conditions and limited computation capacity of each base station in the multi-cell MEC, as well as the stringent QoS requirements, a fundamental and challenging problem is how to offload user tasks to the edge cloud, such that the energy consumption of mobile devices is minimized. In this paper, we first formulate the offline and online location-aware mobile task offloading problems in a multi-cell MEC. For the offline location-aware mobile task offloading problem, we then develop an exact solution and an approximation algorithm with an approximation ratio. For the online problem, we thirdly propose a novel deep reinforcement learning-based offloading algorithm for mobile users to obtain the optimal offloading policy. We finally conduct extensive experiments by simulations to evaluate the proposed algorithms against existing benchmarks. The experimental results show that the proposed algorithms are promising and outperform the benchmark algorithms by significantly reducing energy cost of mobile devices and delays experienced by mobile users.",multimedia
10.1016/j.neucom.2020.02.035,Journal,Neurocomputing,scopus,2020-07-20,sciencedirect,Sparse low rank factorization for deep neural network compression,https://api.elsevier.com/content/abstract/scopus_id/85081399638,"Storing and processing millions of parameters in deep neural networks is highly challenging during the deployment of model in real-time application on resource constrained devices. Popular low-rank approximation approach singular value decomposition (SVD) is generally applied to the weights of fully connected layers where compact storage is achieved by keeping only the most prominent components of the decomposed matrices. Years of research on pruning-based neural network model compression revealed that the relative importance or contribution of each neuron in a layer highly vary among each other. Recently, synapses pruning has also demonstrated that having sparse matrices in network architecture achieve lower space and faster computation during inference time. We extend these arguments by proposing that the low-rank decomposition of weight matrices should also consider significance of both input as well as output neurons of a layer. Combining the ideas of sparsity and existence of unequal contributions of neurons towards achieving the target, we propose sparse low rank (SLR) method which sparsifies SVD matrices to achieve better compression rate by keeping lower rank for unimportant neurons. We demonstrate the effectiveness of our method in compressing famous convolutional neural networks based image recognition frameworks which are trained on popular datasets. Experimental results show that the proposed approach SLR outperforms vanilla truncated SVD and a pruning baseline, achieving better compression rates with minimal or no loss in the accuracy. Code of the proposed approach is avaialble at https://github.com/sridarah/slr.",multimedia
10.1016/j.comcom.2020.05.047,Journal,Computer Communications,scopus,2020-07-01,sciencedirect,Artificial intelligence driven wireless network remote monitoring based on Diffie–Hellman parameter method,https://api.elsevier.com/content/abstract/scopus_id/85085639148,"Remote monitoring of wireless networks based on artificial intelligence can build sensitive anomaly recognition mechanisms, automated event analysis engines and accurate global operation and maintenance capabilities for wireless network defense. Firstly, a simple camera is used to realize real-time acquisition and wireless transmission of video signals based on software-based MPEG-4 compression coding method. The self-developed ActiveX control with video decoding function is embedded in the webpage to realize real-time dynamic display of video information in the computer browser of the monitoring terminal. Secondly, in order to realize the intelligent control of wireless network, the research based on the reverse motion degree posture planning is carried out. The DH parameter method is used to establish the linkage coordinate system of wireless network remote monitoring, and the kinematics formula is derived. The geometric analysis method is used to calculate the motion trajectory of remote monitoring, accurately locate the various angles of remote monitoring and obtain the best motion path. Based on the Pm angle control method of fuzzy neural network, the RBF neural network, fuzzy control the combination of control and Pm control, using the self-learning ability of the neural network and the fuzzy reasoning is ability of fuzzy control. The end effector was adjusted to the target position. Finally, the established mathematical model was simulated by MATLAB, and the characteristics of wireless network remote monitoring were verified.",multimedia
10.1016/j.jvcir.2020.102798,Journal,Journal of Visual Communication and Image Representation,scopus,2020-07-01,sciencedirect,An effective hybrid pruning architecture of dynamic convolution for surveillance videos,https://api.elsevier.com/content/abstract/scopus_id/85084956273,"The large-scale surveillance videos analysis becomes important as the development of the intelligent city; however, the heavy computational resources necessary for the state-of-the-art deep learning model makes real-time processing hard to be implemented. As the characteristic of high scene similarity generally existing in surveillance videos, we propose an effective compression architecture called dynamic convolution, which can reuse the previous feature maps to reduce the calculation amount; and combine with filter pruning to further speed up the performance. In this paper, we tested the presented method on 45 surveillance videos with various scenes. The experimental results show that the hybrid pruning architecture can reduce up to 80.4% of FLOPs while preserving the precision within 1.34% mAP; furthermore, the method can improve the processing speed up to 2.8 times compared to the traditional Single Shot MultiBox Detection.",multimedia
10.1016/j.jvcir.2019.102740,Journal,Journal of Visual Communication and Image Representation,scopus,2020-07-01,sciencedirect,Human-computer interaction based on face feature localization,https://api.elsevier.com/content/abstract/scopus_id/85084949867,"Human-computer interaction is the way in which humans and machines communicate information. With the rapid development of deep learning technology, the technology of human-computer interaction has also made a corresponding breakthrough. In the past, the way human-computer interaction was mostly relied on hardware devices. Through the coordinated work of multiple sensors, people and machines can realize information interaction. However, as theoretical technology continues to mature, algorithms for human-computer interaction are also being enriched. The popularity of convolutional neural networks has made image processing problems easier to solve. Therefore, real-time human-computer interaction can be performed by using image processing, and intelligent of human-computer interaction can be realized. The main idea of this paper is to use the real-time capture of face images and video information to image the face image information. We perform feature point positioning based on the feature points of the face image. We perform expression recognition based on the feature points that are located. At the same time, we perform ray tracing for the identified human eye area. The feature points of the face and the corresponding expressions and implementation movements represent the user's use appeal. Therefore, we can analyze the user's use appeal by locating the face feature area. We define the corresponding action information for specific user face features. We extract the user's corresponding information according to the user's face features, and perform human-computer interaction according to the user's information.",multimedia
10.1016/j.arth.2020.04.048,Journal,Journal of Arthroplasty,scopus,2020-07-01,sciencedirect,Digital Orthopaedics: A Glimpse Into the Future in the Midst of a Pandemic,https://api.elsevier.com/content/abstract/scopus_id/85084400483,"Background
                  The response to COVID-19 catalyzed the adoption and integration of digital health tools into the health care delivery model for musculoskeletal patients. The change, suspension, or relaxation of Medicare and federal guidelines enabled the rapid implementation of these technologies. The expansion of payment models for virtual care facilitated its rapid adoption. The authors aim to provide several examples of digital health solutions utilized to manage orthopedic patients during the pandemic and discuss what features of these technologies are likely to continue to provide value to patients and clinicians following its resolution.
               
                  Conclusion
                  The widespread adoption of new technologies enabling providers to care for patients remotely has the potential to permanently change the expectations of all stakeholders about the way care is provided in orthopedics. The new era of Digital Orthopaedics will see a gradual and nondisruptive integration of technologies that support the patient’s journey through the successful management of their musculoskeletal disease.",multimedia
10.1016/j.patcog.2020.107312,Journal,Pattern Recognition,scopus,2020-07-01,sciencedirect,Learning motion representation for real-time spatio-temporal action localization,https://api.elsevier.com/content/abstract/scopus_id/85081115959,"The current deep learning based spatio-temporal action localization methods that using motion information (predominated is optical flow) obtain the state-of-the-art performance. However, since the optical flow is pre-computed, leading to these methods face two problems – the computational efficiency is low and the whole network is not end-to-end trainable. We propose a novel spatio-temporal action localization approach with an integrated optical flow sub-network to address these two issues. Specifically, our designed flow subnet can estimate optical flow efficiently and accurately by using multiple consecutive RGB frames rather than two adjacent frames in a deep network, simultaneously, action localization is implemented in the same network interactive with flow computation end-to-end. To faster the speed, we exploit a neural network based feature fusion method in a pyramid hierarchical manner. It fuses spatial and temporal features at different granularities via combination function (i.e. concatenation) and point-wise convolution to obtain multiscale spatio-temporal action features. Experimental results on three publicly available datasets, e.g. UCF101-24, JHMDB and AVA show that with both RGB appearance and optical flow cues, the proposed method gets the state-of-the-art performance in both efficiency and accuracy. Noticeably, it gets a significant improvement on efficiency. Compared to the currently most efficient method, it is 1.9 times faster in the running speed and 1.3% video-mAP more accurate on the UCF101-24. Our proposed method reaches real-time computation for the first time (up to 38 FPS).",multimedia
10.1016/j.isatra.2020.02.023,Journal,ISA Transactions,scopus,2020-07-01,sciencedirect,Strengthening the perception of the virtual worlds in a virtual reality environment,https://api.elsevier.com/content/abstract/scopus_id/85080060395,"Virtual reality is becoming more and more improved primarily due to numerous applications and the powers of mobile devices. Using various sensors, precise displays and high computing powers smartphone are becoming devices that make the boost in technology. Now it is necessary to efficiently use various sensors without affecting system operation and improve control abilities for various purposes. Especially in practical applications received by mass users such as games and any kind of experience. In this article, we propose a system that allows to extend the perception of the virtual world by conveying information about the user’s movements in reality into the supervised model. The system retrieves data from several sources, quickly analyzes them using artificial intelligence techniques, and returns information to the mobile phone about the activity that is being processed. The concept extends the understanding of today’s virtual reality by allowing the user to move and perform simple gestures in a specially designed room. Moreover, we propose multiplayer mode in virtual reality, where players are in different places. The proposed architecture of the system has been tested on simple applications, and the results show high potential for implementations in various apps by achieving almost 90% efficiency in changing player direction in real time and only 7.5% of collision cases.",multimedia
10.1016/j.cmpb.2020.105410,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-07-01,sciencedirect,Real-time computer vision system for tracking simultaneously subject-specific rigid head and non-rigid facial mimic movements using a contactless sensor and system of systems approach,https://api.elsevier.com/content/abstract/scopus_id/85079884752,"Background and Objective
                  Head and facial mimic animations play important roles in various fields such as human-machine interactions, internet communications, multimedia applications, and facial mimic analysis. Numerous studies have been trying to simulate these animations. However, they hardly achieved all requirements of full rigid head and non-rigid facial mimic animations in a subject-specific manner with real-time framerates. Consequently, this present study aimed to develop a real-time computer vision system for tracking simultaneously rigid head and non-rigid facial mimic movements.
               
                  Methods
                  Our system was developed using the system of systems approach. A data acquisition sub-system was implemented using a contactless Kinect sensor. A subject-specific model generation sub-system was designed to create the geometrical model from the Kinect sensor without texture information. A subject-specific texture generation sub-system was designed for enhancing the reality of the generated model with texture information. A head animation sub-system with graphical user interfaces was also developed. Model accuracy and system performances were analyzed.
               
                  Results
                  The comparison with MRI-based model shows a very good accuracy level (distance deviation of ~1 mm in neutral position and an error range of [2–3 mm] for different facial mimic positions) for the generated model from our system. Moreover, the system speed can be optimized to reach a high framerate (up to 60 fps) during different head and facial mimic animations.
               
                  Conclusions
                  This study presents a novel computer vision system for tracking simultaneously subject-specific rigid head and non-rigid facial mimic movements in real time. In perspectives, serious game technology will be integrated into this system towards a full computer-aided decision support system for facial rehabilitation.",multimedia
10.1016/j.patter.2020.100042,Journal,Patterns,scopus,2020-06-12,sciencedirect,Deep Learning Identifies Digital Biomarkers for Self-Reported Parkinson's Disease,https://api.elsevier.com/content/abstract/scopus_id/85095745471,"Large-scale population screening and in-home monitoring for patients with Parkinson's disease (PD) has so far been mainly carried out by traditional healthcare methods and systems. Development of mobile health may provide an independent, future method to detect PD. Current PD detection algorithms will benefit from better generalizability with data collected in real-world situations. In this paper, we report the top-performing smartphone-based method in the recent DREAM Parkinson's Disease Digital Biomarker Challenge for digital diagnosis of PD. Utilizing real-world accelerometer records, this approach differentiated PD from control subjects with an area under the receiver-operating characteristic curve of 0.87 by 3D augmentation of accelerometer records, a significant improvement over other state-of-the-art methods. This study paves the way for future at-home screening of PD and other neurodegenerative conditions affecting movement.",multimedia
10.1016/j.engappai.2020.103692,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-06-01,sciencedirect,A novel strategy for classifying perceived video quality using electroencephalography signals,https://api.elsevier.com/content/abstract/scopus_id/85084560826,"Video streaming through the Internet is abundant nowadays. While video quality is continuously demanded, monitoring users’ quality of experience (QoE) is essential when watching video contents. QoE can be evaluated directly through subjective assessment which is the human ground truths; however, such assessment is generally expensive and time consuming, and cannot be implemented in real time. QoE can also be evaluated by video quality models; however, the evaluation is fully based on video contents but human physical states cannot be taken into account. To tackle the limitations, detection of a prominent electroencephalography (EEG) signal feature namely P300 correlated to QoE can be used, when users are viewing videos. P300 is a positive deflection pulse that appears around 300 ms after a significant video distortion appears. QoE can be indicated by P300 pulses. However, the captured EEG signal is generally contaminated with noise. Strong noise generates P300 although video carries no distortion. Hence, detections of P300 patterns are not accurate. In this paper, a double classifier consisting of a first and second classifier is proposed. The first classifier attempts to determine whether the captured EEG feature is abnormal or not, where the abnormal caption behaves opposite to the normal P300 characteristic when showing the distorted video. The second classifier is developed to perform classifications for either normal or abnormal features. We evaluate the performance of the proposed double classifier based on the EEG samples, which are captured when showing video stimuli to participants. The proposed classifier is implemented by the support vector machine and logistic regression, which are commonly used for detection of EEG patterns and are computationally much simpler than deep learning. The performance of the proposed classifier is compared to those of the single classifiers, which determine the QoE directly when the EEG signal is given. Cross-validations showed that generally more than 5% improvement can be achieved by the proposed double classifier. Statistical tests indicate that the proposed double classifier can generally obtain better classification rates than solely using the single classifier at a 97.5% confidence level.",multimedia
10.1016/j.engappai.2020.103670,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-06-01,sciencedirect,"Detecting, locating and recognising human touches in social robots with contact microphones",https://api.elsevier.com/content/abstract/scopus_id/85083676413,"There are many situations in our daily life where touch gestures during natural human–human interaction take place: meeting people (shaking hands), personal relationships (caresses), moments of celebration or sadness (hugs), etc. Considering that robots are expected to form part of our daily life in the future, they should be endowed with the capacity of recognising these touch gestures and the part of its body that has been touched since the gesture’s meaning may differ. Therefore, this work presents a learning system for both purposes: detect and recognise the type of touch gesture (stroke, tickle, tap and slap) and its localisation. The interpretation of the meaning of the gesture is out of the scope of this paper.
                  Different technologies have been applied to perceive touch by a social robot, commonly using a large number of sensors. Instead, our approach uses 3 contact microphones installed inside some parts of the robot. The audio signals generated when the user touches the robot are sensed by the contact microphones and processed using Machine Learning techniques. We acquired information from sensors installed in two social robots, Maggie and Mini (both developed by the RoboticsLab at the Carlos III University of Madrid), and a real-time version of the whole system has been deployed in the robot Mini. The system allows the robot to sense if it has been touched or not, to recognise the kind of touch gesture, and its approximate location. The main advantage of using contact microphones as touch sensors is that by using just one, it is possible to “cover” a whole solid part of the robot. Besides, the sensors are unaffected by ambient noises, such as human voice, TV, music etc. Nevertheless, the fact of using several contact microphones makes possible that a touch gesture is detected by all of them, and each may recognise a different gesture at the same time. The results show that this system is robust against this phenomenon. Moreover, the accuracy obtained for both robots is about 86%.",multimedia
10.1016/j.gie.2019.12.049,Journal,Gastrointestinal Endoscopy,scopus,2020-06-01,sciencedirect,Artificial intelligence using convolutional neural networks for real-time detection of early esophageal neoplasia in Barrett's esophagus (with video),https://api.elsevier.com/content/abstract/scopus_id/85082811592,"Background and Aims
                  The visual detection of early esophageal neoplasia (high-grade dysplasia and T1 cancer) in Barrett’s esophagus (BE) with white-light and virtual chromoendoscopy still remains challenging. The aim of this study was to assess whether a convolutional neural artificial intelligence network can aid in the recognition of early esophageal neoplasia in BE.
               
                  Methods
                  Nine hundred sixteen images from 65 patients of histology-proven early esophageal neoplasia in BE containing high-grade dysplasia or T1 cancer were collected. The area of neoplasia was masked using image annotation software. Nine hundred nineteen control images were collected of BE without high-grade dysplasia. A convolutional neural network (CNN) algorithm was pretrained on ImageNet and then fine-tuned with the goal of providing the correct binary classification of “dysplastic” or “nondysplastic.” We developed an object detection algorithm that drew localization boxes around regions classified as dysplasia.
               
                  Results
                  The CNN analyzed 458 test images (225 dysplasia and 233 nondysplasia) and correctly detected early neoplasia with sensitivity of 96.4%, specificity of 94.2%, and accuracy of 95.4%. With regard to the object detection algorithm for all images in the validation set, the system was able to achieve a mean average precision of .7533 at an intersection over union of .3
               
                  Conclusions
                  In this pilot study, our artificial intelligence model was able to detect early esophageal neoplasia in BE images with high accuracy. In addition, the object detection algorithm was able to draw a localization box around the areas of dysplasia with high precision and at a speed that allows for real-time implementation.",multimedia
10.1016/j.jnca.2020.102596,Journal,Journal of Network and Computer Applications,scopus,2020-06-01,sciencedirect,On the classification of fog computing applications: A machine learning perspective,https://api.elsevier.com/content/abstract/scopus_id/85082445495,"Currently, Internet applications running on mobile devices generate a massive amount of data that can be transmitted to a Cloud for processing. However, one fundamental limitation of a Cloud is the connectivity with end devices. Fog computing overcomes this limitation and supports the requirements of time-sensitive applications by distributing computation, communication, and storage services along the Cloud to Things (C2T) continuum, empowering potential new applications, such as smart cities, augmented reality (AR), and virtual reality (VR). However, the adoption of Fog-based computational resources and their integration with the Cloud introduces new challenges in resource management, which requires the implementation of new strategies to guarantee compliance with the quality of service (QoS) requirements of applications.
                  In this context, one major question is how to map the QoS requirements of applications on Fog and Cloud resources. One possible approach is to discriminate the applications arriving at the Fog into Classes of Service (CoS). This paper thus introduces a set of CoS for Fog applications which includes, the QoS requirements that best characterize these Fog applications. Moreover, this paper proposes the implementation of a typical machine learning classification methodology to discriminate Fog computing applications as a function of their QoS requirements. Furthermore, the application of this methodology is illustrated in the assessment of classifiers in terms of efficiency, accuracy, and robustness to noise. The adoption of a methodology for machine learning-based classification constitutes a first step towards the definition of QoS provisioning mechanisms in Fog computing. Moreover, classifying Fog computing applications can facilitate the decision-making process for Fog scheduler.",multimedia
10.1016/j.rcim.2019.101887,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2020-06-01,sciencedirect,Deep learning-based smart task assistance in wearable augmented reality,https://api.elsevier.com/content/abstract/scopus_id/85074770255,"Wearable augmented reality (AR) smart glasses have been utilized in various applications such as training, maintenance, and collaboration. However, most previous research on wearable AR technology did not effectively supported situation-aware task assistance because of AR marker-based static visualization and registration. In this study, a smart and user-centric task assistance method is proposed, which combines deep learning-based object detection and instance segmentation with wearable AR technology to provide more effective visual guidance with less cognitive load. In particular, instance segmentation using the Mask R-CNN and markerless AR are combined to overlay the 3D spatial mapping of an actual object onto its surrounding real environment. In addition, 3D spatial information with instance segmentation is used to provide 3D task guidance and navigation, which helps the user to more easily identify and understand physical objects while moving around in the physical environment. Furthermore, 2.5D or 3D replicas support the 3D annotation and collaboration between different workers without predefined 3D models. Therefore, the user can perform more realistic manufacturing tasks in dynamic environments. To verify the usability and usefulness of the proposed method, we performed quantitative and qualitative analyses by conducting two user studies: 1) matching a virtual object to a real object in a real environment, and 2) performing a realistic task, that is, the maintenance and inspection of a 3D printer. We also implemented several viable applications supporting task assistance using the proposed deep learning-based task assistance in wearable AR.",multimedia
10.1016/j.cels.2020.04.006,Journal,Cell Systems,scopus,2020-05-20,sciencedirect,Lattice Light-Sheet Microscopy Multi-dimensional Analyses (LaMDA) of T-Cell Receptor Dynamics Predict T-Cell Signaling States,https://api.elsevier.com/content/abstract/scopus_id/85084658613,"Lattice light-sheet microscopy provides large amounts of high-dimensional, high-spatiotemporal resolution imaging data of cell surface receptors across the 3D surface of live cells, but user-friendly analysis pipelines are lacking. Here, we introduce lattice light-sheet microscopy multi-dimensional analyses (LaMDA), an end-to-end pipeline comprised of publicly available software packages that combines machine learning, dimensionality reduction, and diffusion maps to analyze surface receptor dynamics and classify cellular signaling states without the need for complex biochemical measurements or other prior information. We use LaMDA to analyze images of T-cell receptor (TCR) microclusters on the surface of live primary T cells under resting and stimulated conditions. We observe global spatial and temporal changes of TCRs across the 3D cell surface, accurately differentiate stimulated cells from unstimulated cells, precisely predict attenuated T-cell signaling after CD4 and CD28 receptor blockades, and reliably discriminate between structurally similar TCR ligands. All instructions needed to implement LaMDA are included in this paper.",multimedia
10.1016/j.enbuild.2020.109825,Journal,Energy and Buildings,scopus,2020-05-15,sciencedirect,Building temperature regulation in a multi-zone HVAC system using distributed adaptive control,https://api.elsevier.com/content/abstract/scopus_id/85081129562,"During recent years there have been considerable research efforts on improving energy efficiency of buildings. Since Heating, Ventilation and Air-Conditioning (HVAC) systems are responsible for a big part of energy consumption, developing efficient HVAC control systems is crucial. In most of the developed approaches, precise knowledge of system parameters and/or adequate historical data is required. However, these approaches may not perform as well in the presence of dynamic parameter changes due to human activity, material degradation, and wear and tear, or disturbances and other operational uncertainties due to occupancy, solar gains, electrical equipment, and weather conditions. In this paper, we consider buildings with several climate zones and propose a distributed adaptive control scheme for a multi-zone HVAC system which can effectively regulate zone temperature by applying on-line learning and assuming exchange of information between neighboring zones. The controller of each zone achieves the local objective of controlling zone temperature by compensating for the effects of neighboring zones as well as for possible changes in the parameters of the system. Despite the exchange of information, each local controller does not know how the control actions and temperature of a neighboring zone affect the temperature of its own zone. For this reason, each local controller is estimating the parameters of the interconnections in real time and uses them together with the exchanged information to provide a more accurate local zone temperature control. The proposed method is illustrated using an example of temperature control in a six-zone building as well as a large school building, which are implemented in a Building Controls Virtual Test Bed (BCVTB) environment using EnergyPlus and MATLAB/Simulink.",multimedia
10.1016/j.compag.2020.105347,Journal,Computers and Electronics in Agriculture,scopus,2020-05-01,sciencedirect,Learned features of leaf phenotype to monitor maize water status in the fields,https://api.elsevier.com/content/abstract/scopus_id/85082721743,"Water stress significantly influences normal maize growth. Fast and effective maize water stress detection is of great help to monitor the plant status and provide scientific guidance for crop irrigation. Most of the methods are based on manual measurements of soil water content, or laboratory imaging techniques, such as hyperspectral and thermal images at plant level. With the collection of 656 original maize plant images under natural environment, a novel maize leaf image dataset with different water stress levels (well-watered, reduced-watered and drought-stressed) was constructed. This paper considers maize water status detection as a fine-grained classification problem using local leaf images. Inspired by deep learning, a convolutional neural network (CNN) is applied for the first time to maize water stress recognition. In the designed CNN architecture, feature maps from different convolutional layers are merged. Through visualization and importance analysis of the multi-scale feature maps, several specific feature maps are selected as learned features, which provide a strong discrimination ability. An SVM classifier is finally trained using the feature representation as inputs. Compared with existing techniques, the proposed method achieves the satisfying classification performance with an accuracy of 88.41%. This study also provides a quantitative measure of water stress degree using a regression model. Experimental results demonstrate that the learned features perform better than hand-crafted features to detect water stress and quantify stress severity. The proposed framework can be deployed in practical applications for a non-destructive, near real-time, and automatic monitoring of plant water status in fields.",multimedia
10.1016/j.jngse.2020.103270,Journal,Journal of Natural Gas Science and Engineering,scopus,2020-05-01,sciencedirect,Estimation of reservoir porosity based on seismic inversion results using deep learning methods,https://api.elsevier.com/content/abstract/scopus_id/85082196576,"Location limitation of logged wells restricts the porosity estimation across the whole reservoir target, whereas seismic data are always collected to cover larger areas. In this paper, inversion results of seismic data are proposed as inputs for the prediction of reservoir porosity, even though the resolution is decreased, compared with well-log readings. The non-linear inversion scheme used is able to explore the complex relationship between rock properties and seismic data, which could potentially provide a higher quality of inversion results. As a regression process, Convolutional Neural Networks is then applied to estimate the reservoir porosity, based on the outputs of seismic inversion scheme. Incorporating 2D kernel filters which are convolved with input rock properties, the local information inside filters window is considered, and a better prediction performance is to be guaranteed. This is due to the fact that reservoir porosity is formed under depositional and digenetic rules, and it is intrinsically correlated with rock properties along the vertical direction in a short range. The designed workflow is applied to a real dataset from the Vienna Basin where compressibility and shear compliance are inverted and then used as inputs for the porosity estimation by Convolutional Neural Networks. For a comparison, the traditional Artificial Neural Networks is also trained and applied to the same dataset. It is concluded that the Convolutional Neural Networks can achieve a higher accuracy, and a 3D cube of reservoir porosity is obtained without location restriction of well logs.",multimedia
10.1016/j.compag.2020.105339,Journal,Computers and Electronics in Agriculture,scopus,2020-05-01,sciencedirect,Real-time robust detector for underwater live crabs based on deep learning,https://api.elsevier.com/content/abstract/scopus_id/85082113277,"Image analysis technology has drawn dramatic attention and developed rapidly because it enables a non-extractive and non-destructive approach to data acquisition of crab aquaculture. Owing to the irregular shape, multi-scale posture and special underwater environment, it is very challenging to adopt the traditional image recognition methods to detect crabs quickly and effectively. Consequently, we propose a real-time and robust object detector, Faster MSSDLite, for detecting underwater live crabs. Lightweight MobileNetV2 is selected as the backbone of a single shot multi-box detector (SSD), and standard convolution is replaced by depthwise separable convolution in the prediction layers. A feature pyramid network (FPN) is adopted at low extra cost to improve the detection precision of multi-scale crabs and make up for the deficiency of SSD to force different network layers to learn the same features. More significantly, the unified quantized convolutional neural network (Quantized-CNN) framework is applied to quantify the error correction of the improved detector for further accelerating the computation of convolutional layers and compressing the parameters of fully-connected layers. The test results show that Faster MSSDLite has better performance than traditional SSD. The average precision (AP) and F1
                      score of detection are 99.01% and 98.94%, respectively. The detection speed can reach 74.07 frames per second in commonly configured microcomputers (~8× faster than SSD). The computation amount of floating-point numbers required by the detection is reduced to only 0.32 billion (~49× smaller than SSD), and the size of the model is compressed into 4.84 MB (~28× smaller than SSD). The model is also more robust, which can stably detect underwater live crabs in real-time, estimate the live crab biomass in water bodies automatically, and provide reliable feedback information for the fine feeding of automatic feeding boats.",multimedia
10.1016/j.neunet.2020.02.019,Journal,Neural Networks,scopus,2020-05-01,sciencedirect,SOMprocessor: A high throughput FPGA-based architecture for implementing Self-Organizing Maps and its application to video processing,https://api.elsevier.com/content/abstract/scopus_id/85081163303,"The design of neuromorphic chips aims to develop electronic circuits dedicated to executing artificial neural networks, mainly by exploring parallel processing. Unsupervised learning models, such as Self-organizing Maps (SOM), may benefit from massively concurrent hardware-based implementations to meet the requirements of real-time and embedded applications. This work first presents a theoretical analysis of the algorithms implemented in hardware to compute SOM learning and recall phases. This is important because, albeit similar, the processing steps executed in hardware are not necessarily identical to those executed in software. Then, the proposed FPGA architecture entitled SOMprocessor is shown in detail. The circuit of the processor explores two different computational strategies for increasing the performance of current state-of-the-art works. These computational strategies aim to improve the data flow through the processor and its flexibility to implement different network topologies. Finally, this work presents the application of the SOMprocessor to a video categorization task. The results show that topographic and quantization errors are similar between hardware and software implementations, as well as the overall accuracy. Moreover, the proposed FPGA architecture achieves acceleration of 3 to 4 orders of magnitude as compared to CPU executions.",multimedia
10.1016/j.autcon.2020.103144,Journal,Automation in Construction,scopus,2020-05-01,sciencedirect,Semantic segmentation of point clouds of building interiors with deep learning: Augmenting training datasets with synthetic BIM-based point clouds,https://api.elsevier.com/content/abstract/scopus_id/85081123343,"This paper investigates the viability of using synthetic point clouds generated from building information models (BIMs) to train deep neural networks to perform semantic segmentation of point clouds of building interiors. In order to achieve these goals, this paper first presents a procedure for converting digital 3D BIMs into synthetic point clouds using three commercially available software systems. Then the generated synthetic point clouds are used to train a deep neural network. Semantic segmentation performance is compared for several models trained on: real point clouds, synthetic point clouds, and combinations of real and synthetic point clouds. A key finding is the 7.1% IOU boost in performance achieved when a small real point cloud dataset is augmented by synthetic point clouds for training, as compared to training the classifier on the real data alone. The experimental results confirmed the viability of using synthetic point clouds generated from building information models in combination with small datasets of real point clouds. This opens up the possibility of developing a segmentation model for building interiors that can be applied to as-built modeling of buildings that contain unseen indoor structures.",multimedia
10.1016/j.adhoc.2020.102115,Journal,Ad Hoc Networks,scopus,2020-05-01,sciencedirect,A multi-view CNN-based acoustic classification system for automatic animal species identification,https://api.elsevier.com/content/abstract/scopus_id/85080981174,"Automatic identification of animal species by their vocalization is an important and challenging task. Although many kinds of audio monitoring system have been proposed in the literature, they suffer from several disadvantages such as non-trivial feature selection, accuracy degradation because of environmental noise or intensive local computation. In this paper, we propose a deep learning based acoustic classification framework for Wireless Acoustic Sensor Network (WASN). The proposed framework is based on cloud architecture which relaxes the computational burden on the wireless sensor node. To improve the recognition accuracy, we design a multi-view Convolution Neural Network (CNN) to extract the short-, middle-, and long-term dependencies in parallel. The evaluation on two real datasets shows that the proposed architecture can achieve high accuracy and outperforms traditional classification systems significantly when the environmental noise dominate the audio signal (low SNR). Moreover, we implement and deploy the proposed system on a testbed and analyse the system performance in real-world environments. Both simulation and real-world evaluation demonstrate the accuracy and robustness of the proposed acoustic classification system in distinguishing species of animals.",multimedia
10.1016/j.ijmultiphaseflow.2019.103194,Journal,International Journal of Multiphase Flow,scopus,2020-05-01,sciencedirect,Bubble patterns recognition using neural networks: Application to the analysis of a two-phase bubbly jet,https://api.elsevier.com/content/abstract/scopus_id/85079560188,"Gas-liquid two-phase bubbly flows are found in different areas of science and technology such as nuclear energy, chemical industry, or piping systems. Optical diagnostics of two-phase bubbly flows with modern panoramic techniques makes it possible to capture simultaneously instantaneous characteristics of both continuous and dispersed phases with a high spatial resolution. In this paper, we introduce a novel approach based on neural networks to recognize bubble patterns in images and identify their geometric parameters. The originality of the proposed method consists in training of a neural network ensemble using synthetic images that resemble real photographs gathered in experiment. The use of neural networks in combination with automatically generated data allowed us to detect overlapping, blurred, and non-spherical bubbles in a broad range of volume gas fractions. Experiments on a turbulent bubbly jet proved that the implemented method increases the identification accuracy, reducing errors of various kinds, and lowers the processing time compared to conventional recognition methods. Furthermore, utilizing the new method of bubbles recognition, the primary physical parameters of a dispersed phase, such as bubble size distribution and local gas content, were calculated in a near-to-nozzle region of the bubbly jet. The obtained results and integral experimental parameters, especially volume gas fraction, are in good agreement with each other.",multimedia
10.1016/j.cmpb.2019.105263,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-05-01,sciencedirect,Parallelized collision detection with applications in virtual bone machining,https://api.elsevier.com/content/abstract/scopus_id/85076248977,"Background and objectives
                  Virtual reality surgery simulators have been proved effective for training in several surgical disciplines. Nevertheless, this technology is presently underutilized in orthopaedics, especially for bone machining procedures, due to the limited realism in haptic simulation of bone interactions. Collision detection is an integral part of surgery simulators and its accuracy and computational efficiency play a determinant role on the fidelity of simulations. To address this, the primary objective of this study was to develop a new algorithm that enables faster and more accurate collision detection within 1 ms (required for stable haptic rendering) in order to facilitate the improvement of the realism of virtual bone machining procedures.
               
                  Methods
                  The core of the developed algorithm is constituted by voxmap point shell method according to which tool and osseous tissue geometries were sampled by points and voxels, respectively. The algorithm projects tool sampling points into the voxmap coordinates and compute an intersection condition for each point-voxel pair. This step is massively parallelized using Graphical Processing Units and it is further accelerated by an early culling of the unnecessary threads as instructed by the rapid estimation of the possible intersection volume. A contiguous array was used for implicit definition of voxmap in order to guarantee a fast access to voxels and thereby enable efficient material removal. A sparse representation of tool points was employed for efficient memory reductions. The effectiveness of the algorithm was evaluated at various bone sampling resolutions and was compared with prior relevant implementations.
               
                  Results
                  The results obtained with an average hardware configuration have indicated that the developed algorithm is capable to reliably maintain < 1 ms running time in severe tool-bone collisions, both sampled at 10243 resolutions. The results also showed the algorithm running time has a low sensitivity to bone sampling resolution. The comparisons performed suggested that the proposed approach is significantly faster than comparable methods while relying on lower or similar memory requirements.
               
                  Conclusions
                  The algorithm proposed through this study enables a higher numerical efficiency and is capable to significantly enlarge the maximum resolution that can be used by high fidelity/high realism haptic simulators targeting surgical orthopaedic procedures.",multimedia
10.1016/j.compag.2020.105326,Journal,Computers and Electronics in Agriculture,scopus,2020-04-01,sciencedirect,Automated fruit recognition using EfficientNet and MixNet,https://api.elsevier.com/content/abstract/scopus_id/85081045019,"The classification of fruits offers many useful applications in daily life, such as automated harvesting or building up stocks for supermarkets. Studies have been proposed to classify fruits from input images, exploiting image processing and machine learning techniques. Though a lot of improvements have been achieved in recent years, many approaches still suffer prolonged training/testing time, or a considerably high number of false positives. For several applications, it is crucial to provide users with not only precise but also real-time recommendations. In this paper, we propose a practical solution to fruit recognition by exploiting two recently-developed classifiers that have demonstrated themselves to be both effective and efficient. We adopted EfficientNet and MixNet, two families of deep neural networks to build an expert system being able to accurately and swiftly identify fruits. Such a system can be deployed onto devices with limited computational resources to prompt exact and timely recommendations. The approach’s performance has been validated on a real dataset consisting of 48,905 images for training and 16,421 images for testing. The experimental results showed that the application of EfficientNet and MixNet on the considered dataset substantially improves the overall prediction accuracy in comparison to a well-established baseline.",multimedia
10.1016/j.robot.2020.103472,Journal,Robotics and Autonomous Systems,scopus,2020-04-01,sciencedirect,Deploying MAVs for autonomous navigation in dark underground mine environments,https://api.elsevier.com/content/abstract/scopus_id/85079573394,"Operating Micro Aerial Vehicles (MAVs) in subterranean environments is becoming more and more relevant in the field of aerial robotics. Despite the large spectrum of technological advances in the field, flying in such challenging environments is still an ongoing quest that requires the combination of multiple sensor modalities like visual/thermal cameras as well as 3D and 2D lidars. Nevertheless, there exist cases in subterranean environments where the aim is to deploy fast and lightweight aerial robots for area reckoning purposes after an event (e.g. blasting in production areas). This work proposes a novel baseline approach for the navigation of resource constrained robots, introducing the aerial underground scout, with the main goal to rapidly explore unknown areas and provide a feedback to the operator. The main proposed framework focuses on the navigation, control and vision capabilities of the aerial platforms with low-cost sensor suites, contributing significantly towards real-life applications. The merit of the proposed control architecture is that it considers the flying platform as a floating object, composing a velocity controller on the 
                        x
                     , 
                        y
                      axes and altitude control to navigate along the tunnel. Two novel approaches make up the cornerstone of the proposed contributions for the task of navigation: (1) a vector geometry method based on 2D lidar, and (2) a Deep Learning (DL) method through a classification process based on an on-board image stream, where both methods correct the heading towards the center of the mine tunnel. Finally, the framework has been evaluated in multiple field trials in an underground mine in Sweden.",multimedia
10.1016/j.cmpb.2019.105254,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-04-01,sciencedirect,Automatic digital ECG signal extraction and normal QRS recognition from real scene ECG images,https://api.elsevier.com/content/abstract/scopus_id/85076186466,"Background and objective
                  Electrocardiogram (ECG) is one of the most important tools for assessing cardiac function and detecting potential heart problems. However, most of the current ECG report records remain on the paper, which makes it difficult to preserve and analyze the data. Moreover, paper records could result in the loss significant data, which brings inconvenience to the subsequent clinical diagnosis or artificial intelligence-assisted heart health diagnosis. Taking digital pictures is an intuitive way of preserving these files and can be done simply using smartphones or any other devices with cameras. However, these real scene ECG images often have some image noise that hinders signal extraction. How to eliminate image noise and extract ECG binary image automatically from the noisy and low-quality real scene images of ECG reports is the first problem to be solved in this paper. Next, QRS recognition is implemented on the extracted binary images to determine key points of ECG signals. 1D digital ECG signal is also extracted for accessing the exact values of the extracted points. In light of these tasks, an automatic digital ECG signal extraction and normal QRS recognition from real scene ECG images is proposed in this paper.
               
                  Methods
                  The normal QRS recognition approach for real scene ECG images in this paper consists of two steps: ECG binary image extraction from ECG images using a new two-layer hierarchical method, and the subsequent QRS recognition based on a novel feature-fusing method. ECG binary image extraction is implemented using sub-channel filters followed by an adaptive filtering algorithm. According to the ratio between pixel and real value of ECG binary image, 1D digital ECG signal is obtained. The normal QRS recognition includes three main steps: establishment of candidate point sets, feature fusion extraction, and QRS recognition. Two datasets are introduced for evaluation including a real scene ECG images dataset and the public Non-Invasive Fetal Electrocardiogram Database (FECG).
               
                  Results
                  Through the experiment on real scene ECG image, the F1 score for Q, R, S detection is 0.841, 0.992, and 0.891, respectively. The evaluation on the public FECG dataset also proves the robustness of our algorithm, where F1 score for R is 0.992 (0.996 for thoracic lead) and 0.988 for thoracic S wave.
               
                  Conclusions
                  The proposed method in this article is a promising tool for automatically extracting digital ECG signals and detecting QRS complex in real scene ECG images with normal QRS.",multimedia
10.1016/j.cmpb.2019.105099,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-04-01,sciencedirect,Augmented reality navigation for liver resection with a stereoscopic laparoscope,https://api.elsevier.com/content/abstract/scopus_id/85073003483,"Objective
                  Understanding the three-dimensional (3D) spatial position and orientation of vessels and tumor(s) is vital in laparoscopic liver resection procedures. Augmented reality (AR) techniques can help surgeons see the patient's internal anatomy in conjunction with laparoscopic video images.
               
                  Method
                  In this paper, we present an AR-assisted navigation system for liver resection based on a rigid stereoscopic laparoscope. The stereo image pairs from the laparoscope are used by an unsupervised convolutional network (CNN) framework to estimate depth and generate an intraoperative 3D liver surface. Meanwhile, 3D models of the patient's surgical field are segmented from preoperative CT images using V-Net architecture for volumetric image data in an end-to-end predictive style. A globally optimal iterative closest point (Go-ICP) algorithm is adopted to register the pre- and intraoperative models into a unified coordinate space; then, the preoperative 3D models are superimposed on the live laparoscopic images to provide the surgeon with detailed information about the subsurface of the patient's anatomy, including tumors, their resection margins and vessels.
               
                  Results
                  The proposed navigation system is tested on four laboratory ex vivo porcine livers and five operating theatre in vivo porcine experiments to validate its accuracy. The ex vivo and in vivo reprojection errors (RPE) are 6.04 ± 1.85 mm and 8.73 ± 2.43 mm, respectively.
               
                  Conclusion and Significance
                  Both the qualitative and quantitative results indicate that our AR-assisted navigation system shows promise and has the potential to be highly useful in clinical practice.",multimedia
10.1016/j.cmpb.2019.105019,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-04-01,sciencedirect,Automatic diagnosis of fungal keratitis using data augmentation and image fusion with deep convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85070552720,"Background and objectives
                  Fungal keratitis is caused by inflammation of the cornea that results from infection by fungal organisms. The lack of an early effective diagnosis often results in serious complications even blindness. Confocal microscopy is one of the most effective methods in the diagnosis of fungal keratitis, but the diagnosis depends on the subjective judgment of medical experts.
               
                  Methods
                  To address this problem, this paper proposes a novel convolutional neural network framework for the automatic diagnosis of fungal keratitis using data augmentation and image fusion. Firstly, a normal image is augmented by flipping to solve the problem of having a limited and imbalanced database. Secondly, a sub-area contrast stretching algorithm is proposed for image preprocessing to highlight the key structures in the images and to filter out irrelevant information. Thirdly, the histogram matching fusion algorithm is implemented, then the preprocessed image is fused with the original image to form a new algorithm framework and a new database. Finally, the traditional convolutional neural network is integrated into the novel algorithm framework to perform the experiments.
               
                  Results
                  Experiments show that the accuracy of traditional AlexNet and VGGNet is 99.35% and 99.14%, that of AlexNet and VGGNet based on MF fusion is 99.80% and 99.83%, and that of AlexNet and VGGNet based on histogram matching fusion (HMF) is 99.95% and 99.89%. The experimental results show that the AlexNet framework using data augmentation and image fusion achieves a perfect trade-off between the diagnostic performance and the computational complexity, with a diagnostic accuracy of 99.95%.
               
                  Conclusions
                  These experimental results demonstrate the novel convolutional neural network framework perfectly balances the diagnostic performance and computational complexity, and can improve the effect and real-time performance in the diagnosis of fungal keratitis.",multimedia
10.1016/j.eswa.2019.112975,Journal,Expert Systems with Applications,scopus,2020-03-15,sciencedirect,Wildfire detection using transfer learning on augmented datasets,https://api.elsevier.com/content/abstract/scopus_id/85073573447,"Wildfire detection is a time-critical application as the difficulty to pinpoint ignition locations in a short time-frame often leads to the escalation of the severity of fire events. This problem has motivated considerable interest from expert systems research to develop accurate early-warning applications and the breakthroughs in deep learning in complex visual understanding tasks open novel research opportunities. However, despite the improvements in performance demonstrated in the current literature, a comprehensive study of the challenges and limitations of this approach is still a gap in the state-of-the-art. To address this issue, the contributions of this work are threefold. First, we overview recent works to identify common difficulties and shortcomings of these approaches, and assess issues related to the quality of the databases. Second, to overcome data limitations, this work proposes a transfer learning approach coupled with data augmentation techniques tested under a tenfold cross-validation scheme. The proposed framework enables leveraging an open-source dataset featuring images from more than 35 real fire events, which unlike video-based works offers higher variability between samples, allowing evaluating the approach in an extensive set of real scenarios. Third, this article presents an in-depth study of the limitations, providing a comprehensive analysis of the patterns causing misclassifications. The key insights gained in this analysis provide relevant takeaways to guide future research towards the implementation of expert systems in decision support systems in firefighting and civil protection operations.",multimedia
10.1016/j.compag.2020.105284,Journal,Computers and Electronics in Agriculture,scopus,2020-03-01,sciencedirect,An experimental study of stunned state detection for broiler chickens using an improved convolution neural network algorithm,https://api.elsevier.com/content/abstract/scopus_id/85079902403,"Effective recognition method of broiler stunned state has always been an important issue in real industries. In recent years, recognition methods such as neural networks have been receiving increasing attention due to their great merits of high diagnostic accuracy and easy implementation. To improve the accuracy and efficiency of broiler stunned state recognition, an improved fast region-based convolutional neural network (You Only Look Once + Multilayer Residual Module (YOLO + MRM)) algorithm was proposed and applied to the recognition of three broiler stunned states: insufficient, appropriate and excessive stuns. The images were collected from a broiler-slaughtering line using a complementary metal-oxide semiconductor (CMOS) camera. The area of the head and wings of a broiler in the original image was marked according to the PASCAL VOC data format and the dataset of each broiler stunned state was obtained. The results showed that the YOLO + MRM algorithm achieved good performance with an accuracy of 96.77%. To compare YOLO + MRM with other models, similar experiments were conducted using a conventional back propagation neural network (BP-NN) classifier, as well as YOLO, and the recognition accuracies were 90.11% and 94.74%, respectively. YOLO + MRM can complete the detection task of more than 180,000 broilers per hour. Compared with the traditional method, little prior expertise on image recognition is required, the recognition accuracy and speed are improved obviously. This study has provided a foundation and highlighted the potential for automatically detecting the stunned state of broiler chickens, which is crucial for the success of an automatic electric stunning process in the poultry industry.",multimedia
10.1016/j.comcom.2020.02.009,Journal,Computer Communications,scopus,2020-03-01,sciencedirect,UAV monitoring and forecasting model in intelligent traffic oriented applications,https://api.elsevier.com/content/abstract/scopus_id/85079351564,"Intelligent transportation system is a traffic management system developed with the progress of society and traffic. Its idea is to integrate the real-time operation of people, vehicles, roads and traffic involved in the traffic. The purpose of this paper is to build a safe, reliable and efficient vehicle monitoring and forecasting model for IOT. Based on the Beidou satellite positioning technology and Lora communication technology, aiming at the problem that the deep learning detection method cannot meet the real-time requirements in processing the monitoring video, this paper proposes a method of using multiple single target trackers instead of some yolov3 detection tasks, and puts forward the design idea and specific implementation scheme of the vehicle monitoring and prediction model. The vehicle monitoring and prediction model is used to detect four kinds of targets, namely, small cars, buses, trucks and pedestrians. The multi-target trajectory tracking is used to carry out the traffic statistics of multi vehicle types, the detection of two kinds of abnormal behaviors of traffic targets is low speed and parking, and the capture of pedestrians. The experimental results show that the vehicle monitoring and prediction model has the highest accuracy of location and type recognition for four types of traffic objects, namely, small cars, trucks, buses and pedestrians, reaching 80%.",multimedia
10.1016/j.cmpb.2019.105132,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-03-01,sciencedirect,Virtual reality-based measurement of ocular deviation in strabismus,https://api.elsevier.com/content/abstract/scopus_id/85073938186,"Background and objective
                  Strabismus is an eye movement disorder in which shows the abnormal ocular deviation. Cover tests have mainly been used in the clinical diagnosis of strabismus for treatment. However, the whole process depends on the doctor's level of experience, which could be subjected to several factors. In this study, an automated technique for measurement of ocular deviation using a virtual reality (VR) device is developed.
               
                  Methods
                  A VR display system in which the screens that have the fixation target are changed alternately between on and off stages is used to simulate the normal strabismus diagnosis steps. Patients watch special-designed 3D scenes, and their eye motions are recorded by two infrared (IR) cameras. An image-processing-based pupil tracking technique is then applied to track their eye movement. After recording eye motion, two strategies for strabismus angle estimation are implemented: direct measurement and stepwise approximation. The direct measurement converts the eye movement to a strabismus angle after considering the eyeball diameter, while the stepwise approximation measures the ocular deviation through the feedback calibration process.
               
                  Results
                  Experiments are carried out with various strabismus patients. The results are compared to those of their doctors’ measurement, which shows good agreement.
               
                  Conclusions
                  The results clearly indicate that these techniques could identify ocular deviation with high accuracy and efficiency. The proposed system can be applied in small space and has high tolerance for the unexpected head movements compared with other camera-based system.",multimedia
10.1016/j.comcom.2020.01.035,Journal,Computer Communications,scopus,2020-02-15,sciencedirect,Adaptive service function chaining mappings in 5G using deep Q-learning,https://api.elsevier.com/content/abstract/scopus_id/85078700042,"With introduction of Software-Defined Networking (SDN) and Network Functions Virtualization (NFV) technologies, mobile network operators are able to provide on-demand Service Function Chaining (SFC) to meet various needs from users. However, it is challenging to map multiple SFCs to substrate networks efficiently, particularly in a number of key scenarios of forthcoming 5G, where user requests have different priorities and various resource demands. To this end, we first formulate the mapping of multiple SFCs with priorities as a multi-step Linear Integer Programming (ILP) problem, of which the mapping strategy (i.e., the objective function) in each step is configurable to improve overall CPU and bandwidth resource utilization rates. Secondly, to solve the strategy selection problem in each step and alleviate the complexity of ILP, we propose an adaptive deep Q-learning based SFC mapping approach (ADAP), where an agent is learned to make decisions from two low-complexity heuristic SFC mapping algorithms. Finally, we conduct extensive simulations using multiple SFC requests with randomly generated CPU and bandwidth demands in a real-world substrate network topology. Related results demonstrate that compared with a single strategy or random selections of strategies under the ILP-based approach or the proposed heuristic algorithms, our ADAP approach can improve whole-system resource efficiency by scheduling this two simply designed heuristic algorithms properly after limited training episodes.",multimedia
10.1016/j.physa.2019.123151,Journal,Physica A: Statistical Mechanics and its Applications,scopus,2020-02-15,sciencedirect,Early warning system: From face recognition by surveillance cameras to social media analysis to detecting suspicious people,https://api.elsevier.com/content/abstract/scopus_id/85074532417,"Surveillance security cameras are increasingly deployed in almost every location for monitoring purposes, including watching people and their actions for security purposes. For criminology, images collected from these cameras are usually used after an incident occurs to analyze who could be the people involved. While this usage of the cameras is important for a post crime action, there exists the need for real time monitoring to act as an early warning to prevent or avoid an incident before it occurs. In this paper, we describe the development and implementation of an early warning system that recognizes people automatically in a surveillance camera environment and then use data from various sources to identify these people and build their profile and network. The current literature is still missing a complete workflow from identifying people/criminals from a video surveillance to building a criminal information extraction framework and identifying those people and their interactions with others We train a feature extraction model for face recognition using convolutional neural networks to get a good recognition rate on the Chokepoint dataset collected using surveillance cameras. The system also provides the function to record people appearance in a location, such that unknown people passing through a scene excessive number of times (above a threshold decided by a security expert) will then be further analyzed to collect information about them. We implemented a queue based system to record people entrance. We try to avoid missing relevant individuals passing through as in some cases it is not possible to add every passing person to the queue which is maintained using some cache handling techniques. We collect and analyze information about unknown people by comparing their images from the cameras to a list of social media profiles collected from Facebook and intelligent services archives. After locating the profile of a person, traditional news and other social media platforms are crawled to collect and analyze more information about the identified person. The analyzed information is then presented to the analyst where a list of keywords and verb phrases are shown. We also construct the person’s network from individuals mentioned with him/her in the text. Further analysis will allow security experts to mark this person as a suspect or safe. This work shows that building a complete early warning system is feasible to tackle and identify criminals so that authorities can take the required actions on the spot.",multimedia
10.1016/j.comcom.2020.01.018,Journal,Computer Communications,scopus,2020-02-01,sciencedirect,Enhanced resource allocation in mobile edge computing using reinforcement learning based MOACO algorithm for IIOT,https://api.elsevier.com/content/abstract/scopus_id/85077781443,"The Mobile networks deploy and offers a multiaspective approach for various resource allocation paradigms and the service based options in the computing segments with its implication in the Industrial Internet of Things (IIOT) and the virtual reality. The Mobile edge computing (MEC) paradigm runs the virtual source with the edge communication between data terminals and the execution in the core network with a high pressure load. The demand to meet all the customer requirements is a better way for planning the execution with the support of cognitive agent. The user data with its behavioral approach is clubbed together to fulfill the service type for IIOT. The swarm intelligence based and reinforcement learning techniques provide a neural caching for the memory within the task execution, the prediction provides the caching strategy and cache business that delay the execution. The factors affecting this delay are predicted with mobile edge computing resources and to assess the performance in the neighboring user equipment. The effectiveness builds a cognitive agent model to assess the resource allocation and the communication network is established to enhance the quality of service. The Reinforcement Learning techniques Multi Objective Ant Colony Optimization (MOACO) algorithms has been applied to deal with the accurate resource allocation between the end users in the way of creating the cost mapping tables creations and optimal allocation in MEC.",multimedia
10.1016/j.autcon.2019.103012,Journal,Automation in Construction,scopus,2020-02-01,sciencedirect,On-demand monitoring of construction projects through a game-like hybrid application of BIM and machine learning,https://api.elsevier.com/content/abstract/scopus_id/85075291648,"While unavoidable, inspections, progress monitoring, and comparing as-planned with as-built conditions in construction projects do not readily add tangible intrinsic value to the end-users. In large-scale construction projects, the process of monitoring the implementation of every single part of buildings and reflecting them on the BIM models can become highly labour intensive and error-prone, due to the vast amount of data produced in the form of schedules, reports and photo logs. In order to address the mentioned methodological and technical gap, this paper presents a framework and a proof of concept prototype for on-demand automated simulation of construction projects, integrating some cutting edge IT solutions, namely image processing, machine learning, BIM and Virtual Reality. This study utilised the Unity game engine to integrate data from the original BIM models and the as-built images, which were processed via various computer vision techniques. These methods include object recognition and semantic segmentation for identifying different structural elements through supervised training in order to superimpose the real world images on the as-planned model. The proposed framework leads to an automated update of the 3D virtual environment with states of the construction site. This framework empowers project managers and stockholders with an advanced decision-making tool, highlighting the inconsistencies in an effective manner. This paper contributes to body knowledge by providing a technical exemplar for the integration of ML and image processing approaches with immersive and interactive BIM interfaces, the algorithms and program codes of which can help replicability of these approaches by other scholars.",multimedia
10.1016/j.patrec.2019.01.012,Journal,Pattern Recognition Letters,scopus,2020-02-01,sciencedirect,Fast large scale deep face search,https://api.elsevier.com/content/abstract/scopus_id/85060460306,"Towards the large scale face search problem, this paper proposes a fast deep face search method which is realized by combination of deep convolution neural network (CNN), semantic hashing, and hash-based similarity search. First of all, to boost the performance in accuracy of face search, the residual network (Resnet) is exploited to construct a deep face feature model and then train it over the cleaned MS-Celeb-1M, which is used to extract real-valued face feature. Next, by imposing PCA and binarization operations, we convert the real-valued feature into compact hash code used for speeding up the face search. Based on the extracted dual features, the face search can be efficiently performed by adopting two-stage matching (i.e., coarse matching and fine matching) strategy. The coarse matching is implemented under the support of efficient hash indexing technique for yielding a small number of candidates while the fine stage is to filter out the unrelated images by cosine distance comparison of real-valued features. It is worth noting that we offer two coarse matching methods, such as GPU-hash and M-index-hash based matching, which are suitable for tens-of million and billion scale scenarios respectively. The experimental results demonstrate that the proposed method is very effective for large scale face search in both aspects of accuracy and real time property.",multimedia
10.1016/j.ifacol.2020.12.1968,Conference Proceeding,IFAC-PapersOnLine,scopus,2020-01-01,sciencedirect,Dynamic switched non-parametric identification of the human physiological response under virtual reality stimuli,https://api.elsevier.com/content/abstract/scopus_id/85107539463,"In this work, it is proposed a Switched Differential Neural Networks structure (SDNN) to model the human physiological response in a virtual stimuli scenario. Two physiological variables are assessed: electrocardiography and electrodermal activity, which provide a reflex response after stimuli. The proposed approach is focused on the representation of two discrete primary states, relaxation and stress as the response of the virtual stimuli. A switched dynamic approach is set, in which the trigger of an stimuli generates a change in the heartbeat rate as well as in the skin conductivity, constructing the switch between the mentioned states. The SDNN allows to obtain a model structure whose dynamics corresponds to the rate of change of the physiological variables, given as result a particular class of uncertain switched systems. The proposed non-parametric identification in this switched structure is implemented and experimentally assessed showing appropriate convergence rates in, both, switching regions and the continuous states.",multimedia
10.1016/j.procir.2020.07.006,Conference Proceeding,Procedia CIRP,scopus,2020-01-01,sciencedirect,Operator support in human-robot collaborative environments using AI enhanced wearable devices,https://api.elsevier.com/content/abstract/scopus_id/85100836551,"Nowadays, in order to cover the needs of market for product mass customization, industries have started to move to hybrid production cells, involving both robots and human operators. Research has been done during previous years to promote and improve the collaboration between humans and robots, trying to address topics such as safety, awareness and cognitive support in form of Augmented Reality based instructions. Results of previous research show bottlenecks related to the way of interaction of the operators with such supportive systems though. Direct interaction approach with the use of push buttons or indirect-gesture based interaction, which are most often adopted by the researchers, require operators to constantly occupy their hands performing the relevant button presses or gestures. Moreover, previous approaches are hardware dependent and need a lot of customization to work with different hardware. This work tries to address these bottlenecks proposing the usage of wearable devices enhanced with AI in order to support the interaction of human operators with robots in human-robot collaborative environments in a seamless and non-intrusive way, wrapped around a framework called “Operator Support Module” (OSM). Among others, OSM supports a variety of hardware to easily fit in various industrial scenarios. Two case studies will be presented to demonstrate the approach.",multimedia
10.1016/j.promfg.2020.10.053,Conference Proceeding,Procedia Manufacturing,scopus,2020-01-01,sciencedirect,Enabling real-time quality inspection in smart manufacturing through wearable smart devices and deep learning,https://api.elsevier.com/content/abstract/scopus_id/85099870958,"In this paper, we present a novel method for utilising wearable devices with Convolutional Neural Networks (CNN) trained on acoustic and accelerometer signals in smart manufacturing environments in order to provide real-time quality inspection during manual operations. We show through our framework how recorded or streamed sound and accelerometer data gathered from a wrist-attached device can classify certain user actions as successful or unsuccessful. The classification is designed with a Deep CNN model trained on Mel-frequency Cepstral Coefficients (MFCC) from the acoustic input signals. The wearable device provides feedback on three different modalities: audio, visual and haptic; thus ensuring the worker’s awareness at all time. We validate our findings through deployments of the complete AI-enabled device in production facilities of Mercedes-Benz AG. From the conducted experiments it is concluded that the use of acoustic and accelerometer data is valuable to train a classifier with the purpose of action examination during industrial assembly operations, and provides an intuitive interface for ensuring continued and improved quality inspection.",multimedia
10.1016/j.matpr.2020.08.445,Conference Proceeding,Materials Today: Proceedings,scopus,2020-01-01,sciencedirect,Real time fruits quality detection with the help of artificial intelligence,https://api.elsevier.com/content/abstract/scopus_id/85098588044,"One of the major quality of grading fruits is its appearance. Appearance is effects the marketing and choice of consumer. Colour, texture, size, shape are used to find quality of fruit. But the sellers controlling the external quality of fruits to get high profit. In earlier observations, implemented products, computer vision systems for external controlling quality so grading and classification of fruits is based on observations. The proposed system depend on image processing to classify and grade quality of fruits by using mean of image, colour and HOG (Histogram of gradient) feature extractions are used to classify the fruit quality. All machine learning algorithms are used to find the better accuracy of data how it is predicting. In proposed method first data set is collected, then pre-processing is applied for better results. Machine learning algorithms (K-nearest neighbour (KNN), Support Vector Machine (SVM), and PCA is used for dimension reduction and to get good accuracy to implement the system. For big data pre-processing and to get better results Deep learning (CNN) is used to test the fruit in real time world with result and audio sounds. Audio is used to detect object by hearing also.",multimedia
10.1016/j.micpro.2020.103491,Journal,Microprocessors and Microsystems,scopus,2020-01-01,sciencedirect,Distance music education course based on FPGA and wireless sensor,https://api.elsevier.com/content/abstract/scopus_id/85096611950,"Online music courses complement face-to-face learning and higher education in the face of the rapidly evolving technology and the Internet. The Master of College and Distance Education is available worldwide and offers online opportunities to pursue professional development at many universities, which is now online. Personal online courses are another option for music education in real time communication. In the previous method based on Deep learning and data mining for Distance Music Education Course. The existing method gives the technical challenge, over filtering, deployment challenges. The proposed method is based on FPGA (Field Programmable Gate Arrays) and Machine learning for Distance Music Education Course. The wireless sensor shows that there are different ways for adults to participate in online music training. Hence, the nature of online communication and interaction with teachers and students is different. There are requests. For practice-based or performance-based courses, practical issues such as low-quality audio and time delays may arise. Online learning offers flexibility and internationalization and has a strong ability to connect with many people. In this case, wireless sensors communicate our teachers look at it from a practical perspective, such as ease of transportation and payment. Further educational efforts also need to promote music and online distance education.",multimedia
10.1016/j.jksuci.2020.09.018,Journal,Journal of King Saud University - Computer and Information Sciences,scopus,2020-01-01,sciencedirect,Real-time Jordanian license plate recognition using deep learning,https://api.elsevier.com/content/abstract/scopus_id/85095984135,"Countries have different specifications for License Plates (LPs), therefore developing one Automatic license plate recognition (ALPR) system that works well for all LPs types is a difficult task. This paper aims to develop an accurate ALPR for Jordanian LPs. Two-stage Convolutional Neural Networks (CNNs) are used in the proposed approach, the CNNs are based on the YOLO3 framework. The sizes of LPs' characters are very small compared with the frame size, therefore the YOLO3 network architecture is modified to a shallow network to detect small objects. The proposed approach uses temporal information from different frames to remove false predictions. A set of arrays data structure is used to track the vehicles’ LPs and eliminate incorrect ones. To my knowledge, the proposed approach represents the first end-to-end Jordanian ALPR that processes video stream in real-time. To my knowledge, there is no dataset for Jordanian license plates, therefore this paper proposes a new dataset called JALPR dataset. The dataset is available online and includes many real videos for moving vehicles in Jordan. Two well-known commercial software packages are used for comparisons. The experimental results in real videos from YouTube show that the proposed approach is very efficient in recognizing the Jordanian license plates and achieved 87% recognition accuracy, whereas the commercial systems have recognition accuracies that are less than 81%.",multimedia
10.1016/j.promfg.2020.05.146,Conference Proceeding,,scopus,2020-01-01,sciencedirect,One-shot recognition of manufacturing defects in steel surfaces,https://api.elsevier.com/content/abstract/scopus_id/85095111982,"Quality control is an essential process in manufacturing to make the product defect-free as well as to meet customer needs. The automation of this process is important to maintain high quality along with the high manufacturing throughput. With recent developments in deep learning and computer vision technologies, it has become possible to detect various features from the images with near-human accuracy. However, many of these approaches are data intensive. Training and deployment of such a system on manufacturing floors may become expensive and time-consuming. The need for large amounts of training data is one of the limitations of the applicability of these approaches in real-world manufacturing systems. In this work, we propose the application of a Siamese convolutional neural network to do one-shot recognition for such a task. Our results demonstrate how one-shot learning can be used in quality control of steel by identification of defects on the steel surface. This method can significantly reduce the requirements of training data and can also be run in real-time.",multimedia
10.1016/j.procs.2020.07.028,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,A mobile clinical DSS based on augmented reality and deep learning for the home cares of patients afflicted by bedsores,https://api.elsevier.com/content/abstract/scopus_id/85094582861,"A bedsore, also known as pressure sore, pressure ulcer or decubitus ulcer, is the result of constant pressure on skin occurring in bedridden patients and paraplegics continuously sitting in chair. All patients who are immobile for a long time due to any cause are likely to get bedsores. Effective and efficient management of processes related to the treatment of bedsores is an important issue for healthcare organizations as it heavily affects the quality of life of patients and the costs for such organizations. Therefore organizations need and look for more and more to provide their field workforce with smart mobile tools able to support such processes. In such a context, this paper proposes a mobile app implementing a Clinical Decision Support System (CDSS) to help field operators to measure the bedsore, classify its status, trace its evolution along the timeline and making correct decisions about the course of actions to effectively treat it. The mobile app is mostly based on Augmented Reality supported by Deep Learning, thus it requires an adequate system architecture to be effectively deployed, adopted and used. From the conceptual viewpoint, the defined CDSS model lays on three important considerations: providing automatic support to classify the status of a bedsore does not do all the work but help operators to improve the quality of their decisions, augmented reality allows to build a situated environment for decision-making supporting the operators’ cognitive processes, operators should use only one tool to execute all their tasks in order to be more focused on the real problem which is to improve the quality of life of their patients.",multimedia
10.1016/j.nicl.2020.102465,Journal,NeuroImage: Clinical,scopus,2020-01-01,sciencedirect,Upregulating excitability of corticospinal pathways in stroke patients using TMS neurofeedback; A pilot study,https://api.elsevier.com/content/abstract/scopus_id/85093655384,"Upper limb weakness following a stroke affects 80% of survivors and is a key factor in preventing their return to independence. State-of-the art approaches to rehabilitation often require that the patient can generate some activity in the paretic limb, which is not possible for many patients in the early period following stroke. Approaches that enable more patients to engage with upper limb therapy earlier are urgently needed.
                  Motor imagery has shown promise as a potential means to maintain activity in the brain’s motor network, when the patient is incapable of generating functional movement. However, as imagery is a hidden mental process, it is impossible for individuals to gauge what impact this is having upon their neural activity.
                  Here we used a novel brain-computer interface (BCI) approach allowing patients to gain an insight into the effect of motor imagery on their brain-muscle pathways, in real-time. Seven patients 2–26 weeks post stroke were provided with neurofeedback (NF) of their corticospinal excitability measured by the size of motor evoked potentials (MEP) in response to transcranial magnetic stimulation (TMS). The aim was to train patients to use motor imagery to increase the size of MEPs, using the BCI with a computer game displaying neurofeedback.
                  Patients training finger muscles learned to elevate MEP amplitudes above their resting baseline values for the first dorsal interosseous (FDI) and abductor digiti minimi (ADM) muscles. By day 3 for ADM and day 4 for FDI, MEP amplitudes were sustained above baseline in all three NF blocks.
                  Here we have described the first clinical implementation of TMS NF in a population of sub-acute stroke patients. The results show that in the context of severe upper limb paralysis, patients are capable of using neurofeedback to elevate corticospinal excitability in the affected muscles. This may provide a new training modality for early intervention following stroke.",multimedia
10.1016/j.procs.2020.09.269,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,"Alexa, What classes do I have today? The use of artificial intelligence via smart speakers in education",https://api.elsevier.com/content/abstract/scopus_id/85093364102,"Looking back to the rumours from the early 2000’s, when the world of technology bloomed together with the curiosity towards what was next to come, by 2020, robots should have assisted and supported almost every task from our daily life. While this may seem as a Sci-Fi movie scenario, it is partially a tangible reality, that we quickly got used to, thanks to the introduction of smart speakers.
                  As the world changes, so does the future of our students. In this respects, the evolution of the technology comes up with specific environments for educational purpose. Building smart learning environments supported by e-learning platforms is an important area of research in education domain within our days. The evolution of these smart learning environments is justified by some events (Covid19) that force students to learn remotely.
                  The paper proposes a software application component using Alexa smart speaker, that integrates different services (Amazon Web Services, Microsoft Services) for a proper virtual environment platform, for both students and teachers. It addresses the main concerns of the current educational system, and provides a smart solution through the use of Artificial Intelligence based tools. The proposed approach not only achieves unifying data and knowledge-share mechanisms in a remotely mode, but it brings also a good learning experience, increasing the effectiveness and the efficiency of the learning process.",multimedia
10.1016/j.procir.2020.04.135,Conference Proceeding,Procedia CIRP,scopus,2020-01-01,sciencedirect,Application of Artificial Intelligence to an Electrical Rewinding Factory Shop,https://api.elsevier.com/content/abstract/scopus_id/85091693237,"The evolution of artificial intelligence (AI) and big data resulted in the full potential realization of technologies through convergence. Tremendous acceptance, adoption and implementation of the United Nations Sustainable Development Goals (SDG) Agenda 2030, has resulted in original equipment manufacturers (OEM) developing various designs of rotary machines in a bid to improve energy efficiency, with more improvements expected in the coming decade. An effective technique to manage energy efficiency in the smart grid is through integration of demand side management, inclusive of optimization of rewinding of an electric motor in a machine shop. This paper aims to conceptualize application of AI and augmented reality (AR) towards process visibility of remanufacturing rotary machine stators by robotic vision. SLT is the triangulation methodology used in laser scanning for 3D modelling, and instantaneous condition assessment of the core. A pre-defined robotic path is used towards identification of features for range image acquisition. Therefore, the potential of industry 4.0 in resuscitation of end-of-life products through service remanufacturers by RE in a rewinding shop are presented.",multimedia
10.1016/j.procs.2020.05.163,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Current state of research in application of disruptive technologies in engineering education,https://api.elsevier.com/content/abstract/scopus_id/85089033770,"Disruptive innovation technologies have made their way in the field of academia during the past few years. A plethora of literature exists investigating the applications of various disruptive technologies in the field of engineering education. The directions for future research however are still obscured by the copious amount of literature having split opinions and conflicting results which necessitates a review of current state of the research. This paper clarifies the underlying concept of the theory. The authors then critique and summarize the research on present state of implementation mainly focusing on the field of engineering education. The future scope for the research is also discussed keeping in the mind the upcoming new technologies such as mobilecomputing, wearable technologiesand internet of things combined with machine learning.",multimedia
10.1017/S175173112000155X,Journal,Animal,scopus,2020-01-01,sciencedirect,"Storing, combining and analysing turkey experimental data in the Big Data era",https://api.elsevier.com/content/abstract/scopus_id/85087625907,"With the increasing availability of large amounts of data in the livestock domain, we face the challenge to store, combine and analyse these data efficiently. With this study, we explored the use of a data lake for storing and analysing data to improve scalability and interoperability. Data originated from a 2-day animal experiment in which the gait score of approximately 200 turkeys was determined through visual inspection by an expert. Additionally, inertial measurement units (IMUs), a 3D-video camera and a force plate (FP) were installed to explore the effectiveness of these sensors in automating the visual gait scoring. We deployed a data lake using the IMU and FP data of a single day of that animal experiment. This encompasses data from 84 turkeys for which we preprocessed by performing an ‘extract, transform and load’ (ETL-) procedure. To test scalability of the ETL-procedure, we simulated increasing volumes of the available data from this animal experiment and computed the ‘wall time’ (elapsed real time) for converting FP data into comma-separated files and storing these files. With a simulated data set of 30 000 turkeys, the wall time reduced from 1 h to less than 15 min, when 12 cores were used compared to 1 core. This demonstrated the ETL-procedure to be scalable. Subsequently, a machine learning (ML) pipeline was developed to test the potential of a data lake to automatically distinguish between two classses, that is, very bad gait scores v. other scores. In conclusion, we have set up a dedicated customized data lake, loaded data and developed a prediction model via the creation of an ML pipeline. A data lake appears to be a useful tool to face the challenge of storing, combining and analysing increasing volumes of data of varying nature in an effective manner.",multimedia
10.1016/j.procs.2020.04.013,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,A Computationally Efficient sEMG based Silent Speech Interface using Channel Reduction and Decision Tree based Classification,https://api.elsevier.com/content/abstract/scopus_id/85086629115,"Silent Speech Interface is one of the promising areas of Human-Computer Interaction research. The surface electromyography based silent speech interface is a technique where the electric activity of facial muscles are used to detect speech. The existing sEMG based SSI techniques use complex machine learning algorithms and too many number of electrodes on the subject’s face. It creates inconvenience to the user who might have undergone laryngectomy. More number of electrodes becomes highly invasive to the user, while complex classification algorithms increase the computational cost and prevents real time implementation of sEMG based SSI. Thus the objective of this research work was to develop a less complex and computationally less expensive model to classify words. To achieve this goal channel reduction technique and the use of Decision Tree based classification algorithm was employed. Only the time domain features are used as input to the classification algorithm. The motive was to exploit the advantage of computational ease in extracting the time domain features as compared to the frequency domain features.
                  The sEMG data of the words used in this work are obtained from the complete utterance of the sentences and not by individual utterances of the word. Our algorithm was able to achieve a word accuracy of 95.17% even after applying a channel reduction, thereby allowing us to use only the data of 5 channels, in place of a conventional seven channel setup.",multimedia
10.1016/j.procs.2020.04.220,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Design and Fabrication of SHRALA: Social Humanoid Robot Based on Autonomous Learning Algorithm,https://api.elsevier.com/content/abstract/scopus_id/85086626621,"This paper presents the preliminary research work in the Design, Fabrication of a Social Humanoid Robot based on Autonomous Learning Algorithm (SHRALA). Virtual Model of the humanoid robot was developed using Solidworks environment. This model is then fabricated using Creality Ender-3 3D printer. The electronic control circuit was designed and interfaced to computer using ATMEGA 2650 controller board, based on 8-bit AVR microcontroller. In order to easily and efficiently control the SHRALA a Graphical User Interface (GUI) was created using Unity3D editor, where a simple USB joystick was used to actuate the motions of the SHRALA in the virtual environment. The fabricated SHRALA was controlled in real time using a serial communication interface created between the GUI and Arduino Mega 2650 board. The humanoid robot was successfully controlled using the GUI environment and the preliminary results are satisfactory as it is performing the task as per the desired instructions. This research work is a part of the real time humanoid robot development project “SHRALA”, In near future autonomous learning algorithm will also be implemented in the robot and the same will be published as research article in a modular approach.",multimedia
10.1016/j.csbj.2020.05.022,Journal,Computational and Structural Biotechnology Journal,scopus,2020-01-01,sciencedirect,Software tools for 3D nuclei segmentation and quantitative analysis in multicellular aggregates,https://api.elsevier.com/content/abstract/scopus_id/85086379946,"Today, we are fully immersed into the era of 3D biology. It has been extensively demonstrated that 3D models: (a) better mimic the physiology of human tissues; (b) can effectively replace animal models; (c) often provide more reliable results than 2D ones. Accordingly, anti-cancer drug screenings and toxicology studies based on multicellular 3D biological models, the so-called “-oids” (e.g. spheroids, tumoroids, organoids), are blooming in the literature. However, the complex nature of these systems limit the manual quantitative analyses of single cells’ behaviour in the culture. Accordingly, the demand for advanced software tools that are able to perform phenotypic analysis is fundamental. In this work, we describe the freely accessible tools that are currently available for biologists and researchers interested in analysing the effects of drugs/treatments on 3D multicellular -oids at a single-cell resolution level. In addition, using publicly available nuclear stained datasets we quantitatively compare the segmentation performance of 9 specific tools.",multimedia
10.1016/j.promfg.2020.04.082,Conference Proceeding,Procedia Manufacturing,scopus,2020-01-01,sciencedirect,Integrating virtual and physical production processes in learning factories,https://api.elsevier.com/content/abstract/scopus_id/85085519100,"Scaled learning factories are industrial learning environments that provide production systems and processes for learners on a model scale rather than using actual productive machines. This approach has benefits as for instance lower invest, increased approachability and higher safety levels. At the same time, constraints for implementation of actual production processes and required abstraction levels from industrial processes are limitations. To bridge the gap between benefits and limitation we propose the integration of virtual production processes in a prevalent physical learning factories. Resulting mixed reality solutions bear the potential to combine real and virtual objects at the same time and thus extend the physical model environment with virtually represented processes. Based on an initial analysis we develop a concept using spatial augmented reality and a game engine based simulation to realize a virtual integrated production process. The theoretical concept as well as the technical implementation is described. A first evaluation indicates a high rate of acceptance by trainees and illustrates the benefits for learning performance.",multimedia
10.1016/j.promfg.2020.04.037,Conference Proceeding,Procedia Manufacturing,scopus,2020-01-01,sciencedirect,Implementing AR/MR - Learning factories as protected learning space to rise the acceptance for mixed and augmented reality devices in production,https://api.elsevier.com/content/abstract/scopus_id/85085498037,"When talking about digitization, changes in the way of working are inevitable: The implementation of intelligent machines or dealing with real-time data lead to new tasks supported by new technology. Also digital technologies such as Augmented and Mixed Reality (AR/MR) are pushing the market and setting new standards in collaboration, prototyping or maintenance. The correct handling of AR/MR devices requires a change in the employees’ behavior; changing working routines are followed by a new skill set and a change in the culture. The acceptance of employees can therefore be regarded as a critical success factor for the implementation of such technologies. Thus, the present paper answers the research question ‘what factors influence the employee’s acceptance of AR and MR data glasses in industry’. On the basis of a comprehensive literature analysis, an implementation workshop was developed and validated in cooperation with an industrial partner. The results were transformed into a workshop within the learning and research factory ‘Smart Production Lab’ to give employees and students the opportunity to train the handling of data glasses in a protected learning space in order to increase the acceptance for the technology.",multimedia
10.1016/j.procs.2020.03.320,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,A Novel Semantic Approach for Intelligent Response Generation using Emotion Detection Incorporating NPMI Measure,https://api.elsevier.com/content/abstract/scopus_id/85084501270,"Expressions and emotions are the most common way of communication in day-to-day life. In the age of Artificial Intelligence and technological advancements, the entire human race finds itself amidst many software driven voice-assistants. The only reason AI cannot excel and spread its limits is that humans can interpret, understand and express in the form of emotions and these AI-driven systems cannot. Hence, there is a need for a proper methodology for the interpretation of emotions based on both text and speech. In order to accomplish this task, a light weight computational linguistic semantic approach has been proposed for detecting emotions and generating response incorporating NPMI and NAVA words, bridging the gap between Semantics and Natural Language Processing. Experimentations are conducted for the real-word TDIL dataset for emotions such as joy, sorrow, anger, disgust, and fear. The proposed approach yields an accuracy of 96.155% for the emotion joy and 82.44 % for fear which definitely is the best-in-class accuracy for such systems.",multimedia
10.1016/j.procs.2020.03.236,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Deep Convolutional Neural Network based Detection System for Real-time Corn Plant Disease Recognition,https://api.elsevier.com/content/abstract/scopus_id/85084445610,"Corn is one of the most popular food grains in the India and crop loss due to diseases substantially affects the Indian economy and threatens the food availability. Recent access of smart devices can be utilized to provide automatic diagnosis of corn diseases and prevent severe crop losses. This paper presents a real time method based on deep convolutional neural network for corn leaf disease recognition. Deep neural network performance is improved by tuning the hyper-parameters and adjusting the pooling combinations on a system with GPU. Further, the number of parameters of the developed model is optimized to make it suitable for real time inference. The pre-trained deep CNN model was deployed onto raspberry pi 3 using Intel Movidius Neural Compute Stick consisting dedicated CNN hardware blocks. During the recognition of corn leaf diseases, the deep learning model achieves an accuracy of 88.46% demonstrating the feasibility of this method. The presented corn plant disease recognition model is capable of running on standalone smart devices like raspberry-pi or smart-phone and drones.",multimedia
10.1016/j.procs.2020.03.366,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Re-projected SURF Features Based Mean-Shift Algorithm for Visual Tracking,https://api.elsevier.com/content/abstract/scopus_id/85084429241,"Visual tracking is an art of tracking a moving object over video frames using non-stationary cameras, for which feature descriptors of the target are computed and applied to a motion model. In this paper, SURF is used to compute the feature descriptors and Mean-Shift algorithm as a motion model. Mean-shift algorithm is fundamentally a logical approach to track the object on an image frame where the appearance is described by histograms. Mean-Shift tracking can directly be applied to SURF features but there is a big constraint of availability of an adequate number of feature keypoints for a given object. To get over this limitation, the re-projection technique is implemented in this paper for tracking an object in any video recorded from a mobile or stationary camera. Re-projection, online updates the histogram of object template for every frame by superimposing the feature keypoints from upcoming frames to the first frame. The object can be tracked using SURF descriptors without using any secondary information (color, texture, optical flow, gradient, etc.) regarding the object, which makes it computationally inexpensive to be used in real-time systems. Also, the SURF feature is calculated only for the target object that is to be tracked, this further reduces computational complexity. The simulation results prove the effectiveness of the work.",multimedia
10.1016/j.procs.2020.03.355,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Machine Learning in Computer Vision,https://api.elsevier.com/content/abstract/scopus_id/85084422716,"During last few years the computer applications have gone dramatic transformation from simple data processing to machine learning, thanks to the availability and accessibility of huge volume of data collected through sensors and internet. The idea of machine learning demonstrates and propagates the facts that computer has the ability to improve itself with the passage of time. The western countries have shown great interest on the topic of machine learning, computer vision, and pattern recognition via organizing conferences, workshops, collective discussion, experimentation, and real life implementation. This study on machine learning and computer vision explores and analytically evaluates the machine learning applications in computer vision and predicts future prospects. The study has found that the machine learning strategies in computer vision are supervised, un-supervised, and semi-supervised. The commonly used algorithms are neural networks, k-means clustering, and support vector machine. The most recent applications of machine learning in computer vision are object detection, object classification, and extraction of relevant information from images, graphic documents, and videos. Additionally, Tensor flow, Faster-RCNN-Inception-V2 model, and Anaconda software development environment used to identify cars and persons in images.",multimedia
10.1016/j.imu.2020.100324,Journal,Informatics in Medicine Unlocked,scopus,2020-01-01,sciencedirect,Sperm motility analysis system implemented on a hybrid architecture to produce an intelligent analyzer,https://api.elsevier.com/content/abstract/scopus_id/85082863547,"Much research and analysis in biomedicine involve image and video inspection using microscopes. Presently, scientists are dissatisfied with manual observations and assessments, when objective and enhanced data can be obtained by applying new technologies (such as image and video inspection) to biomedical fields, such as sperm analysis. Computer Assisted Sperm Analysis (CASA) systems, developed in the late 1980s, constitute third-generation methods of sperm analysis. This study aimed to develop a standalone medical image and video analysis system that is reconfigurable, flexible, reliable, deterministic, and robust. It proposed a new sperm motility analysis system running on a dual core Central Processing Unit (CPU) + field programmable gate arrays (FPGA) platform, under a real-time operating system (RTOS), which is a step ahead of the third-generation CASA systems.
                  The system hardware and related sperm detection and tracking algorithms were the novelty of this work. The image processing functions mainly run on FPGA, image acquisition, and calculations run on CPU, parallel with FPGA.
                  The result is a much faster, reliable, reconfigurable, and compact intelligent analyzer system.
                  Our prototype system was applied to sperm motility analysis; however, other image processing systems can be applied to this architecture. Additionally, the proposed tracking method for sperm track determination is simple, effective, and does not exert a load on the system.",multimedia
10.1016/j.softx.2020.100426,Journal,SoftwareX,scopus,2020-01-01,sciencedirect,Connecting the CoppeliaSim robotics simulator to virtual reality,https://api.elsevier.com/content/abstract/scopus_id/85080071825,"The CoppeliaSim VR Toolbox provides a set of tools to experience CoppeliaSim robot simulation software in Virtual Reality and to return user interactions. Its primary focus is to create a platform that enables the fast prototyping and verification of robotic systems. Moreover, the generality of the toolbox ensures that it can be valuable in other contexts like robotics education, human–robot interaction or reinforcement learning. The software is designed to have a low entry threshold for moderately complex use cases, but can be extended to perform very complex visualizations for more experienced users.",multimedia
10.1016/j.softx.2020.100419,Journal,SoftwareX,scopus,2020-01-01,sciencedirect,TWINKLE: A digital-twin-building kernel for real-time computer-aided engineering,https://api.elsevier.com/content/abstract/scopus_id/85079158568,"TWINKLE is a library for building families of solvers to perform Canonical Polyadic Decomposition (CPD) of tensors. The common characteristic of these solvers is that the data structure supporting the tuneable solution strategy is based on a Galerkin projection of the phase space. This allows processing and recovering tensors described by highly sparse and unstructured data. For achieving high performance, TWINKLE is written in C++ and uses the Armadillo open source library for linear algebra and scientific computing, based on LAPACK (Linear Algebra PACKage) and BLAS (Basic Linear Algebra Subprograms) routines. The library has been implemented keeping in mind its future extensibility and adaptability to fulfil the different users’ needs in academia and industry regarding Reduced Order Modelling (ROM) and data analysis by means of tensor decomposition. It is especially focused on post-processing data from Computer-Aided-Engineering (CAE) simulation tools.",multimedia
10.1016/bs.adcom.2019.09.008,Book Series,Advances in Computers,scopus,2020-01-01,sciencedirect,Stepping into the digitally instrumented and interconnected era,https://api.elsevier.com/content/abstract/scopus_id/85078358345,"This chapter is to tell all about the digitization-inspired possibilities and opportunities and how software-defined cloud centers are the best fit for hosting and running digital applications. Also, how the next-generation data analytics can be smartly accomplished through cloud platforms and infrastructures is also explained in detail. We are to describe some of the impactful developments and technological advancements brewing in the IT space, how the tremendous amount of data getting produced and processed through cloud systems is to impact the IT and business domains, and how next-generation IT infrastructures are accordingly getting refactored, remedied and readied for the impending big data-induced challenges, how likely the move of the data analytics discipline toward fulfilling the digital universe requirements of extracting and extrapolating actionable insights for the knowledge-parched is, and finally for the establishment and sustenance of the dreamt smarter planet. In short, the uninhibited explosion of digitized systems and connected devices pour out a tremendous amount of multi-structured data and the impending challenge is to make sense out of the data heaps. Data analytics is the way to go and in the recent past, the overwhelming trend is to empower our everyday systems with machine and deep learning algorithms to automatically learn out of data heaps and streams in order to be distinctively intelligent in their actions and reactions. This chapter is specially prepared to put a stimulating foundation for explaining the nitty-gritty of the Digital Twin paradigm.",multimedia
10.1016/j.aap.2019.105319,Journal,Accident Analysis and Prevention,scopus,2020-01-01,sciencedirect,Detecting motorcycle helmet use with deep learning,https://api.elsevier.com/content/abstract/scopus_id/85074491322,"The continuous motorization of traffic has led to a sustained increase in the global number of road related fatalities and injuries. To counter this, governments are focusing on enforcing safe and law-abiding behavior in traffic. However, especially in developing countries where the motorcycle is the main form of transportation, there is a lack of comprehensive data on the safety-critical behavioral metric of motorcycle helmet use. This lack of data prohibits targeted enforcement and education campaigns which are crucial for injury prevention. Hence, we have developed an algorithm for the automated registration of motorcycle helmet usage from video data, using a deep learning approach. Based on 91,000 annotated frames of video data, collected at multiple observation sites in 7 cities across the country of Myanmar, we trained our algorithm to detect active motorcycles, the number and position of riders on the motorcycle, as well as their helmet use. An analysis of the algorithm's accuracy on an annotated test data set, and a comparison to available human-registered helmet use data reveals a high accuracy of our approach. Our algorithm registers motorcycle helmet use rates with an accuracy of −4.4% and +2.1% in comparison to a human observer, with minimal training for individual observation sites. Without observation site specific training, the accuracy of helmet use detection decreases slightly, depending on a number of factors. Our approach can be implemented in existing roadside traffic surveillance infrastructure and can facilitate targeted data-driven injury prevention campaigns with real-time speed. Implications of the proposed method, as well as measures that can further improve detection accuracy are discussed.",multimedia
10.1016/j.apenergy.2019.113998,Journal,Applied Energy,scopus,2020-01-01,sciencedirect,Machine vision for natural gas methane emissions detection using an infrared camera,https://api.elsevier.com/content/abstract/scopus_id/85074166612,"In a climate-constrained world, it is crucial to reduce natural gas methane emissions, which can potentially offset the climate benefits of replacing coal with gas. Optical gas imaging (OGI) is a widely-used method to detect methane leaks, but is labor-intensive and cannot provide leak detection results without operators’ judgment. In this paper, we develop a computer vision approach for OGI-based leak detection using convolutional neural networks (CNN) trained on methane leak images to enable automatic detection. First, we collect ∼1 M frames of labeled videos of methane leaks from different leaking equipment, covering a wide range of leak sizes (5.3–2051.6 g CH4/h) and imaging distances (4.6–15.6 m). Second, we examine different background subtraction methods to extract the methane plume in the foreground. Third, we then test three CNN model variants, collectively called GasNet, to detect plumes in videos. We assess the ability of GasNet to perform leak detection by comparing it to a baseline method that uses an optical-flow based change detection algorithm. We explore the sensitivity of results to the CNN structure, with a moderate-complexity variant performing best across distances. The generated detection probability curves show that the detection accuracy (fraction of leak and non-leak images correctly identified by the algorithm) can reach as high as 99%, the overall detection accuracy can exceed 95% across all leak sizes and imaging distances. Binary detection accuracy exceeds 97% for large leaks (∼710 g CH4/h) imaged closely (∼5–7 m). The GasNet-based computer vision approach could be deployed in OGI surveys for automatic vigilance of methane leak detection with high accuracy in the real world.",multimedia
10.1016/bs.adcom.2019.09.005,Book Series,Advances in Computers,scopus,2020-01-01,sciencedirect,Impact of cloud security in digital twin,https://api.elsevier.com/content/abstract/scopus_id/85073737509,"Digital Twin is a way to virtually represent or model a physical object using the real time data. This innovation sets up a way to deal with industries and organizations to supervise their products, consequently bridging the gap between design and implementations. As the name suggests, “Digital Twin” infers that a reproduction of the product is made in order to have a nearby relationship with the live item. The procedure of computerized twin begins by gathering real time data, processed data, and operational data and performs distinctive investigation which helps in anticipating the future. This additionally enhances the customer experiences by giving a digital feel of their product. The objective behind all these is the job of gathering information and putting them in a place, i.e., the cloud which could store exorbitant data. The user experience gets enhanced by the intervention of digital twin technology which could help in the successful working of the products geographically distributed. The impact of Internet of Things and Cloud Computing lifts up the digital twin.
                  The information gathered from the sources can be arranged in terms of utilization and prospect to change on a timely basis. These data, as they are stored require proper coordination and a legitimate use.
                  Digital Twin innovation assumes incredible opportunities in the field of manufacturing, healthcare, smart cities, automobile and so on. The effect of having a digital twin for the product makes it simple for activities and recognize the blemishes, if any happened. This approach can help reduce the workload and furthermore can get trained on the virtual machine without the need of a specific training.
                  With the most prevailing technologies of today, like Artificial Intelligence, Machine Learning and Internet of Things more prominent approach to train and monitor products, taking care of its own execution, collaborating to different frameworks, performing self-repairs are made possible. Hence the future is getting unfolded with the emerging DIGITAL TWIN era. The massive data utilized in the field of digital twin is prone to severe security breaches. Thus digital twin technology should be handled with extreme care so as to protect the data. Hence, this chapter identifies the ways and means of collecting, organizing and storing the data in a secured cloud environment. The data is filtered according to the use and priority and pushed into the cloud. It is determined to implement an exclusive algorithm for a secured cloud which would greatly benefit the users and the providers to handle and process it effectively.",multimedia
10.1016/j.cogsys.2019.09.015,Journal,Cognitive Systems Research,scopus,2020-01-01,sciencedirect,Multi-Agent neurocognitive models of semantics of spatial localization of events,https://api.elsevier.com/content/abstract/scopus_id/85072851037,"The purpose of the study is to develop a learning system for internal representation of the events localization space to realize orientation and navigation of autonomous mobile systems. The task of the research is the development of simulation models of the semantics of the event localization space based on multi-agent neurocognitive architectures. The paper proves that the multi-agent neurocognitive architecture is an effective formalism for describing the semantics of the spatial localization of events. Main theoretical foundations have been developed for the simulation of spatial relations using the so-called multi-agent facts, consisting of software agents-concepts, reflecting semantic categories corresponding to parts of speech. It is shown that locative software agents that describe the spatial location of objects and events, forming homogeneous connections, compose the so-called field locations. The latter describes a holistic view of the intellectual agent about the environment. The paper defines conceptual foundations of multi-agent modeling of the semantics of subjective reflexive mapping of the interaction between real objects, space and time.",multimedia
10.1016/j.neunet.2019.07.020,Journal,Neural Networks,scopus,2020-01-01,sciencedirect,Deep neural network and data augmentation methodology for off-axis iris segmentation in wearable headsets,https://api.elsevier.com/content/abstract/scopus_id/85072296970,"A data augmentation methodology is presented and applied to generate a large dataset of off-axis iris regions and train a low-complexity deep neural network. Although of low complexity the resulting network achieves a high level of accuracy in iris region segmentation for challenging off-axis eye-patches. Interestingly, this network is also shown to achieve high levels of performance for regular, frontal, segmentation of iris regions, comparing favourably with state-of-the-art techniques of significantly higher complexity. Due to its lower complexity this network is well suited for deployment in embedded applications such as augmented and mixed reality headsets.",multimedia
10.1016/j.future.2019.08.032,Journal,Future Generation Computer Systems,scopus,2020-01-01,sciencedirect,Q-learning based collaborative cache allocation in mobile edge computing,https://api.elsevier.com/content/abstract/scopus_id/85072201451,"The rapid development of  Augmented Reality (AR), Virtual Reality(VR), Internet of Things (IoT), and high-definition video has caught the attention of low latency and high bandwidth network requirements. For huge data transmission, cache technology has been regarded as an effective solution for reducing transmission time from users to remote clouds. However, the increasing variety of cached data has caused the challenge of cache performance. Based on high flexibility, scalability, and deployability of the characteristics of Software-Defined Networking (SDN), this study proposes a collaborative cache mechanism in multiple Remote Radio Heads (RRHs) to multiple Baseband Units (BBUs). In addition, the traditional rule-based and metaheuristics methods are difficult to consider all environmental factors. To reduce the traffic load of backhaul and transmission latency from the remote cloud, we use Q-learning to design the cache mechanism and propose an action selection strategy for the cache problem. Through reinforcement learning to find the appropriate cache state. The simulation results show that the proposed method can effectively improve the cache performance.",multimedia
10.1016/j.bjoms.2019.08.011,Journal,British Journal of Oral and Maxillofacial Surgery,scopus,2020-01-01,sciencedirect,Welcome the “new kid on the block” into the family: artificial intelligence in oral and maxillofacial surgery,https://api.elsevier.com/content/abstract/scopus_id/85072055163,"Recent decades have witnessed the genesis and progressive application of intelligent machines and computer programs that have the ability to process information and execute cognitive functions similar to those of human logic and reasoning such as problem solving and decision making. That is artificial intelligence (AI) in a nutshell as envisioned by John McCarthy, “the father of AI”. Healthcare has welcomed AI, giving rise to collaborations such as the Moorfields Eye Hospital and Google’s DeepMind division in the screening and predicting of retinal disease. The use of AI by the maxillofacial surgical fraternity is, however, limited. We wish to highlight the fact that surgeons are uniquely positioned to help drive these innovations rather than passively waiting for the technology to become useful.",multimedia
10.1016/j.inffus.2019.06.019,Journal,Information Fusion,scopus,2020-01-01,sciencedirect,A snapshot research and implementation of multimodal information fusion for data-driven emotion recognition,https://api.elsevier.com/content/abstract/scopus_id/85067959783,"With the rapid development of artificial intelligence and mobile Internet, the new requirements for human-computer interaction have been put forward. The personalized emotional interaction service is a new trend in the human-computer interaction field. As a basis of emotional interaction, emotion recognition has also introduced many new advances with the development of artificial intelligence. The current research on emotion recognition mostly focuses on single-modal recognition such as expression recognition, speech recognition, limb recognition, and physiological signal recognition. However, the lack of the single-modal emotional information and vulnerability to various external factors lead to lower accuracy of emotion recognition. Therefore, multimodal information fusion for data-driven emotion recognition has been attracting the attention of researchers in the affective computing filed. This paper reviews the development background and hot spots of the data-driven multimodal emotion information fusion. Considering the real-time mental health monitoring system, the current development of multimodal emotion data sets, the multimodal features extraction, including the EEG, speech, expression, text features, and multimodal fusion strategies and recognition methods are discussed and summarized in detail. The main objective of this work is to present a clear explanation of the scientific problems and future research directions in the multimodal information fusion for data-driven emotion recognition field.",multimedia
10.1016/j.jmapro.2019.10.020,Journal,Journal of Manufacturing Processes,scopus,2019-12-01,sciencedirect,Data-driven smart manufacturing: Tool wear monitoring with audio signals and machine learning,https://api.elsevier.com/content/abstract/scopus_id/85074281429,"Tool wear in machining could result in poor surface finish, excessive vibration and energy consumption. Monitoring tool wear in real-time is crucial to improve manufacturing productivity and quality. While numerous sensor-based tool wear monitoring techniques have been demonstrated in laboratory environments, few tool wear monitoring systems have been deployed in factories because it is not realistic to install some of the important sensors such as dynamometers on manufacturing machines. To address this issue, a novel audio signal processing approach is introduced. This technique does not require expensive sensors but audio sensors only. A blind source separation method is used to separate source signals from noise. An extended principal component analysis is used for dimensionality reduction. Real-time multi-channel audio signals are collected during a set of milling tests under varying cutting conditions. The experimental data are used to develop and validate a predictive model. Experimental results have shown that the predictive model is capable of classifying tool wear conditions with high accuracy.",multimedia
10.1016/j.patrec.2019.10.002,Journal,Pattern Recognition Letters,scopus,2019-12-01,sciencedirect,A deep learning approach for face recognition based on angularly discriminative features,https://api.elsevier.com/content/abstract/scopus_id/85073234605,"Face recognition in digital images or video frames has several real-world applications in the modern zone of computer vision. Loss function plays a vital role in deep face recognition. Recently, several loss functions have been proposed in classification techniques to reduce the number of model errors. Among several loss functions, softmax loss implemented either multiplicative angular or additive cosine margin. These individual margins have less capacity to reduce the model`s errors. To fill this gap; we proposed a hybrid angularly discriminative features by combining multiplicative angular and additive cosine margin to improve the efficiency of angular softmax loss and large margin cosine. We trained proposed model using CASIA-WebFace dataset and testing has been performed on Labeled Face in the Wild (LFW), YouTube Faces (YTF), VGGFace1 and VGGFace2. The experimental result shows 99.77% accuracy on LFW dataset whereas 96.40% accuracy achieved on YTF dataset which is higher than the existing similar state-of-the-art techniques.",multimedia
10.1016/j.jvcir.2019.102651,Journal,Journal of Visual Communication and Image Representation,scopus,2019-12-01,sciencedirect,3DSportNet: 3D sport reconstruction by quality-aware deep multi-video summation,https://api.elsevier.com/content/abstract/scopus_id/85072711895,"Automatically reconstructing 3D sceneries from video sequences is an indispensable technique in computer 3D games, urban planning, and intelligent navigation. Many previous work relies on complicated and expensive equipment to fulfill 3D reconstruction under constrained environments. Nevertheless, such schemes are not readily to be applied for reconstructing 3D sport sceneries, such as basketball and mountain climbing. In this work, we propose a novel deep architecture: 3DSportNet, which reconstructs 3D sport sceneries by making use of multiple handheld videos captured by smart phones. In particular, given a rich of mobile videos captured by users, we extract multiple deep/shallow visual features from each sport video frame by leveraging the weakly-supervised semantic encoding. Afterward, a geometry-aware quality model is designed to summarize the multiple videos into multiple key frames from each single video, wherein the objective is that the selected key frames can maximally reconstruct the multiple sport videos. Based on this, we employ the key frames to reconstruct sport videos by utilizing the PMVS2 software. Comprehensive experimental comparisons and visualization results have shown that our method can produce very real 3D sport sceneries and athletes. Besides, the 3D reconstruction time consumption is reduced by 95% compared to conventional methods.",multimedia
10.1016/j.patcog.2019.106965,Journal,Pattern Recognition,scopus,2019-12-01,sciencedirect,A deep one-shot network for query-based logo retrieval,https://api.elsevier.com/content/abstract/scopus_id/85068873170,"Logo detection in real-world scene images is an important problem with applications in advertisement and marketing. Existing general-purpose object detection methods require large training data with annotations for every logo class. These methods do not satisfy the incremental demand of logo classes necessary for practical deployment since it is practically impossible to have such annotated data for new unseen logo. In this work, we develop an easy-to-implement query-based logo detection and localization system by employing a one-shot learning technique using off the shelf neural network components. Given an image of a query logo, our model searches for logo within a given target image and predicts the possible location of the logo by estimating a binary segmentation mask. The proposed model consists of a conditional branch and a segmentation branch. The former gives a conditional latent representation of the given query logo which is combined with feature maps of the segmentation branch at multiple scales in order to obtain the matching location of the query logo in a target image. Feature matching between the latent query representation and multi-scale feature maps of segmentation branch using simple concatenation operation followed by 1 × 1 convolution layer makes our model scale-invariant. Despite its simplicity, our query-based logo retrieval framework achieved superior performance in FlickrLogos-32 and TopLogos-10 dataset over different existing baseline methods.",multimedia
10.1016/j.rcim.2019.05.008,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2019-12-01,sciencedirect,A real-time human-robot interaction framework with robust background invariant hand gesture detection,https://api.elsevier.com/content/abstract/scopus_id/85066259834,"In the light of factories of the future, to ensure productive and safe interaction between robot and human coworkers, it is imperative that the robot extracts the essential information of the coworker. We address this by designing a reliable framework for real-time safe human-robot collaboration, using static hand gestures and 3D skeleton extraction. OpenPose library is integrated with Microsoft Kinect V2, to obtain a 3D estimation of the human skeleton. With the help of 10 volunteers, we recorded an image dataset of alpha-numeric static hand gestures, taken from the American Sign Language. We named our dataset OpenSign and released it to the community for benchmarking. Inception V3 convolutional neural network is adapted and trained to detect the hand gestures. To augment the data for training the hand gesture detector, we use OpenPose to localize the hands in the dataset images and segment the backgrounds of hand images, by exploiting the Kinect V2 depth map. Then, the backgrounds are substituted with random patterns and indoor architecture templates. Fine-tuning of Inception V3 is performed in three phases, to achieve validation accuracy of 99.1% and test accuracy of 98.9%. An asynchronous integration of image acquisition and hand gesture detection is performed to ensure real-time detection of hand gestures. Finally, the proposed framework is integrated in our physical human-robot interaction library OpenPHRI. This integration complements OpenPHRI by providing successful implementation of the ISO/TS 15066 safety standards for “safety rated monitored stop” and “speed and separation monitoring” collaborative modes. We validate the performance of the proposed framework through a complete teaching by demonstration experiment with a robotic manipulator.",multimedia
10.1016/j.patrec.2018.04.009,Journal,Pattern Recognition Letters,scopus,2019-12-01,sciencedirect,A real-time and unsupervised face re-identification system for human-robot interaction,https://api.elsevier.com/content/abstract/scopus_id/85046146958,"In the context of Human-Robot Interaction (HRI), face Re-Identification (face Re-ID) aims to verify if certain detected faces have already been observed by robots. The ability of distinguishing between different users is crucial in social robots as it will enable the robot to tailor the interaction strategy toward the users’ individual preferences. So far face recognition research has achieved great success, however little attention has been paid to the realistic applications of Face Re-ID in social robots. In this paper, we present an effective and unsupervised face Re-ID system which simultaneously re-identifies multiple faces for HRI. This Re-ID system employs Deep Convolutional Neural Networks to extract features, and an online clustering algorithm to determine the face's ID. Its performance is evaluated on two datasets: the TERESA video dataset collected by the TERESA robot, and the YouTube Face Dataset (YTF Dataset). We demonstrate that the optimised combination of techniques achieves an overall 93.55% accuracy on TERESA dataset and an overall 90.41% accuracy on YTF dataset. We have implemented the proposed method into a software module in the HCI^2 Framework [1] for it to be further integrated into the TERESA robot [2], and has achieved real-time performance at 10–26 Frames per second.",multimedia
10.1016/j.neucom.2019.08.031,Journal,Neurocomputing,scopus,2019-11-20,sciencedirect,Deep network for human action recognition using Weber motion,https://api.elsevier.com/content/abstract/scopus_id/85070678569,"Effective motion estimation is one of the prime steps for any human action recognition (HAR) algorithm. Optical flow (OF) and motion history image (MHI) are two well-known methods for motion estimation in videos. OF has several advantages over MHI. But the major drawback with OF is that it is computationally very expensive as compared to the MHI. Therefore, in this paper, a new motion estimation technique named as Weber Motion History Image (WMHI) is proposed. Here, an extremely fast algorithm is proposed for HAR using WMHI, pose information, and convolutional neural network (CNN). In spite of being fast and less space consuming, the algorithm outperforms the existing pose based CNN results on five benchmark datasets namely JHMDB [1], sub-JHMDB [1], MPII [2] and HMDB51 [3] and UCF101 [4]. The work mainly focuses on a new efficient algorithm which can be implemented for real-time HAR in videos. For real-time implementation, the two basic criteria on which an algorithm can be analyzed are space and time complexity. The proposed algorithm is faster as compared to the existing OF based HAR systems. In terms of space complexity, the feature size of the proposed algorithm is almost 50% of the existing OF based algorithm. The recognition results still outperform the existing result by a significant margin.",multimedia
10.1016/j.neucom.2019.06.099,Journal,Neurocomputing,scopus,2019-11-06,sciencedirect,A self-learning dynamic path planning method for evacuation in large public buildings based on neural networks,https://api.elsevier.com/content/abstract/scopus_id/85069916355,"Evacuation path planning is of significant importance to safely and efficiently evacuate occupants inside public buildings. Current computer simulation methods carry out evacuation analysis and then provide emergency education and management with a vivid virtual environment. However, efficient evacuation path planning approaches for evacuation guidance still meet the challenges of generating the analysis models, and lacking of real-time analysis methods under dynamic circumstances. In this study, a dynamic path planning approach based on neural networks is proposed for evacuation planning in large public buildings. First, an automatic process to develop the evacuation analysis model with simplified but sufficient information is presented. Then a path generation algorithm is proposed, together with an evaluation process, to generate a number of training sets for policy neural networks. When the primary policy neural network is preliminarily trained, it falls into a self-learning iteration process. Finally, the approach embeds a dynamic algorithm to simulate the mutual influences among all occupants in the building. The neural network was trained according to a real large public building and then the approach managed to provide rapid and feasible evacuation guidance for both occupants to escape in multiple scenarios and managers to design the evacuation strategy. Test results showed that the proposed approach runs 8–10 times faster than existing software and traditional search algorithms.",multimedia
10.1016/j.ifacol.2019.12.445,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-11-01,sciencedirect,Digital transformation readiness in higher education institutions (hei):the case of kosovo,https://api.elsevier.com/content/abstract/scopus_id/85080901449,"This research investigates the current readiness of Higher Education Institutions for the digital transformation of their processes. The purpose of the study is to investigate the implemented comparative measures and the challenges faced by higher education institutions dealing with the digital transformation of their processes. The specific importance of this study relates to the level of use of digital technologies during the teaching process as well as administrative activities that enable advanced communication between institutions, students, academic and administrative staff, as well as other internal and external networking processes. The research results show a significant change in the particular interest in the use of digital technologies at HEIs. The major digital transformation technologies such as Artificial Intelligence, Cloud Technologies, Internet of Things, undergone comparison and ranking based on the findings from the best practices derived from literature. The same ranking has been conducted at the HEI of Kosovo. The synthesis of two evaluations delivers the final results of this research.",multimedia
10.1016/j.enbuild.2019.109440,Journal,Energy and Buildings,scopus,2019-11-01,sciencedirect,A deep reinforcement learning-based autonomous ventilation control system for smart indoor air quality management in a subway station,https://api.elsevier.com/content/abstract/scopus_id/85072289855,"Mechanical ventilation has been widely implemented to alleviate poor indoor air quality (IAQ) in confined underground public facilities. However, due to time-varying IAQ properties that are influenced by unpredictable factors, including outdoor air quality, subway schedules, and passenger volumes, real-time control that incorporates a trade-off between energy saving and IAQ is limited in conventional rule-based and model-based approaches. We propose a data-driven and intelligent approach for a smart ventilation control system based on a deep reinforcement learning (DeepRL) algorithm. This study utilized a deep Q-network (DQN) algorithm of DeepRL to design the ventilation system. The DQN agent was trained in a virtual environment defined by a gray-box model to simulate an IAQ system in a subway station. Performance of the proposed method over three weeks was evaluated by a comprehensive indoor air-quality index (CIAI) and energy consumption under different outdoor air quality scenarios. The results show that the proposed DeepRL-based ventilation control system reduced energy consumption by up to 14.4% for the validation dataset time interval and improved IAQ from unhealthy to acceptable.",multimedia
10.1016/j.knosys.2019.07.022,Journal,Knowledge-Based Systems,scopus,2019-10-15,sciencedirect,Towards reliable online clickbait video detection: A content-agnostic approach,https://api.elsevier.com/content/abstract/scopus_id/85069746546,"Online video sharing platforms (e.g., YouTube, Vimeo) have become an increasingly popular paradigm for people to consume video contents. Clickbait video, whose content clearly deviates from its title/thumbnail, has emerged as a critical problem on online video sharing platforms. Current clickbait detection solutions that mainly focus on analyzing the text of the title, the image of the thumbnail, or the content of the video are shown to be suboptimal in detecting the online clickbait videos. In this paper, we develop a novel content-agnostic scheme, Online Video Clickbait Protector (OVCP), to effectively detect clickbait videos by exploring the comments from the audience who watched the video. Different from existing solutions, OVCP does not directly analyze the content of the video and its pre-click information (e.g., title and thumbnail). Therefore, it is robust against sophisticated content creators who often generate clickbait videos that can bypass the current clickbait detectors. We evaluate OVCP with a real-world dataset collected from YouTube. Experimental results demonstrate that OVCP is effective in identifying clickbait videos and significantly outperforms both state-of-the-art baseline models and human annotators.",multimedia
10.1016/j.brainres.2019.146341,Journal,Brain Research,scopus,2019-10-15,sciencedirect,Automatic detection and sonification of nonmotor generalized onset epileptic seizures: Preliminary results,https://api.elsevier.com/content/abstract/scopus_id/85069698124,"Long-term video-EEG monitoring has improved diagnosis and treatment of epilepsy, especially in children. However, the amount of data neurophysiologists must analyze has grown remarkably.
                  The main purpose of this paper is to provide a diagnostic support to speed up and ease EEG interpretation for a specific application concerning absence seizures, a type of non-motor generalized epileptic seizures.
                  The proposed method consists of a pre-processing step where signals are filtered through the Stationary Wavelet Transform for the reduction of possible artefacts. Subsequently, a supervised automatic classification method is implemented for seizure detection, based on the Support Vector Machine Fine Gaussian method. Finally, a post-processing step is implemented in which spatial and temporal thresholds are defined for both online and offline application.
                  In addition, a method that applies sonification techniques is developed. Sonification techniques could speed up the process of interpreting information, allowing rapid clinical intervention and a continuous monitoring of the event.
                  The dataset consists of 30 EEG recordings performed in 24 children with absence seizures, clinically evaluated at the Meyer Children's Hospital in Firenze, Italy.
                  The method shows encouraging results both in terms of balanced accuracy (about 96%) and latency times (1.25 s on average), which might make it suitable for online clinical trials. In fact, it was implemented in the perspective of a possible real-time application in clinical practice.",multimedia
10.1016/j.comnet.2019.06.001,Journal,Computer Networks,scopus,2019-10-09,sciencedirect,Guiltiness: A practical approach for quantifying virtual network functions performance,https://api.elsevier.com/content/abstract/scopus_id/85067405286,"In Network Functions Virtualization (NFV), service providers create customized network services by chaining Virtual Network Functions (VNFs) in forwarding graphs, according to individual client demands. Despite the flexibility promoted by the NFV paradigm, specific VNFs used in network services may become bottlenecks due to a number of factors, e.g., lack of resource capacities, demand overload, incorrect ordering, and interdependency between VNFs. Hence, resource monitoring is crucial to determine which VNFs have a negative impact on the quality of service. However, NFV imposes constraints that hinder the adoption of traditional network monitoring approaches, such as: the heterogeneity of environments with all sorts of VNF purposes (e.g., caching, address translation, and performance optimization), and the atypical functioning of specific VNFs that rely on non-blocking I/O implementations. In this paper, we propose a model to quantify the guiltiness of each VNF on degrading the performance of a network service. This model consists of a novel application of the Utilization Law from queuing networks theory. Through numeric assessments on typical scenarios, we refined the set of relevant resource metrics and applied a weighted sum to gauge them in the model. Also, a hybrid algorithm based on linear regression and neural networks is introduced to adjust the model’s parameters according to the environment particularities, such as the type and number of VNFs in the service. Experimental evaluations confirm the ability of the model to (i)detect bottlenecks, and (ii)quantify performance degradations. When capacity restrictions were applied to different types of VNFs, our guiltiness metric was able to detect the root cause of degradations. Further, the guiltiness metric outperformed traditional metrics, being able to characterize 96.15% of the performance issues with a 25.6% reduction in the number of false positives when compared to CPU usage.",multimedia
10.1016/j.engfracmech.2019.106642,Journal,Engineering Fracture Mechanics,scopus,2019-10-01,sciencedirect,Necking-induced fracture prediction using an artificial neural network trained on virtual test data,https://api.elsevier.com/content/abstract/scopus_id/85071523401,"The imperfection-based necking model by Marciniak and Kuczyński (MK) is frequently used for predicting the onset of localized necking under proportional and non-proportional loading, which can be considered a lower limit for the occurrence of fracture in a vehicle body structure subjected to crash loading. A large number of virtual imperfection lines at different orientation angles have to be analysed simultaneously in order to find the critical imperfection causing necking under arbitrary loading. This, and the continuous computation of a “distance to necking” quantity, representing a crucial output quantity for the simulation engineer, makes the model computationally expensive and limits industrial use in full-scale vehicle crash simulations.
                  In this work, an extended MK model is used for creating a virtual test data base under proportional and non-proportional loading for training of a computationally more efficient simple feed-forward neural network (NN). Both models are implemented in a User Material routine of an explicit crash code, where the predictions of the NN are in good agreement with the predictions of the MK reference model, however at a significantly reduced computational cost. Besides a pure numerical validation study, an experimental validation study has been performed, imposing biaxial tension loading followed by plane strain tension loading until necking using a special punch test apparatus. Whereas MK and NN are in good agreement with the experimental observations, the agreement of classical necking models, applied in conjunction with a linear damage accumulation (forming severity) concept was less accurate.",multimedia
10.1016/j.cmpb.2019.104991,Journal,Computer Methods and Programs in Biomedicine,scopus,2019-10-01,sciencedirect,CALIMA: The semi-automated open-source calcium imaging analyzer,https://api.elsevier.com/content/abstract/scopus_id/85071454785,"Background and objective
                  Ever since its discovery, calcium imaging has proven its worth in discovering new insights into the mechanisms of cellular communication. Yet, the analysis of the data generated by calcium imaging experiments demands a large amount of time from researchers. Tools enabling automated and semi-automated analysis are available, but often they allow automating only a part of the data analysis process. Therefore, we developed CALIMA (https://aethelraed.nl/calima), a free and open-source standalone software tool that provides an opportunity to quickly detect cells, to obtain the calcium spikes, and to determine the underlying network structure of neuronal cell cultures.
               
                  Methods
                  Owing to the difference of Gaussians algorithm applied for the cell detection, CALIMA is able to detect regions of interest (ROIs) quickly. The z-scoring algorithm provides a means to set the requirements for spike detection, and the neuronal connections can be reconstructed by analyzing the cross-correlation between the cellular activity. We evaluated CALIMA's reliability, speed, and functionality with a special focus on neuronal cell detection and network reconstruction. The evaluation was performed by using real-life data such as a known example dataset (cultured primary rat cortical neurons, University of Pennsylvania) and by analyzing video graphic footage of in vitro brain cell samples (SH-SY5Y neuroblastoma cultures, one sample with synchronous neuron firing). The obtained results were compared to the corresponding outcomes observed on same datasets for other similar software solutions. Moreover, we compared the results of segmentation and peak detection analysis, the ones obtained using CALIMA and those acquired manually.
               
                  Results
                  CALIMA was able to detect the cells in the cultures within seconds. The average sensitivity was 82% across the datasets checked, comparing favorably with the alternative software solutions. Using the correct parameters, CALIMA's Ca-spikes detection sensitivity reached 96%. Lastly, neuronal networks were reconstructed by combining the data on the ROI's activity and the cell's positions, finding the most likely inter-cell connections.
               
                  Conclusions
                  We found that CALIMA proved to be a robust and fast tool to analyze the data of experiments for the digital reconstruction of the neuronal cellular network while being able to process the analysis steps with minimal user input required and in a time efficient manner.",multimedia
10.1016/j.compag.2019.104973,Journal,Computers and Electronics in Agriculture,scopus,2019-10-01,sciencedirect,Deep learning-based visual recognition of rumex for robotic precision farming,https://api.elsevier.com/content/abstract/scopus_id/85071398904,"In this paper we address the problem of recognising the Broad-leaved dock (Rumex obtusifolius L.) in grasslands from high-resolution 2D images. We discuss and present the determining factors for developing and implementing weed visual recognition algorithms using deep learning. This analysis, leads to the formulation of the proposed algorithm. Our implementation exploits Transfer Learning techniques for deep learning-based feature extraction, in combination with a classifier for weed recognition. A prototype robotic platform has been used to make available an image dataset from a dairy farm containing broad-leaved docks. The evaluation of the proposed algorithm on this dataset shows that it outperforms competing weed/plant recognition methods in recognition accuracy, while producing low false-positive rates under real-world operation conditions.",multimedia
10.1016/j.cmpb.2019.104993,Journal,Computer Methods and Programs in Biomedicine,scopus,2019-10-01,sciencedirect,TTTS-GPS: Patient-specific preoperative planning and simulation platform for twin-to-twin transfusion syndrome fetal surgery,https://api.elsevier.com/content/abstract/scopus_id/85069856373,"Twin-to-twin transfusion syndrome (TTTS) is a serious condition that may occur in pregnancies when two or more fetuses share the same placenta. It is characterized by abnormal vascular connections in the placenta that cause blood to flow unevenly between the babies. If left untreated, perinatal mortality occurs in 90% of cases, whilst neurological injuries are still present in TTTS survivors. Minimally invasive fetoscopic laser surgery is the standard and optimal treatment for this condition, but is technically challenging and can lead to complications. Acquiring and maintaining the required surgical skills need consistent practice, and a steep learning curve. An accurate preoperative planning is thus vital for complex TTTS cases. To this end, we propose the first TTTS fetal surgery planning and simulation platform. The soft tissue of the mother, the uterus, the umbilical cords, the placenta and its vascular tree are segmented and registered automatically from magnetic resonance imaging and 3D ultrasound using computer vision and deep learning techniques. The proposed state-of-the-art technology is integrated into a flexible C++ and MITK-based application to provide a full exploration of the intrauterine environment by simulating the fetoscope camera as well as the laser ablation, determining the correct entry point, training doctors’ movements and trajectory ahead of operation, which allows improving upon current practice. A comprehensive usability study is reported. Experienced surgeons rated highly our TTTS planner and simulator, thus being a potential tool to be implemented in real and complex TTTS surgeries.",multimedia
10.1016/j.ijcard.2019.05.070,Journal,International Journal of Cardiology,scopus,2019-10-01,sciencedirect,Best practices in digital health literacy,https://api.elsevier.com/content/abstract/scopus_id/85067503480,"The connection between health literacy and health outcomes includes access and utilization of healthcare services, patient/provider interaction and self-care. Digital approaches can be designed to simplify or expand on a concept, test for understanding, and do not have a time constraint. New technologies, such as artificial intelligence and machine learning, virtual and augmented reality, and blockchain can move the role of technology beyond data collection to a more integrated system. Rather than being a passive participant, digital solutions provide the opportunity for the individual to be an active participant in their health. These solutions can be delivered in a way that builds or enhances the individual's belief that the plan will be successful and more confidence that they can stick with it. Digital solutions allow for the delivery of multi-media education, such as videos, voice, and print, at different reading levels, in multiple languages, using formal and informal teaching methods. By giving the patient a greater voice and empowering them to be active participants in their care, they can develop their decision making and shared decision making skills. The first step in our health literacy instructional model is to address the emotional state of the person. Once the emotional state has been addressed, and an engagement strategy has been deployed the final phase is the delivery of an educational solution. While a clear definition of health literacy and an instructional model are important, further research must be done to continually determine more effective ways to incorporate health technology in the process of improving health outcomes.",multimedia
10.1016/j.csi.2019.103361,Journal,Computer Standards and Interfaces,scopus,2019-10-01,sciencedirect,Using artificial intelligence for modeling of the realistic animal behaviors in a virtual island,https://api.elsevier.com/content/abstract/scopus_id/85067381625,"The remarkable development of the computer graphic techniques enables the creation and management of more realistic games and virtual environments. However, placing the Artificial Intelligence (AI) in a virtual world get making these environments both more interactive and more believable. One of the most ambitious goals of the AI is to create virtual worlds in which a big number of virtual characters or humans being interacted and behave in an autonomous way. For this purpose, placing embodied intelligence characters in a virtual world offers a unique opportunity to evaluate the AI concept.
                  This paper introduces a Virtual Island developed in an innovative way based on fuzzy rules at the user interaction mechanism. We have used fuzzy tactics to create AI-based animals having various behavior types from an eagles’ perspective which called ‘Flight Simulation’. The simulation utilizes an eagle flying over the airspace of the Island of Chios. The AI on the ground is triggered by other animals when they enter a radius area with a certain speed defined in the software. It then decides how to behave according to health, behavior type and confidence level. Also, there is non-AI sparrow herd placed over the island to make user understand how fast he is and give the user sense of speed what can be called as an in-project feature. Consequently, the used Fuzzy Tactics have been tested in realized Unity 3D simulation. The results of the study have proven that the virtual environment consisting AI-based animals has a good performance in terms of animal-user interactions and provided satisfactory results in run time.",multimedia
10.1016/j.postharvbio.2019.05.023,Journal,Postharvest Biology and Technology,scopus,2019-10-01,sciencedirect,Deep learning for noninvasive classification of clustered horticultural crops – A case for banana fruit tiers,https://api.elsevier.com/content/abstract/scopus_id/85066946812,"Practical classification of some horticultural crops such as banana tiers, lanzones and grapes come into clusters instead of individual classification. Unlike most of classification studies, clustered crops are rarely studied due to their complex physical structure. A noninvasive deep learning classification of clustered banana given only a single image feature has been developed as a pioneering deep learning study for clustered horticultural crops. In recent deep learning developments, mask region-based convolution neural networks, also known as Mask R-CNN, show unique applications in image recognition by detecting objects within an image while simultaneously generating segmentation masks. With Mask R-CNN, detection of the complex banana fruit within an image predicts the banana class while at the same time generating a mask separating the fruit from its background. A real dataset is used based on banana tiers and the developed model discriminates normal from abnormal tiers. Unlike the previous general machine learning study, which discriminates reject class from normal class with classification accuracy of 79%, our deep learning model obtained a better averaged accuracy of 92.5%. The previous average weighted accuracy of 94.2% also improved to 96.1% with only a single image feature instead of tedious multiple image and size features. With data augmentation, the model slightly improved into 93.8% accuracy on classifying reject class and 96.5% for overall accuracy. Having successfully implemented in banana tiers, this deep learning classification can also serve as basis for other clustered horticultural crops.",multimedia
10.1016/j.talanta.2019.05.089,Journal,Talanta,scopus,2019-10-01,sciencedirect,Combination of LEDs and cognitive modeling to quantify sheep cheese whey in watercourses,https://api.elsevier.com/content/abstract/scopus_id/85066257571,"The concentration of sheep cheese whey (CW) in water obtained from two Spanish reservoirs, two Spanish rivers, and distilled water has been estimated by combining spectroscopic measurements, obtained with light-emitting diodes (LEDs), and linear or non-linear algorithms. The concentration range of CW that has been studied covers from 0 to 25% in weight. Every sample was measured by six different types of LEDs possessing different emission wavelengths (blue, orange, green, pink, white, and UV). 1,800 fluorescence measurements were carried out and used to design different types of models to estimate the concentration of CW in water. The fluorescence spectra provided by the pink LED originated the most accurate mathematical models, with mean square errors lower than 3.3% and 2.5% for the linear and non-linear approaches, respectively. The pink LED combined with the non-linear model, which was an artificial neural network, was further validated through a k-fold cross-validation and an internal validation. It should be noted that the sensor used here has been designed and produced by a 3D printer and has the potential of being implemented in situ for real-time and cost-effective analysis of natural watercourses.",multimedia
10.1016/j.optlaseng.2019.04.020,Journal,Optics and Lasers in Engineering,scopus,2019-10-01,sciencedirect,Micro deep learning profilometry for high-speed 3D surface imaging,https://api.elsevier.com/content/abstract/scopus_id/85065563524,"How to obtain object information as rich as possible, with the highest possible speed and accuracy from recorded optical signals, has been a crucial issue to the pursuit of powerful imaging technologies. Nowadays, the speed of ultra-fast photography can exceed one quadrillion. However, it can record only two-dimensional images which lack the depth information, greatly limiting our ability to perceive and to understand the complex real-world objects. Inspired by recent successes of deep learning methods in computer vision, we present a novel high-speed three-dimensional (3D) surface imaging approach named micro deep learning profilometry (μDLP) using the structured light illumination. With a properly trained deep neural network, the phase information is predicted from a single fringe image and then can be converted into the 3D shape. Our experiments demonstrate that μDLP can faithfully retrieve the geometry of dynamic objects at 20,000 frames per second. Moreover, comparative results show that μDLP has superior performance in terms of the phase accuracy, reconstruction efficiency, and the ease of implementation over widely used Fourier-transform-based fast 3D imaging techniques, verifying that μDLP is a powerful high-speed 3D surface imaging approach.",multimedia
10.1016/j.jpdc.2017.11.009,Journal,Journal of Parallel and Distributed Computing,scopus,2019-10-01,sciencedirect,Person re-identification with multiple similarity probabilities using deep metric learning for efficient smart security applications,https://api.elsevier.com/content/abstract/scopus_id/85044716579,"Surveillance video analysis plays a vital role in the daily operations of smart cities, which increasingly relies on person re-identification technology to sustain smart security applications. However, research challenges of re-identification remain especially in terms of recognizing the different appearances of the same person in a harsh real-world environment: (1) the adaptability of the selected features to the dynamic environment cannot be guaranteed, and (2) existing methods rooted from metric learning aim to find a single metric function, and they lack the ability to measure the different appearances of the same person. To address these problems, this study proposes a multiple deep metric learning method empowered by the functionality of person similarity probability measurement. The proposed method exploits multiple stacked auto-encoder networks and classification networks to quantify pedestrians’ similarity relations. The stacked auto-encoder networks directly recognize persons from surveillance images at the pixel level. The classification networks are equipped with the Softmax regression models and produce multiple similarity probabilities to characterize different appearances belonging to the same person. An Adaboost-like model is designed to fuse the probabilities corresponding to multiple metrics, which ensures a high accuracy of recognition. Experimental results on two public datasets (VIPeR and CUHK-01) indicate that the proposed method outperforms existing algorithms by 2%–10% at rank 1. Based on the similarity probabilities learned by the proposed model, the algorithm for matching the person pair can achieve a time complexity as low as 
                        O
                        
                           (
                           n
                           )
                        
                     , which can be deployed at a large scale on the distributed intelligent surveillance network, with each node maintaining limited computing capabilities.",multimedia
10.1016/j.jnca.2019.06.003,Journal,Journal of Network and Computer Applications,scopus,2019-09-15,sciencedirect,MAPLE: A Machine Learning Approach for Efficient Placement and Adjustment of Virtual Network Functions,https://api.elsevier.com/content/abstract/scopus_id/85067443855,"As one of the many advantages of cloud computing, Network Function Virtualization (NFV) has revolutionized the network and telecommunication industry through enabling the migration of network functions from expensive dedicated hardware to software-defined components that run in the form of Virtual Network Functions (VNFs). However, with NFV comes numerous challenges related mainly to the complexity of deploying and adjusting VNFs in the physical networks, owing to the huge number of nodes and links in today's datacenters, and the inter-dependency among VNFs forming a certain network service. Several contributions have been made in an attempt to answer these challenges, where most of the existing solutions focus on the static placement of VNFs and overlook the dynamic aspect of the problem, which arises mainly due to the ever-changing resource availability in the cloud datacenters and the continuous mobility of the users. Few attempts have been lately made to incorporate the dynamic aspect to the VNF deployment solutions. The main problem of these approaches lies in their reactive readjustment scheme which determines the placement/migration strategy upon the receipt of a new request or the happening of a certain event, thus resulting in high setup latencies. In this paper, we take advantage of machine learning to reduce the complexity of the placement and readjustment processes through designing a cluster-based proactive solution. The solution consists of (1) an Integer Linear Programming (ILP) model that considers a tradeoff between the minimization of the latency, Service-Level Objective (SLO) violation cost, hardware utilization, and VNF readjustment cost, (2) an optimized k-medoids clustering approach which proactively partitions the substrate network into a set of disjoint on-demand clusters and (3) data-driven cluster-based placement and readjustment algorithms that capitalize on machine learning to intelligently eliminate some cost functions from the optimization problem to boost its feasibility in large-scale networks. Simulation results show that the proposed solution considerably reduces the readjustment time and decrease the hardware utilization compared to the K-means, original k-medoids and migration without clustering approaches.",multimedia
10.1016/j.ifacol.2019.11.102,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-09-01,sciencedirect,Sustainable operations management for industry 4.0 and its social return,https://api.elsevier.com/content/abstract/scopus_id/85078948022,"In today’s industrial environment, where concepts of smart factories are consolidating their application in companies, it is still necessary to approach management decision making from a perspective that encompasses all aspects of sustainability without losing sight of the social return to which they must contribute. In order to obtain a reliable prediction, of the operation of a Sustainable Manufacturing System (SMS) and its Social Return (SR), this paper develops a methodology and procedures that allow predicting the system performance as a whole. This will allow us to assist management decision making in industries 4.0, supported by multi-criteria methods in knowledge management, simulation, value analysis and operational research by means of:
                  a) Study the economic, social and environmental impacts in the organization and management of the efficient operation of an SMS with the selection of strategies and alternatives in production chains to minimize and / or mitigate environmental and labor risks.
                  b) Encourage of industrial symbiosis or eco-industries networks that create opportunities increasing eco-efficiency and the positive social return of production systems.
                  This proposed methodology will facilitate changes in the structure of production systems in order to implement industry 4.0 paradigms through facilitator technologies such as simulation and virtual reality. This framework will allow Small and Medium Enterprises (SMEs) and other companies to address the decision-making activities that improve the economic-functional efficiency, which will lead to reduce the environmental impact and increase the positive social return of certain production strategies, considering working conditions.
                  The proposed approach went validated, in the area of the Euroregion Galicia North of Portugal, to favour the implementation of the decision-making through the Industry 4.0 Technologies.",multimedia
10.1016/j.ifacol.2019.11.465,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-09-01,sciencedirect,"Integration of automatic generated simulation models, machine control projects and management tools to support whole life cycle of industrial digital twins",https://api.elsevier.com/content/abstract/scopus_id/85078871061,"The paper presents a framework of automatic generation of industrial digital twins. These digital twins will be suitable to support preliminary design phases of systems development, but also to support next phases of detailed designs implementation and systems running phases. These digital twin allow, from the preliminary designing phase, to generate a complete simulation of the target industrial system. But, at the same time, and without the need to develop and add any subsequent code, they should be a valuable support for the phases and tasks of exploitation: maintenance, machine or system learning, etc. The problem is that the requirements for first development phases are much more generic than those for later phases. For this reason, instead of incorporating specificities in the simulation system, the framework takes advantage of the applications which are being developed for the implementation of the real system. In these applications (the control program and the decisions and the high level management system), the specificities have had to be taken into account. The system has been specialized in industrial transportation and warehouse systems which, although have a finite number or building objects, they have an infinite set of final configurations, very different one from each other. The paper presents an evaluation of current simulation platforms suitable to be used as part of the framework, and the digital twin industrial system generation framework itself. An example of application is as well presented.",multimedia
10.1016/j.jacr.2019.05.047,Journal,Journal of the American College of Radiology,scopus,2019-09-01,sciencedirect,"Strengths, Weaknesses, Opportunities, and Threats Analysis of Artificial Intelligence and Machine Learning Applications in Radiology",https://api.elsevier.com/content/abstract/scopus_id/85069706449,"Currently, the use of artificial intelligence (AI) in radiology, particularly machine learning (ML), has become a reality in clinical practice. Since the end of the last century, several ML algorithms have been introduced for a wide range of common imaging tasks, not only for diagnostic purposes but also for image acquisition and postprocessing. AI is now recognized to be a driving initiative in every aspect of radiology. There is growing evidence of the advantages of AI in radiology creating seamless imaging workflows for radiologists or even replacing radiologists. Most of the current AI methods have some internal and external disadvantages that are impeding their ultimate implementation in the clinical arena. As such, AI can be considered a portion of a business trying to be introduced in the health care market. For this reason, this review analyzes the current status of AI, and specifically ML, applied to radiology from the scope of strengths, weaknesses, opportunities, and threats (SWOT) analysis.",multimedia
10.1016/j.clineuro.2019.105442,Journal,Clinical Neurology and Neurosurgery,scopus,2019-09-01,sciencedirect,Artificial intelligence for assisting diagnostics and assessment of Parkinson's disease—A review,https://api.elsevier.com/content/abstract/scopus_id/85069629950,"Artificial intelligence, specifically machine learning, has found numerous applications in computer-aided diagnostics, monitoring and management of neurodegenerative movement disorders of parkinsonian type. These tasks are not trivial due to high inter-subject variability and similarity of clinical presentations of different neurodegenerative disorders in the early stages. This paper aims to give a comprehensive, high-level overview of applications of artificial intelligence through machine learning algorithms in kinematic analysis of movement disorders, specifically Parkinson’s disease (PD). We surveyed papers published between January 2007 and January 2019, within online databases, including PubMed and Science Direct, with a focus on the most recently published studies. The search encompassed papers dealing with the implementation of machine learning algorithms for diagnosis and assessment of PD using data describing motion of upper and lower extremities. This systematic review presents an overview of 48 relevant studies published in the abovementioned period, which investigate the use of artificial intelligence for diagnostics, therapy assessment and progress prediction in PD based on body kinematics. Different machine learning algorithms showed promising results, particularly for early PD diagnostics. The investigated publications demonstrated the potentials of collecting data from affordable and globally available devices. However, to fully exploit artificial intelligence technologies in the future, more widespread collaboration is advised among medical institutions, clinicians and researchers, to facilitate aligning of data collection protocols, sharing and merging of data sets.",multimedia
10.1016/j.dsx.2018.07.014,Journal,Diabetes and Metabolic Syndrome: Clinical Research and Reviews,scopus,2019-09-01,sciencedirect,Prevalence of metabolic syndrome in Iranian patients with schizophrenia: A systematic review and meta-analysis,https://api.elsevier.com/content/abstract/scopus_id/85050864479,"Industry 4.0 is an updated concept of smart production, which is identified with the fourth industrial revolution and the emergence of cyber-physical systems. Industry 4.0 is the next stage in the digitization of productions and industries, where such technologies and concepts as the Internet of things, big data, predictive analytics, cloud computing, machine learning, machine interaction, artificial intelligence, robotics, 3D printing, augmented reality.
                  As an area of therapy with the best market potential and one of the most expensive global diseases, diabetes attracts the best healthcare players, who use innovative technologies.
                  Current trends in digitalization of diabetes management are presented.",multimedia
10.1016/j.patrec.2018.02.013,Journal,Pattern Recognition Letters,scopus,2019-09-01,sciencedirect,Biometric surveillance using visual question answering,https://api.elsevier.com/content/abstract/scopus_id/85042474147,"Surveillance of individuals using visual data requires human-level capabilities for understanding the characteristics that differentiate one person from another. However, because the influx of both video and imagery is increasing at a greater rate than humans can cope with, biometric-based surveillance systems are required to assist with the triage of information based on human-generated queries. Unfortunately, current systems are not robust enough to tackle new tasks, as they involve specialized models that do not leverage existing, pre-trained components. To mitigate these issues, we propose a novel system for biometric-based surveillance that utilizes models that are relevance-aware to triage images and videos based on interaction with single or multiple users. As the system is initially focused on detection of people via their appearance and clothing, we have named the system Context and Collaborative (C2) Visual Question Answering (VQA) for Biometric Object-Attribute Relevance and Surveillance (C2VQA-BOARS). To validate the usefulness of C2VQA-BOARS in real-world scenarios, we provide an implementation of two novel components (Relevance and Triage) and apply them in tasks against two datasets created for biometric surveillance. Our results outperform baseline approaches, proving that a system with a minimal amount of fine-tuned components can robustly handle new datasets and problems as needed.",multimedia
10.1016/j.ymeth.2019.03.012,Journal,Methods,scopus,2019-08-15,sciencedirect,IVS2vec: A tool of Inverse Virtual Screening based on word2vec and deep learning techniques,https://api.elsevier.com/content/abstract/scopus_id/85064277603,"Inverse Virtual Screening is a powerful technique in the early stage of drug discovery process. This technique can provide important clues for biologically active molecules, which is useful in the following researches of durg discovery. In this work, combining with Word2vec, a natural language processing technique, dense fully connected neural network (DFCNN) algorithm is utilized to build up a prediction model. This model is able to perform a binary classification. Based on the query molecule, the input protein candidates can be classified into two subsets. One set is that potential targets with high possibilities to bind with the query molecule and the other one is that the proteins with low possibilities to bind with the query molecule. This model is named as IVS2vec. IVS2vec also can output a score reflecting binding possibility of the association between a protein and a molecule, which is useful to improve efficiency of research. We applied IVS2vec on several databases related to drug development and shown that our model can detect possible therapeutic targets. In addition, our model can identify targets related to adverse drug reactions which is useful to improve medication safety and repurpose drugs. Moreover, IVS2vec can give a very fast speed to perform prediction jobs. It is suitable for processing a large number of compounds in the chemical databases. We also find that IVS2vec has potential capabilities and outperform other state-of-the-art docking tools such as Autodock vina. In this study, IVS2vec brings many convincing results than Autodock vina in the reverse target searching case of Quercetin.",multimedia
10.1016/j.neucom.2019.04.037,Journal,Neurocomputing,scopus,2019-08-04,sciencedirect,LEGION-based image segmentation by means of spiking neural networks using normalized synaptic weights implemented on a compact scalable neuromorphic architecture,https://api.elsevier.com/content/abstract/scopus_id/85065418438,"LEGION (Locally Excitatory, Globally Inhibitory Oscillator Network) topology has demonstrated good capabilities in scene segmentation applications. However, the implementation of LEGION algorithm requires machines with high performance to process a set of complex differential equations limiting its use in practical real-time applications. Recently, several authors have proposed alternative methods based on spiking neural networks (SNN) to create oscillatory neural networks with low computational complexity and highly feasible to be implemented on digital hardware to perform adaptive segmentation of images. Nevertheless, existing SNN with LEGION configuration focus on the membrane model leaving aside the behavior of the synapses although they play an important role in the synchronization of several segments by self-adapting their weights. In this work, we propose a SNN-LEGION configuration along with normalized weight of the synapses to self-adapt the SNN network to synchronize several segments of any size and shape at the same time. The proposed SNN-LEGION method involves a global inhibitor, which is in charge of performing the segmentation process between different objects with different sizes and shapes on time. To validate the proposal, the SNN-LEGION method is implemented on an optimized scalable neuromorphic architecture. Our preliminary results demonstrate that the proposed normalization process of the synaptic weights along with the SNN-LEGION configuration keep the capacity of the LEGION network to separate the segments on time, which can be useful in video processing applications such as vision processing systems for mobile robots, offering lower computational complexity and area consumption compared with previously reported solutions.",multimedia
10.1016/j.mfglet.2019.08.003,Journal,Manufacturing Letters,scopus,2019-08-01,sciencedirect,A self-aware and active-guiding training &amp; assistant system for worker-centered intelligent manufacturing,https://api.elsevier.com/content/abstract/scopus_id/85070738030,"Training and on-site assistance is critical to help workers master required skills, improve worker productivity, and guarantee the product quality. Traditional training methods lack worker-centered considerations that are particularly in need when workers are facing ever-changing demands. In this study, we propose a worker-centered training & assistant system for intelligent manufacturing, which is featured with self-awareness and active-guidance. Multi-modal sensing techniques are applied to perceive each individual worker and a deep learning approach is developed to understand the worker’s behavior and intention. Moreover, an object detection algorithm is implemented to identify the parts/tools the worker is interacting with. Then the worker’s current state is inferred and used for quantifying and assessing the worker performance, from which the worker’s potential guidance demands are analyzed. Furthermore, onsite guidance with multi-modal augmented reality is provided actively and continuously during the operational process. Two case studies are used to demonstrate the feasibility and great potential of our proposed approach and system for applying to the manufacturing industry for frontline workers.",multimedia
10.1016/j.compind.2019.05.001,Journal,Computers in Industry,scopus,2019-08-01,sciencedirect,Industrial robot control and operator training using virtual reality interfaces,https://api.elsevier.com/content/abstract/scopus_id/85065132267,"Nowadays, we are involved in the fourth industrial revolution, commonly referred to as “Industry 4.0,” where cyber-physical systems and intelligent automation, including robotics, are the keys. Traditionally, the use of robots has been limited by safety and, in addition, some manufacturing tasks are too complex to be fully automated. Thus, human-robot collaborative applications, where robots are not isolated, are necessary in order to increase the productivity ensuring the safety of the operators with new perception systems for the robot and new interaction interfaces for the human. Moreover, virtual reality has been extended to the industry in the last years, but most of its applications are not related to robots. In this context, this paper works on the synergies between virtual reality and robotics, presenting the use of commercial gaming technologies to create a totally immersive environment based on virtual reality. This environment includes an interface connected to the robot controller, where the necessary mathematical models have been implemented for the control of the virtual robot. The proposed system can be used for training, simulation, and what is more innovative, for robot controlling in an integrated, non-expensive and unique application. Results show that the immersive experience increments the efficiency of the training and simulation processes, offering a cost-effective solution.",multimedia
10.1016/j.isatra.2019.01.026,Journal,ISA Transactions,scopus,2019-08-01,sciencedirect,A new multi-agent particle swarm algorithm based on birds accents for the 3D indoor deployment problem,https://api.elsevier.com/content/abstract/scopus_id/85061324166,"The 3D indoor deployment of sensor nodes is a complex real world problem, proven to be NP-hard and difficult to resolve using classical methods. In this context, we propose a hybrid approach relying on a novel bird’s accent-based many objective particle swarm optimization algorithm (named acMaPSO) to resolve the problem of 3D indoor deployment on the Internet of Things collection networks. The new concept of bird’s accent is presented to assess the search ability of particles in their local areas. To conserve the diversity of the population during searching, particles are separated into different accent groups by their regional habitation and are classified into different categories of birds/particles in each cluster according to their common manner of singing. A particle in an accent-group can select other particles as its neighbors from its group or from other groups (which sing differently) if the selected particles have the same expertise in singing or are less experienced compared to this particle. To allow the search escaping from local optima, the most expert particles (parents) “die” and are regularly replaced by a novice (newborn) randomly generated ones. Moreover, the hybridization of the proposed acMaPSO algorithm with multi-agent systems is suggested. The new variant (named acMaMaPSO) takes advantage of the distribution and interactivity of particle agents. Experimental, numerical and statistical found results show the effectiveness of the two proposed variants compared to different other recent state-of-the-art of many-objective evolutionary algorithms.",multimedia
10.1016/j.gie.2019.03.019,Journal,Gastrointestinal Endoscopy,scopus,2019-07-01,sciencedirect,Quality assurance of computer-aided detection and diagnosis in colonoscopy,https://api.elsevier.com/content/abstract/scopus_id/85065917454,"Recent breakthroughs in artificial intelligence (AI), specifically via its emerging sub-field “deep learning,” have direct implications for computer-aided detection and diagnosis (CADe and/or CADx) for colonoscopy. AI is expected to have at least 2 major roles in colonoscopy practice—polyp detection (CADe) and polyp characterization (CADx). CADe has the potential to decrease the polyp miss rate, contributing to improving adenoma detection, whereas CADx can improve the accuracy of colorectal polyp optical diagnosis, leading to reduction of unnecessary polypectomy of non-neoplastic lesions, potential implementation of a resect-and-discard paradigm, and proper application of advanced resection techniques. A growing number of medical-engineering researchers are developing both CADe and CADx systems, some of which allow real-time recognition of polyps or in vivo identification of adenomas, with over 90% accuracy. However, the quality of the developed AI systems as well as that of the study designs vary significantly, hence raising some concerns regarding the generalization of the proposed AI systems. Initial studies were conducted in an exploratory or retrospective fashion by using stored images and likely overestimating the results. These drawbacks potentially hinder smooth implementation of this novel technology into colonoscopy practice. The aim of this article is to review both contributions and limitations in recent machine-learning-based CADe and/or CADx colonoscopy studies and propose some principles that should underlie system development and clinical testing.",multimedia
10.1016/j.psep.2019.05.016,Journal,Process Safety and Environmental Protection,scopus,2019-07-01,sciencedirect,An intelligent fire detection approach through cameras based on computer vision methods,https://api.elsevier.com/content/abstract/scopus_id/85065893982,"Fire that is one of the most serious accidents in petroleum and chemical factories, may lead to considerable production losses, equipment damages and casualties. Traditional fire detection was done by operators through video cameras in petroleum and chemical facilities. However, it is an unrealistic job for the operator in a large chemical facility to find out the fire in time because there may be hundreds of video cameras installed and the operator may have multiple tasks during his/her shift. With the rapid development of computer vision, intelligent fire detection has received extensive attention from academia and industry. In this paper, we present a novel intelligent fire detection approach through video cameras for preventing fire hazards from going out of control in chemical factories and other high-fire-risk industries. The approach includes three steps: motion detection, fire detection and region classification. At first, moving objects are detected through cameras by a background subtraction method. Then the frame with moving objects is determined by a fire detection model which can output fire regions and their locations. Since false fire regions (some objects similar with fire) may be generated, a region classification model is used to identify whether it is a fire region or not. Once fire appears in any camera, the approach can detect it and output the coordinates of the fire region. Simultaneously, instant messages will be immediately sent to safety supervisors as a fire alarm. The approach can meet the needs of real-time fire detection on the precision and the speed. Its industrial deployment will help detect fire at the very early stage, facilitate the emergency management and therefore significantly contribute to loss prevention.",multimedia
10.1016/j.patrec.2019.04.016,Journal,Pattern Recognition Letters,scopus,2019-07-01,sciencedirect,BitStream: An efficient framework for inference of binary neural networks on CPUs,https://api.elsevier.com/content/abstract/scopus_id/85065660264,"Convolutional Neural Networks (CNN) has been well-studied and widely used in the field of pattern recognition. Many pattern recognition algorithms need features extracted from CNN models to adapt to complex tasks, such as image classification, object detection, natural language processing and so on. However, to deal with more and more complex tasks, modern CNN models are becoming larger and larger, contain large number of parameters and computation, leading to high consumption of memory, computational and power resources during inference. This makes it difficult to run CNN based applications in real time on mobile devices, where memory, computational and power resources are limited. Binarization of neural networks is proposed to reduce memory and computational complexity of CNN. However, traditional implementations of Binary Neural Networks (BNN) follow the conventional im2col-based convolution computation flow, which is widely used in floating-point networks but not friendly enough to cache when it comes to binarized neural networks. In this paper, we propose BitStream, a general architecture for efficient inference of BNN on CPUs. In BitStream, we propose a simple but novel computation flow for BNN. Unlike existing implementations of BNN, in BitStream, all the layers, including convolutional layers, binarization layers and pooling layers are all calculated in binary precision. Comprehensive analyses demonstrate that our proposed computation flow consumes less memory during inference of BNN, and it’s friendly to cache because of its continuous memory access.",multimedia
10.1016/j.media.2019.05.001,Journal,Medical Image Analysis,scopus,2019-07-01,sciencedirect,Denoising of 3D magnetic resonance images using a residual encoder–decoder Wasserstein generative adversarial network,https://api.elsevier.com/content/abstract/scopus_id/85065426790,"Structure-preserved denoising of 3D magnetic resonance imaging (MRI) images is a critical step in medical image analysis. Over the past few years, many algorithms with impressive performances have been proposed. In this paper, inspired by the idea of deep learning, we introduce an MRI denoising method based on the residual encoder–decoder Wasserstein generative adversarial network (RED-WGAN). Specifically, to explore the structure similarity between neighboring slices, a 3D configuration is utilized as the basic processing unit. Residual autoencoders combined with deconvolution operations are introduced into the generator network. Furthermore, to alleviate the oversmoothing shortcoming of the traditional mean squared error (MSE) loss function, the perceptual similarity, which is implemented by calculating the distances in the feature space extracted by a pretrained VGG-19 network, is incorporated with the MSE and adversarial losses to form the new loss function. Extensive experiments are implemented to assess the performance of the proposed method. The experimental results show that the proposed RED-WGAN achieves performance superior to several state-of-the-art methods in both simulated and real clinical data. In particular, our method demonstrates powerful abilities in both noise suppression and structure preservation.",multimedia
10.1016/j.microrel.2019.04.007,Journal,Microelectronics Reliability,scopus,2019-07-01,sciencedirect,Wireless sEMG-based identification in a virtual reality environment,https://api.elsevier.com/content/abstract/scopus_id/85065412864,"A VR real-time control system based on wireless sEMG was designed. The scene in VR was the kitchen at home. The system included sEMG acquisition module, software control module and VR environment module. The sEMG signals were collected from the subjects by a portable wireless acquisition module. The software control module consisted of four parts: real-time myoelectricity signal detection and segmentation, feature extraction, classification identification and control instruction. The mean square and moving average window method were used to segment sEMG signals. The mean absolute value and singular values of wavelet coefficients were selected as sEMG features. Support vector machine and probabilistic neural network were applied for model training and classification. Finally, the control of four motions in virtual kitchen was completed. The VR environment module was derived to perform different motions according to instructions provided by the classification in virtual kitchen.
                  The experimental results showed that this system could perform the real-time control of virtual kitchen motion. For myoelectricity signals of standard motions, the average offline identification accuracy was 95%, and the average online identification accuracy was 90.31%. For the ones of real motions, the offline accuracy of 86.09% and the online accuracy of 83.33% were achieved respectively. This system can be used for muscle rehabilitation training, and provide immersive virtual kitchen scene, which is of positive significance to the rehabilitation of patients. It can also provide an assessment analysis of the muscle recovery of patients.",multimedia
10.1016/j.compag.2019.04.020,Journal,Computers and Electronics in Agriculture,scopus,2019-07-01,sciencedirect,Livestock vocalisation classification in farm soundscapes,https://api.elsevier.com/content/abstract/scopus_id/85065082795,"Livestock vocalisations have been shown to contain information related to animal welfare and behaviour. Automated sound detection has the potential to facilitate a continuous acoustic monitoring system, for use in a range Precision Livestock Farming (PLF) applications. There are few examples of automated livestock vocalisation classification algorithms, and we have found none capable of being easily adapted and applied to different species’ vocalisations. In this work, a multi-purpose livestock vocalisation classification algorithm is presented, utilising audio-specific feature extraction techniques, and machine learning models. To test the multi-purpose nature of the algorithm, three separate data sets were created targeting livestock-related vocalisations, namely sheep, cattle, and Maremma sheepdogs. Audio data was extracted from continuous recordings conducted on-site at three different operational farming enterprises, reflecting the conditions of real deployment. A comparison of Mel-Frequency Cepstral Coefficients (MFCCs) and Discrete Wavelet Transform-based (DWT) features was conducted. Classification was determined using a Support Vector Machine (SVM) model. High accuracy was achieved for all data sets (sheep: 99.29%, cattle: 95.78%, dogs: 99.67%). Classification performance alone was insufficient to determine the most suitable feature extraction method for each data set. Computational timing results revealed the DWT-based features to be markedly faster to produce (14.81 – 15.38% decrease in execution time). The results indicate the development of a highly accurate livestock vocalisation classification algorithm, which forms the foundation for an automated livestock vocalisation detection system.",multimedia
10.1016/j.bspc.2019.03.011,Journal,Biomedical Signal Processing and Control,scopus,2019-07-01,sciencedirect,Are you afraid of heights and suitable for working at height?,https://api.elsevier.com/content/abstract/scopus_id/85063350700,"Fear of highs is one of the most common phobias all around world. It could affect people’s life, work and health. Standing on high-altitude can lead to fear, anxiety or even panic to some people. In this paper, EEG method is creatively combined with VR technology to assess the severity of fear of heights. By doing time-frequency analysis, we found that alpha band (8–13 Hz) and high beta (20–30 Hz) are sensitive to fear of heights and frontal and parietotemporal areas are the regions of interests for fear of heights. Then using cross mutual information we built up a functional brain networks of every subject. And we extracted EEG features from the brain networks. Statistical analysis was performed to select the features based on significance of difference. Finally, we implemented classification. The performance of classifiers (the average accuracy could reach 94.44%) based on the proposed method was compared to the performance of classifiers based on the traditional physiological features. As a result, the proposed method was verified to be reliable and superior on estimating the severity of fear of heights. In addition, the system was tested on elderly people and came out with good performance. It turns out that the proposed system has good generalization capability and adaptability.",multimedia
10.1016/j.eswa.2019.01.077,Journal,Expert Systems with Applications,scopus,2019-07-01,sciencedirect,Deep learning in material recovery: Development of method to create training database,https://api.elsevier.com/content/abstract/scopus_id/85061339627,"Increasing the rate of material identification, separation and recovery is a priority in resource management and recovery, and rapid, low cost imaging and interpretation is key. This study uses different combinations of cameras, illuminations and data augmentation techniques to create databases of images to train deep neural networks for the recognition of fibre materials. Using a limited set of 24 material samples sized 1200 cm2, it compares the outcome of reducing them to 30 cm2. The best classification accuracies obtained range from 76.6% to 77.5% indicating it is possible to overcome problems such as limited available materials, time, or storage capabilities, by using a setup with 5 cameras, 5 lights and applying simple software image manipulation techniques. The same method can be used to create deep neural network training databases to recognise a wider range of materials typically found in solid waste streams, in real-time. Furthermore, it offers flexibility as the classification cameras could be deployed at different stages within solid waste processing plants, providing feedback for process control, with the potential of increasing plant efficiency and reducing costs.",multimedia
10.1016/j.comcom.2019.03.003,Journal,Computer Communications,scopus,2019-05-01,sciencedirect,The P-ART framework for placement of virtual network services in a multi-cloud environment,https://api.elsevier.com/content/abstract/scopus_id/85064493598,"Carriers’ network services are distributed, dynamic, and investment intensive. Deploying them as virtual network services (VNS) brings the promise of low-cost agile deployments, which reduce time to market new services. If these virtual services are hosted dynamically over multiple clouds, greater flexibility in optimizing performance and cost can be achieved. On the flip side, when orchestrated over multiple clouds, the stringent performance norms for carrier services become difficult to meet, necessitating novel and innovative placement strategies. In selecting the appropriate combination of clouds for placement, it is important to look ahead and visualize the environment that will exist at the time a virtual network service is actually activated. This serves multiple purposes — clouds can be selected to optimize the cost, the chosen performance parameters can be kept within the defined limits, and the speed of placement can be increased. In this paper, we propose the P-ART (Predictive-Adaptive Real Time) framework that relies on predictive-deductive features to achieve these objectives. With so much riding on predictions, we include in our framework a novel concept-drift compensation technique to make the predictions closer to reality by taking care of long-term traffic variations. At the same time, near real-time update of the prediction models takes care of sudden short-term variations. These predictions are then used by a new randomized placement heuristic that carries out a fast cloud selection using a least-cost latency-constrained policy. An empirical analysis carried out using datasets from a queuing-theoretic model and also through implementation on CloudLab, proves the effectiveness of the P-ART framework. The placement system works fast, placing thousands of functions in a sub-minute time frame with a high acceptance ratio, making it suitable for dynamic placement. We expect the framework to be an important step in making the deployment of carrier-grade VNS on multi-cloud systems, using network function virtualization (NFV), a reality.",multimedia
10.1016/j.amsu.2019.04.001,Journal,Annals of Medicine and Surgery,scopus,2019-05-01,sciencedirect,"Artificial intelligence, regenerative surgery, robotics? What is realistic for the future of surgery?",https://api.elsevier.com/content/abstract/scopus_id/85064430299,"The potential of surgery lies in the technological advances that would complement it. The landscape of the field will differ depending on the time period being looked at and would no doubt include conjecture. Initial breakthroughs will need to pave the way for future medical technology and apply to the surgical sciences. Within the next 10 years we would expect to see the emergence of big data analysis, cuttingedge image processing techniques for surgical planning and better implementation of virtual and augmented reality in operating theatres for both patient care and teaching purposes. Over the next 50 to 100 years, the use of quantum computing should lead to increased automation in our healthcare systems. The inception of novel biomaterial invention and advanced genetic engineering will usher in the new age of regenerative medicine in the clinical setting. The future of surgery includes many predictions and promises, but it is apparent that the development will lead to bettering outcome and focus on patient care.",multimedia
10.1016/j.crad.2019.02.006,Journal,Clinical Radiology,scopus,2019-05-01,sciencedirect,Artificial intelligence in breast imaging,https://api.elsevier.com/content/abstract/scopus_id/85062980487,"This article reviews current limitations and future opportunities for the application of computer-aided detection (CAD) systems and artificial intelligence in breast imaging. Traditional CAD systems in mammography screening have followed a rules-based approach, incorporating domain knowledge into hand-crafted features before using classical machine learning techniques as a classifier. The first commercial CAD system, ImageChecker M1000, relies on computer vision techniques for pattern recognition. Unfortunately, CAD systems have been shown to adversely affect some radiologists' performance and increase recall rates. The Digital Mammography DREAM Challenge was a multidisciplinary collaboration that provided 640,000 mammography images for teams to help decrease false-positive rates in breast cancer screening. Winning solutions leveraged deep learning's (DL) automatic hierarchical feature learning capabilities and used convolutional neural networks. Start-ups Therapixel and Kheiron Medical Technologies are using DL for breast cancer screening. With increasing use of digital breast tomosynthesis, specific artificial intelligence (AI)-CAD systems are emerging to include iCAD's PowerLook Tomo Detection and ScreenPoint Medical's Transpara. Other AI-CAD systems are focusing on breast diagnostic techniques such as ultrasound and magnetic resonance imaging (MRI). There is a gap in the market for contrast-enhanced spectral mammography AI-CAD tools. Clinical implementation of AI-CAD tools requires testing in scenarios mimicking real life to prove its usefulness in the clinical environment. This requires a large and representative dataset for testing and assessment of the reader's interaction with the tools. A cost-effectiveness assessment should be undertaken, with a large feasibility study carried out to ensure there are no unintended consequences. AI-CAD systems should incorporate explainable AI in accordance with the European Union General Data Protection Regulation (GDPR).",multimedia
10.1016/j.petrol.2019.01.089,Journal,Journal of Petroleum Science and Engineering,scopus,2019-05-01,sciencedirect,Predicting seismic-based risk of lost circulation using machine learning,https://api.elsevier.com/content/abstract/scopus_id/85061035639,"Lost circulation during well drilling and completion wastes productive time, and even kills the well in severe cases. Timely identifying lost circulation events and taking countermeasures has been the focus of related study. However, a real prediction of lost circulation risk before drilling would be an active response to the challenge. In this paper, a technical solution is proposed to evaluate geological lost-circulation risk in the field using 3D seismic data attributes and machine learning technique. First, four seismic attributes (variance, attenuation, sweetness, RMS amplitude) that are the most correlated with lost circulation incidents are recommended. Then a prediction model is built by conducting supervised learning that involves a majority voting algorithm. The performance of the model is illustrated by six unseen drilled wells and shows the ability and potential to forecast lost circulation probability both along well trajectory and in the region far away from the drilled wells. The prediction resolution in the lateral and vertical direction is about 25 m and 6 m (2 ms), respectively, which are distinct advantages over the traditional description of geological structures using seismic data. It shows that the lost circulation risk can be hardly recognized by interpreting one specific seismic attribute, which is a common practice. Finally, the challenges in predicting lost circulation risk using seismic data are summarized. Overall, the study suggests that machine learning would be a practical solution to predict various construction risks that are related to seismic-based geological issues. Knowing in advance the risks, people could avoid or at least minimize the losses by optimizing well deployment in the field and taking preventive measures.",multimedia
10.1016/j.optcom.2018.12.064,Journal,Optics Communications,scopus,2019-04-15,sciencedirect,Adaptive dynamic wavelength and bandwidth allocation algorithm based on error-back-propagation neural network prediction,https://api.elsevier.com/content/abstract/scopus_id/85059442221,"With the emergence of new services such as high-definition video, cloud computing and virtual reality, Wavelength Division Multiplexing/Time Division Multiplexing-Passive Optical Network (WDM/TDM-PON) has become a key technology for future access network. The development of Software Defined Networking (SDN) and machine learning also brings new opportunities to the flexibility of WDM/TDM-PON. In this paper, an Adaptive Dynamic Bandwidth Allocation algorithm based on error-back-propagation Neural Network Prediction (ADBA-NNP) was proposed to reduce the Round-trip-time (RTT) delay in the bandwidth-scheduling period. A Dynamic Wavelength Allocation (DWA) algorithm and a novel architecture of WDM/TDM-PON was proposed to simple the multi-carrier source. The experimental results validated that the proposed algorithm could dynamically allocate wavelengths under multi-carrier at 12.5G intervals. Compared with the traditional algorithms, the proposed algorithm could reduce the transmission delay by 25%.",multimedia
10.15232/aas.2018-01801,Journal,Applied Animal Science,scopus,2019-04-01,sciencedirect,INVITED REVIEW: Current state of wearable precision dairy technologies in disease detection,https://api.elsevier.com/content/abstract/scopus_id/85067379776,"Purpose
                  The primary objective of this review article is to provide insight into the role of wearable precision dairy technologies (WPDT) in detection of lameness, mastitis, metabolic disorders, and metritis.
               
                  Sources
                  This review is separated into 3 sections: overview of technology development; WPDT behavioral variables linked to disease; and WPDT detection of disease and disorders. Through Web of Science, Google Scholar, and SPAC (Searchable Proceedings of Animal Conferences, ADSA), 99 publications were identified that discuss WPDT that can be used for disease detection and associated similar abnormal behaviors.
               
                  Synthesis
                  Precision dairy technology is the real-time monitoring of animals through behavior monitoring, milk constituents, milk yield, video analysis, record analysis, and physiological monitoring. Technologies can be wearable, incorporated into the milking system, stand alone, or part of the management software. Real-time monitoring has the potential to improve individual cow management and overall farm efficiency. Wearable precision dairy technologies reside on or within the cow for some amount of time. These WPDT currently can measure an individual cow’s time spent at the feed bunk, rumination time, eating time, lying time, standing time, walking time, activity, lying-to-standing transitions, temperature, and rumen pH and provide a cow’s location. Recently, WPDT marketed for estrus detection were adapted for disease detection.
               
                  Conclusions and Applications
                  Potential does exist for WPDT disease detection. Technologies can identify changes in behavior associated with disease or disorders, although no technologies currently provide disease-specific alerts. Future studies should focus on incorporating multiple behavior, physiological, and herd records with machine-learning techniques to create timely, disease-specific alerts.",multimedia
10.1016/j.ohx.2019.e00061,Journal,HardwareX,scopus,2019-04-01,sciencedirect,An open source automated two-bottle choice test apparatus for rats,https://api.elsevier.com/content/abstract/scopus_id/85064083937,"Two-bottle choice tests are a widely used paradigm in rodents to determine preference between two liquids, with utility for testing animal models of addiction, depression and anhedonia. The following paper describes a 3D-printed, Arduino controlled two-bottle choice test that automatically reads and records drinking behavior in rats to allow for detailed analysis of their drinking microstructure. While commercial products exist use lickometers to measure the microstructure of licking, this design uniquely incorporates hydrostatic depth sensors to allow for real-time volumetric measurements in addition to traditional beam break lick sensing, allowing for licking and drinking microstructure analysis. The goal of this design is to provide a user friendly, affordable apparatus that can study unique, complex behaviors without requiring the purchase of specialized scientific equipment or software. Its applications range from studying alcohol preference in animal models of addiction to sucrose preference in motivational deficits and reward evaluation. This design costs less than $180 CAD to build with decreased cost on each additional device. This design has been successfully tested for accuracy and validated using alcohol preference as an example. The apparatus showed consistency between drinking bouts and volume consumed and is shown to be accurate to ±0.086 ml of the actual volume. This design makes using the two-bottle choice paradigm more accurate, while also making its data more robust and informative while allowing for microstructure analysis of both licking behavior and volume consumed.",multimedia
10.1016/j.resuscitation.2019.02.019,Journal,Resuscitation,scopus,2019-04-01,sciencedirect,Development of a novel cardiopulmonary resuscitation measurement tool using real-time feedback from wearable wireless instrumentation,https://api.elsevier.com/content/abstract/scopus_id/85062471861,"Aim
                  The design and implementation of a wearable training device to improve cardiopulmonary resuscitation (CPR) is presented.
               
                  Methods
                  The MYO contains both Electromyography (EMG) and Inertial Measurement Unit (IMU) sensors which are used to detect effective CPR, and the four common incorrect hand and arm positions viz. relaxed fingers; hands too low on the sternum; patient too close; or patient too far. The device determines the rate and depth of compressions calculated using a Fourier transform and dual-quaternions respectively. In addition, common positional mistakes are determined using classification algorithms (six machine learning algorithms are considered and tested). Feedback via Graphical User Interface (GUI) and audio is integrated.
               
                  Results
                  The system is tested by performing CPR on a mannequin and comparing real-time results to theoretical values. Tests show that although the classification algorithm performed well in testing (98%), in real time, it had low accuracy for certain categories (60%), which are attributable to the MYO calibration, sampling rate and misclassification of similar hand positions. Combining these similar incorrect positions into more general categories significantly improves accuracy, and produces the same improved outcome of improved CPR. The rate and depth measures have a general accuracy of 97%.
               
                  Conclusion
                  The system allows for portable, real-time feedback for use in training and in the field, and shows promise toward classifying and improving the administration of CPR.",multimedia
10.1016/j.mehy.2019.02.021,Journal,Medical Hypotheses,scopus,2019-04-01,sciencedirect,Percolation theory for the recognition of patterns in topographic images of the cortical activity,https://api.elsevier.com/content/abstract/scopus_id/85061357293,"Electroencephalogram (EEG) is one of the mechanisms used to collect complex data. Its use includes evaluating neurological disorders, investigating brain function and correlations between EEG signals and real or imagined movements. The Topographic Image of Cortical Activity (TICA) records obtained by the EEG make it possible to observe, through color discrimination, the cortical areas that represent greater or lesser activity. Percolation Theory (PT) reveals properties on the aspects of fluid spreading from a central point, these properties being related to the aspects of the medium, topological characteristics and ease of penetration of a fluid in materials. The hypothesis presented so far considers that synaptic activities originate in points and spread from them, causing different areas of the brain to interact in a diffusive associative behavior, generating electric and magnetic fields by the currents that spread through the brain tissue and have an effect on the scalp sensors. Brain areas spatially separated create large-scale dynamic networks that are described by functional and effective connectivity. The proposition is that this phenomenon behaves like a fluidic spreading, so we can use the PT, through the topological analysis we detect specific signatures related to neural phenomena that manifest changes in the behavior of synaptic diffusion. This signature must be characterized by the Fractal Dimension (FD) values of the scattering clusters, these values will be used as properties in the k-Nearest Neighbors (kNN) method, an TICA will be categorized according to the degree of similarity to the preexisting patterns. In this context, our hypothesis will consolidate as a more computational resource in the service of medicine and another way that opens with the possibility of analysis and detailed inferences of the brain through TICA that go beyond a simply visual observation, as it happens in the present day.",multimedia
10.1016/j.matdes.2018.107577,Journal,Materials and Design,scopus,2019-03-05,sciencedirect,Ensemble Kalman filter-based data assimilation for three-dimensional multi-phase-field model: Estimation of anisotropic grain boundary properties,https://api.elsevier.com/content/abstract/scopus_id/85059744257,"Data assimilation (DA) has been used as a machine learning approach to estimate a system's state and the unknown parameters in its numerical model by integrating observed data into model predictions. In this paper, we propose using the DA methodology based on the ensemble Kalman filter (EnKF) to improve the accuracy of microstructure prediction using three-dimensional multi-phase-field (3D-MPF) model and estimate the model parameters simultaneously. To demonstrate the applicability of the DA methodology, we performed numerical experiments in which a priori assumed true parameters related to the grain boundary (GB) energy cusp and GB mobility peak of Σ7 coincidence site lattice GB were estimated from synthetic data of time-evolving polycrystalline microstructure. Four model parameters related to the Σ7 GB properties were successfully estimated by assimilating the synthetic microstructure data to the 3D-MPF model predictions using the EnKF-based DA method. Furthermore, we accurately reproduced the preliminarily assumed true shapes of GB energy cusp and GB mobility peak by using the estimated parameters. The results suggest that implementation of the EnKF-based DA method in the MPF model has great potential for identifying unknown material properties and estimating unmeasurable microstructure evolutions in polycrystalline materials based on real time-series 3D microstructure observation data.",multimedia
10.1053/j.semvascsurg.2018.12.006,Journal,Seminars in Vascular Surgery,scopus,2019-03-01,sciencedirect,The pathway to a national vascular skills examination and the role of simulation-based training in an increasingly complex specialty,https://api.elsevier.com/content/abstract/scopus_id/85068518473,"The evolving demands of surgical training have led to the successful implementation of skills examinations in the areas of laparoscopic and endoscopic surgery. Currently, there is no similar formal skills assessment in vascular surgery, despite endovascular intervention replacing open surgery in treatment of many vascular conditions. The adoption of less invasive techniques to treat aneurysm and occlusive disease has resulted in new training paradigms and technical challenges for trainees. The duty hour restriction for trainees and declining numbers of complex open vascular interventions have added to the challenges of vascular surgery training. Simulation is a promising avenue for both skills training and assessment. The ability to evaluate the fundamental skills of trainees would be an important step to ensure a degree of uniformity in trainees’ technical abilities. The role of simulation-based training in acquiring, testing, and refining these skills is still in its infancy in the vascular surgery training paradigm. This article aims to impart a deeper understanding of the conditions for developing and implementing the fundamentals of vascular and endovascular surgery, and to provide guidance regarding the role of simulation-based training in a rapidly evolving specialty. There are various forms of simulation available, including benchtop models, high-fidelity simulators, and virtual-reality simulators, and each requires a different method of proficiency assessment. Both open surgery and endovascular skills can be assessed and the application of successful implementation in academic vascular surgery training program is presented.",multimedia
10.1016/j.measurement.2019.01.014,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2019-03-01,sciencedirect,An analytical method for measuring the Parkinson's disease progression: A case on a Parkinson's telemonitoring dataset,https://api.elsevier.com/content/abstract/scopus_id/85060099109,"The use of machine learning techniques for early diseases diagnosis has attracted the attention of scholars worldwide. Parkinson’s Disease (PD) is one of themost common neurological and complicated diseases affecting the central nervous system. Unified Parkinson’s Disease Rating Scale (UPDRS) is widely used for tracking PD symptom progression. Motor- and Total-UPDRS are two important clinical scales of PD. The aim of this study is to predict UPDRS scores through analyzing the speech signal properties which is important in PD diagnosis. We take the advantages of ensemble learning and dimensionality reduction techniques and develop a new hybrid method to predict Total- and Motor-UPDRS. We accordingly improve the time complexity and accuracy of the PD diagnosis systems, respectively, by using Singular Value Decomposition (SVD) and ensembles of Adaptive Neuro-Fuzzy Inference System (ANFIS). We evaluate our method on a large PD dataset and present the results. The results showed that the proposed method is effective in predicting PD progression by improving the accuracy and computation time of the disease diagnosis. The method can be implemented as a medical decision support system for real-time PD diagnosis when big data from the patients is available in the medical datasets.",multimedia
10.1016/j.robot.2019.01.009,Journal,Robotics and Autonomous Systems,scopus,2019-03-01,sciencedirect,Convolutional multi-grasp detection using grasp path for RGBD images,https://api.elsevier.com/content/abstract/scopus_id/85060078029,"Generally, most grasp detection models follow the similar frameworks as that in object detection, which use the convolutional neural network to regress the grasp parameters directly. However, grasp detection and object detection are actually different, for the ground truths in object detection are unique while that in grasp detection are not exhaustive. A predicted grasp could still be applicable despite it does not coincide well with ground truth. In this paper, a novel grasp detection model is constructed to make a fairer evaluation on grasp candidate. Instead of using isolated ground truths, the grasp path is introduced to reveal the possible consequent distribution of ground truths. The grasp candidate is first mapped to grasp path, generating the mapped grasp, and the bias between them works as the estimated error for back-propagation. Experiments deployed on grasping dataset as well as real-world scenarios show that our proposed method could improve the detection accuracy. In addition, it can be well-generalized to detect unseen objects.",multimedia
10.1016/j.neucom.2018.10.063,Journal,Neurocomputing,scopus,2019-02-15,sciencedirect,Deep convolutional extreme learning machines: Filters combination and error model validation,https://api.elsevier.com/content/abstract/scopus_id/85056670642,"In recent years, deep convolutional neural network models have been increasingly used in various computer vision tasks, like plate number recognition, object recognition, automatic digit recognition, and medical applications supporting diagnosis by signals or images. A disadvantage of these networks is the long training time. It can take days to adjust weights with iterative methods based on gradient descent. This can be an obstacle in applications that need frequent training or in real time. Fast convolutional networks avoid gradient-based methods by efficiently defining filters in feature extraction and weights in classification. The issue is how to set the convolutional filter banks, since they are not learned by the backpropagation of gradients? In this work we propose a deep fast convolutional neural network based on extreme learning machine and a fixed bank of filters. We demonstrate that our model is feasible to be used in cost-effective non-specialized computer hardware, performing the training task faster than models running on GPUs. Results were generated on EMNIST dataset representing the widely studied problem of digit recognition. We provide a deep convolutional extreme learning machine (CELM) with two feature extraction stages and combinations of selected filters. For the proposed network, we find that the empirical generalization error is explained by the error model based on a theorem by Rahimi and Retch. In comparison to the state-of-the-art, the proposed network resulted in superior accuracy as well as competitive training time, even in relation to approaches that employ processing in GPUs.",multimedia
10.1016/j.gaitpost.2018.11.029,Journal,Gait and Posture,scopus,2019-02-01,sciencedirect,"Three-dimensional cameras and skeleton pose tracking for physical function assessment: A review of uses, validity, current developments and Kinect alternatives",https://api.elsevier.com/content/abstract/scopus_id/85057183966,"Background
                  Three-dimensional camera systems that integrate depth assessment with traditional two-dimensional images, such as the Microsoft Kinect, Intel Realsense, StereoLabs Zed and Orbecc, hold great promise as physical function assessment tools. When combined with point cloud and skeleton pose tracking software they can be used to assess many different aspects of physical function and anatomy. These assessments have received great interest over the past decade, and will likely receive further study as the integration of depth sensing and augmented reality smartphone cameras occurs more in everyday life.
               
                  Research Question
                  The aim of this review is to discuss how these devices work, what options are available, the best methods for performing assessments and how they can be used in the future.
               
                  Methods
                  Firstly, a review of the Microsoft Kinect devices and associated artificial intelligence, automated skeleton tracking algorithms is provided. This includes a narrative critique of the validity and clinical utility of these devices for assessing different aspects of physical function including spatiotemporal, kinematic and inverse dynamics data derived from gait and balance trials, and anatomical assessments performed using the depth sensor information. Methods for improving the accuracy of data are examined, including multiple-camera systems and sensor fusion with inertial monitoring units, model fitting, and marker tracking. Secondly, alternative hardware, including other structured light and time of flight methods, stereoscopic cameras and augmented reality leveraging smartphone and tablet cameras to perform measurements in three-dimensional space are summarised. Software options related to depth sensing cameras are then discussed, focussing on recent advances such as OpenPose and web-based methods such as PoseNet.
               
                  Results and Significance
                  The clinical and non-laboratory utility of these devices holds great promise for physical function assessment, and recent developments could strengthen their ability to provide important and impactful health-related data.",multimedia
10.1016/j.media.2018.11.003,Journal,Medical Image Analysis,scopus,2019-02-01,sciencedirect,Motion artifact recognition and quantification in coronary CT angiography using convolutional neural networks,https://api.elsevier.com/content/abstract/scopus_id/85056852038,"Excellent image quality is a primary prerequisite for diagnostic non-invasive coronary CT angiography. Artifacts due to cardiac motion may interfere with detection and diagnosis of coronary artery disease and render subsequent treatment decisions more difficult. We propose deep-learning-based measures for coronary motion artifact recognition and quantification in order to assess the diagnostic reliability and image quality of coronary CT angiography images. More specifically, the application, steering and evaluation of motion compensation algorithms can be triggered by these measures. A Coronary Motion Forward Artifact model for CT data (CoMoFACT) is developed and applied to clinical cases with excellent image quality to introduce motion artifacts using simulated motion vector fields. The data required for supervised learning is generated by the CoMoFACT from 17 prospectively ECG-triggered clinical cases with controlled motion levels on a scale of 0–10. Convolutional neural networks achieve an accuracy of 93.3% ± 1.8% for the classification task of separating motion-free from motion-perturbed coronary cross-sectional image patches. The target motion level is predicted by a corresponding regression network with a mean absolute error of 1.12 ± 0.07. Transferability and generalization capabilities are demonstrated by motion artifact measurements on eight additional CCTA cases with real motion artifacts.",multimedia
10.1016/B978-0-12-819178-1.00035-6,Book,"Precision Medicine for Investigators, Practitioners and Providers",scopus,2019-01-01,sciencedirect,Precision medicine in ophthalmology: An evolving revolution in diagnostic and therapeutic tools,https://api.elsevier.com/content/abstract/scopus_id/85093483812,"Precision medicine refers to a stratification of patients using a wide array of individual-specific data to enable precise targeting of disease subgroups with the best available diagnostic and therapeutic approaches. Within ophthalmology, this strategy is being applied successfully and is most evident in the management of the inherited diseases. This paradigm shift in provision of care is accelerated by the emergence of novel imaging technologies, robotics, and artificial intelligence, as well as emerging technologies that integrate bioinformatics data into clinically relevant knowledge. This knowledge is used in turn to develop a system capable of supporting clinical decision-making and utilization of high-precision therapeutic options in both a personalized and cost-effective way. Examples of the diverse areas making rapid progress toward full implementation of precision medicine include, but are not limited to, ocular genetic diseases, robotic surgery, virtual reality simulations, modern imaging techniques, and the role of healthcare providers.",multimedia
10.1016/B978-0-12-815503-5.00008-5,Book,Infrastructure Computer Vision,scopus,2019-01-01,sciencedirect,The future,https://api.elsevier.com/content/abstract/scopus_id/85093476644,"This chapter discusses the future of Infrastructure Computer Vision (ICV). It starts first with an overview of how ICV progressed from the early 1980s up until 2019 and the types of issues addressed given the toolsets at our disposal. The section then continues with an exploration of the current trends in ICV. We attempt to group individual efforts together into trends and provide some context on what enables them, what they make possible, and what the future of those trends might be. We eventually focus on deep learning, consumer-grade ICV applications offered by start-ups, advances in software and hardware development, the new wave of robotics, advances in multi-spectral imaging, and a general note about the cycle of trends using mixed reality as an example. The section then discusses a set of predictions on what might the future look like 10 years from now, and what drivers might facilitate or hinder the realization of those predictions.",multimedia
10.1016/B978-0-12-815956-9.00006-5,Book,Technology in Supply Chain Management and Logistics: Current Practice and Future Applications,scopus,2019-01-01,sciencedirect,Emerging technologies in the health-care supply chain,https://api.elsevier.com/content/abstract/scopus_id/85082603106,"In this chapter, the background and organization of the health-care supply chain are reviewed, and the impact of emerging technologies is described. Maturing technologies, including optimization software, sensors/telematics, cloud computing, data warehouse systems, and automated storage and retrieval, are examined. Growth technologies, including mobility, wearable devices, data analytics, and social media, are examined as they potentially relate to the health-care supply chain. Emerging technologies, including 3D printing, drone delivery, and autonomous vehicles, are presented and examples provided on their use in the health-care supply chain. Exponential technologies, including blockchain, the Internet of Things, virtual/augmented reality, and artificial intelligence, are described with respect to potential applications in the health-care supply chain. Future changes in the external environment of health care, including decentralization, new competitors, and the increased use of telemedicine, are described with respect to impacts on the health-care supply chain.",multimedia
10.1016/B978-0-12-816176-0.00045-4,Book,Handbook of Medical Image Computing and Computer Assisted Intervention,scopus,2019-01-01,sciencedirect,Challenges in computer assisted interventions,https://api.elsevier.com/content/abstract/scopus_id/85082596227,"Challenges in design, implementation, clinical evaluation, and deployment of computer assisted intervention solutions are manifold. Some of these challenges will be discussed in this chapter.
               Computer assistance in both surgical procedures and radiology interventions aim at augmenting the clinicians with the overall objective of providing better clinical outcome. Multimodal imaging, robotics, artificial intelligence, and augmented reality play a major role in computer assisted interventions. After a brief analysis of the state-of-the-art and practice in this field, we discuss the challenges in design and development, as well as translation and deployment of the technology, from research projects motivated by clinical needs to solutions routinely used within clinical setups. We also consider the required training of surgeons and the surgical team as a major component for smooth and successful translation. We present simulation as an important tool not only for the design and development of computer assisted intervention solutions but also in their fast and smooth translation into daily practice.",multimedia
10.1016/B978-0-12-815956-9.00002-8,Book,Technology in Supply Chain Management and Logistics: Current Practice and Future Applications,scopus,2019-01-01,sciencedirect,Technologies in supply chain management and logistics,https://api.elsevier.com/content/abstract/scopus_id/85082571600,"Until recently, technology has been considered an enabler for improvements in underlying supply chain and logistics operations. However, recent trends in society and business, such as mobile computing, social media, and online retailing, have significantly changed almost every aspect of the supply chain and logistics landscape. In this chapter the following technologies were found to have a pervasive role in altering this landscape:
               
                  
                     
                        •
                        Maturing technologies
                     
                     
                        •
                        Optimization software
                     
                     
                        •
                        Sensors/Telematics
                     
                     
                        •
                        Cloud computing
                     
                     
                        •
                        Data warehouse and integration
                     
                     
                        •
                        Automated storage and retrieval
                     
                     
                        •
                        Growth technologies
                     
                     
                        •
                        Mobility
                     
                     
                        •
                        Wearability
                     
                     
                        •
                        Data analytics
                     
                     
                        •
                        Social media
                     
                     
                        •
                        Emerging technologies
                     
                     
                        •
                        3D printing
                     
                     
                        •
                        Drones
                     
                     
                        •
                        Autonomous vehicles
                     
                     
                        •
                        Exponential
                     
                     
                        •
                        Blockchain
                     
                     
                        •
                        Internet of Things
                     
                     
                        •
                        Virtual reality
                     
                     
                        •
                        Machine learning
                     
                  
               
               Each of these technologies will be discussed along with videos illustrating their use.",multimedia
10.1016/B978-0-12-817358-9.00018-4,Book,"Multimodal Scene Understanding: Algorithms, Applications and Deep Learning",scopus,2019-01-01,sciencedirect,Cross-modal Learning by Hallucinating Missing Modalities in RGB-D Vision,https://api.elsevier.com/content/abstract/scopus_id/85082046476,"Diverse input data modalities can provide complementary cues for several tasks, usually leading to more robust algorithms and better performance. However, while a (training) dataset could be accurately designed to include a variety of sensory inputs, it is often the case that not all modalities are available in real life (testing) scenarios, when the model is to be deployed. This raises the challenge of how to learn robust representations leveraging multimodal data in the training stage, while considering limitations at test time, such as noisy or missing modalities. This chapter presents a new approach for multimodal video action recognition, developed within the unified frameworks of distillation and privileged information, named generalized distillation. We consider the particular case of learning representations from depth and RGB videos, while relying on RGB data only at test time. Our approach consists in training a hallucination network that learns to distill depth features through multiplicative connections of spatiotemporal representations, leveraging soft labels and hard labels, and the euclidean distance between feature maps. We report state-of-the-art or comparable results on video action recognition on the largest multimodal dataset available for this task, the NTU RGB+D, as well as on the UWA3DII and Northwestern-UCLA. Our code is available at https://github.com/ncgarcia/modality-distillation.",multimedia
10.1016/j.procs.2020.01.081,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,A Deep Neural Network Framework for Road Side Analysis and Lane Detection,https://api.elsevier.com/content/abstract/scopus_id/85081999144,"This paper presents a computer vision based framework with the aim of aiding the task of driving. The framework serves the purpose of road analysis. Road analysis is further divided into two sub-tasks. The ﬁrst task aims at recognition of the different road signs, the second task aims at lane analysis. The task of automatic driving requires humans to multitask and perform many operations in split seconds. The framework is introduced to aid this task of driving if not completely automate it while keeping in mind of using it with a simple hardware and software setup. The effectiveness of the framework lies in its feature of having minimal complexity which enables it to be used in real-time. The results of the pipeline are quantiﬁed by ﬁrst measuring its accuracy in the classiﬁcation of road signs, second measuring its ability to gather the information about the road (lane analysis and 2 vehicle detection) thirdly by performing the time bench-marking.",multimedia
10.1016/j.procs.2019.12.226,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Unsupervised Neural Network for Homography Estimation in Capsule Endoscopy Frames,https://api.elsevier.com/content/abstract/scopus_id/85079875072,"Capsule endoscopy is becoming the major medical technique for the examination of the gastrointestinal tract, and the detection of small bowel lesions. With the growth of endoscopic capsules and the lack of an appropriate tracking system to allow the localization of lesions, the need to develop software-based techniques for the localisation of the capsule at any given frame is also increasing. With this in mind, and knowing the lack of availability of labelled endoscopic datasets, this work aims to develop a unsupervised method for homography estimation in video capsule endoscopy frames, to later be applied in capsule localisation systems. The pipeline is based on an unsupervised convolutional neural network, with a VGG Net architecture, that estimates the homography between two images. The overall error, using a synthetic dataset, was evaluated through the mean average corner error, which was 34 pixels, showing great promise for the real-life application of this technique, although there is still room for the improvement of its performance.",multimedia
10.1016/j.ifacol.2019.12.110,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-01-01,sciencedirect,VR with Older Adults: Participatory Design of a Virtual ATM Training Simulation,https://api.elsevier.com/content/abstract/scopus_id/85079647308,"In this paper we report on a study conducted with a group of older adults in which they engaged in participatory design workshops to create a VR ATM training simulation. Based on observation, recordings and the developed VR application we present the results of the workshops and offer considerations and recommendations for organizing opportunities for end users, in this case older adults, to directly engage in co-creation of cutting-edge ICT solutions. These include co-designing interfaces and interaction schemes for emerging technologies like VR and AR. We discuss such aspects as user engagement and hardware and software tools suitable for participatory prototyping of VR applications. Finally, we present ideas for further research in the area of VR participatory prototyping with users of various proficiency levels, taking steps towards developing a unified framework for co-design in AR and VR.",multimedia
10.1016/j.procir.2019.03.212,Conference Proceeding,Procedia CIRP,scopus,2019-01-01,sciencedirect,Contribution to the development of a Digital Twin based on product lifecycle to support the manufacturing process,https://api.elsevier.com/content/abstract/scopus_id/85076726437,"The current manufacture challenges are closely linked to the aim of digitalizing the product, the process and the means of production. In such aspects, information about the production processes is available in real-time, allowing managers to act on digital models and, through them, apply decisions in real systems. Thus, having a mirror model or a Digital Twin enables real-time absorption, simulation and implementation of manufacturing variations from the real environment, allowing faster detection of physical problems, and faster production response. The Digital Twin is a virtual representation of the physical system, which is equipped with sensors and actuators and feed the digital system, where the monitoring of data and simulation of variations, for instance, take place. From the synchronized interactions of both components, it is possible to deliver the mentioned faster production responses. Brazilian and German universities joined efforts to develop a Digital Twin based on product lifecycle to support the Manufacturing Process to address these challenges. The proposed Digital Twin seeks to integrate the product twin and the twin of its development process. It shall represent the manufacturing process, enabling the monitoring and optimization of the real production process. The Digital Twin itself is addressed as a product inside the production system and, therefore, its development process will follow the product lifecycle perspective, from the conception and planning to its implementation and usage. The Digital Twin will be further improved with the introduction of Artificial Intelligence tools, characterizing a Smart Digital Twin of the Manufacturing Process. Thus, this paper aims to present the concepts of a research project that is being developed in a joint Brazilian-German Cooperative Research.",multimedia
10.1016/j.procs.2019.09.367,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,PPCU Sam: Open-source face recognition framework,https://api.elsevier.com/content/abstract/scopus_id/85076260223,"In recent years by the popularization of AI, an increasing number of enterprises deployed machine learning algorithms in real life settings. This trend shed light on leaking spots of the Deep Learning bubble, namely the catastrophic decrease in quality when the distribution of the test data shifts from the training data. It is of utmost importance that we treat the promises of novel algorithms with caution and discourage reporting near perfect experimental results by fine-tuning on fixed test sets and finding metrics that hide weak points of the proposed methods. To support the wider acceptance of computer vision solutions we share our findings through a case-study in which we built a face-recognition system from scratch using consumer grade devices only, collected a database of 100k images from 150 subjects and carried out extensive validation of the most prominent approaches in single-frame face recognition literature. We show that the reported worst-case score, 74.3% true-positive ratio drops below 46.8% on real data. To overcome this barrier, after careful error analysis of the single-frame baselines we propose a low complexity solution to cover the failure cases of the single-frame recognition methods which yields an increased stability in multi-frame recognition during test time. We validate the effectiveness of the proposal by an extensive survey among our users which evaluates to 89.5% true-positive ratio.",multimedia
10.1016/j.procs.2019.09.169,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,IAssistMe - Adaptable assistant for persons with eye disabilities,https://api.elsevier.com/content/abstract/scopus_id/85076257910,"Visually challenged people may experience certain difficulties in their daily interaction with technology. That is essentially because the main way to exchange and process information is by written text, images or videos. Since the basic purpose of innovation is to improve people’s lifestyle, in this paper we propose a system that can make technology accessible to a broader group. Our prototype is presented as a mobile application based on vocal interaction, which can help people facing visual disorders consult their personal agenda, create an event, invite other friends to attend it, check the weather in certain areas and many other day-to-day tasks. Regarding the implementation, the project consists of a mobile application that interacts with a cloud based system, which makes it reliable and low in latency due to the resource availability in multiple global regions, provided by the newly emerging platform used in building the infrastructure. The novelty of the system lays in the highly flexible serverless architecture [1] that is open to extension and closed to modification through the set of autonomous cloud processing methods that sustain the base of the functionality. This distributed processing approach guarantees that the user always receives a response from his personal assistant, either by using artificial intelligence context generated phrases, by real-time cloud function processing or by fallback to the training answers.",multimedia
10.1016/j.procs.2019.09.069,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,An Innovative Technology: Augmented Reality Based Information Systems,https://api.elsevier.com/content/abstract/scopus_id/85076255225,"In our generation the information systems evolve with new technologies: augmented reality (AR), IoT, artificial intelligence, blockchain etc. Anymore they perform information exchange by sensors. It is estimated that the systems will be in a state of extreme interaction and reach 50 billion devices connected in Internet in 2020. We know that everything around us will be in interaction and they will do everything without any need of human interference. For example, when our dishwasher is full, it will start to wash automatically, or when the run out of the gasoline, our car will drive to the nearest station, or even when a burglar is entered to our house, it will automatically be detected and be announced to the police office. In business life, the processes will be automatical in maximum level and this technology will increase productivity and efficiency. Next to mobile technology, it is thought that these new generation information systems (IS) will take the biggest place in our lives. AR also will be integrated to these systems to augment the information in real world. Humanity will augment its habitat in an innovative way thanks to these AR based IS. This paper surveys the current state-of-the-art AR systems related with aerospace & defense, industry, education, medical and gaming sectors. The connection of AR based IS and innovation is explained with a technological insight. In addition to international use cases HAVELSAN’s use cases are also given that are performed from the aspect of applied open innovation strategy. This strategy is addressed specific to the implemented activities of AR based IS.",multimedia
10.1016/j.entcs.2019.04.012,Journal,Electronic Notes in Theoretical Computer Science,scopus,2019-01-01,sciencedirect,An Augmented Reality Prototype for supporting IoT-based Educational Activities for Energy-efficient School Buildings,https://api.elsevier.com/content/abstract/scopus_id/85074700429,"The use of Augmented Reality (AR) technologies is currently being investigated in numerous and diverse application domains. In this work, we discuss the ways in which we are integrating AR into educational in-class activities for the GAIA project, aiming to enhance existing tools that target behavioral changes towards energy efficiency in schools. We combine real-time IoT data from a sensing infrastructure inside a fleet of school buildings with AR software running on tablets and smartphones, as companions to a set of educational lab activities aimed at promoting energy awareness in a STEM context. We also utilize this software as a means to ease access to IoT data and simplify device maintenance. We report on the design and current status of our implementation, describing functionality in the context of our target applications, while also relaying our experiences from the use of such technologies in this application domain.",multimedia
10.1016/j.procs.2019.09.007,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Increase the interest in learning by implementing augmented reality: Case studies studying rail transportation.,https://api.elsevier.com/content/abstract/scopus_id/85073117730,"Learn a subject, for some people, might be an uninteresting and boring activity, especially when the subject to learn are difficult subjects to understand. Many methods used to change learning activities become more enjoyable and interested. This study proposed a new method in learning activities, by applied augmented reality technology in the learning process. The case study used in this paper are implementation the augmented reality in studied subjects related to train technology. In this study, author implement augmented reality on learning material, combines real and virtual things in one media, in this case a mobile device. The impact of implementation of augmented studied, at the end of experiment, author can conclude when implement augmented reality technology in learning material helps the learning process and increasing the impressive and fun factor in learning process and make the learning process more interested. Implementation of Augmented Reality in learning material gives more information about the object being studied, information about on shapes, textures, and provide more visualization for the object.",multimedia
10.1016/j.procs.2019.08.230,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Enhancing game experience with facial expression recognition as dynamic balancing,https://api.elsevier.com/content/abstract/scopus_id/85073100962,"Player’s Experience in the game has been known to be one of the essential keys for the success of the game. There are several methods exist to enhance the player’s experiences in the games. One of the unexplored methods is a dynamic balancing system using Facial Expression Recognition. The player’s facial expression is captured in real-time while the player is playing the game, and the dynamic balancing system will automatically adjust the game difficulty based on the player’s facial expressions. This research aims to empirically explore the implementation of Facial Expression Recognition for a dynamic balancing system to enhance the player’s experiences in the game. Two action games (2D and 3D) were developed and evaluated with 60 respondents in two groups. Both groups played the game twice, one with facial expression recognition system as dynamic balancing activated and one without. The results demonstrate that they are statistically significant differences (i.e. improvement) between the baseline and enhanced games with p < 0.01.",multimedia
10.1016/j.procs.2019.08.164,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Self-evacuation drills by mobile virtual reality application to enhance earthquake preparedness,https://api.elsevier.com/content/abstract/scopus_id/85073095394,"Traditional evacuation drills by self-rescue practice are a common method used to educate society in communities, companies or schools in Indonesia which involving participants in large numbers. However, the participants in this approach are not always committed and doing it seriously in some cases. Besides, the participants were also unable to feel the earthquake sensation because no shaking at all when practice evacuation drills. For this reason, it is necessary to design a tool that can be used to practice by themselves with no involving many people, but the sensation of shaking can be felt by the users, one way is using Virtual Reality (VR) technology. This study aims to develop VR-based applications that can create a sensation of shaking such as an earthquake and can be used individually. The method used in this study is initial research, development, testing and analyzing, and recommendations. The development carried out by Unity 3D software which is equipped with GoogleVR plugin. The testing was conducted on 14 students of SMK Batik Batik 1 Surakarta, Indonesia, whose average age of 16 years old and the habit of playing games is 2-3 hours per day on average. From the experiments conducted, 71% stated that earthquake simulations using VR applications are more interesting than animated video, because they can interact with virtual objects directly and the simulations are more realistic. Thus, it can be concluded that the VR application can be used for earthquake evacuation exercises independently, further hope that user preparedness will be better in dealing with natural disasters, especially earthquakes",multimedia
10.1016/j.procs.2019.04.090,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Deep neural network method of recognizing the critical situations for transport systems by video images,https://api.elsevier.com/content/abstract/scopus_id/85071926362,"The deep neural network method of recognizing critical situations for transport systems according to video frames from the intelligent vehicles cameras is offered, that is effective in terms of accuracy and high-speed performance. Unlike the known solutions for the objects and normal or critical situations detection and recognition, it uses the classification with the subsequent reinforcement on the basis of several video stream frames and with the automatic annotation algorithm. The adapted architectures of neural networks are offered: the dual network to identify drivers and passengers according to the face image, the network with independent recurrent layers to classify situations according to the video fragment. The scheme of the intellectual distributed city system of transport safety using the cameras and on-board computers united in a single network is offered. Software modules in Python are developed and natural experiments are made. The possibility of the offered algorithms and programs in UGV or in the driver assistant systems implementation is shown with the illustrating examples in real-time.",multimedia
10.1016/j.promfg.2020.01.288,Conference Proceeding,Procedia Manufacturing,scopus,2019-01-01,sciencedirect,Action recognition in manufacturing assembly using multimodal sensor fusion,https://api.elsevier.com/content/abstract/scopus_id/85070765380,"Production innovations are occurring faster than ever. Manufacturing workers thus need to frequently learn new methods and skills. In fast changing, largely uncertain production systems, manufacturers with the ability to comprehend workers’ behavior and assess their operation performance in near real-time will achieve better performance than peers. Action recognition can serve this purpose. Despite that human action recognition has been an active field of study in machine learning, limited work has been done for recognizing worker actions in performing manufacturing tasks that involve complex, intricate operations. Using data captured by one sensor or a single type of sensor to recognize those actions lacks reliability. The limitation can be surpassed by sensor fusion at data, feature, and decision levels. This paper presents a study that developed a multimodal sensor system and used sensor fusion methods to enhance the reliability of action recognition. One step in assembling a Bukito 3D printer, which composed of a sequence of 7 actions, was used to illustrate and assess the proposed method. Two wearable sensors namely Myo-armband captured both Inertial Measurement Unit (IMU) and electromyography (EMG) signals of assembly workers. Microsoft Kinect, a vision based sensor, simultaneously tracked predefined skeleton joints of them. The collected IMU, EMG, and skeleton data were respectively used to train five individual Convolutional Neural Network (CNN) models. Then, various fusion methods were implemented to integrate the prediction results of independent models to yield the final prediction. Reasons for achieving better performance using sensor fusion were identified from this study.",multimedia
10.1016/bs.adcom.2019.02.004,Book Series,Advances in Computers,scopus,2019-01-01,sciencedirect,SSIM and ML based QoE enhancement approach in SDN context,https://api.elsevier.com/content/abstract/scopus_id/85063000805,"Today, video streaming rose above all other traffic types over the internet. While providing this service with a high quality is the most challenging task, researchers are trying to solve the challenge by giving a more efficient network where congestion, broadband limitations and unsatisfied users are limited. In new multimedia based networks, new challenges move from technology-oriented services to user-oriented services which prove the importance of QoE. Service providers' growth depends nowadays not only on QoS parameters but also on clients' feeling and expectation. That is why; service providers must measure received QoE and this becomes a challenge regarding the evaluation of users' feeling. For users, qualitative perception differs from one user to another and service providers affront difficulties to transform the qualitative values into the quantitative one. The QoE evaluation needs more sophisticated methods to describe the real expectation of users. New multimedia applications provide at any user locations media who are sharing video, and communicating together in virtual network. These applications require providing the best possible QoE to consumers. When it comes to us, we present in this paper a machine learning approach combined with adaptive coding in order to provide a better QoE for video streaming services. This solution will be established using SDN architecture. We can justify this choice because we need a centralized architecture, where the totality of the network is known, to predict its status. So, we will implement a machine learning algorithm in the controller: this algorithm, called ML-based SSIM, will calculate approximately the quality needed for a video to be streamed. Finally, the quality found by the ML-based SSIM Algorithm will be combined with the network situation to choose the right coding. First part of the paper deals with an introduction of QoE requirement, metrics and protocols used especially in streaming services, then we give a complete study around Machine learning algorithms and other fields used in literature to enhance QoE. We define in this paper, at first, QoS and QoE, then the serving environment such as mobile cloud computing and software Defined Network (SDN). Then, we give both objective and subjective metrics, expose mathematical approaches used in modeling, predicting and evaluating QoE. Second, we expose the SSIM approach and explain how our proposed one is based on. The last part of the paper deals with experiments: we describe SDN environment deployment, describe scenarios and finally simulate on SDN emulator some topologies to demonstrate the impact of SDN components helping QoE measurement. At the end, we give the results and values. We highlight the future of our proposition.",multimedia
10.1016/j.imu.2018.12.002,Journal,Informatics in Medicine Unlocked,scopus,2019-01-01,sciencedirect,Implementation of a TCM-based computational health informatics diagnostic tool for Sub-Saharan African students,https://api.elsevier.com/content/abstract/scopus_id/85058678042,"Health status checkup is a crucial step towards early detection of diseases. Health status diagnosis, in university health centers, within the sub-Saharan African region, can be cumbersome and time consuming. In many cases, facilities for health checkup are not available. Traditional Chinese Medicine (TCM) is a promising approach, when integrated with in-silico methods. This study was conducted to implement a TCM-based computational health informatics diagnostic tool. The tool was applied to diagnose African students. This study was also conducted to stimulate further research into in-silico TCM diagnostics. Besides developing a reliable biometric verification system, to ascertain the real identities of patients brought to university health centers, it is assistive to create a platform that provides automated and complementary support for preliminary health diagnostic activities. It also mitigates stress, by helping to efficiently decipher and provide quick objective opinion from the perspective of a computerized decision support system. The diagnostic module of the computational health informatics diagnostic tool adopts knowledge from a TCM facial color diagnosis.
                  A comprehensive literature search was conducted for relevant full-text research papers. Only research publications written in English language were reviewed. The present work was compared qualitatively and quantitatively with the existing works noted in the literature. Facial detection and matching algorithms were implemented for the TCM-based computational health informatics diagnostic tool by using Java programming language. Facial image acquisition processes were conducted. Captured facial images of African students were preprocessed. Facial feature extraction was performed by implementing feature extraction algorithms. An algorithm for the extraction of color information and measurement was also implemented. Knowledge of machine learning was applied to extract and collate facial features, and to machine learn from them. Facial classification and recognition algorithms were implemented. Finally, the results from the computational health informatics diagnostic tool were evaluated, by conducting a performance evaluation and validation.
                  This study provides qualitative and quantitative information on facial recognition, facial color information measurement, as well as prediction of health status, for some sub-Saharan African University students. Performance evaluation was shown using confusion matrix and ROC curves. Statistical analysis of the experimental results was presented. The parameters in each diagnostic illustration were shown with valid range. In order to justify the effectiveness of the computational tool, further explanations were provided from relevant methodology guides on the evaluation of diagnostic tests.
                  The computational health informatics diagnostic tool will complement the diagnostic efforts in university health centers of sub-Saharan African universities. It will also be useful for personal health diagnosis of interested individuals. The tool will also be viable for educating health professionals. TCM will be of immense benefit to developing countries by positively contributing towards diagnosing different non-communicable diseases and some infectious diseases in such countries.",multimedia
10.1016/j.smhl.2018.07.008,Journal,Smart Health,scopus,2018-12-01,sciencedirect,Are you smoking? Automatic alert system helping people keep away from cigarettes,https://api.elsevier.com/content/abstract/scopus_id/85059789843,"Tobacco smoking is responsible for one out of every five deaths in the US, according to the Centers for Disease Control and Prevention (CDC). Recent advances in treatment delivery include technology-based mobile health approaches, which seek to deliver real-time feedback to smokers to aid quit attempts and mitigate lapses. With regard to the measurement of smoking, clinical trials rely on participant self-report and/or biochemical verification of smoking status to evaluate outcomes. Wearable sensors have the potential to improve current approaches by providing personalized feedback and objective verification of smoking status (Burns, 2000). In this paper, we describe the development of a novel smoking cessation system that combines motion detection and an Android software application to monitor smoking in real-time. In this system, a personalized smoking cessation plan will be created based on the goal of complete cessation or smoking reduction. Once the plan is created, the mobile system will monitor the users׳ smoking activity and provide feedback. An LSTM algorithm has been computed to train and test the motion data, which was collected from two armbands, to detect smoking and non-smoking motions. The internet message service will be used to remind users to stick to their plan when the sensor detects current smoking. Related video links are pushed and pulled to the users via Short Message Service (SMS) to support smoking cessation. Findings have implications for tobacco cessation treatment delivery and assessment of smoking status.",multimedia
10.1016/j.cag.2018.10.004,Journal,Computers and Graphics (Pergamon),scopus,2018-12-01,sciencedirect,Simulating complex social behaviours of virtual agents through case-based planning,https://api.elsevier.com/content/abstract/scopus_id/85055350464,"In commercial video games and simulations, non-player characters are capable of quite complex behaviour. Very often though, each class of non-player characters (that we further call virtual agents) is manually programmed or scripted. This means that instead of possessing some level of intelligence, allowing the agent to decide dynamically on the actions it needs to perform, we supply the agent with a list of possible situations that may arise in the game. For each such situation, we give the agent a pre-programmed script that tells it how to behave. Producing such scripts for every role an agent might play in a game or simulation is a very costly exercise. This may be acceptable in commercial game development, where budgets for modern games are sometimes comparable to budgets of Hollywood movies, but not adequate for research simulations and indie games. In this paper, we discuss how indie games and research simulations can be enriched with the sophisticated social behaviour of virtual agents in a semi-automatic manner through the use of AI planning. By supplying agents with roles and developing a computational model of their needs, we can use AI planning (also known as dynamic planning) to increase the complexity of agent behaviour dramatically and at the same time achieve a high degree of automation and reduce the development costs. AI planning is gaining popularity in games development, but it is often discarded due to performance issues. We will show how to improve the performance of planning process through the use of dynamic institutions and case-based planning. We will illustrate the aforementioned ideas on an example of developing a Virtual Reality simulation of everyday life in Ancient Mesopotamia.",multimedia
10.1016/j.ijhcs.2018.06.005,Journal,International Journal of Human Computer Studies,scopus,2018-12-01,sciencedirect,Reasoning about ideal interruptible moments: A soft computing implementation of an interruption classifier in free-form task environments,https://api.elsevier.com/content/abstract/scopus_id/85051663528,"Current trends in society and technology make the concept of interruption a central human computer interaction problem. In this work, a novel soft computing implementation for an Interruption Classifier was designed, developed and evaluated that draws from a user model and real-time observations of the user's actions as s/he works on computer-based tasks to determine ideal times to interact with the user. This research is timely as the number of interruptions people experience daily has grown considerably over the last decade. Thus, systems are needed to manage interruptions by reasoning about ideal timings of interactions.
                  This research shows: (1) the classifier incorporates a user model in its’ reasoning process. Most of the research in this area has focused on task-based contextual information when designing systems that reason about interruptions; (2) the classifier performed at 96% accuracy in experimental test scenarios and significantly outperformed other comparable systems; (3) the classifier is implemented using an advanced machine learning technology—an Adaptive Neural-Fuzzy Inference System—this is unique since all other systems use Bayesian Networks or other machine learning tools; (4) the classifier does not require any direct user involvement—in other systems, users must provide interruption annotations while reviewing video sessions so the system can learn; and (5) a promising direction for reasoning about interruptions for free-form tasks–this is largely an unsolved problem.",multimedia
10.1016/j.future.2018.07.013,Journal,Future Generation Computer Systems,scopus,2018-12-01,sciencedirect,Using behavioral features in tablet-based auditory emotion recognition studies,https://api.elsevier.com/content/abstract/scopus_id/85050510126,"The recognition of emotions in spoken words is one of the most important aspects in human communication and social relationships. Traditional approaches to the study of vocal emotional recognition involve instructing listeners to choose which one of several words describing emotion categories best characterize linguistically neutral utterances or vocalizations uttered by actors portraying various emotional states. To this end, generic experiment control software is usually used, which has some disadvantages. In this paper, we present a system that digitalizes the whole process involved in understanding how people perceive and understand vocal emotions, improving data collection, processing and analysis. Moreover, this system provides a new group of features that allows a more comprehensive characterization of the behavioral dimension underlying vocal emotional recognition. In this paper we describe this system and analyze the relationship between emotional perception, gender, age and Human–Computer Interaction.",multimedia
10.1016/j.neucom.2018.08.042,Journal,Neurocomputing,scopus,2018-11-27,sciencedirect,3D separable convolutional neural network for dynamic hand gesture recognition,https://api.elsevier.com/content/abstract/scopus_id/85053021009,"Dynamic hand gesture recognition, as an essential part of Human–Computer Interaction, and especially an important way to realize Augmented Reality, has been attracting attention from many scholars and yet presenting many more challenges. Recently, being aware of deep convolutional neural network's excellent performance, many scholars began to apply it to gesture recognition, and obtained promising results. However, no enough attention has been paid to the number of parameters in the network and the amount of computer calculation needed until now. In this paper, a 3D separable convolutional neural network is proposed for dynamic gesture recognition. This study aims to make the model less complex without compromising its high recognition accuracy, such that it can be deployed to augmented reality glasses more easily in the future. By the application of skip connection and layer-wise learning rate, the undesired gradient dispersion due to the separation operation is solved and the performance of the network is improved. The fusion of feature information is further promoted by shuffle operation. In addition, a dynamic hand gesture library is built through HoloLens, which thus proves the feasibility of the proposed method.",multimedia
10.1016/j.neucom.2018.08.009,Journal,Neurocomputing,scopus,2018-11-17,sciencedirect,Evaluation of deep neural networks for traffic sign detection systems,https://api.elsevier.com/content/abstract/scopus_id/85052108235,"Traffic sign detection systems constitute a key component in trending real-world applications, such as autonomous driving, and driver safety and assistance. This paper analyses the state-of-the-art of several object-detection systems (Faster R-CNN, R-FCN, SSD, and YOLO V2) combined with various feature extractors (Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19) previously developed by their corresponding authors. We aim to explore the properties of these object-detection models which are modified and specifically adapted to the traffic sign detection problem domain by means of transfer learning. In particular, various publicly available object-detection models that were pre-trained on the Microsoft COCO dataset are fine-tuned on the German Traffic Sign Detection Benchmark dataset. The evaluation and comparison of these models include key metrics, such as the mean average precision (mAP), memory allocation, running time, number of floating point operations, number of parameters of the model, and the effect of traffic sign image sizes. Our findings show that Faster R-CNN Inception Resnet V2 obtains the best mAP, while R-FCN Resnet 101 strikes the best trade-off between accuracy and execution time. YOLO V2 and SSD Mobilenet merit a special mention, in that the former achieves competitive accuracy results and is the second fastest detector, while the latter, is the fastest and the lightest model in terms of memory consumption, making it an optimal choice for deployment in mobile and embedded devices.",multimedia
10.1016/B978-0-12-814601-9.00020-1,Book,Multimodal Behavior Analysis in the Wild: Advances and Challenges.,scopus,2018-11-16,sciencedirect,Wearable systems for improving tourist experience,https://api.elsevier.com/content/abstract/scopus_id/85072183737,"In this chapter we present original approaches for the development of a smart audio-guide that adapts to the actions and interests of visitors of cultural heritage sites and exhibitions either in indoor or outdoor scenarios. The guide is capable of perceiving the context. It understands what the user is looking at, if he is moving or is inattentive (e.g. talking with someone), in order to provide relevant information at the appropriate timing. Automatic recognition of artworks is performed with different approaches depending on the scenario, i.e. indoor and outdoor. These approaches are, respectively, based on Convolutional Neural Network (CNN) and SIFT descriptors, performing, when appropriate, object localization and classification. The computer-vision system works in real time on the mobile device, exploiting also a fusion of audio and motion sensors. Configurable interfaces to ease interaction and fruition of multimedia insights are provided for both scenarios. The audio-guide has been deployed on a NVIDIA Jetson TX1 and a NVIDIA Shield Tablet K1, tested in a real world environment (Bargello Museum of Florence and the historical city center of Florence), and evaluated with regard to system usability.",multimedia
10.1016/j.cmpb.2018.10.006,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-11-01,sciencedirect,Automated detection and classification of liver fibrosis stages using contourlet transform and nonlinear features,https://api.elsevier.com/content/abstract/scopus_id/85054743325,"Background and objective
                  Liver fibrosis is a type of chronic liver injury that is characterized by an excessive deposition of extracellular matrix protein. Early detection of liver fibrosis may prevent further growth toward liver cirrhosis and hepatocellular carcinoma. In the past, the only method to assess liver fibrosis was through biopsy, but this examination is invasive, expensive, prone to sampling errors, and may cause complications such as bleeding. Ultrasound-based elastography is a promising tool to measure tissue elasticity in real time; however, this technology requires an upgrade of the ultrasound system and software. In this study, a novel computer-aided diagnosis tool is proposed to automatically detect and classify the various stages of liver fibrosis based upon conventional B-mode ultrasound images.
               
                  Methods
                  The proposed method uses a 2D contourlet transform and a set of texture features that are efficiently extracted from the transformed image. Then, the combination of a kernel discriminant analysis (KDA)-based feature reduction technique and analysis of variance (ANOVA)-based feature ranking technique was used, and the images were then classified into various stages of liver fibrosis.
               
                  Results
                  Our 2D contourlet transform and texture feature analysis approach achieved a 91.46% accuracy using only four features input to the probabilistic neural network classifier, to classify the five stages of liver fibrosis. It also achieved a 92.16% sensitivity and 88.92% specificity for the same model. The evaluation was done on a database of 762 ultrasound images belonging to five different stages of liver fibrosis.
               
                  Conclusions
                  The findings suggest that the proposed method can be useful to automatically detect and classify liver fibrosis, which would greatly assist clinicians in making an accurate diagnosis.",multimedia
10.1016/j.mechatronics.2018.08.011,Journal,Mechatronics,scopus,2018-11-01,sciencedirect,An interactive and intuitive control interface for a tele-operated robot (AVATAR) system,https://api.elsevier.com/content/abstract/scopus_id/85053070319,"Robotic systems, which are controlled by artificial intelligent or tele-operation control interfaces, have been developed to be deployed instead of the human in extreme environments. However, insufficient artificial intelligence performance in unknown and unpredictable environments, and non-intuitive control interfaces with low immersive feedback have prevented wide spread of such robotic systems. In this paper, an intuitive and interactive control interface with inertial measurement units (IMUs), haptic gloves and a head mounted display (HMD) was developed to control a tele-operated robot in remote environments, which was abbreviated as AVATAR system. The tele-operated robot can be operated by a user’s motions which are measured by the wearable interface. Through a kinematic analysis of the user and the tele-operated robot, desired robot joint angles are calculated to follow the user’s motions in real time. Also, dual cameras on the robot head provide 3D visual information around the robot to the user. A grasping force of the robot hands, measured by motor current, is transmitted to the user as vibration feedback to fingertips of the haptic gloves. A long term evolution (LTE) was used as wireless communication between the user and the robot. The performance of the proposed AVATAR system has been verified by experiments.",multimedia
10.1016/j.asoc.2018.07.052,Journal,Applied Soft Computing Journal,scopus,2018-11-01,sciencedirect,An experimental evaluation of weightless neural networks for multi-class classification,https://api.elsevier.com/content/abstract/scopus_id/85052139837,"WiSARD belongs to the class of weightless neural networks, and it is based on a neural model which uses lookup tables to store the function computed by each neuron rather than storing it in weights of neuron connections. WiSARD is characterised by a simple implementation and a fast learning phase due to one-way RAM access/lookup mechanism. WiSARD was originally conceived as a pattern recognition device mainly focusing on image processing. In this work we present a multi-class classification method in machine learning domain based on WiSARD, called WiSARD Classifier. The method uses the same binary encoding scheme to transform multivariable data in the domain of real numbers into binary patterns which are the input to WiSARD. The main contribution of this work is an extensive experimental evaluation of WiSARD's classification capability in comparison to methods from the state-of-the-art. For the purpose we conducted many experiments applying nine well known machine learning methods (including the WiSARD Classifier) to seventy classification problems. Cross-validation accuracies were collected and compared by means of a statistical analysis based on nonparametric tests (Friedman, Friedman Aligned Rank, and Quade test) to prove how the WiSARD Classifier is very close in performance to the best methods available in most popular machine learning libraries.",multimedia
10.1016/j.measurement.2018.05.099,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2018-11-01,sciencedirect,Parallel three-dimensional electrical capacitance data imaging using a nonlinear inversion algorithm and L<sup>p</sup> norm-based model regularization,https://api.elsevier.com/content/abstract/scopus_id/85049483981,"In order to improve image reconstructions, different classes of nonlinear inversion algorithms are developed and used in different research topics like imaging processes in oil industry or the characterization of complex porous media or multiphase flows. These algorithms are able to avoid local minima and to reach more adapted minima of a given misfit function between observed/measured and computed data. Techniques as different as electrical, ultrasound or potential methods, are used. We present here a nonlinear algorithm that allows us to produce permittivity images by using electrical capacitance tomography (ECT). ECT is a non-invasive technique to image non-conductive permittivity distributions and is used in many oil industry imaging applications such as multiphase flows in pipelines, fluidized bed reactors, mixing vessels, and tanks of phase separation. Even if the ECT technique provides low resolution reconstructions, it is cheap, robust and very fast when compared to other imaging tools. In this method one or more rings of electrodes excite a medium to be imaged at high frequencies, and more particularly at frequencies for which a static electrical potential field has fully developed. In many studies of other research groups only one ring of sources is introduced but the reconstruction accuracy was not totally satisfactory due to the 3D nature of the problem to be solved. Instead of using nonlinear stochastic algorithms like the simulated annealing (SA) technique that we optimized in previous studies to image permittivity distributions of granular or solid materials as well as real oil–gas or two-phase flows in 2D cylindrical vessel configurations, we propose here a new ECT inversion tool to image permittivities in a 3D cylindrical configuration. 3D stochastic optimization methods such as SA, neural networks, genetic algorithms can become computationally too prohibitive, and classical local or linear inversion methods excessively smooth images in many cases. Therefore, we propose here a 3D parallel inversion procedure with different numbers of rings and different 
                        
                           
                              
                                 L
                              
                              
                                 p
                              
                           
                        
                      norms, with
                        
                           1
                           <
                           p
                           ⩽
                           2
                        
                     , applied to the model regularization of the misfit function to increase the resolution of the models after inversion. We are able to better reconstruct two-phase and three-phase (oil, gas and solids) mixtures by combining 
                        
                           
                              
                                 L
                              
                              
                                 p
                              
                           
                        
                     -norm regularizations of the misfit function to minimize and several rings of electrodes. All these algorithms have been implemented in a more general parallel framework TOMOFAST-X designed for multi-physics joint inversion purposes, and could also be used in other fields of research such as larger-scale geophysical exploration for instance.",multimedia
10.1016/j.jmgm.2018.07.007,Journal,Journal of Molecular Graphics and Modelling,scopus,2018-10-01,sciencedirect,Proposing novel TNFα direct inhibitor Scaffolds using fragment-docking based e-pharmacophore modeling and binary QSAR-based virtual screening protocols pipeline,https://api.elsevier.com/content/abstract/scopus_id/85052113589,"Tumor necrosis factor alpha (TNFα) is a homotrimer protein that plays a pivotal role for critical immune functions, including infection, inflammation and antitumor responses. It also plays a primary role in autoimmune diseases like rheumatoid arthritis (RA). So far, only biological therapeutics like infliximab, etanercept, and adalimumab are available as treatment of inflammatory diseases. They directly bind to TNFα and interrupt its binding to its receptor protein tumor necrosis factor receptor (TNFR). However, they may also cause serious side effects such as activating an autoimmune anti-antibody response or the weakening of the body's immune defenses. Thus, small molecule-based therapies can be considered as alternative methods. In this study, a novel method is applied to develop energetically optimized, structure-based pharmacophore models for rapid in silico drug screening. Fragment-based docking results were used in the construction of an universal e-pharmacophore model development. The developed model is then used for screening of small-molecule library Specs-screening compounds (Specs-SC) which includes more than 200.000 drug-like molecules. In another approach, binary QSAR-based models were used to screen Specs-SC, as well as Specs-natural products (NP) which has around 750 compounds, and a library of drugs registered or approved for use in humans NIH's NCGC pharmaceutical collection (NPC) which has around 7500 molecules. The MetaCore/MetaDrug platform was used for binary QSAR models for therapeutic activity prediction as well as pharmacokinetic and toxicity profile predictions of screening molecules. This platform is constructed based on a manually curated database of molecular interactions, molecular pathways, gene-disease associations, chemical metabolism, and toxicity information. Molecular docking and molecular dynamics (MD) simulations were performed for the selected hit molecules. As target protein, both homodimer and homotrimer forms of TNFα were considered. The screening results showed that indinavir and medroxalol from NPC chemical library and a set of compounds (AT-057/43115940, AP-970/42897107, AK-968/41925665, AI-204/31679053, AN-648/41666950, AN-698/42006940) from Specs-SC database were identified as safe and active direct inhibitors of TNFα.",multimedia
10.1016/j.cmpb.2018.08.005,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-10-01,sciencedirect,Fast unsupervised nuclear segmentation and classification scheme for automatic allred cancer scoring in immunohistochemical breast tissue images,https://api.elsevier.com/content/abstract/scopus_id/85051670704,"Background and objective
                  This paper presents an improved scheme able to perform accurate segmentation and classification of cancer nuclei in immunohistochemical (IHC) breast tissue images in order to provide quantitative evaluation of estrogen or progesterone (ER/PR) receptor status that will assist pathologists in cancer diagnostic process.
               
                  Methods
                  The proposed segmentation method is based on adaptive local thresholding and an enhanced morphological procedure, which are applied to extract all stained nuclei regions and to split overlapping nuclei. In fact, a new segmentation approach is presented here for cell nuclei detection from the IHC image using a modified Laplacian filter and an improved watershed algorithm. Stromal cells are then removed from the segmented image using an adaptive criterion in order to get fast tumor nuclei recognition. Finally, unsupervised classification of cancer nuclei is obtained by the combination of four common color separation techniques for a subsequent Allred cancer scoring.
               
                  Results
                  Experimental results on various IHC tissue images of different cancer affected patients, demonstrate the effectiveness of the proposed scheme when compared to the manual scoring of pathological experts. A statistical analysis is performed on the whole image database between immuno-score of manual and automatic method, and compared with the scores that have reached using other state-of-art segmentation and classification strategies. According to the performance evaluation, we recorded more than 98% for both accuracy of detected nuclei and image cancer scoring over the truths provided by experienced pathologists which shows the best correlation with the expert's score (Pearson's correlation coefficient = 0.993, p-value < 0.005) and the lowest computational total time of 72.3 s/image (±1.9) compared to recent studied methods.
               
                  Conclusions
                  The proposed scheme can be easily applied for any histopathological diagnostic process that needs stained nuclear quantification and cancer grading. Moreover, the reduced processing time and manual interactions of our procedure can facilitate its implementation in a real-time device to construct a fully online evaluation system of IHC tissue images.",multimedia
10.1016/j.bica.2018.07.020,Journal,Biologically Inspired Cognitive Architectures,scopus,2018-10-01,sciencedirect,CIT: Integrated cognitive computing and cognitive agent technologies based cognitive architecture for human-like functionality in artificial systems,https://api.elsevier.com/content/abstract/scopus_id/85051344596,"The paper proposes a novel cognitive architecture that combines cognitive computing and cognitive agent technologies for performing human-like functionality. The system architecture is known as CIT (Cognitive Information Technology). This design takes advantage of cognitive computing to handle Experiential Information (EI) using audio processing, computer vision, natural language processing, text mining, and data mining techniques. The CIT architecture includes human like cognitive agent functionality comprising attention, learning, memory, action selection, and action to handle human like individual and distributed knowledge bases to create rational decisions. The work shows CIT architecture practical implementation through “CIT framework” developed in C# and python language. For validating the system performance, the paper shows CIT based Object Recognition and Question Answering System. This framework is anticipated to advance the quality of artificial intelligent agent based decision-making using human like perception, comprehend and action skills, reducing real world business errors and assuring the correct, accurate, knowledgeable and well-timed human like decisions.",multimedia
10.1016/j.bspc.2018.07.004,Journal,Biomedical Signal Processing and Control,scopus,2018-09-01,sciencedirect,A robust audio classification system for detecting pulmonary edema,https://api.elsevier.com/content/abstract/scopus_id/85049952111,"In this paper we present a robust audio classification system to efficiently detect pulmonary edema. The system uses a feature learning technique based on (NMF), then classified with logistic regression. A study was done to compare feature engineering approaches with feature selection techniques against NMF. Different NMF schemes were investigated and also compared with Principal Component Analysis. NMF scored 95% F1 score, which was superior to feature engineering techniques that had scores from 83% to 93%. Background noise collected from hospitals and speech from a speech corpus database was used to simulate noisy data. The system was then tested using noisy data. The best NMF scheme scored 74%, while other feature engineering techniques scored lower; from 66% to 71%. NMF was also used as a signal enhancement tool. It improved the F1 score to 77%. Lastly, only inhalations from breath sounds were considered and this further improved classification results to 86%. The proposed robust classification system using NMF thus proved to be an effective method for audio-based detection of pulmonary edema. If implemented in real-time, the proposed system can be used as a screening tool.",multimedia
10.1016/j.ergon.2018.06.005,Journal,International Journal of Industrial Ergonomics,scopus,2018-09-01,sciencedirect,Artificial intelligence models for predicting the performance of hydro-pneumatic suspension struts in large capacity dump trucks,https://api.elsevier.com/content/abstract/scopus_id/85049336711,"Large dump trucks are being matched with large shovels to achieve bulk economic production in surface mining operations. This process results in high impact shovel loading operations (HISLO) and exposes operators to severe levels of whole-body vibrations (WBV). The performance of the hydro-pneumatic suspension struts, responsible for vibration attenuation in large dump trucks, decreases as a truck age. There is a need for a system for monitoring and predicting the performance of the suspension struts in real time. Artificial intelligence (AI) has been applied for modeling and predicting the suspension system performance for light/smaller vehicles. However, no work has been done to implement AI for modeling and predicting the performance of hydro-pneumatic struts in large dump trucks. This paper is a pioneering effort towards developing AI models for solving this problem. These AI models would incorporate the Artificial Neural Networks (ANN), Mamdani Fuzzy Logic (MFL) and a hybrid system, the Hybrid Neural Fuzzy Interference System (HyFIS), for achieving this goal. Experiments were conducted using a 3D virtual simulator for the CAT 793D in MSC.ADMAS. RMS accelerations in the vertical and horizontal directions at the operator seat were recorded as the two main outputs for the suspension system performance. Eighty percent (80%) of the total experimental data was used in training and developing the models and the remaining 20% for testing and validating the developed models. With an R2 and RMSE of 0.98168505 and 0.00852251 for the training phase, respectively, and 0.9660429 and 0.0195620 for the testing phase, HyFIS model showed the best accuracy for predicting the hydro-pneumatic suspension struts performance for dump trucks. This is the first time that AI models have been developed for dump truck suspension system performance prediction. With the implementation of these models in the dump truck, maintenance personnel can monitor the performance of the suspension system in real-time and schedule proper maintenance and/or replacement. Implementation of such a system will improve the workplace safety, operator's health and the overall system efficiency.",multimedia
10.1016/j.cmpb.2018.06.002,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-09-01,sciencedirect,Fuzzy decision support systems to diagnose musculoskeletal disorders: A systematic literature review,https://api.elsevier.com/content/abstract/scopus_id/85048589929,"Background and objective
                  Musculoskeletal disorders (MSDs) are one of the most important causes of disability with a high prevalence. The accurate and timely diagnosis of these disorders is often difficult. Clinical decision support systems (CDSSs) can help physicians to diagnose diseases quickly and accurately. Given the ambiguous nature of MSDs, fuzzy logic can be helpful in designing the CDSSs knowledge bases. The present study aimed to review the studies on fuzzy CDSSs to diagnose MSDs.
               
                  Methods
                  A comprehensive search was conducted in Medline, Scopus, Cochrane Library, and ISI Web of Science databases to identify relevant studies published until March 15, 2016. Studies were included in which CDSSs were developed using fuzzy logic to diagnose MSDs, and tested their accuracy using real data from patients.
               
                  Results
                  Of the 3188 papers examined, 23 papers included according to the inclusion criteria. The results showed that among all the designed CDSSs only one (CADIAG-2) was implemented in the clinical environment. In about half of the included studies (52%), CDSSs were designed to diagnose inflammatory/infectious disorder of the bone and joint. In most of the included studies (70%), the knowledge was extracted using a combination of three methods (acquiring from experts, analyzing the data, and reviewing the literature). The median accuracy of fuzzy rule-based CDSSs was 91% and it was 90% for other fuzzy models. The most frequently used membership functions were triangular and trapezoidal functions, and the most used method for inference was the Mamdani.
               
                  Conclusions
                  In general, fuzzy CDSSs have a high accuracy to diagnose MSDs. Despite the high accuracy, these systems have been used to a limited extent in the clinical environments. To design of knowledge base for CDSSs to diagnose MSDs, rule-based methods are used more than other fuzzy methods.",multimedia
10.1016/j.jvcir.2018.08.013,Journal,Journal of Visual Communication and Image Representation,scopus,2018-08-01,sciencedirect,Object detection from dynamic scene using joint background modeling and fast deep learning classification,https://api.elsevier.com/content/abstract/scopus_id/85052235817,"In this paper, we couple effective dynamic background modeling with fast deep learning classification to develop an accurate scheme for human-animal detection from camera-trap images with cluttered moving objects. We introduce a new block-wise background model, named as Minimum Feature Difference (MFD), to model the variation of the background of the camera-trap sequences and generate the foreground object proposals. We then develop a region proposals verification to reduce the number of false alarms. Finally, we perform complexity-accuracy analysis of DCNN to construct a fast deep learning classification scheme to classify these region proposals into three categories: human, animals, and background patches. The optimized DCNN is able to maintain high level of accuracy while reducing the computational complexity by 14 times, which allows near real-time implementation of the proposed method on CPU machines. Our experimental results demonstrate that the proposed method outperforms existing methods on our and Alexander von Humboldt Institute camera-trap datasets in both foreground segmentation and object detection.",multimedia
10.1016/j.bica.2018.07.016,Journal,Biologically Inspired Cognitive Architectures,scopus,2018-08-01,sciencedirect,Knowledge acquisition through introspection in Human-Robot Cooperation,https://api.elsevier.com/content/abstract/scopus_id/85051216556,"When cooperating with a team including humans, robots have to understand and update semantic information concerning the state of the environment. The run-time evaluation and acquisition of new concepts fall in the critical mass learning. It is a cognitive skill that enables the robot to show environmental awareness to complete its tasks successfully. A kind of self-consciousness emerges: the robot activates the introspective mental processes inferring if it owns a domain concept or not, and correctly blends the conceptual meaning of new entities. Many works attempt to simulate human brain functions leading to neural network implementation of consciousness; regrettably, some of these produce accurate model that however do not provide means for creating virtual agents able to interact with a human in a teamwork in a human-like fashion, hence including aspects such as self-conscious abilities, trust, emotions and motivations. We propose a method that, based on a cognitive architecture for human-robot teaming interaction, endows a robot with the ability to model its knowledge about the environment it is interacting with and to acquire new knowledge when it occurs.",multimedia
10.1016/j.cmpb.2018.05.019,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-08-01,sciencedirect,How the gender of a victim character in a virtual scenario created to learn CPR protocol affects student nurses’ performance,https://api.elsevier.com/content/abstract/scopus_id/85047645444,"Background and objective
                  Virtual simulations recreate scenarios where student nurses can practice procedures in a safe and supervised manner and with no risk to the patient. Virtual scenarios include digital characters that reproduce human actions. Generally, these characters are modeled as males and restricted roles are assigned to females. Our objective is to evaluate how the character gender of a victim in a scenario created to practice the cardiopulmonary resuscitation protocol (CPR) affects performance of student nurses.
               
                  Methods
                  Three virtual scenarios with cardiac arrest victims modeled as males or females were assigned to 41 students of the Nursing Faculty to practice the CPR protocol. We evaluated student performance with respect to the time to remove clothes, the time to perform the CPR maneuver, and the hands position for CPR. Chi-square, Fisher exact, and Mann–Whitney U were used to test primary outcome measures in the experimental design of victim character sex (male vs. female) and student sex (men vs. women).
               
                  Results
                  The analysis performed did not find statistically differences in time to remove clothes or in time to start CPR. With respect to hands placement we also did not find significant difference in any of the cases.
               
                  Conclusion
                  Nurse student actions are not influenced by the character gender of the victim. Excellent results with respect to hands placement to start CPR are obtained. Virtual scenarios can be a suitable strategy to reduce gender differences in gender sensitive situations such as CPR performance.",multimedia
10.1016/j.media.2018.04.004,Journal,Medical Image Analysis,scopus,2018-07-01,sciencedirect,VP-Nets: Efficient automatic localization of key brain structures in 3D fetal neurosonography,https://api.elsevier.com/content/abstract/scopus_id/85046367108,"Three-dimensional (3D) fetal neurosonography is used clinically to detect cerebral abnormalities and to assess growth in the developing brain. However, manual identification of key brain structures in 3D ultrasound images requires expertise to perform and even then is tedious. Inspired by how sonographers view and interact with volumes during real-time clinical scanning, we propose an efficient automatic method to simultaneously localize multiple brain structures in 3D fetal neurosonography. The proposed View-based Projection Networks (VP-Nets), uses three view-based Convolutional Neural Networks (CNNs), to simplify 3D localizations by directly predicting 2D projections of the key structures onto three anatomical views.
                  While designed for efficient use of data and GPU memory, the proposed VP-Nets allows for full-resolution 3D prediction. We investigated parameters that influence the performance of VP-Nets, e.g. depth and number of feature channels. Moreover, we demonstrate that the model can pinpoint the structure in 3D space by visualizing the trained VP-Nets, despite only 2D supervision being provided for a single stream during training. For comparison, we implemented two other baseline solutions based on Random Forest and 3D U-Nets. In the reported experiments, VP-Nets consistently outperformed other methods on localization. To test the importance of loss function, two identical models are trained with binary corss-entropy and dice coefficient loss respectively. Our best VP-Net model achieved prediction center deviation: 1.8 ± 1.4 mm, size difference: 1.9 ± 1.5 mm, and 3D Intersection Over Union (IOU): 63.2 ± 14.7% when compared to the ground truth. To make the whole pipeline intervention free, we also implement a skull-stripping tool using 3D CNN, which achieves high segmentation accuracy. As a result, the proposed processing pipeline takes a raw ultrasound brain image as input, and output a skull-stripped image with five detected key brain structures.",multimedia
10.1016/j.cmpb.2018.03.013,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-07-01,sciencedirect,Adaptive median binary patterns for fully automatic nerves tracking in ultrasound images,https://api.elsevier.com/content/abstract/scopus_id/85045114372,"Background and Objective
                  In the last decade, Ultrasound-Guided Regional Anesthesia (UGRA) gained importance in surgical procedures and pain management, due to its ability to perform target delivery of local anesthetics under direct sonographic visualization. However, practicing UGRA can be challenging, since it requires high skilled and experienced operator. Among the difficult task that the operator can face, is the tracking of the nerve structure in ultrasound images. Tracking task in US images is very challenging due to the noise and other artifacts.
               
                  Methods
                  In this paper, we introduce a new and robust tracking technique by using Adaptive Median Binary Pattern(AMBP) as texture feature for tracking algorithms (particle filter, mean-shift and Kanade-Lucas-Tomasi(KLT)). Moreover, we propose to incorporate Kalman filter as prediction and correction steps for the tracking algorithms, in order to enhance the accuracy, computational cost and handle target disappearance.
               
                  Results
                  The proposed method have been applied on real data and evaluated in different situations. The obtained results show that tracking with AMBP features outperforms other descriptors and achieved best performance with 95% accuracy.
               
                  Conclusions
                  This paper presents the first fully automatic nerve tracking method in Ultrasound images. AMBP features outperforms other descriptors in all situations such as noisy and filtered images.",multimedia
10.1016/j.compind.2018.03.014,Journal,Computers in Industry,scopus,2018-06-01,sciencedirect,Real-time object detection in agricultural/remote environments using the multiple-expert colour feature extreme learning machine (MEC-ELM),https://api.elsevier.com/content/abstract/scopus_id/85044151304,"It is necessary for autonomous robotics in agriculture to provide real time feedback, but due to a diverse array of objects and lack of landscape uniformity this objective is inherently complex. The current study presents two implementations of the multiple-expert colour feature extreme learning machine (MEC-ELM). The MEC-ELM is a cascading algorithm that has been implemented along side a summed area table (SAT) for fast feature extraction and object classification, for a fully functioning object detection algorithm. The MEC-ELM is an implementation of the colour feature extreme learning machine (CF-ELM), which is an extreme learning machine (ELM) with a partially connected hidden layer; taking three colour bands as inputs. The colour implementation used with the SAT enable the MEC-ELM to find and classify objects quickly, with 84% precision and 91% recall in weed detection in the Y’UV colour space and in 0.5 s per frame. The colour implementation is however limited to low resolution images and for this reason a colour level co-occurrence matrix (CLCM) variant of the MEC-ELM is proposed. This variant uses the SAT to produce a CLCM and texture analyses, with texture values processed as an input to the MEC-ELM. This enabled the MEC-ELM to achieve 78–85% precision and 81–93% recall in cattle, weed and quad bike detection and in times between 1 and 2 s per frame. Both implementations were benchmarked on a standard i7 mobile processor. Thus the results presented in this paper demonstrated that the MEC-ELM with SAT grid and CLCM makes an ideal candidate for fast object detection in complex and/or agricultural landscapes.",multimedia
10.1016/j.cmpb.2018.03.003,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-06-01,sciencedirect,The design and validation of a hybrid digital-signal-processing plug-in for traditional cochlear implant speech processors,https://api.elsevier.com/content/abstract/scopus_id/85043755908,"Background and objective
                  Cochlear implants (CIs) are electronic devices restoring partial hearing to deaf individuals with profound hearing loss. In this paper, a new plug-in for traditional IIR filter-banks (FBs) is presented for cochlear implants based on wavelet neural networks (WNNs). Having provided such a plug-in for commercially available CIs, it is possible not only to use available hardware in the market but also to optimize their performance compared with the-state-of-the-art.
               
                  Methods
                  An online database of Dutch diphone perception was used in our study. The weights of the WNNs were tuned using particle swarm optimization (PSO) on a training set (speech-shaped noise (SSN) of 2 dB SNR), while its performance was assessed on a test set in terms of objective and composite measures in the hold-out validation framework. The cost function was defined based on the combination of mean square error (MSE), short‑time objective intelligibility (STOI) criteria on the training set. Variety of performance indices were used including segmental signal- to -noise ratio (SNRseg), MSE, STOI, log-likelihood ratio (LLR), weighted spectral slope (WSS), and composite measures Csig
                     
                     , 
                     Cbak
                      and Covl
                     . Meanwhile, the following CI speech processing techniques were used for comparison: traditional FBs, dual resonance nonlinear (DRNL) and simple dual path nonlinear (SPDN) models.
               
                  Results
                  The average SNRseg, MSE, and LLR values for the WNN in the entire data set were 2.496 ± 2.794, 0.086 ± 0.025 and 2.323 ± 0.281, respectively. The proposed method significantly improved MSE, SNR, SNRseg, LLR, Csig Cbak
                      and Covl
                      compared with the other three methods (repeated-measures analysis of variance (ANOVA); P < 0.05). The average running time of the proposed algorithm (written in Matlab R2013a) on the training and test sets for each consonant or vowel on an Intel dual-core 2.10 GHz CPU with 2GB of RAM was 9.91 ± 0.87 (s) and 0.19 ± 0.01 (s), respectively.
               
                  Conclusions
                  The proposed algorithm is accurate and precise and is thus a promising new plug-in for traditional CIs. Although the tuned algorithm is relatively fast, it is necessary to use efficient vectorized implementations for real-time CI speech signal processing.",multimedia
10.1016/j.compind.2018.02.007,Journal,Computers in Industry,scopus,2018-06-01,sciencedirect,Dynamic texture recognition and localization in machine vision for outdoor environments,https://api.elsevier.com/content/abstract/scopus_id/85042859858,"This work focuses on detecting and localizing a wide range of dynamic textures in video sequences captured by surveillance cameras. Their reliable and robust analysis constitutes a challenging task for traditional computer vision methods, due to barriers like occlusions, the highly non-rigid nature of the moving entities and the complex stochastic nature of their motions. In order to address these issues, a novel hybrid framework is introduced, combining representations on both a local and global scale. A new, handcrafted local binary pattern (LBP)-flow descriptor with Fisher encoding is initially used to effectively capture low level texture dynamics, and a neural network (NN) is deployed after it to obtain a higher level, deeper and more effective representation scheme, capable of robustly discriminating even challenging dynamic texture classes. A novel localization scheme, based on multi-scale superpixel clustering is introduced, in order to detect texture patterns on local and global scales, inside and throughout sequential video frames. Experiments on various challenging benchmark datasets prove our method's efficacy and generality, as remarkable recognition and localization accuracy rates are achieved at a low computational cost, making it appropriate for real world outdoor applications.",multimedia
10.1016/j.autcon.2018.01.003,Journal,Automation in Construction,scopus,2018-05-01,sciencedirect,Transfer learning and deep convolutional neural networks for safety guardrail detection in 2D images,https://api.elsevier.com/content/abstract/scopus_id/85041454603,"Safety has been a concern for the construction industry for decades. Unsafe conditions and behaviors are considered as the major causes of construction accidents. The current safety inspection of conditions and behaviors heavily rely on human efforts which are limited onsite. To improve the safety performance of the industry, a more efficient approach to identify the unsafe conditions on site is required to supplement the current manual inspection practice. A promising way to supplement the current manual safety inspection is automated and intelligent monitoring/inspection through information and sensing technologies, including localization techniques, environment monitoring, image processing and etc. To assess the potential benefits of contemporary technologies for onsite safety inspection, the authors focused on real-time guardrail detection, as unprotected edges are the ones cause for workers falling from heights.
                  In this paper, the authors developed a safety guardrail detection model based on convolutional neural network (CNN). An augmented data set is generated with the addition of background image to guardrail 3D models and used as training set. Transfer learning is utilized and the Visual Geometry Group architecture with 16 layers (VGG-16) model is adopted to construct the basic features extraction for the neural network. In the CNN implementation, 4000 augmented images were used to train the proposed model, while another 2000 images collected from real construction jobsites and 2000 images from Google were used to validate the proposed model. The proposed CNN-based guardrail detection model obtained a high accuracy of 96.5%. In addition, this study indicates that the synthetic images generated by augment technology can be used to create a large training dataset, and CNN-based image detection algorithm is a promising approach in construction jobsite safety monitoring.",multimedia
10.1016/j.postharvbio.2018.01.013,Journal,Postharvest Biology and Technology,scopus,2018-05-01,sciencedirect,Curvature-based pattern recognition for cultivar classification of Anthurium flowers,https://api.elsevier.com/content/abstract/scopus_id/85041378775,"Real-time classification of agricultural products with various cultivars is an important issue in postharvest processing, which speeds up the processing and consumer delivery time. An innovative approach was developed for cultivar classification of Anthurium flowers based on image processing, B-spline curves, mathematical operations and machine learning classifiers. The algorithm was implemented and tested on a database of Anthurium flower images, which included the images of 15 cultivars of the flower with various sizes and shape categories. The boundary of the flowers was detected and reconstructed using a suitable B-spline curve. The signed curvature of the curve was calculated via mathematical operations. Then, several classifiers were implemented using the machine learning methods, Support Vector Machines (SVM), K-Nearest Neighbors, Discriminant Analysis, Decision Trees, and Naive Bayes, to detect and classify the cultivars of the flower. The experiments were carried out using a different number of training samples of the database images. The effect of various classification methods and variations in the angle of rotation of placing the flowers under the camera on classification accuracy were evaluated and the computation time of the classification process was measured. The results showed that in the unrotated sample with 1.5 pixels/mm density, the classification accuracy of the Naive Bayes and SVM algorithms had the highest classification accuracies, more than 98%. Also, the Decision Trees classifier had the lowest computation time, less than 2.5 ms. The proposed approach had proper classification accuracy and low computational load, which could be used in the real-time classification systems for Anthurium flowers.",multimedia
10.1016/j.jneumeth.2017.07.020,Journal,Journal of Neuroscience Methods,scopus,2018-04-15,sciencedirect,Automated face recognition of rhesus macaques,https://api.elsevier.com/content/abstract/scopus_id/85026478684,"Background
                  Rhesus macaques are widely used in biomedical research. Automated behavior monitoring can be useful in various fields (including neuroscience), as well as having applications to animal welfare but current technology lags behind that developed for other species. One difficulty facing developers is the reliable identification of individual macaques within a group especially as pair- and group-housing of macaques becomes standard. Current published methods require either implantation or wearing of a tracking device.
               
                  New method
                  I present face recognition, in combination with face detection, as a method to non-invasively identify individual rhesus macaques in videos. The face recognition method utilizes local-binary patterns in combination with a local discriminant classification algorithm.
               
                  Results
                  A classification accuracy of between 90 and 96% was achieved for four different groups. Group size, number of training images and challenging image conditions such as high contrast all had an impact on classification accuracy. I demonstrate that these methods can be applied in real time using standard affordable hardware and a potential application to studies of social structure.
               
                  Comparison with existing method(s)
                  Face recognition methods have been reported for humans and other primate species such as chimpanzees but not rhesus macaques. The classification accuracy with this method is comparable to that for chimpanzees. Face recognition has the advantage over other methods for identifying rhesus macaques such as tags and collars of being non-invasive.
               
                  Conclusions
                  This is the first reported method for face recognition of rhesus macaques, has high classification accuracy and can be implemented in real time.",multimedia
10.1016/j.neunet.2018.01.014,Journal,Neural Networks,scopus,2018-04-01,sciencedirect,Accelerated low-rank representation for subspace clustering and semi-supervised classification on large-scale data,https://api.elsevier.com/content/abstract/scopus_id/85042324490,"The scalability of low-rank representation (LRR) to large-scale data is still a major research issue, because it is extremely time-consuming to solve singular value decomposition (SVD) in each optimization iteration especially for large matrices. Several methods were proposed to speed up LRR, but they are still computationally heavy, and the overall representation results were also found degenerated. In this paper, a novel method, called accelerated LRR (ALRR) is proposed for large-scale data. The proposed accelerated method integrates matrix factorization with nuclear-norm minimization to find a low-rank representation. In our proposed method, the large square matrix of representation coefficients is transformed into a significantly smaller square matrix, on which SVD can be efficiently implemented. The size of the transformed matrix is not related to the number of data points and the optimization of ALRR is linear with the number of data points. The proposed ALRR is convex, accurate, robust, and efficient for large-scale data. In this paper, ALRR is compared with state-of-the-art in subspace clustering and semi-supervised classification on real image datasets. The obtained results verify the effectiveness and superiority of the proposed ALRR method.",multimedia
10.1016/j.neucom.2017.12.016,Journal,Neurocomputing,scopus,2018-03-22,sciencedirect,Use of human gestures for controlling a mobile robot via adaptive CMAC network and fuzzy logic controller,https://api.elsevier.com/content/abstract/scopus_id/85038844344,"Mobile robots with manipulators have been more and more commonly applied in extreme and hostile environments to assist or even replace human operators for complex tasks. In addition to autonomous abilities, mobile robots need to facilitate the human–robot interaction control mode that enables human users to easily control or collaborate with robots. This paper proposes a system which uses human gestures to control an autonomous mobile robot integrating a manipulator and a video surveillance platform. A human user can control the mobile robot just as one drives an actual vehicle in the vehicle’s driving cab. The proposed system obtains human’s skeleton joints information using a motion sensing input device, which is then recognized and interpreted into a set of control commands. This is implemented, based on the availability of training data set and requirement of in-time performance, by an adaptive cerebellar model articulation controller neural network, a finite state machine, a fuzzy controller and purposely designed gesture recognition and control command generation systems. These algorithms work together implement the steering and velocity control of the mobile robot in real-time. The experimental results demonstrate that the proposed approach is able to conveniently control a mobile robot using virtual driving method, with smooth manoeuvring trajectories in various speeds.",multimedia
10.1016/j.jappgeo.2018.01.006,Journal,Journal of Applied Geophysics,scopus,2018-03-01,sciencedirect,Inferring the most probable maps of underground utilities using Bayesian mapping model,https://api.elsevier.com/content/abstract/scopus_id/85044639536,"Mapping the Underworld (MTU), a major initiative in the UK, is focused on addressing social, environmental and economic consequences raised from the inability to locate buried underground utilities (such as pipes and cables) by developing a multi-sensor mobile device. The aim of MTU device is to locate different types of buried assets in real time with the use of automated data processing techniques and statutory records. The statutory records, even though typically being inaccurate and incomplete, provide useful prior information on what is buried under the ground and where. However, the integration of information from multiple sensors (raw data) with these qualitative maps and their visualization is challenging and requires the implementation of robust machine learning/data fusion approaches. An approach for automated creation of revised maps was developed as a Bayesian Mapping model in this paper by integrating the knowledge extracted from sensors raw data and available statutory records. The combination of statutory records with the hypotheses from sensors was for initial estimation of what might be found underground and roughly where. The maps were (re)constructed using automated image segmentation techniques for hypotheses extraction and Bayesian classification techniques for segment-manhole connections. The model consisting of image segmentation algorithm and various Bayesian classification techniques (segment recognition and expectation maximization (EM) algorithm) provided robust performance on various simulated as well as real sites in terms of predicting linear/non-linear segments and constructing refined 2D/3D maps.",multimedia
10.1016/j.diin.2017.12.003,Journal,Digital Investigation,scopus,2018-03-01,sciencedirect,Criminal motivation on the dark web: A categorisation model for law enforcement,https://api.elsevier.com/content/abstract/scopus_id/85041635143,"Research into the nature and structure of ‘Dark Webs’ such as Tor has largely focused upon manually labelling a series of crawled sites against a series of categories, sometimes using these labels as a training corpus for subsequent automated crawls. Such an approach is adequate for establishing broad taxonomies, but is of limited value for specialised tasks within the field of law enforcement. Contrastingly, existing research into illicit behaviour online has tended to focus upon particular crime types such as terrorism. A gap exists between taxonomies capable of holistic representation and those capable of detailing criminal behaviour. The absence of such a taxonomy limits interoperability between agencies, curtailing development of standardised classification tools.
                  We introduce the Tor-use Motivation Model (TMM), a two-dimensional classification methodology specifically designed for use within a law enforcement context. The TMM achieves greater levels of granularity by explicitly distinguishing site content from motivation, providing a richer labelling schema without introducing inefficient complexity or reliance upon overly broad categories of relevance. We demonstrate this flexibility and robustness through direct examples, showing the TMM's ability to distinguish a range of unethical and illegal behaviour without bloating the model with unnecessary detail.
                  The authors of this paper received permission from the Australian government to conduct an unrestricted crawl of Tor for research purposes, including the gathering and analysis of illegal materials such as child pornography. The crawl gathered 232,792 pages from 7651 Tor virtual domains, resulting in the collation of a wide spectrum of materials, from illicit to downright banal. Existing conceptual models and their labelling schemas were tested against a small sample of gathered data, and were observed to be either overly prescriptive or vague for law enforcement purposes - particularly when used for prioritising sites of interest for further investigation.
                  In this paper we deploy the TMM by manually labelling a corpus of over 4000 unique Tor pages. We found a network impacted (but not dominated) by illicit commerce and money laundering, but almost completely devoid of violence and extremism. In short, criminality on this ‘dark web’ is based more upon greed and desire, rather than any particular political motivations.",multimedia
10.1016/j.artint.2017.12.001,Journal,Artificial Intelligence,scopus,2018-03-01,sciencedirect,Decentralized Reinforcement Learning of robot behaviors,https://api.elsevier.com/content/abstract/scopus_id/85038868982,"A multi-agent methodology is proposed for Decentralized Reinforcement Learning (DRL) of individual behaviors in problems where multi-dimensional action spaces are involved. When using this methodology, sub-tasks are learned in parallel by individual agents working toward a common goal. In addition to proposing this methodology, three specific multi agent DRL approaches are considered: DRL-Independent, DRL Cooperative-Adaptive (CA), and DRL-Lenient. These approaches are validated and analyzed with an extensive empirical study using four different problems: 3D Mountain Car, SCARA Real-Time Trajectory Generation, Ball-Dribbling in humanoid soccer robotics, and Ball-Pushing using differential drive robots. The experimental validation provides evidence that DRL implementations show better performances and faster learning times than their centralized counterparts, while using less computational resources. DRL-Lenient and DRL-CA algorithms achieve the best final performances for the four tested problems, outperforming their DRL-Independent counterparts. Furthermore, the benefits of the DRL-Lenient and DRL-CA are more noticeable when the problem complexity increases and the centralized scheme becomes intractable given the available computational resources and training time.",multimedia
10.1016/j.jfranklin.2017.07.037,Journal,Journal of the Franklin Institute,scopus,2018-03-01,sciencedirect,System-on-a-chip (SoC)-based hardware acceleration for foreground and background identification,https://api.elsevier.com/content/abstract/scopus_id/85027498536,"The rapid growth of embedded vision applications and accessibility in recent years has instigated a philosophical shift in algorithm and implementation design for artificial intelligence. With the popularization of high-definition video, the amount of data available to be processed has also increased substantially, posing massive computational and communication demands. Hardware acceleration through specialization has received renewed interest in recent years; such acceleration has generally been implemented using two chips, with the image signal processing (ISP) part being performed by a DSP, a GPU or an FPGA and the video content analytics (VCA) part being executed by a processor. GPUs consume a substantial amount of power; thus, it is challenging to deploy them in embedded environments. However, the new generation of SoC-FPGAs that are fabricated with both the microprocessor and FPGA on a single chip consumes less power and can be built into small systems, thereby offering an attractive platform for embedded applications. This study presents the hardware acceleration of a real-time adaptive background and foreground identification algorithm in a SoC, including the capture, processing and display stages. The algorithm can be performed in either 2D or 3D space. The proposed platform uses photometric invariant color, depth data and local binary patterns (LBPs) to distinguish background from foreground. The system uses minimal cell resources, an elastically pipelined architecture is used to absorb variations in processing time, and each pipeline stage is optimized to use the available FPGA primitives. Additionally, the communication-centric architecture used in this work simplifies the implementation of embedded vision algorithms.",multimedia
10.1016/j.media.2017.12.003,Journal,Medical Image Analysis,scopus,2018-02-01,sciencedirect,Multi-hypothesis tracking of the tongue surface in ultrasound video recordings of normal and impaired speech,https://api.elsevier.com/content/abstract/scopus_id/85037537839,"Characterizing tongue shape and motion, as they appear in real-time ultrasound (US) images, is of interest to the study of healthy and impaired speech production. Quantitative anlaysis of tongue shape and motion requires that the tongue surface be extracted in each frame of US speech recordings. While the literature proposes several automated methods for this purpose, these either require large or very well matched training sets, or lack robustness in the presence of rapid tongue motion. This paper presents a new robust method for tongue tracking in US images that combines simple tongue shape and motion models derived from a small training data set with a highly flexible active contour (snake) representation and maintains multiple possible hypotheses as to the correct tongue contour via a particle filtering algorithm. The method was tested on a database of large free speech recordings from healthy and impaired speakers and its accuracy was measured against the manual segmentations obtained for every image in the database. The proposed method achieved mean sum of distances errors of 1.69 ± 1.10 mm, and its accuracy was not highly sensitive to training set composition. Furthermore, the proposed method showed improved accuracy, both in terms of mean sum of distances error and in terms of linguistically meaningful shape indices, compared to the three publicly available tongue tracking software packages Edgetrak, TongueTrack and Autotrace.",multimedia
10.1016/j.anucene.2017.11.026,Journal,Annals of Nuclear Energy,scopus,2018-02-01,sciencedirect,"Intelligent intrusion detection system featuring a virtual fence, active intruder detection, classification, tracking, and action recognition",https://api.elsevier.com/content/abstract/scopus_id/85035143412,"An intrusion detection system (IDS) is primarily used to protect nuclear power plants from external threats, such as sabotage and malicious attacks. However, earlier versions of IDSs are configured to detect an intrusion from visual inspection by an operator. This has the disadvantages of requiring standby human resources and relying on operator capabilities. In this paper, therefore, we propose an image-based intelligent intrusion detection system (IIDS) with a virtual fence, active intruder detection, classification, and tracking, and motion recognition to solve these limitations. An integrated acquisition device was manufactured combining optical and thermal cameras to compensate for the disadvantages of optical cameras, which have difficulty detecting an intrusion at night, under adverse weather conditions, and when the intruder is camouflaged. The virtual fence has a function to set the boundary between surveillance and external areas in a graphical user interface, and to define an early pre-alarm area if necessary. The background model is designed to detect moving objects, and detected objects are segmented into bounding boxes. We implemented a network model based on a convolutional neural network (CNN) to classify moving objects as either intruders or wild animals. If an intruder is detected in real time and is crossing the virtual fence, the alarm tile blinks with the associated color. Five types of intruder behavior patterns are recognized by optimizing a long-term recurrent convolutional network (LRCN) model. The proposed IIDS meets the physical protection requirements recommended in the nuclear regulatory guidelines, and can be used as an unmanned surveillance system. It is expected to perform more active and reliable intrusion detection in combination with existing sensors, such as microwaves, electric fields, and fence disturbance sensors in a nuclear power plant.",multimedia
10.1016/j.future.2017.06.002,Journal,Future Generation Computer Systems,scopus,2018-02-01,sciencedirect,Automated multi-level malware detection system based on reconstructed semantic view of executables using machine learning techniques at VMM,https://api.elsevier.com/content/abstract/scopus_id/85023600868,"In order to fulfill the requirements like stringent timing restraints and demand on resources, Cyber–Physical System (CPS) must deploy on the virtualized environment such as cloud computing. To protect Virtual Machines (VMs) in which CPSs are functioning against malware-based attacks, malware detection and mitigation technique is emerging as a highly crucial concern. The traditional VM-based anti-malware software themselves a potential target for malware-based attack since they are easily subverted by sophisticated malware. Thus, a reliable and robust malware monitoring and detection systems are needed to detect and mitigate rapidly the malware based cyber-attacks in real time particularly for virtualized environment. The Virtual Machine Introspection (VMI) has emerged as a fine-grained out-of-VM security solution to detect malware by introspecting and reconstructing the volatile memory state of the live guest Operating System (OS) by functioning at the Virtual Machine Monitor (VMM) or hypervisor. However, the reconstructed semantic details by the VMI are available in a combination of benign and malicious states at the hypervisor. In order to distinguish between these two states, extensive manual analysis is required by the existing out-of-VM security solutions. To address the foremost issue, in this paper, we propose an advanced VMM-based guest-assisted Automated Multilevel Malware Detection System (AMMDS) that leverages both VMI and Memory Forensic Analysis (MFA) techniques to predict early symptoms of malware execution by detecting stealthy hidden processes on a live guest OS. More specifically, the AMMDS system detects and classifies the actual running malicious executables from the semantically reconstructed process view of the guest OS. The two sub-components of the AMMDS are: Online Malware Detector (OMD) and Offline Malware Classifier (OFMC). The OMD recognizes whether the running processes are benign or malicious using its Local Malware Signature Database (LMSD) and online malware scanner and the OFMC classify unknown malware by adopting machine learning techniques at the hypervisor. The AMMDS has been evaluated by executing large real-world malware and benign executables on to the live guest OSs. The evaluation results achieved 100% of accuracy and zero False Positive Rate (FPR) on the 10-fold cross-validation in classifying unknown malware with maximum performance overhead of 5.8%.",multimedia
10.1016/j.neucom.2017.09.044,Journal,Neurocomputing,scopus,2018-01-31,sciencedirect,Transferring deep knowledge for object recognition in Low-quality underwater videos,https://api.elsevier.com/content/abstract/scopus_id/85030701582,"In recent years, underwater video technologies allow us to explore the ocean in scientific and noninvasive ways, such as environmental monitoring, marine ecology studies, and fisheries management. However the low-light and high-noise scenarios pose great challenges for the underwater image and video analysis. We here propose a CNN knowledge transfer framework for underwater object recognition and tackle the problem of extracting discriminative features from relatively low contrast images. Even with the insufficient training set, the transfer framework can well learn a recognition model for the special underwater object recognition task together with the help of data augmentation. For better identifying objects from an underwater video, a weighted probabilities decision mechanism is introduced to identify the object from a series of frames. The proposed framework can be implemented for real-time underwater object recognition on autonomous underwater vehicles and video monitoring systems. To verify the effectiveness of our method, experiments on a public dataset are carried out. The results show that the proposed method achieves promising results for underwater object recognition on both test image datasets and underwater videos.",multimedia
10.1016/j.neucom.2017.01.030,Journal,Neurocomputing,scopus,2018-01-31,sciencedirect,3D model retrieval using constructive-learning for cross-model correlation,https://api.elsevier.com/content/abstract/scopus_id/85019651253,"With the advance of 3D technology and digital image processing technique, there have been a great number of applications of 3D models, such as virtual reality, computed aided design, and entertainment. Under such circumstance, much research attention has been spent on 3D model retrieval in recent decades. Although extensive research efforts have been dedicated to this task, it is a difficult task to explore the correlation among 3D models, which is the key issue in 3D model retrieval. In this paper, we design and implement a constructive-learning for cross-model correlation algorithm for 3D model retrieval. In this method, we first extract view features from multi-views of 3D models. To exploit the cross-model correlation, we formulate the correlation of 3D models in a hypergraph structure, where both the vertex correlation and the edge correlation are simultaneously learned in a constructive-learning process. Then, the correlation of each model to the query can be used for retrieval. To justify the performance of our proposed algorithm, we have implemented the method and tested on two datasets. We have compared it with recent state-of-the-art methods, and the results have shown superior performance of our proposed method.",multimedia
10.1016/B978-0-12-813068-1.00008-7,Book,Engineering in Medicine: Advances and Challenges,scopus,2018-01-01,sciencedirect,3D graphics to virtual reality in medicine: Opportunities and prospective,https://api.elsevier.com/content/abstract/scopus_id/85083262343,"Today, in medicine, performing a procedure on a human requires complex anatomical and physiological knowledge, including 3D relational and physical properties. All commonly employed imaging modalities attempt to recapitulate this information in some useable form. Each technique, however, can only retrieve a small slice of spatial, temporal, or conceptual knowledge of the body area of interest. Furthermore, in some cases like computed tomography, a large amount of information is gathered without a clear strategy for manual or automated analysis. Current software developments are slowly realizing a convergence of medical imaging methodologies toward one of greater realism. For the purposes of this chapter, this “coming together” of disciplines will be delineated as the field of 3D graphics. Although this is a simplification, 3D graphics will be the primary foundation for a much larger hybridized field whose aim will be the creation of informative and accurate medical spatial representations. To understand how this will affect the clinical fields, we will need to first explore 3D graphics more holistically, delving into areas of physical simulation, 3D movie rendering, video game development, and the expansion of 3D visualization hardware. As we explore these fields, we will relate each of these subdomains to analogous examples in the medical field, also documenting opportunities for commercialization and innovation.",multimedia
10.1016/j.procs.2018.10.237,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,High Performance Geological Disaster Recognition using Deep Learning,https://api.elsevier.com/content/abstract/scopus_id/85062030356,"Geological disaster recognition on optical image is one of the key techniques in disaster control and disaster relief. Comparing with optical images, remote sensing images contain much higher resolution and more visualized contents. In this paper, we propose a landslide recognition framework which trains a deep auto-encoder network on the compressed domain. ANN or SVM is used as the classifier for decision making. In addition, in order to meet the requirement of some real-time applications, a high performance training network on CUDA-enabled GPUs is designed and implemented. Experiments are conducted on optical images from Google Earth.",multimedia
10.1016/j.procir.2018.01.036,Conference Proceeding,Procedia CIRP,scopus,2018-01-01,sciencedirect,"Intuitive robot programming through environment perception, augmented reality simulation and automated program verification",https://api.elsevier.com/content/abstract/scopus_id/85061975291,"The increasing complexity of products and machines as well as short production cycles with small lot sizes present great challenges to production industry. Both, the programming of industrial robots in online mode using hand-held control devices or in offline mode using text-based programming requires specific knowledge of robotics and manufacturer-dependent robot control systems. In particular for small and medium-sized enterprises the machine control software needs to be easy, intuitive and usable without time-consuming learning steps, even for employees with no in-depth knowledge of information technology. To simplify the programming of application programs for industrial robots, we extended a cloud-based, task-oriented robot control system with environment perception and plausibility check functions. For the environment perception a depth camera and pointcloud processing hardware were installed. We detect objects located in the robot’s workspace by pointcloud processing with ROS and the PCL and add them to the augmented reality user interface of the robot control. The combination of process knowledge from task-oriented application programming and information about available workpieces from automated image processing enables a plausibility check and verification of the robot program before execution. After a robot program has been approved by the plausibility check, it is tested in an augmented reality simulation for collisions with the detected objects before deployment to the physical robot hardware. Experiments were carried out to evaluate the effectiveness of the developed extensions and confirmed their functionality.",multimedia
10.1016/j.procir.2018.09.067,Conference Proceeding,Procedia CIRP,scopus,2018-01-01,sciencedirect,A Conceptual Design for Smell Based Augmented Reality: Case Study in Maintenance Diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85059916374,"The trend of Industry 4.0 encourages the next generation of manufacturing to be flexible, intelligent, and interoperable. The implementations of the Artificial Intelligence (AI) technology could potentially enhance maintenance in efficiency, and accuracy. However, it will not be a substitution to the human operator’s flexibility, decision-making and information received by the natural five senses. Augmented reality (AR) is commonly understood as a technology that overlays virtual information onto the existing environment to provide users a new and improved experience to assist their daily activities. However, AR can be used to enhance all human five senses rather than just overlay virtual imagery. In this paper, a design and a practical plan of smell augmentation for diagnosis is initialised, via a case study in maintenance. The aim of this paper is to evaluate the feasibilities, identify challenges, and summarise initial results of overlaying information through smell augmentations.",multimedia
10.1016/B978-0-12-813445-0.00001-0,Book,Computer Vision For Assistive Healthcare,scopus,2018-01-01,sciencedirect,Computer Vision for Sight: Computer Vision Techniques to Assist Visually Impaired People to Navigate in an Indoor Environment,https://api.elsevier.com/content/abstract/scopus_id/85059725012,"This chapter focuses on computer vision techniques to assist visually impaired people to navigate in an indoor environment. First, the problem is defined in terms of tasks, sensors, devices, and the performance requirements (real-time, accuracy, and robustness). Then, a recommended paradigm is proposed to build these systems for real-world applications, which include three important components: environment modeling, localization algorithms, and user interfaces. A broad review of the recent research achievements is provided in two categories: omnidirectional image-based and three-dimensional (3D) model-based approaches. As an example, an omnidirectional-vision-based indoor localization solution is described with algorithms and corresponding implementations in maximizing the use of the visual information surrounding a user. The system includes multiple components: floor plan parsing and path planning for scene modeling, deep learning for place recognition, image indexing for initial localization, 3D vision for position refinement, and portable user interfaces. Finally, we summarize the work and present some discussions for future work.",multimedia
10.1016/j.procs.2018.11.031,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,"Relating language, logic, and imagery",https://api.elsevier.com/content/abstract/scopus_id/85059472144,"The world is a continuum, but words are discrete. Sensory organs map the continuous world to continuous mental models of sights, sounds, actions, and feelings. Those mental models, which represent a moving 3-D virtual reality (VR) are the semantic foundation for all versions of language and logic. A common model for cognition must be able to process and relate all modalities. Kyndi technology represents all information in graphs. They include conceptual graphs for symbolic information and arbitrary graphs for 2-D icons or 3-D VR. All graphs are stored in Cognitive Memory, which can find approximate mappings for arbitrary graphs in logarithmic time. Those mappings include formal unification for logics, and informal analogies for case-based reasoning. The analogies can even map conceptual graphs to the graphs derived from imagery or VR simulations. For reasoning, Peirce’s rules of inference for existential graphs can support operations on arbitrary icons, such as the diagrams in Euclid’s geometry. Those rules, when adapted to conceptual graphs, can map symbolic languages to and from Euclidean style geometrical reasoning. With two new rules of inference, called observation and imagination, the Standard Model of Cognition can support mental models without making any current software obsolete.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
10.1016/j.ifacol.2018.11.271,Conference Proceeding,IFAC-PapersOnLine,scopus,2018-01-01,sciencedirect,Transportation of small objects by robotic throwing and catching: applying genetic programming for trajectory estimation,https://api.elsevier.com/content/abstract/scopus_id/85057037476,"Robotic catching of thrown objects is one of the common robotic tasks, which is explored in several works. This task includes subtask of tracking and forecasting the trajectory of the thrown object. Here we propose an algorithm for estimating future trajectory based on video signal from two cameras. Most of existing implementations use deterministic trajectory prediction and several are based on machine learning. We propose a combined forecasting algorithm where the deterministic motion model for each trajectory is generated via the genetic programming algorithm. Genetic programming is implemented on C++ with use of CUDA library and executed in parallel way on the graphical processing unit. Parallel execution allow genetic programming in real time. Numerical experiments with real trajectories of the thrown tennis ball show that the algorithm can forecast the trajectory accurately.",multimedia
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",multimedia
