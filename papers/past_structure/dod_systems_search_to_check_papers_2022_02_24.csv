doi,type,publication,publisher,publication_date,database,title,url,abstract,domain,id,status
10.1109/iccda.2010.5540715,to_check,2010 International Conference On Computer Design and Applications,IEEE,2010-06-27 00:00:00,ieeexplore,data-oriented architecture for double and single bits error correction using cycle redundancy code,https://ieeexplore.ieee.org/document/5540715/,"Error occurs during transferring, storing and retrieving data. Thus error detection and correction is a necessary technique in information technology. Cycle Redundancy Code, CRC, is a common method in error detection. A new method based on data-oriented theory for single and double bit errors correction by using CRC is presented. The conceptual model of presented method as data-oriented architecture is designed to implement it with hardware. This method is able to determine the exact place of one and two bits in error and correct them. In a way, nonzero calculated remainder on receiver is compared with remainder field of the content of Problem Solution Data Structure, PSDS, to find the error location, as a solution.",data oriented architecture,1,included
10.1109/icacc.2010.5487131,to_check,2010 2nd International Conference on Advanced Computer Control,IEEE,2010-03-29 00:00:00,ieeexplore,data-oriented architecture of ln function,https://ieeexplore.ieee.org/document/5487131/,"In this paper a new architecture to calculate Ln function based on data-oriented theory is introduced. Because of using proper and huge amount of data in modeling, implementing of this type of models causes less calculation complexity. Data-oriented architecture is made of considering memory and small calculation unit together. Proposed method calculates Ln function faster than common methods.",data oriented architecture,2,included
10.1109/icetc.2010.5529337,to_check,2010 2nd International Conference on Education Technology and Computer,IEEE,2010-06-24 00:00:00,ieeexplore,data-oriented architecture of sine,https://ieeexplore.ieee.org/document/5529337/,"A data-oriented architecture is introduced to calculate Sine function by using sine data-oriented model as a data structure and a small calculation unit. The main contribution of this paper is to use a content-accessed memory to handle and manage data-oriented model of sine in this architecture. Using this architecture, sine function calculation will be fast.",data oriented architecture,3,included
10.1109/icacte.2010.5579358,to_check,2010 3rd International Conference on Advanced Computer Theory and Engineering(ICACTE),IEEE,2010-08-22 00:00:00,ieeexplore,data-oriented architecture of sine and cosine functions,https://ieeexplore.ieee.org/document/5579358/,"In this paper a new architecture to calculate Sine and Cosine Function based on data-oriented theory is introduced. To compute sine and cosine by this model less mathematical operations are needed comparing to common methods. Therefore, hardware implementation of this architecture provides faster module.",data oriented architecture,4,included
10.1109/icepe.2014.6970070,to_check,2014 International Conference and Exposition on Electrical and Power Engineering (EPE),IEEE,2014-10-18 00:00:00,ieeexplore,domain specific languages in power systems engineering,https://ieeexplore.ieee.org/document/6970070/,"This paper proposes an information system for data mining that allows the specification of ad-hoc queries on a data warehouse, which contain historical information relative to exceptions (i.e., operating faults) recorded by a SCADA system in a power distribution network. The proposed application can be used by the power system engineers to explore the existent historical data, with no need for any “low level” programming expertise. The data-oriented architecture of the system provides important advantages related to application development and system maintainability.",data oriented architecture,5,included
10.1109/cse.2014.128,to_check,2014 IEEE 17th International Conference on Computational Science and Engineering,IEEE,2014-12-21 00:00:00,ieeexplore,exploring the benefits of introducing network coding into named data networking,https://ieeexplore.ieee.org/document/7023638/,"In recent years, the focus to optimize network transmission efficiency has evolved to adopt methods that let those intermediate data transferring nodes get involved with routing, forwarding and caching. In other words, the new network architecture designs become in favor of hop-to-hop model, instead of traditional TCP-like end-to-end model. Named data networking is a promising future internet data oriented architecture which uses names instead of addresses and exchanges or forwards interest/data pair packets at each node along the path to route data for delivery. And meanwhile Network coding (NC) is a content oriented and effective method to reduce redundancy, increase network throughput and improve robustness. Nonetheless, due to NDN's current preliminary research, less research has combined these two technologies together. This paper presents some new thoughts to study on the benefits brought by integrating network coding to NDN, which can effectively improve network utilization, strengthen caching privacy, and also promote development of the NDN architecture itself.",data oriented architecture,6,not included
10.1007/978-3-030-88207-5_17,to_check,"Cooperative Design, Visualization, and Engineering",Springer,2021-01-01 00:00:00,springer,building a big data oriented architecture for enterprise integration,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-88207-5_17,"Digital transformation is happening across all industries and affecting all facets of our daily life. However, in many corporations, this important process is fragmented and is undertaken without a farsighted plan to take advantage of an invaluable resource: data. This can be due to a variety of reasons, for example, lack of funding, poor business vision, inappropriate consulting or deployment. Digital transformation is a considerable investment since it will determine the system’s ability to grow and adapt to the company’s changing requirements. To achieve that end, the architecture must be flexible both in development and deployment and must also be able to harness the ever-increasing data of the corporation. Among the widely used information system architectures being used in the world, Micro-service is a standout with many advantages. The adaptation of this architecture to work with Big Data, as well as to tackle different aspects of a data system such as load-balancing, file handling and storage, etc. is a very practical area of research. This paper presents such an enterprise integration solution for a mega-corporation client in Vietnam, the An Pha Petrol Group Joint Stock Company, including the architecture and technologies used to build a comprehensive system that brings novel experiences to its 2,000 internal users. It consists of building the information infrastructure and system, super applications for both desktop and mobile devices to enhance the work performance and quality. The approaches and results of this paper are applicable to similar large enterprise solutions.",data oriented architecture,7,included
http://arxiv.org/abs/1706.03968v2,to_check,arxiv,arxiv,2017-06-13 00:00:00,arxiv,asynchronous graph pattern matching on multiprocessor systems,http://arxiv.org/abs/1706.03968v2,"Pattern matching on large graphs is the foundation for a variety of
application domains. Strict latency requirements and continuously increasing
graph sizes demand the usage of highly parallel in-memory graph processing
engines that need to consider non-uniform memory access (NUMA) and concurrency
issues to scale up on modern multiprocessor systems. To tackle these aspects,
graph partitioning becomes increasingly important. Hence, we present a
technique to process graph pattern matching on NUMA systems in this paper. As a
scalable pattern matching processing infrastructure, we leverage a
data-oriented architecture that preserves data locality and minimizes
concurrency-related bottlenecks on NUMA systems. We show in detail, how graph
pattern matching can be asynchronously processed on a multiprocessor system.",data oriented architecture,8,included
10.15598/aeee.v19i4.4183,to_check,core,"'VSB Technical University of Ostrava, Faculty of Electrical Engineering and Computer Sciences'",2021-01-01 00:00:00,core,intelligent bearing fault diagnosis method based on hnr envelope and classification using supervised machine learning algorithms,https://core.ac.uk/download/490710719.pdf,"Research on data-driven bearing fault diagnosis techniques has recently drawn more and more attention due to the availability of massive condition monitoring data. The research work presented in this paper aims to develop an architecture for the detection and diagnosis of bearing faults in the induction machines. The developed data-oriented architecture uses vibration signals collected by sensors placed on the machine, which is based, in the first place, on the extraction of fault indicators based on the harmonics-to-noise ratio envelope. Normalisation is then applied to the extracted indicators to create a well-processed data set. The evolution of these indicators will be studied afterwards according to the type and severity of defects using sequential backward selection technique. Supervised machine learning classification methods are developed to classify the measurements described by the feature vector with respect to the known modes of operation. In the last phase concerning decision making, ten classifiers are tested and applied based on the selected and combined indicators. The developed classification methods allow classifying the observations, with respect to the different modes of bearing condition (outer race, inner race fault or healthy condition). The proposed method is validated on data collected using an experimental bearing test bench. The experimental results indicate that the proposed architecture achieves high accuracy in bearing fault detection under all operational conditions. The results show that, compared to some proposed approaches, our proposed architecture can achieve better performance overall in terms of the number of optimal features and the accuracy of the tests",data oriented architecture,9,not included
10.3390/electronics10151810,to_check,core,'MDPI AG',2021-07-01 00:00:00,core,on-board data management layer: connected vehicle as data platform,,"For connected vehicles, as well as generally for the transportation sector, data are now seen as a precious resource. They can be used to make right decisions, improve road safety, reduce CO2 emissions, or optimize processes. However, analyzing these data is not so much a question of which technologies to use, but rather about where these data are analyzed. Thereby, the emerging vehicle architecture has to become a data-oriented architecture based on embedded computing platforms and take into account new applications, artificial intelligence elements, advanced analytics, and operating systems. Accordingly, in this paper, we introduce the concept of data management to the vehicle by proposing an on-board data management layer, so that the vehicle can play the role of data platform capable of storing, processing, and diffusing data. Our proposed layer supports analytics and data science to deliver additional value from the connected vehicle data and stimulate the development of new services. In addition, our data platform can also form or contribute to shaping the backbone of data-driven transport. An on-board platform was built where the dataset size was reduced 80% and a rate of 99% accuracy was achieved in a 5 min traffic flow prediction using artificial neural networks (ANNs)",data oriented architecture,10,included
10.1109/asru.2007.4430168,to_check,2007 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU),IEEE,2007-12-13 00:00:00,ieeexplore,a data-centric architecture for data-driven spoken dialog systems,https://ieeexplore.ieee.org/document/4430168/,"Data is becoming increasingly crucial for training and (self-) evaluation of spoken dialog systems (SDS). Data is used to train models (e.g. acoustic models) and is 'forgotten'. Data is generated on-line from the different components of the SDS system, e.g. the dialog manager, as well as from the world it is interacting with (e.g. news streams, ambient sensors etc.). The data is used to evaluate and analyze conversational systems both on-line and off-line. We need to be able query such heterogeneous data for further processing. In this paper we present an approach with two novel components: first, an architecture for SDSs that takes a data-centric view, ensuring persistency and consistency of data as it is generated. The architecture is centered around a database that stores dialog data beyond the lifetime of individual dialog sessions, facilitating dialog mining, annotation, and logging. Second, we take advantage of the state-fullness of the data-centric architecture by means of a lightweight, reactive and inference-based dialog manager that itself is stateless. The feasibility of our approach has been validated within a prototype of a phone-based university help-desk application. We detail SDS architecture and dialog management, model, and data representation.",data centric architecture,11,included
10.1109/icdcsw.2003.1203556,to_check,"23rd International Conference on Distributed Computing Systems Workshops, 2003. Proceedings.",IEEE,2003-05-22 00:00:00,ieeexplore,"""data-centric to the max"", the splice architecture experience",https://ieeexplore.ieee.org/document/1203556/,"Over the past 10 years, Thales Naval Nederland (TNN) has successfully applied a pure data-centric architecture called SPLICE in its naval Combat Management Systems This fielded architecture provides the essential non-functional properties as demanded in these mission-critical environments such as (real-time) performance, scalability, fault-tolerance and evolveability. Thales recently contributed this knowledge and experience in a joint submission regarding the OMG's Data Distribution Service (DDS) for Real-time systems. The SPLICE architecture is characterized by autonomous applications with minimal dependencies where function and interaction are clearly separated and SPLICE-agents act as real-time information brokers. SPLICE thus offers a normalized environment that is designed once for all applications and which delivers 'the right information at the right place at the right time'.",data centric architecture,12,included
10.1109/cluster.2012.80,to_check,2012 IEEE International Conference on Cluster Computing,IEEE,2012-09-28 00:00:00,ieeexplore,a decoupled execution paradigm for data-intensive high-end computing,https://ieeexplore.ieee.org/document/6337781/,"High-end computing (HEC) applications in critical areas of science and technology tend to be more and more data intensive. I/O has become a vital performance bottleneck of modern HEC practice. Conventional HEC execution paradigms, however, are computing-centric for computation intensive applications. They are designed to utilize memory and CPU performance and have inherent limitations in addressing the critical I/O bottleneck issues of HEC. In this study, we propose a decoupled execution paradigm (DEP) to address the challenging I/O bottleneck issues. DEP is the first paradigm enabling users to identify and handle data-intensive operations separately. It can significantly reduce costly data movement and is better than the existing execution paradigms for data-intensive applications. The initial experimental tests have confirmed its promising potential. Its data-centric architecture could have an impact in future HEC systems, programming models, and algorithms design and development.",data centric architecture,13,included
10.1109/siot.2016.007,to_check,2016 International Workshop on Secure Internet of Things (SIoT),IEEE,2016-09-30 00:00:00,ieeexplore,addressing data-centric security requirements for iot-based systems,https://ieeexplore.ieee.org/document/7913560/,"Allowing users to control access to their data is paramount for the success of the Internet of Things, therefore, it is imperative to ensure it, even when data has left the users' control, e.g. shared with cloud infrastructure. Consequently, we propose several state of the art mechanisms from the security and privacy research fields to cope with this requirement. To illustrate how each mechanism can be applied, we derive a data-centric architecture providing access control and privacy guaranties for the users of IoT-based applications. Moreover, we discuss the limitations and challenges related to applying the selected mechanisms to ensure access control remotely. Also, we validate our architecture by showing how it empowers users to control access to their health data in a quantified self use case.",data centric architecture,14,included
10.1109/icce-china.2017.7991141,to_check,2017 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW),IEEE,2017-06-14 00:00:00,ieeexplore,an iot framework for intelligent roadside assistance system,https://ieeexplore.ieee.org/document/7991141/,"The connected road infrastructure and roadside assistance services constitute an important consumer market segment in the Intelligent Transportation System (ITS) and Smart Cities. A closer look at available such services reveal the presence of data silos, heterogeneity and lack of interoperability. They affect the overall consumer experience and increase the cost of service development &amp; maintenance. This paper proposes an IoT framework for next generation, intelligent roadside assistance system. A data centric architecture is presented along with solutions of the mentioned challenges.",data centric architecture,15,not included
10.1109/issnip.2005.1595552,to_check,"2005 International Conference on Intelligent Sensors, Sensor Networks and Information Processing",IEEE,2005-12-08 00:00:00,ieeexplore,architectures for wireless sensor networks,https://ieeexplore.ieee.org/document/1595552/,Various architectures have been developed for wireless sensor networks. Many of them leave to the programmer important concepts as the way in which the inter-task communication and dynamic reconfigurations are addressed. In this paper we describe the characteristics of a new architecture we proposed - the data-centric architecture. This architecture offers an easy way of structuring the applications designed for wireless sensor nodes that confers them superior performances.,data centric architecture,16,included
10.1109/cast.2016.7914932,to_check,"2016 International Conference on Computing, Analytics and Security Trends (CAST)",IEEE,2016-12-21 00:00:00,ieeexplore,big data architecture with mobile cloud in cdroid operating system for storing huge data,https://ieeexplore.ieee.org/document/7914932/,We are stepping frontward for an epoch of zeta bytes from Giga/Tera/Peta/Exa bytes in this era of computer science. The data storage in clouds is not the only preference as big data technology is obtainable for processing of both structured and unstructured data. Today a colossal sum of data is engendered by mobile phones (Smartphone) of both the composition types. For the sake of faster processing and elegant data utilization for gigantic quantity of data CDroid operating systems can be implemented with big data. Big data architecture is realized with mobile cloud for paramount deployment of wherewithal. The faster execution can be ended feasible for the make use of a new data centric architecture of MapReduce technology where as HDFS (Hadoop Distributed File System) also plays a big accountability in using data with dissimilar structures. As time advances the degree of data and information generated from smartphone augments and faster execution is call for the same. As per our research and development the only resolution for this mammoth amount of data is to put into practice Big data with CDroid scheme for best use of it. We believe this effort will budge a step ahead on the road to healthier civilization in close proximity to expectations.,data centric architecture,17,included
10.1109/waina.2013.19,to_check,2013 27th International Conference on Advanced Information Networking and Applications Workshops,IEEE,2013-03-28 00:00:00,ieeexplore,ccn-tv: a data-centric approach to real-time video services,https://ieeexplore.ieee.org/document/6550523/,"Content-Centric Networking (CCN) is a promising data-centric architecture, based on in-network caching, name-driven routing, and receiver-initiated sessions, which can greatly enhance the way Internet resources are currently used, making support for a broader set of users with increasing traffic demands possible. The CCN vision is, currently, attracting the attention of many researchers across the world, since it has all the potential to become ready to the market, to be gradually deployed in the Internet of today, and to facilitate a graceful transition from a host-centric networking rationale to a more effective data-centric working behaviour. At the same time, several issues have to be investigated before CCN can be safely deployed at the Internet scale. They include routing, congestion control, caching operations, name-space planning, and application design. With reference to application-related facets, it is worth noticing that the demand for TV services is growing at an exponential rate over time, thus requiring a very careful analysis of their performance in CCN architectures. To this end, in the present contribution we deploy a CCN-TV system, capable of delivering real-time streaming TV services, and we evaluate its performance through a simulation campaign based on real-world topologies.",data centric architecture,18,included
10.1109/bigdata.2015.7363971,to_check,2015 IEEE International Conference on Big Data (Big Data),IEEE,2015-11-01 00:00:00,ieeexplore,component based dataflow processing framework,https://ieeexplore.ieee.org/document/7363971/,"In this paper we present SOA based CLAs12 event Reconstruction and Analyses (CLARA) framework used to develop Earth Science multi-sensor data fusion, processing, and analytics applications (NAIADS: NASA JLAB collaboration). CLARA design focus is on two main traits: a) real-time data stream processing, and b) service oriented architecture (SOA) in a flow based programming (FBP) paradigm. Data driven and data centric architecture of CLARA presents an environment for developing agile, elastic, multilingual data processing applications. The CLARA framework presents solutions, capable of processing large volumes of data interactively and substantially faster than batch systems.",data centric architecture,19,included
10.1109/icsea.2010.30,to_check,2010 Fifth International Conference on Software Engineering Advances,IEEE,2010-08-27 00:00:00,ieeexplore,content server architecture pattern for evolvability and scalability,https://ieeexplore.ieee.org/document/5615125/,"Significant requirements for a large digital preservation system are the system scalability, its ability to store and service heterogeneous digital holdings, and the evolvability over time of both the technologies comprising the system and the data formats in its storage. The use of information technology by the government, business corporations, academic institutions, and the general public results in staggering amounts of digital-born materials requiring long-term preservation and access. Organizations in different domains have to cope with the daunting task of storing and providing access to the growing amount of digital data. In many cases data heterogeneity, which ranges from office automation and geospatial images, to multimedia artifacts, adds to the challenge. In response to these challenges, we propose a Content Server Architecture Pattern. Content Server Architecture Pattern can be applied for instantiation of data-centric architecture, service-centric architecture, storage technology-centric architecture or an architecture that is some hybrid of that set to implement a Content Server Repository portion of a digital preservation system. A key characteristic of Content Server Architecture Pattern is its versatility that allows tailoring of the architecture of a digital preservation system to specific business needs.",data centric architecture,20,included
10.1109/aero.2005.1559422,to_check,2005 IEEE Aerospace Conference,IEEE,2005-03-12 00:00:00,ieeexplore,"data centric, position-based routing in space networks",https://ieeexplore.ieee.org/document/1559422/,"Envisioned space exploration systems and planned space science missions involve increasingly large number of satellites and surface rovers/sensors communicating for coordinated science operations or for on-demand commanding and/or transfer of data. Current approaches that use static routing cannot scale to large numbers of satellites and spacecrafts of future missions. This requires a dynamic approach that can discover networks and links as they become available and intelligently use them for routing. Furthermore, most of the science missions will be geared towards collecting data using various sensors. Adoption of a data-centric communication mechanism can enable in-network aggregation and processing which help make data forwarding more efficient. In this paper, we briefly describe ASCoT, a routing system for science missions of tomorrow, which a) leverages the predictability of satellite trajectories to effect position-based routing in the space backbone, and b) departs from traditional address-centric communication and uses a data-centric architecture to enable energy efficient and low latency operation in proximity networks. Our simulation study using STK/OPNET shows that ASCoT architecture is viable.",data centric architecture,21,included
10.1109/icccn.2019.8847129,to_check,2019 28th International Conference on Computer Communication and Networks (ICCCN),IEEE,2019-08-01 00:00:00,ieeexplore,data-centric video for mixed reality,https://ieeexplore.ieee.org/document/8847129/,"Network video streaming abstractions tend to replicate the paradigms of hardwired video dating back to analog broadcast. With IP video distribution becoming increasingly realistic for a variety of low-latency applications, this paper looks ahead to a data-centric architecture for video that can provide a superset of features from existing abstractions, to support how video is increasingly being used: for non-linear retrieval, variable speed and spatially selective playback, machine analysis, and other new approaches. As a case study, the paper describes the use of the Named Data Networking (NDN) network architecture within an experimental theatrical work being developed at UCLA. The work, a new play, Entropy Bound, uses NDN to enable a hybrid design paradigm for real-time video that combines properties of streams, buses, and stores. This approach unifies real-time live and historical playback, and is used to support edge-assisted machine learning. The paper introduces the play and its requirements (as well as the NDN components applied and developed), discusses key design patterns enabled and explored and their influence on the application architecture, and describes what was learned through practical implementation in a realworld production setting. The paper intends to inform future experimentation with real-time media over information-centric networking and elaborate on the benefits and challenges of using NDN in practice for mixed reality applications today.",data centric architecture,22,included
10.1109/netsys.2019.8854515,to_check,2019 International Conference on Networked Systems (NetSys),IEEE,2019-03-21 00:00:00,ieeexplore,information-centric iot middleware overlay: vsl,https://ieeexplore.ieee.org/document/8854515/,"The heart of the Internet of Things (IoT) is data. IoT services processes data from sensors that interface their physical surroundings, and from other software such as Internet weather databases. They produce data to control physical environments via actuators, and offer data to other services. More recently, service-centric designs for managing the IoT have been proposed. Data-centric or name-based communication architectures complement these developments very well. Especially for edge-based or site-local installations, data-centric Internet architectures can be implemented already today, as they do not require any changes at the core. We present the Virtual State Layer (VSL), a site-local data-centric architecture for the IoT. Special features of our solution are full separation of logic and data in IoT services, offering the data-centric VSL interface directly to developers, which significantly reduces the overall system complexity, explicit data modeling, a semantically-rich data item lookup, stream connections between services, and security-by-design. We evaluate our solution regarding usability, performance, scalability, resilience, energy efficiency, and security.",data centric architecture,23,included
10.1109/trustcom.2016.0248,to_check,2016 IEEE Trustcom/BigDataSE/ISPA,IEEE,2016-08-26 00:00:00,ieeexplore,rethinking high performance computing system architecture for scientific big data applications,https://ieeexplore.ieee.org/document/7847131/,"The increasingly important data-intensive scientific discovery presents a critical question to the high performance computing (HPC) community - how to efficiently support these growing scientific big data applications with HPC systems that are traditionally designed for big compute applications? The conventional HPC systems are computing-centric and designed for computation-intensive applications. Scientific big data applications have growlingly different characteristics compared to big compute applications. These scientific applications, however, will still largely rely on HPC systems to be solved. In this research, we try to answer this question with a rethinking of HPC system architecture. We study and analyze the potential of a new decoupled HPC system architecture for data-intensive scientific applications. The fundamental idea is to decouple conventional compute nodes and dynamically provision as data processing nodes that focus on data processing capability. We present studies and analyses for such decoupled HPC system architecture. The current results have shown its promising potential. Its data-centric architecture can have an impact in designing and developing future HPC systems for growingly important data-intensive scientific discovery and innovation.",data centric architecture,24,included
10.1109/aero.2017.7943816,to_check,2017 IEEE Aerospace Conference,IEEE,2017-03-11 00:00:00,ieeexplore,software architecture and design of the kontur-2 mission,https://ieeexplore.ieee.org/document/7943816/,"This paper describes the software architecture and design of the space segment, communication and ground segment software of the Kontur-2 project, which aimed to study the feasibility of planetary exploration through telepresence. The main research objectives in Kontur-2 were the development and in-flight verification of a space qualified two degree of freedom (DoF) force-feedback joystick (RJo) inside the Zvezda Service Module of the International Space Station (ISS), the implementation of telepresence technologies, and the study of human performance when controlling a force feedback joystick in microgravity. The project was conducted from 2012 to 2015 by a consortium consisting of the German Aerospace Center (DLR), the Russian Federal Space Agency (ROSCOSMOS), The Russian State Scientific Center for Robotics and Technical Cybernetics (RTC), S. P. Korolev Rocket and Space Corporation Energia (RSC “Energia”) and the Yuri A. Gagarin State Scientific Research-and-Testing Cosmonaut Training Center (GCTC). DLR conducted two sets of experiments in which a cosmonaut on board the ISS used RJo to perform different tasks with robots located on-ground. The first was conducted with a 2-DoF robot equipped with a camera system, a task board and torque sensors that allowed the cosmonaut to perceive reactive forces caused by contacts with the environment. For the second set of experiments a humanoid robot was utilized to perform a tele-handshake, as well as a cooperative task between the cosmonaut on ISS and colleagues at RTC in St. Petersburg. To realize these experiments, the consortium developed onboard and on-ground software which are described in this paper. The space segment software consists of the control software for RJo and user interfaces on a laptop to guide the cosmonaut efficiently through the experiments. A state machine was designed for these user interfaces to capture state changes during the experiment execution. This way only relevant contextual information is provided to the cosmonaut. On RJo, a component framework has been deployed combining a data-centric architecture with a CCSDS Space Packet interface. Additionally, the communication software has been designed to support a direct multi-channel connection between ground control and ISS using the S-band radio equipment of the consortium. During contact to ISS, the ground operators used the ground segment software at DLR for experiment support, supervision, maintenance and data logging. The visual feedback from the camera system required by the cosmonaut to perform the experiments was provided by a low-latency video stream through a communication channel with very restricted bandwidth. 23 experiment sessions were carried out in 2015 utilizing the Kontur-2 software, which helped to validate telepresence technologies and study human factors for space applications.",data centric architecture,25,not included
10.1109/ciot.2018.8627124,to_check,2018 3rd Cloudification of the Internet of Things (CIoT),IEEE,2018-07-04 00:00:00,ieeexplore,"fogø5: unifying the computing, networking and storage fabrics end-to-end",https://ieeexplore.ieee.org/document/8627124/,"Fog computing aims at providing horizontal, system-level, abstractions to distribute computing, storage, control and networking functions closer to the user along a cloud-to-thing continuum. Whilst fog computing is increasingly recognized as the key paradigm at the foundation of Consumer and Industrial Internet of Things (IoT), most of the initiatives on fog computing focus on extending cloud infrastructure. As a consequence, these infrastructure fall short in addressing heterogeneity and resource constraints characteristics of fog computing environments. In this paper, we (1) explain the requirements of fog computing infrastructure and how they extend well beyond those traditionally addressed by Cloud Computing infrastructures; (2) introduce fogØ5, a fog Infrastructure that unifies computing, networking and storage fabrics end-to-end, while addressing the challenges imposed by resource heterogeneity, (3) explain the novel architectural approach adopted by fogØ5 to have a server-less data-centric architecture that is scalable, secure, and highly resilient to failures, (4) demonstrate the use of fogØ5 in some real-world use cases and (5) conclude and reports on future works.",data centric architecture,26,included
10.1109/tcc.2015.2474385,to_check,IEEE Transactions on Cloud Computing,IEEE,2020-06-01 00:00:00,ieeexplore,cross-cloud mapreduce for big data,https://ieeexplore.ieee.org/document/7229313/,"MapReduce plays a critical role as a leading framework for big data analytics. In this paper, we consider a geo-distributed cloud architecture that provides MapReduce services based on the big data collected from end users all over the world. Existing work handles MapReduce jobs by a traditional computation-centric approach that all input data distributed in multiple clouds are aggregated to a virtual cluster that resides in a single cloud. Its poor efficiency and high cost for big data support motivate us to propose a novel data-centric architecture with three key techniques, namely, cross-cloud virtual cluster, data-centric job placement, and network coding based traffic routing. Our design leads to an optimization framework with the objective of minimizing both computation and transmission cost for running a set of MapReduce jobs in geo-distributed clouds. We further design a parallel algorithm by decomposing the original large-scale problem into several distributively solvable subproblems that are coordinated by a high-level master problem. Finally, we conduct real-world experiments and extensive simulations to show that our proposal significantly outperforms the existing works.",data centric architecture,27,included
10.1147/jrd.2019.2960220,to_check,IBM Journal of Research and Development,IBM,2020-07-01 00:00:00,ieeexplore,the coral supercomputer systems,https://ieeexplore.ieee.org/document/8935422/,"In 2014, the U.S. Department of Energy (DoE) initiated a multiyear collaboration between Oak Ridge National Laboratory (ORNL), Argonne National Laboratory, and Lawrence Livermore National Laboratory (LLNL), known as “CORAL,” the next major phase in the DoE's scientific computing roadmap. The IBM CORAL systems are based on a fundamentally new data-centric architecture, where compute power is embedded everywhere data resides, combining powerful central processing units (CPUs) with graphics processing units (GPUs) optimized for scientific computing and artificial intelligence workloads. The IBM CORAL systems were built on the combination of mature technologies: 9th-generation POWER CPU, 6th-generation NVIDIA GPU, and 5th-generation Mellanox InfiniBand. These systems are providing scientists with computing power to solve challenges in many research areas beyond previously possible. This article provides an overview of the system solutions deployed at ORNL and LLNL.",data centric architecture,28,included
10.1049/cp.2012.1116,to_check,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),IET,2012-03-05 00:00:00,ieeexplore,design of real-time distributed system using dds,https://ieeexplore.ieee.org/document/6492723/,Data-centric design is a modern method for building advanced real-time distributed system. DDS (Data Distribution Service) is an API specification and an interoperable wire-protocol that defines a data-centric publish-subscribe architecture for connecting the anonymous information providers with the information consumers. The DDS APIs also allow data providers and consumers to present type-safe programming interfaces which are well suited for data-critical real-time distributed systems and QoS-enabled applications. The goal idea of this paper is to present a kind of real-time distributed system based on DDS and a general design of high level API which abstract the publish-subscribe process.,data centric architecture,29,included
10.1109/bigdata47090.2019.9006235,to_check,2019 IEEE International Conference on Big Data (Big Data),IEEE,2019-12-12 00:00:00,ieeexplore,hybrid 2d and 3d visual analytics of network simulation data,https://ieeexplore.ieee.org/document/9006235/,We present a visualization architecture to support 2D and 3D visual analytics applications. The architecture is designed to be data-flow-oriented and reconfigurable such that several diverse visualization components can operate as one integrated system. Our prototype application allows users to visually analyze the results of a complex 3D network simulation data both on large high-resolution display and HTC Vive Head Mounted Display. The network simulation outputs variables describing various characteristics of network connectivity between the moving nodes on the ground and in the air interacting in a dynamically changing 3D environment. Our system uses 2D charting tools to visualize the statistical relationships between simulation variables. We developed a Unity application to animate the network simulation in a virtual environment showing the timevarying results in a 3D environment. The Unity application runs on a complete-immersive Head Mounted Display device. The 2D visualization framework running on our Large High-Resolution Display system supports multiple coordinated views across all the different 2D visualization components including a 2D map. Preliminary results show our data-centric design provides a usercentric visualization tool that can greatly enhance the analytical process and speed up the derivation of insights from data.,data centric architecture,30,included
10.1109/iccworkshops49005.2020.9145301,to_check,2020 IEEE International Conference on Communications Workshops (ICC Workshops),IEEE,2020-06-11 00:00:00,ieeexplore,supporting delay tolerant networking: a comparative study of epidemic routing and ndn,https://ieeexplore.ieee.org/document/9145301/,"Delay Tolerant Networking (DTN) is characterized by its dynamic and intermittent connectivity, resulting in the absence of end-to-end communication paths in general. Many proposed solutions have been developed over the years to enhance TCP/IP protocol stack for DTN environment; Epidemic Routing (ER) is among the earliest and most well-known designs. Recent years have seen both renewed interests and investigations into Epidemic Routing for vehicular and satellite communications, and the development of a new Internet architecture Named Data Networking (NDN) which, due to its data-centric design, can support DTN communications natively. In this paper, we identify the basic functionality requirements for DTN support, compare and contrast ER and NDN to show the commonalities and differences in their designs. We use simulation results to illustrate how the design differences lead to different functionalities and protocol performance: although ER enhances IP nodes with data-centric features to enable packet delivery in DTN environments, compared to NDN's native data-centric design with built-in security, such “patch-on” suffers from not only lower performance with higher overhead, but more importantly the lack of systematic security support.",data centric architecture,31,not included
http://arxiv.org/abs/1705.04958v1,to_check,arxiv,arxiv,2017-05-14 00:00:00,arxiv,a proposed architecture for big data driven supply chain analytics,http://arxiv.org/abs/1705.04958v1,"Advancement in information and communication technology (ICT) has given rise
to explosion of data in every field of operations. Working with the enormous
volume of data (or Big Data, as it is popularly known as) for extraction of
useful information to support decision making is one of the sources of
competitive advantage for organizations today. Enterprises are leveraging the
power of analytics in formulating business strategy in every facet of their
operations to mitigate business risk. Volatile global market scenario has
compelled the organizations to redefine their supply chain management (SCM). In
this paper, we have delineated the relevance of Big Data and its importance in
managing end to end supply chains for achieving business excellence. A Big
Data-centric architecture for SCM has been proposed that exploits the current
state of the art technology of data management, analytics and visualization.
The security and privacy requirements of a Big Data system have also been
highlighted and several mechanisms have been discussed to implement these
features in a real world Big Data system deployment in the context of SCM. Some
future scope of work has also been pointed out. Keyword: Big Data, Analytics,
Cloud, Architecture, Protocols, Supply Chain Management, Security, Privacy.",data centric architecture,32,included
10.1016/j.future.2021.06.020,to_check,core,'Elsevier BV',2023-06-19 00:00:00,core,a big data-centric architecture metamodel for industry 4.0,,"The effective implementation of Industry 4.0 requires the reformulation of industrial processes in order to achieve the vertical and horizontal digitalization of the value chain. For this purpose, it is necessary to provide tools that enable their successful implementation. This paper therefore proposes a data-centric, distributed, dynamically scalable reference architecture that integrates cutting-edge technologies being aware of the existence of legacy technology typically present in these environments. In order to make its implementation easier, we have designed a metamodel that collects the description of all the elements involved in a digital platform (data, resources, applications and monitoring metrics) as well as the necessary information to configure, deploy and execute applications on it. Likewise, we provide a tool compliant to the metamodel that automates the generation of configuration, deployment and launch files and their corresponding transference and execution in the nodes of the platform. We show the flexibility, extensibility and validity of our software artefacts through their application in two case studies, one addressed to preprocess and store pollution data and the other one, more complex, which simulates the management of an electric power distribution of a smart city",data centric architecture,33,included
10.2514/6.2012-549,to_check,core,,2012-01-01 00:00:00,core,towards a unified framework using cpacs for geometry management in aircraft design,,"The performance requirements for the next generations of airliners are stringent and

require invention and design of unconventional configurations departing from the classical

Cayley functional decomposition. The break with tradition calls for higher fidelity physics-

based predictions of performance early on in the project. The paper makes the case for a

unified, open, data-centric software environment for aircraft design and describes the merge

of the CEASIOM conceptual design software package, developed by a number of partners

including KTH, with the CPACS formalized data management system developed at DLR.

The system provides multi-fidelity and multi-disciplinary analysis capabilities for concur-

rent design by geographically distributed expert teams. The data-centric architecture uses

the CPACS schema and access mechanisms for management of design data across all dis-

ciplines and fidelity levels. This makes the system extensible and mitigates the problems

encountered in handing over the model to later design phases. The concepts have been

tested by interfacing external modules to CEASIOM/CPACS through a graphical CPACS

XML editor, the ACbuilder gateway. Results of comparative analyses on models imported

in this way from the RDS and VAMPzero conceptual design packages are reported here.

CPACS will be released to the general public in spring ’12. The CEASIOM team expe-

rience of joining forces via CPACS with DLR is altogether positive and further in-house

development of software for aircraft performance prediction and design by the CEASIOM

team will use the CPACS system",data centric architecture,34,included
10.1002/dac.2964,to_check,core,"John Wiley & Sons, Inc.",2017-01-01 00:00:00,core,push applications and dynamic content generation over content-centric networking,,"Content-Centric Networking (CCN) represents an established candidate for the future Internet, proposing a routing architecture designed to elevate content to first class entity. Starting from the fact that the network usage has dramatically evolved towards content retrieval, CCN relies on an on-demand pull based mechanism to transfer data from the different sources to the heterogeneous consumers. This paradigm enhances the network in a number of ways, ranging from the newly introduced in-network caching capabilities to the benefits provided by the symmetric data routing adopted by CCN. In this renewed network scenario, we place our attention to those applications that do not perfectly fit the pull paradigm, stating that they need to be supported as well and proposing an effective way to achieve scalability on large scale push applications. We provide the following contributions: (i) we identify the functions that a data-centric architecture should support; (ii) propose and compare our solution with the state of the art framework designed for the specific problem of pushing data to content requesters; and (iii) evaluate their performance in terms of traffic generated and scalability achieved by simulating a real Internet Service Provider (ISP) topology and the realistic workload of a generic social network application",data centric architecture,35,included
10.1109/i-span.2009.67,to_check,"2009 10th International Symposium on Pervasive Systems, Algorithms, and Networks",IEEE,2009-12-16 00:00:00,ieeexplore,a data-driven architecture for remote control of sensors over a wireless sensor network and the internet,https://ieeexplore.ieee.org/document/5381871/,"This study revealed an applicable architecture in which a data-driven mechanism was designed to bridge a wireless sensor network (WSN) and the Internet. The system was divided into two independent parts. The first part is the data communication between the sensor network and the database. The other part is the data communication between the database and the user interface (UI). These two parts are connected by the database server. Asynchronous interoperation was introduced while exchanging data between these two parts. Users were not allowed to control the sensors through direct connection to the sensors and can only use the Web service to update the sensor profile built in the database. The sensors were triggered to start the action through a data-update event from the database. A sensor profile built in the database collected all sensor information and all user control command. For the information to be centralized and triggered by the database, regardless of whether sensors were measured in a periodic sampling or an event-driven environment, all sensor actions were triggered through a data-update event in the database. For the sake of improving user experience, a Web-based UI was implemented using scalable vector graphics (SVG) and Ajax technologies. All operations by users were conducted through the Hypertext Transfer Protocol (HTTP) standard method. Therefore, this system can be used via a browser and easily deployed. The proposed architecture is suitable for a healthcare system, a personal body area network, and the Infranet for control.",data driven architecture,36,included
10.1109/sensors47125.2020.9278616,to_check,2020 IEEE SENSORS,IEEE,2020-10-28 00:00:00,ieeexplore,a data-driven architecture for sensor validation based on neural networks,https://ieeexplore.ieee.org/document/9278616/,"In this paper, we propose a novel sensor validation architecture, which performs sensor fault detection, isolation and accommodation (SFDIA). More specifically, a machine-learning based architecture is presented to detect faults in sensors measurements within the system, identify the faulty ones and replace them with estimated values. In our proposed architecture, sensor estimators based on neural networks are constructed for each sensor node in order to accommodate faulty measurements along with a classifier to determine the failure detection and isolation. Finally, numerical results are presented to confirm the effectiveness of the proposed architecture on a publicly-available air quality (AQ) chemical multi-sensor data-set.",data driven architecture,37,not included
10.1109/bigcomp51126.2021.00080,to_check,2021 IEEE International Conference on Big Data and Smart Computing (BigComp),IEEE,2021-01-20 00:00:00,ieeexplore,a modular data-driven architecture for empathetic conversational agents,https://ieeexplore.ieee.org/document/9373265/,"Empathy is a fundamental mechanism of human interactions. As such, it should be an integral part of Human-Computer Interaction systems to make them more relatable. With this work, we focused on conversational scenarios where integrating empathy is crucial to perceive the computer like a human. As a result, we derived the high-level architecture of an Empathetic Conversational Agent we are willing to implement. We relied on theories about artificial empathy to derive the function approximating this mechanism and selected the conversational aspects to control for an empathetic interaction. In particular, we designed a core empathetic controller manages the empathetic responses, predicting, at each turn, the high-level content of the response. The derived architecture integrates empathy in a task-agnostic manner; hence we can employ it in multiple scenarios by changing the objective of the controller.",data driven architecture,38,not included
10.1109/lra.2019.2896485,to_check,IEEE Robotics and Automation Letters,IEEE,2019-04-01 00:00:00,ieeexplore,learning from humans how to grasp: a data-driven architecture for autonomous grasping with anthropomorphic soft hands,https://ieeexplore.ieee.org/document/8629968/,"Soft hands are robotic systems that embed compliant elements in their mechanical design. This enables an effective adaptation with the items and the environment, and ultimately, an increase in their grasping performance. These hands come with clear advantages in terms of ease-to-use and robustness if compared with classic rigid hands, when operated by a human. However, their potential for autonomous grasping is still largely unexplored, due to the lack of suitable control strategies. To address this issue, in this letter, we propose an approach to enable soft hands to autonomously grasp objects, starting from the observations of human strategies. A classifier realized through a deep neural network takes as input the visual information on the object to be grasped, and predicts which action a human would perform to achieve the goal. This information is hence used to select one among a set of human-inspired primitives, which define the evolution of the soft hand posture as a combination of anticipatory action and touch-based reactive grasp. The architecture is completed by the hardware component, which consists of an RGB camera to look at the scene, a 7-DoF manipulator, and a soft hand. The latter is equipped with inertial measurement units at the fingernails for detecting contact with the object. We extensively tested the proposed architecture with 20 objects, achieving a success rate of 81.1% over 111 grasps.",data driven architecture,39,not included
10.1109/nssmic.1998.775181,to_check,1998 IEEE Nuclear Science Symposium Conference Record. 1998 IEEE Nuclear Science Symposium and Medical Imaging Conference (Cat. No.98CH36255),IEEE,1998-11-14 00:00:00,ieeexplore,a 16-channel digital tdc chip,https://ieeexplore.ieee.org/document/775181/,"A 16-channel digital TDC chip has been built for the DIRC Cerenkov counter of the BaBar experiment at the SLAC B-factory (Stanford, USA). The binning is 0.5 ns and the full-scale 32 microseconds. The data driven architecture integrates channel buffering and selective readout of data falling within a programmable time window. The linearity is better than 80 ps rms on 90% of the production parts.",data driven architecture,40,not included
10.1109/emwrts.1996.557821,to_check,Proceedings of the Eighth Euromicro Workshop on Real-Time Systems,IEEE,1996-06-14 00:00:00,ieeexplore,an embedded accelerator for real-time image processing,https://ieeexplore.ieee.org/document/557821/,"The paper presents an embedded reconfigurable accelerator called Xputer, comprising a novel kind of sequencer hardware (data sequencer). For many real-time signal processing, multimedia, and other high-performance applications this new data-driven architecture increases the performance of a single processor system enormously by integrating it as a co-processor for accelerating computation-intensive parts of an application. The reconfigurable architecture and programming environment is described. Its use is illustrated with an automotive application requiring real-time image processing.",data driven architecture,41,not included
10.1109/geoinformatics.2010.5567735,to_check,2010 18th International Conference on Geoinformatics,IEEE,2010-06-20 00:00:00,ieeexplore,an integrated spatio-temporal modeling and analysis framework for climate change research,https://ieeexplore.ieee.org/document/5567735/,"Net primary productivity (NPP) estimation is an important study field of global change and terrestrial ecosystem. Here, we present an integrated modeling and analysis framework for researching climate change using NPP as an ecosystem indicator. It's brings together remote sensing, GIS and an ecosystem simulation model without requiring users to have any knowledge of any other specific software. Satellite data driven architecture can play a positive role in understanding the climate change and carbon cycles from regional to global scales. The benefit of the framework is that it provides complete spatial coverage and high temporal resolution, versus plot samples from which it may be difficult to provide an overall assessment for large-scale study. Recent advances in service-oriented architectures are allowing us to share of model results by geospatial services and create distributed applications needed for the collaborative research. Multi-layer approaches allow the framework more flexible and easy to extend. New datasets and models can be integrated for use in the development of new applications. A preliminary system based on the framework was carried out for monitoring the dynamic changes of terrestrial ecosystem NPP in China. State-of-the art processing algorithms was developed based on light-use efficiency model (Carnegie-Ames-Stanford Approach (CASA) model). Fraction of photosynthetically active radiation absorbed by vegetation (FPAR) is a linear function of Normalized Difference Vegetation Index (NDVI) and Simple Ratio vegetation index (SR). We combined the method of NDVI and SR together to compute the FPAR of China. And then, the NPP time-series of Chinese terrestrial vegetation is built. The System is capable of querying, retrieving, and visualizing datasets with heterogeneous formats and the spatio-temporal analysis revealed the relationship between NPP and climatic change in China. These results supported national trends of NPP in relation to lag effects of climate.",data driven architecture,42,not included
10.1109/fpt.2010.5681493,to_check,2010 International Conference on Field-Programmable Technology,IEEE,2010-12-10 00:00:00,ieeexplore,automatic synthesis of processor arrays with local memories on fpgas,https://ieeexplore.ieee.org/document/5681493/,"In this paper, we present an automatic synthesis framework to map loop nests to processor arrays with local memories on FPGAs. An affine transformation approach is firstly proposed to address space-time mapping problem. Then a data-driven architecture model is introduced to enable automatic generation of processor arrays by extracting this data-driven architecture model from transformed loop nests. Some techniques including memory allocation, communication generation and control generation are presented. Synthesizable RTL codes can be easily generated from the architecture model built by these techniques. A preliminary synthesis tool is implemented based on PLUTO, an automatic polyhedral source-to-source transformation and parallelization framework.",data driven architecture,43,not included
10.1109/icws.2008.147,to_check,2008 IEEE International Conference on Web Services,IEEE,2008-09-26 00:00:00,ieeexplore,common business components and services toward more agile and flexible industry solutions and assets,https://ieeexplore.ieee.org/document/4670150/,"In many decades, many organizations, especially large consulting companies, have been designing, implementing and managing business solutions for every industry around the globe. But due to numerous limitations in process, tooling and skills, most of those solutions were made very specific to individual industry and client needs at its early design stage. Therefore, reuse and more importantly, managing the ever changing business requirements, become almost impossible. Service-orientation and architecture, model-driven business development provides us a new and powerful approach to facilitate asset based industry solution design and development. To further accelerate this, this tutorial will discuss an innovative approach that take advantage of many proven best software engineering practices, from object/component based technology, meta-data driven architecture types (archetypes) that are used to model the common structural and in some cases non-structural business entities such as customer, product, payment, etc. In order to address the consequences introduced by abstracting those common elements out of the specific industry model and be able to enable easy and meta-data based transformation, we properly decompose business components/services into a multi-layered business architecture. Therefore, process/components/services can be decomposed accordingly to facilitate the decomposition and abstraction, while maintaining certain level of necessary traceability across various artifacts. In the realization phase, existing assets/operational systems will be mapped and transformed to the required business components and services to best leverage those existing valuable industry/client investments. To support such a SOA based, model and business driven development process, existing tooling, especially the necessary transformation and integration capability, needs to be significantly enhanced. This tutorial will also present some recommendation based on some recent design and implementation, and they could be used to guide future tooling alignment and integration effort across software modeling, implementation and solution products. In addition, we will present how to leverage existing internal or external assets or product offerings and the open industry reference models and standards (such as ACCORD, ebXML, ARTS/IxRetail). This work is based on authors' collective experience in leading the large end-to-end client engagements across many industries, while promoting various industry leading software engineering best practices.",data driven architecture,44,not included
10.1109/tina.1997.660723,to_check,Proceedings TINA '97 - Global Convergence of Telecommunications and Distributed Object Computing,IEEE,1997-11-20 00:00:00,ieeexplore,data-driven implementation of tina kernel transport network,https://ieeexplore.ieee.org/document/660723/,"To realize the actual TINA-based telecommunications network, the performance of the kernel Transport Network (kTN) such as availability, reliability, throughput and load tolerance becomes more crucial than for existing computer networks. The authors have been studying and developing a super-integrated data-driven processor to be applied to the TINA kTN nodes and network interfaces in CUE (Coordinating Users' requirements and Engineering constraints) project. Since the processor is primarily designed to be a scalable VLSI component, it is easily interconnected to form a super-integrated chip and multi-chip system for achieving the performance and reliability demanded in a TINA environment. We first examine the requirements for kTN. A stream-oriented data-driven architecture is then proposed with special emphasis on effective multiprocessing capability with overload tolerance. After that, we demonstrate that autonomous load balancing among super-integrated data-driven processors without adding any runtime overhead to achieve effective and reliable multiprocessing is possible by utilizing the overload tolerance of the processor. Finally, this paper shows preliminary performance estimations of the super-integrated data-driven processor being developed to perform efficient multiprocessing in protocol handling such as TCP/IP.",data driven architecture,45,included
10.1109/sam48682.2020.9104367,to_check,2020 IEEE 11th Sensor Array and Multichannel Signal Processing Workshop (SAM),IEEE,2020-06-11 00:00:00,ieeexplore,deep radar waveform design for efficient automotive radar sensing,https://ieeexplore.ieee.org/document/9104367/,"In radar systems, unimodular (or constant-modulus) waveform design plays an important role in achieving better clutter/interference rejection, as well as a more accurate estimation of the target parameters. The design of such sequences has been studied widely in the last few decades, with most design algorithms requiring sophisticated a priori knowledge of environmental parameters which may be difficult to obtain in real-time scenarios. In this paper, we propose a novel hybrid model-driven and data-driven architecture that adapts to the ever changing environment and allows for adaptive unimodular waveform design. In particular, the approach lays the groundwork for developing extremely low-cost waveform design and processing frameworks for radar systems deployed in autonomous vehicles. The proposed model-based deep architecture imitates a wellknown unimodular signal design algorithm in its structure, and can quickly infer statistical information from the environment using the observed data. Our numerical experiments portray the advantages of using the proposed method for efficient radar waveform design in time-varying environments.",data driven architecture,46,not included
10.1109/nssmic.2004.1466709,to_check,IEEE Symposium Conference Record Nuclear Science 2004.,IEEE,2004-10-22 00:00:00,ieeexplore,design and evaluation of the clear-pem detector for positron emission mammography,https://ieeexplore.ieee.org/document/1466709/,"The design and evaluation of the imaging system Clear-PEM for positron emission mammography, under development by the PEM Consortium within the framework of the Crystal Clear Collaboration at CERN, is presented. The proposed apparatus is based on fast, segmented, high atomic number radiation sensors with depth-of-interaction measurement capabilities and state-of-the-art data acquisition techniques. The camera consists of two compact and planar detector heads with adequate field-of-view dimensions for breast and axilla imaging. Low-noise integrated electronics provide signal amplification and analog multiplexing based on a new data-driven architecture. The coincidence trigger and data acquisition architecture makes extensive use of pipeline processing structures and multi-event memories for high efficiency up to a data acquisition rate of one million events/s. Experimental validation of the detection techniques, namely the basic properties of the radiation sensors and the ability to measure the depth-of-interaction of the incoming photons, are presented. System performance in terms of detection sensitivity, count-rates and reconstructed image spatial resolution were also evaluated by means of a detailed Monte Carlo simulation and an iterative image reconstruction algorithm.",data driven architecture,47,included
10.1109/cac.2017.8244168,to_check,2017 Chinese Automation Congress (CAC),IEEE,2017-10-22 00:00:00,ieeexplore,design and implementation of data-driven based universal data editing framework,https://ieeexplore.ieee.org/document/8244168/,"Apply Integrated Logistics Support (ILS) to weapon equipment can efficiently improve equipment's automation and digital level. ILS needs support of various integrated support systems, which have demands for data editing. Nowadays, most of data editing software used in these systems are customized and provide a form-based editing approach, which becomes an obstacle to carry out ILS. This paper brings forward to design a data-driven based universal data editing framework. In this framework, data models are taken as input and only corresponding data models need to be modified when data change. Firstly, the whole development process of data editing software that adopt form-based development mode is analyzed in detail to find out problems exists in this development mode. Then the data-driven based universal data editing framework is designed. New idea of data-driven architecture is proposed. Data-driven architecture takes data models as input and processes all data models in a universal way. Finally, key technology for framework realization is given.",data driven architecture,48,included
10.1109/nssmic.2000.949945,to_check,2000 IEEE Nuclear Science Symposium. Conference Record (Cat. No.00CH37149),IEEE,2000-10-20 00:00:00,ieeexplore,error handling for the cdf silicon vertex tracker,https://ieeexplore.ieee.org/document/949945/,"The SVT online tracker for the CDF upgrade reconstructs two-dimensional tracks using information from the Silicon Vertex detector (SVXII) and the Central Outer Tracker (COT). The SVT has an event rate of 100 kHz and a latency time of 10 /spl mu/s. The system is composed of 104 VME 9U digital boards (of 8 different types) and it is implemented as a data driven architecture. Each board runs on its own 30 MHz clock. Since the data output from the SVT (few Mbytes/sec) are a small fraction of the input data (200 Mbytes/sec), it is extremely difficult to track possible internal errors by using only the output stream. For this reason several diagnostic tools have been implemented: local error registers, error bits propagated through the data streams and the Spy Buffer system. Data flowing through each input and output stream of every board are continuously copied to memory banks named Spy Buffers which act as built in logic state analyzers hooked continuously to internal data streams. The contents of all buffers can be frozen at any time (e.g. on error detection) to take a snapshot of all data flowing through each SVT board. The Spy Buffers are coordinated at system level by the Spy Control Board. The architecture, design and implementation of this system are described.",data driven architecture,49,included
10.1109/isit45174.2021.9517812,to_check,2021 IEEE International Symposium on Information Theory (ISIT),IEEE,2021-07-20 00:00:00,ieeexplore,model-inspired deep detection with low-resolution receivers,https://ieeexplore.ieee.org/document/9517812/,"The need to recover high-dimensional signals from their noisy low-resolution quantized measurements is widely encountered in communications and sensing. In this paper, we focus on the extreme case of one-bit quantizers, and propose a deep detector network, called LoRD-Net, for signal recovering from one-bit measurements. Our approach relies on a model-aware data-driven architecture, based on a deep unfolding of first-order optimization iterations. LoRD-Net has a task-based architecture dedicated to recovering the underlying signal of interest from the one-bit noisy measurements without requiring prior knowledge of the channel matrix through which the one-bit measurements are obtained. The proposed deep detector has much fewer parameters compared to black-box deep networks due to the incorporation of domain-knowledge in the design of its architecture, allowing it to operate in a data-driven fashion while benefiting from the flexibility, versatility, and reliability of model-based optimization methods. We numerically evaluate the proposed receiver architecture for one-bit signal recovery in wireless communications and demonstrate that the proposed hybrid methodology outperforms both data-driven and model-based state-of-the-art methods, while utilizing small datasets, on the order of merely ~ 500 samples, for training.",data driven architecture,50,not included
10.1109/icc42927.2021.9500961,to_check,ICC 2021 - IEEE International Conference on Communications,IEEE,2021-06-23 00:00:00,ieeexplore,removing channel estimation by location-only based deep learning for ris aided mobile edge computing,https://ieeexplore.ieee.org/document/9500961/,"In this paper, we investigate a deep learning architecture for lightweight online implementation of a reconfigurable intelligent surface (RIS)-aided multi-user mobile edge computing (MEC) system, where the optimized performance can be achieved based on user equipment’s (UEs’) location-only information. Assuming that each UE is endowed with a limited energy budget, we aim at maximizing the total completed task-input bits (TCTB) of all UEs within a given time slot, through jointly optimizing the RIS reflecting coefficients, the receive beamforming vectors, and UEs’ energy partition strategies for local computing and computation offloading. Due to the coupled optimization variables, a three-step block coordinate descending (BCD) algorithm is first proposed to effectively solve the formulated TCTB maximization problem iteratively with guaranteed convergence. The location-only deep learning architecture is then constructed to emulate the proposed BCD optimization algorithm, through which the pilot channel estimation and feedback can be removed for online implementation with low complexity. The simulation results reveal a close match between the performance of the BCD optimization algorithm and the location-only data-driven architecture, all with superior performance to existing benchmarks.",data driven architecture,51,not included
10.1109/30.982782,to_check,IEEE Transactions on Consumer Electronics,IEEE,2001-11-01 00:00:00,ieeexplore,a novel hdtv video decoder and decentralized control scheme,https://ieeexplore.ieee.org/document/982782/,"A novel dedicated architecture for an HDTV video decoding chip is developed. Each task is mapped to a highly optimized hardware unit by classifying the video processing tasks into three levels. On the function level, a data driven architecture is adopted to make each processing unit operate once the processing data and buffer are available. Therefore the high computing efficiency of each unit is exploited, hardware is saved, and the computing capability is maximized compared with conventional pipeline decoder. On the system level, a decentralized control scheme is designed to provide high efficient communication between all the processing units to yield the best overall performance. Moreover it features simple control logic and minimum size of the connecting buffers.",data driven architecture,52,included
10.1109/tns.2006.870173,to_check,IEEE Transactions on Nuclear Science,IEEE,2006-02-01 00:00:00,ieeexplore,design and evaluation of the clear-pem scanner for positron emission mammography,https://ieeexplore.ieee.org/document/1610954/,"The design and evaluation of the imaging system Clear-PEM for positron emission mammography, under development by the PEM Consortium within the framework of the Crystal Clear Collaboration at CERN, is presented. The proposed apparatus is based on fast, segmented, high atomic number radiation sensors with depth-of-interaction measurement capabilities, and state-of-the-art data acquisition techniques. The camera consists of two compact and planar detector heads with dimensions 16.5/spl times/14.5 cm/sup 2/ for breast and axilla imaging. Low-noise integrated electronics provide signal amplification and analog multiplexing based on a new data-driven architecture. The coincidence trigger and data acquisition architecture makes extensive use of pipeline processing structures and multi-event memories for high efficiency up to a data acquisition rate of one million events/s. Experimental validation of the detection techniques, namely the basic properties of the radiation sensors and the ability to measure the depth-of-interaction of the incoming photons, are presented. System performance in terms of detection sensitivity, count-rates and reconstructed image spatial resolution were also evaluated by means of a detailed Monte Carlo simulation and an iterative image reconstruction algorithm.",data driven architecture,53,included
10.1109/access.2021.3071274,to_check,IEEE Access,IEEE,2021-01-01 00:00:00,ieeexplore,graph neural network: a comprehensive review on non-euclidean space,https://ieeexplore.ieee.org/document/9395439/,"This review provides a comprehensive overview of the state-of-the-art methods of graph-based networks from a deep learning perspective. Graph networks provide a generalized form to exploit non-euclidean space data. A graph can be visualized as an aggregation of nodes and edges without having any order. Data-driven architecture tends to follow a fixed neural network trying to find the pattern in feature space. These strategies have successfully been applied to many applications for euclidean space data. Since graph data in a non-euclidean space does not follow any kind of order, these solutions can be applied to exploit the node relationships. Graph Neural Networks (GNNs) solve this problem by exploiting the relationships among graph data. Recent developments in computational hardware and optimization allow graph networks possible to learn the complex graph relationships. Graph networks are therefore being actively used to solve many problems including protein interface, classification, and learning representations of fingerprints. To encapsulate the importance of graph models, in this paper, we formulate a systematic categorization of GNN models according to their applications from theory to real-life problems and provide a direction of the future scope for the applications of graph models as well as highlight the limitations of existing graph networks.",data driven architecture,54,not included
10.1109/tsp.2021.3117503,to_check,IEEE Transactions on Signal Processing,IEEE,2021-01-01 00:00:00,ieeexplore,lord-net: unfolded deep detection network with low-resolution receivers,https://ieeexplore.ieee.org/document/9557819/,"The need to recover high-dimensional signals from their noisy low-resolution quantized measurements is widely encountered in communications and sensing. In this paper, we focus on the extreme case of one-bit quantizers, and propose a deep detector entitled LoRD-Net for recovering information symbols from one-bit measurements. Our method is a model-aware data-driven architecture based on deep unfolding of first-order optimization iterations. LoRD-Net has a task-based architecture dedicated to recovering the underlying signal of interest from the one-bit noisy measurements without requiring prior knowledge of the channel matrix through which the one-bit measurements are obtained. The proposed deep detector has much fewer parameters compared to black-box deep networks due to the incorporation of domain-knowledge in the design of its architecture, allowing it to operate in a data-driven fashion while benefiting from the flexibility, versatility, and reliability of model-based optimization methods. LoRD-Net operates in a blind fashion, which requires addressing both the non-linear nature of the data-acquisition system as well as identifying a proper optimization objective for signal recovery. Accordingly, we propose a two-stage training method for LoRD-Net, in which the first stage is dedicated to identifying the proper form of the optimization process to unfold, while the latter trains the resulting model in an end-to-end manner. We numerically evaluate the proposed receiver architecture for one-bit signal recovery in wireless communications and demonstrate that the proposed hybrid methodology outperforms both data-driven and model-based state-of-the-art methods, while utilizing small datasets, on the order of merely <inline-formula><tex-math notation=""LaTeX"">$\sim 500$</tex-math></inline-formula> samples, for training.",data driven architecture,55,not included
10.1109/access.2021.3091716,to_check,IEEE Access,IEEE,2021-01-01 00:00:00,ieeexplore,modeling and key technologies of a data-driven smart city system,https://ieeexplore.ieee.org/document/9462829/,"The smart city operation and management center with a hierarchical data-driven architecture has already become one of the most widely used solutions for smart cities in practice, solving the problems associated with data acquisition, data gathering and storage, data processing, and data application. At present, the construction of smart city operation and management center faces bottlenecks such as incomplete top-level design theory, the insufficient integration capability of software and hardware, the low efficiency of data collection and aggregation, and the lack of intelligence in data analysis and application. Aiming to address the above problems, this paper proposes a `two-dimension, three-layer, and six-goal' top-level design model for a smart city, with six principles for a smart city operational pattern, and focuses on three key technologies: (1) infrastructure integration and application, (2) multidimensional perception data collection and aggregation, and (3) intelligent data analysis and data service. Following the guidance of this model, Longgang District of Shenzhen has constructed a smart city operation and management center including integrated ICT infrastructure, an urban fine management system, and an intelligent urban data analysis and service system. The actual effects and quantitative improvements in the practical case show that the top-level design model of a smart city proposed in this paper has achieved successful results, and it thereby offers an applicability model of a smart city that can be referenced and replicated.",data driven architecture,56,included
10.1109/tkde.2019.2953839,to_check,IEEE Transactions on Knowledge and Data Engineering,IEEE,2021-06-01 00:00:00,ieeexplore,open relation extraction for chinese noun phrases,https://ieeexplore.ieee.org/document/8903488/,"Relation Extraction (RE) aims at harvesting relational facts from texts. A majority of existing research targets at knowledge acquisition from sentences, where subject-verb-object structures are usually treated as the signals of existence of relations. In contrast, relational facts expressed within noun phrases are highly implicit. Previous works mostly relies on human-compiled assertions and textual patterns in English to address noun phrase-based RE. For Chinese, the corresponding task is non-trivial because Chinese is a highly analytic language with flexible expressions. Additionally, noun phrases tend to be incomplete in grammatical structures, where clear mentions of predicates are often missing. In this article, we present an unsupervised Noun Phrase-based Open RE system for the Chinese language (NPORE), which employs a three-layer data-driven architecture. The system contains three components, i.e., Modifier-sensitive Phrase Segmenter, Candidate Relation Generator and Missing Relation Predicate Detector. It integrates with a graph clique mining algorithm to chunk Chinese noun phrases, considering how relations are expressed. We further propose a probabilistic method with knowledge priors and a hypergraph-based random walk process to detect missing relation predicates. Experiments over Chinese Wikipedia show NPORE outperforms state-of-the-art, capable of extracting 55.2 percent more relations than the most competitive baseline, with a comparable precision at 95.4 percent.",data driven architecture,57,not included
10.1109/acc.2013.6580528,to_check,2013 American Control Conference,IEEE,2013-06-19 00:00:00,ieeexplore,data-driven design of kpi-related fault-tolerant control system for wind turbines,https://ieeexplore.ieee.org/document/6580528/,"In this paper, a scheme for an integrated design of fault-tolerant control (FTC) systems for a wind turbine benchmark is proposed, with focus on the overall performance of the system. For that a key performance indicator (KPI) which reflects the economic performance of the system is defined, and the objective of the proposed FTC scheme is to maintain the system KPI in the admissible range in faulty conditions. The basic idea behind this scheme is data-driven design of the proposed fault-tolerant architecture whose core is an observer/residual generator based realization of the Youla parameterization of all stabilizing controllers with an embedded residual generator for fault detection (FD) purpose. The performance and effectiveness of the proposed scheme are demonstrated through the wind turbine benchmark model proposed in [1].",data driven architecture,58,not included
10.23919/acc50511.2021.9482806,to_check,2021 American Control Conference (ACC),IEEE,2021-05-28 00:00:00,ieeexplore,direct data-driven design of switching controllers for constrained systems,https://ieeexplore.ieee.org/document/9482806/,"This paper presents a hierarchical structure to directly design controllers for (possibly nonlinear) constrained systems. The proposed architecture combines the advantages of an inner data-driven switching controller designed to achieve a predefined closed-loop behavior and an outer model predictive controller, which is used as a reference governor. These design choices enable us to avoid the identification step typical of model-based approaches while exploiting the ability of model predictive controllers to handle constraints and optimize the closed-loop performance. As a proof of concept, a benchmark simulation example is used to demonstrate the effectiveness of the proposed strategy.",data driven architecture,59,not included
10.1109/tii.2018.2843124,to_check,IEEE Transactions on Industrial Informatics,IEEE,2018-10-01 00:00:00,ieeexplore,data-driven design of fog-computing-aided process monitoring system for large-scale industrial processes,https://ieeexplore.ieee.org/document/8370742/,"Stimulated by the recent development of fog computing technology, in this paper, a fog-computing-aided process monitoring and control architecture is proposed for large-scale industrial processes, which enables reliable and efficient online performance optimization in each fog computing node without modifying predesigned control subsystems. Moreover, a closed-loop data-driven method is developed for the process monitoring system design and an adaptive configuration approach is proposed to deal with the problems caused by the changes of process parameters and operating points. The feasibility and effectiveness of the proposed design approaches are verified and demonstrated through the case study on the Tennessee Eastman benchmark system.",data driven architecture,60,not included
10.1109/spawc51858.2021.9593131,to_check,2021 IEEE 22nd International Workshop on Signal Processing Advances in Wireless Communications (SPAWC),IEEE,2021-09-30 00:00:00,ieeexplore,fast power control adaptation via meta-learning for random edge graph neural networks,https://ieeexplore.ieee.org/document/9593131/,"Power control in decentralized wireless networks poses a complex stochastic optimization problem when formulated as the maximization of the average sum rate for arbitrary interference graphs. Recent work has introduced data-driven design methods that leverage graph neural network (GNN) to efficiently parametrize the power control policy mapping channel state information (CSI) to the power vector. The specific GNN architecture, known as random edge GNN (REGNN), defines a non-linear graph convolutional architecture whose spatial weights are tied to the channel coefficients, enabling a direct adaption to channel conditions. This paper studies the higher-level problem of enabling fast adaption of the power control policy to time-varying topologies. To this end, we apply first-order meta-learning on data from multiple topologies with the aim of optimizing for a few-shot adaptation to new network configurations.",data driven architecture,61,not included
10.1109/tie.2013.2273477,to_check,IEEE Transactions on Industrial Electronics,IEEE,2014-05-01 00:00:00,ieeexplore,real-time implementation of fault-tolerant control systems with performance optimization,https://ieeexplore.ieee.org/document/6560360/,"In this paper, two online schemes for an integrated design of fault-tolerant control (FTC) systems with application to Tennessee Eastman (TE) benchmark are proposed. Based on the data-driven design of the proposed fault-tolerant architecture whose core is an observer/residual generator based realization of the Youla parameterization of all stabilization controllers, FTC is achieved by an adaptive residual generator for the online identification of the fault diagnosis relevant vectors, and an iterative optimization method for system performance enhancement. The performance and effectiveness of the proposed schemes are demonstrated through the TE benchmark model.",data driven architecture,62,not included
10.1007/s10845-018-1430-y,to_check,Journal of Intelligent Manufacturing,Springer,2020-01-01 00:00:00,springer,"a data-driven cyber-physical approach for personalised smart, connected product co-development in a cloud-based environment",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10845-018-1430-y,"The rapid development of information and communication technology enables a promising market of information densely product, i.e. smart, connected product (SCP), and also changes the way of user–designer interaction in the product development process. For SCP, massive data generated by users drives its design innovation and somehow determines its final success. Nevertheless, most existing works only look at the new functionalities or values that are derived in the one-way communication by introducing novel data analytics methods. Few work discusses about an effective and systematic approach to enable individual user innovation in such context, i.e. co-development process, which sets the fundamental basis of the prevailing concept of data-driven design. Aiming to fill this gap, this paper proposes a generic data-driven cyber-physical approach for personalised SCP co-development in a cloud-based environment. A novel concept of smart, connected, open architecture product is hence introduced with a generic cyber-physical model established in a cloud-based environment, of which the interaction processes are enabled by co-development toolkits with smartness and connectedness. Both the personalized SCP modelling method and the establishment of its cyber-physical product model are described in details. To further demonstrate the proposed approach, a case study of a smart wearable device (i.e. i-BRE respiratory mask) development process is given with general discussions.",data driven architecture,63,included
10.1007/978-3-319-75429-1_18,to_check,Integrated Uncertainty in Knowledge Modelling and Decision Making,Springer,2018-01-01 00:00:00,springer,big data driven architecture for medical knowledge management systems in intracranial hemorrhage diagnosis,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-75429-1_18,"Stroke is the most common and dangerous cerebrovascular disease. According to the statistics from World Health Organization (WHO), only following heart attack, stroke is one of the two leading causes of human deaths. In addition, in Vietnam, a shortage of specialized equipment and qualified professionals is becoming a significant problem for not only accurate diagnosis but also timely and effective treatment of stroke, especially intracranial hemorrhage (ICH), an acute case of stroke. This research will analyze challenges and show solutions for constructing an effective knowledge system in ICH diagnosis and treatment that helps to shorten professional gap among hospitals and regions. We suggest a service-oriented architecture for the big data driven knowledge system based on medical imaging of ICH. The architecture ensures the development of knowledge obeying a systematic and complete process including the exploration and exploitation of knowledge from medical imaging. Besides, the architecture adapts to modern trends in knowledge service modeling.",data driven architecture,64,included
10.1007/978-3-319-07863-2_21,to_check,Human Interface and the Management of Information. Information and Knowledge in Applications and Services,Springer,2014-01-01 00:00:00,springer,data driven enterprise ux: a case study of enterprise management systems,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-07863-2_21,"This paper describes and makes a case for a data driven user experience design process for Enterprise IT. The method described employs an approach that focuses on defining the key modules (objects) in an enterprise IT software and the data sets used by these modules very early in the design process. We discuss how mapping parent child relationships between key entities in the software and the linked data helps create a holistic view of the product ecosystem which in turn allows the designer to create an uncluttered information architecture and user journey that maps closely to mental construct of the system in the user’s mind. We further argue that in the present age of big data, working with well-defined data sets and visible data relationships creates a valuable information repository for the designer to take decisions regarding task optimization and building business intelligence in the system itself. We also discuss the urgent need, advantages and methods of ‘consumerizing’ the Enterprise UI to increase users productivity and reduce the learning curve. Lastly, these ideas are exemplified through a real life case study for an enterprise server management system.",data driven architecture,65,not included
10.1007/978-3-642-39200-9_5,to_check,Web Engineering,Springer,2013-01-01 00:00:00,springer,semantic data driven interfaces for web applications,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-39200-9_5,"Modern day interfaces must deal with a large number of heterogeneity factors, such as varying user profiles and runtime hardware and software platforms. These conditions require interfaces that can adapt to the changes in the <user, platform, environment> triad. The Model-Based User Interface approach has been proposed as a way to deal with these requirements. In this paper we present a data-driven, rule-based interface definition model capable of taking into account the semantics of the data it is manipulating, especially in the case of Linked Data. An implementation architecture based on the Synth environment supporting this model is presented.",data driven architecture,66,included
10.1007/978-3-642-23333-3_4,to_check,Electronic Participation,Springer,2011-01-01 00:00:00,springer,combining social and government open data for participatory decision-making,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-23333-3_4,"In the last years, several research endeavors were launched aiming at involving popular social media platforms in electronic participation. These early endeavors seem to present some essential limitations related mainly to scalability and uptake. In order to avoid these limitations, we introduce a two-phased approach for supporting participatory decision-making based on the integration and analysis of social and government open data. The proposed approach is based on the literature related to the analysis of massive amounts of social data for future events prediction. In this paper we also present a Web data driven architecture for the implementation of the proposed approach. The architecture is based on the use of linked data paradigm as a layer that will enable integration of data from different sources. We anticipate that the proposed approach will (i) allow decision makers to understand and predict public opinion and reaction about specific decisions; and (ii) enable citizens to inadvertently contribute in decision-making.",data driven architecture,67,not included
10.1007/978-3-642-04492-2_21,to_check,Management Enabling the Future Internet for Changing Business and New Computing Services,Springer,2009-01-01 00:00:00,springer,the proposal of service delivery platform built on distributed data driven architecture,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-04492-2_21,"SDP (Service Delivery Platform) is a recommended system platform for NGN (Next Generation Network) that is expected to resolve two common system running problems: one is functional aspects such as high availability and providing effective maintenance methods, the other is cost aspects such as simplifying development method of a service. However, SDP is still on the way to be standardized, and its architecture has two problems: the congestion of service requests and flexibility of enabler, a service component of SDP. This paper explains how to build a SDP by adopting Distributed Data Driven Architecture and how our system resolves the problems by evaluating the prototype.",data driven architecture,68,included
10.1007/978-94-015-8196-7_6,to_check,Linear Algebra for Large Scale and Real-Time Applications,Springer,1993-01-01 00:00:00,springer,a parallel image rendering algorithm and architecture based on ray tracing and radiosity shading,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-94-015-8196-7_6,"Algorithms for rendering color scenes on a video screen potentially belong to the class of massively parallel algorithms. Developing effective and efficient data-driven architectures for algorithms from this class is in general a hard problem. However, in case of application specific algorithms, such as the rendering algorithm described in this paper, feasible solutions are conceivable. The parallel algorithm/architecture presented in this paper is a linear speed-up accelerator for the rendering of photo realistic scenes in interaction time.",data driven architecture,69,included
http://arxiv.org/abs/2202.07448v1,to_check,arxiv,arxiv,2022-02-04 00:00:00,arxiv,"towards a unified pandemic management architecture: survey, challenges
  and future directions",http://arxiv.org/abs/2202.07448v1,"The pandemic caused by SARS-CoV-2 has left an unprecedented impact on health,
economy and society worldwide. Emerging strains are making pandemic management
increasingly challenging. There is an urge to collect epidemiological,
clinical, and physiological data to make an informed decision on mitigation
measures. Advances in the Internet of Things (IoT) and edge computing provide
solutions for pandemic management through data collection and intelligent
computation. While existing data-driven architectures attempt to automate
decision-making, they do not capture the multifaceted interaction among
computational models, communication infrastructure, and the generated data. In
this paper, we perform a survey of the existing approaches for pandemic
management, including online data repositories and contact-tracing
applications. We then envision a unified pandemic management architecture that
leverages the IoT and edge computing to automate recommendations on vaccine
distribution, dynamic lockdown, mobility scheduling and pandemic prediction. We
elucidate the flow of data among the layers of the architecture, namely, cloud,
edge and end device layers. Moreover, we address the privacy implications,
threats, regulations, and existing solutions that may be adapted to optimize
the utility of health data with security guarantees. The paper ends with a
lowdown on the limitations of the architecture and research directions to
enhance its practicality.",data driven architecture,70,included
http://arxiv.org/abs/2110.09005v1,to_check,arxiv,arxiv,2021-10-18 00:00:00,arxiv,unsupervised learned kalman filtering,http://arxiv.org/abs/2110.09005v1,"In this paper we adapt KalmanNet, which is a recently pro-posed deep neural
network (DNN)-aided system whose architecture follows the operation of the
model-based Kalman filter (KF), to learn its mapping in an unsupervised manner,
i.e., without requiring ground-truth states. The unsupervised adaptation is
achieved by exploiting the hybrid model-based/data-driven architecture of
KalmanNet, which internally predicts the next observation as the KF does. These
internal features are then used to compute the loss rather than the state
estimate at the output of the system. With the capability of unsupervised
learning, one can use KalmanNet not only to track the hidden state, but also to
adapt to variations in the state space (SS) model. We numerically demonstrate
that when the noise statistics are unknown, unsupervised KalmanNet achieves a
similar performance to KalmanNet with supervised learning. We also show that we
can adapt a pre-trained KalmanNet to changing SS models without providing
additional data thanks to the unsupervised capabilities.",data driven architecture,71,not included
http://arxiv.org/abs/2108.13178v1,to_check,arxiv,arxiv,2021-08-04 00:00:00,arxiv,"black-box and modular meta-learning for power control via random edge
  graph neural networks",http://arxiv.org/abs/2108.13178v1,"In this paper, we consider the problem of power control for a wireless
network with an arbitrarily time-varying topology, including the possible
addition or removal of nodes. A data-driven design methodology that leverages
graph neural networks (GNNs) is adopted in order to efficiently parametrize the
power control policy mapping the channel state information (CSI) to transmit
powers. The specific GNN architecture, known as random edge GNN (REGNN),
defines a non-linear graph convolutional filter whose spatial weights are tied
to the channel coefficients. While prior work assumed a joint training approach
whereby the REGNN-based policy is shared across all topologies, this paper
targets adaptation of the power control policy based on limited CSI data
regarding the current topology. To this end, we propose both black-box and
modular meta-learning techniques. Black-box meta-learning optimizes a
general-purpose adaptation procedure via (stochastic) gradient descent, while
modular meta-learning finds a set of reusable modules that can form components
of a solution for any new network topology. Numerical results validate the
benefits of meta-learning for power control problems over joint training
schemes, and demonstrate the advantages of modular meta-learning when data
availability is extremely limited.",data driven architecture,72,not included
http://arxiv.org/abs/2105.00459v1,to_check,arxiv,arxiv,2021-05-02 00:00:00,arxiv,"fast power control adaptation via meta-learning for random edge graph
  neural networks",http://arxiv.org/abs/2105.00459v1,"Power control in decentralized wireless networks poses a complex stochastic
optimization problem when formulated as the maximization of the average sum
rate for arbitrary interference graphs. Recent work has introduced data-driven
design methods that leverage graph neural network (GNN) to efficiently
parametrize the power control policy mapping channel state information (CSI) to
the power vector. The specific GNN architecture, known as random edge GNN
(REGNN), defines a non-linear graph convolutional architecture whose spatial
weights are tied to the channel coefficients, enabling a direct adaption to
channel conditions. This paper studies the higher-level problem of enabling
fast adaption of the power control policy to time-varying topologies. To this
end, we apply first-order meta-learning on data from multiple topologies with
the aim of optimizing for a few-shot adaptation to new network configurations.",data driven architecture,73,not included
http://arxiv.org/abs/1910.06115v1,to_check,arxiv,arxiv,2019-10-11 00:00:00,arxiv,"microservices based linked data quality model for buildings energy
  management services",http://arxiv.org/abs/1910.06115v1,"During the production, distribution, and consumption of energy, a large
quantity of data is generated. For efficiently using of energy resources other
supplementary data such as building information, weather, and environmental
data etc. are also collected and used. All these energy data and relevant data
is published as linked data in order to enhance the reusability of data and
maximization of energy management services capability. However, the quality of
this linked data is questionable because of wear and tears of sensors,
unreliable communication channels, and highly diversification of data sources.
The provision of high-quality energy management services requires high quality
linked data, which reduces billing cost and improve the quality of the living
environment. Assessment and improvement methodologies for the quality of data
along with linked data needs to process very diverse data from highly diverse
data sources. Microservices based data-driven architecture has great
significance to processes highly diverse linked data with modularity,
scalability, and reliability. This paper proposed microservices based
architecture along with domain data and metadata ontologies to enhance and
assess energy-related linked data quality.",data driven architecture,74,not included
http://arxiv.org/abs/1807.06699v5,to_check,arxiv,arxiv,2018-07-17 00:00:00,arxiv,adaptive neural trees,http://arxiv.org/abs/1807.06699v5,"Deep neural networks and decision trees operate on largely separate
paradigms; typically, the former performs representation learning with
pre-specified architectures, while the latter is characterised by learning
hierarchies over pre-specified features with data-driven architectures. We
unite the two via adaptive neural trees (ANTs) that incorporates representation
learning into edges, routing functions and leaf nodes of a decision tree, along
with a backpropagation-based training algorithm that adaptively grows the
architecture from primitive modules (e.g., convolutional layers). We
demonstrate that, whilst achieving competitive performance on classification
and regression datasets, ANTs benefit from (i) lightweight inference via
conditional computation, (ii) hierarchical separation of features useful to the
task e.g. learning meaningful class associations, such as separating natural
vs. man-made objects, and (iii) a mechanism to adapt the architecture to the
size and complexity of the training dataset.",data driven architecture,75,not included
10.14627/537690036,to_check,core,Wichmann Verlag im VDE Verlag GmbH,2020-01-01 00:00:00,core,bridging tangible and virtual realities : computational procedures for data-informed participatory processes,,"Driven by technological advances, growing amounts of available data, and an emergent need for participatory processes, landscape architecture is witnessing a moment of disruption whereby formerly separated areas of operation become increasingly connected. While distinctions between various aspects of the design process are diminishing, a need for a novel, more inclusive toolset arises. The ‘tangible table’ paradigm is an attempt at combining intuitive ways of physical modelling with data-driven design strategies and the interactive simulation of naturally occurring phenomena. Despite its existence for more than 20 years, tangible tables have mainly focused on very specific workflows and therefore have not found wider adoption in landscape architectural practice or education. We list the limitations of previous implementations and introduce a novel software solution aimed at popularizing tangible table setups. Our software is embedded in a widespread visual programming environment, which allows for straightforward augmentation of physical models with computational design tech-niques. Using a week-long PhD course as a case study, we demonstrate the usefulness of the proposed software and its potential applications to solving various landscape architectural challenges through increased emphasis on participatory processes.Peer reviewe",data driven architecture,76,not included
'elsevier bv',to_check,core,https://core.ac.uk/download/146492122.pdf,2013-01-01 00:00:00,core,10.1016/j.procs.2013.05.357,,"Cloud computing urges the need for novel on-demand approaches, where the Quality of Service (QoS) requirements of cloud-based services can dynamically and adaptively evolve at runtime as Service Level Agreement (SLA) and environment changes. Given the unpredictable, dynamic and on-demand nature of the cloud, it would be unrealistic to assume that optimal QoS can be achieved at design time. As a result, there is an increasing need for dynamic and self- adaptive QoS optimization solutions to respond to dynamic changes in SLA and the environment. In this context, we posit that the challenge of self-adaptive QoS optimization encompasses two dynamics, which are related to QoS sensitivity and conflicting objectives at runtime. We propose novel design of a dynamic data-driven architecture for optimizing QoS influenced by those dynamics. The architecture leverages on DDDAS primitives by employing distributed simulations and symbiotic feedback loops, to dynamically adapt decision making metaheuristics, which optimizes for QoS tradeoffs in cloud-based systems. We use a scenario to exemplify and evaluate the approach",data driven architecture,77,included
10.5075/epfl-thesis-3545,to_check,core,A multitasking and data-driven architecture for multi-agents simulations,2006-04-24 00:00:00,core,https://core.ac.uk/download/147916631.pdf,,"The expansion of 3D real-time simulations (3DRTS) into millions of homes together with the technical progress of computers hardware force to approach software developments for 3DRTS from different perspectives. From an historical standpoint, 3DRTS started principally as homebrew developments. The underlined consequences are the lack of standardization for producing such applications. Nowadays, computers hardware can reproduce close to photo-realism 3D images within interactive environments. This was made possible with the continuous improvements in computers hardware. During many years, the hardware evolution was following vertical speed-up improvements, by increasing CPU clocks speed and memory bandwidth. Today, we are reaching the limits of this approach from a power consumption, heat, and intrinsic materials characteristics perspectives. As an outcome, the next-generation of computer hardware and home consoles are presenting multitasking architectures. This obliges to re-think software development for 3DRTS, moving from the serial and single-threaded approach to a concurrent design. We explore conceptual designs handling the current scale and complexity offered by 3DRTS developments by adopting stronger engineering practices. This is needed to control the underlined complexity and rising developments costs. The direct consequence of being able to generate highly detailed virtual worlds is to involve more deeply artists and designers in the development process. We propose mechanisms that free developers from common low-levels problematic, such as memory management or data synchronization issues. Our architecture relies on extending the Component Based Development (CBD) model for multitasking architectures. This obliges to define specific patterns either directly inspired by other fields in computer science or dedicated for 3DRTS. This includes promoting multi-layer design where the low-level routines are tightly connected to computer hardware by describing the importance of conceiving hardware-oblivious systems. This is important, as memory bandwidth is becoming the principal bottleneck in current applications. Another fundamental aspect consists to move from the single iterative global loop commonly found in single-threaded systems, by incorporating mechanisms for balancing the workflow more accurately. If those optimizations and evolutions are required for assuring efficient real-time performance, they do not allow non-programmers to interact with the system with ease. Our method consists to promote high-level languages and concurrent model relying on Microthreads. This gives the ability to develop and execute scripts in a multitasking environment without the common C/C++ issues. This is primordial to let designers experiment with ideas in a safer and efficient environment. This will leads to adopt the data-driven paradigm to control agents in our simulations, by clearly separating the logic and data layers. This offer better flexibility and reduce the existence of simulation specific code. In addition, we illustrate that the best technology and designs have a limited meaning, if they do not come with a complete production pipeline for managing and controlling simulation assets. This also affects fine tuning parameters where different hardware may perform better in some areas or worse in other. Finally, different use-cases demonstrate the strong and weakness aspects of our approach",data driven architecture,78,not included
,to_check,core,,1994-01-01 00:00:00,core,"a language-independent, data-oriented architecture for grapheme-to-phoneme conversion",,"We report on an implemented grapheme-to-phoneme conversion architecture. Given a set of examples (spelling words with their associated phonetic representation) in a language, a grapheme-to-phoneme conversion system is automatically produced for that language which takes as its input the spelling of words, and produces as its output the phonetic transcription according to the rules implicit in the training data. This paper describes the architecture and focuses on our solution to the alignment problem: given the spelling and the phonetic trancription of a word (often differing in length), these two representations have to be aligned in such a way that grapheme symbols or strings of grapheme symbols are consistently associated with the same phonetic symbol. If this alignment has to be done by hand, it is extremely labour-intensive. 1 Introduction  Grapheme-to-phoneme conversion is an essential module in any text-to-speech system. Various language-specific sources of linguistic knowledge ..",data oriented architecture,79,included
,to_check,core,,2012-01-01 00:00:00,core,measurements in opportunistic networks,,"Opportunistic networks are a subset of delay tolerant networks where the contacts are unscheduled. Such networks can be formed ad hoc by wire-less devices, such as mobile phones and laptops. In this work we use a data-centric architecture for opportunistic networks to evaluate data dis-semination overhead, congestion in nodes ’ buffer, and the impact of transfer ordering. Dissemination brings an overhead since data is replicated to be spread in the network and overhead leads to congestion, i.e., overloaded buffers. We develop and implement an emulation testbed to experimentally eval-uate properties of opportunistic networks. We evaluate the repeatability of experiments in the emulated testbed that is based on virtual computers. We show that the timing variations are on the order of milliseconds. The testbed was used to investigate overhead in data dissemination, congestion avoidance, and transfer ordering in opportunistic networks. We show that the overhead can be reduced by informing other nodes in the network about what data a node is carrying. Congestion avoidance was evaluated in terms of buffer management, since that is the available tool in an opportunistic network, to handle congestion. It was shown that replication information of data objects in the buffer yields the best results. We show that in a data-centric architecture were each data item is valued differently, transfer ordering is important to achieve delivery of the most valued data. 1 ",data centric architecture,80,included
,to_check,core,,2013-09-24 00:00:00,core,s.: persistent information state in a data-centric architecture,,"We present the ADAMACH data centric dialog system, that allows to perform on- and offline mining of dialog context, speech recognition results and other system-generated representations, both within and across dialogs. The architecture implements a “fat pipeline” for speech and language processing. We detail how the approach integrates domain knowledge and evolving empirical data, based on a user study in the University Helpdesk domain. ",data centric architecture,81,included
,to_check,core,,2001-01-01 00:00:00,core,adaptive collaboration for wired and wireless platforms - a data-centric architecture for collaboration environments uses xml to adapt shared data dynamically between devices with widely disparate capabilities.,,"This article begins by introducing a data-centric  architecture that abstracts collaborative tasks as  editing of data repositories, followed by descriptions  of the role of XML in managing heterogeneity  and intelligent software agents in discovering  network and computing environment condition",data centric architecture,82,included
,to_check,core,,2001-01-01 00:00:00,core,emacspeak - toward the speech-enabled semantic www,,"Emacspeak has pioneered the speech-enabling approach to providing intelligent  spoken feedback for a variety of daily computing tasks. This includes audio  formatted output from World Wide Web (WWW) pages by utilizing Aural Cascading  Style Sheets (ACSS). However, until recently such spoken output has been  limited by presentational HTML pages optimized for visual interaction.  The WWW is presently transitioning toward a data-centric architecture; content  ---and its semantics--- is encapsulated in XML ([W3C98]) pages designed to  be served in a manner most appropriate to a given client. This opens up significant  opportunities in generating high-quality spoken feedback from richly encoded  WWW content. Though XML is still in its early stages of wide-spread adoption,  some of the benefits to come can already be seen today. Many sites now offer  access to both presentational HTML, as well as the underlying data. Examples  include historical stock charts, driving directions, and other useful information.  Emacspeak now exploits the availability of such semantically encoded content  to provide a richer end-user experience. This article introduces some of the data  acquisition techniques used in Emacspeak and focuses on the end-user experience  when interacting with such structured information.  ",data centric architecture,83,not included
,to_check,core,,2011-01-01 00:00:00,core,data serving climate simulation science at the nasa center for climate simulation,https://core.ac.uk/download/pdf/10560731.pdf,"The NASA Center for Climate Simulation (NCCS) provides high performance computational resources, a multi-petabyte archive, and data services in support of climate simulation research and other NASA-sponsored science. This talk describes the NCCS's data-centric architecture and processing, which are evolving in anticipation of researchers' growing requirements for higher resolution simulations and increased data sharing among NCCS users and the external science community",data centric architecture,84,included
,to_check,core,,2004-01-01 00:00:00,core,wireless sensor networks dynamic runtime configuration,,"Current Wireless Sensor Networks (WSN) use fixed layered architectures, that can be modified only at compile time. Using a non-layered architecture, which allows dynamic loading of modules and automatic reconfiguration to adapt to the surrounding environment was believed to be too resource consuming to be employed. We have created a so-called data centric architecture and developed a new operating system (DCOS), to support it. As we will show in this paper, the new architecture and operating system are good candidates for WSNs, allowing flexibility in the configuration and exploitation of the sensor network",data centric architecture,85,included
,to_check,core,,2017-05-01 00:00:00,core,resource management in sensing services with audio applications,https://core.ac.uk/download/158321560.pdf,"Middleware abstractions, or services, that can bridge the gap between the increasingly pervasive sensors and the sophisticated inference applications exist, but they lack the necessary resource-awareness to support high data-rate sensing modalities such as audio/video. This work therefore investigates the resource management problem in sensing services, with application in audio sensing. First, a modular, data-centric architecture is proposed as the framework within which optimal resource management is studied. Next, the guided-processing principle is proposed to achieve optimized trade-off between resource (energy) and (inference) performance.

On cascade-based systems, empirical results show that the proposed approach significantly improves the detection performance (up to 1.7x and 4x reduction in false-alarm and miss rate, respectively) for the same energy consumption, when compared to the duty-cycling approach. Furthermore, the guided-processing approach is also generalizable to graph-based systems. Resource-efficiency in the multiple-application setting is achieved through the feature-sharing principle. Once applied, the method results in a system that can achieve 9x resource saving and 1.43x improvement in detection performance in an example application.

Based on the encouraging results above, a prototype audio sensing service is built for demonstration. An interference-robust audio classification technique with limited training data would prove valuable within the service, so a novel algorithm with the desired properties is proposed. The technique combines AI-gram time-frequency representation and multidimensional dynamic time warping, and it outperforms the state-of-the-art using the prominent-region-based approach across a wide range of (synthetic, both stationary and transient) interference types and signal-to-interference ratios, and also on field recordings (with areas under the receiver operating characteristic and precision-recall curves being 91% and 87%, respectively)",data centric architecture,87,included
,to_check,core,,2012-05-19 00:00:00,core,1 social-driven internet of connected objects,,"Abstract—Internet evolution has been recently related with some aspect of user empowerment, mostly in terms of content distribution, and this has been ultimately accelerated by the fast-paced introduction and expansion of wireless technologies. Hence, the Internet should start to be seen as a communications infrastructure able to support the integration of a myriad of embedded and personal wireless objects. This way a future Internet will support the interaction between users ’ social, physical and virtual sphere. This position paper aims to raise some discussion about the technology required to ensure an efficient interaction between the physical, social and virtual worlds by extending the Internet by means of interconnected objects. Namely, it is argued that an efficient interaction between the physical, social and virtual worlds requires the development of a data-centric architecture based on IP-driven opportunisitc networking able to make useful data available to people when and where they really need it, augmenting their social and environmental awareness. Index Terms—user-centric paradigm, data-centric architecture, IP-based opportunistic networking I",data centric architecture,88,not included
,to_check,core,,2007-01-01 00:00:00,core,gestion de l'évolution des applications web,,"Nous nous intéressons dans cet article à la gestion de l’évolution logicielle dans les 
processus pilotés par les modèles (MDE). Plus spécifiquement, nous tentons de hisser la 
gestion de l’évolution logicielle au niveau des spécifications. Nous examinons les défis 
conceptuels et techniques qui apparaissent lorsque  la gestion de l’évolution est considérée 
comme une problématique de premier ordre dans un processus d’ingénierie piloté par les 
modèles. Dans le contexte spécifique de la réalisation d’applications web, nous proposons un 
cadre formel s’organisant autour de : (i) une architecture pilotée par les données, (ii) un 
méta-modèle ciblant les applications web, (iii) un modèle de traçabilité permettant de gérer 
les évolutions des modèles et de vérifier la cohérence des différentes versions. Notre objectif 
est d’abstraire autant que possible la gestion de l’évolution et de la hisser au niveau du 
méta-modèle, de sorte que celle-ci reste générique.We focus on the evolution aspect of MDE, and more specifically on the design of 
web applications following a model-driven approach. In this context we address the issue of
managing software evolution at the specification level. We examine the conceptual and 
technical challenges that occur when trying to raise evolution management concerns as first-class MDE issues. Focusing on Web applications design, we propose a general framework 
which consists of (i) a data-centric architecture, (ii) an integrated meta-model to support 
specifications of such applications and (iii) a traceability model to manage evolutions and 
evaluate consistencies of applications’ versions. Our goal is to promote, as much a possible,
the traceability management at the meta-model level in order to make it generic.ou",data centric architecture,89,not included
,to_check,core,,2015-08-26 00:00:00,core,adaptive collaboration for wired and wireless platforms,,"A data-centric architecture for collaboration environments uses XML to adapt shared data dynamically between devices with widely disparate capabilities. Expanding the Internet’s reach withwireless links and mobile terminalsestablishes an infrastructure that permits not only individual roaming but also, potentially, interactive collaboration in a more complex workspace. The classic example is an expert using a 3D CAD model on a workstation to collaborate with someone in the field using a handheld device. The possibilities for collaboration will become more elaborate with advances in visualization technologies for small portable devices (for example, see the MiniGL 3D graphics library from Digita",data centric architecture,90,included
,to_check,core,,2009-08-31 00:00:00,core,a context-oriented synchronization approach,,"Synchronization gained great importance in modern applications and allows mobility in the context of information technology. Users are not limited to one computer any more, but can take their data with them on a laptop. Two common architectures have been developed recently, the Data-Centric Architecture as well as the Service-Oriented Architecture. This paper compares two existing technologies for the implementation of a mobile client and introduces a new approach, developed based on the requirements of a major insurance company, the Context-Oriented Architecture. This approach allows detection and resolution of conflicts within the context in which the objects were changed, while still ensuring data correctness and consistency. Therefore two new synchronization concepts are introduced: the synchronization of complex objects and dialogue-sensitive synchronization. An application implementing this approach has been realized and successfully deployed. 1",data centric architecture,91,included
,to_check,core,HAL CCSD,2017-03-27 00:00:00,core,towards blockchain-based auditable storage and sharing of iot data,https://core.ac.uk/download/145154055.pdf,"International audienceToday the cloud plays a central role in storing, processing , and distributing data. Despite contributing to the rapid development of various applications, including the IoT, the current centralized storage architecture has led into a myriad of isolated data silos and is preventing the full potential of holistic data-driven analytics for IoT data. In this abstract, we advocate a data-centric design for IoT with focus on resilience, sharing, and auditable protection of information. We introduce the initial design of our blockchain-based end-to-end encrypted data storage system. We enable a secure and persistent data management, by utilizing the blockchain as an auditable access control layer to a decentralized storage layer",data centric architecture,92,included
,to_check,core,,2018-01-01 00:00:00,core,collaborative systems engineering in the ascent abort-2 crew module/separation ring project,https://core.ac.uk/download/pdf/161999682.pdf,"Generally speaking, systems engineering (SE) tool-sets face a dilemma balancing power and accessibility. High-powered SE tools (MagicDraw, Cradle, Core, etc.) tend to be specialized and are available only to highly trained Systems Engineers, and/or through the use of a 'back room' developer team making the output products available to the broader team. On the other hand, highly accessible tools (MS Word, Excel, etc.) do not have the power to implement SE in a rigorous manner. NASA has to test all aspects of the new human-rated Orion Multi-Purpose Crew Vehicle spacecraft prior to its first crewed mission. The test program includes uncrewed launch abort flight tests to demonstrate the capability to save the crew in the event that a launch failure occurs. Orion's second abort flight test will be a low-altitude flight test known as ""Ascent Abort 2 (AA-2).""  This test is currently scheduled to be carried out at Cape Canaveral Air Force Station's Space Launch Complex 46 (SLC-46) in Florida in 2019. NASA's in-house AA-2 Crew Module and Separation Ring (CSR) Team is producing the crew module and separation ring. Operating jointly as both an Advanced Exploration Systems (AES) Project and an Orion Project, the CSR project charter includes development of innovative, streamlined and generally more efficient practices for creation of flight hardware and software. One result of this tasking has been development of a collaborative and data-centric systems engineering environment within the team's shared web environment (Microsoft SharePoint). Through the use of built-in, 'out of the box capabilities' present in MS SharePoint, the CSR Systems Engineering team has created (with some limited developer support) a data-centric architecture for the project's SE implementation, including functional and interface analysis, requirements development and management, risk management, verification planning and management, test results, and end item management. Data elements are linked between data structures so as to define and control relationships between item types, link requirements to parents and children, and link tests to the requirements that they verify. The overall project team integration is increased by also linking SE content to project management content over the project life cycle, including team communication, action items, configuration management, decisional and meeting materials, and life cycle reviews. This presentation will provide an overview of the collaborative SE environment, showing how it provides the power for a number of SE tasks while still providing the accessibility and transparency to allow the full project team to collaborate and succeed. Given the project phase, we'll be able to present a nearly full lifecycle discussion, from concept through verification and approaching delivery",data centric architecture,93,not included
,to_check,core,,2019-10-11 00:00:00,core,http://arxiv.org/abs/1910.06115,,"During the production, distribution, and consumption of energy, a large
quantity of data is generated. For efficiently using of energy resources other
supplementary data such as building information, weather, and environmental
data etc. are also collected and used. All these energy data and relevant data
is published as linked data in order to enhance the reusability of data and
maximization of energy management services capability. However, the quality of
this linked data is questionable because of wear and tears of sensors,
unreliable communication channels, and highly diversification of data sources.
The provision of high-quality energy management services requires high quality
linked data, which reduces billing cost and improve the quality of the living
environment. Assessment and improvement methodologies for the quality of data
along with linked data needs to process very diverse data from highly diverse
data sources. Microservices based data-driven architecture has great
significance to processes highly diverse linked data with modularity,
scalability, and reliability. This paper proposed microservices based
architecture along with domain data and metadata ontologies to enhance and
assess energy-related linked data quality",data driven architecture,94,not included
,to_check,core,,2010-01-01 00:00:00,core,10.1109/geoinformatics.2010.5567735,,"Net primary productivity (NPP) estimation is an important study field of global change and terrestrial ecosystem. Here, we present an integrated modeling and analysis framework for researching climate change using NPP as an ecosystem indicator. It&apos;s brings together remote sensing, GIS and an ecosystem simulation model without requiring users to have any knowledge of any other specific software. Satellite data driven architecture can play a positive role in understanding the climate change and carbon cycles from regional to global scales. The benefit of the framework is that it provides complete spatial coverage and high temporal resolution, versus plot samples from which it may be difficult to provide an overall assessment for large-scale study. Recent advances in service-oriented architectures are allowing us to share of model results by geospatial services and create distributed applications needed for the collaborative research. Multi-layer approaches allow the framework more flexible and easy to extend. New datasets and models can be integrated for use in the development of new applications. A preliminary system based on the framework was carried out for monitoring the dynamic changes of terrestrial ecosystem NPP in China. State-of-the art processing algorithms was developed based on light-use efficiency model (Carnegie-Ames-Stanford Approach (CASA) model). Fraction of photosynthetically active radiation absorbed by vegetation (FPAR) is a linear function of Normalized Difference Vegetation Index (NDVI) and Simple Ratio vegetation index (SR). We combined the method of NDVI and SR together to compute the FPAR of China. And then, the NPP time-series of Chinese terrestrial vegetation is built. The System is capable of querying, retrieving, and visualizing datasets with heterogeneous formats and the spatio-temporal analysis revealed the relationship between NPP and climatic change in China. These results supported national trends of NPP in relation to lag effects of climate.Computer Science, Information SystemsEngineering, Electrical &amp;    ElectronicEICPCI-S(ISTP)",data driven architecture,95,not included
,to_check,core,"Web Monitoring of EOS Front-End Ground Operations, Science Downlinks and Level 0 Processing",2008-01-01 00:00:00,core,https://core.ac.uk/download/pdf/195383281.pdf,,"This paper addresses the efforts undertaken and the technology deployed to aggregate and distribute the metadata characterizing the real-time operations associated with NASA Earth Observing Systems (EOS) high-rate front-end systems and the science data collected at multiple ground stations and forwarded to the Goddard Space Flight Center for level 0 processing. Station operators, mission project management personnel, spacecraft flight operations personnel and data end-users for various EOS missions can retrieve the information at any time from any location having access to the internet. The users are distributed and the EOS systems are distributed but the centralized metadata accessed via an external web server provide an effective global and detailed view of the enterprise-wide events as they are happening. The data-driven architecture and the implementation of applied middleware technology, open source database, open source monitoring tools, and external web server converge nicely to fulfill the various needs of the enterprise. The timeliness and content of the information provided are key to making timely and correct decisions which reduce project risk and enhance overall customer satisfaction. The authors discuss security measures employed to limit access of data to authorized users only",data driven architecture,96,included
