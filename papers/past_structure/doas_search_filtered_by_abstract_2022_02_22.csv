id,doi,publisher,database,url,domain,publication_date,algorithm_type,training_schema,algorithm_goal,architecture,title,abstract,status
1,10.1109/tro.2021.3084374,IEEE,ieeexplore,https://ieeexplore.ieee.org/document/9453856/,robotics,2/1/2022 0:00,semi-supervised,not defined,not defined,not defined,cat-like jumping and landing of legged robots in low gravity using deep reinforcement learning,"In this article, we show that learned policies can be applied to solve legged locomotion control tasks with extensive flight phases, such as those encountered in space exploration. Using an off-the-shelf deep reinforcement learning algorithm, we train a neural network to control a jumping quadruped robot while solely using its limbs for attitude control. We present tasks of increasing complexity leading to a combination of 3-D (re)orientation and landing locomotion behaviors of a quadruped robot traversing simulated low-gravity celestial bodies. We show that our approach easily generalizes across these tasks and successfully trains policies for each case. Using sim-to-real transfer, we deploy trained policies in the real world on the SpaceBok robot placed on an experimental testbed designed for 2-D microgravity experiments. The experimental results demonstrate that repetitive controlled jumping and landing with natural agility is possible.",excluded
2,10.1109/tifs.2021.3131026,IEEE,ieeexplore,https://ieeexplore.ieee.org/document/9627681/,science,1/1/2000 0:00,not defined,not defined,not defined,not defined,poligraph: intrusion-tolerant and distributed fake news detection system,"We present Poligraph, an intrusion-tolerant and decentralized fake news detection system. Poligraph aims to address architectural, system, technical, and social challenges of building a practical, long-term fake news detection platform. We first conduct a case study for fake news detection at authors’ institute, showing that machine learning-based reviews are less accurate but timely, while human reviews, in particular, experts reviews, are more accurate but time-consuming. This justifies the need for combining both approaches. At the core of Poligraph is two-layer consensus allowing seamlessly combining machine learning techniques and human expert determination. We construct the two-layer consensus using Byzantine fault-tolerant (BFT) and asynchronous threshold common coin protocols. We prove the correctness of our system in terms of conventional definitions of security in distributed systems (agreement, total order, and liveness) as well as new review validity (capturing the accuracy of news reviews). We also provide theoretical foundations on parameter selection for our system. We implement Poligraph and evaluate its performance on Amazon EC2 using a variety of news from online publications and social media. We demonstrate Poligraph achieves throughput of more than 5,000 transactions per second and latency as low as 0.05 second. The throughput of Poligraph is only marginally (<inline-formula> <tex-math notation=""LaTeX"">${4\%}$ </tex-math></inline-formula>–<inline-formula> <tex-math notation=""LaTeX"">${7\%}$ </tex-math></inline-formula>) slower than that of an unreplicated, single-server implementation. In addition, we conduct a real-world case study for the review of fake and real news among both experts and non-experts, which validates the practicality of our approach.",architecture
3,http://arxiv.org/abs/2201.05753v1,arxiv,arxiv,http://arxiv.org/abs/2201.05753v1,robotics,1/15/2022 0:00,not defined,not defined,not defined,not defined,"parameter identification and motion control for articulated rigid body
  robots using differentiable position-based dynamics","Simulation modeling of robots, objects, and environments is the backbone for
all model-based control and learning. It is leveraged broadly across dynamic
programming and model-predictive control, as well as data generation for
imitation, transfer, and reinforcement learning. In addition to fidelity, key
features of models in these control and learning contexts are speed, stability,
and native differentiability. However, many popular simulation platforms for
robotics today lack at least one of the features above. More recently,
position-based dynamics (PBD) has become a very popular simulation tool for
modeling complex scenes of rigid and non-rigid object interactions, due to its
speed and stability, and is starting to gain significant interest in robotics
for its potential use in model-based control and learning. Thus, in this paper,
we present a mathematical formulation for coupling position-based dynamics
(PBD) simulation and optimal robot design, model-based motion control and
system identification. Our framework breaks down PBD definitions and
derivations for various types of joint-based articulated rigid bodies. We
present a back-propagation method with automatic differentiation, which can
integrate both positional and angular geometric constraints. Our framework can
critically provide the native gradient information and perform gradient-based
optimization tasks. We also propose articulated joint model representations and
simulation workflow for our differentiable framework. We demonstrate the
capability of the framework in efficient optimal robot design, accurate
trajectory torque estimation and supporting spring stiffness estimation, where
we achieve minor errors. We also implement impedance control in real robots to
demonstrate the potential of our differentiable framework in human-in-the-loop
applications.",experiments
4,10.1016/j.autcon.2021.104088,scopus,sciencedirect,https://api.elsevier.com/content/abstract/scopus_id/85120874971,industry,2/1/2022,not defined,not defined,not defined,not defined,vision-based high-precision intelligent monitoring for shield tail clearance,"Real-time shield tail clearance measurement and monitoring is a key task during shield tunneling construction. The shield tail clearance measurement and monitoring technology development is still in its infancy, the current methods are mainly designed manually based on intuition. In order to fill the gap between the requirement of shield tail clearance measurement and monitoring and the limitations of the current methods, this paper systematically studies the existing mechanisms related to shield tail clearance measurement and monitoring, and develops a high-precision intelligent monitoring system for shield tail clearance. The proposed monitoring system includes four components: 1) two types of shield tail clearance calculation models, 2) the integrated hardware of the monitoring system which is composed of a data acquisition unit, a signal transmission unit and a control unit, 3) the region of interest (ROI) extraction method based on deep neural network, and the image processing algorithms for image enhancement and feature extraction, 4) the custom-developed software built on mature integrated development environment (IDE). After the calculation model of shield tail clearance is established, the system uses monitoring devices equipped with industrial cameras to obtain the on-site image, and then applies image processing technologies along with deep learning approach to extract the key features, which are brought into the model to calculate the values of shield tail clearance, finally displays these values and simulates the current tunneling attitude of the shield machine in real time. The experimental results show that the system proposed in this paper achieves the goal of high precision measuring and real-time monitoring of the shield tail clearance.",excluded
5,10.1109/lra.2021.3116700,IEEE,ieeexplore,https://ieeexplore.ieee.org/document/9555228/,multimedia,1/1/2022 0:00,not defined,not defined,not defined,not defined,sim2real learning of obstacle avoidance for robotic manipulators in uncertain environments,"Obstacle avoidance for robotic manipulators can be challenging when they operate in unstructured environments. This problem is probed with the sim-to-real (sim2real) deep reinforcement learning, such that a moving policy of the robotic arm is learnt in a simulator and then adapted to the real world. However, the problem of sim2real adaptation is notoriously difficult. To this end, this work proposes (1) a unified representation of obstacles and targets to capture the underlying dynamics of the environment while allowing generalization to unseen goals and (2) a flexible end-to-end model combining the unified representation with the deep reinforcement learning control module that can be trained by interacting with the environment. Such a representation is agnostic to the shape and appearance of the underlying objects, which simplifies and unifies the scene representation in both simulated and real worlds. We implement this idea with a vision-based actor-critic framework by devising a bounding box predictor module. The predictor estimates the 3D bounding boxes of obstacles and targets from the RGB-D input. The features extracted by the predictor are fed into the policy network, and all the modules are jointly trained. This makes the policy learn object-aware scene representation, which leads to a data-efficient learning of the obstacle avoidance policy. Our experiments in simulated environment and the real-world show that the end-to-end model of the unified representation achieves better sim2real adaption and scene generalization than state-of-the-art techniques.",experiments
6,http://arxiv.org/abs/2201.07312v1,arxiv,arxiv,http://arxiv.org/abs/2201.07312v1,multimedia,1/18/2022 0:00,not defined,not defined,not defined,not defined,model-driven cluster resource management for ai workloads in edge clouds,"Since emerging edge applications such as Internet of Things (IoT) analytics
and augmented reality have tight latency constraints, hardware AI accelerators
have been recently proposed to speed up deep neural network (DNN) inference run
by these applications. Resource-constrained edge servers and accelerators tend
to be multiplexed across multiple IoT applications, introducing the potential
for performance interference between latency-sensitive workloads. In this
paper, we design analytic models to capture the performance of DNN inference
workloads on shared edge accelerators, such as GPU and edgeTPU, under different
multiplexing and concurrency behaviors. After validating our models using
extensive experiments, we use them to design various cluster resource
management algorithms to intelligently manage multiple applications on edge
accelerators while respecting their latency constraints. We implement a
prototype of our system in Kubernetes and show that our system can host 2.3X
more DNN applications in heterogeneous multi-tenant edge clusters with no
latency violations when compared to traditional knapsack hosting algorithms.",architecture
7,http://arxiv.org/abs/2201.01369v1,arxiv,arxiv,http://arxiv.org/abs/2201.01369v1,robotics,1/4/2022 0:00,not defined,not defined,not defined,not defined,"using simulation optimization to improve zero-shot policy transfer of
  quadrotors","In this work, we show that it is possible to train low-level control policies
with reinforcement learning entirely in simulation and, then, deploy them on a
quadrotor robot without using real-world data to fine-tune. To render zero-shot
policy transfers feasible, we apply simulation optimization to narrow the
reality gap. Our neural network-based policies use only onboard sensor data and
run entirely on the embedded drone hardware. In extensive real-world
experiments, we compare three different control structures ranging from
low-level pulse-width-modulated motor commands to high-level attitude control
based on nested proportional-integral-derivative controllers. Our experiments
show that low-level controllers trained with reinforcement learning require a
more accurate simulation than higher-level control policies.",excluded
8,http://arxiv.org/abs/2201.09550v1,arxiv,arxiv,http://arxiv.org/abs/2201.09550v1,multimedia,1/24/2022 0:00,not defined,not defined,not defined,not defined,crowd tracking and monitoring middleware via map-reduce,"This paper presents the design, implementation, and operation of a novel
distributed fault-tolerant middleware. It uses interconnected WSNs that
implement the Map-Reduce paradigm, consisting of several low-cost and low-power
mini-computers (Raspberry Pi). Specifically, we explain the steps for the
development of a novice, fault-tolerant Map-Reduce algorithm which achieves
high system availability, focusing on network connectivity. Finally, we
showcase the use of the proposed system based on simulated data for crowd
monitoring in a real case scenario, i.e., a historical building in Greece (M.
Hatzidakis' residence).The technical novelty of this article lies in presenting
a viable low-cost and low-power solution for crowd sensing without using
complex and resource-intensive AI structures or image and video recognition
techniques.",architecture
9,10.1109/lra.2022.3143289,IEEE,ieeexplore,https://ieeexplore.ieee.org/document/9682507/,robotics,4/1/2022 0:00,not defined,not defined,not defined,not defined,visuotactile 6d pose estimation of an in-hand object using vision and tactile sensor data,"Knowledge of the 6D pose of an object can benefit in-hand object manipulation. Existing 6D pose estimation methods use vision data. In-hand 6D object pose estimation is challenging because of heavy occlusion produced by the robot’s grippers, which can have an adverse effect on methods that rely on vision data only. Many robots are equipped with tactile sensors at their fingertips that could be used to complement vision data. In this letter, we present a method that uses both tactile and vision data to estimate the pose of an object grasped in a robot’s hand.The main challenges of this research include 1) lack of standard representation for tactile sensor data, 2) fusion of sensor data from heterogeneous sources—vision and tactile, and 3) a need for large training datasets. To address these challenges, first, we propose use of point clouds to represent object surfaces that are in contact with the tactile sensor. Second, we present a network architecture based on pixel-wise dense fusion to fuse vision and tactile data to estimate the 6D pose of an object. Third, we extend NVIDIA’s Deep Learning Dataset Synthesizer to produce synthetic photo-realistic vision data and the corresponding tactile point clouds for 11 objects from the YCB Object and Model Set in Unreal Engine 4. We present results of simulated experiments suggesting that using tactile data in addition to vision data improves the 6D pose estimate of an in-hand object. We also present qualitative results of experiments in which we deploy our network on real physical robots showing successful transfer of a network trained on synthetic data to a real system.",experiments
10,10.1016/j.ssci.2021.105529,scopus,sciencedirect,https://api.elsevier.com/content/abstract/scopus_id/85118705579,industry,2/1/2022,not defined,not defined,not defined,not defined,a novel decision support system for managing predictive maintenance strategies based on machine learning approaches,"Nowadays, the industrial environment is characterised by growing competitiveness, short response times, cost reduction and reliability of production to meet customer needs. Thus, the new industrial paradigm of Industry 4.0 has gained interest worldwide, leading many manufacturers to a significant digital transformation. Digital technologies have enabled a novel approach to decision-making processes based on data-driven strategies, where knowledge extraction relies on the analysis of a large amount of data from sensor-equipped factories. In this context, Predictive Maintenance (PdM) based on Machine Learning (ML) is one of the most prominent data-driven analytical approaches for monitoring industrial systems aiming to maximise reliability and efficiency. In fact, PdM aims not only to reduce equipment failure rates but also to minimise operating costs by maximising equipment life. When considering industrial applications, industries deal with different issues and constraints relating to process digitalisation. The main purpose of this study is to develop a new decision support system based on decision trees (DTs) that guides the decision-making process of PdM implementation, considering context-aware information, quality and maturity of collected data, severity, occurrence and detectability of potential failures (identified through FMECA analysis) and direct and indirect maintenance costs. The decision trees allow the study of different scenarios to identify the conditions under which a PdM policy, based on the ML algorithm, is economically profitable compared to corrective maintenance, considered to be the current scenario. The results show that the proposed methodology is a simple and easy way to implement tool to support the decision process by assessing the different levels of occurrence and severity of failures. For each level, savings and the potential costs have been evaluated at leaf nodes of the trees aimed at defining the most suitable maintenance strategy implementation. Finally, the proposed DTs are applied to a real industrial case to illustrate their applicability and robustness.",excluded
11,10.1007/978-3-030-92127-9_68,Springer,springer,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-92127-9_68,multimedia,1/1/2022 0:00,not defined,not defined,not defined,not defined,application of digital twin theory for improvement of natural gas treatment unit,"This paper describes fundamental principles of Digital Twins theory and provides exact investigation results in application of Digital Twins theory in upstream branch of oil and gas industry, namely based on example of natural gas treatment plant’s performance increase. As one of key process units of natural gas treatment which allows to implement most powerful functions of digital twin gas sweetening unit with set of membranes is considered as object of investigation. On the base of membrane technology manipulated variables are defined as inputs to digital twin model. Some theoretical results as well as real references of model’s engine calculations are reflected in the paper. Details of technical dashboards to visualize calculated results of running model based on manipulated variables are presented including monthly key performance indicators report dashboard, process flow diagram dashboard and high-level management dashboard. Paper also demonstrates data flow between digital twin model and real process unit and also inside digital twin model.",excluded
12,10.1016/j.softx.2021.100956,scopus,sciencedirect,https://api.elsevier.com/content/abstract/scopus_id/85121968187,industry,1/1/2022,not defined,not defined,not defined,not defined,tx2_fcnn_node: an open-source ros compatible tool for monocular depth reconstruction,"We present tx2_fcnn_node – a Robot Operating System (ROS) compatible tool that is aimed at seamless integration of various monocular depth reconstruction neural networks to the robotic software based on ROS (which is a de-facto standard in the area of robotics). Our tool simplifies the process of deploying, evaluating, and comparing depth reconstruction neural networks both on real robots and in simulation. We complement our software with a set of the precompiled neural networks which can be used off the shelf, with some of them being able to demonstrate near real-time performance when running onboard compact embedded platforms, e.g. Nvidia Jetson TX2, that are often used nowadays both in academia and industry.",excluded
