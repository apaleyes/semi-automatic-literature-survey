paperId,url,title,abstract,venue,year,id,type,status
7f4d129454480cea7683c5ed610c128876b6e12f,https://www.semanticscholar.org/paper/7f4d129454480cea7683c5ed610c128876b6e12f,Technology enablers for the implementation of Industry 4.0 to traditional manufacturing sectors: A review,"The traditional manufacturing sectors (footwear, textiles and clothing, furniture and toys, among others) are based on small and medium enterprises with limited capacity on investing in modern production technologies. Although these sectors rely heavily on product customization and short manufacturing cycles, they are still not able to take full advantage of the fourth industrial revolution. Industry 4.0 surfaced to address the current challenges of shorter product life-cycles, highly customized products and stiff global competition. The new manufacturing paradigm supports the development of modular factory structures within a computerized Internet of Things environment. With Industry 4.0, rigid planning and production processes can be revolutionized. However, the computerization of manufacturing has a high degree of complexity and its implementation tends to be expensive, which goes against the reality of SMEs that power the traditional sectors. This paper reviews the main scientific-technological advances that have been developed in recent years in traditional sectors with the aim of facilitating the transition to the new industry standard.",Comput. Ind.,2021,1,to_check,unknown
c138133577e40f56f64be95ab493a678bc6ee325,https://www.semanticscholar.org/paper/c138133577e40f56f64be95ab493a678bc6ee325,"Measuring User Experience, Usability and Interactivity of a Personalized Mobile Augmented Reality Training System","Innovative technology has been an important part of firefighting, as it advances firefighters’ safety and effectiveness. Prior research has examined the implementation of training systems using augmented reality (AR) in other domains, such as welding, aviation, army, and mathematics, offering significant pedagogical affordances. Nevertheless, firefighting training systems using AR are still an under-researched area. The increasing penetration of AR for training is the driving force behind this study, and the scope is to analyze the main aspects affecting the acceptance of AR by firefighters. The current research uses a technology acceptance model, extended by the external constructs of perceived interactivity and personalization, to consider both the system and individual level. The proposed model was evaluated by a sample of 200 users, and the results show that both the external variables of perceived interactivity and perceived personalization are prerequisite factors in extending the TAM model. The findings reveal that the usability is the strongest predictor of firefighters’ behavioral intentions to use the AR system, followed by the ease of use with smaller, yet meaningful, direct and indirect effects on firefighters’ intentions. The identified acceptance factors help AR developers enhance the firefighters’ experience in training operations.",Sensors,2021,2,to_check,unknown
d325aa9305ec92a75511dff3c5b2cdcc8b6c3953,https://www.semanticscholar.org/paper/d325aa9305ec92a75511dff3c5b2cdcc8b6c3953,Deep Reinforcement Learning with Shallow Controllers: An Experimental Application to PID Tuning,"Deep reinforcement learning (RL) is an optimization-driven framework for producing control strategies for general dynamical systems without explicit reliance on process models. Good results have been reported in simulation. Here we demonstrate the challenges in implementing a state of the art deep RL algorithm on a real physical system. Aspects include the interplay between software and existing hardware; experiment design and sample efficiency; training subject to input constraints; and interpretability of the algorithm and control law. At the core of our approach is the use of a PID controller as the trainable RL policy. In addition to its simplicity, this approach has several appealing features: No additional hardware needs to be added to the control system, since a PID controller can easily be implemented through a standard programmable logic controller; the control law can easily be initialized in a “safe” region of the parameter space; and the final product—a well-tuned PID controller—has a form that practitioners can reason about and deploy with confidence.",ArXiv,2021,3,to_check,unknown
dcbbe1d306b7ef25c2e9c5a5ba1599d79d03909c,https://www.semanticscholar.org/paper/dcbbe1d306b7ef25c2e9c5a5ba1599d79d03909c,Motivational engine with autonomous sub-goal identification for the Multilevel Darwinist Brain,"Abstract This work proposes a motivational system for an autonomous robot that guides the fulfillment of its goals in a developmental manner, discovering sub-goals not only as a way to simplify goal achievement, but as a way to acquire knowledge in an incremental, modular and reusable fashion. This system has been called MotivEn (Motivational Engine) and we have carried out its initial integration within the Multilevel Darwinist Brain (MDB) cognitive architecture. We describe here the main elements of MotivEn and how they improve the current MDB operation. Moreover, we present in detail a specific implementation of MotivEn and the application results obtained in terms of sub-goal identification when applying it in a real robot experiment with the MDB.",BICA 2016,2016,4,to_check,unknown
102f3f5f75401b1a70a6d3af4cf6f5df11ecb925,https://www.semanticscholar.org/paper/102f3f5f75401b1a70a6d3af4cf6f5df11ecb925,Introducing Synaptic Delays in the NEAT Algorithm to Improve Modelling in Cognitive Robotics,"This paper describes and tests an approach to improve the temporal processing capabilities of the neuroevolution of augmenting topologies (NEAT) algorithm. This algorithm is quite popular within the robotics community for the production of trained neural networks without having to determine a priori their size and topology. The main drawback of the traditional NEAT algorithm is that, even though it can implement recurrent synaptic connections, which allow it to perform some time related processing tasks, its capabilities are rather limited, especially when dealing with precise time dependent phenomena. NEAT’s ability to capture the underlying dynamics that correspond to complex time series still has a lot of room for improvement. To address this issue, the paper describes a new implementation of the NEAT algorithm that is able to generate artificial neural networks (ANNs) with trainable time delayed synapses in addition to its previous capacities. We show that this approach, called tao-NEAT improves the behavior of the neural networks obtained when dealing with complex time related processes. Several examples are presented, both dealing with the generation of ANNs that are able to produce complex theoretical signals such as chaotic signals or real data series, as in the case of the monthly number of international airline passengers or monthly $$\hbox {CO}_{2}$$CO2 concentrations. In these examples, t-NEAT clearly improves over the traditional NEAT algorithm in these tasks. A final example of the integration of this approach within a robot cognitive mechanism is also presented, showing the clear improvements it could provide in the modeling required for many cognitive processes.",Neural Processing Letters,2016,5,to_check,unknown
f5255357b82adb03c6c6729fc939bd1b82b22a02,https://www.semanticscholar.org/paper/f5255357b82adb03c6c6729fc939bd1b82b22a02,A weighted fuzzy C-means clustering method with density peak for anomaly detection in IoT-enabled manufacturing process,"Accurate anomaly detection is the premise of production process control and normal execution of production plan. The implementation of Internet of Things (IoT) provides data foundation and guarantee for real-time perception and detection of production state. Taking abundant IoT data as support, a density peak (DP)-weighted fuzzy C-means (WFCM) based clustering method is proposed to detect abnormal situations in production process. Firstly, a features correlation and redundancy measure method based on mutual information (MI) and conditional MI is proposed, unsupervised feature reduction is completed based on the principle of maximum correlation-minimum redundancy. Secondly, a DP-WFCM based clustering model is established to identify clusters with fewer samples to detect production anomalies. DP is used to obtain the initial clustering centers to solve the problem that FCM is sensitive to the initial centers and the clusters number needs to be determined manually in advance. MI-based similarities are introduced as weight coefficients to guide the clustering process, which improves convergence speed and clustering quality. Finally, a real case from an IoT enabled machining workshop is carried out to verify the accuracy and effectiveness of the proposed method in anomaly detection of manufacturing process.",J. Intell. Manuf.,2020,6,to_check,unknown
4d8fa54a23581d052296c31ae955cf711d01210f,https://www.semanticscholar.org/paper/4d8fa54a23581d052296c31ae955cf711d01210f,OFDM symbol identification by an unsupervised learning system under dynamically changing channel effects,"Orthogonal frequency-division multiplexing (OFDM) is one of the most successful digital communication techniques. Nevertheless, the decrease in inter-symbol interference in quadrature amplitude modulation (QAM) over dispersive channels is still challenging. Different researches recently proposed the idea of using unsupervised learning as an alternative to the classic approaches to equalization of OFDM channels. In those purposes, the identification of a received QAM symbol is possible by the comparison of its position on the in-phase/quadrature (IQ) plane relative to the positions of previously arrived symbols, generally processed by the Kohonen’s Self-Organizing Map (SOM) algorithm. This work presents the SOM unsupervised learning method executed on an embedded system applied to QAM symbols identification. The system is implemented on an FPGA, a configurable digital circuit able to meet the low power and parallel process requirements of mobile applications. Also, in order to extend the classical set of experiments to evaluate our system, this paper proposes a theoretical model of the time-varying scheme representing the transition between different channel characteristics, obtained from real measurements available on a public repository. The model is employed to verify our purpose under dynamically both changing and realistic conditions. On the assumption that it is provided enough IQ symbols for the initial training process, the hardware implementation of SOM is able to track and identify the time-varying distorted QAM constellation. No knowledge of channel characteristics is necessary. The system spends only some microseconds at start-up to reach about 100% performance, and no dedicated training phase is needed afterward.",Neural Computing and Applications,2018,7,to_check,unknown
116d6e724d0d15fbb2e84d741477102f9d988ed3,https://www.semanticscholar.org/paper/116d6e724d0d15fbb2e84d741477102f9d988ed3,iCub Whole-Body Control through Force Regulation on Rigid Non-Coplanar Contacts,"This paper details the implementation on the humanoid robot iCub of state-of-the-art algorithms for whole-body control. We regulate the forces between the robot and its surrounding environment to stabilize a desired robot posture. We assume that the forces and torques are exerted on rigid contacts. The validity of this assumption is guaranteed by constraining the contact forces and torques, e.g. the contact forces must belong to the associated friction cones. The implementation of this control strategy requires to estimate the external forces acting on the robot, and the internal joint torques. We then detail algorithms to obtain these estimations when using a robot with an iCub-like sensor set, i.e. distributed six-axis force-torque sensors and whole-body tactile sensors. A general theory for identifying the robot inertial parameters is also presented. From an actuation standpoint, we show how to implement a joint torque control in the case of DC brushless motors. In addition, the coupling mechanism of the iCub torso is investigated. The soundness of the entire control architecture is validated in a real scenario involving the robot iCub balancing and making contacts at both arms.",Front. Robot. AI,2015,8,to_check,unknown
cfc8a362f7f7e7b1bce51caac0db50dfb52b7f13,https://www.semanticscholar.org/paper/cfc8a362f7f7e7b1bce51caac0db50dfb52b7f13,Implementation of biomimetic central pattern generators on field-programmable gate array,"This study is a step towards the design of neuroprostheses using artificial biomimetic neural networks like the central pattern generator (CPG) we could find in the leech’s heartbeat system. We propose a resource-frugal implementation of CPG on a field-programmable gate array (FPGA) platform. Using Izhikevich’s neuron model and short-term plasticity synapse model, our implementation can host and mimic 500 CPGs in real time. Our results have been validated by comparing them to biological data. Our study shows a solid step towards hybridization of biological nervous system and artificial neural networks.",,2015,9,to_check,unknown
fab4b767e3ae70e8e04e991e8d626fe6b3184213,https://www.semanticscholar.org/paper/fab4b767e3ae70e8e04e991e8d626fe6b3184213,Learning Navigation Policies for Mobile Robots in Deep Reinforcement Learning with Random Network Distillation,"Learning navigation policies considers the task of training a model that can find collision-free paths for mobile robots, where various Deep Reinforcement Learning (DRL) methods have been applied with promising results. However, the natural reward function for the task is usually sparse, i.e., obtaining a penalty for the collision and a positive reward for arriving the target position, which makes it difficult to learn. In particular, for some complex navigation environments, it is hard to search a collision-free path by the random exploration, which leads to a rather slow learning speed and solutions with poor performance. In this paper, we propose a DRL based approach to train an end-to-end navigation planner, i.e, the policy neural network, that directly translates the local grid map and the relative goal of the robot into its moving actions. To handle the sparse reward problem, we augment the normal extrinsic reward from the environment with intrinsic reward signals measured by random network distillation (RND). In specific, the intrinsic reward is calculated by two different networks from RND, which encourages the agent to explore a state that has not been seen before. The experimental results show that by augmenting the reward function with intrinsic reward signals by RND, solutions with better performance can be learned more efficiently and more stably in our approach. We also deploy the trained model to a real robot, which can perform collision avoidance in navigation tasks without any parameter tuning. A video of our experiments can be found at https://youtu.be/b1GJrWfO8pw.",ICIAI,2021,10,to_check,unknown
1c9c12a5c9f3cfd9cd1eefbe818bfb92d37520ac,https://www.semanticscholar.org/paper/1c9c12a5c9f3cfd9cd1eefbe818bfb92d37520ac,"Cloud-based mission control of USV fleet: Architecture, implementation and experiments","Abstract In this paper, a cloud-based mission control architecture is proposed to achieve flexible remote access and coordinated mission control among a fleet of unmanned surface vehicles (USVs). First, a cloud-based mission control architecture that renders easy, timely and prioritized remote access to the USVs regardless of the remote operator’s location is proposed. It is achieved by leveraging remote cloud-based technology and local Operating onboard System. Decentralized property of the architecture accomplishes scalable monitoring, remote control, data acquisition and missions sharing for an USV fleet. Second, the related software interfaces are required for this task: the user interface of the remote client that is used for mission control/planning and data visualization and that is applicable across mobile robotic systems; and the back-end interface for the local USVs that bridges robotic and cloud server and provides seamless integration with the well-established Robot Operating System (ROS). ROS is nowadays, the most widely used framework for robotics developments. Furthermore, the proposed cloud-based mission control architecture is implemented on a fleet of real vehicles, H2Omni-X USVs, and the performance of the remote experimentation is demonstrated during sea trials at the Adriatic coast, Croatia, representing the practical contribution of this paper.",,2021,11,to_check,unknown
8193122b2cf5ec63ead24f36d3093f7f55e23d46,https://www.semanticscholar.org/paper/8193122b2cf5ec63ead24f36d3093f7f55e23d46,Cooperative Heterogeneous Multi-Robot Systems,"The emergence of the Internet of things and the widespread deployment of diverse computing systems have led to the formation of heterogeneous multi-agent systems (MAS) to complete a variety of tasks. Motivated to highlight the state of the art on existing MAS while identifying their limitations, remaining challenges, and possible future directions, we survey recent contributions to the field. We focus on robot agents and emphasize the challenges of MAS sub-fields including task decomposition, coalition formation, task allocation, perception, and multi-agent planning and control. While some components have seen more advancements than others, more research is required before effective autonomous MAS can be deployed in real smart city settings that are less restrictive than the assumed validation environments of MAS. Specifically, more autonomous end-to-end solutions need to be experimentally tested and developed while incorporating natural language ontology and dictionaries to automate complex task decomposition and leveraging big data advancements to improve perception algorithms for robotics.",ACM Comput. Surv.,2019,12,to_check,unknown
1a4696401d822c632735b070dacdf88a50c7acfc,https://www.semanticscholar.org/paper/1a4696401d822c632735b070dacdf88a50c7acfc,Towards robust grasps: Using the environment semantics for robotic object affordances,"In this talk I will look back over four years of long-term deployments of autonomous mobile robots in everyday environments. From this I will present examples of the kinds of things that mobile robots can learn over long autonomous operations in such environments, including navigation information, human activities, object models, and mission schedules. Following this I will explore the issues (software, hardware, and social) that impacted upon the autonomy of our deployed robots, and look at what we can learn from these experiences as both AI practitioners and as engineers deploying robots in real environments. Dr. Maarten Sierhuis, Chief Technology Director at Nissan Research Center Silicon Valley, Founder of Ejenta Title: Seamless Autonomous Mobility (SAM) Abstract: Artificial intelligence will make vehicles able to drive autonomously in a wide variety of scenarios. However, unexpected situations can still arise as these long-term autonomous vehicles interact in the world, potentially limiting the uses of fully autonomous driving in the near future. Nissan’s Seamless Autonomous Mobility provides a solution that can overcome this issue through the intelligent integration of humans. Artificial intelligence will make vehicles able to drive autonomously in a wide variety of scenarios. However, unexpected situations can still arise as these long-term autonomous vehicles interact in the world, potentially limiting the uses of fully autonomous driving in the near future. Nissan’s Seamless Autonomous Mobility provides a solution that can overcome this issue through the intelligent integration of humans. Dr. Peter Wurman, VP of Engineering at Cogitai, Former Co-founder of Kiva Systems Title: The Disruptive Power of Robots Abstract: Kiva Systems introduced swarms of agile robots into an industry dominated by stationary conveyor systems. The path from concept through successful startup and eventual acquisition involved challenges on all fronts. In this talk I’ll explain the business problem that motivated the innovation, Kiva technology and the benefits it brought to customers, and the future of applications of robotics in warehouses. Kiva Systems introduced swarms of agile robots into an industry dominated by stationary conveyor systems. The path from concept through successful startup and eventual acquisition involved challenges on all fronts. In this talk I’ll explain the business problem that motivated the innovation, Kiva technology and the benefits it brought to customers, and the future of applications of robotics in warehouses.",AAAI 2018,2018,13,to_check,unknown
7c1949a48e36e92e9bc44906fd5589c4653f9707,https://www.semanticscholar.org/paper/7c1949a48e36e92e9bc44906fd5589c4653f9707,Simultaneous Semantic and Collision Learning for 6-DoF Grasp Pose Estimation,"Grasping in cluttered scenes has always been a great challenge for robots, due to the requirement of the ability to well understand the scene and object information. Previous works usually assume that the geometry information of the objects is available, or utilize a step-wise, multi-stage strategy to predict the feasible 6-DoF grasp poses. In this work, we propose to formalize the 6-DoF grasp pose estimation as a simultaneous multi-task learning problem. In a unified framework, we jointly predict the feasible 6-DoF grasp poses, instance semantic segmentation, and collision information. The whole framework is jointly optimized and end-to-end differentiable. Our model is evaluated on large-scale benchmarks as well as the real robot system. On the public dataset, our method outperforms prior state-of-the-art methods by a large margin (+4.08 AP). We also demonstrate the implementation of our model on a real robotic platform and show that the robot can accurately grasp target objects in cluttered scenarios with a high success rate. Project link: https://openbyterobotics.github.io/sscl.",2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2021,14,to_check,unknown
a09d1ea248e56f9d82346f8df07be36a4594f49d,https://www.semanticscholar.org/paper/a09d1ea248e56f9d82346f8df07be36a4594f49d,Deep learning for picking point detection in dense cluster,"This paper considers the problem of picking objects in cluster. This requires the robot to reliably detect the picking point for the known or unseen objects under the environment with occlusion, disorder and a variety of objects. We present a novel pipeline to detect picking point based on deep convolutional neural network (CNN). A two-dimensional picking configuration is proposed, thus an extensive data augmentation strategy is enabled and a labeled dataset is established quickly and easily. At last, we demonstrate the implementation of our method on a real robot and show that our method can accurately detect picking point of unseen objects and achieve a pick success of 91% in cluster bin-picking scenario.",2017 11th Asian Control Conference (ASCC),2017,15,to_check,unknown
119678648278fca3190f865e634409d78f730719,https://www.semanticscholar.org/paper/119678648278fca3190f865e634409d78f730719,CloudAAE: Learning 6D Object Pose Regression with On-line Data Synthesis on Point Clouds,"It is often desired to train 6D pose estimation systems on synthetic data because manual annotation is expensive. However, due to the large domain gap between the synthetic and real images, synthesizing color images is expensive. In contrast, this domain gap is considerably smaller and easier to fill for depth information. In this work, we present a system that regresses 6D object pose from depth information represented by point clouds, and a lightweight data synthesis pipeline that creates synthetic point cloud segments for training. We use an augmented autoencoder (AAE) for learning a latent code that encodes 6D object pose information for pose regression. The data synthesis pipeline only requires texture-less 3D object models and desired viewpoints, and it is cheap in terms of both time and hardware storage. Our data synthesis process is up to three orders of magnitude faster than commonly applied approaches that render RGB image data. We show the effectiveness of our system on the LineMOD, LineMOD Occlusion, and YCB Video datasets. The implementation of our system is available at: https://github.com/GeeeG/CloudAAE.",2021 IEEE International Conference on Robotics and Automation (ICRA),2021,16,to_check,unknown
ac95ec8f7d53365e3a03d88d77cce81a02193f5b,https://www.semanticscholar.org/paper/ac95ec8f7d53365e3a03d88d77cce81a02193f5b,Hardware Acceleration of Monte-Carlo Sampling for Energy Efficient Robust Robot Manipulation,"Algorithms based on Monte-Carlo sampling have been widely adapted in robotics and other areas of engineering due to their performance robustness. However, these sampling-based approaches have high computational requirements, making them unsuitable for real-time applications with tight energy constraints. In this paper, we investigate 6 degree-of-freedom (6DoF) pose estimation for robot manipulation using this method, which uses rendering combined with sequential Monte-Carlo sampling. While potentially very accurate, the significant computational complexity of the algorithm makes it less attractive for mobile robots, where runtime and energy consumption are tightly constrained. To address these challenges, we develop a novel hardware implementation of Monte-Carlo sampling on an FPGA with lower computational complexity and memory usage, while achieving high parallelism and modularization. Our results show 12X–21X improvements in energy efficiency over low-power and high-end GPU implementations, respectively. Moreover, we achieve real time performance without compromising accuracy.",2020 30th International Conference on Field-Programmable Logic and Applications (FPL),2020,17,to_check,unknown
f47d2bba0458de7953a58619cd4a51ce4cc19d9c,https://www.semanticscholar.org/paper/f47d2bba0458de7953a58619cd4a51ce4cc19d9c,Acceleration Techniques for Energy Efficient Sampling based Machine Learning,"Deep learning algorithms based on convolutional neural networks (CNNs) have led to major improvements in accuracy for such tasks as object recognition. However, CNNs may not have sufficient robustness when presented with challenging or new scenarios (e.g, from unstructured or changing environments). Alternatively, algorithms based on Monte-Carlo sampling have been widely adapted in robotics and other areas of engineering due to their performance robustness. However, these sampling-based approaches have high computational requirements, making them unsuitable for real-time applications with tight energy constraints. In this paper, we investigate 6 degree-offreedom (6DoF) pose estimation for robot manipulation using this method, which uses rendering combined with sequential MonteCarlo sampling. While potentially very accurate, the significant computational complexity of the algorithm makes it less attractive for mobile robots, where runtime and energy consumption are tightly constrained. To address these challenges, we develop a novel hardware implementation of Monte-Carlo sampling on an FPGA with lower computational complexity and memory usage, while achieving high parallelism and modularization. Our results show 12X–21X improvements in energy efficiency over low-power and high-end GPU implementations, respectively. Moreover, we achieve real time performance without compromising accuracy.",,2020,18,to_check,unknown
aba7b3fbbbb87ca37b0df1f7e6c28dec185f7905,https://www.semanticscholar.org/paper/aba7b3fbbbb87ca37b0df1f7e6c28dec185f7905,Pose Estimation for Texture-less Shiny Objects in a Single RGB Image Using Synthetic Training Data,"In the industrial domain, the pose estimation of multiple texture-less shiny parts is a valuable but challenging task. In this particular scenario, it is impractical to utilize keypoints or other texture information because most of them are not actual features of the target but the reflections of surroundings. Moreover, the similarity of color also poses a challenge in segmentation. In this article, we propose to divide the pose estimation process into three stages: object detection, features detection and pose optimization. A convolutional neural network was utilized to perform object detection. Concerning the reliability of surface texture, we leveraged the contour information for estimating pose. Since conventional contour-based methods are inapplicable to clustered metal parts due to the difficulties in segmentation, we use the dense discrete points along the metal part edges as semantic keypoints for contour detection. Afterward, we exploit both keypoint information and CAD model to calculate the 6D pose of each object in view. A typical implementation of deep learning methods not only requires a large amount of training data, but also relies on intensive human labor for labeling the datasets. Therefore, we propose an approach to generate datasets and label them automatically. Despite not using any real-world photos for training, a series of experiments showed that the algorithm built on synthetic data perform well in the real environment.",ArXiv,2019,19,to_check,unknown
6e6ae08259b22ac769c9a81a62f9752eb2b9e732,https://www.semanticscholar.org/paper/6e6ae08259b22ac769c9a81a62f9752eb2b9e732,Applying CORBA Technology for the Teleoperation of Wheeeler,"In this paper, we present development of Wheeeler - the hyper mobile robot. Hyper mobile robots belong to the group of highly articulated robots, sometimes called “snake-like” or serpentine robots. Wheeeler has 7 segments driven by wheels and interconnected by 2 degrees- of-freedom joints (Fig. 28.1). This machine is expected to operate in rough terrain, traverse stairs and trenches, avoid obstacles, or climb over them, and also pass through tight spaces. Our project is in the simulation stage and currently we focus on the communication issues. Although, modeling and tests are performed in simulator (Webots 5 PRO) now, the same control software will work with real robot soon. In this paper, we shortly present the actual version of model; introduce the sensory suite and local controllers’ configuration. In the main paragraph we present the implementation of CORBA technology in client-server communication.",RoMoCo,2007,20,to_check,unknown
1abdeafe4b6e36e2566ffc0054b2357c3929baae,https://www.semanticscholar.org/paper/1abdeafe4b6e36e2566ffc0054b2357c3929baae,One-Shot Imitation Filming of Human Motion Videos,"Imitation learning has been applied to mimic the operation of a human cameraman in several autonomous cinematography systems. To imitate different filming styles, existing methods train multiple models, where each model handles a particular style and requires a significant number of training samples. As a result, existing methods can hardly generalize to unseen styles. In this paper, we propose a framework, which can imitate a filming style by ""seeing"" only a single demonstration video of the same style, i.e., one-shot imitation filming. This is done by two key enabling techniques: 1) feature extraction of the filming style from the demo video, and 2) filming style transfer from the demo video to the new situation. We implement the approach with deep neural network and deploy it to a 6 degrees of freedom (DOF) real drone cinematography system by first predicting the future camera motions, and then converting them to the drone's control commands via an odometer. Our experimental results on extensive datasets and showcases exhibit significant improvements in our approach over conventional baselines and our approach can successfully mimic the footage with an unseen style.",ArXiv,2019,21,to_check,unknown
e6debe8731daadf256ba4005fd291f85792885b4,https://www.semanticscholar.org/paper/e6debe8731daadf256ba4005fd291f85792885b4,Can a Robot Become a Movie Director? Learning Artistic Principles for Aerial Cinematography,"Aerial filming is constantly gaining importance due to the recent advances in drone technology. It invites many intriguing, unsolved problems at the intersection of aesthetical and scientific challenges. In this work, we propose a deep reinforcement learning agent which supervises motion planning of a filming drone by making desirable shot mode selections based on aesthetical values of video shots. Unlike most of the current state-of-the-art approaches that require explicit guidance by a human expert, our drone learns how to make favorable viewpoint selections by experience. We propose a learning scheme that exploits aesthetical features of retrospective shots in order to extract a desirable policy for better prospective shots. We train our agent in realistic AirSim simulations using both a hand-crafted reward function as well as reward from direct human input. We then deploy the same agent on a real DJI M210 drone in order to test the generalization capability of our approach to real world conditions. To evaluate the success of our approach in the end, we conduct a comprehensive user study in which participants rate the shot quality of our methods. Videos of the system in action can be seen at https://youtu.be/qmVw6mfyEmw.",2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2019,22,to_check,unknown
https://www.sciencedirect.com/science/article/pii/S2352711021001837,https://www.sciencedirect.com/science/article/pii/S2352711021001837,tx2_fcnn_node: An open-source ROS compatible tool for monocular depth reconstruction,"We present tx2_fcnn_node a Robot Operating System (ROS) compatible tool that is aimed at seamless integration of various monocular depth reconstruction neural networks to the robotic software based on ROS (which is a de-facto standard in the area of robotics). Our tool simplifies the process of deploying, evaluating, and comparing depth reconstruction neural networks both on real robots and in simulation. We complement our software with a set of the precompiled neural networks which can be used off the shelf, with some of them being able to demonstrate near real-time performance when running onboard compact embedded platforms, e.g. Nvidia Jetson TX2, that are often used nowadays both in academia and industry.",Sciencedirect,2022,23,to_check,unknown
845c1a9a43924a5ac907861f3b98f8f32f009832,https://www.semanticscholar.org/paper/845c1a9a43924a5ac907861f3b98f8f32f009832,"Internet of Robotic Things: Concept, Technologies, and Challenges","Internet of Things allow massive number of uniquely addressable “things” to communicate with each other and transfer data over existing internet or compatible network protocols. This paper proposes a new concept which tackles the issues for supporting control and monitoring activities at deployment sites and industrial automations, where intelligent things can monitor peripheral events, induce sensor data acquired from a variety of sources, use ad hoc, local, and distributed “machine intelligence” to determine appropriate course of actions, and then act to control or disseminate static or dynamic position aware robotic things in the physical world through a seamless manner by providing a means for utilizing them as Internet of robotic things (IoRT). Although progressive advancements can be seen in multi-robotic systems, robots are constantly getting enriched by easier developmental functionalities, such vertical robotic service centric silos are not enough for continuously and seamlessly supporting for which they are meant. In this paper, a novel concept—IoRT is presented that highlights architectural principles, vital characteristics, as well as research challenges. The aim of this paper is to provide a better understanding of the architectural assimilation of IoRT and identify important research directions on this term.",IEEE Access,2016,24,to_check,unknown
