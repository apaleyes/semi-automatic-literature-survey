paperId,url,title,abstract,venue,year,id,type
7f4d129454480cea7683c5ed610c128876b6e12f,https://www.semanticscholar.org/paper/7f4d129454480cea7683c5ed610c128876b6e12f,Technology enablers for the implementation of Industry 4.0 to traditional manufacturing sectors: A review,"The traditional manufacturing sectors (footwear, textiles and clothing, furniture and toys, among others) are based on small and medium enterprises with limited capacity on investing in modern production technologies. Although these sectors rely heavily on product customization and short manufacturing cycles, they are still not able to take full advantage of the fourth industrial revolution. Industry 4.0 surfaced to address the current challenges of shorter product life-cycles, highly customized products and stiff global competition. The new manufacturing paradigm supports the development of modular factory structures within a computerized Internet of Things environment. With Industry 4.0, rigid planning and production processes can be revolutionized. However, the computerization of manufacturing has a high degree of complexity and its implementation tends to be expensive, which goes against the reality of SMEs that power the traditional sectors. This paper reviews the main scientific-technological advances that have been developed in recent years in traditional sectors with the aim of facilitating the transition to the new industry standard.",Comput. Ind.,2021,1,filtered
f93f4b617bc453a8c7d0891c3c6599a653541f2c,https://www.semanticscholar.org/paper/f93f4b617bc453a8c7d0891c3c6599a653541f2c,"Crop-planning, making smarter agriculture with climate data","Agriculture has an important tradition in Latin America and large areas have maintained stable conditions for decades with constant practices and yield. Planning processes in those areas have not suffered any change for years and some countries like Colombia have not modified its rural policies in the last three of four decades; on the other hand, natural and environmental conditions have changed dramatically in the last years as a consequence of climate change and climate variability modifying established practices for traditional crops. Since farmers have suffered several effects on its production process they have realized the importance of supporting future actions on reliable climate data, scientific development have also grown in last decades and planning offices are looking for better practices, today' scientists and planning offices are trying to link all this reality in a new paradigm called “Climate Smart Agriculture”. The Research program on Climate Change, Agriculture and Food Security - CCAFS follows this interest of linking its research results with open data sources, software developers and Latin American problems therefore in 2014 they performed a hackathon in Lima to develop new applications that help farmers to support their decision on scientific information. “Crop-planning” is one product designed and developed at CCAFS's hackathon conceived as a worldwide platform for sharing and sowing crop calendars and agro-climate data, it compiles open dataset like historical production, land cover, local climate conditions and integrates an interface for crowdsourced collection of dates of agricultural activities, it is designed to offer easy access to relevant data and updated crop calendars from farmers and also share management practices from local authorities. Although it is farmer oriented, principal users are technical assistants that deal with the application and share knowledge with farmers, they will use their experience to warranty knowledge management and overcome technical difficulties of web and mobile platforms in rural areas.",2015 Fourth International Conference on Agro-Geoinformatics (Agro-geoinformatics),2015,2,filtered
b9471a96b47736fcf142c1da53f927b51e59706f,https://www.semanticscholar.org/paper/b9471a96b47736fcf142c1da53f927b51e59706f,3D camera-based markerless navigation system for robotic osteotomies,"Abstract A markerless system for the registration of a bone’s pose is presented which reduces the setup time and the damage to the bone to a minimum. For the registration, a particle filter is implemented which is able to estimate a bone’s pose using depth images. In a phantom study, the pose of 3D-printed bones has been estimated at a rate of 90 Hz and with a precision of a few millimeters. The particle filter is stable under partial occlusions and only diverges when the bone is fully occluded. During a cadaver study, the preoperatively planned cutting edges have been projected as augmented reality (AR) templates onto the hip bones of five cadavers. By cutting manually along the AR templates, surgeons were able to extract ten transplants in the same time as with conventional osteotomy templates. Using the presented navigation system can save hours spent on the construction and production of conventional templates. In conclusion, this work represents one step towards a broader acceptance of robotic osteotomies.",Autom.,2020,3,filtered
26cfc16bcbb7ec8dce6a3dc410d14cd2cf383623,https://www.semanticscholar.org/paper/26cfc16bcbb7ec8dce6a3dc410d14cd2cf383623,Contextual Reinforcement Learning of Visuo-tactile Multi-fingered Grasping Policies,"Using simulation to train robot manipulation policies holds the promise of an almost unlimited amount of training data, generated safely out of harm's way. One of the key challenges of using simulation, to date, has been to bridge the reality gap, so that policies trained in simulation can be deployed in the real world. We explore the reality gap in the context of learning a contextual policy for multi-fingered robotic grasping. We propose a Grasping Objects Approach for Tactile (GOAT) robotic hands, learning to overcome the reality gap problem. In our approach we use human hand motion demonstration to initialize and reduce the search space for learning. We contextualize our policy with the bounding cuboid dimensions of the object of interest, which allows the policy to work on a more flexible representation than directly using an image or point cloud. Leveraging fingertip touch sensors in the hand allows the policy to overcome the reduction in geometric information introduced by the coarse bounding box, as well as pose estimation uncertainty. We show our learned policy successfully runs on a real robot without any fine tuning, thus bridging the reality gap.",ArXiv,2019,4,filtered
c138133577e40f56f64be95ab493a678bc6ee325,https://www.semanticscholar.org/paper/c138133577e40f56f64be95ab493a678bc6ee325,"Measuring User Experience, Usability and Interactivity of a Personalized Mobile Augmented Reality Training System","Innovative technology has been an important part of firefighting, as it advances firefighters’ safety and effectiveness. Prior research has examined the implementation of training systems using augmented reality (AR) in other domains, such as welding, aviation, army, and mathematics, offering significant pedagogical affordances. Nevertheless, firefighting training systems using AR are still an under-researched area. The increasing penetration of AR for training is the driving force behind this study, and the scope is to analyze the main aspects affecting the acceptance of AR by firefighters. The current research uses a technology acceptance model, extended by the external constructs of perceived interactivity and personalization, to consider both the system and individual level. The proposed model was evaluated by a sample of 200 users, and the results show that both the external variables of perceived interactivity and perceived personalization are prerequisite factors in extending the TAM model. The findings reveal that the usability is the strongest predictor of firefighters’ behavioral intentions to use the AR system, followed by the ease of use with smaller, yet meaningful, direct and indirect effects on firefighters’ intentions. The identified acceptance factors help AR developers enhance the firefighters’ experience in training operations.",Sensors,2021,5,filtered
d325aa9305ec92a75511dff3c5b2cdcc8b6c3953,https://www.semanticscholar.org/paper/d325aa9305ec92a75511dff3c5b2cdcc8b6c3953,Deep Reinforcement Learning with Shallow Controllers: An Experimental Application to PID Tuning,"Deep reinforcement learning (RL) is an optimization-driven framework for producing control strategies for general dynamical systems without explicit reliance on process models. Good results have been reported in simulation. Here we demonstrate the challenges in implementing a state of the art deep RL algorithm on a real physical system. Aspects include the interplay between software and existing hardware; experiment design and sample efficiency; training subject to input constraints; and interpretability of the algorithm and control law. At the core of our approach is the use of a PID controller as the trainable RL policy. In addition to its simplicity, this approach has several appealing features: No additional hardware needs to be added to the control system, since a PID controller can easily be implemented through a standard programmable logic controller; the control law can easily be initialized in a “safe” region of the parameter space; and the final product—a well-tuned PID controller—has a form that practitioners can reason about and deploy with confidence.",ArXiv,2021,6,filtered
24f9cec3c63d0a37a709bbccdf55c55a7770614d,https://www.semanticscholar.org/paper/24f9cec3c63d0a37a709bbccdf55c55a7770614d,Double Q-PID algorithm for mobile robot control,"Abstract Many expert systems have been developed for self-adaptive PID controllers of mobile robots. However, the high computational requirements of the expert systems layers, developed for the tuning of the PID controllers, still require previous expert knowledge and high efficiency in algorithmic and software execution for real-time applications. To address these problems, in this paper we propose an expert agent-based system, based on a reinforcement learning agent, for self-adapting multiple low-level PID controllers in mobile robots. For the formulation of the artificial expert agent, we develop an incremental model-free algorithm version of the double Q -Learning algorithm for fast on-line adaptation of multiple low-level PID controllers. Fast learning and high on-line adaptability of the artificial expert agent is achieved by means of a proposed incremental active-learning exploration-exploitation procedure, for a non-uniform state space exploration, along with an experience replay mechanism for multiple value functions updates in the double Q -learning algorithm. A comprehensive comparative simulation study and experiments in a real mobile robot demonstrate the high performance of the proposed algorithm for a real-time simultaneous tuning of multiple adaptive low-level PID controllers of mobile robots in real world conditions.",Expert Syst. Appl.,2019,7,filtered
5b6220c4f7d20a43fa80821a69c7eb2524f03133,https://www.semanticscholar.org/paper/5b6220c4f7d20a43fa80821a69c7eb2524f03133,Perceptual Generalization and Context in a Network Memory Inspired Long-Term Memory for Artificial Cognition,"In the framework of open-ended learning cognitive architectures for robots, this paper deals with the design of a Long-Term Memory (LTM) structure that can accommodate the progressive acquisition of experience-based decision capabilities, or what different authors call ""automation"" of what is learnt, as a complementary system to more common prospective functions. The LTM proposed here provides for a relational storage of knowledge nuggets given the form of artificial neural networks (ANNs) that is representative of the contexts in which they are relevant in a configural associative structure. It also addresses the problem of continuous perceptual spaces and the task- and context-related generalization or categorization of perceptions in an autonomous manner within the embodied sensorimotor apparatus of the robot. These issues are analyzed and a solution is proposed through the introduction of two new types of knowledge nuggets: P-nodes representing perceptual classes and C-nodes representing contexts. The approach is studied and its performance evaluated through its implementation and application to a real robotic experiment.",Int. J. Neural Syst.,2019,8,filtered
31d1df842f56f0eb592886aac0a93ec93128a505,https://www.semanticscholar.org/paper/31d1df842f56f0eb592886aac0a93ec93128a505,CIT: Integrated cognitive computing and cognitive agent technologies based cognitive architecture for human-like functionality in artificial systems,"Abstract The paper proposes a novel cognitive architecture that combines cognitive computing and cognitive agent technologies for performing human-like functionality. The system architecture is known as CIT (Cognitive Information Technology). This design takes advantage of cognitive computing to handle Experiential Information (EI) using audio processing, computer vision, natural language processing, text mining, and data mining techniques. The CIT architecture includes human like cognitive agent functionality comprising attention, learning, memory, action selection, and action to handle human like individual and distributed knowledge bases to create rational decisions. The work shows CIT architecture practical implementation through “CIT framework” developed in C# and python language. For validating the system performance, the paper shows CIT based Object Recognition and Question Answering System. This framework is anticipated to advance the quality of artificial intelligent agent based decision-making using human like perception, comprehend and action skills, reducing real world business errors and assuring the correct, accurate, knowledgeable and well-timed human like decisions.",Biologically Inspired Cognitive Architectures,2018,9,filtered
76f958640687b379aec44e5293c5b40d1cc39ece,https://www.semanticscholar.org/paper/76f958640687b379aec44e5293c5b40d1cc39ece,Utility Model Re-description within a Motivational System for Cognitive Robotics,"This paper describes a re-descriptive approach to the efficient acquisition of ever higher level and more precise utility models within the motivational system (MotivEn) of a cognitive architecture. The approach is based on a two-step process whereby, as a first step, simple imprecise sensor correlation related utility models are obtained from the interaction traces of the robot. These utility models allow the robot to increase the frequency of achieving goals, and thus, provide lots of traces that can be used to try to train precise value functions implemented as artificial neural networks. The approach is tested experimentally on a real robotic setup that involves the coordination of two robots.",2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2018,10,filtered
bc65f99c5fc710d8f2a2ae3445af367f2eb98a60,https://www.semanticscholar.org/paper/bc65f99c5fc710d8f2a2ae3445af367f2eb98a60,Multilevel Darwinist Brain: Context Nodes in a Network Memory Inspired Long Term Memory,"The Multilevel Darwinist Brain (MDB) is a cognitive architecture aimed at providing autonomous and self-motivated life-long learning capabilities for robots. This paper deals with a new structure and implementation for the long term memory (LTM) in MDB based on Fuster’s concept of Network memory and on the introduction of a new type of node or cognit called Context Node (Cnode). The idea of Network memory as proposed here, provides a path to hierarchically and progressively relate LTM knowledge elements, allowing for a developmental approach to learning that permits very efficient experience based responses from the robot. We include a simple, albeit quite illustrative, example of the application of these ideas using a real Baxter robot.",IWINAC,2017,11,filtered
dcbbe1d306b7ef25c2e9c5a5ba1599d79d03909c,https://www.semanticscholar.org/paper/dcbbe1d306b7ef25c2e9c5a5ba1599d79d03909c,Motivational engine with autonomous sub-goal identification for the Multilevel Darwinist Brain,"Abstract This work proposes a motivational system for an autonomous robot that guides the fulfillment of its goals in a developmental manner, discovering sub-goals not only as a way to simplify goal achievement, but as a way to acquire knowledge in an incremental, modular and reusable fashion. This system has been called MotivEn (Motivational Engine) and we have carried out its initial integration within the Multilevel Darwinist Brain (MDB) cognitive architecture. We describe here the main elements of MotivEn and how they improve the current MDB operation. Moreover, we present in detail a specific implementation of MotivEn and the application results obtained in terms of sub-goal identification when applying it in a real robot experiment with the MDB.",BICA 2016,2016,12,filtered
102f3f5f75401b1a70a6d3af4cf6f5df11ecb925,https://www.semanticscholar.org/paper/102f3f5f75401b1a70a6d3af4cf6f5df11ecb925,Introducing Synaptic Delays in the NEAT Algorithm to Improve Modelling in Cognitive Robotics,"This paper describes and tests an approach to improve the temporal processing capabilities of the neuroevolution of augmenting topologies (NEAT) algorithm. This algorithm is quite popular within the robotics community for the production of trained neural networks without having to determine a priori their size and topology. The main drawback of the traditional NEAT algorithm is that, even though it can implement recurrent synaptic connections, which allow it to perform some time related processing tasks, its capabilities are rather limited, especially when dealing with precise time dependent phenomena. NEAT’s ability to capture the underlying dynamics that correspond to complex time series still has a lot of room for improvement. To address this issue, the paper describes a new implementation of the NEAT algorithm that is able to generate artificial neural networks (ANNs) with trainable time delayed synapses in addition to its previous capacities. We show that this approach, called tao-NEAT improves the behavior of the neural networks obtained when dealing with complex time related processes. Several examples are presented, both dealing with the generation of ANNs that are able to produce complex theoretical signals such as chaotic signals or real data series, as in the case of the monthly number of international airline passengers or monthly $$\hbox {CO}_{2}$$CO2 concentrations. In these examples, t-NEAT clearly improves over the traditional NEAT algorithm in these tasks. A final example of the integration of this approach within a robot cognitive mechanism is also presented, showing the clear improvements it could provide in the modeling required for many cognitive processes.",Neural Processing Letters,2016,13,filtered
6fdc3a95b3b10dab13c7c4166daf2d013691ca20,https://www.semanticscholar.org/paper/6fdc3a95b3b10dab13c7c4166daf2d013691ca20,A Multiple Context Brain for Experiments With Robot Consciousness,"The PURR-PUSS system (PP) is a versatile model of a human-like brain, designed to be implemented in parallel hardware and embodied in the head of a robot moving in the real world. The aim of the research with PP is to try out mechanisms for learning, intelligence and consciousness. Limitations of resources have dictated that the experiments with PP are made on a personal computer by simulating the brain and robot body in a microworld. The unique features of PP are multiple context and novelty-seeking. In this paper, a squash-pop microworld is described first, so that concrete examples can be given for a brief review of the PP system, followed by two new features called trail memory, to realize Baars' global workspace, and belief memory, to realize Rosenthal's higher order thoughts and Johnson-Laird's conscious reasoning. The extended system, PP*, is designed to give consciousness to the subconscious PP, but higher order thoughts and conscious reasoning prove to be elusive. A definition of a conscious robot provides a measure of progress.",IEEE Transactions on Autonomous Mental Development,2011,14,filtered
85180e4e393d6da898ce3979eaeed3abb2e2a138,https://www.semanticscholar.org/paper/85180e4e393d6da898ce3979eaeed3abb2e2a138,Adaptivity on the Robot Brain Architecture Level Using Reinforcement Learning,"The design and implementation of a robot brain often requires making decisions between different modules with similar functionality. Many implementations and components are easy to create or can be downloaded, but it is difficult to assess which combination of modules work well and which does not. This paper discusses a reinforcement learning mechanism where the robot is choosing between the different components using empirical feedback and optimization criteria. With the interval estimation algorithm the robot deselects poorly functioning modules and retains only the best ones. A discount factor ensures that the robot keeps adapting to new circumstances in the real world. This allows the robot to adapt itself continuously on the architecture level and also allows working with large development teams creating several different implementations with similar functionalities to give the robot biggest chance to solve a task. The architecture is tested in the RoboCup@Home setting and can handle failure situations.",RoboCup,2012,15,filtered
13e35abae4e70dcbab11fbf87a63df996cb70feb,https://www.semanticscholar.org/paper/13e35abae4e70dcbab11fbf87a63df996cb70feb,Internet of Things for the Future of Smart Agriculture: A Comprehensive Survey of Emerging Technologies,"This paper presents a comprehensive review of emerging technologies for the internet of things (IoT)-based smart agriculture. We begin by summarizing the existing surveys and describing emergent technologies for the agricultural IoT, such as unmanned aerial vehicles, wireless technologies, open-source IoT platforms, software defined networking (SDN), network function virtualization (NFV) technologies, cloud/fog computing, and middleware platforms. We also provide a classification of IoT applications for smart agriculture into seven categories: including smart monitoring, smart water management, agrochemicals applications, disease management, smart harvesting, supply chain management, and smart agricultural practices. Moreover, we provide a taxonomy and a side-by-side comparison of the state-of-the-art methods toward supply chain management based on the blockchain technology for agricultural IoTs. Furthermore, we present real projects that use most of the aforementioned technologies, which demonstrate their great performance in the field of smart agriculture. Finally, we highlight open research challenges and discuss possible future research directions for agricultural IoTs.",IEEE/CAA Journal of Automatica Sinica,2021,16,filtered
cb0630bbe0f22662abae83a44cf26ef70814c4e7,https://www.semanticscholar.org/paper/cb0630bbe0f22662abae83a44cf26ef70814c4e7,Digital Livestock Farming,"Abstract As the global human population increases, livestock agriculture must adapt to provide more livestock products and with improved efficiency while also addressing concerns about animal welfare, environmental sustainability, and public health. The purpose of this paper is to critically review the current state of the art in digitalizing animal agriculture with Precision Livestock Farming (PLF) technologies, specifically biometric sensors, big data, and blockchain technology. Biometric sensors include either noninvasive or invasive sensors that monitor an individual animal’s health and behavior in real time, allowing farmers to integrate this data for population-level analyses. Real-time information from biometric sensors is processed and integrated using big data analytics systems that rely on statistical algorithms to sort through large, complex data sets to provide farmers with relevant trending patterns and decision-making tools. Sensors enabled blockchain technology affords secure and guaranteed traceability of animal products from farm to table, a key advantage in monitoring disease outbreaks and preventing related economic losses and food-related health pandemics. Thanks to PLF technologies, livestock agriculture has the potential to address the abovementioned pressing concerns by becoming more transparent and fostering increased consumer trust. However, new PLF technologies are still evolving and core component technologies (such as blockchain) are still in their infancy and insufficiently validated at scale. The next generation of PLF technologies calls for preventive and predictive analytics platforms that can sort through massive amounts of data while accounting for specific variables accurately and accessibly. Issues with data privacy, security, and integration need to be addressed before the deployment of multi-farm shared PLF solutions becomes commercially feasible.",,2021,17,filtered
f5255357b82adb03c6c6729fc939bd1b82b22a02,https://www.semanticscholar.org/paper/f5255357b82adb03c6c6729fc939bd1b82b22a02,A weighted fuzzy C-means clustering method with density peak for anomaly detection in IoT-enabled manufacturing process,"Accurate anomaly detection is the premise of production process control and normal execution of production plan. The implementation of Internet of Things (IoT) provides data foundation and guarantee for real-time perception and detection of production state. Taking abundant IoT data as support, a density peak (DP)-weighted fuzzy C-means (WFCM) based clustering method is proposed to detect abnormal situations in production process. Firstly, a features correlation and redundancy measure method based on mutual information (MI) and conditional MI is proposed, unsupervised feature reduction is completed based on the principle of maximum correlation-minimum redundancy. Secondly, a DP-WFCM based clustering model is established to identify clusters with fewer samples to detect production anomalies. DP is used to obtain the initial clustering centers to solve the problem that FCM is sensitive to the initial centers and the clusters number needs to be determined manually in advance. MI-based similarities are introduced as weight coefficients to guide the clustering process, which improves convergence speed and clustering quality. Finally, a real case from an IoT enabled machining workshop is carried out to verify the accuracy and effectiveness of the proposed method in anomaly detection of manufacturing process.",J. Intell. Manuf.,2020,18,filtered
e716a1d60fc26fedd5d86ec1ed8f02d4fdd1fe81,https://www.semanticscholar.org/paper/e716a1d60fc26fedd5d86ec1ed8f02d4fdd1fe81,Artificial intelligence techniques for enabling Big Data services in distribution networks: A review,"Abstract Artificial intelligence techniques lead to data-driven energy services in distribution power systems by extracting value from the data generated by the deployed metering and sensing devices. This paper performs a holistic analysis of artificial intelligence applications to distribution networks, ranging from operation, monitoring and maintenance to planning. The potential artificial intelligence techniques for power system applications and needed data sources are identified and classified. The following data-driven services for distribution networks are analyzed: topology estimation, observability, fraud detection, predictive maintenance, non-technical losses detection, forecasting, energy management systems, aggregated flexibility services and trading. A review of the artificial intelligence methods implemented in each of these services is conducted. Their interdependencies are mapped, proving that multiple services can be offered as a single clustered service to different stakeholders. Furthermore, the dependencies between the AI techniques with each energy service are identified. In recent years there has been a significant rise of deep learning applications for time series prediction tasks. Another finding is that unsupervised learning methods are mainly being applied to customer segmentation, buildings efficiency clustering and consumption profile grouping for non-technical losses detection. Reinforcement learning is being widely applied to energy management systems design, although more testing in real environments is needed. Distribution network sensorization should be enhanced and increased in order to obtain larger amounts of valuable data, enabling better service outcomes. Finally, the future opportunities and challenges for applying artificial intelligence in distribution grids are discussed.",,2021,19,filtered
4d5a882e125d41124fa895b3d68e9e8dfd80f235,https://www.semanticscholar.org/paper/4d5a882e125d41124fa895b3d68e9e8dfd80f235,A bibliographic review of trends in design and management of electrical power transmission transformers,"Electricity transmission substations are fixed infrastructure assets, and the power transformer is the most visible item of equipment. The technologies embedded in protection and control switchgear, as well as in power transformers change over the very long life of a substation, even though the basic functionality remains the same. Changes in equipment technologies present salient but real challenges in design of electricity transmission networks, and especially on acquisition, operation and maintenance, and disposal of transformers deployed in substations. In addition to obsolescence, some of the challenges include age-related degradation, as well as increasingly sophisticated loading requirements on substations. A bibliographic search between 1970 and 2014 indicates that new materials plus computer-aided modelling and tools are widely applied to design and manufacture transformers to achieve higher voltage and power ratings, while sensors, information and computing systems technologies and big data analytics are increasing applied to determine transformer health index. Empirical data obtained from a case study utility suggests that operators and maintainers tend to focus on technical health indices, and this raises concern as to the robustness of decisions to decommission, refurbish, replace, and dispose of transformers in electricity transmission substations. Keywords—electrical transformer technology trends; transformer replacement decisions; substation asset management",,2016,20,filtered
8abc1240fd02c210ad2a95f7e12c53ee61c26680,https://www.semanticscholar.org/paper/8abc1240fd02c210ad2a95f7e12c53ee61c26680,"Modeling, simulation, and implementation issues of CPGs for neuromorphic engineering applications","Neuromorphic engineering is a discipline used to develop hardware, which can mimic the characteristics and abilities of biological systems by investigating their physiological structures and data transfer mechanisms. The recent studies about the neuromorphic systems mostly consist of robotic applications whose designs are inspired by Central Pattern Generators (CPGs). CPGs are special neural networks which can produce coordinated rhythmic activity patterns and these rhythmic movements are modeled mathematically, tested with simulation programs and verified by hardware implementations. A reconfigurable hardware platform (Field Programmable Gate Array “FPGA”) is compatible with numerical simulation tools, allows software control over hardware, has a user‐friendly interface and allows real time modifications. Thus, recently, it is preferred in CPG based robotic applications. In this study, the details of the modeling, simulation and implementation stages of several CPG structures are introduced by using a digital reconfigurable hardware platform. In order to show the conceptual learning achievements of these stages and to assess the contribution to the modeling, simulation and implementation skills of the students, a training course has been planned for the undergraduate students at Erciyes University. This process has been held in an educative manner supported by a survey and an experimental examination, so that this training course has been evaluated by the trainees in terms of the advantage, practicality, and challenge.",Comput. Appl. Eng. Educ.,2018,21,filtered
22d86c1d6d359fbd5a4c05579cfabd01b58eccb3,https://www.semanticscholar.org/paper/22d86c1d6d359fbd5a4c05579cfabd01b58eccb3,A Novel Hardware-Efficient CPG Model Based on Nonlinear Dynamics of Asynchronous Cellular Automaton,"A novel hardware-efficient central pattern generator (CPG) model based on the nonlinear dynamics of an asynchronous cellular automaton is presented. It is shown that the presented model can generate multi-phase synchronized periodic signals, which are suitable for controlling a snake robot. Then, the presented model is implemented on a field programmable gate array (FPGA) and is connected to a snake robot hardware. It is shown by real machine experiments that the presented model can realize rhythmic spinal locomotions of the snake robot. Moreover, it is shown that the presented model consumes much fewer hardware resources (FPGA slices) than a standard simple CPG model.",ICONIP,2017,22,filtered
4d8fa54a23581d052296c31ae955cf711d01210f,https://www.semanticscholar.org/paper/4d8fa54a23581d052296c31ae955cf711d01210f,OFDM symbol identification by an unsupervised learning system under dynamically changing channel effects,"Orthogonal frequency-division multiplexing (OFDM) is one of the most successful digital communication techniques. Nevertheless, the decrease in inter-symbol interference in quadrature amplitude modulation (QAM) over dispersive channels is still challenging. Different researches recently proposed the idea of using unsupervised learning as an alternative to the classic approaches to equalization of OFDM channels. In those purposes, the identification of a received QAM symbol is possible by the comparison of its position on the in-phase/quadrature (IQ) plane relative to the positions of previously arrived symbols, generally processed by the Kohonen’s Self-Organizing Map (SOM) algorithm. This work presents the SOM unsupervised learning method executed on an embedded system applied to QAM symbols identification. The system is implemented on an FPGA, a configurable digital circuit able to meet the low power and parallel process requirements of mobile applications. Also, in order to extend the classical set of experiments to evaluate our system, this paper proposes a theoretical model of the time-varying scheme representing the transition between different channel characteristics, obtained from real measurements available on a public repository. The model is employed to verify our purpose under dynamically both changing and realistic conditions. On the assumption that it is provided enough IQ symbols for the initial training process, the hardware implementation of SOM is able to track and identify the time-varying distorted QAM constellation. No knowledge of channel characteristics is necessary. The system spends only some microseconds at start-up to reach about 100% performance, and no dedicated training phase is needed afterward.",Neural Computing and Applications,2018,23,filtered
970ff5216f30c29d69d61139be94822484ca8fca,https://www.semanticscholar.org/paper/970ff5216f30c29d69d61139be94822484ca8fca,Fast FPGA-based method for Matsuoka parameters tuning,"In this paper we present a novel method for real time hardware implementation of Central Pattern Generators (CPGs) for bipedal robot walking. We introduce a closed form solution for Matsuoka CPG model which is a widely applied parametric neuron-based method for walking pattern generation. Existing parameter tuning methods including trial and error, optimization methods like genetic algorithms or etc. are both computationally slow and inefficient. Our methodology is arguably fast and accurate and can be implemented on FPGA in online applications.",2016 2nd International Conference of Signal Processing and Intelligent Systems (ICSPIS),2016,24,filtered
116d6e724d0d15fbb2e84d741477102f9d988ed3,https://www.semanticscholar.org/paper/116d6e724d0d15fbb2e84d741477102f9d988ed3,iCub Whole-Body Control through Force Regulation on Rigid Non-Coplanar Contacts,"This paper details the implementation on the humanoid robot iCub of state-of-the-art algorithms for whole-body control. We regulate the forces between the robot and its surrounding environment to stabilize a desired robot posture. We assume that the forces and torques are exerted on rigid contacts. The validity of this assumption is guaranteed by constraining the contact forces and torques, e.g. the contact forces must belong to the associated friction cones. The implementation of this control strategy requires to estimate the external forces acting on the robot, and the internal joint torques. We then detail algorithms to obtain these estimations when using a robot with an iCub-like sensor set, i.e. distributed six-axis force-torque sensors and whole-body tactile sensors. A general theory for identifying the robot inertial parameters is also presented. From an actuation standpoint, we show how to implement a joint torque control in the case of DC brushless motors. In addition, the coupling mechanism of the iCub torso is investigated. The soundness of the entire control architecture is validated in a real scenario involving the robot iCub balancing and making contacts at both arms.",Front. Robot. AI,2015,25,filtered
cfc8a362f7f7e7b1bce51caac0db50dfb52b7f13,https://www.semanticscholar.org/paper/cfc8a362f7f7e7b1bce51caac0db50dfb52b7f13,Implementation of biomimetic central pattern generators on field-programmable gate array,"This study is a step towards the design of neuroprostheses using artificial biomimetic neural networks like the central pattern generator (CPG) we could find in the leech’s heartbeat system. We propose a resource-frugal implementation of CPG on a field-programmable gate array (FPGA) platform. Using Izhikevich’s neuron model and short-term plasticity synapse model, our implementation can host and mimic 500 CPGs in real time. Our results have been validated by comparing them to biological data. Our study shows a solid step towards hybridization of biological nervous system and artificial neural networks.",,2015,26,filtered
70ac48d994aa4a85884384dcbad501b9f2451821,https://www.semanticscholar.org/paper/70ac48d994aa4a85884384dcbad501b9f2451821,Versatile educational and research robotic platform based on reconfigurable hardware,"This paper presents the development of a field-programmable gate array (FPGA)-based platform. This platform is intended for the community as an educational and efficient prototyping tool, in digital signal processing, robotics, and control, but it can also be used as to develop custom robotic architectures. The proposed platform centered around an FPGA device is embedded on an off-the-shelf Phoenix hexapod robot. The platform is equipped with a camera module targeted to real time computer vision. From an academic point of view, the main use for the developed platform is to be employed as a didactic resource that facilitates the understanding of theoretical concepts commonly used in engineering courses and to speed up the development cycle in hands-on practice. A set of software tools and low-level drivers have been developed to configure the vision sensor, transfer images to/from a computer and to manage the testing of image and digital processing and control tasks in a transparent way. To validate the platform a hardware vision architecture and a locomotion control module have been created. The high level control is performed in a soft-processor that simulates the Arduino ONE micro controller. The soft-processor takes information from the vision sensor to generate controls signals for a generic module able to take a digital input and deliver a pulse-width modulation (PWM) output.",2014 International Conference on ReConFigurable Computing and FPGAs (ReConFig14),2014,27,filtered
8fb7ad2268200a4440eb336872f7971bc85e4bd4,https://www.semanticscholar.org/paper/8fb7ad2268200a4440eb336872f7971bc85e4bd4,A Survey and Categorization of Small Low-Cost Unmanned Aerial Vehicle System Identification,"Remote sensing has traditionally be done with satellites and manned aircraft. While these methods can yield useful scientific data, satellites and manned aircraft have limitations in data frequency, process time, and real time re-tasking. Small low-cost unmanned aerial vehicles (UAVs) can bridge the gap for personal remote sensing for scientific data. Precision aerial imagery and sensor data requires an accurate dynamics model of the vehicle for controller development. One method of developing a dynamics model is system identification (system ID). The purpose of this paper is to provide a survey and categorization of current methods and applications of system ID for small low-cost UAVs. This paper also provides background information on the process of system ID with in-depth discussion on practical implementation for UAVs. This survey divides the summaries of system ID research into five UAV groups: helicopter, fixed-wing, multirotor, flapping-wing, and lighter-than-air. The research literature is tabulated into five corresponding UAV groups for further research.",J. Intell. Robotic Syst.,2014,28,filtered
9f4722294a2c99f18dec9e24446c283f7edb6920,https://www.semanticscholar.org/paper/9f4722294a2c99f18dec9e24446c283f7edb6920,Managing IoT Cyber-Security Using Programmable Telemetry and Machine Learning,"Cyber-security risks for Internet of Things (IoT) devices sourced from a diversity of vendors and deployed in large numbers, are growing rapidly. Therefore, management of these devices is becoming increasingly important to network operators. Existing network monitoring technologies perform traffic analysis using specialized acceleration on network switches, or full inspection of packets in software, which can be complex, expensive, inflexible, and unscalable. In this paper, we use SDN paradigm combined with machine learning to leverage the benefits of programmable flow-based telemetry with flexible data-driven models to manage IoT devices based on their network activity. Our contributions are three-fold: (1) We analyze traffic traces of 17 real consumer IoT devices collected in our lab over a six-month period and identify a set of traffic flows (per-device) whose time-series attributes computed at multiple timescales (from a minute to an hour) characterize the network behavior of various IoT device types, and their operating states (i.e., booting, actively interacted with user, or being idle); (2) We develop a multi-stage architecture of inference models that use flow-level attributes to automatically distinguish IoT devices from non-IoTs, classify individual types of IoT devices, and identify their states during normal operations. We train our models and validate their efficacy using real traffic traces; and (3) We quantify the trade-off between performance and cost of our solution, and demonstrate how our monitoring scheme can be used in operation for detecting behavioral changes (firmware upgrade or cyber attacks).",IEEE Transactions on Network and Service Management,2020,29,filtered
c12dff5ce0c189dab6307781ac2133625aff85d6,https://www.semanticscholar.org/paper/c12dff5ce0c189dab6307781ac2133625aff85d6,Visuomotor Reinforcement Learning for Multirobot Cooperative Navigation,"This article investigates the multirobot cooperative navigation problem based on raw visual observations. A fully end-to-end learning framework is presented, which leverages graph neural networks to learn local motion coordination and utilizes deep reinforcement learning to generate visuomotor policy that enables each robot to move to its goal without the need of environment map and global positioning information. Experimental results show that, with a few tens of robots, our approach achieves comparable performance with the state-ofthe-art imitation learning-based approaches with bird-view state inputs. We also illustrate our generalizability to crowded and large environments and our scalability to ten times number of the training robots. In addition, we demonstrate that our model trained for multirobot case can also improve the success rate in the single-robot navigation task in unseen environments. Note to Practitioners—With the development of intelligent industrial and logistic systems, robotic transportation systems are widely implemented. However, existing multirobot path coordination and navigation approaches are basically under some unreasonable assumptions, which are very hard to be implemented in practical scenarios. This article aims to greatly promote the real application of learning-based multirobot cooperative navigation approach, in order to achieve the following. First, we introduce an end-to-end reinforcement learning framework instead of the Manuscript received June 25, 2021; accepted August 24, 2021. This article was recommended for publication by Associate Editor T. Xu and Editor D. O. Popa upon evaluation of the reviewers’ comments. This work was supported in part by the Natural Science Foundation of China under Grant 62073222 and Grant U1913204, in part by Shanghai Municipal Education Commission and Shanghai Education Development Foundation through “Shu Guang” Project under Grant 19SG08, in part by Shenzhen Science and Technology Program under Grant JSGG20201103094400002, and in part by the Science and Technology Commission of Shanghai Municipality under Grant 21511101900. (Zhe Liu and Qiming Liu contributed equally to this work.) (Corresponding author: Hesheng Wang.) Zhe Liu is with the Department of Computer Science and Technology, University of Cambridge, Cambridge CB2 1TN, U.K. (e-mail: zl457@cam.ac.uk). Qiming Liu, Ling Tang, and Hongye Wang are with the Department of Automation, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: qimingliu@sjtu.edu.cn; elftat@sjtu.edu.cn; wanghongye@sjtu.edu.cn). Kefan Jin is with the MOE Key Laboratory of Marine Intelligent Equipment and System and the State Key Laboratory of Ocean Engineering, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: jinkefan@sjtu.edu.cn). Ming Liu is with the Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong (e-mail: eelium@ust.hk). Hesheng Wang is with the Department of Automation, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: wanghesheng@sjtu.edu.cn). Color versions of one or more figures in this article are available at https://doi.org/10.1109/TASE.2021.3114327. Digital Object Identifier 10.1109/TASE.2021.3114327 commonly used imitation learning strategy, as the latter one needs exhaustive training data to cover all the scenarios and does not have the required generalizability. Second, we directly use the raw sensor data instead of the commonly used birdeye-view semantic observations, as the latter one is generally not representative of practical application scenario from the robot perspective and cannot solve the occlusion issue. Third, we interpret our learned model to illustrate which parts of the input and shared observations contribute most to the robots’ final actions. The above interpretability ensures predictability (thus safety) of our visuomotor policy in practical applications. Our learned visuomotor policy has the ability to coordinate dozens of robots by only using raw visual observations in unknown environments without map nor global localization information, this is the first time in the literature. Our future work includes solving the sim-to-real issue and conducting physical experiments.",IEEE Transactions on Automation Science and Engineering,2021,30,filtered
fab4b767e3ae70e8e04e991e8d626fe6b3184213,https://www.semanticscholar.org/paper/fab4b767e3ae70e8e04e991e8d626fe6b3184213,Learning Navigation Policies for Mobile Robots in Deep Reinforcement Learning with Random Network Distillation,"Learning navigation policies considers the task of training a model that can find collision-free paths for mobile robots, where various Deep Reinforcement Learning (DRL) methods have been applied with promising results. However, the natural reward function for the task is usually sparse, i.e., obtaining a penalty for the collision and a positive reward for arriving the target position, which makes it difficult to learn. In particular, for some complex navigation environments, it is hard to search a collision-free path by the random exploration, which leads to a rather slow learning speed and solutions with poor performance. In this paper, we propose a DRL based approach to train an end-to-end navigation planner, i.e, the policy neural network, that directly translates the local grid map and the relative goal of the robot into its moving actions. To handle the sparse reward problem, we augment the normal extrinsic reward from the environment with intrinsic reward signals measured by random network distillation (RND). In specific, the intrinsic reward is calculated by two different networks from RND, which encourages the agent to explore a state that has not been seen before. The experimental results show that by augmenting the reward function with intrinsic reward signals by RND, solutions with better performance can be learned more efficiently and more stably in our approach. We also deploy the trained model to a real robot, which can perform collision avoidance in navigation tasks without any parameter tuning. A video of our experiments can be found at https://youtu.be/b1GJrWfO8pw.",ICIAI,2021,31,filtered
1c9c12a5c9f3cfd9cd1eefbe818bfb92d37520ac,https://www.semanticscholar.org/paper/1c9c12a5c9f3cfd9cd1eefbe818bfb92d37520ac,"Cloud-based mission control of USV fleet: Architecture, implementation and experiments","Abstract In this paper, a cloud-based mission control architecture is proposed to achieve flexible remote access and coordinated mission control among a fleet of unmanned surface vehicles (USVs). First, a cloud-based mission control architecture that renders easy, timely and prioritized remote access to the USVs regardless of the remote operator’s location is proposed. It is achieved by leveraging remote cloud-based technology and local Operating onboard System. Decentralized property of the architecture accomplishes scalable monitoring, remote control, data acquisition and missions sharing for an USV fleet. Second, the related software interfaces are required for this task: the user interface of the remote client that is used for mission control/planning and data visualization and that is applicable across mobile robotic systems; and the back-end interface for the local USVs that bridges robotic and cloud server and provides seamless integration with the well-established Robot Operating System (ROS). ROS is nowadays, the most widely used framework for robotics developments. Furthermore, the proposed cloud-based mission control architecture is implemented on a fleet of real vehicles, H2Omni-X USVs, and the performance of the remote experimentation is demonstrated during sea trials at the Adriatic coast, Croatia, representing the practical contribution of this paper.",,2021,32,filtered
8193122b2cf5ec63ead24f36d3093f7f55e23d46,https://www.semanticscholar.org/paper/8193122b2cf5ec63ead24f36d3093f7f55e23d46,Cooperative Heterogeneous Multi-Robot Systems,"The emergence of the Internet of things and the widespread deployment of diverse computing systems have led to the formation of heterogeneous multi-agent systems (MAS) to complete a variety of tasks. Motivated to highlight the state of the art on existing MAS while identifying their limitations, remaining challenges, and possible future directions, we survey recent contributions to the field. We focus on robot agents and emphasize the challenges of MAS sub-fields including task decomposition, coalition formation, task allocation, perception, and multi-agent planning and control. While some components have seen more advancements than others, more research is required before effective autonomous MAS can be deployed in real smart city settings that are less restrictive than the assumed validation environments of MAS. Specifically, more autonomous end-to-end solutions need to be experimentally tested and developed while incorporating natural language ontology and dictionaries to automate complex task decomposition and leveraging big data advancements to improve perception algorithms for robotics.",ACM Comput. Surv.,2019,33,filtered
1a4696401d822c632735b070dacdf88a50c7acfc,https://www.semanticscholar.org/paper/1a4696401d822c632735b070dacdf88a50c7acfc,Towards robust grasps: Using the environment semantics for robotic object affordances,"In this talk I will look back over four years of long-term deployments of autonomous mobile robots in everyday environments. From this I will present examples of the kinds of things that mobile robots can learn over long autonomous operations in such environments, including navigation information, human activities, object models, and mission schedules. Following this I will explore the issues (software, hardware, and social) that impacted upon the autonomy of our deployed robots, and look at what we can learn from these experiences as both AI practitioners and as engineers deploying robots in real environments. Dr. Maarten Sierhuis, Chief Technology Director at Nissan Research Center Silicon Valley, Founder of Ejenta Title: Seamless Autonomous Mobility (SAM) Abstract: Artificial intelligence will make vehicles able to drive autonomously in a wide variety of scenarios. However, unexpected situations can still arise as these long-term autonomous vehicles interact in the world, potentially limiting the uses of fully autonomous driving in the near future. Nissan’s Seamless Autonomous Mobility provides a solution that can overcome this issue through the intelligent integration of humans. Artificial intelligence will make vehicles able to drive autonomously in a wide variety of scenarios. However, unexpected situations can still arise as these long-term autonomous vehicles interact in the world, potentially limiting the uses of fully autonomous driving in the near future. Nissan’s Seamless Autonomous Mobility provides a solution that can overcome this issue through the intelligent integration of humans. Dr. Peter Wurman, VP of Engineering at Cogitai, Former Co-founder of Kiva Systems Title: The Disruptive Power of Robots Abstract: Kiva Systems introduced swarms of agile robots into an industry dominated by stationary conveyor systems. The path from concept through successful startup and eventual acquisition involved challenges on all fronts. In this talk I’ll explain the business problem that motivated the innovation, Kiva technology and the benefits it brought to customers, and the future of applications of robotics in warehouses. Kiva Systems introduced swarms of agile robots into an industry dominated by stationary conveyor systems. The path from concept through successful startup and eventual acquisition involved challenges on all fronts. In this talk I’ll explain the business problem that motivated the innovation, Kiva technology and the benefits it brought to customers, and the future of applications of robotics in warehouses.",AAAI 2018,2018,34,filtered
8d42cdf275a59535a9f0e109d81e280e37af0338,https://www.semanticscholar.org/paper/8d42cdf275a59535a9f0e109d81e280e37af0338,An Adaptive Robotics Middleware for a cloud-based bridgeOS,"Robotic applications and their capabilities have grown exponentially in recent years, but hardware limitations and environment restrictions still lead to unfulfilled requirements. As Cloud Computing matured, however, robotics began taking advantage of its elastic resources by offloading computation and data to the cloud, effectively creating what is now called Cloud Robotics. Although a multitude of frameworks have been proposed over the years, each with its own unique specifications and goals, none has become dominant nor able to provide a standard and generic solution linking both robots, users and the cloud. An innovative platform, bridgeOS, attempts to take on this role by providing a new solution and framework, integrating recent Services paradigms, using a web-oriented approach and supporting a prominent software for networked robotics, the Robot Operating System (ROS). To accomplish this, we propose a cloud-based extension for the bridgeOS framework, capable of dynamic service deployments for the robots, and add support for adaptive decision making, based on available resources and performance metrics, to optimize in real time, both how those services are distributed and how well they perform. Overall, the middleware we developed is robust, resilient, versatile and capable of scaling to hundreds of components. Our experimental results show that it is a viable solution, with benefits exceeding the overhead it generates.",,2017,35,filtered
7c1949a48e36e92e9bc44906fd5589c4653f9707,https://www.semanticscholar.org/paper/7c1949a48e36e92e9bc44906fd5589c4653f9707,Simultaneous Semantic and Collision Learning for 6-DoF Grasp Pose Estimation,"Grasping in cluttered scenes has always been a great challenge for robots, due to the requirement of the ability to well understand the scene and object information. Previous works usually assume that the geometry information of the objects is available, or utilize a step-wise, multi-stage strategy to predict the feasible 6-DoF grasp poses. In this work, we propose to formalize the 6-DoF grasp pose estimation as a simultaneous multi-task learning problem. In a unified framework, we jointly predict the feasible 6-DoF grasp poses, instance semantic segmentation, and collision information. The whole framework is jointly optimized and end-to-end differentiable. Our model is evaluated on large-scale benchmarks as well as the real robot system. On the public dataset, our method outperforms prior state-of-the-art methods by a large margin (+4.08 AP). We also demonstrate the implementation of our model on a real robotic platform and show that the robot can accurately grasp target objects in cluttered scenarios with a high success rate. Project link: https://openbyterobotics.github.io/sscl.",2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2021,36,filtered
39b768f1a9b5e0bdaa5fcf8b10c3133cb753b4a6,https://www.semanticscholar.org/paper/39b768f1a9b5e0bdaa5fcf8b10c3133cb753b4a6,Machine Vision Techniques Used in Agriculture and Food Industry: A Review,"Last few decades has seen lot of advancement in the technologies associated with the automation in agriculture and food industry. This includes a wide range of agricultural operations including seedbed preparation, intercultural operations, application of fertilizers and chemicals, harvesting, transportation, and grading. Researchers have developed robots that assist the farmers in getting these operations done and help them overcome the labour shortage problem. Artificial intelligence has changed the way decisions used to be made in agricultural and other operations and has made automation of many tasks feasible. Machine learning technique is a subtype of artificial intelligence which is used for processing of images of fruits, crop and other objects which can give a wide range of information that may be useful in decision making. With the advancement in GPU and software technology it is possible to process huge amount of data in real time. Further, with the availability of convolutional neural networks such as AlexNet, ResNet, International Journal of Current Microbiology and Applied Sciences ISSN: 2319-7706 Volume 9 Number 3 (2020) Journal homepage: http://www.ijcmas.com",,2020,37,filtered
7852fb1112961d3c26707cf470bc6d7a5054b34f,https://www.semanticscholar.org/paper/7852fb1112961d3c26707cf470bc6d7a5054b34f,A Robotic Semantic Grasping Method For Pick-and-place Tasks,"In recent years, it has attracted significant interest for mobile robots to complete the grasping tasks. A fully autonomous robotic pick-and-place system requires dependable object recognition and localization in cluttered environments. Most of current robot grasping methods based on learning mostly train the models with exploiting human-labeled datasets, then grasping perpendicularly to the plane where the object is placed. In this paper, a robotic semantic grasping method is proposed to estimate six-degree-of-freedom (6DOF) grasping pose for the robotic manipulator, thereby a grip perpendicularly to the surface of the object can be achieved. Firstly, the graspable location is detected by an instance segmentation detection model and ellipse fitting method. Secondly, by processing the pixel mask and point clouds of the target object, the 6DOF grasping pose is estimated. Finally, the proposed method was implemented and tested in a real robot manipulator. Experimental results show that the proposed semantic grasping method enables to accomplish pick-and-place tasks in an unstructured scene.",2019 Chinese Automation Congress (CAC),2019,38,filtered
24b3bf1702d123d57510f9576496109aa4789270,https://www.semanticscholar.org/paper/24b3bf1702d123d57510f9576496109aa4789270,Robotic grasping using visual and tactile sensing,"Abstract Visual and tactile sensing are complementary factors in the task of robotic grasping. In this paper, a grasp detection deep network is first proposed to detect the grasp rectangle from the visual image， then a new metric using tactile sensing is designed to assess the stability of the grasp. By means of this scheme, a THU grasp dataset， which includes the visual information, corresponding tactile and grasp configurations， is collected to train the proposed deep network. Experiments results have demonstrated that the proposed grasp detection deep networks outperform other mainstream approaches in a public grasp dataset. Furthermore， the grasp success rate can be improved significantly in real world scenarios. The trained model has also been successfully implemented in a new robotic platform to perform the robotic grasping task in a cluttered scenario.",Inf. Sci.,2017,39,filtered
a09d1ea248e56f9d82346f8df07be36a4594f49d,https://www.semanticscholar.org/paper/a09d1ea248e56f9d82346f8df07be36a4594f49d,Deep learning for picking point detection in dense cluster,"This paper considers the problem of picking objects in cluster. This requires the robot to reliably detect the picking point for the known or unseen objects under the environment with occlusion, disorder and a variety of objects. We present a novel pipeline to detect picking point based on deep convolutional neural network (CNN). A two-dimensional picking configuration is proposed, thus an extensive data augmentation strategy is enabled and a labeled dataset is established quickly and easily. At last, we demonstrate the implementation of our method on a real robot and show that our method can accurately detect picking point of unseen objects and achieve a pick success of 91% in cluster bin-picking scenario.",2017 11th Asian Control Conference (ASCC),2017,40,filtered
42413c946894f8ca1f2265f2f26e80a87da6cff3,https://www.semanticscholar.org/paper/42413c946894f8ca1f2265f2f26e80a87da6cff3,Fusion of information from multiple robots,"Abstract Whilst scaling the size of multi-robot team has its pros and cons as described in the previous chapter, often the size of the environment to be monitored necessitates a multi-robot setup. Thus, if a disconnected and decentralized team of agents is considered, multiple intermediate GP models (one model per agent) will be obtained with no communication overhead. Given the limited number of observations available to each agent, each of these will have the capability to explain the environmental dynamics to a certain extent, but the question is: which model can be trusted? Simply put, ignoring some of the models generated leads to information waste whilst multiple models cannot be used to decipher the true underlying dynamics unless they are fused. To this end, this chapter describes a novel discrete weighted posterior fusion mechanism referred to as FuDGE which allows for taking the confidence over the prediction of each expert whilst fusing the posteriors. As opposed to existing works which directly perform model fusion, this approach is amicable to real robot deployment in the sense that learning is only required whilst the robots are observing the environment and individual models are being optimized. At the end of all missions, the posteriors are fused based on the quality of learnt models. This fusion approach has shown promising results when evaluated over a real-world Ozone dataset.",,2020,41,filtered
aa262b568c6a4fd24b36fa37dc282bc0c9a46d2e,https://www.semanticscholar.org/paper/aa262b568c6a4fd24b36fa37dc282bc0c9a46d2e,OCRTOC: A Cloud-Based Competition and Benchmark for Robotic Grasping and Manipulation,"In this paper, we propose a cloud-based benchmark for robotic grasping and manipulation, called the OCRTOC benchmark. The benchmark focuses on the object rearrangement problem, specifically table organization tasks. We provide a set of identical real robot setups and facilitate remote experiments of standardized table organization scenarios in varying difficulties. In this workflow, users upload their solutions to our remote server and their code is executed on the real robot setups and scored automatically. After each execution, the OCRTOC team resets the experimental setup manually. We also provide a simulation environment that researchers can use to develop and test their solutions. With the OCRTOC benchmark, we aim to lower the barrier of conducting reproducible research on robotic grasping and manipulation and accelerate progress in this field. Executing standardized scenarios on identical real robot setups allows us to quantify algorithm performances and achieve fair comparisons. Using this benchmark we held a competition in the 2020 International Conference on Intelligence Robots and Systems (IROS 2020). In total, 59 teams took part in this competition worldwide. We present the results and our observations of the 2020 competition, and discuss our adjustments and improvements for the upcoming OCRTOC 2021 competition. The homepage of the OCRTOC competition is www.ocrtoc.org, and the OCRTOC software package is available at https://github.com/OCRTOC/OCRTOC_software_package.",IEEE Robotics and Automation Letters,2021,42,filtered
119678648278fca3190f865e634409d78f730719,https://www.semanticscholar.org/paper/119678648278fca3190f865e634409d78f730719,CloudAAE: Learning 6D Object Pose Regression with On-line Data Synthesis on Point Clouds,"It is often desired to train 6D pose estimation systems on synthetic data because manual annotation is expensive. However, due to the large domain gap between the synthetic and real images, synthesizing color images is expensive. In contrast, this domain gap is considerably smaller and easier to fill for depth information. In this work, we present a system that regresses 6D object pose from depth information represented by point clouds, and a lightweight data synthesis pipeline that creates synthetic point cloud segments for training. We use an augmented autoencoder (AAE) for learning a latent code that encodes 6D object pose information for pose regression. The data synthesis pipeline only requires texture-less 3D object models and desired viewpoints, and it is cheap in terms of both time and hardware storage. Our data synthesis process is up to three orders of magnitude faster than commonly applied approaches that render RGB image data. We show the effectiveness of our system on the LineMOD, LineMOD Occlusion, and YCB Video datasets. The implementation of our system is available at: https://github.com/GeeeG/CloudAAE.",2021 IEEE International Conference on Robotics and Automation (ICRA),2021,43,filtered
14739e62c1bba4f5df5cc39d1edc5d8252ab62e9,https://www.semanticscholar.org/paper/14739e62c1bba4f5df5cc39d1edc5d8252ab62e9,Leveraging Self-Supervision for Cross-Domain Crowd Counting,"State-of-the-art methods for counting people in crowded scenes rely on deep networks to estimate crowd density. While effective, these data-driven approaches rely on large amount of data annotation to achieve good performance, which stops these models from being deployed in emergencies during which data annotation is either too costly or cannot be obtained fast enough. One popular solution is to use synthetic data for training. Unfortunately, due to domain shift, the resulting models generalize poorly on real imagery. We remedy this shortcoming by training with both synthetic images, along with their associated labels, and unlabeled real images. To this end, we force our network to learn perspective-aware features by training it to recognize upside-down real images from regular ones and incorporate into it the ability to predict its own uncertainty so that it can generate useful pseudo labels for fine-tuning purposes. This yields an algorithm that consistently outperforms state-of-the-art cross-domain crowd counting ones without any extra computation at inference time.",ArXiv,2021,44,filtered
2fcf8164f1cec60ecd487f4d2ed75d4a2f0849ed,https://www.semanticscholar.org/paper/2fcf8164f1cec60ecd487f4d2ed75d4a2f0849ed,Mask-based Object Pose Estimation with Domain Transfer,"Object pose estimation is important for robots to understand and interact with the real world. This problem is challenging because the various objects, clutter and occlusions between objects in the scene. Deep learning methods show better performances than traditional problems in this problem but training a convolutional neural network needs lots of annotated data which is expensive to obtain. This paper proposes a general method by using domain transfer technology to efficiently solve object pose estimation problem. Besides, the proposed method obtains mask to achieve high quality performance by combing an instance segmentation framework, Mask R-CNN. We present the results of our experiments with the LineMOD dataset. We also deploy our method to robotic grasp object based on the estimated pose.",2021 IEEE 10th Data Driven Control and Learning Systems Conference (DDCLS),2021,45,filtered
b82336fa538b7383f0fae65d92b77fe8812446aa,https://www.semanticscholar.org/paper/b82336fa538b7383f0fae65d92b77fe8812446aa,Multi-View Object Pose Refinement With Differentiable Renderer,"This letter introduces a novel multi-view 6 DoF object pose refinement approach focusing on improving methods trained on synthetic data. It is based on the DPOD detector, which produces dense 2D-3D correspondences between the model vertices and the image pixels in each frame. We have opted for the use of multiple frames with known relative camera transformations, as it allows introduction of geometrical constraints via an interpretable ICP-like loss function. The loss function is implemented with a differentiable renderer and is optimized iteratively. We also demonstrate that a full detection and refinement pipeline, which is trained solely on synthetic data, can be used for auto-labeling real data. We perform quantitative evaluation on LineMOD, Occlusion, Homebrewed and YCB-V datasets and report excellent performance in comparison to the state-of-the-art methods trained on the synthetic and real data. We demonstrate empirically that our approach requires only a few frames and is robust to close camera locations and noise in extrinsic camera calibration, making its practical usage easier and more ubiquitous.",IEEE Robotics and Automation Letters,2021,46,filtered
c7fcb5f1f58b850a9ebbda4ca800163efecbe9f7,https://www.semanticscholar.org/paper/c7fcb5f1f58b850a9ebbda4ca800163efecbe9f7,Yolo+FPN: 2D and 3D Fused Object Detection With an RGB-D Camera,"In this paper we propose a new deep neural network system, called Yolo+FPN, which fuses both 2D and 3D object detection algorithms to achieve better real-time object detection results and faster inference speed, to be used on real robots. Finding an optimized fusion strategy to efficiently combine 3D object detection with 2D detection information is useful and challenging for both indoor and outdoor robots. In order to satisfy real-time requirements, a trade-off between accuracy and efficiency is needed. We not only have improved training and test accuracies and lower mean losses on the KITTI object detection benchmark comparing with our baseline method, but also achieve competitive average precision on 3D detection of all classes in three levels of difficulty comparing with other state-of-the-art methods. Also, we implemented Yolo+FPN system using an RGB-D camera, and compared the speed of object detection using different GPUs. For the real implementation of both indoor and outdoor scenes, we focus on person detection, which is the most challenging and important among the three classes.",2020 25th International Conference on Pattern Recognition (ICPR),2021,47,filtered
ac95ec8f7d53365e3a03d88d77cce81a02193f5b,https://www.semanticscholar.org/paper/ac95ec8f7d53365e3a03d88d77cce81a02193f5b,Hardware Acceleration of Monte-Carlo Sampling for Energy Efficient Robust Robot Manipulation,"Algorithms based on Monte-Carlo sampling have been widely adapted in robotics and other areas of engineering due to their performance robustness. However, these sampling-based approaches have high computational requirements, making them unsuitable for real-time applications with tight energy constraints. In this paper, we investigate 6 degree-of-freedom (6DoF) pose estimation for robot manipulation using this method, which uses rendering combined with sequential Monte-Carlo sampling. While potentially very accurate, the significant computational complexity of the algorithm makes it less attractive for mobile robots, where runtime and energy consumption are tightly constrained. To address these challenges, we develop a novel hardware implementation of Monte-Carlo sampling on an FPGA with lower computational complexity and memory usage, while achieving high parallelism and modularization. Our results show 12X–21X improvements in energy efficiency over low-power and high-end GPU implementations, respectively. Moreover, we achieve real time performance without compromising accuracy.",2020 30th International Conference on Field-Programmable Logic and Applications (FPL),2020,48,filtered
f47d2bba0458de7953a58619cd4a51ce4cc19d9c,https://www.semanticscholar.org/paper/f47d2bba0458de7953a58619cd4a51ce4cc19d9c,Acceleration Techniques for Energy Efficient Sampling based Machine Learning,"Deep learning algorithms based on convolutional neural networks (CNNs) have led to major improvements in accuracy for such tasks as object recognition. However, CNNs may not have sufficient robustness when presented with challenging or new scenarios (e.g, from unstructured or changing environments). Alternatively, algorithms based on Monte-Carlo sampling have been widely adapted in robotics and other areas of engineering due to their performance robustness. However, these sampling-based approaches have high computational requirements, making them unsuitable for real-time applications with tight energy constraints. In this paper, we investigate 6 degree-offreedom (6DoF) pose estimation for robot manipulation using this method, which uses rendering combined with sequential MonteCarlo sampling. While potentially very accurate, the significant computational complexity of the algorithm makes it less attractive for mobile robots, where runtime and energy consumption are tightly constrained. To address these challenges, we develop a novel hardware implementation of Monte-Carlo sampling on an FPGA with lower computational complexity and memory usage, while achieving high parallelism and modularization. Our results show 12X–21X improvements in energy efficiency over low-power and high-end GPU implementations, respectively. Moreover, we achieve real time performance without compromising accuracy.",,2020,49,filtered
aba7b3fbbbb87ca37b0df1f7e6c28dec185f7905,https://www.semanticscholar.org/paper/aba7b3fbbbb87ca37b0df1f7e6c28dec185f7905,Pose Estimation for Texture-less Shiny Objects in a Single RGB Image Using Synthetic Training Data,"In the industrial domain, the pose estimation of multiple texture-less shiny parts is a valuable but challenging task. In this particular scenario, it is impractical to utilize keypoints or other texture information because most of them are not actual features of the target but the reflections of surroundings. Moreover, the similarity of color also poses a challenge in segmentation. In this article, we propose to divide the pose estimation process into three stages: object detection, features detection and pose optimization. A convolutional neural network was utilized to perform object detection. Concerning the reliability of surface texture, we leveraged the contour information for estimating pose. Since conventional contour-based methods are inapplicable to clustered metal parts due to the difficulties in segmentation, we use the dense discrete points along the metal part edges as semantic keypoints for contour detection. Afterward, we exploit both keypoint information and CAD model to calculate the 6D pose of each object in view. A typical implementation of deep learning methods not only requires a large amount of training data, but also relies on intensive human labor for labeling the datasets. Therefore, we propose an approach to generate datasets and label them automatically. Despite not using any real-world photos for training, a series of experiments showed that the algorithm built on synthetic data perform well in the real environment.",ArXiv,2019,50,filtered
514021c79e5bbbbcbd82c96f10193aa94be81233,https://www.semanticscholar.org/paper/514021c79e5bbbbcbd82c96f10193aa94be81233,Modular Robotics and Locomotion: Application to Limbless Robots,"This dissertation discusses the locomotion of modular robots. It is focused specifically on the study of 1D topology configurations (called snakes or limbless robots). The problem to solve is how to coordinate the joint's movement so that modular robots can move both in one and two dimensions. A big challenge in robotics is the development of a very versatile robot with the full capability of moving on different terrains. This is especially important in applications where the environment is unknown in advance, such as the exploration of other planet's surfaces, navigation in hostile environments and search and rescue operations. Modular robotics offers the promise of increasing the versatility in locomotion by means of building robots from basic modules. Each configuration has its own locomotive characteristics that should be studied. If the robots have the ability to be self-reconfigurable, then they will be able to change their shapes and topology in order to select the best gait for every terrain and negotiate with different tasks. One kind of bio-inspired controllers for mobile robots used in the last decade are based on CPG (Central pattern generators), which are a specialized neurons that produce rhythms for controlling the muscle activities of animals. In the steady state CPG behave like fixed-frequency oscillators. For that reason, they can be replaced by a simplified model like sinusoidal generators. The main advantage is that they are extremely simple to implement and requires very few computing resources. Therefore, they can be implemented in low-end inexpensive microcontrollers. Moreover, the generators can also be realized directly as hardware components using either digital or analog electronics. In this dissertation a general classification of modular robots is established based on their topologies and types of connection. The hypothesis of using sinusoidal generators for controlling the locomotion of 1D pitch-pitch and pitch-yaw modular robots of any length is raised. The results show that this simple model is efficient and the gaits obtained are natural and smooth. It is shown that at least they can move in five different movements. Some of them are totally new and have not been previously studied or implemented by other researchers, from the best of our knowledge. In addition, the relationships between the generator's parameters and the robot kinematics have been obtained. Another problem is to find the minimal configurations for locomotion, which are the modular robots within the studied groups that have the minimum number of modules and are still capable of moving in one and two dimensions. This problem has been solved and the two minimal configurations are presented. Their kinematics models are studied throughout too. The experiments confirm that the solutions found to the coordination problem are valid for the locomotion of real mobile modular robots. Four kinds of modular robotic prototypes have been built using the identical Y1 modules, which have been designed specifically for this thesis. Finally the knowledge about the locomotion of pitch-pitch and pitch-yaw connecting modular robots has been summarized in 27 key principles.",,2008,51,filtered
6e6ae08259b22ac769c9a81a62f9752eb2b9e732,https://www.semanticscholar.org/paper/6e6ae08259b22ac769c9a81a62f9752eb2b9e732,Applying CORBA Technology for the Teleoperation of Wheeeler,"In this paper, we present development of Wheeeler - the hyper mobile robot. Hyper mobile robots belong to the group of highly articulated robots, sometimes called “snake-like” or serpentine robots. Wheeeler has 7 segments driven by wheels and interconnected by 2 degrees- of-freedom joints (Fig. 28.1). This machine is expected to operate in rough terrain, traverse stairs and trenches, avoid obstacles, or climb over them, and also pass through tight spaces. Our project is in the simulation stage and currently we focus on the communication issues. Although, modeling and tests are performed in simulator (Webots 5 PRO) now, the same control software will work with real robot soon. In this paper, we shortly present the actual version of model; introduce the sensory suite and local controllers’ configuration. In the main paragraph we present the implementation of CORBA technology in client-server communication.",RoMoCo,2007,52,filtered
1abdeafe4b6e36e2566ffc0054b2357c3929baae,https://www.semanticscholar.org/paper/1abdeafe4b6e36e2566ffc0054b2357c3929baae,One-Shot Imitation Filming of Human Motion Videos,"Imitation learning has been applied to mimic the operation of a human cameraman in several autonomous cinematography systems. To imitate different filming styles, existing methods train multiple models, where each model handles a particular style and requires a significant number of training samples. As a result, existing methods can hardly generalize to unseen styles. In this paper, we propose a framework, which can imitate a filming style by ""seeing"" only a single demonstration video of the same style, i.e., one-shot imitation filming. This is done by two key enabling techniques: 1) feature extraction of the filming style from the demo video, and 2) filming style transfer from the demo video to the new situation. We implement the approach with deep neural network and deploy it to a 6 degrees of freedom (DOF) real drone cinematography system by first predicting the future camera motions, and then converting them to the drone's control commands via an odometer. Our experimental results on extensive datasets and showcases exhibit significant improvements in our approach over conventional baselines and our approach can successfully mimic the footage with an unseen style.",ArXiv,2019,53,filtered
e6debe8731daadf256ba4005fd291f85792885b4,https://www.semanticscholar.org/paper/e6debe8731daadf256ba4005fd291f85792885b4,Can a Robot Become a Movie Director? Learning Artistic Principles for Aerial Cinematography,"Aerial filming is constantly gaining importance due to the recent advances in drone technology. It invites many intriguing, unsolved problems at the intersection of aesthetical and scientific challenges. In this work, we propose a deep reinforcement learning agent which supervises motion planning of a filming drone by making desirable shot mode selections based on aesthetical values of video shots. Unlike most of the current state-of-the-art approaches that require explicit guidance by a human expert, our drone learns how to make favorable viewpoint selections by experience. We propose a learning scheme that exploits aesthetical features of retrospective shots in order to extract a desirable policy for better prospective shots. We train our agent in realistic AirSim simulations using both a hand-crafted reward function as well as reward from direct human input. We then deploy the same agent on a real DJI M210 drone in order to test the generalization capability of our approach to real world conditions. To evaluate the success of our approach in the end, we conduct a comprehensive user study in which participants rate the shot quality of our methods. Videos of the system in action can be seen at https://youtu.be/qmVw6mfyEmw.",2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),2019,54,filtered
307bccaee7e7eda278b9cad46522e315b0a638de,https://www.semanticscholar.org/paper/307bccaee7e7eda278b9cad46522e315b0a638de,Formal verification of neural networks for safety-critical tasks in deep reinforcement learning,"In the last years, neural networks achieved groundbreaking successes in a wide variety of applications. However, for safety critical tasks, such as robotics and healthcare, it is necessary to provide some specific guarantees before the deployment in a real world context. Even in these scenarios, where high cost equipment and human safety are involved, the evaluation of the models is usually performed with the standard metrics (i.e., cumulative reward or success rate). In this paper, we introduce a novel metric for the evaluation of models in safety critical tasks, the violation rate. We build our work upon the concept of formal verification for neural networks, providing a new formulation for the safety properties that aims to ensure that the agent always makes rational decisions. To perform this evaluation, we present ProVe (Property Verifier), a novel approach based on the interval algebra, designed for the analysis of our novel behavioral properties. We apply our method to different domains (i.e., mapless navigation for mobile robots, trajectory generation for manipulators, and the standard ACAS benchmark). Results show that the violation rate computed by ProVe provides a good evaluation for the safety of trained models.",UAI,2021,55,filtered
fc099e2d0a8236ce198d7eadd6abb183aa6847b0,https://www.semanticscholar.org/paper/fc099e2d0a8236ce198d7eadd6abb183aa6847b0,Macro workstep detection for assembly manufacturing,"In this paper, we introduce a detection system for macro worksteps in a manufacturing assembly line using depth images. The sensor is mounted on the ceiling with a top-down angle. The system was deployed in a real life industrial process where workers had to assemble an ATM machine. Experimental results show the effectiveness of three identification approaches that were used: (1) template matching using a single template per macro workstep, (2) multiple templates for macro worksteps and (3) template matching and motion detection in order to detect the transition between each two consecutive macro worksteps. Each approach has its own benefits in terms of processing speed, accuracy and precision and we discuss them in details along with the challenges the system had, in the discussion section. The results are also investigated in details and we present the future plans for the proposed detection system.",PETRA,2020,56,filtered
715b22c6f8286b7dbf05e08217db3d7b51c93091,https://www.semanticscholar.org/paper/715b22c6f8286b7dbf05e08217db3d7b51c93091,A Simple Geometrical-Based Calibration Technique for 3D Scanners with Rotating Platform,"Active three-dimensional (3D) scanning techniques usually create 3D models of real scenes by using known light patterns reflected by surfaces and captured by cameras. Each scanning technique has its own implementation issues, which can impact on its complexity, processing time and data precision. This paper proposes a simple geometrical-based calibration technique for 3D scanners with rotating platform. As we focus on low-cost and accessibility, the scanning system was implemented using offthe-shelf components. Also its structure was designed to be 3D printed. Two objects are scanned and their point clouds are used to assess the system performance. Results show that the proposed model presents a good trade-off between accuracy and implementation complexity with an average accuracy error equals to 0.196 mm and a mean squared error (MSE) smaller than 4.65%.","International journal of simulation: systems, science & technology",2019,57,filtered
52acb53bac559ea73b68edf598cab021f383fa35,https://www.semanticscholar.org/paper/52acb53bac559ea73b68edf598cab021f383fa35,Data Warehouse and Decision Support on Integrated Crop Big Data,"In recent years, precision agriculture is becoming very popular. The introduction of modern information and communication technologies for collecting and processing Agricultural data revolutionise the agriculture practises. This has started a while ago (early 20th century) and it is driven by the low cost of collecting data about everything; from information on fields such as seed, soil, fertiliser, pest, to weather data, drones and satellites images. Specially, the agricultural data mining today is considered as Big Data application in terms of volume, variety, velocity and veracity. Hence it leads to challenges in processing vast amounts of complex and diverse information to extract useful knowledge for the farmer, agronomist, and other businesses. It is a key foundation to establishing a crop intelligence platform, which will enable efficient resource management and high quality agronomy decision making and recommendations. In this paper, we designed and implemented a continental level agricultural data warehouse (ADW). ADW is characterised by its (1) flexible schema; (2) data integration from real agricultural multi datasets; (3) data science and business intelligent support; (4) high performance; (5) high storage; (6) security; (7) governance and monitoring; (8) consistency, availability and partition tolerant; (9) cloud compatibility. We also evaluate the performance of ADW and present some complex queries to extract and return necessary knowledge about crop management.",Int. J. Bus. Process. Integr. Manag.,2020,58,filtered
c4784652b900a9df26ac9247a232dca1b901dfe1,https://www.semanticscholar.org/paper/c4784652b900a9df26ac9247a232dca1b901dfe1,Operations Research Problems and Data Envelopment Analysis in Agricultural Land Processing – A Review,"Research Question: This paper aims at specifying the contribution of operations research (OR) methods and techniques to agricultural land processing. Motivation: Agricultural production is performed on an agricultural land, which has to be exploited in the best possible way, given the increasing human population and the limited availability of the land. Considering the importance of this issue, a large number of research studies dealing with problems in agriculture can be found in the literature, and many of these problems are solved by OR methods and techniques. However, to our knowledge, there are no review papers that deal with this specific area, so the main motivation is to provide a detailed review of selected OR methods application in the agricultural land processing area. Idea: The core idea behind this research is to perceive a real impact of OR methods and techniques implementation in the agricultural land processing. The research is based on detailed literature review for the period 2014-2019 and performed statistics involving publication by year, publication by journal and statistics involving keywords in articles. Data: The review was conducted using online repositories of the papers published in SCI and SCIe journals with impact factors in the period from 2014-2019. Tools: Analyzed papers are divided into three groups according to the OR method applied: linear optimization problems, DEA method and other OR methods (non linear, multicriteria, mixed integer programming, dynamic programming). Papers within the groups are analyzed according to the type of problems solved. Statistical analyses of all collected data were used to get a good insight into the applications of operations research problems and data envelopment analysis in agricultural land processing. Findings: The number of published papers in this specific area has a growing trend over the observed years (with some minor decrease in 2016 and 2019 in comparison with the previous year). All of the articles are related to specific application of the given methods to solving problems in the agricultural land processing, and this is the reason for many different keywords appearing in the articles. Some very important keywords such as “operations research” or “OR” does not appear in any article as a keyword. Inclusion of such common keywords may result in a faster search in repositories of all articles. Contribution: The primary contribution of this paper is a detailed review of application of linear optimization, data envelopment analysis and other OR methods in agricultural land processing in the period 2014-2019.",,2020,59,filtered
70080fdcaff014b5acb1ec2d2db4de9bfb4f0c57,https://www.semanticscholar.org/paper/70080fdcaff014b5acb1ec2d2db4de9bfb4f0c57,Zero-Shot Uncertainty-Aware Deployment of Simulation Trained Policies on Real-World Robots,"While deep reinforcement learning (RL) agents have demonstrated incredible potential in attaining dexterous behaviours for robotics, they tend to make errors when deployed in the real world due to mismatches between the training and execution environments. In contrast, the classical robotics community have developed a range of controllers that can safely operate across most states in the real world given their explicit derivation. These controllers however lack the dexterity required for complex tasks given limitations in analytical modelling and approximations. In this paper, we propose Bayesian Controller Fusion (BCF), a novel uncertainty-aware deployment strategy that combines the strengths of deep RL policies and traditional handcrafted controllers. In this framework, we can perform zero-shot sim-to-real transfer, where our uncertainty based formulation allows the robot to reliably act within out-of-distribution states by leveraging the handcrafted controller while gaining the dexterity of the learned system otherwise. We show promising results on two real-world continuous control tasks, where BCF outperforms both the standalone policy and controller, surpassing what either can achieve independently. A supplementary video demonstrating our system is provided at https://bit.ly/bcf_deploy.",ArXiv,2021,60,filtered
https://www.sciencedirect.com/science/article/pii/S2352711021001837,https://www.sciencedirect.com/science/article/pii/S2352711021001837,tx2_fcnn_node: An open-source ROS compatible tool for monocular depth reconstruction,"We present tx2_fcnn_node a Robot Operating System (ROS) compatible tool that is aimed at seamless integration of various monocular depth reconstruction neural networks to the robotic software based on ROS (which is a de-facto standard in the area of robotics). Our tool simplifies the process of deploying, evaluating, and comparing depth reconstruction neural networks both on real robots and in simulation. We complement our software with a set of the precompiled neural networks which can be used off the shelf, with some of them being able to demonstrate near real-time performance when running onboard compact embedded platforms, e.g. Nvidia Jetson TX2, that are often used nowadays both in academia and industry.",Sciencedirect,2022,61,filtered
845c1a9a43924a5ac907861f3b98f8f32f009832,https://www.semanticscholar.org/paper/845c1a9a43924a5ac907861f3b98f8f32f009832,"Internet of Robotic Things: Concept, Technologies, and Challenges","Internet of Things allow massive number of uniquely addressable “things” to communicate with each other and transfer data over existing internet or compatible network protocols. This paper proposes a new concept which tackles the issues for supporting control and monitoring activities at deployment sites and industrial automations, where intelligent things can monitor peripheral events, induce sensor data acquired from a variety of sources, use ad hoc, local, and distributed “machine intelligence” to determine appropriate course of actions, and then act to control or disseminate static or dynamic position aware robotic things in the physical world through a seamless manner by providing a means for utilizing them as Internet of robotic things (IoRT). Although progressive advancements can be seen in multi-robotic systems, robots are constantly getting enriched by easier developmental functionalities, such vertical robotic service centric silos are not enough for continuously and seamlessly supporting for which they are meant. In this paper, a novel concept—IoRT is presented that highlights architectural principles, vital characteristics, as well as research challenges. The aim of this paper is to provide a better understanding of the architectural assimilation of IoRT and identify important research directions on this term.",IEEE Access,2016,62,filtered
4d9351c8c32e530b2acf5186c974c471ec46175a,https://www.semanticscholar.org/paper/4d9351c8c32e530b2acf5186c974c471ec46175a,Workshop on Task Planning for Intelligent Robots in Service and Manufacturing,"Automated task planning for robots is usually implemented on a motion primitive domain, where the focus is on constructing meaningful, general motion primitives. In this work we propose planning on the higher abstraction level of robot skills. In this context, skills are general, functional blocks that contain both sensing and action, have a welldefined expected outcome and set of preconditions, and are thus immediately useful for planning. By using a world model, which is focused on the skills, we show that this is in fact the case. We show automated task planning and execution, as a sequence of skills and their parameters, based on the desired goal state and the current state from the world model. Experiments show that the approach is immediately applicable, given a skill-equipped robot, and that inconsistencies between the world model and physical world are overcome simply by replanning.",,2015,63,filtered
