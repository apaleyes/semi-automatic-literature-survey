doi,type,query_name,query_value,publication,publisher,publication_date,database,title,url,abstract,status,id,semantic_score
10.1109/ms.2020.2993662,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE Software,2020-01-01 00:00:00,semantic_scholar,what is really different in engineering ai-enabled systems?,https://www.semanticscholar.org/paper/05086329135fdb15049a5ac8edd7f980762f2097,"Advances in machine learning (ML) algorithms and increasing availability of computational power have resulted in huge investments in systems that aspire to exploit artificial intelligence (AI), in particular ML. AIenabled systems, software-reliant systems that include data and components that implement algorithms mimicking learning and problem solving, have inherently different characteristics than software systems alone.1 However, the development and sustainment of such systems also have many parallels with building, deploying, and sustaining software systems. A common observation is that although software systems are deterministic and you can build and test to a specification, AI-enabled systems, in particular those that include ML components, are generally probabilistic. Systems with ML components can have a high margin of error due to the uncertainty that often follows predictive algorithms. The margin of error can be related to the inability to predict the result in advance or the same result cannot be reproduced. This characteristic makes AI-enabled systems hard to test and verify.2 Consequently, it is easy to assume that what we know about designing and reasoning about software systems does not immediately apply in AI engineering. AI-enabled systems are software systems. The sneaky part about engineering AI systems is they are ""just like"" conventional software systems we can design and reason about until they?re not.",included,765,0.9178138971328736
10.1515/auto-2022-0020,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,at - Automatisierungstechnik,2022-01-01 00:00:00,semantic_scholar,paise® – process model for ai systems engineering,https://www.semanticscholar.org/paper/20e4fac51b5a8ced6e66f9fe11cddad7d87c6d6e,"Abstract The application of artificial-intelligence-(AI)-based methods within the context of complex systems poses new challenges within the product life cycle. The process model for AI systems engineering, PAISE®, addresses these challenges by combining approaches from the disciplines of systems engineering, software development and data science. The general approach builds on a component-wise development of the overall system including an AI component. This allows domain specific development processes to be parallelized. At the same time, component dependencies are tested within interdisciplinary checkpoints, thus resulting in a refinement of component specifications.",included,1111,0.9021071195602416
http://arxiv.org/abs/2001.07522v2,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),arxiv,arxiv,2020-01-16 00:00:00,arxiv,engineering ai systems: a research agenda,http://arxiv.org/abs/2001.07522v2,"Artificial intelligence (AI) and machine learning (ML) are increasingly
broadly adopted in industry, However, based on well over a dozen case studies,
we have learned that deploying industry-strength, production quality ML models
in systems proves to be challenging. Companies experience challenges related to
data quality, design methods and processes, performance of models as well as
deployment and compliance. We learned that a new, structured engineering
approach is required to construct and evolve systems that contain ML/DL
components. In this paper, we provide a conceptualization of the typical
evolution patterns that companies experience when employing ML as well as an
overview of the key problems experienced by the companies that we have studied.
The main contribution of the paper is a research agenda for AI engineering that
provides an overview of the key engineering challenges surrounding ML solutions
and an overview of open items that need to be addressed by the research
community at large.",not included,71,0.8996371030807495
http://arxiv.org/abs/1707.09095v2,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),arxiv,arxiv,2017-07-28 00:00:00,arxiv,toward the starting line: a systems engineering approach to strong ai,http://arxiv.org/abs/1707.09095v2,"Artificial General Intelligence (AGI) or Strong AI aims to create machines
with human-like or human-level intelligence, which is still a very ambitious
goal when compared to the existing computing and AI systems. After many hype
cycles and lessons from AI history, it is clear that a big conceptual leap is
needed for crossing the starting line to kick-start mainstream AGI research.
This position paper aims to make a small conceptual contribution toward
reaching that starting line. After a broad analysis of the AGI problem from
different perspectives, a system-theoretic and engineering-based research
approach is introduced, which builds upon the existing mainstream AI and
systems foundations. Several promising cross-fertilization opportunities
between systems disciplines and AI research are identified. Specific potential
research directions are discussed.",included,79,0.8995599150657654
10.1109/bigdata55660.2022.10021121,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2022 IEEE International Conference on Big Data (Big Data),2022-01-01 00:00:00,semantic_scholar,towards implementing responsible ai,https://www.semanticscholar.org/paper/6035386cbdadfd80ccae0b103bda9d04f65b44fb,"As the deployment of artificial intelligence (AI) is changing many fields and industries, there are concerns about AI systems making decisions and recommendations without adequately considering various ethical aspects, such as accountability, reliability, transparency, explainability, contestability, privacy, and fairness. While many sets of AI ethics principles have been recently proposed that acknowledge these concerns, such principles are high-level and do not provide tangible advice on how to develop ethical and responsible AI systems. To gain insight on the possible implementation of the principles, we conducted an empirical investigation involving semi-structured interviews with a cohort of AI practitioners. The salient findings cover four aspects of AI system design and development, adapting processes used in software engineering: (i) high-level view, (ii) requirements engineering, (iii) design and implementation, (iv) deployment and operation.",not included,1196,0.894280195236206
10.1109/wain52551.2021.00015,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Workshop on AI Engineering - Software Engineering for AI,2021-01-01 00:00:00,semantic_scholar,understanding and modeling ai-intensive system development,https://www.semanticscholar.org/paper/854aa07af911d493de2c465c5748b9453cee6a4d,"Developers of AI-Intensive Systems—i.e., systems that involve both “traditional” software and Artificial Intelligence—are recognizing the need to organize development systematically and use engineered methods and tools. Since an AI-Intensive System (AIIS) relies heavily on software, it is expected that Software Engineering (SE) methods and tools can help. However, AIIS development differs from the development of “traditional” software systems in a few substantial aspects. Hence, traditional SE methods and tools are not suitable or sufficient by themselves and need to be adapted and extended.A quest for “SE for AI” methods and tools has started. We believe that, in this effort, we should learn from experience and avoid repeating some of the mistakes made in the quest for SE in past years. To this end, a fundamental instrument is a set of concepts and a notation to deal with AIIS and the problems that characterize their development processes.In this paper, we propose to describe AIIS via a notation that was proposed for SE and embeds a set of concepts that are suitable to represent AIIS as well. We demonstrate the usage of the notation by modeling some characteristics that are particularly relevant for AIIS.",included,960,0.8918479681015015
10.1109/wain52551.2021.00020,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Workshop on AI Engineering - Software Engineering for AI,2021-01-01 00:00:00,semantic_scholar,requirement engineering challenges for ai-intense systems development,https://www.semanticscholar.org/paper/e4189dca82737cbaf9b56d1e6f58e9e1dddd8151,"Availability of powerful computation and communication technology as well as advances in artificial intelligence enable a new generation of complex, AI-intense systems and applications. Such systems and applications promise exciting improvements on a societal level, yet they also bring with them new challenges for their development. In this paper we argue that significant challenges relate to defining and ensuring behaviour and quality attributes of such systems and applications. We specifically derive four challenge areas from relevant use cases of complex, AI-intense systems and applications related to industry, transportation, and home automation: understanding, determining, and specifying (i) contextual definitions and requirements, (ii) data attributes and requirements, (iii) performance definition and monitoring, and (iv) the impact of human factors on system acceptance and success. Solving these challenges will imply process support that integrates new requirements engineering methods into development approaches for complex, AI-intense systems and applications. We present these challenges in detail and propose a research roadmap.",not included,910,0.8906081318855286
10.1145/3452383.3453718,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Symposium on Electronic Commerce,2021-01-01 00:00:00,semantic_scholar,a report on the second international workshop on software engineering for artificial intelligence (se4ai 2021),https://www.semanticscholar.org/paper/b4a45aaa71fb7d32c25bc7b17ebe255ab7ff2abd,"Computers control increasing numbers of objects in our daily life: phones, aircraft, cars, buildings, manufacturing machines, musical instruments, etc. In these so-called cyber-physical systems (CPSs), computers interact directly with the physical world through sensors and actuators. Those systems are becoming the key infrastructure and backbone of our society and are at the heart of revolutionary changes in our daily lives and economy. The sophistication and complexity of CPSs keep increasing since they must realize more functions with limited resources, which makes them increasingly difficult to build and manage. In particular, the cyber (software) part of these systems is growing rapidly and has become a key part of CPS, as they are the basis of operation for these systems. Artificial intelligence (AI) has a fundamental influence on the economy, administration, and society. AI is now also affecting software engineering, providing robust approaches for software development to analyze and evaluate complex software and its development processes. Repository mining, machine learning, big data analytics, and software visualization enable targeted insights and powerful predictions for software quality, software development, and software project management. The research community has shown a keen interest in this emerging field. This report presents a summary of the workshop held on February 2021 at KIT Bhubaneswar, co-located with the 14th Innovations in Software Engineering Conference (ISEC 2021).",not included,994,0.8878777623176575
10.48550/arxiv.2212.11854,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Business &amp; Information Systems Engineering,2022-01-01 00:00:00,semantic_scholar,data-centric artificial intelligence,https://www.semanticscholar.org/paper/70df7fec4224c0d98252a6c61ee5f835be6f9e0b,"Data-centric artificial intelligence (data-centric AI) represents an emerging paradigm that emphasizes the importance of enhancing data systematically and at scale to  build effective and efficient AI-based systems. The novel paradigm complements recent model-centric AI, which focuses on improving the performance of AI-based systems based on changes in the model using a fixed set of data. The objective of this article is to introduce practitioners and researchers from the field of Business and Information Systems Engineering (BISE) to data-centric AI. The paper defines relevant terms, provides key characteristics to contrast the paradigm of data-centric AI with the model-centric one, and introduces a framework to illustrate the different dimensions of data-centric AI. In addition, an overview of available tools for data-centric AI is presented and this novel paradigm is differenciated from related concepts. Finally, the paper discusses the longer-term implications of data-centric AI for the BISE community.",included,1263,0.8859785795211792
10.1109/rew.2019.00051,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2019 IEEE 27th International Requirements Engineering Conference Workshops (REW),2019-01-01 00:00:00,semantic_scholar,requirements engineering challenges in building ai-based complex systems,https://www.semanticscholar.org/paper/58090cdbb7526f4e22c09387814ee060dab1de54,"This paper identifies and tackles the challenges of the requirements engineering discipline when applied to development of AI-based complex systems. Due to their complex behaviour, there is an immanent need for a tailored development process for such systems. However, there is still no widely used and specifically tailored process in place to effectively and efficiently deal with requirements suitable for specifying a software solution that uses machine learning. By analysing the related work from software engineering and artificial intelligence fields, potential contributions have been recognized from agent-based software engineering and goal-oriented requirements engineering research, as well as examples from large product development companies. The challenges have been discussed, with proposals given how and when to tackle them. RE4AI taxonomy has also been outlined, to inform the tailoring of development process.",included,651,0.8855636715888977
10.1184/r1/16560183.v1,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE pervasive computing,2021-01-01 00:00:00,semantic_scholar,human-centered ai,https://www.semanticscholar.org/paper/264b9b136889da3b4d7e50ef58c77678b35dc3e0,"We identify three specific areas of focus to advance human-centered AI:• Designers and systems must understand the context of use and sense changes over time: Successful AI Engineering depends on the team’s ability to identify and articulate the desired system outcome and understand human and contextual factors affecting the outcome. The system itself must be able to learn when shifts in context have occurred. What are the best ways to maintain clarity around operational intent and mechanisms for adapting and evolving systems based on dynamic contexts and user needs?• Development of tools, processes, and practices to scope and facilitate human-machine teaming: Implementation of AI systems entails high levels of interdependence between human and machine. Adoption of AI systems requires the primary users to interact with and understand systems, gaining appropriate levels of trust. Every AI system needs to be designed to recognize boundaries and unfamiliar scenarios, and to provide transparency regarding its limitations.• Methods, mechanisms, and mindsets to engage in critical oversight: AI systems learn through data and observations, rather than being explicitly programmed for a deterministic outcome. Critical and reflective oversight by organizations, teams, and individuals that create and use AI systems is needed to uphold ethical principles and proactively consider the risks of bias, misuse, abuse, and unintended consequences through design, development, and ongoing deployment.For each area, we identify ongoing work as well and challenges and opportunities in developing and deploying AI systems with confidence.",included,934,0.8841918706893921
10.18293/seke2019-094,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Conference on Software Engineering and Knowledge Engineering,2019-01-01 00:00:00,semantic_scholar,safe-by-design development method for artificial intelligent based systems,https://www.semanticscholar.org/paper/876d346fb11be7636f30b11f597a525ce50dfd26,"Albeit Artiﬁcial Intelligent (AI) based systems are nowa-days deployed in a variety of safety critical domains, current engineering methods and standards are barely applicable for their development and assurance. The lack of common criteria to assess safety levels as well as the dependency of certain development phases w.r.t. the chosen technology (e.g., machine learning modules) are among the identiﬁed drawbacks. In addition, the development of such engineering methods has been hampered by the emerging challenges in AI-based systems design mainly regarding autonomy, correctness and prevention of catastrophic risks. In this paper we propose an approach to conduct a safe-by-design development process for AI based systems. The approach relies upon a method which beneﬁts from a reference AI architecture and safety principles. This contribution helps to address safety concerns and to comprehend current AI architectures diversity and particularities.",included,691,0.8835116624832153
10.1515/auto-2022-0076,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,at - Automatisierungstechnik,2022-01-01 00:00:00,semantic_scholar,ki-engineering – ai systems engineering,https://www.semanticscholar.org/paper/f8492b9265e21f7db13c71214b68d640c6bf3903,Abstract KI-Engineering – translated as AI Systems Engineering – aims at the development of a new engineering practice in the intersection of Systems Engineering and Artificial Intelligence. Its goal is to professionalize the use of AI methods in a systems engineering context. The article defines KI-Engineering and compares it with historical examples of research disciplines that founded engineering disciplines. It furthermore discusses the long-term challenges where further development is needed and which results were already achieved in the context of the Competence Center for KI-Engineering (CC-KING).,included,1110,0.8826118111610413
10.1109/iisr.2018.8535903,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Symposium on Robotics,2018-01-01 00:00:00,semantic_scholar,the risks of low level narrow artificial intelligence,https://www.semanticscholar.org/paper/a537f52e8febb263d320690cdf3eb99a4e03131d,"There is a great deal of concern expressed by many in the artificial intelligence (AI) community about the existential risk of this rapidly developing technology. This paper provides a discussion on some issues that need to be addressed to handle potential future risks and provides some new perspectives. The development of artificial intelligence is moving from relatively limited standalone to large-scale, complex distributed systems. However, potential risks such as malfunction, malicious attacks and mismatch of objective can occur from hardware and software failures or design errors. Moreover, a system controlled by high level AI can become unpredictable in its behaviours and thus ethical risks can emerge when such systems have to make a decision related to operational issues. Given that all new, disruptive, technologies have risks associated with them, what we need to do, as practitioners and users, is to find ways of mitigating those risks. We discuss applications of agent-based simulation to illustrate some of the risks and, potentially, how to mitigate them.",included,173,0.8822519183158875
10.1109/re51729.2021.00070,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE International Requirements Engineering Conference,2021-01-01 00:00:00,semantic_scholar,human-centric requirements engineering for artificial intelligence software systems,https://www.semanticscholar.org/paper/60727256f6d41a2d5b5e20a45c3eb53a04fe2565,"The surge in data availability and processing power has made it possible for Artificial Intelligence (AI) to advance at a faster rate. However, the different nature of AI systems has posed significant new challenges to Requirements Engineering (RE). Literature has shown that AI systems do not use current RE methods. It was also found that data scientists are taking the role of the requirements engineers resulting in software that does not focus on users needs. Building AI software with a human-centric approach has proven to produce more ethical, transparent, inclusive and non-bias outcomes. This research will look into adjusting current RE methodologies to fit into AI systems from a human-centric perspective. The project will aim to establish requirements specifications for human-centric AI and map them into a modeling language. A platform will be used to visually model and present requirements. Finally, I plan to conduct a case study to evaluate the modeling language. To date, I have conducted a Systematic Literature Review (SLR) to find current RE methodologies and challenges in AI and currently in the planning phase of a survey to find adopted practices in the industry.",included,929,0.8811267614364624
10.1145/3194104.3194109,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2018 IEEE/ACM 6th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering (RAISE),2018-01-01 00:00:00,semantic_scholar,ways of applying artificial intelligence in software engineering,https://www.semanticscholar.org/paper/e2d55453c901bc5b26ae24b80d14a9a88c35f71f,"As Artificial Intelligence (AI) techniques become more powerful and easier to use they are increasingly deployed as key components of modern software systems. While this enables new functionality and often allows better adaptation to user needs it also creates additional problems for software engineers and exposes companies to new risks. Some work has been done to better understand the interaction between Software Engineering and AI but we lack methods to classify ways of applying AI in software systems and to analyse and understand the risks this poses. Only by doing so can we devise tools and solutions to help mitigate them. This paper presents the AI in SE Application Levels (AI-SEAL) taxonomy that categorises applications according to their point of application, the type of AI technology used and the automation level allowed. We show the usefulness of this taxonomy by classifying 15 papers from previous editions of the RAISE workshop. Results show that the taxonomy allows classification of distinct AI applications and provides insights concerning the risks associated with them. We argue that this will be important for companies in deciding how to apply AI in their software applications and to create strategies for its use.",not included,85,0.8807332515716553
10.1145/3368089.3417039,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,ESEC/SIGSOFT FSE,2020-01-01 00:00:00,semantic_scholar,continuous experimentation on artificial intelligence software: a research agenda,https://www.semanticscholar.org/paper/68b5623e6aeaaa32d4f6a09b18148fee096bb940,"Moving from experiments to industrial level AI software development requires a shift from understanding AI/ ML model attributes as a standalone experiment to know-how integrating and operating AI models in a large-scale software system. It is a growing demand for adopting state-of-the-art software engineering paradigms into AI development, so that the development efforts can be aligned with business strategies in a lean and fast-paced manner. We describe AI development as an “unknown unknown” problem where both business needs and AI models evolve over time. We describe a holistic view of an iterative, continuous approach to develop industrial AI software basing on business goals, requirements and Minimum Viable Products. From this, five areas of challenges are presented with the focus on experimentation. In the end, we propose a research agenda with seven questions for future studies.",not included,878,0.8805668950080872
http://arxiv.org/abs/2302.07872v1,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),arxiv,arxiv,2023-02-14 00:00:00,arxiv,data-centric governance,http://arxiv.org/abs/2302.07872v1,"Artificial intelligence (AI) governance is the body of standards and
practices used to ensure that AI systems are deployed responsibly. Current AI
governance approaches consist mainly of manual review and documentation
processes. While such reviews are necessary for many systems, they are not
sufficient to systematically address all potential harms, as they do not
operationalize governance requirements for system engineering, behavior, and
outcomes in a way that facilitates rigorous and reproducible evaluation. Modern
AI systems are data-centric: they act on data, produce data, and are built
through data engineering. The assurance of governance requirements must also be
carried out in terms of data. This work explores the systematization of
governance requirements via datasets and algorithmic evaluations. When applied
throughout the product lifecycle, data-centric governance decreases time to
deployment, increases solution quality, decreases deployment risks, and places
the system in a continuous state of assured compliance with governance
requirements.",included,30,0.8804633617401123
10.1109/sose55472.2022.9812672,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Symposium on Service Oriented Software Engineering,2022-01-01 00:00:00,semantic_scholar,engineering dependable ai systems,https://www.semanticscholar.org/paper/5a19c398c2b4738f5eb473a175807bb9b59e6d71,"If AI algorithms are now pervasive in our daily life, they essentially deliver non critical services, i.e., services which failures remain socially and economically acceptable. In order to introduce those algorithms in critical systems, new engineering practices must be defined to give a justified trust in the capability of the system to deliver the intended services. In this paper, we give an overview of the approach that we have put in place to reach this goal in the framework of the French Confiance.ai program. Based on the needs of the industrial partners of the program, we propose a model-based analysis framework capturing the two dimensions of the problem: the one related to the development and operation of the system and the one related to the trust in the system.",included,1123,0.8794834017753601
10.15407/pp2022.03-04.099,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,PROBLEMS IN PROGRAMMING,2022-01-01 00:00:00,semantic_scholar,some aspects of software engineering for ai-based systems,https://www.semanticscholar.org/paper/17f80eaec2808e01a766be634fa5b77e9dfa57ef,"AI-based software systems are rapidly spreading in various business areas. In this context, the unavoidable convergence of the Software Engineering and Artificial Intelligence and Machine Learning (AI/ML) disciplines is considered an obvious and one of the following significant challenges within the engineering process. The life cycle, models, and technologies of AI/ML elements are pretty specific, and this should be considered in software engineering to ensure their performance and compliance with business needs. AI/ML applications have some distinct characteristics compared to traditional software applications. Thus, several challenges and risk factors regarding AI/ML applications appear to software developers. To study the common challenges in AI/ML application development, we used two different perspectives: software engineering and machine learning. AI/ML applications, like other software systems, need a well-defined software engineering process for their development and maintenance. We discussed challenges and recommendations for different phases of the software development life cycle for ML applications, particularly requirement engineering, design, implementation, integration, testing, and deployment. AI/ML application development has specific aspects to consider as a software development project. We discussed the characteristics and recommendations concerning problem formulation, data acquisition, preprocessing, feature extraction, model building, evaluation, model integration and deployment, model management, and ethics in AI/ML development. In the work, there were formulated recommendations for each analyzed challenge that should be useful for software developers. The next stage of this research is the compilation of detailed systematic guidelines for the software development process for AI/ML systems.",included,1124,0.87928307056427
10.48550/arxiv.2208.02837,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Artificial General Intelligence,2022-01-01 00:00:00,semantic_scholar,core and periphery as closed-system precepts for engineering general intelligence,https://www.semanticscholar.org/paper/21672a43ee8ea925173702fe034cbde18d9c773a,"Engineering methods are centered around traditional notions of decomposition and recomposition that rely on partitioning the inputs and outputs of components to allow for component-level properties to hold after their composition. In artificial intelligence (AI), however, systems are often expected to influence their environments, and, by way of their environments, to influence themselves. Thus, it is unclear if an AI system's inputs will be independent of its outputs, and, therefore, if AI systems can be treated as traditional components. This paper posits that engineering general intelligence requires new general systems precepts, termed the core and periphery, and explores their theoretical uses. The new precepts are elaborated using abstract systems theory and the Law of Requisite Variety. By using the presented material, engineers can better understand the general character of regulating the outcomes of AI to achieve stakeholder needs and how the general systems nature of embodiment challenges traditional engineering practice.",included,1233,0.8783146739006042
10.5555/3463952.3464248,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Adaptive Agents and Multi-Agent Systems,2021-01-01 00:00:00,semantic_scholar,software engineering methods for responsible artificial intelligence,https://www.semanticscholar.org/paper/40a6c6adf5f8a0cffcf0c36e1963d6324add2705,"In order to ensure responsible Artificial intelligence (AI) applications engineering, we need to make sure that the development of AI systems is mindful of the consequences for individuals and societies. By anticipating the consequences of the design choices, reflecting upon the problem being solved by engaging all stakeholders and taking appropriate actions to ensure openness and the system’s social, legal, and ethical acceptability. This research aims to develop an engineering process model by which ethical considerations can be addressed throughout the AI systems’ software development life-cycle. The design methodological framework engineered in this PhD research will support aligning system goals with key ethical values by providing explicit values analysis and interpretation mechanisms, formal representation of ethical values, mechanisms for stakeholders participation in handling ethical deliberation, and providing support for governance and compliance mechanisms.",included,975,0.8775680065155029
10.1049/joe.2019.1135,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Jurnal Engineering,2017-01-01 00:00:00,semantic_scholar,three iqs of ai systems and their testing methods,https://www.semanticscholar.org/paper/3ac1ae71926ba9e560f147858af60fa3fb0c80c3,"The rapid development of artificial intelligence has brought the artificial intelligence threat theory as well as the problem about how to evaluate the intelligence level of intelligent products. Both need to find a quantitative method to evaluate the intelligence level of intelligence systems, including human intelligence. Based on the standard intelligence system and the extended Von Neumann architecture, this paper proposes General IQ, Service IQ and Value IQ evaluation methods for intelligence systems, depending on different evaluation purposes. Among them, the General IQ of intelligence systems is to answer the question of whether the artificial intelligence can surpass the human intelligence, which is reflected in putting the intelligence systems on an equal status and conducting the unified evaluation. The Service IQ and Value IQ of intelligence systems are used to answer the question of how the intelligent products can better serve the human, reflecting the intelligence and required cost of each intelligence system as a product in the process of serving human.",not included,248,0.8765653967857361
10.1109/dasc50938.2020.9256709,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2020 AIAA/IEEE 39th Digital Avionics Systems Conference (DASC),IEEE,2020-10-15 00:00:00,ieeexplore,the conception of a large-scale systems engineering environment,https://ieeexplore.ieee.org/document/9256709/,"With the rise of artificial intelligence, it is time to shape the systems engineering tooling environment for the future. In the last decade, we have seen several emerging technologies that will potentially have a great impact in complex systems. These new technologies are expected to cause a disruptive impact not only in the products but also in to the tools used across the whole product life cycle. For this reason, is imperative to perform a critical review of the current systems engineering tooling ecosystem. This assessment should also map the open research problems that could prevent the complete integration of the new technologies into the systems engineering framework. This paper proposes a new architecture for a system engineering environment to operate in large scale projects. The objective of this research is twofold: it will first identify the capabilities for the next generation platform, and secondly, it will evaluate how artificial intelligence applications can be integrated in compliance with DO-330. The concept developed by this research will drive tool design recommendations enabling the use of artificial intelligence driven applications in a systems engineering tooling ecosystem.",included,1762,0.8759571313858032
10.48550/arxiv.2212.10693,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Information and Software Technology,2022-01-01 00:00:00,semantic_scholar,requirements engineering for artificial intelligence systems: a systematic mapping study,https://www.semanticscholar.org/paper/09b2043f4bafdafffee77197ba1420db4cbc646b,"[Context] In traditional software systems, Requirements Engineering (RE) activities are well-established and researched. However, building Artificial Intelligence (AI) based software with limited or no insight into the system's inner workings poses significant new challenges to RE. Existing literature has focused on using AI to manage RE activities, with limited research on RE for AI (RE4AI). [Objective] This paper investigates current approaches for specifying requirements for AI systems, identifies available frameworks, methodologies, tools, and techniques used to model requirements, and finds existing challenges and limitations. [Method] We performed a systematic mapping study to find papers on current RE4AI approaches. We identified 43 primary studies and analysed the existing methodologies, models, tools, and techniques used to specify and model requirements in real-world scenarios. [Results] We found several challenges and limitations of existing RE4AI practices. The findings highlighted that current RE applications were not adequately adaptable for building AI systems and emphasised the need to provide new techniques and tools to support RE4AI. [Conclusion] Our results showed that most of the empirical studies on RE4AI focused on autonomous, self-driving vehicles and managing data requirements, and areas such as ethics, trust, and explainability need further research.",not included,1155,0.8749252557754517
10.1515/auto-2022-0015,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,at - Automatisierungstechnik,2022-01-01 00:00:00,semantic_scholar,industrial challenges for ai systems engineering,https://www.semanticscholar.org/paper/d13fc37f940384b53032042504c858175b471201,"Abstract Integration of Artificial Intelligence (AI) methods into industrial systems engineering processes is challenging. Despite an increasing body of knowledge on AI techniques and impressive state-of-the-art reports, the application of AI in industrial contexts is only at an early stage. This paper summarizes challenges for AI Systems Engineering. Two examples of AI systems engineering are provided: the TRUMPF Sorting Guide and ABB BatchInsight. Summaries of the projects give insights into the project executions and related challenges. The learnings from these projects also show that increased maturity of AI systems engineering can be expected from increased method competence and adjusted project setups. Here guidelines and best practices for AI systems engineering can support.",not included,1112,0.8741061091423035
10.18293/seke2020-094,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Conference on Software Engineering and Knowledge Engineering,2020-01-01 00:00:00,semantic_scholar,guidelines for quality assurance of machine learning-based artificial intelligence,https://www.semanticscholar.org/paper/36e614624eca44d7854c982d089e033658b50431,"Significant effort is being put into developing industrial applications for artificial intelligence (AI), especially those using machine learning (ML) techniques. Despite the intensive support for building ML applications, there are still challenges when it comes to evaluating, assuring, and improving the quality or dependability. The difficulty stems from the unique nature of ML, namely, system behavior is derived from training data not from logical design by human engineers. This leads to black-box and intrinsically imperfect implementations that invalidate many principles and techniques in traditional software engineering. In light of this situation, the Japanese industry has jointly worked on a set of guidelines for the quality assurance of AI systems (in the Consortium of Quality Assurance for AI-based Products and Services) from the viewpoint of traditional quality-assurance engineers and test engineers. We report on the second version of these guidelines, which cover a list of quality evaluation aspects, catalogue of current state-of-the-art techniques, and domain-specific discussions in five representative domains. The guidelines provide significant insights for engineers in terms of methodologies and designs for tests driven by application-specific requirements.",included,836,0.8727734684944153
10.1109/icse48619.2023.00012,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),IEEE,2023-05-20 00:00:00,ieeexplore,software engineering as the linchpin of responsible ai,https://ieeexplore.ieee.org/document/10172687/,"From humanity's existential risks to safety risks in critical systems to ethical risks, responsible AI, as the saviour, has become a major research challenge with significant real-world consequences. However, achieving responsible AI remains elusive despite the plethora of high-level ethical principles, risk frameworks and progress in algorithmic assurance. In the meantime, software engineering (SE) is being upended by AI, grappling with building system-level quality and alignment from inscrutable machine learning models and code generated from natural language prompts. The upending poses new challenges and opportunities for engineering AI systems responsibly. This talk will share our experiences in helping the industry achieve responsible AI systems by inventing new SE approaches. It will dive into industry challenges (such as risk silos and principle-algorithm gaps) and research challenges (such as lack of requirements, emerging properties and inscrutable systems) and make the point that SE is the linchpin of responsible AI. But SE also requires some fundamental rethinking - shifting from building functions into AI systems to discovering and managing emerging functions from AI systems. Only by doing so can SE take on critical new roles, from understanding human intelligence to building a thriving human-AI symbiosis.",included,1879,0.8714330196380615
10.1145/3383219.3383220,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Conference on Evaluation & Assessment in Software Engineering,2020-01-01 00:00:00,semantic_scholar,a multiple case study of artificial intelligent system development in industry,https://www.semanticscholar.org/paper/17596a8474722592eaa5f0795f00b82efc73ffd3,"There is a rapidly increasing amount of Artificial Intelligence (AI) systems developed in recent years, with much expectation on its capacity of innovation and business value generation. However, the promised value of AI systems in specific business contexts might not be understood, and further integrated into the development processes. We wanted to understand how software engineering processes and practices can be applied to develop AI systems in a fast-faced, business-driven manner. As the first step, we explored contextual factors of AI development and the connections between AI developments to business opportunities. We conducted 12 semi-structured interviews in seven companies in Brazil, Norway and Southeast Asia. Our investigation revealed different types of AI systems and different AI development approaches. However, it is common that business opportunities involving with AI systems are not validated and there is lack of business-driven metrics that guide the development of AI systems. The findings have implications for future research on business-driven AI development and supporting tools and practices.",not included,841,0.8704707026481628
10.1177/0037549717727362,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Conference on Advances in System Simulation,2017-01-01 00:00:00,semantic_scholar,special issue on artificial intelligence in modeling and simulation,https://www.semanticscholar.org/paper/ddf869b3a382899d9eea49b86b833294b5e21a9e,"Artificial Intelligence (AI) is concerned with the development of innovative computing systems based on new models that simulate or emulate different aspects of natural intelligence. Such models can exhibit characteristics typically attributed to human intelligence like reasoning, perception, planning, learning, pattern recognition, problem-solving, rationality, and decision making, as well as more general characteristics of intelligence, like autonomy, proactivity, adaptability or sociability. Examples of AI models are knowledge-based systems, intelligent agents and multi-agent systems. AI can be an appealing computational tool for the modeling and simulation of systems for which it is difficult or even impossible to develop detailed physical or engineering simulation models using standard mathematical methods. AI-based models can be very useful for simulating natural and intentional systems as found for example, but not only, in different fields like social, economic and life sciences.",not included,151,0.8695105910301208
10.1109/isse54508.2022.10005487,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2022 IEEE International Symposium on Systems Engineering (ISSE),IEEE,2022-10-26 00:00:00,ieeexplore,examples of ai-based assistance systems in context of model-based systems engineering,https://ieeexplore.ieee.org/document/10005487/,"Digitization is changing many fields of our society. Technical systems in particular are undergoing major changes. Tomorrow’s systems are characterized by their autonomy, high level of interconnection, and socio-technical interfaces. These systems can no longer be developed by one engineering discipline alone, but require interdisciplinary development teams. This type of development requires a high degree of collaboration, communication, and orchestration. Model-Based Systems Engineering (MBSE) supports engineers in the interdisciplinary development of future systems. MBSE uses models to generate a unified and complete view of the system. This allows changes to be easily tracked and the visualization helps to understand the system discipline-independent. The creation of these models still requires high effort. New AI technologies can be used to derive potential assistant systems in the context of MBSE. This paper shows realized examples of AI-based assistance systems. They are motivated by the experience of using MBSE in research and development projects with high complexity and inter-disciplinarity. The presented results are defined and first prototypically realized assistance within student projects.",not included,1746,0.8693345785140991
10.1145/3489449.3490014,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,European Conference on Pattern Languages of Programs,2021-01-01 00:00:00,semantic_scholar,architectural patterns for integrating ai technology into safety-critical systems,https://www.semanticscholar.org/paper/98cbc71f45d131de722c04bffb18cb59f4f75b44,"Artificial Intelligence (AI) is widely acknowledged as one of the most disruptive technologies driving the digital transformation of industries, enterprises, and societies in the 21st century. Advances in computing speed, algorithmic improvements, and access to a vast amount of data contributed to the adaption of AI in many different domains. Due to the outstanding performance, AI technology is increasingly integrated into safety-critical applications. However, the established safety engineering processes and practices have been only successfully applied in conventional model-based system development and no commonly agreed approaches for integrating AI technology are available yet. This work presents two architectural patterns that can support designers and engineers in the conception of safety-critical AI-enhanced cyber-physical system (CPS) applications. The first pattern addresses the problem of integrating AI capabilities into safety-critical functions. The second pattern deals with architectural approaches to integrate AI technologies for monitoring and learning system-specific behavior at runtime.",included,922,0.8690606355667114
http://arxiv.org/abs/1911.02912v1,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),arxiv,arxiv,2019-10-15 00:00:00,arxiv,priority quality attributes for engineering ai-enabled systems,http://arxiv.org/abs/1911.02912v1,"Deploying successful software-reliant systems that address their mission
goals and user needs within cost, resource, and expected quality constraints
require design trade-offs. These trade-offs dictate how systems are structured
and how they behave and consequently can effectively be evolved and sustained.
Software engineering practices address this challenge by centering system
design and evolution around delivering key quality attributes, such as
security, privacy, data centricity, sustainability, and explainability. These
concerns are more urgent requirements for software-reliant systems that also
include AI components due to the uncertainty introduced by data elements.
Moreover, systems employed by the public sector exhibit unique design time and
runtime challenges due to the regulatory nature of the domains. We assert that
the quality attributes of security, privacy, data centricity, sustainability,
and explainability pose new challenges to AI engineering and will drive the
success of AI-enabled systems in the public sector. In this position paper, we
enumerate with examples from healthcare domain concerns related to these
requirements to mitigate barriers to architecting and fielding AI-enabled
systems in the public sector.",included,73,0.8663809895515442
10.1109/icess.2019.8782512,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Conference on Embedded Software and Systems,2019-01-01 00:00:00,semantic_scholar,an open and modular architecture for autonomous and intelligent systems,https://www.semanticscholar.org/paper/690eba7bcbadb3a93c3b8808d16d8a9a3bd7d2ce,"Over the past few decades, remarkable progress has been made in the the field of Artificial Intelligence (AI). For some tasks such as games, natural language processing, and image classification, AI powered applications can match or surpass human performance. Despite this progress, truly Autonomous and Intelligent Systems (AIS) serving the needs of, and sharing the environment with humans, are yet to become a commercial reality. AIS engineering requires considerable integration efforts that must be disciplined and guided by a reference model enabling reuse and concurrent design: an open and modular architecture. While several specialized architectures have been developed over the course of few decades, there is a need for a unified approach that supports multi-agency, learning, knowledge representation, reasoning, planning, and run-time verification. In this paper, we propose an open and modular architecture for autonomous and intelligent systems. We start by defining the three primary modules of the architecture, namely situational assessment, knowledge repository and management, and decision making. We then refine each module into functional units and we describe possible interaction patterns among them.",included,695,0.8660294413566589
10.1145/3550356.3561609,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,ACM/IEEE International Conference on Model Driven Engineering Languages and Systems,2022-01-01 00:00:00,semantic_scholar,industrial requirements for supporting ai-enhanced model-driven engineering,https://www.semanticscholar.org/paper/e6fa6cfb4f68298519e7da4757f82d77dd614607,"There is an increasing interest in research on the combination of AI techniques and methods with MDE. However, there is a gap between AI and MDE practices, as well as between researchers and practitioners. This paper tackles this gap by reporting on industrial requirements in this field. In the AIDOaRt research project, practitioners and researchers collaborate on AI-augmented automation supporting modeling, coding, testing, monitoring, and continuous development in cyber-physical systems. The project specifically lies at the intersection of industry and academia collaboration with several industrial use cases. Through a process of elicitation and refinement, 78 high-level requirements were defined, and generalized into 30 generic requirements by the AIDOaRt partners. The main contribution of this paper is the set of generic requirements from the project for enhancing the development of cyber-physical systems with artificial intelligence, DevOps, and model-driven engineering, identifying the hot spots of industry needs in the interactions of MDE and AI. Future work will refine, implement and evaluate solutions toward these requirements in industry contexts.",not included,1147,0.8654136061668396
10.3724/sp.j.1041.2024.00363,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Acta Psychologica Sinica,2022-01-01 00:00:00,semantic_scholar,new research paradigms and agenda of human factors science in the intelligence era,https://www.semanticscholar.org/paper/a334d529f6b6e778c32436454b405c5cc51b36a7,"This paper proposes the innovative concept of""human factors science""to characterize engineering psychology, human factors engineering, human-computer interaction, and other similar fields. Although the perspectives in these fields differ, they share a common approach:""human-centered design.""In the AI era, the human-machine relationship presents a trans-era evolution to""human-AI teaming.""The change has raised challenges for human factors science, compelling us to re-examine current research paradigms and agendas. Based on our previous work, this paper proposes three research paradigms: (1) human-AI joint cognitive systems: this regards an intelligent agent as a cognitive agent with a certain level of cognitive capabilities. A human-AI system can be characterized as a joint cognitive system in which humans and intelligent agents work as teammates for collaboration; (2) human-AI joint cognitive ecosystems: an intelligent ecosystem with multiple human-AI systems can be represented as a human-AI joint cognitive ecosystem. The overall performance of the ecosystem depends on optima collaboration and design across the multiple human-AI systems; (3) intelligent sociotechnical systems (iSTS): human-AI systems are design, developed, and deployed in an iSTS environment. The successful design, development, and deployment of a human-AI system within an iSTS environment depends on the synergistic optimization between the subsystems. This paper looks forward to the future research agenda of human factors science from three aspects: human-AI interaction, intelligent human-machine interface, and human-AI teaming. Analyses show that the three new research paradigms will benefit future research in human factors science. We believe the proposed research paradigms and the future research agenda will mutually promote each other, further advancing human factors science in the AI era.",not included,1375,0.8643624782562256
10.1109/ms.2020.2987666,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE Software,2020-01-01 00:00:00,semantic_scholar,the ai effect: working at the intersection of ai and se,https://www.semanticscholar.org/paper/9437a77b0ea18961ade324f50d3e65738b2eab0c,"This special issue explores the intersection of artificial intelligence (AI) and software engineering (SE), that is, what can AI do for SE, and how can we as software engineers design and build better AI systems?",not included,799,0.863954484462738
10.1109/icoias.2018.8494128,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2018 International Conference on Intelligent Autonomous Systems (ICoIAS),IEEE,2018-03-03 00:00:00,ieeexplore,intelligent autonomous systems for software engineering - an example,https://ieeexplore.ieee.org/document/8494128/,"In this ever-growing competitive world, traditionally large corporation IT systems need substantial effort and cost to maintain and manage systems engineering is called as IT Service management. With advancement of Artificial Intelligence (AI), IT service management can draw benefits and drive efficiency the way an incident or ticket is managed. AI can not only help in incident resolution steps (like incident creation, recording, response, resolution and closure), but also can ensure no-recurrence or no-repeat of the incident. This opportunity is the focus of this paper. In this paper, AI concepts starting from knowledge management, corpus creation and defining machine learning algorithm to automate all service management actions will be discussed. Readers of this paper will learn how to apply AI in IT Service management and identify approaches to define organizational specific machine learning algorithms. This paper also provides a bird's eye view of what is the structured approach for applying AI in various IT fields, with Service management as an example field.",not included,1805,0.8639512658119202
10.1109/dsn-w50199.2020.00023,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2020 50th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W),2020-01-01 00:00:00,semantic_scholar,ai safety landscape from short-term specific system engineering to long-term artificial general intelligence,https://www.semanticscholar.org/paper/976788d6edc75e73d9800e12500df882b0b51402,"AI Safety is an emerging area that integrates very different perspectives from mainstream AI, critical system engineering, dependable autonomous systems, artificial general intelligence, and many other areas concerned and occupied with building AI systems that are safe. Because of this diversity, there is an important level of disagreement in the terminology, the ontologies and the priorities of the field. The Consortium on the Landscape of AI Safety (CLAIS) is an international initiative to create a worldwide, consensus-based and generally-accepted knowledge base (online, interactive and constantly evolving) of structured subareas in AI Safety, including terminology, technologies, research gaps and opportunities, resources, people and groups working in the area, and connection with other subareas and disciplines. In this note we summarise early discussions around the initiative, the associated workshops, its current state and activities, including the body of knowledge, and how to contribute. On a more technical side, I will cover a few spots in the landscape, from very specific and short-term safety engineering issues appearing in specialised systems, to more long-term hazards emerging from more general and powerful intelligent systems.",not included,774,0.8636248111724854
10.1145/3385032.3385055,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Symposium on Electronic Commerce,2020-01-01 00:00:00,semantic_scholar,a report on the first workshop on software engineering for artificial intelligence (se4ai 2020),https://www.semanticscholar.org/paper/fc70735820056998c6351026f928ceea90424087,"With advancement in technology-driven decision making, the software-intensive systems for decisions have become more robust, dynamic, adaptive, context-aware, dependable. Architectural designs of such systems crave for new approaches where the data-driven decision making has to be incorporated in the solution. Methods for recommendation mechanism, prediction of operation failures, dealing with unsafe conditions etc are going to be part of the solution itself. Integrating such features to conceive an intelligent system that will directly influence the business solution is mostly appreciated. This would not have been possible without the direct interference of Artificial Intelligence which has been a standard procedure of industrial repertoire since 1980s. The direct impact of AI on social and economic life has been been felt mostly in last decade (since 2007) with the advent of smart phone, which contribute largely to ""big data"". The era of ""big data"" has witnessed the efficacy of Machine Learning and there is a need of the hour to combine data-driven machine intelligence with human intelligence (insights and domain knowledge) to effectively make the software development (requirement, design, testing, deployment and operation management) intelligent. The research community has shown a keen interest in this emerging field. In this report, we present a pre-organization summary of the workshop to be held on February 27, 2020, at IIIT Jabbalpur (India), co-located with the 13th Innovations in Software Engineering Conference (ISEC 2020).",not included,816,0.8635998368263245
10.1145/3299819.3299843,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Artificial Intelligence and Cloud Computing Conference,2018-01-01 00:00:00,semantic_scholar,ai based intelligent system on the edison platform,https://www.semanticscholar.org/paper/aff8681225be05b78df1ed663c65087c65334b7e,"In recent years, artificial intelligence (AI) has become a trend all over the world. This trend has led to the application and development of intelligent system that apply AI. In this paper, we describe a system architecture that uses AI, on a platform called EDISON, for computer science and engineering research. This architecture can be used to develop intelligent systems and can support applications in various fields by assisting in the development of algorithms and computer code. In this paper, we demonstrate the scalability of the proposed architecture on EDISON using different languages and application examples from various fields.",included,312,0.8619464039802551
10.1109/dsd53832.2021.00053,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Euromicro Symposium on Digital Systems Design,2021-01-01 00:00:00,semantic_scholar,"aidoart: ai-augmented automation for devops, a model-based framework for continuous development in cyber-physical systems",https://www.semanticscholar.org/paper/27bed49eb06b15f29260a217a3329d36c111801e,"With the emergence of Cyber-Physical Systems (CPS), the increasing complexity in development and operation demands for an efficient engineering process. In the recent years DevOps promotes closer continuous integration of system development and its operational deployment perspectives. In this context, the use of Artificial Intelligence (AI) is beneficial to improve the system design and integration activities, however, it is still limited despite its high potential. AIDOaRT is a 3 years long H2020-ECSEL European project involving 32 organizations, grouped in clusters from 7 different countries, focusing on AI-augmented automation supporting modelling, coding, testing, monitoring and continuous development of Cyber-Physical Systems (CPS). The project proposes to apply Model-Driven Engineering (MDE) principles and techniques to provide a framework offering proper AI-enhanced methods and related tooling for building trustable CPSs. The framework is intended to work within the DevOps practices combining software development and information technology (IT) operations. In this regard, the project points at enabling AI for IT operations (AIOps) to auto-mate decision making process and complete system development tasks. This paper presents an overview of the project with the aim to discuss context, objectives and the proposed approach.",not included,918,0.8591272830963135
10.1109/rew56159.2022.00037,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2022 IEEE 30th International Requirements Engineering Conference Workshops (REW),2022-01-01 00:00:00,semantic_scholar,ai ethics impact assessment based on requirement engineering,https://www.semanticscholar.org/paper/1cc70f06afd34865deede7001925f35d250cc456,"This paper proposes a methodology for evaluating the ethical impact of artificial intelligence (AI) systems on people and society based on AI ethics guidelines. The ethical impact of AI has been recognized as a social issue, and countries and organizations have formulated principles and guidelines on AI ethics, and laws and regulations will be enforced in Europe. Because these principles and guidelines are written in terms of philosophy and law, AI service providers, developers, and business users have the challenge of how they should practice the principles and guidelines to their AI systems. To address this challenge, we first analyzed cases of ethical problems caused by AI in the past and assumed that ethical problems could be linked to interactions between components of AI systems and stakeholders related to such systems. On the basis of this assumption, we then developed a methodology to comprehensively extract the ethical risks that an AI system poses. This methodology consists of two approaches. The first approach is to develop an AI ethics model that embodies ethics guidelines as necessary requirements for ethical AI systems and correlates these requirements with interactions. The second approach is an impact assessment process that uses the AI ethics models to extract ethical risks for individual AI systems. In this paper, we discuss the details of this methodology and show the results of an initial validation to verify the above assumption and the ease of the impact assessment process.",included,1144,0.8575771450996399
10.1109/transai60598.2023.00015,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2023 Fifth International Conference on Transdisciplinary AI (TransAI),IEEE,2023-09-27 00:00:00,ieeexplore,ai engineering to deploy reliable ai in industry,https://ieeexplore.ieee.org/document/10387654/,"To bring competitive advantage to industry through a sound AI deployment, we need an end-to-end “AI systems engineering” process covering the overall lifecycle of an AI system, both at component level and at system level, regardless of whether the specifications come from regulation and reliability concerns.",included,1777,0.8573559522628784
10.1080/14606925.2019.1594979,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),core,core,2019-04-01 01:00:00,core,"forget the singularity, its mundane artificial intelligence that should be our immediate concern",https://core.ac.uk/download/196591310.pdf,"Fuelled by Science Fiction and the pronouncements of Silicon Valley gurus such as Elon Musk, the ‘Singularity’ is arguably the biggest geek myth of our time and is distracting us from addressing the numerous problems emerging with the increasing use of Artificial intelligence (AI). Artificial General Intelligence (AGI) is often perceived to mean super human like intelligence such as the ones depicted in movies like Her (2013) and Ex Machina (2014). These anthropomorphic representations of AI besiege our attention away from the very real threat of biases introduced through Machine Learning (ML). In this paper we will consider whether current practices within Human-Centred Design (HCD) permit designers to consider interactions and services in which non-human algorithms play a significant role and consider how approaches inspired by Object Oriented Ontology (OOO) may offer newperspectives for framing design activities concerning AI",included,3237,0.8563174605369568
10.1109/syscon48628.2021.9447069,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2021 IEEE International Systems Conference (SysCon),IEEE,2021-05-15 00:00:00,ieeexplore,design strategies for integrating artificial intelligence into systems engineering environment,https://ieeexplore.ieee.org/document/9447069/,"The use of artificial intelligence capabilities for developing airborne safety-critical systems has been troublesome to the aerospace industry. This technology inserts new sources of non-determinism on process execution, increasing difficulty to ensure safety requirements. In this work, we evaluate the artificial intelligence capabilities for improving systems engineering methodology. From this analysis, we present design strategies to support the tool qualification process. The design strategies are a sound basis for applying artificial intelligence into the tools employed during the whole airborne systems life cycle.",included,1745,0.8561747670173645
10.1109/apsecw53869.2021.00015,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2021 28th Asia-Pacific Software Engineering Conference Workshops (APSEC Workshops),2021-01-01 00:00:00,semantic_scholar,qunomon: a fair testbed of quality evaluation for machine learning models,https://www.semanticscholar.org/paper/2189acddf4c94524644b20aae114bac22706ec60,"Rapid development of artificial intelligence (AI) technologies brings quality and reliability issues to real-world applications and business products, as well as their advanced performance. However, traditional testing methods of the quality of engineering systems have difficulties supporting AI systems with machine learning (ML) based on large-scale data due to their uncertainty, non-deterministic, and vulnerability. Academic fields have studied new techniques to manage and guarantee high-quality ML components in AI systems with the importance of realizing trustworthy AI. Moreover, regulatory authorities have developed new guidelines and rules for safe and broad market adoption to control quality. Although there is a lot of effort from both sides, ML quality control and assessment pose challenges that arise from gaps between their different points of view. This paper proposes a new testbed called “Qunomon (QUality + gNOMON)” that harmonizes gaps of two sides and supports the combination and comparison of various testing methods in ML component quality. The testbed is designed to improve the findability, accessibility, interoperability, and reusability of testing methods. Furthermore, we show the efficiency of quality testing and reporting with case studies where our testbed is applied.",not included,1063,0.8552283644676208
10.18034/abcjar.v7i2.695,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,ABC Journal of Advanced Research,2018-01-01 00:00:00,semantic_scholar,exploiting the potential of artificial intelligence in decision support systems,https://www.semanticscholar.org/paper/5f6ddb79ee92b983c090ed5b51160e785067044e,"For several years now, the concept of AI being able to quickly and extensively replace expert workers at massive scales has been on the cusp of becoming a reality. Although AI has shown to be an effective tool for many activities, humans still have a significant advantage in many other areas. Companies are becoming more conscious of this fact. As a result, they are restructuring their business processes to provide their experts and customers with AI support in a more targeted manner. This study aims to present a high-quality review that covers unique, cutting-edge technologies and methodologies connected with the scientific design, development, and implementation of AI-DSS employing the most recent developments in AI and multi-criteria decision-making. The review will be presented in the form of a report. This article examines whether or not the growth of so-called artificial intelligence-driven decision support systems, also known as AI-DSS, threatens decision-making processes and, if so, how that threat manifests itself.  
  
Keywords: , , , ",not included,99,0.855110228061676
10.1017/s0890060421000093,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,"Artificial intelligence for engineering design, analysis and manufacturing",2021-01-01 00:00:00,semantic_scholar,smart designing of smart systems,https://www.semanticscholar.org/paper/63399f2ac541952efc6c4cc1a204a9714e9551c1,"We live in an age when previously disjunctive concepts, theories, methodologies, technologies, implementations, applications, and cultures are coming together. This does not mean a reductionist integration but a holistic synthesis of the abovementioned things. This widespread phenomenon is often referred to as convergence, which may happen in multiple forms across multiple domains. Examples include forming a transdisciplinary scientific discipline, amalgamating hardware, software, and cyberware in complex systems, interplaying social demands and technological affordances, and merging massive data, information, and knowledge. Convergence influences not only physical but also cognitive processes. Fueled by the results of artificial narrow and general intelligence, the physical, perceptive, and cognitive capabilities of humans and intellectualized engineering systems are also converging. This rapidly proliferating trend of convergence provided theoretical underpinning for this thematic collection and explains its practical relevance. In this case, convergence concerns the approaches and methods of smart designing and the development of smart systems, and is facilitated by various manifestations of artificial intelligence (AI) enablers. There were two sources of papers that contributed to this thematic collection. First, several papers were based on the best papers of the Thirteens International Symposium on Tools and Methods of Competitive Engineering (TMCE 2020). The selected papers were reworked and extended with additional research results and findings. The other papers were contributed based on the Call for Papers proposed by the guest editors. All papers were critically reviewed and revised by the authors before their acceptance for publication. The papers included in this thematic collection cover critical specific aspects of smart design, smart systems, and smart designing of smart systems. Altogether eight papers are included, which offer novel theories, methods, working principles, system functions, and smartness enablers. They reflect a reasonable coherence and complement each other. The first paper, entitled Connectors of smart design and smart systems, is a position paper that discusses the backgrounds and proposes an interpretation of the concepts of smart designing and smart systems, respectively. Contributed by Imre Horváth, this paper also proposes a reasoning model concerning the relationship between smart designing and smart systems. It is argued that the progression toward smart designing and smart systems has been triggered and enabled by the recent advances in AI research and development. The author provides an interpretation of the concept of smartness and an overview of the characteristics of smart design as an AI-supported creative problem-solving methodology. The paradigmatic features and system engineering issues of smart systems are also discussed. The genuine contribution of this position paper is a conceptual model of AI-based couplings of smart designing and smart systems, referred to as “connectors.” Examples of the principal types of connectors are given. It is shown that smart design tends to manifest as an approach of blueprinting smart systems, whereas smart systems are used as intellectualized enablers of the implementation of smart design. The identified primary connectors, as AI-based enablers, hint at forms and methods how smart designing may be associated with smart systems in practice. In the second paper entitled Smart design of intelligent companion toys for preschool children, Xin Wang, Nian Yin, and Zhinan Zhang put forward a complete process to smartly design and update the smart companion toys for children, which is user-centered and environment-oriented. As a smart system, the smart companion toy takes children’s cognition and emotion as the core consideration to provide a more natural and exciting interactive experience. Simultaneously, it coordinates the development of children’s multiple senses at every stage. The entire design process is divided into three main parts, which are requirement confirmation, collaborative design, and iterative updates after the sale. Requirement confirmation is completed via demand collection, authenticity, and prioritizing. Before sale, the design process can be divided into input, analysis, function, output, user interface, evaluation, and testing, all of which are collaboratively completed by humans and AI. After being put into use, the smart iterative update process is completed through interaction with users and the environment with local processors and the company cloud. Under the framework proposed in the first paper, the companion system’s smartness is demonstrated through the smart, collaborative design process enabled by “connectors” such as graphics-based modeling, simulation, optimization, and user behavior mining.",not included,1008,0.8549078702926636
http://arxiv.org/abs/2403.14697v1,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),arxiv,arxiv,2024-03-15 00:00:00,arxiv,"an aic-based approach for articulating unpredictable problems in open
  complex environments",http://arxiv.org/abs/2403.14697v1,"This research paper presents an approach to enhancing the predictive
capability of architects in the design and assurance of systems, focusing on
systems operating in dynamic and unpredictable environments. By adopting a
systems approach, we aim to improve architects' predictive capabilities in
designing dependable systems (for example, ML-based systems). An aerospace case
study is used to illustrate the approach. Multiple factors (challenges)
influencing aircraft detection are identified, demonstrating the effectiveness
of our approach in a complex operational setting. Our approach primarily aimed
to enhance the architect's predictive capability.",not included,2,0.8544579744338989
10.1109/tem.2023.3268340,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),SCOPUS_ID:85159803879,scopus,2023-01-01 00:00:00,scopus,ai in the context of complex intelligent systems: engineering management consequences,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85159803879&origin=inward,"
AbstractView references

As artificial intelligence (AI) is increasingly integrated into the context of complex products and systems (CoPS), making complex systems more intelligent, this article explores the consequences and implications for engineering management in emerging complex intelligent systems (CoIS). Based on five engineering management aspects, including design objectives, system boundaries, architecting and modeling, predictability and emergence, and learning and adaptation, a case study representing future CoIS illustrates how these five aspects, as well as their relationship to criticality and generativity, emerge as AI becomes an integrated part of the system. The findings imply that a future combined perspective on allowing generativity and maintaining or enhancing criticality is necessary, and notably, the results suggest that the understanding of system integrators and CoPS management partly fundamentally alters and partly is complemented with the emergence of CoIS. CoIS puts learning and adaptation characteristics in the foreground, i.e., CoIS are associated with increasingly generative design objectives, fluid system boundaries, new architecting and modeling approaches, and challenges predictability. The notion of bounded generativity is suggested to emphasize the combination of generativity and criticality as a direction for transforming engineering management in CoPS contexts and demands new approaches for designing future CoIS and safeguard its important societal functions. Author
",included,2447,0.8543676137924194
10.1007/978-1-4842-9502-1_8,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),AI Startup Strategy,Springer,2023-01-01 00:00:00,springer,building an ai platform,http://dx.doi.org/10.1007/978-1-4842-9502-1_8,"As an AI startup, it is essential to have a clear strategy for designing, developing, and operating an AI platform that can meet market demands. In the previous chapters, we learned about validating AI products from various perspectives. This chapter will explore the details of building a successful AI platform that involves designing, developing, and operating the AI system. Building an AI platform is a complex process that requires careful consideration of many factors. We will explore the importance of the three pillars of AI platform design: system design, process design, and team design. We will provide a comprehensive framework that unifies these pillars into a single approach to building an effective AI platform. Measuring the maturity of an AI platform is also an essential aspect of the building process. We will discuss how to assess the platform at different stages, from initial development to optimized operation. This chapter will also discuss the challenges and best practices of building an AI platform. We will explore common issues and provide practical solutions to ensure success. To illustrate how the framework and best practices discussed in this chapter can be applied in practice, we will provide a case study of designing, developing, and operating an eKYC AI as a Service platform. This case study will provide real-world examples of the key considerations and decisions in building an effective AI platform. By the end of this chapter, you will have a comprehensive understanding of what it takes to build a successful AI platform and the steps involved in designing, developing, and operating such a system.",included,1617,0.8540821075439453
10.3233/aic-201523,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,AI Communications,2021-01-01 00:00:00,semantic_scholar,an interdisciplinary conceptual study of artificial intelligence (ai) for helping benefit-risk assessment practices: towards a comprehensive qualification matrix of ai programs and devices (pre-print 2020),https://www.semanticscholar.org/paper/a39e88db75509ae36ffa66249107b53a48c39f86,"This paper proposes a comprehensive analysis of existing concepts coming from different disciplines tackling the notion of intelligence, namely psychology and engineering, and from disciplines aiming to regulate AI innovations, namely AI ethics and law. The aim is to identify shared notions or discrepancies to consider for qualifying AI systems. Relevant concepts are integrated into a matrix intended to help defining more precisely when and how computing tools (programs or devices) may be qualified as AI while highlighting critical features to serve a specific technical, ethical and legal assessment of challenges in AI development. Some adaptations of existing notions of AI characteristics are proposed. The matrix is a risk-based conceptual model designed to allow an empirical, flexible and scalable qualification of AI technologies in the perspective of benefit-risk assessment practices, technological monitoring and regulatory compliance: it offers a structured reflection tool for stakeholders in AI development that are engaged in responsible research and innovation.Pre-print version (achieved on May 2020)",included,959,0.8538931012153625
10.48550/arxiv.2205.04358,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,arXiv.org,2022-01-01 00:00:00,semantic_scholar,towards operationalising responsible ai: an empirical study,https://www.semanticscholar.org/paper/f91eb7ab0d96b91cc892efc841effd3ef985dcd3,"—While artiﬁcial intelligence (AI) has great poten- tial to transform many industries, there are concerns about its ability to make decisions in a responsible way. Many AI ethics guidelines and principles have been recently proposed by governments and various organisations, covering areas such as privacy, accountability, safety, reliability, transparency, explainability, contestability, and fairness. However, such principles are typically high-level and do not provide tangible guidance on how to design and develop responsible AI systems. To address this shortcoming, we present an empirical study involving interviews with 21 scientists and engineers, designed to gain insight into practitioners’ perceptions of AI ethics principles, their possible implementation, and the trade-offs between the principles. The salient ﬁndings cover four aspects of AI system development: (i) overall development process, (ii) requirements engineering, (iii) design and implementation, (iv) deployment and operation.",not included,1203,0.8535141944885254
http://arxiv.org/abs/2203.15628v1,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),arxiv,arxiv,2022-03-29 00:00:00,arxiv,"exploring opportunities in usable hazard analysis processes for ai
  engineering",http://arxiv.org/abs/2203.15628v1,"Embedding artificial intelligence into systems introduces significant
challenges to modern engineering practices. Hazard analysis tools and processes
have not yet been adequately adapted to the new paradigm. This paper describes
initial research and findings regarding current practices in AI-related hazard
analysis and on the tools used to conduct this work. Our goal with this initial
research is to better understand the needs of practitioners and the emerging
challenges of considering hazards and risks for AI-enabled products and
services. Our primary research question is: Can we develop new structured
thinking methods and systems engineering tools to support effective and
engaging ways for preemptively considering failure modes in AI systems? The
preliminary findings from our review of the literature and interviews with
practitioners highlight various challenges around integrating hazard analysis
into modern AI development processes and suggest opportunities for exploration
of usable, human-centered hazard analysis tools.",included,40,0.8534960746765137
10.1109/cesser-ip.2019.00008,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2019 IEEE/ACM Joint 7th International Workshop on Conducting Empirical Studies in Industry (CESI) and 6th International Workshop on Software Engineering Research and Industrial Practice (SER&IP),IEEE,2019-05-28 00:00:00,ieeexplore,best practices for engineering ai-infused applications: lessons learned from microsoft teams,https://ieeexplore.ieee.org/document/8836177/,"Artificial intelligence and machine learning (AI/ML) are some of the newest trends to hit the software industry, compelling organizations to evolve their development processes to deliver novel products to their customers. In this talk, I describe a study in which we learned how Microsoft software teams develop AI/ML-based applications using a nine-stage AI workflow process informed by prior experiences developing early AI applications (e.g. search and NLP) and data science tools (e.g. application telemetry and bug reporting). Adapting this workflow into their pre-existing, well-evolved, Agile-like software engineering processes and job roles has resulted in a number of engineering challenges unique to the AI/ML domain, some universal to all teams, but others related to the amount of prior AI/ML experience and education the teams have. I tell you about some challenges and the solutions that teams have come up with. The lessons that Microsoft has learned can help other organizations embarking on their own path towards AI and ML.",included,1873,0.8530495762825012
10.23919/date51398.2021.9473980,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),"2021 Design, Automation & Test in Europe Conference & Exhibition (DATE)",IEEE,2021-02-05 00:00:00,ieeexplore,systems engineering roadmap for dependable autonomous cyber-physical systems,https://ieeexplore.ieee.org/document/9473980/,"Autonomous cyber-physical systems have enormous potential to make our lives more sustainable, more comfortable, and more economical. Artificial Intelligence and connectivity enable autonomous behavior, but often stand in the way of market launch. Traditional engineering techniques are no longer sufficient to achieve the desired dependability; current legal and normative regulations are inappropriate or insufficient. This paper discusses these issues, proposes advanced systems engineering to overcome these issues, and provides a roadmap by structuring fields of action.",not included,1759,0.8529434204101562
10.1109/rew.2019.00043,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2019 IEEE 27th International Requirements Engineering Conference Workshops (REW),2019-01-01 00:00:00,semantic_scholar,the 6th international workshop on artificial intelligence for requirements engineering (aire'19),https://www.semanticscholar.org/paper/4a43dbc8e6586a650c05b0fd68872846b066e6a6,Welcome to the 6th edition of the International Workshop on Artificial Intelligence for Requirements Engineering (AIRE'19). This interdisciplinary workshop is intended to explore and extend the synergies between Artificial Intelligence and Requirements Engineering. The AIRE workshop's aim is to: (i) study Requirements Engineering (RE) areas that may benefit from the application of AI techniques; and (ii) investigate how RE can be conducted for AI-based systems. The workshop is an established venue for inspiring a broad community to engage in interdisciplinary discussions concerning novel research directions for Requirements Engineering and Artificial Intelligence.,not included,709,0.8525999784469604
10.1109/re51729.2021.00008,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE International Requirements Engineering Conference,2021-01-01 00:00:00,semantic_scholar,what’s up with requirements engineering for artificial intelligence systems?,https://www.semanticscholar.org/paper/0433639e31918b3f90d866eb61293b0e8760c3ff,"In traditional approaches to building software systems (that do not include an Artificial Intelligent (AI) or Machine Learning (ML) component), Requirements Engineering (RE) activities are well-established and researched. However, building software systems with one or more AI components may depend heavily on data with limited or no insight into the system’s workings. Therefore, engineering such systems poses significant new challenges to RE. Our search showed that literature has focused on using AI to manage RE activities, with limited research on RE for AI (RE4AI). Our study’s main objective was to investigate current approaches in writing requirements for AI/ML systems, identify available tools and techniques used to model requirements, and find existing challenges and limitations. We performed a Systematic Literature Review (SLR) of current RE4AI methods and identified 27 primary studies. Using these studies, we analysed the key tools and techniques used to specify and model requirements and found several challenges and limitations of existing RE4AI practices. We further provide recommendations for future research, based on our analysis of the primary studies and mapping to industry guidelines in Google PAIR). The SLR findings highlighted that present RE applications were not adaptive to manage most AI/ML systems and emphasised the need to provide new techniques and tools to support RE4AI.",included,923,0.852554202079773
10.18034/ajtp.v5i3.669,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,American Journal of Trade and Policy,2018-01-01 00:00:00,semantic_scholar,business insights of artificial intelligence and the future of humans,https://www.semanticscholar.org/paper/326cbe50284826ed01569c1fd4137bb44e67394d,"Recent technological advancements and the increasing pace of adopting artificial intelligence (AI) technologies constitute a need to identify and analyze the issues regarding their implementation in the education sector. This is because the education sector is associated with highly dynamic business environments controlled and maintained by information systems. In addition, the education sector is a sector that is associated with information systems. On the other hand, it was discovered through an analysis of the current research that a moderate amount of investigation has been conducted in this field. We have highlighted the benefits and obstacles of adopting artificial intelligence in the education sector to fill this hole. Before this, a brief discussion was presented on the fundamental ideas of AI and its development over time. In addition, we have evaluated the usefulness of contemporary AI technologies for students and teachers, which are currently on the software market. These technologies are currently available. We have built a strategy implementation model, outlined by a standard five-step method and the corresponding configuration guide. This is the very last thing that we have done. To check and ensure the accuracy of their design, we independently devised three implementation plans for three distinct institutions of higher education. The results acquired will contribute to a more profound knowledge of the particulars of AI systems, services, and tools, which will, in turn, pave the way for implementing these things more efficiently.",not included,126,0.852178692817688
10.1109/spicscon54707.2021.9885722,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),"2021 IEEE International Conference on Signal Processing, Information, Communication & Systems (SPICSCON)",IEEE,2021-12-04 00:00:00,ieeexplore,a framework of metaverse for systems engineering,https://ieeexplore.ieee.org/document/9885722/,"Recently the Metaverse has received enormous attention around the world. The advanced metaverse will be a more realistic environment with greater specific and subtle interconnections, with less race, gender, and even physical impairment, all of which would be immensely helpful to society. However, metaverse is still in its infancy, with a lot of room for improvement. The industry has already begun to prepare for the metaverse’s enormous potential, supported by frenzied investment, yet there are few talks on metaverse in academia to scientifically lead its growth. In this paper, we present a metaverse design that adopts a global approach to technology, communication, and the environment. We propose an AI-driven metaverse model that might be deployed to realize the promise of model-based systems engineering in the near future. Finally, we offer research questions that should be taken up by academia to further the metaverse.",included,1736,0.8510017395019531
http://arxiv.org/abs/1702.07193v1,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),arxiv,arxiv,2017-02-23 00:00:00,arxiv,ontologies in system engineering: a field report,http://arxiv.org/abs/1702.07193v1,"In recent years ontologies enjoyed a growing popularity outside specialized
AI communities. System engineering is no exception to this trend, with
ontologies being proposed as a basis for several tasks in complex industrial
implements, including system design, monitoring and diagnosis. In this paper,
we consider four different contributions to system engineering wherein
ontologies are instrumental to provide enhancements over traditional ad-hoc
techniques. For each application, we briefly report the methodologies, the
tools and the results obtained with the goal to provide an assessment of merits
and limits of ontologies in such domains.",not included,80,0.8497790098190308
10.1109/sose52839.2021.00025,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Symposium on Service Oriented Software Engineering,2021-01-01 00:00:00,semantic_scholar,"a vision for composing, integrating, and deploying ai planning functionalities",https://www.semanticscholar.org/paper/54abdfcefd2ca6b17e826b0fb7949c93a63469d4,"AI planning deals with automatically selecting and organising actions to achieve some user objective. The field offers planning tools not only to solve planning problems but also to address other planning aspects, such as modeling problems and validating found solutions. Despite the need for a fully-fledged planning functionality in real-world applications, however, no tool exists supporting all aspects. As a result, there is a need to manually combine several planning tools that are heterogeneous in terms of software, design, and configuration requirements. While the manual process of combining, integrating and, finally, deploying these systems is time-consuming and error-prone, it also demands immense planning and technical expertise from the practitioners. In this paper, we introduce a vision for composing, integrating, and deploying AI planning functionalities contemplated given several prerequisites for the design of planning services. The objective is to enable straightforward composition and integration of various modular planning services provided by different tools into advanced AI planning systems by intuitive modelling and automatic deployment. Our vision can lead to new research and development opportunities in both AI planning and system engineering, ultimately contributing to the industrialisation of AI.",not included,949,0.8496817350387573
10.1145/3522664.3528598,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2022 IEEE/ACM 1st International Conference on AI Engineering – Software Engineering for AI (CAIN),2022-01-01 00:00:00,semantic_scholar,ai governance in the system development life cycle: insights on responsible machine learning engineering,https://www.semanticscholar.org/paper/bfa3cb3fae2d4fcc66b18dba752467f4f5861073,"In this study we explore the incorporation of artificial intelligence (AI) governance to system development life cycle (SDLC) models. We conducted expert interviews among AI and SDLC professionals and analyzed the interview data using qualitative coding and clustering to extract AI governance concepts. Subsequently, we mapped these concepts onto three stages in the machine learning (ML) system development process: (1) design, (2) development, and (3) operation. We discovered 20 governance concepts, some of which are relevant to more than one of the three stages. Our analysis highlights AI governance as a complex process that involves multiple activities and stakeholders. As development projects are unique, the governance requirements and processes also vary. This study is a step towards understanding how AI governance is conceptually connected to ML systems’ management processes through the project life cycle. CCS CONCEPTS • Software and its engineering $^{\rightarrow}$ Software creation and management.",included,1138,0.8494580388069153
10.1002/iis2.12988,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,INCOSE International Symposium,2022-01-01 00:00:00,semantic_scholar,artificial intelligence capabilities for effective model‐based systems engineering: a vision paper,https://www.semanticscholar.org/paper/b964424f02da2e6ef879c96d33dfcae103630e14,"Both Model‐Based Systems Engineering (MBSE) and Artificial Intelligence (AI) have been challenged for their deployment in real‐world applications. Although MBSE remains the focal point of any systems engineering activities, its adoption still faces significant hurdles to demonstrate its return on investment. Recently, AI has received intensive attention, and its applications made their way into our daily life products. From an industrial perspective, within the context of the design and development of mechatronic systems, there is a lack of coherent foundation to enable the application of AI in MBSE. This vision paper discusses the role of AI in solving a set of MBSE challenges. As a result, we contribute by describing the actual MBSE adoption challenges and follow up with the characterization of the capabilities of AI in solving these challenges. With this initial work, we aim to trigger both AI and MBSE communities for further research discussions and industrial applications to help in achieving an intelligent design and development environment.",not included,1118,0.8473312854766846
10.4230/dagrep.10.2.76,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Dagstuhl Reports,2020-01-01 00:00:00,semantic_scholar,se4ml - software engineering for ai-ml-based systems (dagstuhl seminar 20091),https://www.semanticscholar.org/paper/a979947809dd146c81a11625a8eedd52536bacfc,"Multiple research disciplines, from cognitive sciences to biology, finance, physics, and the social sciences, as well as many companies, believe that data-driven and intelligent solutions are necessary. Unfortunately, current artificial intelligence (AI) and machine learning (ML) technologies are not sufficiently democratized - building complex AI and ML systems requires deep expertise in computer science and extensive programming skills to work with various machine reasoning and learning techniques at a rather low level of abstraction. It also requires extensive trial and error exploration for model selection, data cleaning, feature selection, and parameter tuning. Moreover, there is a lack of theoretical understanding that could be used to abstract away these subtleties. Conventional programming languages and software engineering paradigms have also not been designed to address challenges faced by AI and ML practitioners. In 2016, companies invested $26–39 billion in AI and McKinsey predicts that investments will be growing over the next few years. Any AI/ML-based systems will need to be built, tested, and maintained, yet there is a lack of established engineering practices in industry for such systems because they are fundamentally different from traditional software systems. 
This Dagstuhl Seminar brought together two rather disjoint communities together, software engineering and programming languages (PL/SE) and artificial intelligence and machine learning (AI-ML) to discuss open problems on how to improve the productivity of data scientists, software engineers, and AI-ML practitioners in industry.",not included,768,0.8467990756034851
10.1109/icse-seip55303.2022.9793864,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2022 IEEE/ACM 44th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP),2021-01-01 00:00:00,semantic_scholar,software engineering for responsible ai: an empirical study and operationalised patterns,https://www.semanticscholar.org/paper/6a03b02e61b447ce1456624853d7accfd24a2711,"AI ethics principles and guidelines are typically high-level and do not provide concrete guidance on how to develop responsible AI systems. To address this shortcoming, we perform an empirical study involving interviews with 21 scientists and engineers to understand the practitioners' views on AI ethics principles and their implementation. Our major findings are: (1) the current practice is often a done-once-and-forget type of ethical risk assessment at a particular development step, which is not sufficient for highly uncertain and continual learning AI systems; (2) ethical requirements are either omitted or mostly stated as high-level objectives, and not specified explicitly in verifiable way as system outputs or outcomes; (3) although ethical requirements have the characteristics of cross-cutting quality and non-functional requirements amenable to architecture and design analysis, system-level architecture and design are under-explored; (4) there is a strong desire for continuously monitoring and validating AI systems post deployment for ethical requirements but current operation practices provide limited guidance. To address these findings, we suggest a preliminary list of patterns to provide operationalised guidance for developing responsible AI systems.",included,917,0.8452555537223816
10.1002/j.2371-9621.2021.tb00015.x,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,The AI Magazine,2021-01-01 00:00:00,semantic_scholar,advances in theory and applications of artificial intelligence,https://www.semanticscholar.org/paper/29417f1e3578c914cb73c53f24404671acb81e98,"Copyright © 2021, Association for the Advancement of Artificial Intelligence. All rights reserved. ISSN 0738-4602 86 AI MAGAZINE This year, the 33rd meeting of the International Conference on Industrial, Engineering, and Other Applications of Applied Intelligent Systems 20201 was held in Kitakyushu, Japan from 22 to 25 September 2020. The International Conference on Industrial, Engineering, and Other Applications of Applied Intelligent Systems focuses on artificial intelligence (AI) and its applications. This long-standing conference has been held every year since 1988. To date, the conference has been located in twenty different countries. The 2020 conference was sponsored by the International Society of Applied Intelligence and was held in cooperation with Springer; Kitakyushu City; the KDDI Foundation; the Association for the Advancement of Artificial Intelligence; the Association for Computing Machinery; the Austrian Association for Artificial Intelligence; the Institute of Electrical and Electronics Engineers; the Catalan Association for Artificial Intelligence; the Graz University of Technology; the Italian Artificial Intelligence Association; Iwate Prefectural University, Japan; the Japanese Society for Artificial Intelligence; the Lithuanian Computer Society; the Spanish Society for Artificial Intelligence; the Society for the Study of AI and the Simulation of Behavior; the Taiwanese Association for Consumer Electronics; the Taiwanese Association for Artificial Intelligence; Texas State University; and the University of Klagenfurt. This year, one-hundred and nineteen papers were submitted to the conference. The papers were submitted either to the main track or to one of special sessions: Collective Intelligence in Social Media and Intelligent Knowledge Engineering in Decision-Making Systems. An international program committee composed of eighty-two researchers from thirtysix countries evaluated each paper during a three-review double-blind peer review process. Sixty-two full papers and seventeen short papers were selected for publication in the conference proceedings, which were published in Springer’s Lectures Notes in Artificial Intelligence series.2 Nine additional papers were selected as poster papers and published in a separate proceeding.  The 33rd International Conference on Industrial, Engineering, and Other Applications of Applied Intelligent Systems was held in Kitakyushu, Japan on 22 to 25 September 2020. This report provides an overview and summary of the conference. Advances in Theory and Applications of Artificial Intelligence",not included,1064,0.8448173999786377
http://arxiv.org/abs/2401.03223v2,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),arxiv,arxiv,2024-01-06 00:00:00,arxiv,"an intelligent sociotechnical systems (ists) framework: toward a
  sociotechnically-based hierarchical human-centered ai approach",http://arxiv.org/abs/2401.03223v2,"Insights: - The human-centered AI (HCAI) approach and the sociotechnical
systems (STS) theory share the same goal: ensuring that new technologies such
as AI best serve humans in a sociotechnical environment. - HCAI practice needs
to fully embrace sociotechnical systems thinking, while traditional STS needs
to evolve to address the emerging characteristics of AI technology. - We
propose a conceptual framework for intelligent sociotechnical systems (iSTS) to
enhance traditional STS theory in the AI era. - Based on iSTS, we further
propose a sociotechnical-based hierarchical HCAI approach as a paradigmatic
extension to existing HCAI practice, further advancing HCAI practice.",included,9,0.844709575176239
10.1007/s43681-023-00276-7,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),AI and Ethics,Springer,2023-03-27 00:00:00,springer,the rapid competitive economy of machine learning development: a discussion on the social risks and benefits,http://dx.doi.org/10.1007/s43681-023-00276-7,"Research in artificial intelligence (AI) has started in the twentieth century but it was not until 2012 that modern models of artificial neural networks aided the machine learning process considerably so that in the past ten years, both computer vision as well as natural language processing have become increasingly better. AI developments have accelerated rapidly, leaving open questions about the potential benefits and risks of these dynamics and how the latter might be managed. This paper discusses three major risks, all lying in the domain of AI safety engineering: the problem of AI alignment, the problem of AI abuse, and the problem of information control. The discussion goes through a short history of AI development, briefly touching on the benefits and risks, and eventually making the case that the risks might potentially be mitigated through strong collaborations and awareness concerning trustworthy AI. Implications for the (digital) humanities are discussed.",not included,1606,0.8446024656295776
10.1109/sysose.2019.8753852,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2019 14th Annual Conference System of Systems Engineering (SoSE),IEEE,2019-05-22 00:00:00,ieeexplore,experiences in evolving system-of-systems engineering methodology to address pain points,https://ieeexplore.ieee.org/document/8753852/,"The growing interest in System-of-Systems has resulted in rapid and widespread application of its concepts to a variety of problems. While this generated a large number of novel and valuable techniques, tools, and methodologies in System-of-Systems Engineering, it also broadened the problem domains, and subsequently made it difficult to achieve a high degree of coordination and cohesion in the discipline. Previous attempts at creating a formal structure to System-of-Systems Engineering provided valuable support to practitioners, but have been sometimes disconnected from the current practical needs in the discipline, leaving behind some pain points that still need to be addressed. In this work, we propose a different perspective to deal with the pain points: based on our experience and on analysis of the current challenges of System-of-Systems Engineering, we identify potential research directions which are based on domain-agnostic methodology, but of interest to a variety of problems in System-of-Systems. This dual feature of the research directions is explored here to identify a connection between the necessity of establishing formal and generic procedures for System-of-Systems Engineering along with the usability and utility of practical tools and techniques for applied problems.",not included,1747,0.8444346189498901
10.1109/emr.2023.3284708,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),SCOPUS_ID:85165915950,scopus,2023-01-01 00:00:00,scopus,artificial intelligence in engineering management - an editor's perspective (2023),https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85165915950&origin=inward,"
AbstractView references

Today, we live in a world determined by multiple crises creating less certainty about the future and its prediction. At the same time, new Artificial Intelligence (AI) technologies are developed at high pace that may lead to a new revolution in how we do business and manage companies. Generative AI tools offer exciting opportunities while at the same time putting to question some well-established solutions. This calls for more and extensive insights in research and practice to tackle the question how these technologies can be used for engineering management. © 1973-2011 IEEE.
",not included,2412,0.8440803289413452
10.1007/s43681-022-00206-z,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),AI and Ethics,Springer,2023-08-01 00:00:00,springer,needs and artificial intelligence,http://dx.doi.org/10.1007/s43681-022-00206-z,"Throughout our history, we, Homo sapiens, have used technologies to better satisfy our needs . The relation between needs and technology is so fundamental that the US National Research Council defines the distinguishing characteristic of technology as its goal “to make modifications in the world [in order] to meet human needs” [ 1 ]. Artificial intelligence (AI) is one of the most promising emerging technologies of our time. Similar to other technologies, AI is expected by many “to meet [human] needs”. In this article, we reflect on the relationship between needs and AI, and call for the realization of needs-aware AI systems. We argue that re-thinking needs for , through , by , and with AI can be a very useful means towards the development of realistic approaches for sustainable H uman-aware, A ccountable, L awful, and E thical (HALE) AI systems. We discuss some of the most critical gaps, barriers, enablers, and drivers of co-creating future AI-based sociotechnical systems in which [human] needs are well considered and met. Finally, we provide an overview of potential challenges and considerations that should be carefully taken into account; and call for joint, immediate, and interdisciplinary efforts and collaborations to start on the path to needs-aware AI.",not included,1595,0.8438124060630798
10.1145/3437479.3437485,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,ACM SIGSOFT Softw. Eng. Notes,2021-01-01 00:00:00,semantic_scholar,the 8th international workshop on realizing artificial intelligence synergies in software engineering,https://www.semanticscholar.org/paper/a1c0693ee6ff7874ade2b4998692049744e06d50,"The International Workshop on Realizing Arti cial Intelligence Synergies in Software Engineering (RAISE) aims to present the state of the art in the crossover between Software Engineering and Arti cial Intelligence. This workshop explored not only the appli- cation of AI techniques to SE problems but also the application of SE techniques to AI problems. Software has become critical for realizing functions central to our society. For example, software is essential for nancial and transport systems, energy generation and distribution systems, and safety-critical medical applications. Software development costs trillions of dollars each year yet, still, many of our software engineering methods remain mostly man- ual. If we can improve software production by smarter AI-based methods, even by small margins, then this would improve a crit- ical component of the international infrastructure, while freeing up tens of billions of dollars for other tasks.",not included,993,0.8436208367347717
10.1109/sysose.2018.8428714,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2018 13th Annual Conference on System of Systems Engineering (SoSE),IEEE,2018-06-22 00:00:00,ieeexplore,sose 2018 [front cover],https://ieeexplore.ieee.org/document/8428714/,The following topics are dealt with: systems engineering; software architecture; systems analysis; Internet of Things; health care; security of data; formal specification; mobile robots; decision making; learning (artificial intelligence).,not included,1818,0.8433235883712769
10.1007/978-3-031-34560-9_2,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),Advanced Information Systems Engineering,Springer,2023-01-01 00:00:00,springer,can information system engineering make cyber-human systems smarter?,http://dx.doi.org/10.1007/978-3-031-34560-9_2,"The term smart is often used carelessly in relation to systems, devices, and other entities such as cities that capture or otherwise process or use information. This exploratory paper takes the idea of smartness seriously as a way to reveal basic issues related to IS engineering and its possibilities and limitations. This paper defines work system, cyber-human system, digital agent, smartness of systems and devices, and IS engineering. It links those ideas to IS engineering challenges related to cyber-human systems. Those challenges call for applying ideas that are not applied often in IS engineering, such as facets of work, roles and responsibilities of digital agents, patterns of interaction between people and digital agents, knowledge objects, and a range of criteria for evaluating cyber-human systems and digital agents. In combination, those ideas point to new possibilities for expanding IS engineering to reflect emerging challenges related to making cyber-human systems smarter.",not included,1642,0.8418298363685608
10.1109/syscon53536.2022.9773829,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2022 IEEE International Systems Conference (SysCon),IEEE,2022-04-28 00:00:00,ieeexplore,closed systems paradigm for intelligent systems,https://ieeexplore.ieee.org/document/9773829/,"Intelligent systems ought to be distinguished as a special type of system. While some adopt this view informally, in practice, systems engineering methods for intelligent systems are still centered around traditional systems engineering notions of engineering by aggregation of components. We posit that this traditional approach follows from holding a notion of open systems as the fundamental precept, and that engineering intelligent systems, in contrast, requires an approach that holds notions of closed systems as fundamental precepts. We take a systems theoretic approach to defining closed system phenomena and their relation to engineering intelligence. We propose the concept of variety; particularly the law of requisite variety to enable closed view in engineering. We discuss how open and closed view approaches to engineering intelligent systems address variety differently, as well as the implications of this difference on engineering practice.",included,1786,0.8415651321411133
10.1109/models-c.2019.00028,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C),2019-01-01 00:00:00,semantic_scholar,preface to mde intelligence 2019: 1st workshop on artificial intelligence and model-driven engineering,https://www.semanticscholar.org/paper/054fbd019b5762e37070e3dcaa87f6797f63d6fd,"Model-driven engineering (MDE) and Artificial Intelligence (AI) are two separate fields in computer science, which can clearly benefit from cross-fertilization and collaboration. There are at least two ways in which such integrations - which we call MDE Intelligence - can manifest: (1) MDE can benefit from integrating AI concepts and ideas to increasing the power and flexibility of model-driven techniques by means of the application of AI algorithms. (2) Conversely, AI can benefit from integrating concepts and ideas from MDE—for example, using domain-specific languages and model transformations allows domain experts to directly express and manipulate their problems while providing an auditable computation pipeline. To discuss and further stimulate such integrations, the 1st edition of the Workshop on Artificial Intelligence and Model-driven Engineering (MDE Intelligence) was held on September 16, 2019 in Munich, Germany, as part of the satellite events of the IEEE/ACM 22th International Conference on Model-Driven Engineering Languages and Systems (MODELS 2019).",not included,682,0.8413366079330444
10.1115/1.4062597,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),SCOPUS_ID:85173951276,scopus,2023-12-01 00:00:00,scopus,zero-trust for the system design lifecycle,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85173951276&origin=inward,"
AbstractView references

In an age of worsening global threat landscape and accelerating uncertainty, the design and manufacture of systems must increase resilience and robustness across both the system itself and the entire systems design process. We generally trust our colleagues after initial clearance/background checks; and systems to function as intended and within operating parameters after safety engineering review, verification, validation, and/ or system qualification testing. This approach has led to increased insider threat impacts; thus, we suggest moving to the ""trust, but verify""approach embodied by the Zero-Trust paradigm. Zero-Trust is increasingly adopted for network security but has not seen wide adoption in systems design and operation. Achieving the goal of Zero-Trust throughout the systems lifecycle will help to ensure that no single bad actor-whether human or machine learning/artificial intelligence (ML/AI)-can induce failure anywhere in a system's lifecycle. Additionally, while ML/AI and their associated risks are already entrenched within the operations phase of many systems' lifecycles, ML/AI is gaining traction during the design phase. For example, generative design algorithms are increasingly popular, but there is less understanding of potential risks. Adopting the Zero-Trust philosophy helps ensure robust and resilient design, manufacture, operations, maintenance, upgrade, and disposal of systems. We outline the rewards and challenges of implementing Zero-Trust and propose the framework for Zero-Trust for the system design lifecycle. This article highlights several areas of ongoing research with focus on high priority areas where the community should focus efforts. © 2023 by ASME.
",included,2036,0.8407002687454224
10.48550/arxiv.2203.02927,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,arXiv.org,2022-01-01 00:00:00,semantic_scholar,enabling automated machine learning for model-driven ai engineering,https://www.semanticscholar.org/paper/a25338007d621df488130f3278a2a7c5f77c6676,"Developing smart software services requires both Software Engineering and Artificial Intelligence (AI) skills. AI practitioners, such as data scientists often focus on the AI side, for example, creating and training Machine Learning (ML) models given a specific use case and data. They are typically not concerned with the entire software development life-cycle, architectural decisions for the system and performance issues beyond the predictive ML models (e.g., regarding the security, privacy, throughput, scalability, availability, as well as ethical, legal and regulatory compliance). In this manuscript, we propose a novel approach to enable Model-Driven Software Engineering and Model-Driven AI Engineering. In particular, we support Automated ML, thus assisting software engineers without deep AI knowledge in developing AI-intensive systems by choosing the most appropriate ML model, algorithm and techniques with suitable hyper-parameters for the task at hand. To validate our work, we carry out a case study in the smart energy domain.",not included,1150,0.8402649164199829
10.1145/3387939.3391595,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Symposium on Software Engineering for Adaptive and Self-Managing Systems,2020-01-01 00:00:00,semantic_scholar,a hybrid approach combining control theory and ai for engineering self-adaptive systems,https://www.semanticscholar.org/paper/03454b3e323aca957b33f5644c0292935c27deba,"Control theoretical techniques have been successfully adopted as methods for self-adaptive systems design to provide formal guarantees about the effectiveness and robustness of adaptation mechanisms. However, the computational effort to obtain guarantees poses severe constraints when it comes to dynamic adaptation. In order to solve these limitations, in this paper, we propose a hybrid approach combining software engineering, control theory, and AI to design for software self-adaptation. Our solution proposes a hierarchical and dynamic system manager with performance tuning. Due to the gap between high-level requirements specification and the internal knob behavior of the managed system, a hierarchically composed components architecture seek the separation of concerns towards a dynamic solution. Therefore, a two-layered adaptive manager was designed to satisfy the software requirements with parameters optimization through regression analysis and evolutionary meta-heuristic. The optimization relies on the collection and processing of performance, effectiveness, and robustness metrics w.r.t control theoretical metrics at the offline and online stages. We evaluate our work with a prototype of the Body Sensor Network (BSN) in the healthcare domain, which is largely used as a demonstrator by the community. The BSN was implemented under the Robot Operating System (ROS) architecture, and concerns about the system dependability are taken as adaptation goals. Our results reinforce the necessity of performing well on such a safety-critical domain and contribute with substantial evidence on how hybrid approaches that combine control and AI-based techniques for engineering self-adaptive systems can provide effective adaptation.",included,766,0.8395721912384033
10.1145/3282517.3282538,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,SOEN,2019-01-01 00:00:00,semantic_scholar,designing the software systems of the future,https://www.semanticscholar.org/paper/4fd5d22c18798b7e89629626033adbb8f8ef17aa,"We report here on the Future of Software Design Workshop that was held on Jan 12-14, 2018 in Pittsburgh, PA under the sponsorship of the Carnegie Mellon University Software Engineering Institute. The software industry is awash in modern trends that involve artificial intelligence (AI), autonomy, data everywhere, etc. These trends affect the structure of softwareintensive systems and their designs. The goal of the workshop was to bring together participants from diverse backgrounds to formulate ideas for software design of future systems and related research opportunities and challenges. In this report we summarize the outcomes of the workshop",not included,708,0.8389962911605835
10.1109/compsac54236.2022.00140,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Annual International Computer Software and Applications Conference,2021-01-01 00:00:00,semantic_scholar,supporting ai engineering on the iot edge through model-driven tinyml,https://www.semanticscholar.org/paper/96dba71bb1a50b01c12b5d48cef5cc18384cd8c8,"Software engineering of network-centric Artificial Intelligence (AI) and Internet of Things (IoT) enabled Cyber-Physical Systems (CPS) and services, involves complex design and validation challenges. In this paper, we propose a novel approach, based on the model-driven software engineering paradigm, in particular the domain-specific modeling methodology. We focus on a sub-discipline of AI, namely Machine Learning (ML) and propose the delegation of data analytics and ML to the IoT edge. This way, we may increase the service quality of ML, for example, its availability and performance, regardless of the network conditions, as well as maintaining the privacy, security and sustainability. We let practitioners assign ML tasks to heterogeneous edge devices, including highly resource-constrained embedded microcontrollers with main memories in the order of Kilobytes, and energy consumption in the order of milliwatts. This is known as Tiny ML. Furthermore, we show how software models with different levels of abstraction, namely platform-independent and platform-specific models can be used in the software development process. Finally, we validate the proposed approach using a case study addressing the predictive maintenance of a hydraulics system with various networked sensors and actuators.",included,920,0.8387377858161926
10.1109/wain52551.2021.00027,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Workshop on AI Engineering - Software Engineering for AI,2021-01-01 00:00:00,semantic_scholar,towards productizing ai/ml models: an industry perspective from data scientists,https://www.semanticscholar.org/paper/04ca01245cb8dd95be4b6cef0ecd7103ac809daa,"The transition from AI/ML models to production-ready AI-based systems is a challenge for both data scientists and software engineers. In this paper, we report the results of a workshop conducted in a consulting company to understand how this transition is perceived by practitioners. Starting from the need for making AI experiments reproducible, the main themes that emerged are related to the use of the Jupyter Notebook as the primary prototyping tool, and the lack of support for software engineering best practices as well as data science specific functionalities.",not included,953,0.8385639190673828
10.1109/rew56159.2022.00033,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2022 IEEE 30th International Requirements Engineering Conference Workshops (REW),2022-01-01 00:00:00,semantic_scholar,aire 2022: 9th international workshop on artificial intelligence and requirements engineering,https://www.semanticscholar.org/paper/5389904501e17a881be4fc504d5902af65230538,"RE researchers have employed AI techniques to tackle different notions of requirements quality, have applied the techniques to different case studies and domains, and have used different metrics to assess the performance of their techniques. Given the pervasiveness of AI-based systems in our daily life, recent years have also seen an increasing need for RE techniques to support sound and structured development of AI system, with particular interest in explainability of system behaviour. The primary purpose of the AIRE workshop is to explore synergies between AI and RE in order to identify complex RE problems that could benefit from the application of AI techniques and the other way round, thus addressing RE for AI challenges. The edition of the workshop in 2022 received 6 submissions, which were independently reviewed by at least three program committee members. In the end, 5 papers were accepted. All the conflicts of interest were treated seriously and independently. The workshop takes place virtually on August 16, 2022. We hope that you enjoy the AIRE’22 workshop and its proceedings. We consider that in the days when AI is gaining prominence in our daily lives, the RE community cannot neglect the benefit that AI techniques can deliver to the practice of requirements engineering. The workshop will feature also two keynotes, from Fabiano Dalpiaz, from the University of Utrecht, the Netherlands, on Requirements Conversations: A New Frontier in AI-for-RE, and from Jennifer Horkoff, on Requirements Engineering for Machine Learning: Non-functional Requirements as Core Functions. We look forward to seeing you all at this workshop and the future editions. We are very grateful to the Program Committee members and authors of the submissions for their hard work and dedication in putting together this program. We would like to thank you all for your participation in AIRE’22.",not included,1241,0.8375562429428101
10.1609/aimag.v39i4.2823,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,The AI Magazine,2018-01-01 00:00:00,semantic_scholar,reports of the workshops of the 32nd aaai conference on artificial intelligence,https://www.semanticscholar.org/paper/179189e48cdc4f4c60d4e4e66fa0ed8a424a65c6,"The AAAI-18 workshop program included 15 workshops covering a wide range of topics in AI. Workshops were held Sunday and Monday, February 2–7, 2018, at the Hilton New Orleans Riverside in New Orleans, Louisiana, USA. This report contains summaries of the Affective Content Analysis workshop; the Artificial Intelligence Applied to Assistive Technologies and Smart Environments; the AI and Marketing Science workshop; the Artificial Intelligence for Cyber Security workshop; the AI for Imperfect-Information Games; the Declarative Learning Based Programming workshop; the Engineering Dependable and Secure Machine Learning Systems workshop; the Health Intelligence workshop; the Knowledge Extraction from Games workshop; the Plan, Activity, and Intent Recognition workshop; the Planning and Inference workshop; the Preference Handling workshop; the Reasoning and Learning for Human-Machine Dialogues workshop; and the the AI Enhanced Internet of Things Data Processing for Intelligent Applications workshop.",not included,140,0.8372226357460022
http://arxiv.org/abs/2010.07022v1,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),arxiv,arxiv,2020-10-06 00:00:00,arxiv,"towards a policy-as-a-service framework to enable compliant, trustworthy
  ai and hri systems in the wild",http://arxiv.org/abs/2010.07022v1,"Building trustworthy autonomous systems is challenging for many reasons
beyond simply trying to engineer agents that 'always do the right thing.' There
is a broader context that is often not considered within AI and HRI: that the
problem of trustworthiness is inherently socio-technical and ultimately
involves a broad set of complex human factors and multidimensional
relationships that can arise between agents, humans, organizations, and even
governments and legal institutions, each with their own understanding and
definitions of trust. This complexity presents a significant barrier to the
development of trustworthy AI and HRI systems---while systems developers may
desire to have their systems 'always do the right thing,' they generally lack
the practical tools and expertise in law, regulation, policy and ethics to
ensure this outcome. In this paper, we emphasize the ""fuzzy"" socio-technical
aspects of trustworthiness and the need for their careful consideration during
both design and deployment. We hope to contribute to the discussion of
trustworthy engineering in AI and HRI by i) describing the policy landscape
that must be considered when addressing trustworthy computing and the need for
usable trust models, ii) highlighting an opportunity for trustworthy-by-design
intervention within the systems engineering process, and iii) introducing the
concept of a ""policy-as-a-service"" (PaaS) framework that can be readily applied
by AI systems engineers to address the fuzzy problem of trust during the
development and (eventually) runtime process. We envision that the PaaS
approach, which offloads the development of policy design parameters and
maintenance of policy standards to policy experts, will enable runtime trust
capabilities intelligent systems in the wild.",not included,60,0.8362947106361389
10.1109/re.2019.00009,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE International Requirements Engineering Conference,2019-01-01 00:00:00,semantic_scholar,requirements we live by,https://www.semanticscholar.org/paper/30edf4a54ffaab72188dd95b620d589690d002c7,"Enlightened requirements engineering (RE) researchers and practitioners generally accept that RE is as much about understanding the world as it is about understanding the software and systems that will be built to inhabit that world. As a result, the RE field has fostered a multi-disciplinary following of researchers and practitioners who are prepared to engage deeply in application domains, to apply a range of technical and socio-technical skills to understand those domains, and to accept that the outcome of an effective RE process may not deliver a software system at all. The RE community has also developed, deployed, and evaluated a wide range of contributions that reflect such enlightenment: conceptual models that reflect the relationships between the world and the machine, domain models and scenarios that reflect understandings of problem domains, and enterprise models that reflect the organisations and processes that build and deploy systems. All these in addition to the models that capture the all-important behaviour of systems and software. It seems to me however that the RE discipline is at a crossroads. The mechanics of the discipline appear to be established – much of the published research is now empirical – or technical, but only in so far as it responds to technological advances elsewhere, such as mobile and ubiquitous technologies represented by the Internet of Things, richer application domains such as Industrie 4.0 and Smart Cities, or more advanced computational techniques that are maturing, such AI, machine learning, and blockchains. As a community, we reassure ourselves that our discipline is safe and thriving, after all RE is a “forever problem”: all systems we wish to build will have requirements, now and forever. But this is to be complacent. RE has no protected status to study and deploy requirements. The formal models we elicit, design, and build are increasingly deployable by other disciplines, as are the values that we seek our modern, AI-driven systems to embody. A new and potentially radical re-framing of our discipline may be needed, and I will speculate what this may look like. It may require letting go of what we have considered to be the boundaries of our discipline, while embracing new but fluid boundaries. I have advocated and explored “software without boundaries” as one such framing that challenges the separation of ‘world and the machine’, not because I don't accept the separation of the ‘what’ and the ‘how’, the ‘indicative’ and the ‘optative’, or the ‘problem’ and the ‘solution’, but because the world we live in no longer accepts these separations. Society, more often than not, does not think of systems, of technology, or indeed of software; it thinks of ways of working, ways of interacting, ways of living. Requirements, such as they are, are ‘requirements we live by’ not requirements of systems in the world. At an extreme, if one believes the AI hype, ‘the world and the machine’ will increasingly be replaced by the ‘world in the machine’. Where does the RE community stand on this, and what can this community do to contribute to the framing and solving of this new reality? My own work in recent years has evolved to reflect the above. I still revisit, with some pride, the ‘RE Roadmap’ that Steve Easterbrook and I published in 2000 – many of the fundamental RE principles we presented still hold today. But I cringe at how we missed the changing nature of the world in which we operate: a world populated by autonomous and adaptive systems, populated by big data and associated analytics, and populated by stakeholders whose multiple perspectives reflect a multitude of ethical and social values, not all of which are wholesome, and many of which are actively subversive or malicious. My own research on security and privacy requirements only scratches the surface of this evolving reality. I invite the RE community to reflect on how it frames its own research in this context.",not included,745,0.8354607820510864
10.1145/3359313,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Proc. ACM Hum. Comput. Interact.,2019-01-01 00:00:00,semantic_scholar,human-ai collaboration in data science,https://www.semanticscholar.org/paper/8ece479b5dfed4727d2d9b9763f777bb9a94096e,"The rapid advancement of artificial intelligence (AI) is changing our lives in many ways. One application domain is data science. New techniques in automating the creation of AI, known as AutoAI or AutoML, aim to automate the work practices of data scientists. AutoAI systems are capable of autonomously ingesting and pre-processing data, engineering new features, and creating and scoring models based on a target objectives (e.g. accuracy or run-time efficiency). Though not yet widely adopted, we are interested in understanding how AutoAI will impact the practice of data science. We conducted interviews with 20 data scientists who work at a large, multinational technology company and practice data science in various business settings. Our goal is to understand their current work practices and how these practices might change with AutoAI. Reactions were mixed: while informants expressed concerns about the trend of automating their jobs, they also strongly felt it was inevitable. Despite these concerns, they remained optimistic about their future job security due to a view that the future of data science work will be a collaboration between humans and AI systems, in which both automation and human expertise are indispensable.",not included,662,0.8354597687721252
10.1109/ictc55196.2022.9952989,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Information and Communication Technology Convergence,2022-01-01 00:00:00,semantic_scholar,trustops: a risk-based ai engineering process,https://www.semanticscholar.org/paper/f4b42bdd510b993177c578830e89e58776060aab,"We live in an era of artificial intelligence (AI) technology, which enables traditional HW/SW systems to help humans make wise decisions and even operate in intelligent ways. However, due to its inductive behaviors, this data-driven technology creates problems differ from those of conventional deductive systems. Therefore, the more AI is used in a wider range of industries and societies, the more problems and issues unseen before arise in human society. That's why most international organizations and nations released principles, and are struggling to find a technical methodology for assuring trustworthiness of AI. In many studies and papers, technical requirements are being presented individually and risk management is raised as the one of those. This paper intends to present an integrated and systematic engineering process that implements technical requirements in aspect of risk management.",included,1149,0.8350556492805481
10.1145/3522664.3528607,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2022 IEEE/ACM 1st International Conference on AI Engineering – Software Engineering for AI (CAIN),2022-01-01 00:00:00,semantic_scholar,towards a roadmap on software engineering for responsible ai,https://www.semanticscholar.org/paper/dccd738bc67c1e4b807b07872ff065fadc4253da,"Although AI is transforming the world, there are serious concerns about its ability to behave and make decisions responsibly. Many ethical regulations, principles, and frameworks for responsible AI have been issued recently. However, they are high level and difficult to put into practice. On the other hand, most AI researchers focus on algorithmic solutions, while the responsible AI challenges actually crosscut the entire engineering lifecycle and components of AI systems. To close the gap in operationalizing responsible AI, this paper aims to develop a roadmap on software engineering for responsible AI. The roadmap focuses on (i) establishing multi-level governance for responsible AI systems, (ii) setting up the development processes incorporating process-oriented practices for responsible AI systems, and (iii) building responsible-AI-by-design into AI systems through system-level architectural style, patterns and techniques. CCS CONCEPTS • Software and its engineering;",not included,1130,0.8344433307647705
10.1109/sose59841.2023.10178624,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2023 18th Annual System of Systems Engineering Conference (SoSe),IEEE,2023-06-16 00:00:00,ieeexplore,a new technology rises: non-human knowledge workers and decision-making in a system of complex systems,https://ieeexplore.ieee.org/document/10178624/,"To accomplish their missions, organizations make decisions—a form of knowledge work—that consumes scarce resources. As advanced algorithms, like artificial intelligence (AI), become more ubiquitous and affordable, some organizations are turning to such technical systems to strengthen their decision-making and, by extension, system-level performance. However, the degree to which AI and autonomous systems impact system-level performance is suboptimal because existing approaches generally ignore two critical design factors—the extent to which algorithmic systems relieve humans of knowledge work and are structurally encoded in the system's task and communication structures. The purposeful design and incorporation of non-human knowledge workers (NHKWs) into organizations are central to system of systems engineering; NHKWs are likely to impact system complexity, the attainment of stakeholder goals, and other system performance measures. Against the backdrop of the ATLAS Experiment, this perspective paper explores the construct of NHKWs, distinguishes NHKWs from AI and similar algorithmic systems, and makes the case that intentionally designing NHKWs into an organization's technological framework is needed for more robust system-level performance and goal attainment.",not included,1774,0.8342373967170715
10.3233/idt-219001,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Journal of Intelligent Decision Technologies,2021-01-01 00:00:00,semantic_scholar,15 years of the international journal of intelligent decision technologies (idt): reflection from the editors,https://www.semanticscholar.org/paper/55bd65c46d88afc524fdf21853af0ae7ea36147d,"The inspiration for IDT grew out of conversations between Professor/Dr. Gloria Phillips-Wren and Professor/Dr. Lakhmi Jain at the Knowledge Engineering Systems (KES) International annual conferences. The mission of KES is stated as “dissemination, transfer, sharing and brokerage of knowledge” to address knowledge-intensive subjects. As a large professional scientific community, KES sponsors a broad spectrum of publications and activities for research scientists, academics, engineers and practitioners. Research in intelligent agents and intelligent systems in the timeframe of 2004–2006 at KES conferences was focused on algorithms and technical specifications. During the same general time period, the technology was becoming mature enough to be implemented into real-world decision support systems (DSS) for previously intractable problems. Thus, the idea emerged to create a special focus in KES that blended these two areas of technical aspects of intelligent systems and decision support through both a new journal and an annual conference. This ultimately resulted in a proposal for an interdisciplinary research journal that focused on supporting and advancing human decision making though the use of intelligent technologies. The journal was envisioned as bridging computer science with its development of artificial intelligence and intelligent agents, information systems with its development of decision support applications, and engineering with its development of systems. The growth of the internet with its concomitant availability of data exploded the amount and types of information that must be considered by a decision maker. Decisions must often be made in real-time under uncertain, stressful conditions that may change rapidly. Synergies between intelligent and information technologies can, for example, deliver artificial intelligence to enhance human judgment, perceive anomalies in data, enable collaboration, speed processing of new information, assist in risk assessment, identify and retrieve needed knowledge, suggest alternatives to the decision maker, and automate some decisional tasks. Intelligent Decision Technologies (IDT): An International Journal is dedicated to advancing knowledge in the theory and application of intelligent technologies and systems that support decision making. The field of intelligent decision support has continued to expand rapidly and reach real systems due, in part, to advances in enabling technologies. Advances and efficiencies in Artificial Intelligence (AI), internet speeds, real-time data acquisition such as the Internet of Things (IoT), distributed data storage, data processing via cluster computing and virtualization, and network-centric environments such as cloud technologies can deliver intelligent systems at scale in real-time. Since many applications involve some type of decision, IDT provides a forum for original research that has the potential to improve decision making using intelligent technologies. IDT joined the flagship KES Journal as an official journal of KES a couple of years after its successful launch. IDT is also an annual conference series under the KES umbrella of Smart Digital Futures.",not included,1089,0.8339088559150696
10.3390/make3010004,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Machine Learning and Knowledge Extraction,2020-01-01 00:00:00,semantic_scholar,ai system engineering - key challenges and lessons learned,https://www.semanticscholar.org/paper/75d16719ec5378cfe433143232d02029ad9dadbe,"The main challenges are discussed together with the lessons learned from past and ongoing research along the development cycle of machine learning systems. This will be done by taking into account intrinsic conditions of nowadays deep learning models, data and software quality issues and human-centered artificial intelligence (AI) postulates, including confidentiality and ethical aspects. The analysis outlines a fundamental theory-practice gap which superimposes the challenges of AI system engineering at the level of data quality assurance, model building, software engineering and deployment. The aim of this paper is to pinpoint research topics to explore approaches to address these challenges.",not included,770,0.8338991403579712
10.1007/s00146-024-01882-7,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),AI & SOCIETY,Springer,2024-03-07 00:00:00,springer,"trust, artificial intelligence and software practitioners: an interdisciplinary agenda",http://dx.doi.org/10.1007/s00146-024-01882-7,"Trust and trustworthiness are central concepts in contemporary discussions about the ethics of and qualities associated with artificial intelligence (AI) and the relationships between people, organisations and AI. In this article we develop an interdisciplinary approach, using socio-technical software engineering and design anthropological approaches, to investigate how trust and trustworthiness concepts are articulated and performed by AI software practitioners. We examine how trust and trustworthiness are defined in relation to AI across these disciplines, and investigate how AI, trust and trustworthiness are conceptualised and experienced through an ethnographic study of the work practices of nine practitioners in the software industry. We present key implications of our findings for the generation of trust and trustworthiness and for the training and education of future software practitioners.",not included,1434,0.8338250517845154
10.1109/apsecw53869.2021.00011,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2021 28th Asia-Pacific Software Engineering Conference Workshops (APSEC Workshops),2021-01-01 00:00:00,semantic_scholar,landscape of requirements engineering for machine learning-based ai systems,https://www.semanticscholar.org/paper/0951c6e56ef4c78305f5419cae0e079f7e289725,"Techniques and practices in RE are not well researched, although problems and the research challenges on requirements engineering (RE) for machine learning-based systems (MLS) are evaluated via empirical case studies. A systematic literature review of RE for MLS was conducted to guide practitioners and researchers to design and research effective RE for ML systems and software. We identified 32 papers. Although many studies have been recently conducted, problem statements and research challenges remain. Future studies should include the monitoring requirements for concept drifts and how domain experts collaborate with ML experts and engineers.",not included,913,0.8334622979164124
10.1109/ms.2018.3571224,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE Software,2018-01-01 00:00:00,semantic_scholar,software engineering for machine-learning applications: the road ahead,https://www.semanticscholar.org/paper/cc3d1830b5220b68d8e785130e4b0d5ab7563d67,"The First Symposium on Software Engineering for Machine Learning Applications (SEMLA) aimed to create a space in which machine learning (ML) and software engineering (SE) experts could come together to discuss challenges, new insights, and practical ideas regarding the engineering of ML and AI-based systems. Key challenges discussed included the accuracy of systems built using ML and AI models, the testing of those systems, industrial applications of AI, and the rift between the ML and SE communities. This article is part of a theme issue on software engineering’s 50th anniversary.",not included,687,0.8333806395530701
10.1109/smc52423.2021.9658640,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),"2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",IEEE,2021-10-20 00:00:00,ieeexplore,human-machine intelligence: frigates are intelligent organisms,https://ieeexplore.ieee.org/document/9658640/,"Human control over artificial agents is of increased importance today given the recent advances of artificial intelligence and its impact on today’s societies. This makes interdisciplinary cooperation especially between human-factors/ergonomics and artificial intelligence an important challenge that needs to be addressed. In addition to the common bridge that exists between human-factors/ergonomics and artificial intelligence, i.e., the balanced integration of humans and artificial agents into one loop, we reinterpret the work of cognitive systems engineering and resilience engineering as human-machine intelligence. The goal of human-machine intelligence is to understand and create intelligence in the homo machina, an intelligent organism made of human- and artificial agents. We define intelligence in a way that highlights decision making and adaptation and apply this definition to the design of the homo machina. This creates a unified viewpoint which fosters a shared approach between human-factors/ergonomics, artificial intelligence, and cognitive psychology.",not included,1803,0.832979142665863
10.1109/icsc59802.2024.00047,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2024 IEEE 18th International Conference on Semantic Computing (ICSC),IEEE,2024-02-07 00:00:00,ieeexplore,"designing social good semantic computing architectures for the long tail: case studies, evaluation, and challenges",https://ieeexplore.ieee.org/document/10475636/,"Many real-world systems, especially systems characterized by high social activity (such as the Web), tend to obey power law distributions and thereby have a significant ‘long tail’. We argue that researching, developing and designing semantic computing systems for the long tail, especially dependent on inductive AI, constitutes an important class of problems, not least because the long tail is challenging both technically and socially. By its very nature, the long tail is irregular, testing the generalization capabilities of the state-of-the-art, especially in architectures and interfaces that are built on some form of machine learning or statistical inference (including large language models). As machine learning and generative AI continues to be integrated into more front facing systems, the issue of the long tail cannot be ignored by either the systems engineering or the AI communities. We present two case studies with important social consequences (fighting human trafficking online, and managing information effectively and in real-time during humanitarian crises) where semantic computing and AI platforms specifically designed to handle long-tail challenges find critical application, and sometimes with drastically different design choices compared to designing only for the short tail (with the main goal of maximizing average accuracy).",included,1795,0.8320419192314148
10.1145/3596454.3597176,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),SCOPUS_ID:85168335496,scopus,2023-06-27 00:00:00,scopus,speeding up the engineering of interactive systems with generative ai,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85168335496&origin=inward,"
AbstractView references

This keynote discusses the opportunities and challenges of using Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) as tools for developing interactive systems. We will look at different stages in the development lifecycle of interactive systems and assess the value of AI support. We explore how GenAI and LLMs can potentially speed-up the ideation, requirements elicitation, architecture development, prototyping, implementation, and testing of interactive systems. The talk will outline emerging practices, such as the use of prompts for code and system generation, to facilitate prototyping and accelerate implementation. We will outline fundamental challenges and suggest emerging research directions, and pose research questions. What will software development tools look like in the future? How can we efficiently use AI to develop interactive systems without compromising quality? We also speculate about the implications of these developments for researchers, practitioners, and society. We believe that it will massively accelerate the digital transformation. Interactive AI-based tools for systems and software development will become a major research direction. © 2023 Owner/Author.
",not included,2134,0.8318575024604797
10.1109/raise.2019.00015,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,RAISE@ICSE,2019-01-01 00:00:00,semantic_scholar,towards concept based software engineering for intelligent agents,https://www.semanticscholar.org/paper/4167fbb4c9d3e4d0ab4982d4d102edc5c935ae1e,"The development of AI and machine learning applications at an industry mature level while maintaining quality and productivity goals is one of today's major challenges. Research in the field of intelligent agents has achieved many successes in recent years, especially due to various reinforcement learning techniques, and promises a high benefit in times of automation and autonomous systems. Bringing them into production, however, requires optimization against many other criteria than just accuracy. This leads to the emerging field of machine teaching. We already know many of the objectives used there from software engineering research, which has led to many well-established principles in recent decades. One of them is the component-based development whose idea finds an interesting counterpart in hierarchical reinforcement learning. We show that both areas can benefit from each other and introduce our approach of concept based software engineering, which is focused on supporting productivity and quality goals during the development of such systems.",included,684,0.8317070007324219
10.7203/metode.9.11145,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),core,core,2019-01-01 00:00:00,core,"towards artificial intelligence : advances, challenges, and risks",https://core.ac.uk/download/459219022.pdf,"This text contains some reflections on artificial intelligence (AI). First, we distinguish between strong and weak AI, as well as the concepts related to general and specific AI. Following this, we briefly describe the main current AI models and discuss the need to provide common-sense knowledge to machines in order to advance towards the goal of a general AI. Next, we talk about the current trends in AI based on the analysis of large amounts of data, which has recently allowed experts to make spectacular progress. Finally, we discuss other topics which, now and in the future, will continue to be key in AI, before closing with a brief reflection on the risks of AI",not included,3231,0.8308760523796082
10.1609/aimag.v39i3.2809,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,The AI Magazine,2018-01-01 00:00:00,semantic_scholar,learning from artificial intelligence's previous awakenings: the history of expert systems,https://www.semanticscholar.org/paper/c65f90f67f9ebc4ab1ed6304f30bd26f66a3d486,"This article frames and presents the discussion at an invited panel “AI History: Expert Systems” held at the AAAI-17 conference held in San Francisco. The panel’s purpose was to open up this history of expert systems, its transformational aspects, and its connections to today’s AI awakening.",not included,102,0.8308395147323608
10.1109/tcyb.2018.2879213,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE Transactions on Cybernetics,2018-01-01 00:00:00,semantic_scholar,guest editorial from intelligent control to smart management of cyber-physical-social systems: a celebration of 70th anniversary of cybernetics by norbert wiener,https://www.semanticscholar.org/paper/a811df6464547d2c5f4b236f113c008de6b9d7d1,"Inspired by the idealism embodied in Russell and Whitehead’s “Principia Mathematica,” Wiener marched along a different and unique path toward sciences of intelligence and behavior which culminated at “Cybernetics: Or Control and Communication in the Animal and the Machine” 70 years ago. Since then, we have witnessed the birth of Cognitive Science, Artificial Intelligence (AI), Computational Intelligence, and many other new research fields and disciplines, all of which have been catalyzed by Cybernetics. The IEEE Systems, Man, AND Cybernetics Society and this Transactions on Cybernetics have become the focal point of the broad cybernetics community by promoting the theory, practice, and interdisciplinary aspects of systems science and engineering, human-machine systems, and cybernetics principles. It is a time of celebration and reflection.",not included,396,0.8307636976242065
10.1109/sose50414.2020.9130505,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Symposium on Service Oriented Software Engineering,2020-01-01 00:00:00,semantic_scholar,artificial intelligence based asset management,https://www.semanticscholar.org/paper/c9ea5cb0d31eb247a4a412f636403eefbb1d4773,"In a System Engineering perspective, asset management (AM) is related to a subset of techniques focusing on the in-service phase, aligned with product life-cycle management discipline. Today, within AM solution market, the integration of Artificial Intelligence (AI) technics above traditional entreprise solution is a key trend. This paper is focusing on how symbolic AI and data driven AI could improve some issues of the AM life cycle, in particular in asset acquisition, performance analysis and forecasting, asset monitoring, predictive and prescriptive maintenance, supply chain optimisation including spare parts management…",not included,870,0.8302757740020752
10.13140/rg.2.2.17162.77762,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),core,core,2018-01-01 00:00:00,core,a value-sensitive design approach to intelligent agents,https://core.ac.uk/download/146502298.pdf,"This chapter proposed a novel design methodology called Value-Sensitive Design and its potential application to the field of artificial intelligence research and design. It discusses the imperatives in adopting a design philosophy that embeds values into the design of artificial agents at the early stages of AI development. Because of the high risk stakes in the unmitigated design of artificial agents, this chapter proposes that even though VSD may turn out to be a less-than-optimal design methodology, it currently provides a framework that has the potential to embed stakeholder values and incorporate current design methods. The reader should begin to take away the importance of a proactive design approach to intelligent agents",not included,3264,0.8300749063491821
http://arxiv.org/abs/1911.07133v1,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),arxiv,arxiv,2019-11-17 00:00:00,arxiv,"autonomics: in search of a foundation for next generation autonomous
  systems",http://arxiv.org/abs/1911.07133v1,"The potential benefits of autonomous systems have been driving intensive
development of such systems, and of supporting tools and methodologies.
However, there are still major issues to be dealt with before such development
becomes commonplace engineering practice, with accepted and trustworthy
deliverables. We argue that a solid, evolving, publicly available,
community-controlled foundation for developing next generation autonomous
systems is a must. We discuss what is needed for such a foundation, identify a
central aspect thereof, namely, decision-making, and focus on three main
challenges: (i) how to specify autonomous system behavior and the associated
decisions in the face of unpredictability of future events and conditions and
the inadequacy of current languages for describing these; (ii) how to carry out
faithful simulation and analysis of system behavior with respect to rich
environments that include humans, physical artifacts, and other systems,; and
(iii) how to engineer systems that combine executable model-driven techniques
and data-driven machine learning techniques. We argue that autonomics, i.e.,
the study of unique challenges presented by next generation autonomous systems,
and research towards resolving them, can introduce substantial contributions
and innovations in system engineering and computer science.",included,72,0.829957902431488
10.1007/978-981-97-0503-0_4,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),"AI, Consciousness and The New Humanism",Springer,2024-01-01 00:00:00,springer,artificial intelligence: a case for ethical design and multidisciplinarity,http://dx.doi.org/10.1007/978-981-97-0503-0_4,"Autonomous and intelligent systems and services that use narrow artificial intelligence technologies such as statistical learning and limited inferencing (AISSN) are pervasive in our lives and industry. These systems, very far from having human-like intelligence, will offer significant potential for doing social good, achieving productivity gains and advancing science and engineering. However, AISSN systems can have unanticipated and harmful impacts. This chapter highlights the ethical challenges of AISSNs using three diverse and pervasive examples: Internet of Things, conversational AI, and semi-autonomous vehicles. We contend that AISSNs will be the norm for the foreseeable future and that artificial general intelligence will not develop anytime soon. The ethical challenges of AISSNs are addressable using human-centred “Ethical Design”, the use of widely accepted moral standards of right and wrong to guide the conduct of people in the ideation, design, development, and deployment of AISSN systems. Depending on the problem domain, multidisciplinary teams of computer scientists and engineers, sociologists, economists, ethicists, linguists, and cultural anthropologists will be required to implement humanistic design processes.",not included,1553,0.8299493193626404
10.1145/3564121.3564798,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Conference on AI-ML-Systems,2022-01-01 00:00:00,semantic_scholar,health assurance: ai model monitoring platform,https://www.semanticscholar.org/paper/e9316a708da9d46301b797d5fd38411d66dba735,"Businesses are increasingly reliant on Machine Learning models to manage user experiences. It becomes important to not only focus on building robust and state-of-the-art models but also continuously monitor and evaluate them. Continuous monitoring enables the AI team to ensure the right frequency of model training and pro-actively investigate erroneous patterns and predictions, before it has a wider business impact. A robust and effective monitoring system is thus needed to ensure business and engineering teams are aware of model performance and any data anomalies which could impact downstream model accuracy. In this paper, we present our Health Assurance model monitoring solution. Currently, the system serves the health monitoring needs of more than 250 models across 11 AI verticals with an average anomaly detection precision of 60%.",not included,1198,0.8296725749969482
10.1109/re51729.2021.00009,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE International Requirements Engineering Conference,2021-01-01 00:00:00,semantic_scholar,non-functional requirements for machine learning: understanding current use and challenges in industry,https://www.semanticscholar.org/paper/74cbf7434d580a2eddf636ba71e7218ef453981f,"Machine Learning (ML) is an application of Artificial Intelligence (AI) that uses big data to produce complex predictions and decision-making systems, which would be challenging to obtain otherwise. To ensure the success of ML-enabled systems, it is essential to be aware of certain qualities of ML solutions (performance, transparency, fairness), known from a Requirement Engineering (RE) perspective as non-functional requirements (NFRs). However, when systems involve ML, NFRs for traditional software may not apply in the same ways; some NFRs may become more prominent or less important; NFRs may be defined over the ML model, data, or the entire system; and NFRs for ML may be measured differently. In this work, we aim to understand the state-of-the-art and challenges of dealing with NFRs for ML in industry. We interviewed ten engineering practitioners working with NFRs and ML. We find examples of (1) the identification and measurement of NFRs for ML, (2) identification of more and less important NFRs for ML, and (3) the challenges associated with NFRs and ML in the industry. This knowledge paints a picture of how ML-related NFRs are treated in practice and helps to guide future RE for ML efforts.",not included,1018,0.8295584321022034
10.1109/cain58948.2023.00019,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2023 IEEE/ACM 2nd International Conference on AI Engineering – Software Engineering for AI (CAIN),IEEE,2023-05-16 00:00:00,ieeexplore,conceptualising software development lifecycle for engineering ai planning systems,https://ieeexplore.ieee.org/document/10164777/,"Given the prominence of AI planning in research and industry, the development of AI planning software and its integration into production architectures are becoming important. However, building and managing planning software is a complex and expertise-dependent process without methodological support that would ensure AI planning applications have high quality and industrial strength. To that end, we propose a lifecycle for developing AI planning systems that consists of ten phases related to the design, development, and operation of planning systems.",included,1874,0.8290835022926331
http://arxiv.org/abs/2311.06263v1,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),arxiv,arxiv,2023-09-27 00:00:00,arxiv,no trust without regulation!,http://arxiv.org/abs/2311.06263v1,"The explosion in the performance of Machine Learning (ML) and the potential
of its applications are strongly encouraging us to consider its use in
industrial systems, including for critical functions such as decision-making in
autonomous systems. While the AI community is well aware of the need to ensure
the trustworthiness of AI-based applications, it is still leaving too much to
one side the issue of safety and its corollary, regulation and standards,
without which it is not possible to certify any level of safety, whether the
systems are slightly or very critical.The process of developing and qualifying
safety-critical software and systems in regulated industries such as aerospace,
nuclear power stations, railways or automotive industry has long been well
rationalized and mastered. They use well-defined standards, regulatory
frameworks and processes, as well as formal techniques to assess and
demonstrate the quality and safety of the systems and software they develop.
However, the low level of formalization of specifications and the uncertainties
and opacity of machine learning-based components make it difficult to validate
and verify them using most traditional critical systems engineering methods.
This raises the question of qualification standards, and therefore of
regulations adapted to AI. With the AI Act, the European Commission has laid
the foundations for moving forward and building solid approaches to the
integration of AI-based applications that are safe, trustworthy and respect
European ethical values. The question then becomes ""How can we rise to the
challenge of certification and propose methods and tools for trusted artificial
intelligence?""",not included,17,0.8290234804153442
10.1109/iccicc46617.2019.9146038,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2019 IEEE 18th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC),IEEE,2019-07-25 00:00:00,ieeexplore,"on autonomous systems: from reflexive, imperative and adaptive intelligence to autonomous and cognitive intelligence",https://ieeexplore.ieee.org/document/9146038/,"Autonomous systems underpinned by cognitive intelligence represent advanced forms of artificial intelligence studied in intelligence science, systems science, and computational intelligence. Traditional theories and technologies of autonomous systems put emphases on human-system interactions and humans in-the-loop. This paper explores the intelligence and system foundations of autonomous systems. It focuses on what structural and behavioral properties constitute the intelligence power of autonomous systems. It explains how system intelligence aggregates from reflexive, imperative, adaptive intelligence to autonomous and cognitive intelligence. A Hierarchical Intelligence Model (HIM) is introduced to elaborate the evolution of human and system intelligence as an inductive process. A set of properties of system autonomy is formally analyzed towards a wide range of autonomous system applications in computational intelligence and systems engineering.",not included,1814,0.8280785083770752
10.1109/icarcv57592.2022.10004251,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,"International Conference on Control, Automation, Robotics and Vision",2022-01-01 00:00:00,semantic_scholar,adaptive design of a cyber-physical system for industrial risk management decision support,https://www.semanticscholar.org/paper/7a509bd9ea1542518eb767004272a65630d80127,"This article presents an integrated design of intelligent decision support systems (DSSs) for industrial risk management. The need for this class of systems has been necessitated by resilience building and threat response planning problems faced by complex industrial installations in energy and mining sectors. The proposed DSS software architecture is AI-based and applies causal and anticipatory networks, multi-criteria analysis, information fusion and knowledge engineering techniques. The use of AI-tools follows the AI-alignment paradigm, where AI evolution provides clues regarding the most suitable techniques to solve anticipated industrial safety problems in different time scales. We propose a general scheme of industrial risk management which includes threats, sensors, information flows, and decision-making models. This scheme is complemented by the risk optimization module, which selects the actions and actuators to implement them. Signals received from sensors are fused and confronted with threat management scenarios contained in the knowledge base. The recommendations concerning prevention, protection, and threat mitigation measures are generated by the DSS and conveyed to human decision makers for approval. Selected actions can also be autonomously initiated. Previous activity assessments result on an improved configuration of sensors and actuators, as well as more effective first responder actions. Threat and risk management modules of the DSS are linked by a sequential machine learning procedure, so that the results of prior decisions can be used to learn managerial preferences and parameters of risk mitigating scenarios.",not included,1333,0.8279922604560852
10.1109/smc42975.2020.9283454,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,"IEEE International Conference on Systems, Man and Cybernetics",2020-01-01 00:00:00,semantic_scholar,ieee 7010: a new standard for assessing the well-being implications of artificial intelligence,https://www.semanticscholar.org/paper/056fa1a9cff1be88533516978412dc9212eff003,"Artificial intelligence (AI) enabled products and services are becoming a staple of everyday life. While governments and businesses are eager to enjoy the benefits of AI innovations, the mixed impact of these autonomous and intelligent systems on human well-being has become a pressing issue. The purpose of this article is to review one of the first international standards focused on the social and ethical implications of AI: The Institute of Electrical and Electronics Engineering’s (IEEE) Standard (Std) 7010-2020 Recommended Practice for Assessing the Impact of Autonomous and Intelligent Systems on Human Well-being. Incorporating well-being factors throughout the lifecycle of AI is both challenging and urgent and IEEE 7010 aims to provide guidance for those who design, deploy, and procure these technologies. Before introducing IEEE 7010, we consider possible benefits of an approach for AI centered around well-being and the measurement of well-being data. Next, we critically examine how the standard relates to approaches and perspectives in place in the AI community. Finally, we indicate where future efforts are needed for IEEE 7010 to better achieve its ambitions.",not included,835,0.8277711868286133
10.1145/3088342,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Communications of the ACM,2017-01-01 00:00:00,semantic_scholar,artificial intelligence poised to ride a new wave,https://www.semanticscholar.org/paper/7027db226725bb30828dc3c4e67e8e943ff8b8ff,"Flush with recent successes, and pushed by even newer technology, AI systems could get much smarter.",not included,155,0.8276472091674805
10.1145/3278721.3278785,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,"AAAI/ACM Conference on AI, Ethics, and Society",2018-01-01 00:00:00,semantic_scholar,the design of human oversight in autonomous weapon systems,https://www.semanticscholar.org/paper/b5c7c3ea625bab010fa3f6f8021cd21b68e79068,"As the reach and capabilities of Artificial Intelligence (AI) systems increases, there is also a growing awareness of the ethical, legal and societal impact of the potential actions and decisions of these systems. Many are calling for guidelines and regulations that can ensure the responsible design, development, implementation, and policy of AI. In scientific literature, AI is characterized by the concepts of Adaptability, Interactivity and Autonomy (Floridi & Sanders, 2004). According to Floridi and Sanders (2004), Adaptability means that the system can change based on its interaction and can learn from its experience. Machine learning techniques are an example of this. Interactivity occurs when the system and its environment act upon each other and Autonomy implies that the system itself can change its state.",not included,380,0.8271796703338623
10.1109/ase51524.2021.9678647,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Conference on Automated Software Engineering,2021-01-01 00:00:00,semantic_scholar,towards fluid software architectures: bidirectional human-ai interaction,https://www.semanticscholar.org/paper/87cc86ba7b42c45a0b924bffc1ad602dc688648f,"The research on engineering software applications that employ artificial intelligence (AI) and machine learning (ML) is at an all-time peak. However, most of the research in this area is focused on the interactions between humans and AI which, in turn, is predominantly concerned with either building immersive interfaces and user experiences that allow for increased telemetry or on handling AI and ML applications in production (MLOps). Nonetheless, the research on fundamental architectural differences between AI-powered applications and traditional ones did not receive its fair share of attention. To that end, we believe that a new take on the fundamental architecture of building software applications is needed. With the ever increasing prominence of content-driven AI-powered applications, it is our conviction that 1) content could be served by servers without clients requesting, 2) servers could (should) request data from clients without waiting for their requests, and 3) interfaces should dynamically adapt to updates that happen to the intelligence driving the application. Hence, in this paper, we propose the fluid architecture that facilitates the bidirectional interaction between clients and servers as well as accommodates the co-dependent evolution of interfaces and back-end intelligence in AI-powered systems.",included,978,0.8270476460456848
10.1007/978-3-031-35891-3_32,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),Artificial Intelligence in HCI,Springer,2023-01-01 00:00:00,springer,approaching ai: a practical guide to understanding and using ai for hci,http://dx.doi.org/10.1007/978-3-031-35891-3_32,"Artificial intelligence (AI), is an important evolution in computer science that is only beginning to take hold within the HCI communities. But while the science of AI was twice pronounced dead, it continues to evolve, so do the number of definitions, concepts, applications, and theories that are included in the study of AI. Understanding the definitions and concepts, the functions, terms and relationships associated with this sub-discipline of computer science can be challenging. Today, HCI researchers have an opportunity to begin to apply AI concepts to designing interactions and interfaces that will represent an evolution to the way humans use computers. However, because of the complexities and seemingly disconnected research efforts, HCI researchers must develop a clear and practical understanding of AI — the discipline, concepts, technologies, and terminology — to effectively develop the safe and trusted AI applications of the future. Towards this goal, this paper presents a high-level overview of AI, its history, and the key components, terms, and technologies that currently represent the constantly evolving science. Our goal is to motivate and support the adoption of AI as a safe and trusted layer of computer interactions towards the development of a new paradigm for HCI research.",not included,1649,0.8269311189651489
10.48550/arxiv.2203.00905,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,arXiv.org,2022-01-01 00:00:00,semantic_scholar,responsible-ai-by-design: a pattern collection for designing responsible ai systems,https://www.semanticscholar.org/paper/da40fe10253e732460baff189e7c8cdac9e6033d,"Although AI has significant potential to transform society, there are serious concerns about its ability to behave and make decisions responsibly. Many ethical regulations, principles, and guidelines for responsible AI have been issued recently. However, these principles are high-level and difficult to put into practice. In the meantime much effort has been put into responsible AI from the algorithm perspective, but they are limited to a small subset of ethical principles amenable to mathematical analysis. Responsible AI issues go beyond data and algorithms and are often at the system-level crosscutting many system components and the entire software engineering lifecycle. Based on the result of a systematic literature review, this paper identifies one missing element as the system-level guidance - how to design the architecture of responsible AI systems. We present a summary of design patterns that can be embedded into the AI systems as product features to contribute to responsible-AI-by-design.",included,1132,0.8269172310829163
10.1109/rew53955.2021.00075,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2021 IEEE 29th International Requirements Engineering Conference Workshops (REW),2021-01-01 00:00:00,semantic_scholar,an re’21 workshop on environment-driven requirements engineering (envire’21),https://www.semanticscholar.org/paper/28bb6627842a97f22fad20ab0fe19a2545417042,"We organize a one-day workshop on Environment-Driven Requirements Engineering(EnviRE’21) in conjunction with the 29th IEEE International Requirements Engineering Conference. With the rising influence of AI, IoT, and cyber-physical systems, we realize that the environment, in which the software operates, becomes more open and evolves rapidly with stakeholders’ changing needs. EnviRE’21 features one keynote, four accepted papers, and one accepted presentation. Overall, the workshop is aimed at bringing the interested researchers and practitioners together, exchanging ideas and visions, and exploring a set of open problems to pursue in the years to come.",not included,985,0.8267159461975098
http://arxiv.org/abs/2201.03413v2,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),arxiv,arxiv,2022-01-10 00:00:00,arxiv,systems challenges for trustworthy embodied systems,http://arxiv.org/abs/2201.03413v2,"A new generation of increasingly autonomous and self-learning embodied
systems is about to be developed. When deploying embodied systems into a
real-life context we face various engineering challenges, as it is crucial to
coordinate the behavior of embodied systems in a beneficial manner, ensure
their compatibility with our human-centered social values, and design
verifiably safe and reliable human-machine interaction. We are arguing that
traditional systems engineering is coming to a climacteric from embedded to
embodied systems, and with assuring the trustworthiness of dynamic federations
of situationally aware, intent-driven, explorative, ever-evolving, largely
non-predictable, and increasingly autonomous embodied systems in uncertain,
complex, and unpredictable real-world contexts. We are therefore identifying a
number of urgent systems challenges for trustworthy embodied systems, including
robust and human-centric AI, cognitive architectures, uncertainty
quantification, trustworthy self-integration, and continual analysis and
assurance.",not included,42,0.8266982436180115
10.1145/3284432.3287195,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Conference on Human-Agent Interaction,2018-01-01 00:00:00,semantic_scholar,human-artificial intelligence partnerships,https://www.semanticscholar.org/paper/a0b49c4fdaebd45d1634809fe3400e4b37d74c44,"In our increasingly connected world, computation is everywhere and we are generating ever more data about everything. These trends will profoundly change the ways in which we work with computers. Specifically, we need the machines to be smarter and more helpful. Central to this vision is the means by which we can forge effective partnerships with such artificial intelligence (AI) systems. Until now, humans have generally been the masters and technology the slave. This needs to change. Today's AI systems can act on high-level human commands and achieve complex goals in a flexible manner. But, while such systems are good at solving narrowly defined tasks, they don't know how to collaborate with humans or how to operate as part of a problem-solving team. This talk will explore how humans and AI systems can work together. In such partnerships, the humans and the AI systems complement each other's strengths and weaknesses, leading to a rise in the humans, as well as in the machines. Drawing on multi-disciplinary work in the areas of AI, autonomous systems, machine learning, crowd sourcing and ubiquitous computing, this talk explores the scientific underpinning of such systems, the applications they have been applied to, and the societal implications of their widespread adoption.",not included,171,0.8266030550003052
10.1109/sysose.2018.8428711,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2018 13th Annual Conference on System of Systems Engineering (SoSE),IEEE,2018-06-22 00:00:00,ieeexplore,data-driven aspects of engineering the use of operational data in sos engineering: chances and challenges,https://ieeexplore.ieee.org/document/8428711/,"System of systems engineering moves towards the realization of smart systems. Information and its underlying data forms the backbone for such cyber-physical systems, especially within the application domains of the internet of things and of infrastructure systems of systems. Data therefore becomes a key component within system engineering. In this context, the rise of applied data science allows for novel uses of systems' operational data for engineering purposes. We recognize several areas for which data-driven approaches yield promising results, but also identify challenges that render success difficult. These challenges, i.e., data sparsity, the skewness of statistical distributions w.r.t. relevant objects and the semantics of the context of systems, are in parts known to the data science community, but require an appropriate interpretation for engineering purposes. In our own work, we rely on existing domain knowledge to complement data driven aspects of system of systems engineering within a modelbased approach to address these and similar challenges.",not included,1793,0.8265716433525085
10.1093/jamia/ocac006,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,J. Am. Medical Informatics Assoc.,2021-01-01 00:00:00,semantic_scholar,defining amia's artificial intelligence principles,https://www.semanticscholar.org/paper/a2736b7a0f7a0002e912c665b1dc99fd40b469c4,"Recent advances in the science and technology of artificial intelligence (AI) and growing numbers of deployed AI systems in healthcare and other services have called attention to the need for ethical principles and governance. We define and provide a rationale for principles that should guide the commission, creation, implementation, maintenance, and retirement of AI systems as a foundation for governance throughout the lifecycle. Some principles are derived from the familiar requirements of practice and research in medicine and healthcare: beneficence, nonmaleficence, autonomy, and justice come first. A set of principles follow from the creation and engineering of AI systems: explainability of the technology in plain terms; interpretability, that is, plausible reasoning for decisions; fairness and absence of bias; dependability, including ""safe failure""; provision of an audit trail for decisions; and active management of the knowledge base to remain up to date and sensitive to any changes in the environment. In organizational terms, the principles require benevolence-aiming to do good through the use of AI; transparency, ensuring that all assumptions and potential conflicts of interest are declared; and accountability, including active oversight of AI systems and management of any risks that may arise. Particular attention is drawn to the case of vulnerable populations, where extreme care must be exercised. Finally, the principles emphasize the need for user education at all levels of engagement with AI and for continuing research into AI and its biomedical and healthcare applications.",included,1042,0.826555073261261
10.1109/icus58632.2023.10318312,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2023 IEEE International Conference on Unmanned Systems (ICUS),IEEE,2023-10-15 00:00:00,ieeexplore,a conceptual framework for human interaction with intelligent systems,https://ieeexplore.ieee.org/document/10318312/,"Development of artificial intelligence technologies calls for novel modalities in human interaction with systems. This paper presents a comprehensive conceptual framework to meet this trend. Five human-autonomy teaming forms were proposed firstly, including fully human control, mostly human control & partially autonomy control, human-autonomy negotiation, mostly autonomy control & partially human control, and fully autonomy control. Correspondingly, five levels of human-autonomy interaction were defined, ranging from Ll to L5. Then, four conceptual architectures of human-autonomy teaming were constructed, denoting traded control, executive control, combined control, and supervisory control. Finally, human-autonomy teaming was instantiated based on the systematic approaches in systems engineering. Use case analysis was carried out to sketch the components and their interactions in a typical form of human-autonomy teaming. Block definition and external interaction analysis were implemented with Systems Modeling Language to clarify the internal and external input-output relations in a formalized way. The framework put forward in this work may contribute to designing hardware architectures of human interaction with intelligent systems.",not included,1769,0.8257430791854858
10.1109/acsos-c52956.2021.00048,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2021 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C),2021-01-01 00:00:00,semantic_scholar,ai - based on the fly design of experiments in physics and engineering,https://www.semanticscholar.org/paper/bde7647482dc456b9239f2004aae5b215c9c92ee,"When designing scientific experiments, the focus is mostly on data acquisition rather than on online analysis of data. However, immediate analysis enables active control or instant redesign of the experiment. In this article, we elaborate on the opportunities of creating self-improving experimental designs following the Self-Improving System Integration (SISSY) concept. Here, we propose several research questions and assess their importance by focusing on one use case concentrating on SISSY systems in general as well as two specific use cases taken from physics and materials engineering, respectively.",not included,921,0.825473964214325
10.1109/jas.2020.1003432,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE/CAA Journal of Automatica Sinica,2021-01-01 00:00:00,semantic_scholar,towards a theoretical framework of autonomous systems underpinned by intelligence and systems sciences,https://www.semanticscholar.org/paper/7bb320e281f16a476255a5c654c48e4644a6c3ed,"Autonomous systems are an emerging AI technology functioning without human intervention underpinned by the latest advances in intelligence, cognition, computer, and systems sciences. This paper explores the intelligent and mathematical foundations of autonomous systems. It focuses on structural and behavioral properties that constitute the intelligent power of autonomous systems. It explains how system intelligence aggregates from reflexive, imperative, adaptive intelligence to autonomous and cognitive intelligence. A hierarchical intelligence model ( HIM ) is introduced to elaborate the evolution of human and system intelligence as an inductive process. The properties of system autonomy are formally analyzed towards a wide range of applications in computational intelligence and systems engineering. Emerging paradigms of autonomous systems including brain-inspired systems, cognitive robots, and autonomous knowledge learning systems are described. Advances in autonomous systems will pave a way towards highly intelligent machines for augmenting human capabilities.",included,951,0.8254063129425049
10.1080/17477778.2020.1863755,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,J. Simulation,2021-01-01 00:00:00,semantic_scholar,bringing ai to the edge: a formal m&s specification to deploy effective iot architectures,https://www.semanticscholar.org/paper/80715ef54a3c2de4557f7961103d6802ce80ecfc,"ABSTRACT Internet of Things applications are based on ubiquitous networks of multiple distributed devices, with limited computing resources and power, capable of collecting and storing data from heterogeneous sources in real-time. To avoid network saturation and delays, new architectures are needed to provide real-time Big Data and data analytics capabilities at the edge of the network, where energy efficiency needs to be considered to ensure a sustainable and effective deployment in areas of human activity. In this research, we present an IoT model based on the principles of Model-Based Systems Engineering. It covers the description of the entire architecture, from IoT devices to the processing units in edge data centres, and includes the location-awareness of user equipment, network, and computing infrastructures to optimise federated resource management in terms of delay and power consumption. We present a framework to assist the dimensioning and the dynamic operation of IoT data stream analytics applications.",not included,945,0.8252373933792114
10.1109/rams51492.2024.10457626,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2024 Annual Reliability and Maintainability Symposium (RAMS),IEEE,2024-01-25 00:00:00,ieeexplore,arcs-r: mission critical combined reliability and cybersecurity systems engineering analysis,https://ieeexplore.ieee.org/document/10457626/,"This paper explores how reliability analysis and cyber-security analysis can be combined using Artificial Intelligence and Machine Learning (AI/ML), and Large Language Models (LLM) to produce a continuously updated resilience analysis. This is achieved by modeling both the hardware and software of the system, and employing LLMs and AI/ML to continuously search for new software vulnerabilities and feed that information into continuously updating resilience models. A case study of a drone is presented that demonstrates the promise of the proposed method. It is expected that using the proposed method, named Assessment for Risk in Cybersecurity and Safety - Resilience (ARCS-R), will reduce failure rate of mission-critical cyber-physical systems by reducing the likelihood of a potential initiating event causing a prolonged degradation in system performance that impacts system resilience.",not included,1742,0.8250085711479187
10.1109/rew56159.2022.00007,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2022 IEEE 30th International Requirements Engineering Conference Workshops (REW),2022-01-01 00:00:00,semantic_scholar,an re’22 workshop on environment-driven requirements engineering (envire’22),https://www.semanticscholar.org/paper/07205c2acc12899a9d6c5115b1b66f2b4037eb7b,"We organize a one-day workshop on Environment-Driven Requirements Engineering (EnviRE’22) in conjunction with the 30th IEEE International Requirements Engineering Conference. With the rising influence of AI, IoT, and cyber-physical systems, we realize that the environment, in which the software operates, becomes more open and evolves rapidly with stakeholders’ changing needs. EnviRE’22 features one keynote and five accepted papers. Overall, the workshop is aimed at bringing the interested researchers and practitioners together, exchanging ideas and visions, and exploring a set of open problems to pursue in the years to come.",not included,1238,0.8248109817504883
10.1109/aire51212.2020.00012,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Workshop on Artificial Intelligence for Requirements Engineering,2020-01-01 00:00:00,semantic_scholar,towards an extended requirements problem formulation for superintelligence safety,https://www.semanticscholar.org/paper/60fd917a81fe79c94e2cda4599802269e412d5e6,"Under the headline ""AI safety"", a wide-reaching issue is being discussed, whether in the future some ""superhuman artificial intelligence"" / ""superintelligence"" could pose a threat to humanity. In addition, the late Steven Hawking warned that the rise of robots may be disastrous for mankind. A major concern is that even benevolent superhuman artificial intelligence (AI) may become seriously harmful if its given goals are not exactly aligned with ours, or if we cannot specify precisely its objective function. Metaphorically, this is compared to king Midas in Greek mythology, who expressed the wish that everything he touched should turn to gold, but obviously this wish was not specified precisely enough. In our view, this sounds like requirements problems and the challenge of their precise formulation. Hence, we take a new perspective on the problem by exploring it using insights from requirements engineering (RE). In addition, the overall issue calls for a major RE endeavor, figuring out the wishes and the needs with regard to a superintelligence, which will in our opinion most likely be a very complex softwareintensive system based on AI. In this paper, we introduce the idea of developing a new theoretical formulation of an extended requirements problem applicable to it, since it involves goals of both stakeholders and of the AI-based system-to-be-built.",included,883,0.8247873783111572
10.1007/s43039-023-00076-1,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),Italian Journal of Marketing,Springer,2023-09-01 00:00:00,springer,"how intelligent automation, service robots, and ai will reshape service products and their delivery",http://dx.doi.org/10.1007/s43039-023-00076-1,"Intelligent Automation in form of robots, smart self-service technologies, wearable technologies, software and systems such as machine learning, generative artificial intelligence (AI) such as ChatGPT, and the metaverse are increasingly adopted in a wide range of customer-facing service settings. The shift toward robot- and AI-powered services will lead to improved customer experiences, service quality, and productivity all at the same time. However, these also carry ethical, fairness, and privacy risks for customers and society. In this opinion piece, we discuss the implications of the service revolution for service firms, their marketing, and their customers, and provide avenues for future research opportunities.",not included,1588,0.8247710466384888
10.1109/peeic59336.2023.10450939,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),"2023 International Conference on Power Energy, Environment & Intelligent Control (PEEIC)",IEEE,2023-12-23 00:00:00,ieeexplore,"transforming electronics engineering with artificial intelligence: opportunities and challenges in design, testing, production, maintenance, and control systems",https://ieeexplore.ieee.org/document/10450939/,"This article examines how artificial intelligence (AI) is being incorporated into electronics engineering and how this might completely change the discipline. AI-based systems have prospects for raising system dependability, lowering energy usage, and boosting performance. The study offers a summary of the most recent developments in the fields of design automation, testing and diagnostic, production, maintenance, and control systems in electronics engineering. AI-based design automation technologies optimize the design process by cutting expenses and time spent on development while enhancing precision and effectiveness. AI-powered testing and diagnosis systems identify flaws early on, saving money and downtime. AI-powered industrial solutions improve efficiency, reduce waste, and boost effectiveness. AI-based maintenance methods reduce expenses and downtime while improving equipment reliability. AI-driven control systems improve system performance, reduce energy consumption, and increase stability. It is likely that as AI advances, new applications and tactics that push the boundaries of electronics engineering will surface. Concerns such as employment displacement, ethical dilemmas, data security, and privacy must all be addressed. However, the application of AI in the field of electronics has the potential to greatly advance a variety of industries and businesses given enough consideration and planning.",not included,1880,0.824475884437561
10.1145/3098888.3098895,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,SIGAI,2017-01-01 00:00:00,semantic_scholar,ai practioners: on the northeast ohio acm,https://www.semanticscholar.org/paper/55caf28fc364133cf8e578c12e455ca6930b7132,"I am currently the chair of NEOACM (North-east Ohio ACM), a professional chapter of the ACM, located in the state of Ohio in the U.S. founded in 2008. NEOACM is quickly coming up on its 10th anniversary. Our chapter, like most, is dedicated to advancing the art, science, engineering, and application of information technology, serving both professional and public interests. We accomplish much of our mission by hosting workshops, speakers, and panel discussions that are open to the public. In my capacity as chair, I have had the opportunity to influence the direction of some of the workshops and panel discussions that we host. I've always had a predilection for most things AI and I'm particularly interested in how the descriptions of embedded AI technologies are worded when those technologies are integral to goods and services targeted toward the average citizen or general public. Sure as insiders we throw around phrases like computational linguistics, particle swarm optimization, machine learning, domain ontologies, agent-oriented architectures, etc. all the time because its normal vernacular. But we know in most instances our techno-speak will need to be translated into terminology that's more consumer-oriented once commercial applications start to be generated. It's the gap that I worry about. The translation from artificial intelligence, computer science, and mathematics specific terminology into descriptions that the average citizen will end up trying to grapple with. For instance:",not included,525,0.8241390585899353
10.1145/3522664.3528590,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2022 IEEE/ACM 1st International Conference on AI Engineering – Software Engineering for AI (CAIN),2022-01-01 00:00:00,semantic_scholar,"data smells: categories, causes and consequences, and detection of suspicious data in ai-based systems",https://www.semanticscholar.org/paper/90af44f974da16aaa4d7c0fc4c771f27e7f4da58,"High data quality is fundamental for today’s AI-based systems. However, although data quality has been an object of research for decades, there is a clear lack of research on potential data quality issues (e.g., ambiguous, extraneous values). These kinds of issues are latent in nature and thus often not obvious. Nevertheless, they can be associated with an increased risk of future problems in AI-based systems (e.g., technical debt, data-induced faults). As a counterpart to code smells in software engineering, we refer to such issues as Data Smells. This article conceptualizes data smells and elaborates on their causes, consequences, detection, and use in the context of AI-based systems. In addition, a catalogue of 36 data smells divided into three categories (i.e., Believability Smells, Understandability Smells, Consistency Smells) is presented. Moreover, the article outlines tool support for detecting data smells and presents the result of an initial smell detection on more than 240 real-world datasets.",not included,1131,0.8239993453025818
10.1609/aimag.v40i4.5202,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,The AI Magazine,2019-01-01 00:00:00,semantic_scholar,current approaches in applied artificial intelligence: the 2019 iea/aie conference the iea/aie 2019 conference,https://www.semanticscholar.org/paper/3fe8c50b151b36350d3ba8a50dfb1b170d94f1c4,"The 32nd meeting of the International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems was held July 9–11, 2019, in Graz, Austria. The conference focus for 2019 was on automated driving, autonomous systems, robotics, and AI in tourism.",not included,733,0.823138952255249
10.1109/fuzz-ieee55066.2022.9882675,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE International Conference on Fuzzy Systems,2022-01-01 00:00:00,semantic_scholar,security considerations for the procurement and acquisition of artificial intelligence (ai) systems,https://www.semanticscholar.org/paper/d42e04841c817a11eb6d8717d8d62b14c38fcff3,"Procurement is a critical step in the setup of systems, as reverting decisions made at this point is typically time-consuming and costly. Especially Artificial Intelligence (AI) based systems face many challenges, starting with unclear and unknown side parameters at design time of the systems, changing ecosystems and regulations, as well as problems of overselling capabilities of systems by vendors. Furthermore, the AI Act puts forth a great deal of additional requirements for operators of critical AI systems, like risk management and transparency measures, thus making procurement even more complex. In addition, the number of providers of AI systems is drastically increasing. In this paper we provide guidelines for the procurement of AI based systems that support the decision maker in identifying the key elements for the procurement of secure AI systems, depending on the respective technical and regulatory environment. Furthermore, we provide additional resources for utilizing these guidelines in practical procurement.",included,1412,0.8225700259208679
10.1017/s0890060421000068,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,"Artificial intelligence for engineering design, analysis and manufacturing",2021-01-01 00:00:00,semantic_scholar,connectors of smart design and smart systems,https://www.semanticscholar.org/paper/be91fa22a3b8bfb9483ae7ca0781d7ca9e4c65f8,"Abstract Though they can be traced back to different roots, both smart design and smart systems have to do with the recent developments of artificial intelligence. There are two major questions related to them: (i) What way are smart design and smart systems enabled by artificial narrow, general, or super intelligence? and (ii) How can smart design be used in the realization of smart systems? and How can smart systems contribute to smart designing? A difficulty is that there are no exact definitions for these novel concepts in the literature. The endeavor to analyze the current situation and to answer the above questions stimulated an exploratory research whose first findings are summarized in this paper. Its first part elaborates on a plausible interpretation of the concept of smartness and provides an overview of the characteristics of smart design as a creative problem solving methodology supported by artificial intelligence. The second part exposes the paradigmatic features and system engineering issues of smart systems, which are equipped with application-specific synthetic system knowledge and reasoning mechanisms. The third part presents and elaborates on a conceptual model of AI-based couplings of smart design and smart systems. The couplings may manifest in various concrete forms in real life that are referred to as “connectors” in this paper. The principal types of connectors are exemplified and discussed. It has been found that smart design tends to manifest as a methodology of blue-printing smart systems and that smart systems will be intellectualized the enablers of implementation of smart design. Understanding the affordances of and creating proper connectors between smart design and smart systems need further explorative research.",not included,1005,0.8224819898605347
10.1007/978-3-031-42307-9_1,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),"Systems, Software and Services Process Improvement",Springer,2023-01-01 00:00:00,springer,sustained enablement of ai ethics in industry,http://dx.doi.org/10.1007/978-3-031-42307-9_1,"Artificial Intelligence (AI) has become an increasingly pervasive technology in various industries, offering numerous benefits such as increased efficiency, productivity, and innovation. However, the ethical implications of AI adoption in industry have raised concerns and AI ethics has emerged as a critical field of study, focusing on the trustworthy development, deployment, and use of AI technologies. In this paper, we explore an AI Ethics concept with a particular focus on sustained enabling factors to guide organizations in navigating the ethical challenges associated with AI adoption.",not included,1678,0.8222194910049438
10.1002/j.2371-9621.2021.tb00012.x,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,The AI Magazine,2021-01-01 00:00:00,semantic_scholar,"artificial intelligence's grand challenges: past, present, and future",https://www.semanticscholar.org/paper/f707a3f2aaa12dfb27f04b282253630ed29c32c0,"Copyright © 2021, Association for the Advancement of Artificial Intelligence. All rights reserved. ISSN 0738-4602 Spring 2021 61 grand challenges are important as they act as compasses for researchers and practitioners alike — especially young professionals — who are pondering worthwhile problems to work on, testing the boundaries of what is possible! Challenge tasks also unleash the competitive spirit in participants as evidenced by the plethora of active participants in Kaggle competitions (and forum discussions therein). prize money and research bragging rights also accrue to the winners. The Defense Advanced research projects Agency grand Challenges1 and X prizes2 are some of the best-known successful programs that have helped make significant progress across many domains applying artificial intelligence (Ai). As grand challenges are accomplished, other than the long-term benefits the solutions engender, the positive press they garner helps rally society behind the field. Trickle-down benefits include renewed respect for and trust in science and technology by citizens, as well as a desirable focus on science, technology, engineering, and mathematics education.  Innovative, bold initiatives that capture the imagination of researchers and system builders are often required to spur a field of science or technology forward. A vision for the future of artificial intelligence was laid out by Turing Award winner Raj Reddy in his 1988 Presidential address to the Association for the Advancement of Artificial Intelligence. It is time to provide an accounting of the progress that has been made in the field, over the last three decades, toward the challenge goals. While some tasks such as the world-champion chess machine were accomplished in short order, many others, such as self-replicating systems, require more focus and breakthroughs for completion. A new set of challenges for the current decade is also proposed, spanning the health, wealth, and wisdom spheres. Artificial Intelligence’s Grand Challenges: Past, Present, and Future",not included,1091,0.8216977119445801
10.1145/3075564.3076259,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Conf. Computing Frontiers,2017-01-01 00:00:00,semantic_scholar,bonseyes: platform for open development of systems of artificial intelligence: invited paper,https://www.semanticscholar.org/paper/250f130fadcec134088be094b230489286dadf8e,"The Bonseyes EU H2020 collaborative project aims to develop a platform consisting of a Data Marketplace, a Deep Learning Toolbox, and Developer Reference Platforms for organizations wanting to adopt Artificial Intelligence. The project will be focused on using artificial intelligence in low power Internet of Things (IoT) devices (""edge computing""), embedded computing systems, and data center servers (""cloud computing""). It will bring about orders of magnitude improvements in efficiency, performance, reliability, security, and productivity in the design and programming of systems of artificial intelligence that incorporate Smart Cyber-Physical Systems (CPS). In addition, it will solve a causality problem for organizations who lack access to Data and Models. Its open software architecture will facilitate adoption of the whole concept on a wider scale. To evaluate the effectiveness, technical feasibility, and to quantify the real-world improvements in efficiency, security, performance, effort and cost of adding AI to products and services using the Bonseyes platform, four complementary demonstrators will be built. Bonseyes platform capabilities are aimed at being aligned with the European FI-PPP activities and take advantage of its flagship project FIWARE. This paper provides a description of the project motivation, goals and preliminary work.",included,103,0.8214880228042603
10.3233/jid-229010,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Journal of Integrated Design & Process Science,2022-01-01 00:00:00,semantic_scholar,digital engineering transformation with trustworthy ai towards industry 4.0: emerging paradigm shifts,https://www.semanticscholar.org/paper/f9ce47cfa0292fa13a201ebd195c9b348757f86e,"Digital engineering transformation is a crucial process for the engineering paradigm shifts in the fourth industrial revolution (4IR), and artificial intelligence (AI) is a critical enabling technology in digital engineering transformation. This article discusses the following research questions: What are the fundamental changes in the 4IR? More specifically, what are the fundamental changes in engineering? What is digital engineering? What are the main uncertainties there? What is trustworthy AI? Why is it important today? What are emerging engineering paradigm shifts in the 4IR? What is the relationship between the data-intensive paradigm and digital engineering transformation? What should we do for digitalization? From investigating the pattern of industrial revolutions, this article argues that ubiquitous machine intelligence is the defining power brought by the 4IR. Digitalization is a condition to leverage ubiquitous machine intelligence. Digital engineering transformation towards Industry 4.0 has three essential building blocks: digitalization of engineering, leveraging ubiquitous machine intelligence, and building digital trust and security. The engineering design community at large is facing an excellent opportunity to bring the new capabilities of ubiquitous machine intelligence and trustworthy AI principles, as well as digital trust, together in various engineering systems design to ensure the trustworthiness of systems in Industry 4.0.",not included,1162,0.8212636709213257
http://arxiv.org/abs/2402.10977v1,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),arxiv,arxiv,2024-02-15 00:00:00,arxiv,generative ai and process systems engineering: the next frontier,http://arxiv.org/abs/2402.10977v1,"This article explores how emerging generative artificial intelligence (GenAI)
models, such as large language models (LLMs), can enhance solution
methodologies within process systems engineering (PSE). These cutting-edge
GenAI models, particularly foundation models (FMs), which are pre-trained on
extensive, general-purpose datasets, offer versatile adaptability for a broad
range of tasks, including responding to queries, image generation, and complex
decision-making. Given the close relationship between advancements in PSE and
developments in computing and systems technologies, exploring the synergy
between GenAI and PSE is essential. We begin our discussion with a compact
overview of both classic and emerging GenAI models, including FMs, and then
dive into their applications within key PSE domains: synthesis and design,
optimization and integration, and process monitoring and control. In each
domain, we explore how GenAI models could potentially advance PSE
methodologies, providing insights and prospects for each area. Furthermore, the
article identifies and discusses potential challenges in fully leveraging GenAI
within PSE, including multiscale modeling, data requirements, evaluation
metrics and benchmarks, and trust and safety, thereby deepening the discourse
on effective GenAI integration into systems analysis, design, optimization,
operations, monitoring, and control. This paper provides a guide for future
research focused on the applications of emerging GenAI in PSE.",not included,5,0.821081817150116
10.1609/aimag.v38i3.2756,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,The AI Magazine,2017-01-01 00:00:00,semantic_scholar,steps toward robust artificial intelligence,https://www.semanticscholar.org/paper/96ef2680eada97d2e7ff65e7a075513ecd449cdd,"Recent advances in artificial intelligence are encouraging governments and corporations to deploy AI in high-stakes settings including driving cars autonomously, managing the power grid, trading on stock exchanges, and controlling autonomous weapons systems. Such applications require AI methods to be robust to both the known unknowns (those uncertain aspects of the world about which the computer can reason explicitly) and the unknown unknowns (those aspects of the world that are not captured by the system’s models). This article discusses recent progress in AI and then describes eight ideas related to robustness that are being pursued within the AI research community. While these ideas are a start, we need to devote more attention to the challenges of dealing with the known and unknown unknowns. These issues are fascinating, because they touch on the fundamental question of how finite systems can survive and thrive in a complex and dangerous world",included,134,0.8210446238517761
10.5220/0003581200460056,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,MDA/MDSD,2017-01-01 00:00:00,semantic_scholar,knowledge integration for domain modeling,https://www.semanticscholar.org/paper/4bfa924cb14ddc168d2f4d45b2c270e9f808e0e0,"This research integrates artificial intelligence (AI) and system analysis by exploiting ontology, natural language processing (NLP), business use cases and model-driven architecture (MDA) for knowledge engineering and domain modeling. We describe an approach for compounding declarative and procedural knowledge in a way that corresponds to AI and system analysis standards, and is compliant for acquiring a domain model corresponding to MDA standards. We are recognizing the possibility of automatically transforming this knowledge to a Computation Independent Model (CIM) for MDA.",not included,416,0.8209315538406372
10.1109/sose52739.2021.9497497,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Symposium on Service Oriented Software Engineering,2021-01-01 00:00:00,semantic_scholar,empowering adaptive human autonomy collaboration with artificial intelligence,https://www.semanticscholar.org/paper/9cf5196842d4f62e7e76b31765cadf12c5c2843f,"We can now see examples emerge of intelligent distributed hybrid systems with autonomous functions pursuing a specific goal while adapting dynamically to changing environments. Such solutions are made possible by convergence of new technologies, but achieving comprehensive monitoring of the multiple interactions in their organization and functions along their life cycles, in missions and/or safety critical contexts, still challenges system (of systems) engineering practices. This paper considers the main gaps towards trusted systems of systems, including human-AI collaboration, human-machine teaming and solution effectiveness monitoring in a life cycle perspective. These gaps call for an inter-disciplinary sociotechnical approach in engineering towards Adjustable Human Autonomy Collaboration (DUAL), whose justification is outlined in this position paper.",not included,1039,0.8205769062042236
10.1631/fitee.2300537,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),SCOPUS_ID:85178939500,scopus,2023-11-01 00:00:00,scopus,software development in the age of intelligence: embracing large language models with the right approach,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85178939500&origin=inward,"
AbstractView references

Embracing LLMs is definitely a correct and even necessary direction for software enterprises to improve quality and efficiency. However, achieving systematic and comprehensive intelligent software development still requires careful consideration and there is much fundamental work to do. For enterprises, solidifying the digitization and knowledge accumulation of software development, as well as the fundamental capabilities of software engineering such as requirement analysis, design, and validation, remains crucial and is also a basic condition for achieving higher levels of intelligent development. For academic research, there is still much work to do in the direction of systematic and comprehensive intelligent software development. This also requires us have a deeper understanding of the complexity of software systems and software requirements and design, based on understanding the capabilities of LLMs. © 2023, Zhejiang University Press.
",included,2056,0.8203039765357971
10.1049/trit.2018.1008,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,CAAI Transactions on Intelligence Technology,2018-01-01 00:00:00,semantic_scholar,artificial intelligence in internet of things,https://www.semanticscholar.org/paper/0945b1ea6338545bd9fb47626ca90abbb69a8820,"Functioning of the Internet is persistently transforming from the Internet of computers (IoC) to the ‘Internet of things (IoT)’. Furthermore, massively interconnected systems, also known as cyber-physical systems (CPSs), are emerging from the assimilation of many facets like infrastructure, embedded devices, smart objects, humans, and physical environments. What the authors are heading to is a huge ‘Internet of Everything in a Smart Cyber Physical Earth’. IoT and CPS conjugated with ‘data science’ may emerge as the next ‘smart revolution’. The concern that arises then is to handle the huge data generated with the much weaker existing computation power. The research in data science and artificial intelligence (AI) has been striving to give an answer to this problem. Thus, IoT with AI can become a huge breakthrough. This is not just about saving money, smart things, reducing human effort, or any trending hype. This is much more than that – easing human life. There are, however, some serious issues like the security concerns and ethical issues which will go on plaguing IoT. The big picture is not how fascinating IoT with AI seems, but how the common people perceive it – a boon, a burden, or a threat.",not included,120,0.8198994398117065
10.1109/dsn58367.2023.00006,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2023 53rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN),IEEE,2023-06-30 00:00:00,ieeexplore,message from the dsn 2023 program chairs,https://ieeexplore.ieee.org/document/10202644/,"On behalf of the entire research track program committee, it is our great pleasure to present you to the research track of the 53rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN 2023). The program includes very solid contributions addressing diverse aspects of system robustness (including reliability, dependability, safety and security) across multiple domains including hardware, software, networks, cyber-physical and autonomous systems, artificial intelligence and machine learning. The program of the research track consists of 47 contributions, which consist of 40 research papers, five practical experience reports, and two tool papers.",not included,1871,0.8191484808921814
10.4230/oasics.iccsw.2018.11,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Imperial College Computing Student Workshop,2018-01-01 00:00:00,semantic_scholar,harnessing ai for research,https://www.semanticscholar.org/paper/caa915b6d9da4a8fd3c7035eaf69d614678bf226,"Artificial Intelligence is increasingly being used to both augment existing fields of research and open up new avenues of discovery. From quality control for imaging flow cytometry to computational musicology, modern AI is an exciting new tool for research and thus knowing how to engineer AI systems in a research context is a vital new skill for RSEs to acquire. In this talk, I will outline four different areas of AI: supervised learning, unsupervised learning, interactive learning, and Bayesian learning. For each of these approaches, I will discuss how they typically map to different research problems and explore best practices for RSEs via specific use cases. At the end of the talk, you will have received a high-level overview of AI technologies and their use in research, have seen some cool examples of how AI has been used in a wide range of research areas, and have a good sense of where to go to learn more. 2012 ACM Subject Classification Computing methodologies → Artificial intelligence",not included,356,0.8187957406044006
10.1109/icws53863.2021.00014,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2021 IEEE International Conference on Web Services (ICWS),2021-01-01 00:00:00,semantic_scholar,software services engineering manifesto - a cross-cutting declaration,https://www.semanticscholar.org/paper/9b0777eb2196aa752a91f209f17d1c21b266bd59,"As we have entered the Internet-of-Things (IoT) era, further blessed with rapid advances in several key technological areas including DevOps, AI/ML, 5G/6G/, neurocomputing, to name a few, it is imperative we think big and aim high. This new venture will require professionals in both software engineering and services computing to collaborate with an unprecedented intensity, and jointly develop the new interdisciplinary field hereby named Software Services Engineering (SSE). In SSE, the ever-deepening system dynamics emerging from both environments and humans in varying contexts are imposing steep challenges to both researchers and practitioners. Humans, both developers and the vast number of end users, are embedded ever closer to IoT environments, and are being afforded ample opportunities to continuously inject inputs during system development and after deployment. In fact, humans are increasingly playing the roles of both sensor and actuator. Traditional requirements engineering researchers are being lured more than ever into exploiting the IoT environments where human users are deeply embedded, to gather contextual information that inevitably introduces lots of ambiguity and uncertainty. Provisioning of highly adaptable and scalable microservices would be key to timely meeting ever-changing human desires and ever-evolving system requirements in the nimblest manner. As such, an ultra-agile and field-programmable development methodology and environment will be imperative to achieving such ultrafine grained microservices provisioning. Such ultra-agility and ultrafine granularity requirements imposed to the services industry obligate company executives to expect extreme manageability assurance to become the centroid of system operations and administration. The ultimate goal in pursuit of such a noble dream will be to provide genuinely individualized and trustworthy service, possibly enabled by AI, but it should be both explainable and ethical. Facing such grand challenges, this declaration samples a subset of burning issues in SSE through observations in seven themes, only meant to be starting points for the SSE community to further investigate. Through our declarations we also call for heightened attention to an assorted array of existing, barely emerging or non-existent services computing and software engineering methods for a concerted effort to research and explore.",not included,1003,0.8177403211593628
10.1109/iv47402.2020.9304740,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2020 IEEE Intelligent Vehicles Symposium (IV),IEEE,2020-11-13 00:00:00,ieeexplore,can ai-based components be part of dependable systems?,https://ieeexplore.ieee.org/document/9304740/,"Artificial Intelligence and especially Machine Learning have become main topics in the scientific community as well as in industry. These techniques seem to be a solution for complex problems and are suggested even for critical applications such as the medical diagnosis, predictive analytic in finance or autonomous driving. But will it be feasible to employ such techniques in critical systems in the avionics, train, or medical domain taking into account the current regulations in domain-specific standard relating to dependability? Validation, verification and certification in these domains strongly rely on explicit traceability and provability of functional and dependability requirements down to the code level. This seems to be impossible for components derived using e.g. learning approaches. Nonetheless, scientific community and industry do not want to lose the advantages related to AI-based techniques - new ways to ensure the required level of confidence just need to be found. This is a process that requires people with different professional background to work together - and it has started. This paper presents selected aspects relating to the current state of the art with regard to AI and dependable systems and describes ongoing activities and ideas for obstacle detection and routing for autonomous driving at HAW Hamburg.",included,1866,0.8174083828926086
10.1109/icsa.2019.00005,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Conference on Software Architecture,2019-01-01 00:00:00,semantic_scholar,message from the general chair and pc chairs of icsa 2019,https://www.semanticscholar.org/paper/230d6c5981047254b5cba3a45b3e212060ba6904,"The increasing size of software systems, trends to release software ever more frequently, the emerging hyper-connectivity of systems, and new technology trends such as IoT or AI technologies, demand innovative software engineering solutions. As a consequence, the ways software is developed and maintained are rapidly changing. In addition to technical challenges and the fast pace of technology evolution, software engineers must consider a multitude of other influences such as design and code quality, costs and business risks, market considerations, customer requirements, the ever increasing demand for change, to name just a few. These often conflicting requirements and forces are usually handled by the software architect. The International Conference on Software Architecture (ICSA) is the premier platform for academia and industry to join efforts in addressing these challenges, bringing innovative solutions, ideas and synergies in the software architecture domain.",not included,736,0.8172255158424377
10.1109/tiv.2023.3332877,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),IEEE Transactions on Intelligent Vehicles,IEEE,2023-11-01 00:00:00,ieeexplore,autonomous services: the evolution of services through intelligent vehicles,https://ieeexplore.ieee.org/document/10319096/,"The emergence of intelligent vehicles brings unique opportunities for the service industry. This study introduces the concept of autonomous services, a new service paradigm, and autonomous services systems, in which intelligent vehicles are vital enabling technology. Specifically, autonomous services aim to minimize unnecessary human participation and effort in the service process by leveraging intelligence for service delivery, rather than relying on simple stimulus-response or rule-based program behavior. This letter reports on the first Decentralized and Hybrid Workshop (DHW) on autonomous services, aiming to reduce the cost of human labor and improve the quality and efficiency of service while tackling the challenges posed by a shrinking workforce. The introduction of intelligent vehicles enhances the capability of the service systems, while also significantly increasing complexity. To address the challenges associated with complexity, the Systems Engineering (SE) approach is indispensable. The Requirements-Functional-Logical-Physical (RFLP) framework can implement Model-Based System Engineering (MBSE) and help researchers and managers to understand the autonomous services system more comprehensively, so as to better operate and manage it. We substitute “Implementation” for “Physical” in this research to define and elaborate on the autonomous services system. Finally, we outline the potential research opportunities within the autonomous services system.",included,1838,0.8170905709266663
10.1109/mts.2017.2697081,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE technology & society magazine,2017-01-01 00:00:00,semantic_scholar,the fleeting opportunity to create our values by design [opinion],https://www.semanticscholar.org/paper/a5774b1dbd826c6ab1ba5339e32a34b9046c699f,"In a time when artificial intelligence and autonomous systems (AI/AS) are providing more opportunities for personalization and time savings than ever before, it’s critical to pause for a moment to ask, “How will machines know what we value if we don’t know ourselves?” This isn’t rhetorical, and the play on words is intentional. While it may come easy to criticize programmers creating the code defining AI/AS, where machines or systems that mirror human values come into play, we as individuals need to identify, test, and codify these attributes so we can best help technologists align their creations with our deeply held beliefs.",not included,579,0.8168261647224426
10.1007/978-3-030-40760-5_3,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),SCOPUS_ID:85080855645,scopus,2020-01-01 00:00:00,scopus,basic structures of systems,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85080855645&origin=inward,"
AbstractView references

The essence of system science resides in the philosophy of holism. When talking about the state that system reaches optimal, it generally refers to global optimum of the whole system with respect to the objective features that are included in the intrinsic features of a system. The attainment of global optimum of a system must rely on the normal deployment of functions (features) of its subsystems. The word ‘system’ originates from Latin word syste¯ma meaning that a whole is made of several parts or members. Many different definitions had been made by scholars for system from different perspectives based on their particular research objectives. Let’s give some examples of them. “System is a pre-given set composed of elements and their normal behaviors”; “System is a well-organized wholeness”; “System is an entity made of connected materials and processes;” “System is a body composed of ordered elements/factors working towards a common goal” are some popular examples for the definition of system. The development of system theory and their applications in different field were mainly attributed to the contributions of scholars such as biologist Ludwig von Bertalanffy (1901–1972), Norbert Wiener (1894–1964), Ross Ashby (1903–1972), John Henry Holland (1929–2015), and Murray Gell-Mann (1929–2019). Bertalanffy pioneered the general system theory by introducing models, principles, and laws that apply to it. Wiener and Ashby used mathematics to study systems. Holland, Gell-Mann, and others proposed the term “complex adaptive system”. General system theory attempts to provide a definition that can capture common properties of various systems. The definition for general system is: a body composed of well-organized elements working toward attaining particular goals or features. This definition apparently includes 4 concepts and their relationships, namely system, element, structure, feature, relationships between elements, relationships between elements and structure, and relationships between system and external environment. The purpose of system theory is to investigate form, structure, and laws of general systems, to examine the common properties of those systems, to capture and illustrate their features using mathematical methods, and consequently to identify the mechanisms, rules, laws, principles, and mathematical models that can be applied to general systems. And the ultimate objective of learning system theory is to use the understanding on the system to better manage, control, renovate, or change the current system structures (natural or man-made systems) to align them with the needs of our civilized world. With better understanding on the system structures, we can introduce all kinds of interventions or policies to enable the systems of interest attain their optimal performance or outcomes. Moreover, by gaining better understanding on the dynamics of a system over time, decision/policy makers and practitioners can prevent policy-resistance (counter-intuitive behaviors). System theory is recognized a discipline that possesses both mathematical and logic characteristics. System theory proclaims that holism, connectedness, hierarchical structure, and dynamic equilibrium, time-dependence are common properties of all systems, which are both philosophy of system thinking and principles of using system approach. As a branch of scientific approaches, system theory helps identify the objective laws on how world is running and also offers human being a way of thinking the world. Therefore, system theory is also called system approach since it can represent concept, view, model, and mathematical methods as well. In Bertalanffy’s masterpiece titled “General System Theory; Foundations, Development, Applications”, he emphasized the concept of holism. System, as a organic body, is not mechanical combination or simple addition of its constituents but an organic combination of its elements working together towards a common goal. The system’s features are emerging behaviors, which can not be found in its individual elements or subsystems. By quoting Aristotle’s “A whole is greater than the sum of its part,” Bertalanffy opposed those mechanical philosophy that the wholeness (system behaviors) can be observed or inferred from the behavior of a particular element of the system. He also stated that each element of a system is in a particular location in the system hierarchy, which is also tightly coupled with other elements. The connectedness among system’s elements renders system integral and holistic. The “should-be” function of a system’s element will disappear once it is separated from the system structure. For example, having done the hand amputation due to traumatic injury, the removed ‘limb’ would never function as it should when it was an integral part of a person. The fundamental thoughts of system theory is to treat the object being investigated as a system and to analyze the structure, function, dynamic relationships between elements, system, and their environment. With better understanding on the dynamics, complexities, and uncertainties associated with the system, the ultimate goal is to find how it attain its optimal target and, consequently provide counterfactual analysis when interventions are needed to be implemented in the system. Systems are ubiquitous in the universe. From cosmos to the microscopic world, systems exist everywhere such as Milky Way, solar system, earth system, social system, transportation system, production system, human body system, bacterial system, cell system, and atom. The emergence of system theory brought profound changes on the way how people think about the world. In conventional research practices, Descartes’ philosophy of ‘reductionism’ had been dominating the academic fields. Under such influence, the general practice in research is to divide a complicated issue or object into multiple parts and investigate each part individually. Thereafter, the characteristics of those individual parts are then used to infer the behaviors of the original issue or object. The reductionisim approach focuses on local substructures or elements and abides by the unidirectional causal-effect determinism. Although this approach had proved valid for centuries within certain confined ranges and had served as the most popular way of thinking in mainstream research communities, it can only handle simple issues or objects without being able to capture the wholeness, dynamic interactions, and circular causalities of complicated objects (i.e., systems in the language of system theory). With accelerated development in economy, technology, and society, human beings with traditional analytical thinking became incompetent in dealing with issues/objects with thousands or even millions of variables connected/networked in various ways. However, the emergence of system theory, cybernetics, and informatics paved the way for human beings to drive the rapid advancement of modern science and technologies. The widespread applications of system theory have made it become the basis for developing new theories in handling complicated system in the fields of politics, economy, military, culture, science, and society, etc. Regarding the trend of system theory, the authors think it is moving towards the formation of unified framework that summarizes the achievements obtained from the empirical and theoretical research in different fields. System thinking ensued by system theory has become a very powerful force to overturn the ingrained singular causation thinking. For ease of studying system, many ways are used to categorize system: (1) natural systems and artificial systems (whether designed by human being or not); (2) natural systems, social systems, and thinking systems (according to research subject); (3) macro systems, mesa system, micro systems, and microscopic systems(scale of the systems); (4) simple systems, complex systems (in term of structure); (5) simple small systems, simple large systems, simple giant systems, and complex giant systems, etc.(scale and structure); (6) open systems, closed systems (whether there exists interaction with environment); (7) balanced systems (systems having equilibrium), non-equilibrium systems, near-equilibrium systems, and far-from-equilibrium systems (whether there exists equilibrium). © 2020, Springer Nature Switzerland AG.
",not included,2842,0.8164234161376953
10.1007/978-1-4842-9669-1_16,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),Grow Your Business with AI,Springer,2023-01-01 00:00:00,springer,selecting ai tools and platforms,http://dx.doi.org/10.1007/978-1-4842-9669-1_16,"Artificial intelligence (AI) has become a vital component for many businesses seeking to innovate, streamline operations, and gain competitive advantage. As this technology continues to evolve rapidly, the range of AI tools and platforms available for businesses has broadened significantly. As companies across industries look to harness the power of AI, the decision of selecting the right AI tools and platforms becomes critical to the success of their initiatives. This chapter aims to provide a comprehensive guide to help businesses navigate the complex landscape of AI tools and platforms, understand the advantages and drawbacks of each option, and make informed decisions that align with their unique needs, resources, and strategic objectives.",not included,1640,0.8163391351699829
10.1109/istas52410.2021.9629134,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Symposium on Technology and Society,2021-01-01 00:00:00,semantic_scholar,from value-lists to value-based engineering with ieee 7000™,https://www.semanticscholar.org/paper/77ac63e6beb6ff23aaa1c6a73bfc57e72ae7b841,"Digital ethics is currently being discussed worldwide as a necessity to create more reliable IT systems. This discussion, fueled by the fear of uncontrollable general artificial intelligence (AI) and by ethical dilemmas of existing systems, has moved many institutions and scientists to demand value principles that should guide the development of future IT systems. These usually include the demand for privacy, security, transparency, fairness, etc. This article shows why working through lists of values is insufficient for good or ethically aligned design. It will be shown how a truly ethical ‘Value-based Engineering’ (VbE) would have to look like instead, so that technical product innovation as a whole is put on better (more ethical) feet. VbE is a process-driven, holistic approach to system engineering which initially drew from the ideas of Value Sensitive Design and Ethical Computing. From 2016-2021 VbE was further fleshed out in the IEEE 7000™standardization project *.*This article presents inter alia guidance for ethical engineering given in the forthcoming IEEE 7000− standard. However, this article solely represents the views of the author and does not necessarily represent a position of either the IEEE P7000 Working Group, IEEE or the IEEE Standards Association. The official link to the IEEE P7000 is: https://sagroups.iece.org/7000/.",not included,984,0.8163038492202759
10.24963/ijcai.2018/718,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Joint Conference on Artificial Intelligence,2018-01-01 00:00:00,semantic_scholar,the facets of artificial intelligence: a framework to track the evolution of ai,https://www.semanticscholar.org/paper/169a674654f1634ded0fd5527dcb6630c8e261de,"We present nine facets for the analysis of the past and future evolution of AI. Each facet has also a set of edges that can summarise different trends and contours in AI. With them, we first conduct a quantitative analysis using the information from two decades of AAAI/IJCAI conferences and around 50 years of documents from AI topics, an official database from the AAAI, illustrated by several plots. We then perform a qualitative analysis using the facets and edges, locating AI systems in the intelligence landscape and the discipline as a whole. This analytical framework provides a more structured and systematic way of looking at the shape and boundaries of AI.",not included,91,0.8157639503479004
10.1109/transai60598.2023.00016,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2023 Fifth International Conference on Transdisciplinary AI (TransAI),IEEE,2023-09-27 00:00:00,ieeexplore,addressing critical issues and challenges for dynamic cybersecurity management in organisations and local/regional networks: the cs-aware-next project,https://ieeexplore.ieee.org/document/10387599/,"In our paper we present interactions between artificial intelligence (AI) and the field of cybersecurity. We present work of the Horizon Europe CS-AWARE-NEXT project that aims to provide improved cybersecurity management capabilities to organisations and local/ regional supply networks. Such organisations and networks operate in a highly dynamic cybersecurity environment, and must comply with European legislation such as the network and information security (NIS/NIS2) directive. Organisations increasingly understand that cybersecurity needs to be more dynamic and collaborative, building on a shared situational awareness of potential cybersecurity issues relevant to the organisations and networks in question. There is no doubt that there exists a cybersecurity shortfall in many organisations as the majority of their legacy systems have not been designed either to foster cybersecurity awareness, nor are they Artificial Intelligence / Machine Learning-ready, in terms of permitting models and algorithms to be deployed, or to interact with the application logic of the original systems. To remedy this, there is a need for experimenting with novel approaches to information systems engineering that can address needs emerging from the inclusion of dedicated Artificial Intelligence and Machine Learning modules and components to enable provisions for self-healing, self-protecting, and self-configuration.",not included,1778,0.8155702948570251
10.1701/2829.28580,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Recenti progressi in medicina,2017-01-01 00:00:00,semantic_scholar,[artificial intelligence in medicine: limits and obstacles.],https://www.semanticscholar.org/paper/0b848914f459531ddf5cad4f0dc475e210b3308c,"Data scientists and physicians are starting to use artificial intelligence (AI) even in the medical field in order to better understand the relationships among the huge amount of data coming from the great number of sources today available. Through the data interpretation methods made available by the recent AI tools, researchers and AI companies have focused on the development of models allowing to predict the risk of suffering from a specific disease, to make a diagnosis, and to recommend a treatment that is based on the best and most updated scientific evidence. Even if AI is used to perform unimaginable tasks until a few years ago, the awareness about the ongoing revolution has not yet spread through the medical community for several reasons including the lack of evidence about safety, reliability and effectiveness of these tools, the lack of regulation accompanying hospitals in the use of AI by health care providers, the difficult attribution of liability in case of errors and malfunctions of these systems, and the ethical and privacy questions that they raise and that, as of today, are still unanswered.",not included,188,0.8151605129241943
10.3233/jid-210013,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Journal of Integrated Design & Process Science,2021-01-01 00:00:00,semantic_scholar,integrating ai microservices into hard-real-time sos to ensure trustworthiness of digital enterprise using mission engineering,https://www.semanticscholar.org/paper/8bcde174b5bcce0661abff1b4390a605a51be9e7,"Due to the increased complexities and operating speeds of today’s and tomorrow’s system-of-systems (SoS) architectural configurations for digital enterprises, the design of new domain architecture management systems is required. A key element of these new designs will be the incorporation of Artificial Intelligence (AI) microservices to provide dynamically containerized and orchestrated service capabilities within a lightweight interoperability fabric with the ability to operate in hard-real-time environments. Each containerized AI microservice exposes an independent, programmable function, which enables it to be easily reused, evolved, or replaced without compromising interoperability across critical mission essential functions to execute mission threads. In addition, embedded in this design needs to be a trust management layer to enforce reliable messaging and trust amongst the actors. This paper provides a framework for planned research and demonstrates the feasibility of microservices using a representative simple problem to demonstrate the application of the framework. Early positive analysis results using AI microservices within an SoS environment shows that the 500 milli-second (ms) threshold for latency can be met.",not included,925,0.8149674534797668
10.1145/3293578.3298781,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Mexican Conference on Human-Computer Interaction,2018-01-01 00:00:00,semantic_scholar,identifying human-computer interaction patterns in support of the user interfaces design,https://www.semanticscholar.org/paper/e9c7c02a4ce6221d27f3a9182afdfd2cd4bc217a,"In the process of designing user interfaces (UI), when a designer makes use of the Human-Computer Interaction (HCI) patterns, generally it is found that they are multiple and abstract which makes the selection and interpretation of these patterns complicated. This article shows an overview and update of my research project for my PhD, that focuses on the identification of HCI patterns using Artificial Intelligence (AI) techniques. The results it seeks to promote the use of AI techniques in Requirements Engineering tasks.",not included,555,0.8147118091583252
10.1109/jsyst.2018.2876836,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),SCOPUS_ID:85056183083,scopus,2019-09-01 00:00:00,scopus,conceptualization of a system-of-systems in the defense domain: an experience report in the brazilian scenario,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85056183083&origin=inward,"
AbstractView references

National sovereignty and protection require a diversity of interdependent systems that jointly provide a large infrastructure for the national security, making possible a continuous monitoring and control. These systems assure the confidential information exchange while providing more complex functionalities when working together and forming alliances known as Systems-of-Systems (SoS). This paper reports an experience in the Brazilian defense scenario, externalizing the acquired knowledge in the form of lessons learned during the conduction of a real, strategic project called SisGAAz (Blue Amazon Management System), which has its main goal to develop the Brazilian navy management SoS. In particular, we focus on reporting our experience in the architectural design of this SoS as a quality driver in our project. We also raise challenges that were overcome, and also others that must still be faced. The results communicated herein contribute to deliver a panorama of the Brazilian state of the practice about SoS engineering. Such results are important, as they report the current situation and gaps to be bridged by both academics and practitioners, not only in Brazil but also worldwide, especially in those developing countries that are also living and implementing such technological revolution. © 2019 IEEE.
",not included,2895,0.814680278301239
10.1109/rws50334.2020.9241268,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2020 Resilience Week (RWS),IEEE,2020-10-23 00:00:00,ieeexplore,resilient data : an interdisciplinary approach,https://ieeexplore.ieee.org/document/9241268/,"Cybersecurity continues the migration toward data-informed solutions and the quality of the data is gaining in importance. Data accuracy is foundational to the trustworthiness required of artificial intelligence solutions. Trustworthy data must be accurate, robust, resistant and resilient to unauthorized modifications, going beyond traditional security solutions that perform data integrity checking. Cyber-physical systems present unique challenges with physical outcomes.Cyber-physical systems present unique challenges in achieving trustworthy data. The combination of security data and safety data is unique. Capturing both sets of data and determining the accuracy of that data requires an interdisciplinary approach. This effort describes the merging of information theory and information security constructs along with physical systems data. Knowledge is needed in control systems engineering, cybersecurity and information theory. As training data that informs decisions and feeds artificial intelligence algorithms accuracy and resilience are important.Resilient data is trustworthy data that represents a research challenge offering an opportunity to apply lessons learned from information disorders into the broader cybersecurity environment including the cyber-physical systems that power much of the US critical infrastructure. Creating resilient data, for use as training data requires data be examined in ways that have not historically been a part of traditional cybersecurity analysis. This effort describes a proposed method of contextually evaluating cyber-physical systems security data in order to determine the accuracy of the data and in the event of tampering, reconstitute the data to the last known trustworthy state.",not included,1817,0.814482569694519
10.1109/syseng.2017.8088273,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),SCOPUS_ID:85040117422,scopus,2017-10-26 00:00:00,scopus,model-based requirements engineering: architecting for system requirements with stakeholders in mind,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85040117422&origin=inward,"
AbstractView references

Specifying system requirements (SysReqs) is a critical activity in complex systems development. The SysReqs and emerging architecture are constructed through gradual and iterative transition from the problem domain and operational stakeholder requirements to the conceptual solution domain. They later constitute the basis for functional requirements elaborating, concept formation, technology selection, function-to-form allocation, and asset utilization. Only rarely can stakeholder requirements (SHRs) readily translate to SysReqs. Systems engineers must therefore elicit, analyze, and evolve the SysReqs, as these will radically affect the system's performance, robustness, endurance, and appeal. Model-Based Systems Engineering (MBSE) provides a framework for effective and consistent systems engineering and architecting. MBSE relies on modeling languages, such as Object-Process Methodology (OPM). OPM is a holistic MBSE paradigm and language for complex systems and processes, standardized as ISO 19450, which relies on the principle of minimal universal ontology. In this paper, we propose a model-based requirement engineering (MBRE) approach to facilitate the transition from SHRs to SysReqs, and from SysReqs to system architecture specification. We demonstrate the applicability of this framework in architecting a robotic baggage loading system for a leading international airport. © 2017 IEEE.
",not included,3120,0.8144716620445251
10.1109/iccicc53683.2021.9811311,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE International Conference on Cognitive Informatics and Cognitive Computing,2021-01-01 00:00:00,semantic_scholar,autonomous software requirement specifications towards ai programming,https://www.semanticscholar.org/paper/1fc59c04ed32cad26ea0573cd9f811abc0b801a0,"Autonomous software requirement specifications and code generation are not only an ultimate goal of AI Programming (AIP), but also a persistent challenge to theories and technologies of software engineering. A cognitive system is demanded to autonomously elicit and rigorously refine software requirements in order to generate a set of formal specifications as the front-end of AIP. This paper presents a novel methodology for the design of an Intelligent Tool for Autonomous Software Specifications (ITASS) based on latest advances in software science and intelligent mathematics. ITASS is implemented as an interactive system for capturing software requirements and generating mathematic-based specifications for code generation in the back-end of the AIP system. The ITASS methodology and experiments are demonstrated for solving real-world and complex software engineering problems enabled by the AIP theories underpinned by intelligent mathematics.",included,981,0.8142650127410889
10.1017/9781108616188.008,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Next-Generation Ethics,2017-01-01 00:00:00,semantic_scholar,guidelines for artificial intelligence containment,https://www.semanticscholar.org/paper/b0c820f9d7fa4d8c56a7887548834b7ba65ddfa5,"With almost daily improvements in capabilities of artificial intelligence it is more important than ever to develop safety software for use by the AI research community. Building on our previous work on AI Containment Problem we propose a number of guidelines which should help AI safety researchers to develop reliable sandboxing software for intelligent programs of all levels. Such safety container software will make it possible to study and analyze intelligent artificial agent while maintaining certain level of safety against information leakage, social engineering attacks and cyberattacks from within the container.",included,156,0.8141870498657227
10.1002/ajim.23037,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,American Journal of Industrial Medicine,2019-01-01 00:00:00,semantic_scholar,artificial intelligence: implications for the future of work.,https://www.semanticscholar.org/paper/cf4efa86481a961596e0d04050d6ff96e30e45e4,"Artificial intelligence (AI) is a broad transdisciplinary field with roots in logic, statistics, cognitive psychology, decision theory, neuroscience, linguistics, cybernetics, and computer engineering. The modern field of AI began at a small summer workshop at Dartmouth College in 1956. Since then, AI applications made possible by machine learning (ML), an AI subdiscipline, include Internet searches, e-commerce sites, goods and services recommender systems, image and speech recognition, sensor technologies, robotic devices, and cognitive decision support systems (DSSs). As more applications are integrated into everyday life, AI is predicted to have a globally transformative influence on economic and social structures similar to the effect that other general-purpose technologies, such as steam engines, railroads, electricity, electronics, and the Internet, have had. Novel AI applications in the workplace of the future raise important issues for occupational safety and health. This commentary reviews the origins of AI, use of ML methods, and emerging AI applications embedded in physical objects like sensor technologies, robotic devices, or operationalized in intelligent DSSs. Selected implications on the future of work arising from the use of AI applications, including job displacement from automation and management of human-machine interactions, are also reviewed. Engaging in strategic foresight about AI workplace applications will shift occupational research and practice from a reactive posture to a proactive one. Understanding the possibilities and challenges of AI for the future of work will help mitigate the unfavorable effects of AI on worker safety, health, and well-being.",not included,690,0.8140895366668701
10.1186/s12913-024-10894-4,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),BMC Health Services Research,BioMed Central,2024-04-03 00:00:00,springer,capturing artificial intelligence applications’ value proposition in healthcare – a qualitative research study,http://dx.doi.org/10.1186/s12913-024-10894-4,"Artificial intelligence (AI) applications pave the way for innovations in the healthcare (HC) industry. However, their adoption in HC organizations is still nascent as organizations often face a fragmented and incomplete picture of how they can capture the value of AI applications on a managerial level. To overcome adoption hurdles, HC organizations would benefit from understanding how they can capture AI applications’ potential. We conduct a comprehensive systematic literature review and 11 semi-structured expert interviews to identify, systematize, and describe 15 business objectives that translate into six value propositions of AI applications in HC. Our results demonstrate that AI applications can have several business objectives converging into risk-reduced patient care, advanced patient care, self-management, process acceleration, resource optimization, and knowledge discovery. We contribute to the literature by extending research on value creation mechanisms of AI to the HC context and guiding HC organizations in evaluating their AI applications or those of the competition on a managerial level, to assess AI investment decisions, and to align their AI application portfolio towards an overarching strategy.",not included,1420,0.8139474391937256
10.1145/3363384.3363481,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Halfway to the Future Symposium,2019-01-01 00:00:00,semantic_scholar,beyond hci and cscw: challenges and useful practices towards a human-centred vision of ai and ia,https://www.semanticscholar.org/paper/e1a062e4129aec6201c98ee96f2025be51996cef,"Over the decades, technologies envisioned by pioneers such as Douglas Engelbart are becoming a reality. AI has become an important driver for technological progress, posing questions for the future of human-computer interaction. Our research group at Fraunhofer FIT looks back on a 51 year long research tradition that started with Engelbart’s vision and followed through the larger developments of HCI from the introduction of CSCW up to successful projects involving the engineering of large software systems in practice. In this paper, we outline the history of our institute against the background of trends in HCI, working out the cornerstones and “useful practices” from our research tradition towards our vision of the future of a human-centred AI/IA, with the expectation that this analysis may be useful for similar organisations. In doing so, we illustrate tensions between theory and application, humans and technology, and show how keeping those aspects in balance is an important challenge and chance for bringing disruptive emerging technologies successfully into practice.",not included,673,0.8134079575538635
10.5130/acis2018.bp,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,ACIS,2018-01-01 00:00:00,semantic_scholar,ontology in software engineering,https://www.semanticscholar.org/paper/35b197d779e879b095921f6eef391efbe1c7eb9a,"During the past years, ontological thinking and design have become more and more popular in the field of Artificial Intelligence (AI). More recently, Software Engineering (SE) has evolved towards more conceptual approaches based on the extensive adoption of models and meta-models. This paper briefly discusses the role of ontologies in SE according to a perspective that closely matches the theoretical life-cycle. These roles vary considerably across the development lifecycle. The use of ontologies to improve SE development activities is still relatively new (2000 onward), but it is definitely no more a novelty. Indeed, the role of such structures is well consolidated in certain SE aspects, such as requirement engineering. On the other hand, despite their well-known potential as knowledge representation mechanisms, ontologies are not completely exploited in the area of SE. We first (i) proposes a brief overview of ontologies and their current understanding within the Semantic Web with a focus on the benefits provided; then, the role that ontologies play in the more specific context of SE is addressed (ii); finally, we deal with (iii) some brief considerations looking at specific types of software architecture, such as Multi-Agent Systems (MAS) and Service-Oriented Architecture (SOA). The main limitation of our research is that we are focusing on traditional developments, where phases occur mostly sequentially. However, industry has fully embraced agile developments. It is unclear that agile practitioners are willing to adopt ontologies as a tool, unless we ensure that they can provide a clear benefit and they be used in a lean way, without introducing significant overhead to the agile development process.",not included,378,0.8133354783058167
10.54364/aaiml.2023.1156,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Advances in Artificial Intelligence and Machine Learning,2019-01-01 00:00:00,semantic_scholar,superintelligence safety: a requirements engineering perspective,https://www.semanticscholar.org/paper/1e9c639bb2221483575b27cc99c3a448ba894270,"Under the headline “AI safety”, a wide-reaching issue is being discussed, whether in the future some “superhuman artificial intelligence” / “superintelligence” could pose a threat to humanity. In addition, the late Steven Hawking warned that the rise of robots may be disastrous for mankind. A major concern is that even benevolent superhuman artificial intelligence (AI) may become seriously harmful if its given goals are not exactly aligned with ours, or if we cannot specify precisely its objective function. Metaphorically, this is compared to king Midas in Greek mythology, who expressed the wish that everything he touched should turn to gold, but obviously this wish was not specified precisely enough. In our view, this sounds like requirements problems and the challenge of their precise formulation. (To our best knowledge, this has not been pointed out yet.) As usual in requirements engineering (RE), ambiguity or incompleteness may cause problems. In addition, the overall issue calls for a major RE endeavor, figuring out the wishes and the needs with regard to a superintelligence, which will in our opinion most likely be a very complex software-intensive system based on AI. This may even entail theoretically defining an extended requirements problem.",included,704,0.8132004737854004
10.1109/autotestcon47462.2022.9984783,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2022 IEEE AUTOTESTCON,IEEE,2022-09-01 00:00:00,ieeexplore,test and evaluation harnesses for learning systems,https://ieeexplore.ieee.org/document/9984783/,"There is an increasing demand for operational uses of machine learning (ML), however, a lack of best practices for test and evaluation (T &E) of learning systems is a hindrance to supply. This manuscript proposes a new framework for best practices, described as T &E harnesses, that corresponds principally to the task of engineering a learning system-in contrast to the status quo task of solving a learning problem. The primary difference is a question of scope. This manuscript places T &E for ML into the broader scope of systems engineering processes. Importantly, two challenge problems, acquisition and operations, are used to motivate the use of T &E harnesses for learning systems. This manuscript draws from recent findings in experimental design for ML, combinatorial interaction testing of ML solutions, and the general systems modeling of ML. The concept of T &E harnesses is closely tied to existing models of systems engineering processes. We draw the conclusion that existing best practices for T &E form a subset of what is needed to rigorously test for system-level satisfaction of stakeholder needs.",not included,1824,0.8130490779876709
10.1145/3278721.3278766,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,"AAAI/ACM Conference on AI, Ethics, and Society",2018-01-01 00:00:00,semantic_scholar,regulating for 'normal ai accidents': operational lessons for the responsible governance of artificial intelligence deployment,https://www.semanticscholar.org/paper/83d1769a9aee035698b13273130841af03e66a87,"New technologies, particularly those which are deployed rapidly across sectors, or which have to operate in competitive conditions, can disrupt previously stable technology governance regimes. This leads to a precarious need to balance caution against performance while exploring the resulting 'safe operating space'. This paper will argue that Artificial Intelligence is one such critical technology, the responsible deployment of which is likely to prove especially complex, because even narrow AI applications often involve networked (tightly coupled, opaque) systems operating in complex or competitive environments. This ensures such systems are prone to 'normal accident'-type failures which can cascade rapidly, and are hard to contain or even detect in time. Legal and governance approaches to the deployment of AI will have to reckon with the specific causes and features of such 'normal accidents'. While this suggests that large-scale, cascading errors in AI systems are inevitable, an examination of the operational features that lead technologies to exhibit 'normal accidents' enables us to derive both tentative principles for precautionary policymaking, and practical recommendations for the safe(r) deployment of AI systems. This may help enhance the safety and security of these systems in the public sphere, both in the short- and in the long term.",not included,93,0.8128957748413086
http://arxiv.org/abs/2112.01226v1,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),arxiv,arxiv,2021-10-31 00:00:00,arxiv,"role of artificial intelligence, clinicians & policymakers in clinical
  decision making: a systems viewpoint",http://arxiv.org/abs/2112.01226v1,"What is a system? Is one of those questions that is yet not clear to most
individuals in this world. A system is an assemblage of interacting,
interrelated and interdependent components forming a complex and integrated
whole with an unambiguous and common goal. This paper emphasizes on the fact
that all components of a complex system are inter-related and interdependent in
some way and the behavior of that system depends on these independences. A
health care system as portrayed in this article is widespread and complex. This
encompasses not only hospitals but also governing bodies like the FDA,
technologies such as AI, biomedical devices, Cloud computing and many more. The
interactions between all these components govern the behavior and existence of
the overall healthcare system. In this paper, we focus on the interaction of
artificial intelligence, care providers and policymakers and analyze using
systems thinking approach, their impact on clinical decision making",included,45,0.8128914833068848
10.1111/exsy.12234,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Expert Syst. J. Knowl. Eng.,2017-01-01 00:00:00,semantic_scholar,special issue on innovative techniques and applications of artificial intelligence guest editorial,https://www.semanticscholar.org/paper/e0d339135039cb48a347202b015740392fb3ff69,"As a continuation of a fruitful experimental collaboration between BCS Specialist Group in Artificial Intelligence and Expert Systems: The Journal of Knowledge Engineering, this special issue is dedicated to extended and upgraded original contributions of the three best paper submissions presented at the flagship conference AI‐2012, the thirty‐second SGAI International Conference on Artificial Intelligence, which was held in Cambridge, England, from December 11th to 13th, 2012. The AI‐2012 conference is the 32nd annual event of BCS SGAI in the leading series of UK‐based international conferences on Artificial Intelligence and one of the longest running AI conference series in Europe. SGAI, the Specialist Group on Artificial Intelligence (www.bcs‐sgai. org) of the British Computer Society, is one of the longest serving specialist groups of the British Computer Society, and a member of ECCAI, the European Co‐ordinating Committee on Artificial Intelligence. BCS SGAI AI‐2012 is part of the series of conferences that has run annually without a break since 1981 on developments in AI and sharing experiences in the practical issues of developing AI systems. All conference papers are peer‐reviewed by an international panel of world‐renowned expert referees, and a specialist committee prioritises their votes for the best paper awards of each stream. The best original conference papers were selected by the AI‐2012 programme committees as the most relevant voted papers for each of the three streams: the technical stream, the application stream, and the young researcher (student) contribution. The expanded versions of the papers containing substantial additional work are the result of the invitation to be submitted to and peer‐reviewed independently for the inclusion in this journal special issue by the special issue editorial board of the journal. The accepted extended versions of the best three BCS‐SGAI AI‐2012 papers are summarised below.",not included,150,0.812765896320343
10.1109/syscon53536.2022.9773890,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2022 IEEE International Systems Conference (SysCon),IEEE,2022-04-28 00:00:00,ieeexplore,creating a digital twin of an insider threat detection enterprise using model-based systems engineering,https://ieeexplore.ieee.org/document/9773890/,"Inference Enterprise Modeling (IEM) is a methodology developed to address test and evaluation limitations that insider threat detection enterprises face due to a lack of ground truth and/or missing data. IEM uses a collection of statistical, data processing, analysis, and machine learning techniques to estimate and forecast the performance of these enterprises. As part of developing the IEM method, models satisfying various detection system evaluation requirements were created. In this work, we extend IEM as a digital twin generation technique by representing modeled processes as executable UML Activity Diagrams and tracing solution processes to problem requirements using ontologies. Using the proposed framework, we can rapidly prototype a digital twin of a detection system that can also be imported and executed in systems engineering simulation software tools such as Cameo Enterprise Architecture Simulation Toolkit. Cyber security and threat detection is a continuous process that requires regular maintenance and testing throughout its lifecycle, but there often exists access issues for sensitive and private data and proprietary detection model details to perform adequate test and evaluation activities in the live production environment. To solve this issue, organizations can use a digital twin technique to create a real-time virtual counterpart of the physical system. We describe a method for creating digital twins of live and/or hypothetical insider threat detection enterprises for the purpose of performing test and evaluation activities on continuous monitoring systems that are sensitive to disruptions. In this work, we use UML Activity Diagrams to leverage the integrated simulation capabilities of Model-Based Systems Engineering (MBSE).",included,1744,0.8124027252197266
10.1109/isse54508.2022.10005383,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2022 IEEE International Symposium on Systems Engineering (ISSE),IEEE,2022-10-26 00:00:00,ieeexplore,patients’ perceptions of integrating ai into healthcare: systems thinking approach,https://ieeexplore.ieee.org/document/10005383/,"Artificial intelligence (AI) has become more integrated into healthcare with a promising future. The expansion and application of Artificial Intelligence depend on technologies, policymakers, healthcare providers, as well as patients. Nevertheless, how to systematically understand AI interventions from the patients' perspectives should be further explored. In this paper, we first outline patients' perceptions of integrating AI into healthcare systems through a brief survey-based case study. Next, we emphasized the challenges and concerns of applying AI to complex healthcare systems while considering the components' interactions. Then a three-layer structure was proposed to highlight the complexity of Human-AI-Technology interactions linked to the governance system. Moreover, a causal loop diagram (CLD) is established to analyze the dynamic and causality of the adoption of AI in healthcare inspired by the systems thinking approach to help understand the patients' attitudes and perceptions of the whole picture.",included,1849,0.811959445476532
10.1109/mts.2018.2876105,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE technology & society magazine,2018-01-01 00:00:00,semantic_scholar,assessing artificial intelligence for humanity: will ai be the our biggest ever advance ? or the biggest threat [opinion],https://www.semanticscholar.org/paper/12b6335e9c5c824b885b857f3f9d3ac98a2ad63b,"Recent rapid advancements in artificial intelligence (AI) are arguably the most important dimension of humanity’s progress to date. As members of the human race, that is, homo sapiens, we are defined by our capacity for cognition. Until now, humans were the only species capable of higher cognitive functions. But today AI has advanced to a stage where on many cognitionrelated tasks it can match and even surpass the performance of humans. Examples include not only AI’s spectacular successes in winning Go, chess, and other board games with humans, and in surpassing humans on fully defined world puzzles. But AI is also now achieving extremely high efficiency in practical applications such as speech and object recognition, self-driving cars, intelligent tutoring systems, efficient decision support systems, and in the capacity to detect patterns in Big Data and in constructing accurate models of social behavior. Thus, for the first time in history, we must ask ourselves: “has our monopoly on intelligence, however defined, been challenged?”",not included,90,0.8119093775749207
10.1007/978-3-030-60117-1_32,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),SCOPUS_ID:85094144617,scopus,2020-01-01 00:00:00,scopus,safety analytics for ai systems,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85094144617&origin=inward,"
AbstractView references

Growing AI technologies are a threat to safety and security in systems due to its obscurity and uncertainty. This study introduces a prevailing Deep Learning model, Convolutional Neural Network (CNN) and it’s deep weaknesses through a simple case study of the CNN model based on Keras for handwriting recognition. It reveals that CNN algorithms don’t adapt well to changes. Adding new cases to the training data may improve accuracy, but not to the same level as before. Synthetic training data may improve the accuracy superficially because of the similarity of data distributions between generated data and original data. Prevailing ML models such as Generative Adversarial Networks (GAN) have their limitations such as similarity-addiction and modality collapse. They could be toxic to safety engineering without domain expertise. The study proposed four test strategies: 1) AI systems should be tested by the third parties, not the developers; 2) test datasets should be categorically different from training datasets; the test data should not be a part of the training data; the test data should be collected from independent sources to increase the “diversity” of data modality; 3) avoid fake data, or simulated data; and 4) don’t collect the data that are conveniently available, but actively collect disastrous event data, unexpected, or the worst scenarios that may destroy the model. The study also introduces a multidimensional checklist for AI safety analysis, including sensors, data and environments, default and recovery mode, system architectures, and human-system interaction. © 2020, Springer Nature Switzerland AG.
",included,2827,0.8118554949760437
10.1177/15553434221097357,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Journal of Cognitive Engineering and Decision Making,2022-01-01 00:00:00,semantic_scholar,a sociotechnical systems framework for the application of artificial intelligence in health care delivery,https://www.semanticscholar.org/paper/f47fe4e6a34083f5f9a48cf281acfdd1fe52c1ea,"In the coming years, artificial intelligence (AI) will pervade almost every aspect of the health care delivery system. AI has the potential to improve patient safety (e.g., diagnostic accuracy) as well as reduce the burden on clinicians (e.g., documentation-related workload); however, these benefits are yet to be realized. AI is only one element of a larger sociotechnical system that needs to be considered for effective AI application. In this paper, we describe the current challenges of integrating AI into clinical care and propose a sociotechnical systems (STS) approach for AI design and implementation. We demonstrate the importance of an STS approach through a case study on the design and implementation of a clinical decision support (CDS). In order for AI to reach its potential, the entire work system as well as clinical workflow must be systematically considered throughout the design of AI technology.",included,1408,0.8117738962173462
10.1109/sose52839.2021.00028,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Symposium on Service Oriented Software Engineering,2021-01-01 00:00:00,semantic_scholar,model-based test modeling and automation tool for intelligent mobile apps,https://www.semanticscholar.org/paper/bee60aa8343ae0057ce24cea34df4302e0f916f7,"Functionalities of AI-powered mobile Apps or systems heavily depend on the given training dataset. The challenge in this case is that a learning system will change its behavior due to a slight change of dataset. While current alternative approaches for evaluating these apps either focus on individual performance measurement such as accuracy etc. Inspired by principles of the decision tree test method in software engineering, we introduce a 3D decision tree testing model for AI testing, a combined AI feature input tree, context tree, and output tree methodology for testing AI-powered applications. We report a newly developed AI test automation tool (known as AITest), which is built and implemented based on an innovative 3D AI Test model for AI-powered functions in intelligent mobile apps to support model-based AI function testing, test data generation, and auto test scripting and execution, and adequate test coverage analysis. Furthermore, the tool infrastructure, components, sample applications, and case study results are presented.",included,1061,0.8117448687553406
10.1109/jsyst.2017.2725920,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),IEEE Systems Journal,IEEE,2018-09-01 00:00:00,ieeexplore,a human–machine methodology for investigating systems thinking in a complex corpus,https://ieeexplore.ieee.org/document/7990334/,"Systems thinking characterizes the paradigm needed to effectively design, maintain, and utilize systems. Prior work has shown that there is a language of systems thinking and that its presence can be quantified within text using supervised learning methods. Building on this foundation, we present a human-in-the-loop methodology that utilizes topic models to facilitate the identification of systems thinking within a corpus of documents. Though explorative, it requires no manual grading of documents, which makes it significantly faster than previous methods. The methodology uses each document's topic proportion within a systems thinking topic as a proxy measure for the potential of strong systems thinking. The novel aspect of the methodology is in the seeding of the corpus; the user encourages the emergence of the systems thinking topic by adding several documents that demonstrate strong systems thinking to the corpus. Additionally, seeding could be used with concepts other than systems thinking. A Tukey test on a graded corpus reveals that the top echelons of strong systems thinking papers have significantly higher mean topic proportions in the systems thinking topic than lower graded papers. Additionally, a case study on a corpus of Army documents related to the development, character, and management of soldiers demonstrates the methodology's effectiveness in overviewing a system and in providing research direction. The definition of strong systems thinking and the interpretation of topics are subjective, but the methodology overcomes this hurdle by leveraging human intuition and keeping a human in the loop.",not included,1851,0.8115895986557007
http://arxiv.org/abs/2101.03989v2,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),arxiv,arxiv,2021-01-11 00:00:00,arxiv,technology readiness levels for machine learning systems,http://arxiv.org/abs/2101.03989v2,"The development and deployment of machine learning (ML) systems can be
executed easily with modern tools, but the process is typically rushed and
means-to-an-end. The lack of diligence can lead to technical debt, scope creep
and misaligned objectives, model misuse and failures, and expensive
consequences. Engineering systems, on the other hand, follow well-defined
processes and testing standards to streamline development for high-quality,
reliable results. The extreme is spacecraft systems, where mission critical
measures and robustness are ingrained in the development process. Drawing on
experience in both spacecraft engineering and ML (from research through product
across domain areas), we have developed a proven systems engineering approach
for machine learning development and deployment. Our ""Machine Learning
Technology Readiness Levels"" (MLTRL) framework defines a principled process to
ensure robust, reliable, and responsible systems while being streamlined for ML
workflows, including key distinctions from traditional software engineering.
Even more, MLTRL defines a lingua franca for people across teams and
organizations to work collaboratively on artificial intelligence and machine
learning technologies. Here we describe the framework and elucidate it with
several real world use-cases of developing ML methods from basic research
through productization and deployment, in areas such as medical diagnostics,
consumer computer vision, satellite imagery, and particle physics.",included,57,0.8114748001098633
10.1609/aimag.v40i3.5181,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,The AI Magazine,2019-01-01 00:00:00,semantic_scholar,reports of the aaai 2019 spring symposium series,https://www.semanticscholar.org/paper/49c9b0776f3119ea5eb29ee18d89b94cfca6f939,"
 
 
The AAAI 2019 Spring Series was held Monday through Wednesday, March 25–27, 2019 on the campus of Stanford University, adjacent to Palo Alto, California. The titles of the nine symposia were Artificial Intelligence, Autonomous Machines, and Human Awareness: User Interventions, Intuition and Mutually Constructed Context; Beyond Curve Fitting — Causation, Counterfactuals and Imagination-Based AI; Combining Machine Learning with Knowledge Engineering; Interpretable AI for Well-Being: Understanding Cognitive Bias and Social Embeddedness; Privacy- Enhancing Artificial Intelligence and Language Technologies; Story-Enabled Intelligence; Towards Artificial Intelligence for Collaborative Open Science; Towards Conscious AI Systems; and Verification of Neural Networks. 
 
 
",not included,735,0.8113674521446228
10.1007/978-3-030-47124-8_40,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),SCOPUS_ID:85088453211,scopus,2021-01-01 00:00:00,scopus,zadehian paradigms shaping 21<sup>st</sup> century artificial intelligence,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85088453211&origin=inward,"
AbstractView references

Starting from the premise that Zadeh’s research heritage is irreducible to his 20th Century work, the paper aims to show that his Generalized Theory of Uncertainty is even more influential now, for 21st Century service-oriented engineering, than his papers on fuzzy sets were for the product-based industrial era. To mirror the whole architectonics of Zadeh’s work, the paper highlights the lasting puissance and evolution of 20th Century Zadehian paradigms. On this groundwork, two paradigmatic breakthroughs follow: (a) moving from ‘information is statistical in nature’ to ‘information is a generalized constraint’; (b) setting as target ‘achievement of NL-capability’. Next, two cardinal upshots: reshaping the relation between numbers and words and scaling down the importance of algorithmic paradigms. Both are needed to meet the challenge of modern artificial intelligence: interacting with living systems; emphasis is on model tractability (for efficiency) and on model interpretability (for user acceptance). © 2021, Springer Nature Switzerland AG.
",not included,2757,0.8105475902557373
10.1080/10447318.2022.2086033,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International journal of human computer interactions,2022-01-01 00:00:00,semantic_scholar,insight into user acceptance and adoption of autonomous systems in mission critical environments,https://www.semanticscholar.org/paper/265e0035527bdf048deaff1db372647be8f08f95,"Abstract With Industry 4.0 the immense progression of Artificial Intelligence (AI) technology has introduced new challenges for engineers to effectively design human-automation interaction in autonomous systems that are mission critical. Although various autonomous systems are currently being utilized in mission critical environments, there is limited literature and research on which factors affect the acceptance and adoption of said systems. Understanding which factors are most critical for the human-automation interaction could lead to seamless acceptance and adoption and more effective and less expensive missions. Findings of 47 semi-structured interviews revealed ease of use and system reliability to be significant factors for the acceptance and adoption of autonomous systems independent of the level of automation. Through our findings we expand on the current technology acceptance models by including mission critical factors. Emphasis is given to the discussion and consideration of the human factors and engineering approaches associated with the design of autonomous systems for mission critical environments that are needed to empower tomorrow’s users with effective AI systems technology.",not included,1246,0.8103929758071899
10.1109/ice.2018.8436265,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,"International Conference on Engineering, Technology and Innovation",2018-01-01 00:00:00,semantic_scholar,the key concepts of ethics of artificial intelligence,https://www.semanticscholar.org/paper/82afc6e1e3aa05e957e77db2343ef39f5f312b81,"The growing influence and decision-making capacities of Autonomous systems and Artificial Intelligence in our lives force us to consider the values embedded in these systems. But how ethics should be implemented into these systems? In this study, the solution is seen on philosophical conceptualization as a framework to form practical implementation model for ethics of AI. To take the first steps on conceptualization main concepts used on the field needs to be identified. A keyword based Systematic Mapping Study (SMS) on the keywords used in AI and ethics was conducted to help in identifying, defying and comparing main concepts used in current AI ethics discourse. Out of 1062 papers retrieved SMS discovered 37 re-occurring keywords in 83 academic papers. We suggest that the focus on finding keywords is the first step in guiding and providing direction for future research in the AI ethics field.",not included,105,0.8103669881820679
http://arxiv.org/abs/2307.04495v1,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),arxiv,arxiv,2023-07-10 00:00:00,arxiv,"model-driven engineering method to support the formalization of machine
  learning using sysml",http://arxiv.org/abs/2307.04495v1,"Methods: This work introduces a method supporting the collaborative
definition of machine learning tasks by leveraging model-based engineering in
the formalization of the systems modeling language SysML. The method supports
the identification and integration of various data sources, the required
definition of semantic connections between data attributes, and the definition
of data processing steps within the machine learning support.
  Results: By consolidating the knowledge of domain and machine learning
experts, a powerful tool to describe machine learning tasks by formalizing
knowledge using the systems modeling language SysML is introduced. The method
is evaluated based on two use cases, i.e., a smart weather system that allows
to predict weather forecasts based on sensor data, and a waste prevention case
for 3D printer filament that cancels the printing if the intended result cannot
be achieved (image processing). Further, a user study is conducted to gather
insights of potential users regarding perceived workload and usability of the
elaborated method.
  Conclusion: Integrating machine learning-specific properties in systems
engineering techniques allows non-data scientists to understand formalized
knowledge and define specific aspects of a machine learning problem, document
knowledge on the data, and to further support data scientists to use the
formalized knowledge as input for an implementation using (semi-) automatic
code generation. In this respect, this work contributes by consolidating
knowledge from various domains and therefore, fosters the integration of
machine learning in industry by involving several stakeholders.",included,25,0.8103031516075134
10.1109/tse.2021.3106280,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE Transactions on Software Engineering,2021-01-01 00:00:00,semantic_scholar,socio-technical grounded theory for software engineering,https://www.semanticscholar.org/paper/7abac45941d30b162e93ba6c5203d1ccc955c585,"Grounded Theory (GT), a sociological research method designed to study social phenomena, is increasingly being used to investigate the human and social aspects of software engineering (SE). However, being written by and for sociologists, GT is often challenging for a majority of SE researchers to understand and apply. Additionally, SE researchers attempting ad hoc adaptations of traditional GT guidelines for modern socio-technical (ST) contexts often struggle in the absence of clear and relevant guidelines to do so, resulting in poor quality studies. To overcome these research community challenges and leverage modern research opportunities, this paper presents Socio-Technical Grounded Theory (STGT) designed to ease application and achieve quality outcomes. It defines what exactly is meant by an ST research context and presents the STGT guidelines that expand GT's philosophical foundations, provide increased clarity and flexibility in its methodological steps and procedures, define possible scope and contexts of application, encourage frequent reporting of a variety of interim, preliminary, and mature outcomes, and introduce nuanced evaluation guidelines for different outcomes. It is hoped that the SE research community and related ST disciplines such as computer science, data science, artificial intelligence, information systems, human computer/robot/AI interaction, human-centered emerging technologies (and increasingly other disciplines being transformed by rapid digitalisation and AI-based augmentation), will benefit from applying STGT to conduct quality research studies and systematically produce rich findings and mature theories with confidence.",not included,1015,0.8101922869682312
10.1109/iccicc53683.2021.9811324,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE International Conference on Cognitive Informatics and Cognitive Computing,2021-01-01 00:00:00,semantic_scholar,ieee icci*cc series in year 20: latest advances in cognitive informatics and cognitive computing towards general ai (plenary panel report-i),https://www.semanticscholar.org/paper/c08c5016aa6784b37b32aa0215bae45f8e47bbe4,"Cognitive Informatics (CI) and Cognitive Computing (CC) are fundamental intelligence theories and general AI technologies triggered by the transdisciplinary advances in intelligence, computer, brain, knowledge, cognitive, robotic, and cybernetic sciences for engineering implementations. This paper presents a summary of the plenary panel (Part I) on the theoretical foundations of CI/CC as well recent breakthroughs in AI engineering reported in the 20th IEEE International ICCI*CC Conference (ICCI*CC'21). The latest advances in CI and CC towards general AI are presented by twenty-two distinguished panelists. Strategic AI engineering applications in CI, CC, and cognitive systems are elaborated for abstract intelligence, general AI, cognitive robots, autonomous systems, intelligent vehicles, and safety-and-mission-critical systems.",not included,954,0.8100847601890564
10.1109/smc42975.2020.9282836,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),"2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",IEEE,2020-10-14 00:00:00,ieeexplore,toward a mbse research testbed: prototype implementation and lessons learned,https://ieeexplore.ieee.org/document/9282836/,"As Model Based Systems Engineering (MBSE) continues to advance in terms of system life cycle coverage, modeling languages, methods, and tools, there is a growing need of an overarching framework for organizing MBSE artifacts that facilitates their rapid retrieval and use by MBSE researchers. At the same time, researchers must have an environment supportive of exploring, experimenting with, and collecting performance data when using potentially heterogenous modeling constructs and algorithms over broad ranges of conditions and assumptions. These requirements jointly imply the need for a MBSE research testbed that enables experimentation with diverse modeling, analysis, simulation, verification, and validation approaches under nominal and off-nominal conditions, collect and analyze data to uncover patterns and trends, reuse models and components as applicable, and serve as a repository for scenarios, models, case studies, and lessons learned. This paper presents progress to date and lessons learned from the prototype MBSE testbed implementation.",not included,1830,0.8098418712615967
10.1007/978-3-031-29053-4_5,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),The AI-Enabled Enterprise,Springer,2023-01-01 00:00:00,springer,democratized hyper-automated software development,http://dx.doi.org/10.1007/978-3-031-29053-4_5,"Modern enterprises are evolving into a complex system of systems that need to deliver stated goals while operating in a dynamic and uncertain environment. Given the ever-increasing pervasiveness of software, enterprises are relying heavily on software systems to address a variety of adaptive needs at strategy, process and system levels. The demand-supply situation for trained software developers is already skewed, and the skew is likely to increase further with time. Recent advances in AI techniques in general and Generative AI in particular may lead to a promising solution wherein Subject Matter Experts are empowered to play a greater and more direct role in software development. This chapter motivates the need, proposes a pragmatic line of attack and discusses technology enablers to support this line of attack.",not included,1625,0.8098028302192688
10.1109/syscon48628.2021.9447091,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE Systems Conference,2021-01-01 00:00:00,semantic_scholar,system level knowledge representation for complexity,https://www.semanticscholar.org/paper/0be5103e7414f164d206bea9b01ab06feca0f9d9,"To develop systems capable of high level cognitive functions such as intelligence, it is necessary to formally capture different types of knowledge, so that they can be used to support complex processes, such as inference and reasoning. The design and engineering of Intelligent Systems to support large distributed socio technical processes increasingly leverages converging techniques from Artificial Intelligence, Knowledge Representation (KR) and Cognitive Architectures. This is resulting in multi layered architectures and AI technologies which one the one hand offer unprecedented capabilities, on the other hand present innumerable, often inconceivable risks. Sophisticated conceptual structures are necessary not only to support the modeling, validation and explanation of complex engineered systems, but primarily to support cognition and conceptualization of the complexities involved, for designers, developers, end users and any stakeholder. Depending on the cognitive makeup of observers, and on the knowledge available, complexity can be conceptualized and traversed following a diversity of methods and patterns. Sometimes complexity can be broken down into cognitively accessible chunks, in other cases however, it cannot be broken down without losing essential information about the system as a whole. Addressing the need to develop cognitive artifacts, methods and techniques that can capture and represent complexity, this paper proposes the outline of conceptual structure that bridges existing approaches which tend to distinguish between cognitive engineering and Knowledge Representation, with the aim to integrate technical and socio technical systems dimensions. The paper presents considerations about cognitive aspects of complex systems theory and practice. It anticipates a convergence between cognitive architectures and KR, introduces the notion of System Level Knowledge Representation and applies it to navigate socio technical complexity in systems engineering. A summary of related work where the System Level Knowledge Representation is being developed and evaluated is also provided.",not included,1065,0.8096051812171936
10.1145/3578527.3578548,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),SCOPUS_ID:85149125083,scopus,2023-02-23 00:00:00,scopus,a modeling language for novice engineers to design well at saas product companies,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85149125083&origin=inward,"
AbstractView references

Software-as-a-Service (SaaS) product companies have brought in significant changes in how we build software from architecture and engineering process perspective. SaaS products are large, distributed software systems hosted in cloud and built using collaborating services (or micro-services). The software releases happen in days and weeks, necessitating an agile development process. Novice engineers (those who join the company fresh from college) need to become comfortable with complex systems and proficient in agile delivery with high quality, otherwise they fall behind in productivity. The paper posits that, to be successful at these SaaS product companies, the novice engineers need good modeling and design skills. While this has been for all software development, the changes driven by SaaS products have made this need more acute. Such skills will allow them to capture their feature behaviors (in context of their understanding of the larger product) in an implementation-independent manner and any knowledge gaps can be identified and bridged by their collaborators. We propose a modeling language that is easy for them to learn and use, and which has characteristics suitable for the kind of engineering work they need to do in their early years in a SaaS product company. This modeling language is based on the notion of Transition Systems. The paper demonstrates the usage and value of this language by creating a model for a real feature. The modeling language is quite general and transcends abstraction boundaries. We also present a modeling process that should be used with this language for better results. This is a short position paper that presents an idea about a new modeling language for a specific purpose (helping novice engineers design well at SaaS product companies). Validation studies for the language and the design process is a work in progress and the results will be shared in a full paper later. © 2023 ACM.
",not included,2181,0.8095322847366333
10.1007/978-3-031-42622-3_23,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),Collaborative Networks in Digitalization and Society 5.0,Springer,2023-01-01 00:00:00,springer,a maturity model for collaborative agents in human-ai ecosystems,http://dx.doi.org/10.1007/978-3-031-42622-3_23,"AI entities lean on the aspects of their autonomy to carry out their tasks and perform intelligently. But when these entities collaborate in human-AI teams, their levels of autonomy and collaboration have to be balanced out. We present a maturity model for agents regarding this aspect of balancing. Whereas simple AI systems use pre-designed mechanisms, more advanced systems are able to learn this from experience. The maturity model is a two-dimensional matrix in which the degree of agency forms the horizontal axis, and the level of interaction the vertical axis. We validate the use of this maturity model with use-cases in the field of urban energy efficiency.",included,1662,0.809422492980957
10.1109/ms.2022.3193975,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE Software,2022-01-01 00:00:00,semantic_scholar,taming data quality in ai-enabled industrial internet of things,https://www.semanticscholar.org/paper/8df4c04b25a24a8d941ed50401d92faf183ade63,We address the problem of taming data quality in artificial intelligence (AI)-enabled Industrial Internet of Things systems by devising machine learning pipelines as part of a decentralized edge-to-cloud architecture. We present the design and deployment of our approach from an AI engineering perspective using two industrial case studies.,included,1191,0.8093363046646118
10.4230/dagrep.9.3.52,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Dagstuhl Reports,2019-01-01 00:00:00,semantic_scholar,engineering reliable multiagent systems (dagstuhl seminar 19112),https://www.semanticscholar.org/paper/880954e6525ae8a976a053d65c073fc1683859b0,"This report documents the program and outcomes of Dagstuhl Seminar 19112 ""Engineering Reliable Multiagent Systems"". The aim of this seminar was to bring together researchers from various scientific disciplines, such as software engineering of autonomous systems, software verification, and relevant subareas of AI, such as ethics and machine learning, to discuss the emerging topic of the reliability of (multi-)agent systems and autonomous systems in particular. The ultimate aim of the seminar was to establish a new research agenda for engineering reliable autonomous systems.",not included,659,0.8092065453529358
10.18034/abr.v7i3.650,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Asian Business Review,2017-01-01 00:00:00,semantic_scholar,application of artificial intelligence in contemporary business: an analysis for content management system optimization,https://www.semanticscholar.org/paper/da6631cbdcad93fbdfc7553fe9fb59424655a3b0,"Modern business is vital to finance, and AI has revolutionized the modern industry. Automation of many business operations has raised global concerns and alarms. Current business and related jobs are rising dramatically as the global population grows. Business administrators' conventional methods could be more efficient for these needs. These new tactics properly manage business products and services so industry persons may use technology to boost profits. It has protected harvest yield from environmental changes, overpopulation, changing business demands, and food safety challenges. Artificial intelligence can promote intelligent production methods to reduce loss and increase returns. Using artificial intelligence platforms, one can collect a considerable amount of data from government and public sites or real-time monitoring and collection of different data using IoT (Internet of Things) and then use it to empower business people to solve all their business problems. This research helps business people worldwide improve their business techniques. This paper uses the waterfall technique to develop and build an intelligent system by sequentially collecting data, analyzing requirements, planning, coding, testing, and implementing. This system can also generate ideas for managing common challenges in farm information systems, improving policy programs, augmentation and analysis, and managing production data. Finally, management information systems are analyzed, and suggestions for further development are made.",not included,222,0.8091461062431335
10.1109/edocw52865.2021.00048,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2021 IEEE 25th International Enterprise Distributed Object Computing Workshop (EDOCW),IEEE,2021-10-29 00:00:00,ieeexplore,static vs dynamic architecture of aware cyber physical systems of systems,https://ieeexplore.ieee.org/document/9626343/,"The Enterprise Architecture and Systems Engineering communities are often faced with complexity barriers that develop due to the fact that modern systems must be agile and resilient. This requires dynamic changes to the system so as to adapt to changing missions as well as changes in the internal and external environments. The requirement is not entirely new, but practitioners need guidance on how to manage the life cycle of such systems. This is a problem because we must be able to architect systems by alleviating the difficulties in systems life cycle management (e.g., by helping the enterprise- or systems engineer organise and maintain models and architecture descriptions of the system of interest). Building on Pask’s conversation theoretic model of aware (human or machine) individuals, the paper proposes a reference model for systems that maintain their own models real time, act efficiently, and create system-level awareness on all levers of aggregation.",not included,1819,0.8089338541030884
10.1109/iccicc53683.2021.9811336,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE International Conference on Cognitive Informatics and Cognitive Computing,2021-01-01 00:00:00,semantic_scholar,ieee icci*cc series in year 20: latest advances in cognitive computing (plenary panel report-ii),https://www.semanticscholar.org/paper/ce594ea5e1845cf645907c98ef90e07f0d95f3dc,"Cognitive Computing (CC) is a contemporary field of fundamental intelligence theories and general AI technologies triggered by the transdisciplinary development in intelligence, computer, brain, knowledge, cognitive, robotic, and cybernetic sciences for engineering implementations. This paper presents a summary of the plenary panel (Part II) on the theoretical foundations of CI/CC and recent breakthroughs in AI engineering reported in the 20th IEEE International ICCI*CC Conference (ICCI*CC'21). The latest advances in CI and CC towards general AI are presented by twenty-two distinguished panelists. Strategic AI engineering applications in CI, CC, and cognitive systems are elaborated for abstract intelligence, cognitive robots, autonomous systems, intelligent vehicles, and safety-and-mission-critical systems.",not included,1090,0.8088568449020386
10.1080/00207543.2022.2069525,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Journal of Production Research,2022-01-01 00:00:00,semantic_scholar,the assistant project: ai for high level decisions in manufacturing,https://www.semanticscholar.org/paper/42ac8fb795265758e2a076fe492c55483f9e19e1,"This paper outlines the main idea and approach of the H2020 ASSISTANT (LeArning and robuSt deciSIon SupporT systems for agile mANufacTuring environments) project. ASSISTANT is aimed at the investigation of AI-based tools for adaptive manufacturing environments, and focuses on the development of a set of digital twins for integration with, management of, and decision support for production planning and control. The ASSISTANT tools are based on the approach of extending generative design, an established methodology for product design, to a broader set of manufacturing decision making processes; and to make use of machine learning, optimisation, and simulation techniques to produce executable models capable of ethical reasoning and data-driven decision making for manufacturing systems. Combining human control and accountable AI, the ASSISTANT toolsets span a wide range of manufacturing processes and time scales, including process planning, production planning, scheduling, and real-time control. They are designed to be adaptable and applicable in a both general and specific manufacturing environments.",not included,1178,0.8087862730026245
10.1109/models-c.2019.00099,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2019 ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C),2019-01-01 00:00:00,semantic_scholar,improving mbse tools ux with ai-empowered software assistants,https://www.semanticscholar.org/paper/1e0ff2b8f8889e4c2ceead1e8a80f8d45c07a48a,"Model Based Software Engineering (MBSE) consists in applying Model-Based Engineering principles - mostly abstraction and automation - to software engineering practices. As concluded by several empirical studies during the past 10 years, applying MBSE methodology is no more a question and we shall now wonder how to do it rather than if we should. One of the major criticisms of MBSE remains about the available tooling to apply its methodology. Multiple surveys show that the usability of tools and the lack of skills from the user are two key barriers that still slow down the spread of the MBSE approach. In the meantime, these surveys also highlight the difficulties software engineers often encounter during the modeling activity itself, regardless of the tool. Indeed, complex operations such as problem-to-model mapping, consistency checking or error identification are still often manually performed by humans. The recent advances in AIs introduced new software-based systems able to interact with their users to help them in their daily life. The purpose of this PhD is to investigate how such AIs (which we will call software assistants) could help software engineers to face the complexity of software modeling. Interactions between software assistants and users of MBSE tools will be the bulk of this work. We plan to implement software assistants and provide them an access to a high-quality knowledge repository on models that we will build to study these interactions. Based on these studies, we hope to contribute laying the foundations of interactions with software assistants. The end result will feature a knowledge repository and a Software Assistant acting together to help users modeling by catering for new ideas, recommendations and help. This work will also provide frameworks to create knowledge repositories and IDE-embedded software assistants.",not included,671,0.808530867099762
10.1145/3185046,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),SCOPUS_ID:85053511194,scopus,2018-04-01 00:00:00,scopus,a modeling language for conceptual design of systems integration solutions,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85053511194&origin=inward,"
AbstractView references

Systems integration'connecting software systems for cross-functional work'is a significant concern in many large organizations, which continue to maintain hundreds, if not thousands, of independently evolving software systems. Current approaches in this space remain ad hoc, and closely tied to technology platforms. Following a design science approach, and via multiple design-evaluate cycles, we develop Systems Integration Requirements Engineering Modeling Language (SIRE-ML) to address this problem. SIRE-ML builds on the foundation of coordination theory, and incorporates important semantic information about the systems integration domain. The article develops constructs in SIRE-ML, and a merge algorithm that allows both functional managers and integration professionals to contribute to building a systems integration solution. Integration models built with SIRE-ML provide benefits such as ensuring coverage and minimizing ambiguity, and can be used to drive implementation with different platforms such as middleware, services, and distributed objects. We evaluate SIRE-ML for ontological expressiveness and report findings about applicability check with an expert panel. The article discusses implications for future research such as tool building and empirical evaluation, as well as implications for practice. © 2018 ACM 2158-656X/2018/09-ART8 $15.00
",not included,3049,0.8084061741828918
10.24251/hicss.2022.553,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),core,core,2022-01-03 08:00:00,core,artificial intelligence (ai) and digital transformation in the insurance market: a case study analysis of bgl group,https://core.ac.uk/download/489426047.pdf,"Artificial Intelligence (AI) is transforming the insurance industry and there are many examples in the business press and at industry conferences. However, there is a paucity of detailed conceptual analysis and evaluation of AI technology that places AI in a strategic context and considers how different AI applications fit together and form a coherent picture. In this paper, a detailed case study of BGL group, a leading European insurance firm, is presented. A general business process model of insurance companies is used to structure the analysis. Five AI applications are described using an insurance firm-customer data flow diagram, which illustrates the marketing impact of AI technology and shows the nature of the business value creation process. The results are generalized into an AI customer lifecycle model, which has broad applicability to digital transformation projects. The likely future direction of AI in insurance is outlined and further research opportunities are identified",not included,3277,0.8083584904670715
10.1007/s43681-023-00289-2,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),AI and Ethics,Springer,2023-05-30 00:00:00,springer,auditing large language models: a three-layered approach,http://dx.doi.org/10.1007/s43681-023-00289-2,"Large language models (LLMs) represent a major advance in artificial intelligence (AI) research. However, the widespread use of LLMs is also coupled with significant ethical and social challenges. Previous research has pointed towards auditing as a promising governance mechanism to help ensure that AI systems are designed and deployed in ways that are ethical, legal, and technically robust. However, existing auditing procedures fail to address the governance challenges posed by LLMs, which display emergent capabilities and are adaptable to a wide range of downstream tasks. In this article, we address that gap by outlining a novel blueprint for how to audit LLMs. Specifically, we propose a three-layered approach, whereby governance audits (of technology providers that design and disseminate LLMs), model audits (of LLMs after pre-training but prior to their release), and application audits (of applications based on LLMs) complement and inform each other. We show how audits, when conducted in a structured and coordinated manner on all three levels, can be a feasible and effective mechanism for identifying and managing some of the ethical and social risks posed by LLMs. However, it is important to remain realistic about what auditing can reasonably be expected to achieve. Therefore, we discuss the limitations not only of our three-layered approach but also of the prospect of auditing LLMs at all. Ultimately, this article seeks to expand the methodological toolkit available to technology providers and policymakers who wish to analyse and evaluate LLMs from technical, ethical, and legal perspectives.",included,1604,0.8081768155097961
10.1109/smc.2019.8914324,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)",IEEE,2019-10-09 00:00:00,ieeexplore,the digital (mission) twin: an integrating concept for future adaptive cyber-physical-human systems,https://ieeexplore.ieee.org/document/8914324/,"Top-down decomposition of a complex system of systems (SoS) requires representation of the behavior of multiple individuals and cyber-physical systems performing a wide variety of tasks, usually at different times and with different goals. In the future, as humans and machines learn and co-adapt in their mission context, systems engineering must develop approaches that support dynamic analysis and synthesis in both the design and operation of systems. The concept of a “digital (mission) twin” provides an integration framework for design and control of future complex cyber-physical-human SoS. The framework builds on mission function task (MFT) analysis, providing a basis for model-based systems engineering (MBSE) activities to identify and address needs for automation or other forms of advanced technology that improve overall system performance. However, human-driven adaptation and eventually machine adaptation of complex SoS poses organizational and methodological challenges. We discuss the need for and opportunities for convergence of three often segregated SE methodologies: product engineering, human systems integration, and mission/operations analysis by expanding the product or process engineering view of a digital twin to the mission level. In the present this gives us a framework to analyze and specify automation and adaptation opportunities at the mission level. In the future we envision this twin continuously operates with the real systems to manage both emergent mission conditions and lifecycle adaptation. We applied this framework to a complex military mission using a case where artificial intelligence can be incorporated widely across a set of mission tasks to significantly improve performance.",included,1826,0.8081477880477905
10.3233/idt-210997,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Journal of Intelligent Decision Technologies,2022-01-01 00:00:00,semantic_scholar,intelligent decision technologies: an international journal (idt) enters its 16th year: a short note from the editors,https://www.semanticscholar.org/paper/7497aa84ab48bedc6ee8f968f7dfc1eb89acb1d9,"Intelligent Decision Technologies (IDT): An International Journal (https://www.iospress.com/catalog/ journals/intelligent-decision-technologies) is dedicated to the advancement and dissemination of research results and knowledge in the theory and application of intelligent technologies and systems in support of decision making. The IDT Journal is affiliated with KES International (http://www.kesinternational.org/), “a professional community, with networking, research and publication opportunities for all those who work in knowledge-intensive subjects”. KES sponsors international conferences on leading-edge topics, including an annual conference for Intelligent Decision Technologies. The idea of the IDT Journal originated through discussions between Professor/Dr. Gloria Phillips-Wren and Professor/Dr. Lakhmi C. Jain at the Knowledge Engineering Systems (KES) International annual conferences in the timeframe of 2004–2006. The spark that at the time inspired the two Professors to initiate the IDT Journal lay in the fact that, while research mainly focused on algorithms and technical specifications, the technology was also becoming mature enough to be implemented into real-world decision support systems (DSS) for previously intractable problems. Thus, the IDT Journal was launched in 2007. Profs./Drs. Lakhmi C. Jain and Gloria Phillips-Wren introduced the IDT Journal to the research community with an editorial note stating that “The purpose of this peer reviewed, scholarly journal is to develop a forum for theoretical and applied research that combines artificial intelligence based in computer science, decision support based in information technology, and systems development based in engineering science. Interdisciplinary advances in these fields have the potential to significantly improve individual and organizational decision making. The growth of the internet with its concomitant availability of data has exploded the amount and types of information that must be considered by a decision maker. Decisions must often be made in real-time under uncertain, stressful conditions that may change rapidly. Synergies between intelligent and information technologies can, for example, deliver artificial intelligence to enhance human judgment, perceive anomalies in data, enable collaboration, speed processing of new information, assist in risk assessment, identify and retrieve needed knowledge, suggest alternatives to the decision maker, and automate some decisional tasks. We look forward to the dialogue within this community and welcome your research for publication” [1]. Since its launch, the IDT Journal is in continuous circulation with a new issue published quarterly by IOS Press (https://www.iospress.com/) headquartered in Amsterdam, the Netherlands. At the same time, the field of intelligent decision support has been enjoying continuous and rapid expansion in theory, paradigms and real-world systems and applications. This expansion is due to parallel advances and efficiencies in such enabling technologies as (1) Artificial Intelligence (AI); (2) connectivity between devices such as the Internet of Things (IoT); (3) data storage, processing and transmission in distributed, virtualized and networkcentric environments (e.g. cloud technologies); (4) remarkable computer and internet transmission speeds;",not included,1376,0.8080148100852966
10.1145/3199919.3199924,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Workshop on Web of Things,2017-01-01 00:00:00,semantic_scholar,beyond physical mashups: autonomous systems for the web of things,https://www.semanticscholar.org/paper/612cbd359c4a10793ce51662ad8975df8a047ea8,"By abstracting devices to Web resources, the Web of Things (WoT) fosters innovation and rapid prototyping in the Internet of Things (IoT): it enables developers to use standard Web technologies for creating mashups of Web services that perceive and act on the physical world (a.k.a. physical mashups). In recent years, however, it has become apparent that current programming paradigms for Web development have important shortcomings when it comes to engineering IoT systems: static Web mashups cannot adapt to dynamic IoT environments, and manually mashing-up the IoT does not scale. To address these limitations, WoT researchers started to look for means to engineer WoT systems that are more autonomous in pursuit of their design objectives. The engineering of autonomous systems has already been explored to a large extent in the scientific literature on artificial intelligence. In this position paper, we distill that large body of research into a coherent set of abstractions for engineering autonomous WoT systems.",not included,377,0.8079974055290222
10.1613/jair.1.11345,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,arXiv.org,2017-01-01 00:00:00,semantic_scholar,human-in-the-loop artificial intelligence,https://www.semanticscholar.org/paper/b2277775e67ad13a5ab22d86a055e1f49a4cc8f5,"Little by little, newspapers are revealing the bright future that Artificial Intelligence (AI) is building. Intelligent machines will help everywhere. However, this bright future has a dark side: a dramatic job market contraction before its unpredictable transformation. Hence, in a near future, large numbers of job seekers will need financial support while catching up with these novel unpredictable jobs. This possible job market crisis has an antidote inside. In fact, the rise of AI is sustained by the biggest knowledge theft of the recent years. Learning AI machines are extracting knowledge from unaware skilled or unskilled workers by analyzing their interactions. By passionately doing their jobs, these workers are digging their own graves. 
In this paper, we propose Human-in-the-loop Artificial Intelligence (HIT-AI) as a fairer paradigm for Artificial Intelligence systems. HIT-AI will reward aware and unaware knowledge producers with a different scheme: decisions of AI systems generating revenues will repay the legitimate owners of the knowledge used for taking those decisions. As modern Robin Hoods, HIT-AI researchers should fight for a fairer Artificial Intelligence that gives back what it steals.",included,135,0.807987630367279
10.48550/arxiv.2204.04211,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,arXiv.org,2022-01-01 00:00:00,semantic_scholar,measuring ai systems beyond accuracy,https://www.semanticscholar.org/paper/40ed2b01f62baeb649ec5d30363bf392c25c246e,"Current test and evaluation (T&E) methods for assessing ma- chine learning (ML) system performance often rely on incomplete metrics. Testing is additionally often siloed from the other phases of the ML system lifecycle. Research inves- tigating cross-domain approaches to ML T&E is needed to drive the state of the art forward and to build an Artificial Intelligence (AI) engineering discipline. This paper advo- cates for a robust, integrated approach to testing by outlining six key questions for guiding a holistic T&E strategy.",included,1151,0.8078747987747192
10.1109/icaa52185.2022.00013,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2022 IEEE International Conference on Assured Autonomy (ICAA),IEEE,2022-03-24 00:00:00,ieeexplore,a mapping of assurance techniques for learning enabled autonomous systems to the systems engineering lifecycle,https://ieeexplore.ieee.org/document/9763657/,"Learning enabled autonomous systems provide increased capabilities compared to traditional systems. However, the complexity of and probabilistic nature in the underlying methods enabling such capabilities present challenges for current systems engineering processes for assurance, and test, evaluation, verification, and validation (TEVV). This paper provides a preliminary attempt to map recently developed technical approaches in the assurance and TEVV of learning enabled autonomous systems (LEAS) literature to a traditional systems engineering v-model. This mapping categorizes such techniques into three main approaches: development, acquisition, and sustainment. This mapping reviews the latest techniques to develop safe, reliable, and resilient learning enabled autonomous systems, without recommending radical and impractical changes to existing systems engineering processes. By performing this mapping, we seek to assist acquisition professionals by (i) informing comprehensive test and evaluation planning, and (ii) objectively communicating risk to leaders.",not included,1737,0.8077064752578735
10.1109/issrew.2017.60,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2017 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW),2017-01-01 00:00:00,semantic_scholar,establishing verification and validation objectives for safety-critical bayesian networks,https://www.semanticscholar.org/paper/a648ca9af981e6fd323138c0aee8afa0985d6c86,"The assurance of autonomous systems and the technologies that drive them is a major research challenge in the safety-critical systems engineering domain. The nature of many of these Machine Learning (ML) and Artificial Intelligence (AI) approaches raises a number of additional, technology-specific assurance concerns. One such approach is the Bayesian Network (BN) probabilistic modelling framework. Bayesian Networks and the family of modelling techniques they belong to form the basis of many AI applications. However, little research has been conducted into the assurance of BN-based systems for use in safety-critical applications. This paper explores some of the key distinctions between BN-based software-intensive systems and conventional software systems. It introduces a modelling framework that explicitly captures BN-based systemspecific considerations and facilitates both the communication of assurance concerns between safety practitioners and system stakeholders, and the subsequent safety analysis of the system itself. It demonstrates how this approach can be used to develop specific verification and validation objectives for a BN-based system in a medical application.",not included,459,0.8076406121253967
10.1145/3488560.3501394,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Web Search and Data Mining,2022-01-01 00:00:00,semantic_scholar,modern theoretical tools for understanding and designing next-generation information retrieval system,https://www.semanticscholar.org/paper/c9c7519d69798523fd0c42a27b54918840b673c2,"In the relatively short history of machine learning, the subtle balance between engineering and theoretical progress has been proved critical at various stages. The most recent wave of AI has brought to the IR community powerful techniques, particularly for pattern recognition. While many benefits from the burst of ideas as numerous tasks become algorithmically feasible, the balance is tilting toward the application side. The existing theoretical tools in IR can no longer explain, guide, and justify the newly-established methodologies. With no choices, we have to bet our design on black-box mechanisms that we only empirically understand. The consequences can be suffering: in stark contrast to how the IR industry has envisioned modern AI making life easier, many are experiencing increased confusion and costs in data manipulation, model selection, monitoring, censoring, and decision making. This reality is not surprising: without handy theoretical tools, we often lack principled knowledge of the pattern recognition model's expressivity, optimization property, generalization guarantee, and our decision-making process has to rely on over-simplified assumptions and human judgments from time to time. Facing all the challenges, we started researching advanced theoretical tools emerging from various domains that can potentially resolve modern IR problems. We encountered many impactful ideas and made several independent publications emphasizing different pieces. Time is now to bring the community a systematic tutorial on how we successfully adapt those tools and make significant progress in understanding, designing, and eventually productionize impactful IR systems. We emphasize systematicity because IR is a comprehensive discipline that touches upon particular aspects of learning, causal inference analysis, interactive (online) decision-making, etc. It thus requires systematic calibrations to render the actual usefulness of the imported theoretical tools to serve IR problems, as they usually exhibit unique structures and definitions. Therefore, we plan this tutorial to systematically demonstrate our learning and successful experience of using advanced theoretical tools for understanding and designing IR systems.",not included,1357,0.8075500130653381
10.1109/mc.2017.154,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Computer,2017-01-01 00:00:00,semantic_scholar,standardizing ethical design for artificial intelligence and autonomous systems,https://www.semanticscholar.org/paper/c644a6e891f41bff1732c4760e7c298c51d6622d,"AI is here now, available to anyone with access to digital technology and the Internet. But its consequences for our social order aren't well understood. How can we guide the way technology impacts society?",not included,96,0.8070101141929626
10.1109/mts.2022.3197116,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE technology & society magazine,2022-01-01 00:00:00,semantic_scholar,value-based engineering with ieee 7000,https://www.semanticscholar.org/paper/f0a5f6436d863918d646c4855ec680482a143e7f,"In recent years, there has been a steady increase in awareness of the need to design technology more ethically. The crashes of two Boeing 737 MAX airplanes <xref ref-type=""bibr"" rid=""ref1"">[1]</xref> as well as the Volkswagen scandal <xref ref-type=""bibr"" rid=""ref2"">[2]</xref> have contributed to the questioning of ethical practices in classic engineering departments. Several studies revealed the potential bias and manipulability of software systems, including critical judicial systems and social networks <xref ref-type=""bibr"" rid=""ref3"">[3]</xref>. The lack of artificial intelligence (AI) transparency became subject to a stream of criticism. To the positive surprise of long-term scholars in the social issues of technology, the IT industry woke up to the need for a more forward-looking, responsible, and ethical planning of IT systems.",not included,1226,0.8067067265510559
10.24251/hicss.2021.639,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Hawaii International Conference on System Sciences,2021-01-01 00:00:00,semantic_scholar,ethical perspectives in ai: a two-folded exploratory study from literature and active development projects,https://www.semanticscholar.org/paper/20b8a3bfc4224d6958c1b546e734dddcd027b617,"Background: Interest in Artificial Intelligence (AI) based systems has been gaining traction at a fast pace, both for software development teams and for society as a whole. This increased interest has lead to the employment of AI techniques such as Machine Learning and Deep Learning for diverse purposes, like medicine and surveillance systems, and such uses have raised the awareness about the ethical implications of the usage of AI systems. Aims: With this work we aim to obtain an overview of the current state of the literature and software projects on tools, methods and techniques used in practical AI ethics. Method: We have conducted an exploratory study in both a scientific database and a software projects repository in order to understand their current state on techniques, methods and tools used for implementing AI ethics. Results: A total of 182 abstracts were retrieved and five classes were deviseds were retrieved and five classes were devised from the analysis in Scopus, 1) AI in Agile and Business for Requirement Engineering (RE) (22.8%), 2) RE in Theoretical Context (14.8%), 3) Quality Requirements (22.6%), 4) Proceedings and Conferences (22%), 5) AI in Requirements Engineering (17.8%). Furthermore, out of 589 projects from GitHub, we found 21 tools for implementing AI ethics. Highlighted publicly available tools found to assist the implementation of AI ethics are InterpretML, Deon and TransparentAI. Conclusions: The combined energy of both explored sources fosters an enhanced debate and stimulates progress towards AI",not included,974,0.8065502643585205
10.1007/s10270-023-01132-2,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),Software and Systems Modeling,Springer,2023-12-01 00:00:00,springer,from process mining to augmented process execution,http://dx.doi.org/10.1007/s10270-023-01132-2,"Business process management (BPM) is a well-established discipline comprising a set of principles, methods, techniques, and tools to continuously improve the performance of business processes. Traditionally, most BPM decisions and activities are undertaken by business stakeholders based on manual data collection and analysis techniques. This is time-consuming and potentially leads to suboptimal decisions, as only a restricted subset of data and options are considered. Over the past decades, a rich set of data-driven techniques has emerged to support and automate various activities and decisions across the BPM lifecycle, particularly within the process mining field. More recently, the uptake of artificial intelligence (AI) methods for BPM has led to a range of approaches for proactive business process monitoring. Given their common data requirements and overlapping goals, process mining and AI-driven approaches to business process optimization are converging. This convergence is leading to a promising emerging concept, which we call (AI-)augmented process execution : a collection of data analytics and artificial intelligence methods for continuous and automated improvement and adaptation of business processes. This article gives an outline of research at the intersection between process mining and AI-driven process optimization, classifies the researched techniques based on their scope and objectives, and positions augmented process execution as an additional layer on top of this stack.",not included,1567,0.8065018057823181
10.1089/cyber.2016.29060.csi,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,"Cyberpsychology, Behavior, and Social Networking",2017-01-01 00:00:00,semantic_scholar,bringing more transparency to artificial intelligence,https://www.semanticscholar.org/paper/9e1dff6f8cb4a2dab6fa8705f5fe17cd562928c9,"The development of artificial intelligence (AI) has taken giant steps during the last decade to the point that for many experts, including the world-renowned atrophysics Stephen Hawking and hi-tech entrepreneur Elon Musk, AI could even destroy civilization by overtaking humans. However, on the other hand, AI may bring about huge benefits for humankind, some of which may be still beyond our imagination today. Thus, the scientific community is faced with the challenge of how we can develop powerful AI systems that support civilization while at the same time preventing the potential side effects of an uncontrolled AI evolution. To address these challenges, in late September 2016, tech giants Google, Facebook, Microsoft, Amazon, and IBM launched a ‘‘Partnership on Artificial Intelligence To Benefit People and Society.’’ The new alliance has been established ‘‘to study and formulate best practices on AI technologies, to advance the public’s understanding of AI, and to serve as an open platform for discussion and engagement about AI and its influences on people and society’’ (https://www .partnershiponai.org/). As claimed in the mission statement, a specific goal of the initiative is to help improving public awareness of what is happening in the AI field, where a number of players are shaping the future of intelligent services. Also, the Partnership aims to create more inclusive discussion by extending participation from AI specialists to activists and experts in other disciplines, such as psychology, philosophy, economics, finance, sociology, public policy, and law, to discuss and provide guidance on emerging issues related to the impact of AI on society. The Partnership has the potential to create a greater multidisciplinary understanding of the opportunities and challenges associated with potential breakthroughs in this field. Yet, some key players, such as Apple and Elon Musk’s OpenAI—a nonprofit AI research project (https://www .openai.com/blog/)—have not yet joined the club. While the goals of the Partnership have been set, the strategy that the alliance intends to put in place to attain these objectives is still unclear. Thus, it is too early to understand how the association will concretely address the challenges that need to be addressed with the public, such as how AI can be used safely to support military activities, or how to deal with the legal responsibilities for any damage caused by AI to humans.",included,189,0.8062982559204102
10.1109/coginfocom50765.2020.9237822,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE International Conference on Cognitive Infocommunications,2020-01-01 00:00:00,semantic_scholar,beyond 160 applications of an expert system: key to a better usability,https://www.semanticscholar.org/paper/640ab1634e1708de26d7513f789fbbdddf57f5a2,"The most influential relevant thinkers have complained of the “poverty” of Expert Systems (ES) both in the past (Dreyfus and Dreyfus, 1986) and in recently studies as well (Müller and Bostrom, 2016). We developed our own AI-Based Expert System shell for rule-based and case-based reasoning three decades ago and now there are 160 Knowledge Engineering (KE) process behind us with this system. We hope that this experience give us the right to formulate an opinion about that what is the key to a better usability and user experience in understanding of the result of the decision making process. While we do not think that ES is an omnipotent panacea, we also do not think that its applicability is determined only by the shell capabilities. However, one ability is essential; namely, presenting the result as simply as possible in order to that the decision-maker also can understand it. Our finding is that ES shells are only able to be transparent if they are designed by people who have an understanding of the human thinking process instead of a strong math-based software development approach.",not included,875,0.8055980801582336
10.1145/3375627.3375872,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),core,core,2020-11-09 00:00:00,core,steps towards value-aligned systems,http://arxiv.org/abs/2002.05672,"Algorithmic (including AI/ML) decision-making artifacts are an established
and growing part of our decision-making ecosystem. They are indispensable tools
for managing the flood of information needed to make effective decisions in a
complex world. The current literature is full of examples of how individual
artifacts violate societal norms and expectations (e.g. violations of fairness,
privacy, or safety norms). Against this backdrop, this discussion highlights an
under-emphasized perspective in the literature on assessing value misalignment
in AI-equipped sociotechnical systems. The research on value misalignment has a
strong focus on the behavior of individual tech artifacts. This discussion
argues for a more structured systems-level approach for assessing
value-alignment in sociotechnical systems. We rely primarily on the research on
fairness to make our arguments more concrete. And we use the opportunity to
highlight how adopting a system perspective improves our ability to explain and
address value misalignments better. Our discussion ends with an exploration of
priority questions that demand attention if we are to assure the value
alignment of whole systems, not just individual artifacts.Comment: Original version appeared in Proceedings of the 2020 AAAI ACM
  Conference on AI, Ethics, and Society (AIES '20), February 7-8, 2020, New
  York, NY, USA. 5 pages, 2 figures. Corrected some typos in this versio",included,3228,0.8055118918418884
10.23919/date51398.2021.9474185,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),SCOPUS_ID:85108370840,scopus,2021-02-01 00:00:00,scopus,veridevops: automated protection and prevention to meet security requirements in devops,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85108370840&origin=inward,"
AbstractView references

Current software development practices are increasingly based on using both COTS and legacy components which make such systems prone to security vulnerabilities. The modern practice addressing ever changing conditions, DevOps, promotes frequent software deliveries, however, verification methods artifacts should be updated in a timely fashion to cope with the pace of the process. VeriDevOps, Horizon 2020 project, aims at providing a faster feedback loop for verifying the security requirements and other quality attributes of large scale cyber-physical systems. VeriDevOps focuses on optimizing the security verification activities, by automatically creating verifiable models directly from security requirements formulated in natural language, using these models to check security properties on design models and then generating artefacts such as, tests or monitors that can be used later in the DevOps process. The main drivers for these advances are: Natural Language Processing, a combined formal verification and model-based testing approach, and machine-learning-based security monitors. VeriDevOps is in its initial stage - the project started on 1.10.2020 and it will run for three years. In this paper we will present the major conceptual ideas behind the project approach as well as the organizational settings. © 2021 EDAA.
",not included,2692,0.8048649430274963
10.1109/rew56159.2022.00038,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,2022 IEEE 30th International Requirements Engineering Conference Workshops (REW),2022-01-01 00:00:00,semantic_scholar,can requirements engineering support explainable artificial intelligence? towards a user-centric approach for explainability requirements,https://www.semanticscholar.org/paper/a792faefc9230dc89aab3fac643a7d9ce0bf2077,"With the recent proliferation of artificial intelligence systems, there has been a surge in the demand for explainability of these systems. Explanations help to reduce system opacity, support transparency, and increase stakeholder trust. In this position paper, we discuss synergies between requirements engineering (RE) and Explainable AI (XAI). We highlight challenges in the field of XAI, and propose a framework and research directions on how RE practices can help to mitigate these challenges.",included,1216,0.8046533465385437
10.1145/3502771.3502781,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,ACM SIGSOFT Softw. Eng. Notes,2022-01-01 00:00:00,semantic_scholar,software engineering and ai for data quality in cyber- physical systems - sea4dq'21 workshop report,https://www.semanticscholar.org/paper/c64b90a28c9542c07d7336b61fa226305fc841a7,"Cyber-physical systems (CPS) have been developed in many industrial sectors and application domains in which the quality requirements of data acquired are a common factor. Data quality in CPS can deteriorate because of several factors such as sensor faults and failures due to operating in harsh and uncertain environments. How can software engineering and artificial intelligence (AI) help manage and tame data quality issues in CPS? This is the question we aimed to investigate in the SEA4DQ workshop. Emerging trends in software engineering need to take data quality management seriously as CPS are increasingly datacentric in their approach to acquiring and processing data along the edge-fog-cloud continuum. This workshop provided researchers and practitioners a forum for exchanging ideas, experiences, understanding of the problems, visions for the future, and promising solutions to the problems in data quality in CPS. Examples of topics include software/hardware architectures and frameworks for data quality management in CPS; software engineering and AI to detect anomalies in CPS data or to repair erroneous CPS data. SEA4DQ 2021, which took place on August 24th, 2021 was a satellite event of the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC / FSE) 2021. The workshop attracted 35 international participants and was exciting with a great keynote, six excellent presentations, and concluded on a high note with a panel discussion. SEA4DQ was motivated by the common research interests from the EU projects for Zero-Defects Manufacturing such as InterQ and Dat4.Zero.",not included,1122,0.8045250773429871
10.1007/s00766-024-00415-4,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),Requirements Engineering,Springer,2024-03-21 00:00:00,springer,an empirical investigation of challenges of specifying training data and runtime monitors for critical software with machine learning and their relation to architectural decisions,http://dx.doi.org/10.1007/s00766-024-00415-4,"The development and operation of critical software that contains machine learning (ML) models requires diligence and established processes. Especially the training data used during the development of ML models have major influences on the later behaviour of the system. Runtime monitors are used to provide guarantees for that behaviour. Runtime monitors for example check that the data at runtime is compatible with the data used to train the model. In a first step towards identifying challenges when specifying requirements for training data and runtime monitors, we conducted and thematically analysed ten interviews with practitioners who develop ML models for critical applications in the automotive industry. We identified 17 themes describing the challenges and classified them in six challenge groups. In a second step, we found interconnection between the challenge themes through an additional semantic analysis of the interviews. We explored how the identified challenge themes and their interconnections can be mapped to different architecture views. This step involved identifying relevant architecture views such as data, context, hardware, AI model, and functional safety views that can address the identified challenges. The article presents a list of the identified underlying challenges, identified relations between the challenges and a mapping to architecture views. The intention of this work is to highlight once more that requirement specifications and system architecture are interlinked, even for AI-specific specification challenges such as specifying requirements for training data and runtime monitoring.",not included,1430,0.8043467402458191
http://arxiv.org/abs/2006.12497v3,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),arxiv,arxiv,2020-06-21 00:00:00,arxiv,technology readiness levels for ai & ml,http://arxiv.org/abs/2006.12497v3,"The development and deployment of machine learning systems can be executed
easily with modern tools, but the process is typically rushed and
means-to-an-end. The lack of diligence can lead to technical debt, scope creep
and misaligned objectives, model misuse and failures, and expensive
consequences. Engineering systems, on the other hand, follow well-defined
processes and testing standards to streamline development for high-quality,
reliable results. The extreme is spacecraft systems, where mission critical
measures and robustness are ingrained in the development process. Drawing on
experience in both spacecraft engineering and AI/ML (from research through
product), we propose a proven systems engineering approach for machine learning
development and deployment. Our Technology Readiness Levels for ML (TRL4ML)
framework defines a principled process to ensure robust systems while being
streamlined for ML research and product, including key distinctions from
traditional software engineering. Even more, TRL4ML defines a common language
for people across the organization to work collaboratively on ML technologies.",included,63,0.804334282875061
10.1109/ms.2023.3339408,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),SCOPUS_ID:85187131916,scopus,2024-03-01 00:00:00,scopus,"testing, debugging, and log analysis with modern ai tools",https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85187131916&origin=inward,"
AbstractView references

This edition of the Practitioners Digest covers recent papers employing generative artificial intelligence in support of testing, debugging, and log analysis that were presented at the 38th IEEE/ACM International Conference on Automated Software Engineering (ASE 2023) and the 16th IEEE International Conference on Software, Testing, Verification and Validation (ICST 2023). Feedback or suggestions are welcome. In addition, if you try or adopt any of the practices included in the column, please send us and the authors of the paper(s) a note about your experiences. © 1984-2012 IEEE.
",not included,1895,0.80413419008255
10.1609/aaai.v32i1.11382,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,AAAI Conference on Artificial Intelligence,2018-01-01 00:00:00,semantic_scholar,smarths: an ai platform for improving government service provision,https://www.semanticscholar.org/paper/52883bf093c42ced1dddf36c7580f1e9bfb05b8f,"
 
 Over the years, government service provision in China has been plagued by inefficiencies. Previous attempts to address this challenge following a toolbox e-government system model in China were not effective. In this paper, we report on a successful experience in improving government service provision in the domain of social insurance in Shandong Province, China. Through standardization of service workflows following the Complete Contract Theory (CCT) and the infusion of an artificial intelligence (AI) engine to maximize the expected quality of service while reducing waiting time, the Smart Human-resource Services (SmartHS) platform transcends organizational boundaries and improves system efficiency. Deployments in 3 cities involving 2,000 participating civil servants and close to 3 million social insurance service cases over a 1 year period demonstrated that SmartHS significantly improves user experience with roughly a third of the original front desk staff. This new AI-enhanced mode of operation is useful for informing current policy discussions in many domains of government service provision.
 
",not included,300,0.8040947914123535
10.1145/3641399.3641437,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),SCOPUS_ID:85186762725,scopus,2024-02-22 00:00:00,scopus,workshop report on generative ai-based software engineering,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85186762725&origin=inward,"
AbstractView references

The co-authors have organized and conducting the Generative AI-based Software Engineering workshop, co-located with the 17th Innovations in Software Engineering Conference (ISEC) at Bangalore, India on 22nd Feb. 2024. This report briefly describes the objectives and brief contents of the workshop, and hoping that the execution of the planned contents during the workshop will meet the set objectives. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
",not included,1911,0.8039441108703613
http://arxiv.org/abs/2207.07599v1,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),arxiv,arxiv,2022-06-21 00:00:00,arxiv,value-based engineering with ieee 7000tm,http://arxiv.org/abs/2207.07599v1,"Digital ethics is being discussed worldwide as a necessity to create more
reliable IT systems. This discussion, fueled by the fear of uncontrollable
artificial intelligence (AI) has moved many institutions and scientists to
demand a value-based system engineering. This article presents how
organizations can build responsible and ethically founded systems with the
'Value-based Engineering' (VBE) approach that was standardized in the IEEE
7000TM standard. VBE is a transparent, clearly-structured, step-by-step
methodology combining innovation management, risk management, system and
software engineering in one process framework. It embeds a robust value
ontology and terminology. It has been tested in various case studies. This
article introduces readers to the most important steps and contributions of the
approach.",not included,37,0.8036711812019348
10.1145/3177884,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,ACM Trans. Internet Techn.,2018-01-01 00:00:00,semantic_scholar,guest editors’ introduction,https://www.semanticscholar.org/paper/595f42cf1d47afcbd6891e3ae77b51d6498fce33,"Cybersecurity underpins the lives of ordinary people—their safety, work, health, and entertainment. Yet despite its importance, cybersecurity is often approached in a reactive manner—taking corrective actions to “patch” vulnerabilities after they are detected or exploited. In the absence of fundamental improvements in formal processes and methods, the same or similar problems can recur. In contrast, a scientific vision for security and privacy should be proactive. The focus of this TOIT special section is to provide a forum to discuss and advance security and privacy by means of Artificial Intelligence (AI) approaches. Approaches that are intelligent and self-adaptive are crucial to deal with the complexities of effectively protecting sensitive assets in all security-critical domains. This is where research from the AI community can make a difference in security and privacy. Specifically, AI can help address a long-standing problem, namely, that security and privacy are attempted to be inserted as an afterthought, which is rarely adequate. We identify the following key areas in AI, and review advancements in such areas that would help solve fundamental hard problems regarding security (CyBOK 2017) and privacy (Such 2017). Normative models: Secure and privacy-aware governance of sociotechnical systems can only be achieved by bridging the divide between technical solutions to security and privacy such as access control systems and the human and social factors associated with the users of such systems. Development of unified computational models for the social and the technical tiers of sociotechnical systems as well as their verification are therefore of utmost importance. Previous work (Barth et al. 2006; Chopra et al. 2014; Criado and Such 2016; Kafalı et al. 2016a; Singh 2013) has shown that a formalization of norms captures sociotechnical system concepts by regulating user interactions. Norms serve as a computational method for establishing user accountability by capturing a precise",not included,598,0.8035589456558228
10.48550/arxiv.2203.03847,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,arXiv.org,2022-01-01 00:00:00,semantic_scholar,trust in ai and implications for the aec research: a literature analysis,https://www.semanticscholar.org/paper/8c72089e7a7ce152a5c5ad91adcd2569e564ac0d,"Engendering trust in technically acceptable and psychologically embraceable systems requires domain-specific research to capture unique characteristics of the field of application. The architecture, engineering, and construction (AEC) research community has been recently harnessing advanced solutions offered by artificial intelligence (AI) to improve project workflows. Despite the unique characteristics of work, workers, and workplaces in the AEC industry, the concept of trust in AI has received very little attention in the literature. This paper presents a comprehensive analysis of the academic literature in two main areas of trust in AI and AI in the AEC, to explore the interplay between AEC projects unique aspects and the sociotechnical concepts that lead to trust in AI. A total of 490 peer-reviewed scholarly articles are analyzed in this study. The main constituents of human trust in AI are identified from the literature and are characterized within the AEC project types, processes, and technologies.",not included,1189,0.8035358786582947
10.4018/ijncr.310006,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Journal of Natural Computing Research,2022-01-01 00:00:00,semantic_scholar,insights into incorporating trustworthiness and ethics in ai systems with explainable ai,https://www.semanticscholar.org/paper/7ecae0b8c34e9d728517d616baf80c15d6d064b7,"Over the past seven decades since the advent of artificial intelligence (AI) technology, researchers have demonstrated and deployed systems incorporating AI in various domains. The absence of model explainability in critical systems such as medical AI and credit risk assessment among others has led to neglect of key ethical and professional principles which can cause considerable harm. With explainability methods, developers can check their models beyond mere performance and identify errors. This leads to increased efficiency in time and reduces development costs. The article summarizes that steering the traditional AI systems toward responsible AI engineering can address concerns raised in the deployment of AI systems and mitigate them by incorporating explainable AI methods. Finally, the article concludes with the societal benefits of the futuristic AI systems and the market shares for revenue generation possible through the deployment of trustworthy and ethical AI systems.",included,1143,0.8033174872398376
10.1109/indin51773.2022.9976107,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2022 IEEE 20th International Conference on Industrial Informatics (INDIN),IEEE,2022-07-28 00:00:00,ieeexplore,integration of machine learning task definition in model-based systems engineering using sysml,https://ieeexplore.ieee.org/document/9976107/,"In order to allow Systems Engineers to utilize data produced in cyber-physical systems (CPS), they have to cooperate with data-scientists for custom data-extraction, data-preparation, and/or data-transformation mechanisms. While interfaces in CPS systems might be generic, the data that is produced for custom application needs has to be transformed and merged in very specific ways, to allow systems engineers proper interpretation and insight-extraction. In order to enable efficient cooperation between systems engineers and data scientists, the systems engineers have to provide a fine-grained specification that (a) describes all parts of the CPS, (b) how they might interact, (c) what data is exchanged between them, and (d) how the data inter-relates. A data scientists can then iteratively (including further refinements of the specification) prepare the necessary custom machine-learning models and components. Therefore, this work introduces a method supporting the collaborative definition of machine learning tasks by leveraging model-based systems engineering in the formalization of the systems modeling language SysML. The method supports the identification and integration of various data sources, the required definition of semantic connections between data attributes and the definition of the data processing steps within the machine learning support. Integrating machine learning-specific properties in systems engineering techniques allows non-data scientists to define a machine learning problem, document knowledge on the data, and further supports data scientists to use the formalized knowledge as input for an implementation.",not included,1748,0.8031995296478271
10.1145/3137574.3137585,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,SIGAI,2017-01-01 00:00:00,semantic_scholar,how do we ensure that we remain in control of our autonomous weapons?,https://www.semanticscholar.org/paper/c5841f4e0f767a304e69e2a5dbfb4078bc8f1bc5,"'... our AI systems must do what we want them to do.''
 This quote is mentioned in the Open Letter: Research Priorities for Robust and Beneficial Artificial Intelligence (AI) (Future of Life Institute, 2016) signed by over 8.600 people including Elon Musk and Stephan Hawking. This open letter received a lot of media attention with news headlines as: 'Musk, Wozniak and Hawking urge ban on warfare AI and autonomous weapons' (Gibbs, 2015) and it fused the debate on this topic. Although this type of 'War of the Worlds' news coverage might seem exaggerated at first glance, the underlying question on how we ensure that our Autonomous Weapons remain under our control, is in my opinion one of the most pressing issues for AI technology at this moment in time.
 To remain in control of our Autonomous Weapons and AI in general, meaning that its actions are intentional and according to our plans (Cushman, 2015), we should design it in a responsible manner and to do so I believe we must find a way incorporate our moral and ethical values into their design. The ART principle, an acronym for Accountability, Responsibility and Transparency can support a responsible design of AI. The Value-Sensitive Design (VSD) approach can be used to cover the ART principle. In this essay, I show how Autonomous Weapons can be designed responsibly by applying the VSD approach which is an iterative process that considers human values throughout the design process of technology (Davis & Nathan, 2015; Friedman & Kahn Jr, 2003).",included,539,0.8030397295951843
10.1109/acsos55765.2022.00030,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Conference on Autonomic Computing and Self-Organizing Systems,2022-01-01 00:00:00,semantic_scholar,a modular and composable approach to develop trusted artificial intelligence,https://www.semanticscholar.org/paper/d1e8e98848d6a4cad32c1fe9ad7eb051f37256bd,"Trustworthy artificial intelligence (Trusted AI) is of utmost importance when learning-enabled components (LECs) are used in autonomous, safety-critical systems. When reliant on deep learning, these systems need to address the reliability, robustness, and interpretability of learning models. In addition to developing specific strategies to address each of these concerns, appropriate software architectures are needed to coordinate LECs and ensure they deliver acceptable behavior under uncertain conditions. This work proposes a model-driven framework of loosely-coupled modular services designed to monitor and control LECs with respect to Trusted AI assurance concerns. The proposed framework is composable, deploying independent services to improve the resilience and robustness of AI systems. The overarching objective of this framework is to support software engineering principles focusing on modularity, composability, and reusability in order to facilitate development and maintenance tasks, while also increasing stakeholder confidence in Trusted AI systems. To demonstrate this framework, it has been implemented to manage the operation of an autonomous rover’s vision-based LEC while exposed to uncertain environmental conditions.",included,1335,0.8028196096420288
10.1145/3626234,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,ACM Computing Surveys,2022-01-01 00:00:00,semantic_scholar,responsible ai pattern catalogue: a collection of best practices for ai governance and engineering,https://www.semanticscholar.org/paper/05ad97039402554fd3917e9381e09a4e4c2da1c6,"Responsible AI is widely considered as one of the greatest scientific challenges of our time and is key to increase the adoption of AI. Recently, a number of AI ethics principles frameworks have been published. However, without further guidance on best practices, practitioners are left with nothing much beyond truisms. Also, significant efforts have been placed at algorithm-level rather than system-level, mainly focusing on a subset of mathematics-amenable ethical principles, such as fairness. Nevertheless, ethical issues can arise at any step of the development lifecycle, cutting across many AI and non-AI components of systems beyond AI algorithms and models. To operationalize responsible AI from a system perspective, in this paper, we present a Responsible AI Pattern Catalogue based on the results of a Multivocal Literature Review (MLR). Rather than staying at the principle or algorithm level, we focus on patterns that AI system stakeholders can undertake in practice to ensure that the developed AI systems are responsible throughout the entire governance and engineering lifecycle. The Responsible AI Pattern Catalogue classifies the patterns into three groups: multi-level governance patterns, trustworthy process patterns, and responsible-AI-by-design product patterns. These patterns provide systematic and actionable guidance for stakeholders to implement responsible AI.",not included,1137,0.8022953271865845
10.1109/aero47225.2020.9172802,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2020 IEEE Aerospace Conference,IEEE,2020-03-14 00:00:00,ieeexplore,artificial intelligence agents to support data mining for sos modeling of space systems design,https://ieeexplore.ieee.org/document/9172802/,"The complex and multidisciplinary nature of space systems and mission architectures is especially evident in early stage of design and architecting, where systems stakeholders have to keep into account all the aspects of a project, including alternatives, cost, risk, and schedule and evaluate various potentially conflicting metrics with a high level of uncertainty. Though aerospace engineering is a relatively young discipline, stakeholders in the field can rely on a vast body of knowledge and good practices for space systems design and architecting of space missions. These guidelines have been identified and refined over the years. However, the increase in size and complexity of applications in the aerospace discipline highlighted some gaps in this approach: first, the amount of available information is now very large and originates from multiple sources, often with diverse representations, and useful data for trade space analysis or analysis of all potential alternatives can be easily overlooked; second, the variety and complexity of the systems involved and of the different domains to be kept into account can generate unexpected interactions that cannot be easily identified; third, continuous advancements in the field of aerospace resulted in the development of new approaches and methodologies, for which a common knowledge database is not existing yet, thus requiring substantial effort upfront. To address these gaps and support both decision making in early stage of space systems design and increased automation in extraction of necessary data to feed working groups and analytical methodologies, we propose the training and use of Artificial Intelligence agents. These agents can be trained to recognize not only information coming from standardized representations, for example Model Based Systems Engineering diagrams, but also descriptions of systems and functionalities in plain English. This capability allows each agent to quantify the relevance of publications and documents to the query for which it is trained. At the same time, each agent can recognize potentially useful information in documents which are only loosely connected to the systems or functionalities on which the agent has been trained, and which would possibly be overlooked in a traditional literature review. The search for pertinent sources can be further refined using keywords, that let the user specify more details about the systems or functionality of interest, based on the intended use of the data. In this work we illustrate the use of Artificial Intelligent agents to sort space habitat subsystems into NASA Technology Roadmaps categories and to identify relevant sources of data for these subsystems. We demonstrate how the agents can support the retrieval of complex information required to feed existing System-of-Systems analytic tools and discuss challenges of this approach and future steps.",not included,1783,0.8018620610237122
10.1126/science.357.6346.19,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,Science,2017-01-01 00:00:00,semantic_scholar,"ai glossary: artificial intelligence, in so many words.",https://www.semanticscholar.org/paper/492445d775f5fec43face6aa8a6c78fb48407f61,"Just what do people mean by artificial intelligence (AI)? The term has never had
 clear boundaries. When it was introduced at a seminal 1956 workshop at Dartmouth
 College, it was taken broadly to mean making a machine behave in ways that would
 be called intelligent if seen in a human. An important recent advance in AI has
 been machine learning, which shows up in technologies from spellcheck to
 self-driving cars and is often carried out by computer systems called neural
 networks. Any discussion of AI is likely to include other terms as well. We
 present a glossary of key words and phrases.",not included,94,0.8018578886985779
10.1145/3486622.0000002,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,WI/IAT,2021-01-01 00:00:00,semantic_scholar,why is it so hard to make self-driving cars? (trustworthy autonomous systems),https://www.semanticscholar.org/paper/afc0291e12228163f948a2195c95fe7b8c6fe218,"Why is self-driving so hard? Despite the enthusiastic involvement of big technological companies and the massive investment of many billions of dollars, all the optimistic predictions about self-driving cars ''being around the corner'' went utterly wrong. I argue that these difficulties emblematically illustrate the challenges raised by the vision for trustworthy autonomous systems. These are critical systems intended to replace human operators in complex organizations, very different from other intelligent systems such as game-playing robots or intelligent personal assistants. I discuss complexity limitations inherent to autonomic behavior but also to integration in complex cyber-physical and human environments. I argue that existing critical systems engineering techniques fall short of meeting the complexity challenge. I also argue that emerging end-to-end AI-enabled solutions currently developed by industry, fail to provide the required strong trustworthiness guarantees. I advocate a hybrid design approach combining model-based and data-based techniques and seeking tradeoffs between performance and trustworthiness. I also discuss the validation problem emphasizing the need for rigorous simulation and testing techniques allowing technically sound safety evaluation. I conclude that building trustworthy autonomous systems goes far beyond the current AI vision. To reach this vision, we need a new scientific foundation enriching and extending traditional systems engineering with data-based techniques.",not included,980,0.8018409013748169
10.1109/isse54508.2022.10005441,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2022 IEEE International Symposium on Systems Engineering (ISSE),IEEE,2022-10-26 00:00:00,ieeexplore,towards a data engineering process in data-driven systems engineering,https://ieeexplore.ieee.org/document/10005441/,"Highly Automated Driving (HAD) has become one of the leading trends in the automotive industry. Mandatory tasks like environment perception and scene understanding challenge existing rule-based methods. Thus, data-driven technologies and Artificial Intelligence (AI) have been introduced to automotive software development. Utilizing data in the development process has become essential as these systems are no longer developed with classical systems engineering methods, but rather by deriving requirements from and training the algorithms with recorded real-world data. This entails the introduction of data-driven workflows and data-management as new aspects of Automotive Systems Engineering (ASE). Tasks related to the development of Artificial Intelligence (AI) software differ from their classical engineering and programming counterparts. Thus, engineers require new tools and methods for developing safe and accurate AI-based software and handling data efficiently during ASE. Another important aspect of data-driven development is ensuring data quality throughout the systems engineering process. Hence, this paper aims to take a step towards the introduction of a data engineering process in data-driven automotive systems engineering. Putting a spotlight on developing well-designed data sets as the central element for training and validating AI-based software. Besides determining the quality of data sets, we present steps towards improving data and data set quality.",included,1764,0.8017510771751404
10.3233/aic-170748,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,AI Communications,2017-01-01 00:00:00,semantic_scholar,supporting adaptiveness of cyber-physical processes through action-based formalisms,https://www.semanticscholar.org/paper/c550f06b954879e2dda66c0540dc6ae527e3fad4,"Cyber Physical Processes (CPPs) refer to a new generation of business processes enacted in many application environments (e.g., emergency management, smart manufacturing, etc.), in which the presence of Internet-of-Things devices and embedded ICT systems (e.g., smartphones, sensors, actuators) strongly inﬂuences the coordination of the real-world entities (e.g., humans, robots, etc.) inhabitating such environments. A Process Management System (PMS) employed for executing CPPs is required to automatically adapt its running processes to anomalous situations and exogenous events by minimising any human intervention. In this paper, we tackle this issue by introducing an approach and an adaptive Cognitive PMS, called SmartPM , which combines process execution monitoring, unanticipated exception detection and automated resolution strategies leveraging on three well-established action-based formalisms developed for reasoning about actions in Artiﬁcial Intelligence (AI), including the situation calculus, IndiGolog and automated planning. Interest-ingly, the use of SmartPM does not require any expertise of the internal working of the AI tools involved in the system.",not included,440,0.8017236590385437
10.1109/sose52739.2021.9497496,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2021 16th International Conference of System of Systems Engineering (SoSE),IEEE,2021-06-18 00:00:00,ieeexplore,system of systems engineering approach for complex deterministic and nondeterministic systems (acdans),https://ieeexplore.ieee.org/document/9497496/,"As new commercial and military systems evolve, engineers face significant challenges that require solutions beyond traditional systems engineering. For example, military commanders recognize that in order to confront threats from high-tech adversaries, an advanced system of systems (SoS) is required to coordinate combat across multiple battlefield domains: land, sea, air, space, and cyberspace. System of Systems Engineering (SoSE), along with associated Modeling and Simulation (M&S) tools, can fill some of this need, especially for operational decision-support for complex multi-domain environments. This paper presents an M&S-based SoSE approach for complex SoS composed of deterministic and non-deterministic subsystems supported with reinforcement learning. The paper presents this new methodology, use cases, and preliminary results that address specific SoS challenges for a set of complex decision-support challenges.",included,1758,0.8016894459724426
10.48550/arxiv.2207.00644,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,arXiv.org,2022-01-01 00:00:00,semantic_scholar,using a cognitive architecture to consider antiblackness in design and development of ai systems,https://www.semanticscholar.org/paper/266c331b1036cfddabdf86af799cd6bd6e5ac9ef,"How might we use cognitive modeling to consider the ways in which antiblackness, and racism more broadly, impact the design and development of AI systems? We provide a discussion and an example towards an answer to this question. We use the ACT-R/{\Phi} cognitive architecture and an existing knowledge graph system, ConceptNet, to consider this question not only from a cognitive and sociocultural perspective, but also from a physiological perspective. In addition to using a cognitive modeling as a means to explore how antiblackness may manifest in the design and development of AI systems (particularly from a software engineering perspective), we also introduce connections between antiblackness, the Human, and computational cognitive modeling. We argue that the typical eschewing of sociocultural processes and knowledge structures in cognitive architectures and cognitive modeling implicitly furthers a colorblind approach to cognitive modeling and hides sociocultural context that is always present in human behavior and affects cognitive processes.",included,1148,0.8016064763069153
10.1145/3387940.3391493,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Conference on Software Engineering,2020-01-01 00:00:00,semantic_scholar,human-ai partnerships for chaos engineering,https://www.semanticscholar.org/paper/1b2987f3d07f0e55e213320c728e4a010c4db080,"Chaos Engineering refers to the practice of introducing faults in a system and observe the extent to which the system remains fault tolerant. However, is randomization the best approach to expose faults within a system? We aim to answer this question by introducing Chaos into different software architecture patterns and demonstrate how a back-end system can be made fault tolerant through artificial intelligence (AT). This paper discusses what aspects of AI would be used to make a system more resilient to perturbations and the results of these findings against existing chaos engineering approaches.",not included,780,0.8013909459114075
10.1145/3284869.3284875,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,International Conference on Smart Objects and Technologies for Social Good,2018-01-01 00:00:00,semantic_scholar,intelligent machines for good?: more focus on the context,https://www.semanticscholar.org/paper/0a33dfef5b2d1588b3a6796ad9b827054699c79d,"Machine learning and modern Artificial Intelligence (AI) systems are influencing several aspects of our human lives. Many of these algorithms, based on Artificial Neural Networks (ANNs), have been empowered to make decisions and take actions, based on the well-known notions of efficiency and speed. The aura of objectivity and infallibility of such algorithms, nonetheless, have been already put into question (e.g., refer to the debate about the recent tragic car crashes that have involved self-driving cars). In this setting, our intuition identifies a key issue around the problem of AI errors and bias into the insufficient or inaccurate (human) activity of comprehension and codification of the context where the ANNs will have to operate. We present here a simple cognification ANN-based case study, in an underwater scenario, where we recovered from a situation of partial failure, by including additional contextual factors that were initially disregarded. Our final reflection is that a nuanced consideration of a complex context, and subsequent technical actions, should be always kept in mind before an AI-based system takes its final shape. Because machines have still no context for what they are doing, it is a human duty and responsibility to codify it.",included,532,0.8012804985046387
10.1109/isse46696.2019.8984475,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),SCOPUS_ID:85081091640,scopus,2019-10-01 00:00:00,scopus,design and validation of cyber-physical systems through model abstraction<sup>∗</sup>,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85081091640&origin=inward,"
AbstractView references

Cyber Physical Systems (CPSs) are a category of systems of systems (SoS) that integrate physical and computational elements. Such systems have existed for some time, but rigorous design methodologies for CPSs are scarce. The typical design process of a CPS makes use of a large number of models to help answer the wide range of design questions that arise in development. In other words, the design process produces models that describe the various crucial aspects, scopes and system components on different level of detail and abstraction. These partial models can potentially be coupled for effective information propagation across the different modeling perspectives to increase design reliability. However, they are usually expressed in different specialized tools and programming languages as a consequence of the system heterogeneity and the preference of the numerous designers involved. This paper therefore proposes generating abstractions of detailed sub-models, and then embedding those abstractions into system-wide models formulated in other formalisms. © 2019 IEEE.
",not included,2870,0.8006588816642761
10.23919/istafrica.2017.8101981,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),2017 IST-Africa Week Conference (IST-Africa),IEEE,2017-06-02 00:00:00,ieeexplore,managing diseases thru' asclepios: an agile information exploitation framework,https://ieeexplore.ieee.org/document/8101981/,"This paper describes the development of an open-source information system, called Asclepios, which manages a plethora of information on communicable diseases in an agile manner. Asclepios exploits information from multiple databases from both open sources (Third Party) and Second party sources. A variety of tools are available in Asclepios to perform extensive processing of numeric and texts (along with some image and video processing) so that trend information can be gleaned on various communicable diseases. The Asclepios architecture draws together a confluence of technologies and industrial standards such as: cloud computing, metadata, ontology generation and management, artificial intelligence, pattern recognition, decision support system, data mining and systems engineering. Because of the use of Component Based Software Engineering (CBSE) methodology for its design, the architecture is scalable, its components replaceable dynamically and configured for the requirements of a given application. The underlying architecture of Asclepios is therefore horizontal, but it has an ability to support several verticals as epidemiology, pharmacology and other fields easily. The application of Asclepios is wide ranging - from military to Government through to medical and tourism and pharmaceuticals. Further, Asclepios-like applications are very much needed in most Third world countries, including all countries in Africa, as it can significantly enhance the health, safety and well-being of people.",included,1812,0.8005644679069519
10.1109/scc55611.2022.00059,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,IEEE International Conference on Services Computing,2022-01-01 00:00:00,semantic_scholar,"digital sovereignty and software engineering for the iot-laden, ai/ml-driven era",https://www.semanticscholar.org/paper/5584452d43b9317528fdb22d3bffcd38ba124449,"Today’s software engineering already needs to deal with challenges originating from the multidisciplinarity that is required to realize IoT products. Many variants consist of sensor/actuator-powered systems that nowadays use AI/ML systems to better cope with the unstructuredness of their intended operational design domain (ODD). At the same time, though, such systems need to be monitored, diagnosed, maintained, and evolved using cloud-powered dashboards and data analytics pipelines that process, aggregate, and analyze countless data points–preferably in real-time. This position paper discusses selected aspects related to Digital Sovereignty from a software engineering’s perspective for the IoT-laden, AI/ML-driven era. While we can undeniably expect more and more benefits from such solutions, light shall be shed in particular on challenges and responsibilities at design-and operation-time that, at minimum, prepare for and enable or, even better, preserve and extend digital sovereignty from a software engineering’s perspective.",not included,1146,0.8003007173538208
10.18420/inf2022_95,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),semantic_scholar,arXiv.org,2021-01-01 00:00:00,semantic_scholar,mde4qai: towards model-driven engineering for quantum artificial intelligence,https://www.semanticscholar.org/paper/ce79dcf0c1c83e1f3a4fd029690870211e36c0f7,"Over the past decade, Artificial Intelligence (AI) has provided enormous new possibilities and opportunities, but also new demands and requirements for software systems. In particular, Machine Learning (ML) has proven useful in almost every vertical application domain. Although other subdisciplines of AI, such as intelligent agents and Multi-Agent Systems (MAS) did not become promoted to the same extent, they still possess the potential to be integrated into the mainstream technology stacks and ecosystems, for example, due to the ongoing prevalence of the Internet of Things (IoT) and smart CyberPhysical Systems (CPS). However, in the decade ahead, an unprecedented paradigm shift from classical computing towards Quantum Computing (QC) is expected, with perhaps a quantumclassical hybrid model. We expect the Model-Driven Engineering (MDE) paradigm to be an enabler and a facilitator, when it comes to the quantum and the quantum-classical hybrid applications as it has already proven beneficial in the highly complex domains of IoT, smart CPS and AI with inherently heterogeneous hardware and software platforms, and APIs. This includes not only automated code generation, but also automated model checking and verification, as well as model analysis in the early design phases, and model-to-model transformations both at the design-time and at the runtime. In this paper, the vision is focused on MDE for Quantum AI, and a holistic approach integrating all of the above.",not included,979,0.8002294898033142
10.3390/aerospace10030279,to_check,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),SCOPUS_ID:85151346420,scopus,2023-03-01 00:00:00,scopus,aerobert-classifier: classification of aerospace requirements using bert,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85151346420&origin=inward,"
AbstractView references

The system complexity that characterizes current systems warrants an integrated and comprehensive approach to system design and development. This need has brought about a paradigm shift towards Model-Based Systems Engineering (MBSE) approaches to system design and a departure from traditional document-centric methods. While MBSE shows great promise, the ambiguities and inconsistencies present in Natural Language (NL) requirements hinder their conversion to models directly. The field of Natural Language Processing (NLP) has demonstrated great potential in facilitating the conversion of NL requirements into a semi-machine-readable format that enables their standardization and use in a model-based environment. A first step towards standardizing requirements consists of classifying them according to the type (design, functional, performance, etc.) they represent. To that end, a language model capable of classifying requirements needs to be fine-tuned on labeled aerospace requirements. This paper presents an open-source, annotated aerospace requirements corpus (the first of its kind) developed for the purpose of this effort that includes three types of requirements, namely design, functional, and performance requirements. This paper further describes the use of the aforementioned corpus to fine-tune BERT to obtain the aeroBERT-Classifier: a new language model for classifying aerospace requirements into design, functional, or performance requirements. Finally, this paper provides a comparison between aeroBERT-Classifier and other text classification models such as GPT-2, Bidirectional Long Short-Term Memory (Bi-LSTM), and bart-large-mnli. In particular, it shows the superior performance of aeroBERT-Classifier on classifying aerospace requirements over existing models, and this is despite the fact that the model was fine-tuned using a small labeled dataset. © 2023 by the authors.
",not included,2175,0.800186276435852
