abstract,doi,downloadUrl,id,title,publishedDate,publisher,journals,database,query_name,query_value
"This paper presents a comparative analysis of human and AI performance on a sentiment analysis task involving the coding of qualitative data from community program transcripts. The results demonstrate promising but imperfect agreement between two AI models, Claude and Bing, versus three human annotators and one expert annotator using the Community Capitals framework categories. While both models achieved fair alignment with human judgment, confusion patterns emerged involving metaphorical language and text overlapping multiple categories. The findings provide a case study for benchmarking conversational AI systems against human baselines to reveal limitations and target improvements. Key gaps center around distinguishing between social and human elements and handling cultural references. Expanded testing on more diverse datasets could further quantify differences in classification capabilities. Overall, the analysis exposes definable areas where machines still struggle compared to humans, highlighting productive research directions to eventually achieve a similar threshold to humans across diverse language inputs. As AI systems enter real-world applications, human-AI comparative studies can help define boundaries between robust statistics-based learning and adaptive human cognition",,https://core.ac.uk/download/599439372.pdf,153851243,evaluating ai sentiment analysis,2023-01-01T08:00:00,Rollins Scholarship Online,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper explores educational interactions involving humans and artificial
intelligences not as sequences of prompts and responses, but as a social
process of conversation and exploration. In this conception, learners
continually converse with AI language models within a dynamic computational
medium of internet tools and resources. Learning happens when this distributed
system sets goals, builds meaning from data, consolidates understanding,
reconciles differences, and transfers knowledge to new domains. Building social
generative AI for education will require development of powerful AI systems
that can converse with each other as well as humans, construct external
representations such as knowledge maps, access and contribute to internet
resources, and act as teachers, learners, guides and mentors. This raises
fundamental problems of ethics. Such systems should be aware of their
limitations, their responsibility to learners and the integrity of the
internet, and their respect for human teachers and experts. We need to consider
how to design and constrain social generative AI for education.Comment: 8 pages, 4 figures, 1 tabl",,http://arxiv.org/abs/2306.10063,143477920,"towards social generative ai for education: theory, practices and ethics",2023-06-14T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In the digital transformation era, when flexibility and know-how in manufacturing complex products become a critical competitive advantage, artificial intelligence (AI) is one of the technologies driving the digital transformation of industry and industrial products. These products with high complexity based on multi-dimensional requirements need flexible and adaptive manufacturing lines and novel components, e.g., dedicated CPUs, GPUs, FPGAs, TPUs and neuromorphic architectures that support AI operations at the edge with reliable sensors and specialised AI capabilities. 

The change towards AI-driven applications in industrial sectors enables new innovative industrial and manufacturing models. New process management approaches appear and become part of the core competence in the organizations and the network of manufacturing sites. 

In this context, bringing AI from the cloud to the edge and promoting the silicon-born AI components by advancing Moore’s law and accelerating edge processing adoption in different industries through reference implementations becomes a priority for digitising industry.

This article gives an overview of the ECSEL AI4DI project that aims to apply at the edge AI-based technologies, methods, algorithms, and integration with Industrial Internet of Things (IIoT) and robotics to enhance industrial processes based on repetitive tasks, focusing on replacing process identification and validation methods with intelligent technologies across automotive, semiconductor, machinery, food and beverage, and transportation industries.publishedVersio",10.13052/rp-9788770226103,https://core.ac.uk/download/588316362.pdf,150396703,artificial intelligence advancements for digitising industry,2022-01-01T00:00:00,River Publishers,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Both, Lean Construction (LC) techniques and Artificial Intelligence (AI) methods strive for the continuous improvement of production systems in projects and organizations. A combined implementation of both approaches is an ongoing research area. Therefore, the question arises as to whether the added value generated by implementing both approaches jointly is greater than the added value generated by implementing them independently and what is the significance of people in their combined use. This paper explores theoretically the potential of synergies between LC and AI in the AEC sector with exemplary use cases as well as their resulting effects. Humans play a crucial role as interface between a combined use of both of them. As a result, a framework containing LC, AI and people is formed as basis for further combined developments. Therefore, change management, an area in which Lean has spent several years developing, can help both approaches gain traction. With the results, targeted applications can be developed, and practice can be supported",10.5445/ir/1000162384,https://core.ac.uk/download/588864916.pdf,150942971,synergies between lean construction and artificial intelligence: ai driven continuous improvement process,2023-09-20T01:00:00,International Group for Lean Construction,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The recent sale of an artificial intelligence (AI)-generated portrait for $432,000 at Christie's art auction has raised questions about how credit and responsibility should be allocated to individuals involved and how the anthropomorphic perception of the AI system contributed to the artwork's success. Here, we identify natural heterogeneity in the extent to which different people perceive AI as anthropomorphic. We find that differences in the perception of AI anthropomorphicity are associated with different allocations of responsibility to the AI system and credit to different stakeholders involved in art production. We then show that perceptions of AI anthropomorphicity can be manipulated by changing the language used to talk about AI—as a tool versus agent—with consequences for artists and AI practitioners. Our findings shed light on what is at stake when we anthropomorphize AI systems and offer an empirical lens to reason about how to allocate credit and responsibility to human stakeholders",10.1016/j.isci.2020.101515,,89383704,who gets credit for ai-generated art?,2020-01-01T00:00:00,'Elsevier BV',"[{'title': 'iScience', 'identifiers': ['issn:2589-0042', '2589-0042']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The research publication, “Generative Agents: Interactive Simulacra of Human Behavior,” by Stanford and Google in 2023 established that large language models (LLMs) such as GPT-4 can generate interactive agents with credible and emergent human-like behaviors. However, their application in simulating human responses in cybersecurity scenarios, particularly in social engineering attacks, remains unexplored. In addressing that gap, this study explores the potential of LLMs, specifically the Open AI GPT-4 model, to simulate a broad spectrum of human responses to social engineering attacks that exploit human social behaviors, framing our primary research question: How does the simulated behavior of human targets, based on the Big Five personality traits, responds to social engineering attacks? . This study aims to provide valuable insights for organizations and researchers striving to systematically analyze human behavior and identify prevalent human qualities, as defined by the Big Five personality traits, that are susceptible to social engineering attacks, specifically phishing emails. Also, it intends to offer recommendations for the cybersecurity industry and policymakers on mitigating these risks. The findings indicate that LLMs can provide realistic simulations of human responses to social engineering attacks, highlighting certain personality traits as more susceptible",,https://core.ac.uk/download/588636158.pdf,150722801,harnessing large language models to simulate realistic human responses to social engineering attacks: a case study,2023-08-30T08:00:00,Virtual Commons - Bridgewater State University,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"What should our ethical concerns be in a future with ‘Artificially Intelligent’ agents?  The zeitgeist of AI agents often envisions a future encompassing a hyper intelligent singularity. In this worldview, AI “monsters” appear very separate from us as, abstracted, ethically ungrounded omnipotent overlords. A world of superintelligences that have moved beyond our comprehension, with no ethical restraint.  In this polemic, I explore a different future. I examine how realistic digital humans pose a very real ethical dilemma, as we assume intelligence based on their appearance, leading to an abdication of responsibility.  I explore the future of realistic digital agents and avatars, and ask: what does this human-like form say about us? How will we judge ourselves when the computer, looks like us? I argue that the singularity is unlikely and thus the primary ethical concern is not some superhuman AI intelligence, but in how we, ourselves, treat these digital humans",10.5130/acis2018.db,https://core.ac.uk/download/301386524.pdf,17828861,artificial intelligence is no match for human stupidity: ethical reflections on avatars and agents,2018-01-01T00:00:00,AIS Electronic Library (AISeL),[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We introduce Jais and Jais-chat, new state-of-the-art Arabic-centric
foundation and instruction-tuned open generative large language models (LLMs).
The models are based on the GPT-3 decoder-only architecture and are pretrained
on a mixture of Arabic and English texts, including source code in various
programming languages. With 13 billion parameters, they demonstrate better
knowledge and reasoning capabilities in Arabic than any existing open Arabic
and multilingual models by a sizable margin, based on extensive evaluation.
Moreover, the models are competitive in English compared to English-centric
open models of similar size, despite being trained on much less English data.
We provide a detailed description of the training, the tuning, the safety
alignment, and the evaluation of the models. We release two open versions of
the model -- the foundation Jais model, and an instruction-tuned Jais-chat
variant -- with the aim of promoting research on Arabic LLMs. Available at
https://huggingface.co/inception-mbzuai/jais-13b-chatComment: Arabic-centric, foundation model, large-language model, LLM,
  generative model, instruction-tuned, Jais, Jais-cha",,http://arxiv.org/abs/2308.16149,151805587,"jais and jais-chat: arabic-centric foundation and instruction-tuned open
  generative large language models",2023-09-29T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Artificial intelligence is rapidly and radically changing our lives and world. This book is a multidisciplinary engagement with the present and future impacts of AI from the standpoint of Christian faith. It provides technological, philosophical, and theological foundations for thinking about AI, as well as a series of reflections on the impact of AI on relationships, behavior, education, work, and moral action. The book serves as an accessible introduction to AI as well as a guide to wise consideration, design, and use of AI by examining foundational understandings and beliefs from a Christian perspective.https://digitalcommons.spu.edu/open_books/1002/thumbnail.jp",,https://core.ac.uk/download/544082988.pdf,132386051,"ai, faith, and the future",2022-01-01T08:00:00,Digital Commons @ SPU,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Large language models (LLMs) have emerged as powerful machine-learning
systems capable of handling a myriad of tasks. Tuned versions of these systems
have been turned into chatbots that can respond to user queries on a vast
diversity of topics, providing informative and creative replies. However, their
application to physical science research remains limited owing to their
incomplete knowledge in these areas, contrasted with the needs of rigor and
sourcing in science domains. Here, we demonstrate how existing methods and
software tools can be easily combined to yield a domain-specific chatbot. The
system ingests scientific documents in existing formats, and uses text
embedding lookup to provide the LLM with domain-specific contextual information
when composing its reply. We similarly demonstrate that existing image
embedding methods can be used for search and retrieval across publication
figures. These results confirm that LLMs are already suitable for use by
physical scientists in accelerating their research efforts.Comment: 12 pages, 5 figure",,http://arxiv.org/abs/2306.10067,143477933,domain-specific chatbots for science using embeddings,2023-06-15T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This research aims to explore and analyze the utilization of Artificial Intelligence (AI) as a reference in creating works in Visual Communication Design. The research method used is exploratory research, which aims to explore a specific topic or issue in more depth and gain a better understanding of it. The research procedure conducted includes: 1) Understanding keywords, 2) Testing the use of prompts on AI sites, and 3) Analyzing the data descriptively and analytically. The result obtained is that Artificial Intelligence (AI) image sites can be used as a reference in creating works of Visual Communication Design by deepening and clarifying the use of prompt sentences. The implication of this research is to consider the utilization of Artificial Intelligence (AI) image sites as a reference for creating works.Penelitian ini bertujuan untuk mengeksplorasi dan menganalisis pemanfaatan Artificial Intelligence (AI) sebagai referensi dalam membuat karya dalam Desain Komunikasi Visual. Metode penelitian yang digunakan yaitu penelitian eksploratif (exploratory research) yang bertujuan untuk menjelajahi topik atau isu tertentu secara lebih mendalam dan memperoleh pemahaman yang lebih baik tentang topik tersebut. Prosedur penelitian yang dilakukan yaitu: 1) Pemahaman kata kunci, 2) Uji coba penggunaan instruksi (prompt) pada situs-situs AI, 3) Analisa data secara deskriptif analitik. Hasil yang didapatkan yaitu situs-situs Gambar Artificial Intelligence (AI) dapat digunakan sebagai referensi dalam pembuatan karya Desain Komunikasi Visual dengan memperdalam dan memperjelas penggunaan kalimat instruksi (prompt). Implikasi dari penelitian ini yaitu menjadi pertimbangan pemanfaatan situs-situs gambar Artificial Intelligence (AI) sebagai referensi berkarya",10.30812/sasak.v5i1.2966,https://core.ac.uk/download/568525178.pdf,148539759,analisis pemanfaatan artificial intelligence (ai) sebagai referensi dalam desain komunikasi visual,2023-06-10T01:00:00,'STMIK Bumigora Mataram',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We present REMARK-LLM, a novel efficient, and robust watermarking framework
designed for texts generated by large language models (LLMs). Synthesizing
human-like content using LLMs necessitates vast computational resources and
extensive datasets, encapsulating critical intellectual property (IP). However,
the generated content is prone to malicious exploitation, including spamming
and plagiarism. To address the challenges, REMARK-LLM proposes three new
components: (i) a learning-based message encoding module to infuse binary
signatures into LLM-generated texts; (ii) a reparameterization module to
transform the dense distributions from the message encoding to the sparse
distribution of the watermarked textual tokens; (iii) a decoding module
dedicated for signature extraction; Furthermore, we introduce an optimized beam
search algorithm to guarantee the coherence and consistency of the generated
content. REMARK-LLM is rigorously trained to encourage the preservation of
semantic integrity in watermarked content, while ensuring effective watermark
retrieval. Extensive evaluations on multiple unseen datasets highlight
REMARK-LLM proficiency and transferability in inserting 2 times more signature
bits into the same texts when compared to prior art, all while maintaining
semantic integrity. Furthermore, REMARK-LLM exhibits better resilience against
a spectrum of watermark detection and removal attacks",,http://arxiv.org/abs/2310.12362,152091313,"remark-llm: a robust and efficient watermarking framework for generative
  large language models",2023-10-18T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
Article discussing the effects of artificial intelligence on the creative process in the art world,,https://core.ac.uk/download/591224401.pdf,152349809,ai and the creative process: part one,2023-10-24T08:00:00,Digital Commons@Lindenwood University,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Most experts agree that large language models (LLMs), such as those used by Copilot and ChatGPT, are expected to revo-
lutionize the way in which software is developed. Many papers are currently devoted to analyzing the potential advantages
and limitations of these generative AI models for writing code. However, the analysis of the current state of LLMs with
respect to software modeling has received little attention. In this paper, we investigate the current capabilities of ChatGPT to
perform modeling tasks and to assist modelers, while also trying to identify its main shortcomings. Our findings show that,
in contrast to code generation, the performance of the current version of ChatGPT for software modeling is limited, with
various syntactic and semantic deficiencies, lack of consistency in responses and scalability issues. We also outline our views
on how we perceive the role that LLMs can play in the software modeling discipline in the short term, and how the modeling
community can help to improve the current capabilities of ChatGPT and the coming LLMs for software modeling.Funding for open access publishing: Universidad de Málaga/ CBU",10.1007/s10270-023-01105-5,https://core.ac.uk/download/588388028.pdf,150436806,on the assessment of generative ai in modeling tasks: an experience report with chatgpt and uml,2023-01-01T00:00:00,Springer,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Large language models such as ChatGPT-3.5 and GPT-4.0 are ubiquitous and
dominate the current discourse. Their transformative capabilities have led to a
paradigm shift in how we interact with and utilize (text-based) information.
Each day, new possibilities to leverage the capabilities of these models
emerge. This paper presents findings on the performance of different large
language models in a university of applied sciences' undergraduate computer
science degree program. Our primary objective is to assess the effectiveness of
these models within the curriculum by employing them as educational aids. By
prompting the models with lecture material, exercise tasks, and past exams, we
aim to evaluate their proficiency across different computer science domains. We
showcase the strong performance of current large language models while
highlighting limitations and constraints within the context of such a degree
program. We found that ChatGPT-3.5 averaged 79.9% of the total score in 10
tested modules, BingAI achieved 68.4%, and LLaMa, in the 65 billion parameter
variant, 20%. Despite these convincing results, even GPT-4.0 would not pass the
degree program - due to limitations in mathematical calculations.Comment: Submitted to AI4AI Workshop 202",,http://arxiv.org/abs/2308.02432,144991567,"performance of large language models in a computer science degree
  program",2023-07-24T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The growth of artificial intelligence (AI) is being referred to as the beginning of ""the fourth industrial revolution"". With the rapid development of hardware, algorithms, and applications, AI not only provides a new concept and relevant solutions to solve the problem of complexity science but also provides a new concept and method to promote the development of traditional Chinese medicine (TCM). In this study, based on the research and development of AI technology applications in biomedical and clinical diagnosis and treatment, we introduce AI technologies in current TCM research. This can have applications in intelligent clinical information acquisition, intelligent clinical decision, and efficacy evaluation of TCM; intelligent classification management, intelligent prescription, and drug research in Chinese herbal medicine; and health management. Furthermore, we propose a framework of ""intelligent TCM"" and outline its development prospects",10.61797/ijaaiml.v2i2.121,https://core.ac.uk/download/595875541.pdf,154163773,combining artificial intelligence with traditional chinese medicine for intelligent health management,2021-12-15T00:00:00,Research Lake International Inc.,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Public debate about AI is dominated by Frankenstein Syndrome, the fear that AI will become superhuman and escape human control. Although superintelligence is certainly a possibility, the interest it excites can distract the public from a more imminent concern: the rise of Artificial Stupidity (AS). This article discusses the roots of Frankenstein Syndrome in Mary Shelley’s famous novel of 1818. It then provides a philosophical framework for analysing the stupidity of artificial agents, demonstrating that modern intelligent systems can be seen to suffer from ‘stupidity of judgement’. Finally it identifies an alternative literary tradition that exposes the perils and benefits of AS. In the writings of Edmund Spenser, Jonathan Swift and E.T.A. Hoffmann, ASs replace, enslave or delude their human users. More optimistically, Joseph Furphy and Laurence Sterne imagine ASs that can serve human intellect as maps or as pipes. These writers provide a strong counternarrative to the myths that currently drive the AI debate. They identify ways in which even stupid artificial agents can evade human control, for instance by appealing to stereotypes or distancing us from reality. And they underscore the continuing importance of the literary imagination in an increasingly automated society",10.1080/03080188.2020.1840219,https://core.ac.uk/download/334410702.pdf,8228882,artificial stupidity,2020-07-01T00:00:00,'Informa UK Limited',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This papers explores the question of human authorship when works are created
with generative AI tools.Comment: 3 figure",,http://arxiv.org/abs/2309.13055,149799493,originality and the future of copyright in an age of generative ai,2023-09-07T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The explosion in the performance of Machine Learning (ML) and the potential
of its applications are strongly encouraging us to consider its use in
industrial systems, including for critical functions such as decision-making in
autonomous systems. While the AI community is well aware of the need to ensure
the trustworthiness of AI-based applications, it is still leaving too much to
one side the issue of safety and its corollary, regulation and standards,
without which it is not possible to certify any level of safety, whether the
systems are slightly or very critical.The process of developing and qualifying
safety-critical software and systems in regulated industries such as aerospace,
nuclear power stations, railways or automotive industry has long been well
rationalized and mastered. They use well-defined standards, regulatory
frameworks and processes, as well as formal techniques to assess and
demonstrate the quality and safety of the systems and software they develop.
However, the low level of formalization of specifications and the uncertainties
and opacity of machine learning-based components make it difficult to validate
and verify them using most traditional critical systems engineering methods.
This raises the question of qualification standards, and therefore of
regulations adapted to AI. With the AI Act, the European Commission has laid
the foundations for moving forward and building solid approaches to the
integration of AI-based applications that are safe, trustworthy and respect
European ethical values. The question then becomes ""How can we rise to the
challenge of certification and propose methods and tools for trusted artificial
intelligence?",,http://arxiv.org/abs/2311.06263,153804337,no trust without regulation!,2023-09-27T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The ease of using a Large Language Model (LLM) to answer a wide variety of
queries and their high availability has resulted in LLMs getting integrated
into various applications. LLM-based recommenders are now routinely used by
students as well as professional software programmers for code generation and
testing. Though LLM-based technology has proven useful, its unethical and
unattributed use by students and professionals is a growing cause of concern.
As such, there is a need for tools and technologies which may assist teachers
and other evaluators in identifying whether any portion of a source code is LLM
generated.
  In this paper, we propose a neural network-based tool that instructors can
use to determine the original effort (and LLM's contribution) put by students
in writing source codes. Our tool is motivated by minimum description length
measures like Kolmogorov complexity. Our initial experiments with moderate
sized (up to 500 lines of code) have shown promising results that we report in
this paper",,http://arxiv.org/abs/2307.04492,144552838,calculating originality of llm assisted source code,2023-07-10T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper analyses a visual archive of drawings produced by an interactive
robotic art installation where audience members narrated their dreams into a
system powered by CLIPdraw deep learning (DL) model that interpreted and
transformed their dreams into images. The resulting archive of prompt-image
pairs were examined and clustered based on concept representation accuracy. As
a result of the analysis, the paper proposes four groupings for describing and
explaining CLIP-generated results: clear concept, text-to-text as image,
indeterminacy and confusion, and lost in translation. This article offers a
glimpse into a collection of dreams interpreted, mediated and given form by
Artificial Intelligence (AI), showcasing oftentimes unexpected, visually
compelling or, indeed, the dream-like output of the system, with the emphasis
on processes and results of translations between languages, sign-systems and
various modules of the installation. In the end, the paper argues that proposed
clusters support better understanding of the neural model",,http://arxiv.org/abs/2306.07429,143380317,explaining clip through co-creative drawings and interaction,2023-06-12T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper argues that if we are to come to creative terms with AI image-making then we must critically interrogate these new tools in the production of creative works. In doing so, designers can start to chart new creative workflows that integrate AI for image-making while augmenting and then evolving our current ways of designing. Workflows are shown that relate to how AI models can augment human creativity in hybrid (human and AI) creative endeavors while taking advantage of the affordances of these technologies",,https://core.ac.uk/download/588868937.pdf,150879228,giving up control: hybrid ai-augmented workflows for image-making,2023-10-17T08:00:00,Digital Scholarship@UNLV,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In recent years there has been growing interest in artificial neural networks (ANNs) which are quickly becoming the primary device for machine learning. Used for finding patterns in large data sets, ANNs were also recently employed in many artistic contexts: as tools for artists, semi-independent creators of content, and even as invisible ""critics"" which / who predict our aesthetic preferences. The aim of this paper is to speculate about the disruptive effect of these ‘alien agencies’ on the (modernist) aesthetic regime of art centred around the notion of autonomy. The author examines how neural networks and connectionist epistemologies may potentially affect the most common ways of producing, circulating, and valorising art. He claims that the possibility of automatizing creativity and art criticism may lead to the emergence of a new aesthetic regime based on forms of dynamic, distributed and probabilistic governance",10.14236/ewic/evac18.19,https://core.ac.uk/download/196611257.pdf,57214074,the dawn of the dead : (improbable) art after ai-zombie apocalypse,2018-01-01T00:00:00,'BCS Learning and Development Limited',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This essay explains complementary frameworks for understanding and managing AI in usage contexts. In contrast with broad generalizations about the nature and impact of AI, those frameworks focus on specific AI-based digital agents used by people and/or machines performing purposeful activities in business, home, or societal environments. The agent responsibility (AR) framework helps in describing roles and responsibilities of specific AI-based digital agents in their usage contexts. The agent evaluation (AE) framework identifies six criteria that different stakeholders might use for evaluating AI-based digital agents",,https://core.ac.uk/download/552657985.pdf,137210499,how can you verify that i am using ai? complementary frameworks for describing and evaluating ai-based digital agents in their usage contexts,2023-01-03T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"To apply eyeshadow without a brush, should I use a cotton swab or a
toothpick? Questions requiring this kind of physical commonsense pose a
challenge to today's natural language understanding systems. While recent
pretrained models (such as BERT) have made progress on question answering over
more abstract domains - such as news articles and encyclopedia entries, where
text is plentiful - in more physical domains, text is inherently limited due to
reporting bias. Can AI systems learn to reliably answer physical common-sense
questions without experiencing the physical world? In this paper, we introduce
the task of physical commonsense reasoning and a corresponding benchmark
dataset Physical Interaction: Question Answering or PIQA. Though humans find
the dataset easy (95% accuracy), large pretrained models struggle (77%). We
provide analysis about the dimensions of knowledge that existing models lack,
which offers significant opportunities for future research.Comment: AAAI 202",10.1609/aaai.v34i05.6239,http://arxiv.org/abs/1911.11641,89589990,piqa: reasoning about physical commonsense in natural language,2019-11-26T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In an educational landscape dramatically altered by the swift proliferation
of Large Language Models, this essay interrogates the urgent this essay
interrogates the urgent pedagogical modifications required in secondary
schooling. Anchored in Madeline Grumet's triadic framework of curriculum
inquiry, the study delineates the multifaceted relationship between Generative
AI and Elliot Eisner's explicit, implicit, and null curriculum concepts. It
scrutinizes the logistical and ethical challenges, such as the reliability of
AI detectors, that educators confront when attempting to assimilate this
nascent technology into long-standing curricular structures. Engaging with Ted
Aoki's theory of the ""zone of between"", the essay illuminates educators'
dilemmas in reconciling prescriptive curricular aims with the fluid realities
of classroom life, all within an educational milieu in constant flux due to
Generative AI. The paper culminates in a reflective analysis by the researcher,
identifying avenues for further scholarly investigation within each of Grumet's
constitutive strands of curriculum theory, thereby providing a roadmap for
future research on Generative AI's transformative impact on educational
practice.Comment: 14 page",,http://arxiv.org/abs/2309.13053,149799103,using curriculum theory to inform approaches to generative ai in schools,2023-09-07T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"An important challenge for safety in machine learning and artificial
intelligence systems is a~set of related failures involving specification
gaming, reward hacking, fragility to distributional shifts, and Goodhart's or
Campbell's law. This paper presents additional failure modes for interactions
within multi-agent systems that are closely related. These multi-agent failure
modes are more complex, more problematic, and less well understood than the
single-agent case, and are also already occurring, largely unnoticed. After
motivating the discussion with examples from poker-playing artificial
intelligence (AI), the paper explains why these failure modes are in some
senses unavoidable. Following this, the paper categorizes failure modes,
provides definitions, and cites examples for each of the modes: accidental
steering, coordination failures, adversarial misalignment, input spoofing and
filtering, and goal co-option or direct hacking. The paper then discusses how
extant literature on multi-agent AI fails to address these failure modes, and
identifies work which may be useful for the mitigation of these failure modes.Comment: 12 Pages, This version re-submitted to Big Data and Cognitive
  Computing, Special Issue ""Artificial Superintelligence: Coordination &
  Strategy",10.3390/bdcc3020021,http://arxiv.org/abs/1810.10862,54163227,"multiparty dynamics and failure modes for machine learning and
  artificial intelligence",2019-04-01T01:00:00,'MDPI AG',"[{'title': 'Big Data and Cognitive Computing', 'identifiers': ['2504-2289', 'issn:2504-2289']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"With the rapid growth of language-learning models like ChatGPT, academia has been forced to reckon with the way the tool can be used as a citation source. However, given the secrecy of the tool\u27s dataset and its inability to provide sources for the information it provides, the question of if using it is plagiarism has become more pressing. Examining fanfiction as a source for how plagiarism and AI has been dealt with, the paper examines the paradox of citing ChatGPT and other models like it and the central question of how and when we can use it and use it ethically",,https://core.ac.uk/download/588592139.pdf,150533677,“source?” “i made it up”: the ethics of citing chatgpt in academia,2023-07-01T08:00:00,Scholarship@Western,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Large language models (LLMs) have enabled remarkable advances in automated
task-solving with multi-agent systems. However, most existing LLM-based
multi-agent approaches rely on predefined agents to handle simple tasks,
limiting the adaptability of multi-agent collaboration to different scenarios.
Therefore, we introduce AutoAgents, an innovative framework that adaptively
generates and coordinates multiple specialized agents to build an AI team
according to different tasks. Specifically, AutoAgents couples the relationship
between tasks and roles by dynamically generating multiple required agents
based on task content and planning solutions for the current task based on the
generated expert agents. Multiple specialized agents collaborate with each
other to efficiently accomplish tasks. Concurrently, an observer role is
incorporated into the framework to reflect on the designated plans and agents'
responses and improve upon them. Our experiments on various benchmarks
demonstrate that AutoAgents generates more coherent and accurate solutions than
the existing multi-agent methods. This underscores the significance of
assigning different roles to different tasks and of team cooperation, offering
new perspectives for tackling complex tasks. The repository of this project is
available at https://github.com/Link-AGI/AutoAgents",,http://arxiv.org/abs/2309.17288,152053194,autoagents: a framework for automatic agent generation,2023-10-15T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We introduce SwiftSage, a novel agent framework inspired by the dual-process
theory of human cognition, designed to excel in action planning for complex
interactive reasoning tasks. SwiftSage integrates the strengths of behavior
cloning and prompting large language models (LLMs) to enhance task completion
performance. The framework comprises two primary modules: the Swift module,
representing fast and intuitive thinking, and the Sage module, emulating
deliberate thought processes. The Swift module is a small encoder-decoder LM
fine-tuned on the oracle agent's action trajectories, while the Sage module
employs LLMs such as GPT-4 for subgoal planning and grounding. We develop a
heuristic method to harmoniously integrate the two modules, resulting in a more
efficient and robust problem-solving process. In 30 tasks from the ScienceWorld
benchmark, SwiftSage significantly outperforms other methods such as SayCan,
ReAct, and Reflexion, demonstrating its effectiveness in solving complex
real-world tasks.Comment: Project website: https://yuchenlin.xyz/swiftsage",,http://arxiv.org/abs/2305.17390,143041943,"swiftsage: a generative agent with fast and slow thinking for complex
  interactive tasks",2023-05-27T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Large language models (LLMs), with their remarkable conversational
capabilities, have demonstrated impressive performance across various
applications and have emerged as formidable AI assistants. In view of this, it
raises an intuitive question: Can we harness the power of LLMs to build
multimodal AI assistants for visual applications? Recently, several multi-modal
models have been developed for this purpose. They typically pre-train an
adaptation module to align the semantics of the vision encoder and language
model, followed by fine-tuning on instruction-following data. However, despite
the success of this pipeline in image and language understanding, its
effectiveness in joint video and language understanding has not been widely
explored. In this paper, we aim to develop a novel multi-modal foundation model
capable of comprehending video, image, and language within a general framework.
To achieve this goal, we introduce Valley, a Video Assistant with Large
Language model Enhanced abilitY. The Valley consists of a LLM, a temporal
modeling module, a visual encoder, and a simple projection module designed to
bridge visual and textual modes. To empower Valley with video comprehension and
instruction-following capabilities, we construct a video instruction dataset
and adopt a two-stage tuning procedure to train it. Specifically, we employ
ChatGPT to facilitate the construction of task-oriented conversation data
encompassing various tasks, including multi-shot captions, long video
descriptions, action recognition, causal relationship inference, etc.
Subsequently, we adopt a pre-training-then-instructions-tuned pipeline to align
visual and textual modalities and improve the instruction-following capability
of Valley. Qualitative experiments demonstrate that Valley has the potential to
function as a highly effective video assistant that can make complex video
understanding scenarios easy",,http://arxiv.org/abs/2306.07207,152033788,valley: video assistant with large language model enhanced ability,2023-10-08T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This study examines the efficacy of two SOTA large language models (LLMs),
namely ChatGPT and Microsoft Bing Chat (BingChat), in catering to the needs of
Vietnamese students. Although ChatGPT exhibits proficiency in multiple
disciplines, Bing Chat emerges as the more advantageous option. We conduct a
comparative analysis of their academic achievements in various disciplines,
encompassing mathematics, literature, English language, physics, chemistry,
biology, history, geography, and civic education. The results of our study
suggest that BingChat demonstrates superior performance compared to ChatGPT
across a wide range of subjects, with the exception of literature, where
ChatGPT exhibits better performance. Additionally, BingChat utilizes the more
advanced GPT-4 technology in contrast to ChatGPT, which is built upon GPT-3.5.
This allows BingChat to improve to comprehension, reasoning and generation of
creative and informative text. Moreover, the fact that BingChat is accessible
in Vietnam and its integration of hyperlinks and citations within responses
serve to reinforce its superiority. In our analysis, it is evident that while
ChatGPT exhibits praiseworthy qualities, BingChat presents a more apdated
solutions for Vietnamese students.Comment: 13 pages; 6 figure",,http://arxiv.org/abs/2307.08272,144848659,chatgpt is good but bing chat is better for vietnamese students,2023-07-19T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The use of decision-making support tools during assessments, such as electronic differential diagnosis in examinations, is just the tip of the iceberg when it comes to how technology is currently changing assessment practice. We have reached a transformative stage in the development of artificial intelligence (AI). We can no longer rely on non-invigilated assessments and submitted ‘artefacts’ to demonstrate student learning and competence. This is bringing many long-term demands on educators, course coordinators and curriculum designers, forcing us to rethink assessment approaches. Going forward, we see an important distinction between ‘assisted’ assessments and ‘unassisted’ assessments. With the recent increase and facilitation of virtual assessment through convenient online platforms, and the new challenge to non-invigilated assessment formats posed by AI, we think the time has come for the ‘rehabilitation’ and re-acceptance of the oral format as a highly valuable and unique form of assessment in medical education. Nevertheless, generative AI need not threaten the validity or trustworthiness of our assessments in either formative or summative contexts. Rather, it can add fidelity and nuance to assisted assessment while facilitating a greater focus and purposefulness to unassisted assessment",,https://core.ac.uk/download/576205637.pdf,147706041,rethinking assessment in response to generative artificial intelligence,2023-01-01T08:00:00,ACEReSearch,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Recent increases in computing power, coupled with rapid growth in the availability and quantity of data have rekindled our interest in the theory and applications of artificial intelligence (AI). However, for AI to be confidently rolled out by industries and governments, users want greater transparency through explainable AI (XAI) systems. The author introduces XAI concepts, and gives an overview of areas in need of further exploration-such as type-2 fuzzy logic systems-to ensure such systems can be fully understood and analyzed by the lay user",10.1109/mc.2018.3620965,https://core.ac.uk/download/288431084.pdf,8728912,"toward human-understandable, explainable ai",2018-09-01T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In this paper, we address the concept of ""alignment"" in large language models
(LLMs) through the lens of post-structuralist socio-political theory,
specifically examining its parallels to empty signifiers. To establish a shared
vocabulary around how abstract concepts of alignment are operationalised in
empirical datasets, we propose a framework that demarcates: 1) which dimensions
of model behaviour are considered important, then 2) how meanings and
definitions are ascribed to these dimensions, and by whom. We situate existing
empirical literature and provide guidance on deciding which paradigm to follow.
Through this framework, we aim to foster a culture of transparency and critical
evaluation, aiding the community in navigating the complexities of aligning
LLMs with human populations.Comment: Socially Responsible Language Modelling Research (SoLaR) @ NeurIPs
  202",,http://arxiv.org/abs/2310.02457,153558011,"the empty signifier problem: towards clearer paradigms for
  operationalising ""alignment"" in large language models",2023-11-15T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Recent advancements in large language models (LLMs) have shown potential for
human-like agents. To help these agents adapt to new tasks without extensive
human supervision, we propose the Learning through Communication (LTC)
paradigm, a novel training approach enabling LLM agents to improve continuously
through interactions with their environments and other agents. Recent
advancements in large language models (LLMs) have shown potential for
human-like agents. To help these agents adapt to new tasks without extensive
human supervision, we propose the Learning through Communication (LTC)
paradigm, a novel training approach enabling LLM agents to improve continuously
through interactions with their environments and other agents. Through
iterative exploration and PPO training, LTC empowers the agent to assimilate
short-term experiences into long-term memory. To optimize agent interactions
for task-specific learning, we introduce three structured communication
patterns: Monologue, Dialogue, and Analogue-tailored for common tasks such as
decision-making, knowledge-intensive reasoning, and numerical reasoning. We
evaluated LTC on three datasets: ALFWorld (decision-making), HotpotQA
(knowledge-intensive reasoning), and GSM8k (numerical reasoning). On ALFWorld,
it exceeds the instruction tuning baseline by 12% in success rate. On HotpotQA,
LTC surpasses the instruction-tuned LLaMA-7B agent by 5.1% in EM score, and it
outperforms the instruction-tuned 9x larger PaLM-62B agent by 0.6%. On GSM8k,
LTC outperforms the CoT-Tuning baseline by 3.6% in accuracy. The results
showcase the versatility and efficiency of the LTC approach across diverse
domains. We will open-source our code to promote further development of the
community.Comment: Preprin",,http://arxiv.org/abs/2310.01444,152035003,adapting llm agents through communication,2023-10-10T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"As a research field, artificial intelligence (AI) exists for several years. More recently, technological breakthroughs, coupled with the fast availability of data, have brought AI closer to commercial use. Internet giants such as Google, Amazon, Apple or Facebook invest significantly into AI, thereby underlining its relevance for business models worldwide. For the highly data driven finance industry, AI is of intensive interest within pilot projects, still, few AI applications have been implemented so far. This study analyzes drivers and inhibitors of a successful AI application in the finance industry based on panel data comprising 22 semi-structured interviews with experts in AI in finance. As theoretical lens, we structured our results using the TOE framework. Guidelines for applying AI successfully reveal AI-specific role models and process competencies as crucial, before trained algorithms will have reached a quality level on which AI applications will operate without human intervention and moral concerns",10.24251/hicss.2019.770,https://core.ac.uk/download/186639318.pdf,9615007,artificial intelligence for the financial services industry: what challenges organizations to succeed?,2019-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The ethics of AI in industrial environments is a new field within applied ethics, with notable dynamics but no well-established issues and no standard overviews. It poses many more challenges than similar consumer and general business applications, and the digital transformation of industrial sectors has brought into the ethical picture even more considerations to address. This relates to integrating AI and autonomous learning machines based on neural networks, genetic algorithms, and agent architectures into manufacturing processes.

This article presents the ethical challenges in industrial environments and the implications of developing, implementing, and deploying AI technologies and applications in industrial sectors in terms of complexity, energy demands, and environmental and climate changes. 

It also gives an overview of the ethical considerations concerning digitising industry and ways of addressing them, such as potential impacts of AI on economic growth and productivity, workforce, digital divide, alignment with trustworthiness, transparency, and fairness.

Additionally, potential issues concerning the concentration of AI technology within only a few companies, human-machine relationships, and behavioural and operational misconduct involving AI are examined. 

Manufacturers, designers, owners, and operators of AI—as part of autonomy and autonomous industrial systems—can be held responsible if harm is caused. Therefore, the need for accountability is also addressed, particularly related to industrial applications with non-functional requirements such as safety, security, reliability, and maintainability supporting the means of AI-based technologies and applications to be auditable via an assessment either internally or by a third party. This requires new standards and certification schemes that allow AI systems to be assessed objectively for compliance and results to be repeatable and reproducible. 

This article is based on work, findings, and many discussions within the context of the AI4DI project.publishedVersio",10.13052/rp-9788770226103,https://core.ac.uk/download/588316377.pdf,150396697,ethical considerations and trustworthy industrial ai systems,2022-01-01T00:00:00,River Publishers,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"With AI technology rapidly advancing, natural language processing systems are producing higher quality creative work like music and poetry. With the arrival of GPT-3, the generative pre-trained transformer, in May 2020, we are now confronting more opportunities to question its strengths and weaknesses.  These transformer models have been known to successfully recreate the styles and themes of specific authors, writing across genres, and creating exciting new reversals. The main criticism remains that the AI cannot maintain coherent arguments or narrative threads",,https://core.ac.uk/download/427141978.pdf,112590265,the gpt3 re-imagining of “howl” by allen ginsberg:  what  are  the strengths  and  weaknesses  of  this  representation?,2020-10-01T08:00:00,"Digital Kenyon: Research, Scholarship, and Creative Exchange",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The advent of Large Language Models (LLMs) has shown the potential to improve
relevance and provide direct answers in web searches. However, challenges arise
in validating the reliability of generated results and the credibility of
contributing sources, due to the limitations of traditional information
retrieval algorithms and the LLM hallucination problem. Aiming to create a
""PageRank"" for the LLM era, we strive to transform LLM into a relevant,
responsible, and trustworthy searcher. We propose a novel generative retrieval
framework leveraging the knowledge of LLMs to foster a direct link between
queries and online sources. This framework consists of three core modules:
Generator, Validator, and Optimizer, each focusing on generating trustworthy
online sources, verifying source reliability, and refining unreliable sources,
respectively. Extensive experiments and evaluations highlight our method's
superior relevance, responsibility, and trustfulness against various SOTA
methods.Comment: 14 pages, 4 figures, under peer revie",,http://arxiv.org/abs/2310.12443,152091489,"know where to go: make llm a relevant, responsible, and trustworthy
  searcher",2023-10-18T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper looks back at historical precedents for how computational systems and ideas have been visualized as a means of access to and engagement with a broader audience, and to develop a new more tangible language to address abstraction. These precedents share a subversive ground in using a visual language to provoke new ways of engaging with about complex ideas. Two new approaches to visualizing algorithmic systems are proposed for the emerging context of algorithmic ethics in society, looking at prototypical algorithms in computer vision and machine learning systems, to think through the meaning created by algorithmic structure and process. The aim is to use visual design to provoke new kinds of thinking and criticality that can offer opportunities to address algorithms in their increasingly more politicized role today. These new approaches are developed from an arts research perspective to support critical thinking and arts knowledge through creative coding and interactive design",10.7559/citarj.v11i2.666,https://core.ac.uk/download/480542279.pdf,129700848,computational visualization for critical thinking,2019-05-01T01:00:00,'Universidade Catolica Portuguesa',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The Department of Defense has stated publicly that future defense capabilities will depend strongly on autonomous systems;systems that make sophisticated judgments about the world and choose appropriate courses of action, and perhaps even adapt and learn over time. Developing and deploying such systems poses more than just a technical challenge in robotics and artificial intelligence;it also poses many challenges to the acquisition process and workforce. From cost estimation to sustainment planning, every aspect of acquisition will be affected. Test and evaluation, in particular, may require not only novel methodologies and resources, but organizational and process changes as well.Naval Postgraduate School Acquisition Research Progra",,https://core.ac.uk/download/343437429.pdf,123566941,acquisition challenges of autonomous systems,2018-04-30T01:00:00,"Monterey, California. Naval Postgraduate School",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper presents a simulation-based approach to countering online dis/misinformation. This disruptive technology experiment incorporated a synthetic environment component, based on adapted SIR epidemiological model to evaluate and visualize the effectiveness of suggested solutions to the issue. The participants in the simulation were given a realistic scenario depicting a dis/misinformation threat and were asked to select a number of solutions, described in IoS (Ideas-of-Systems) cards. During the event, the qualitative and quantitative characteristics of the IoS cards, were tested in a synthetic environment (SEN), built after a Susceptible-Infected-Resistant (SIR) model. The participants, divided into teams, presented and justified their dis/misinformation strategy which included three IoS card selections. A jury of subject matter experts, announced the winning team, based on the merits of the proposed strategies and the compatibility of the different cards, grouped together",,https://core.ac.uk/download/534830284.pdf,131152535,a gamefied synthetic environment for evaluation of counter-disinformation solutions,2022-01-01T08:00:00,ODU Digital Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This primer explores the exciting subject of intelligence. Intelligence is a
fundamental component of all living things, as well as Artificial
Intelligence(AI). Artificial Intelligence has the potential to affect all of
our lives and a new era for modern humans. This paper is an attempt to explore
the ideas associated with intelligence, and by doing so understand the
implications, constraints, and potentially the capabilities of future
Artificial Intelligence. As an exploration, we journey into different parts of
intelligence that appear essential. We hope that people find this useful in
determining where Artificial Intelligence may be headed. Also, during the
exploration, we hope to create new thought-provoking questions. Intelligence is
not a single weighable quantity but a subject that spans Biology, Physics,
Philosophy, Cognitive Science, Neuroscience, Psychology, and Computer Science.
Historian Yuval Noah Harari pointed out that engineers and scientists in the
future will have to broaden their understandings to include disciplines such as
Psychology, Philosophy, and Ethics. Fiction writers have long portrayed
engineers and scientists as deficient in these areas. Today, modern society,
the emergence of Artificial Intelligence, and legal requirements all act as
forcing functions to push these broader subjects into the foreground. We start
with an introduction to intelligence and move quickly onto more profound
thoughts and ideas. We call this a Life, the Universe and Everything primer,
after the famous science fiction book by Douglas Adams. Forty-two may very well
be the right answer, but what are the questions?Comment: 34 pages, 12 Figure",,http://arxiv.org/abs/2008.07324,87179770,intelligence primer,2020-08-18T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Artificial Intelligence (AI) appears to be advancing at an ever-accelerating pace and affecting

much of human life. The power of AI has already been demonstrated in various areas – from

smartphone personal assistants and customer support chatbots to medical diagnoses and

driverless cars. At the same time, these applications bring multiple challenges and much

hyperbole. Nonetheless, of particular importance here, AI systems have also entered the

classroom. However, while promising to enhance education, the design and deployment of these

tools again raise particular concerns and challenges. We begin this chapter with a brief history

and definition of AI outlining the evolution of AI techniques aiming to imitate or outperform

human cognitive capacities. We continue by exploring what AI systems promise to deliver in

educational contexts and their impact on learners, examining the interaction through the lens of

three analytical categories: learning with AI, learning about AI and preparing for AI. We also

explore the risks related to the introduction of AI into education and investigate transversal

issues related to all three categories, noting that currently little attention has been paid to what is

ethically acceptable for AI and education. Finally, we conclude by trying to answer two

questions: how can we make better AI tools for education and how can education help address

the challenges created by AI",,https://core.ac.uk/download/565368198.pdf,149342008,the challenge of artificial intelligence,2023-01-01T00:00:00,'Cambridge University Press (CUP)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We introduce DataCI, a comprehensive open-source platform designed
specifically for data-centric AI in dynamic streaming data settings. DataCI
provides 1) an infrastructure with rich APIs for seamless streaming dataset
management, data-centric pipeline development and evaluation on streaming
scenarios, 2) an carefully designed versioning control function to track the
pipeline lineage, and 3) an intuitive graphical interface for a better
interactive user experience. Preliminary studies and demonstrations attest to
the easy-to-use and effectiveness of DataCI, highlighting its potential to
revolutionize the practice of data-centric AI in streaming data contexts.Comment: 3 pages, 4 figure",,http://arxiv.org/abs/2306.15538,143787585,dataci: a platform for data-centric ai on streaming data,2023-06-27T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"© 2020 ACM. This is the author's version of the work. It is posted here by permission of ACM for your personal use. Not for redistribution. The definitive version was published in Ubiquity [Vol 2020, Iss. May, (May 2020): https://doi.org/10.1145/3401842.The use of computers in design is substantially different today from what it was only 30 years ago, and light-years ahead of how things were designed before computers entered the scene 60 years ago. This article discusses the use of computers, more specifically computational design, as a useful tool for designers. Herein, computational design refers to the application of computational tools to design practice.Peer reviewe",10.1145/3401842,https://core.ac.uk/download/323988825.pdf,8788477,machine learning and computational design,2020-05-01T00:00:00,'Association for Computing Machinery (ACM)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The increasing presence of artificial intelligence and automated technology is changing journalism. While the term artificial intelligence dates back to the 1950s, and has since acquired several meanings, there is a general consensus around the nature of AI as the theory and development of computer systems able to perform tasks normally requiring human intelligence. Since many of the AI tools journalists are now using come from other disciplines—computer science, statistics, and engineering, for example—they tend to be general purpose. 

Now that journalists are using AI in the newsroom, what must they know about these technologies, and what must technologists know about journalistic standards when building them? 

On June 13, 2017, the Tow Center for Digital Journalism and the Brown Institute for Media Innovation convened a policy exchange forum of technologists and journalists to consider how artificial intelligence is impacting newsrooms and how it can be better adapted to the field of journalism. The gathering explored questions like: How can journalists use AI to assist the reporting process? Which newsroom roles might AI replace? What are some areas of AI that news organizations have yet to capitalize on? Will AI eventually be a part of the presentation of every news story",10.7916/d8x92prd,https://core.ac.uk/download/161457444.pdf,46258616,artificial intelligence: practice and implications for journalism,2017-01-01T00:00:00,'Columbia University Libraries/Information Services',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Large language models (LLMs) have been increasingly used to interact with
external environments (e.g., games, compilers, APIs) as goal-driven agents.
However, it remains challenging for these language agents to quickly and
efficiently learn from trial-and-error as traditional reinforcement learning
methods require extensive training samples and expensive model fine-tuning. We
propose Reflexion, a novel framework to reinforce language agents not by
updating weights, but instead through linguistic feedback. Concretely,
Reflexion agents verbally reflect on task feedback signals, then maintain their
own reflective text in an episodic memory buffer to induce better
decision-making in subsequent trials. Reflexion is flexible enough to
incorporate various types (scalar values or free-form language) and sources
(external or internally simulated) of feedback signals, and obtains significant
improvements over a baseline agent across diverse tasks (sequential
decision-making, coding, language reasoning). For example, Reflexion achieves a
91% pass@1 accuracy on the HumanEval coding benchmark, surpassing the previous
state-of-the-art GPT-4 that achieves 80%. We also conduct ablation and analysis
studies using different feedback signals, feedback incorporation methods, and
agent types, and provide insights into how they affect performance.Comment: v4 contains a few additional experiment",,http://arxiv.org/abs/2303.11366,152034395,reflexion: language agents with verbal reinforcement learning,2023-10-10T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Dialogue systems and large language models (LLMs) have gained considerable
attention. However, the direct utilization of LLMs as task-oriented dialogue
(TOD) models has been found to underperform compared to smaller task-specific
models. Nonetheless, it is crucial to acknowledge the significant potential of
LLMs and explore improved approaches for leveraging their impressive abilities.
Motivated by the goal of leveraging LLMs, we propose an alternative approach
called User-Guided Response Optimization (UGRO) to combine it with a smaller
TOD model. This approach uses LLM as annotation-free user simulator to assess
dialogue responses, combining them with smaller fine-tuned end-to-end TOD
models. By utilizing the satisfaction feedback generated by LLMs, UGRO further
optimizes the supervised fine-tuned TOD model. Specifically, the TOD model
takes the dialogue history as input and, with the assistance of the user
simulator's feedback, generates high-satisfaction responses that meet the
user's requirements. Through empirical experiments on two TOD benchmarks, we
validate the effectiveness of our method. The results demonstrate that our
approach outperforms previous state-of-the-art (SOTA) results.Comment: Accepted by CIKM 202",10.1145/3583780.3615220,http://arxiv.org/abs/2306.09821,152091710,"unlocking the potential of user feedback: leveraging large language
  model as user simulator to enhance dialogue system",2023-10-19T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Artificial intelligence, as a separate field of research, is currently experiencing a boom - new methods of machine learning and hardware are emerging and improving, and the results achieved change the life of society. Machine translation, handwriting recognition, speech recognition are changing our reality. The work of creating unmanned vehicles, voice assistants and other devices using these technologies is in an active process. The article examines the historical context of the artificial intelligence development, it evaluates the possibilities of its introduction into cyber games, as a safe and effective platform for testing new methods of machine learning. The promotion of such projects can increase the reputation of development companies, ensure increased user confidence in other products and, with a competent marketing strategy, cause a significant public resonance among video game fans, providing the developer with economic profit",10.34069/ai/2020.28.04.15,https://core.ac.uk/download/pdf/328005485.pdf,87084537,the evolution of artificial intelligence and the possibility of its application in cyber games,2020-04-21T01:00:00,'Amazonia Investiga',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Instruction tuning large language model (LLM) on image-text pairs has
achieved unprecedented vision-language multimodal abilities. However, their
vision-language alignments are only built on image-level, the lack of
region-level alignment limits their advancements to fine-grained multimodal
understanding. In this paper, we propose instruction tuning on
region-of-interest. The key design is to reformulate the bounding box as the
format of spatial instruction. The interleaved sequences of visual features
extracted by the spatial instruction and the language embedding are input to
LLM, and trained on the transformed region-text data in instruction tuning
format. Our region-level vision-language model, termed as GPT4RoI, brings brand
new conversational and interactive experience beyond image-level understanding.
(1) Controllability: Users can interact with our model by both language and
spatial instructions to flexibly adjust the detail level of the question. (2)
Capacities: Our model supports not only single-region spatial instruction but
also multi-region. This unlocks more region-level multimodal capacities such as
detailed region caption and complex region reasoning. (3) Composition: Any
off-the-shelf object detector can be a spatial instruction provider so as to
mine informative object attributes from our model, like color, shape, material,
action, relation to other objects, etc. The code, data, and demo can be found
at https://github.com/jshilong/GPT4RoI.Comment: Code has been released at https://github.com/jshilong/GPT4Ro",,http://arxiv.org/abs/2307.03601,144509816,gpt4roi: instruction tuning large language model on region-of-interest,2023-07-07T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"[Excerpt] The ideas and uses for Artificial Intelligence (AI) are abundant, and each business is seemingly ripe for disruption, including HR. As the hype surrounding AI continues to be championed by popular press, we began our research in order to determine whether the press’ biased view that AI was here and ready to implement was accurate. We found that in reality, AI programs were far behind the progress discussed, as the software was slower, more expensive, and there was a general lack of amalgamation throughout the industry. From there, we asked CAHRS partners to tell us where AI was used in their company, and how it helped them deliver HR differently. Our research focused on how AI technology will disrupt, change, or bolster the HR function, specifically in Talent Acquisition and Learning and Development (L&D) spaces.
We found our CAHRS partners dove into AI, and represented three key points along a spectrum of AI implementation. Of the 59 participants at 32 companies, 26% are Observers, 48% are Explorers, and 26% are Implementers. Observers were companies that did not believe AI fits with their strategy, and therefore do not intend to implement AI right now. Explorers are companies that have begun to actively explore AI through industry research, vendor exploration, and piloting AI and machine learning (ML) technologies. Implementers are companies that have either built in house or worked with an external vendor to implement an AI or machine learning technology. The CAHRS partners represented such a wide range along this spectrum because there are no best practices for AI implementation. However, each of our partners that leveraged AI understood the tool, while also understanding their business needs, people, and technology, which allowed them to utilize AI technology",,https://core.ac.uk/download/219376652.pdf,63664120,cahrs partners\u27 implementation of artificial intelligence,2018-06-01T08:00:00,DigitalCommons@ILR,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"As the penetration of digital technology deepens and the demands for educational modernization grow, attention is increasingly being drawn towards the application of artificial intelligence (AI) in the field of education. Especially in educational practice, the optimization of students’ learning experiences and the enhancement of their metacognitive abilities through AI technology have captivated the interest of numerous educators and scholars. Metacognition, which represents a core skill in student self-regulation and self-management, has a significant impact on student learning outcomes and quality. However, current educational support systems primarily rely upon traditional methods of data collection and analysis, which have limitations in terms of real-time responsiveness, granularity, and comprehensiveness. The present research aims to investigate the integration of AI technology with a specific focus on the learning process through educational support systems and the development of a cooperative teaching interaction model. This will ultimately enhance the development of students’ metacognitive abilities more effectively",,https://core.ac.uk/download/599236031.pdf,153696555,enhancing students' metacognition via ai-driven educational support systems,2023-12-19T00:00:00,International Federation of Engineering Education Societies (IFEES),[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Large vision-language models (VLMs) such as GPT-4 have achieved unprecedented
performance in response generation, especially with visual inputs, enabling
more creative and adaptable interaction than large language models such as
ChatGPT. Nonetheless, multimodal generation exacerbates safety concerns, since
adversaries may successfully evade the entire system by subtly manipulating the
most vulnerable modality (e.g., vision). To this end, we propose evaluating the
robustness of open-source large VLMs in the most realistic and high-risk
setting, where adversaries have only black-box system access and seek to
deceive the model into returning the targeted responses. In particular, we
first craft targeted adversarial examples against pretrained models such as
CLIP and BLIP, and then transfer these adversarial examples to other VLMs such
as MiniGPT-4, LLaVA, UniDiffuser, BLIP-2, and Img2Prompt. In addition, we
observe that black-box queries on these VLMs can further improve the
effectiveness of targeted evasion, resulting in a surprisingly high success
rate for generating targeted responses. Our findings provide a quantitative
understanding regarding the adversarial vulnerability of large VLMs and call
for a more thorough examination of their potential security flaws before
deployment in practice. Code is at https://github.com/yunqing-me/AttackVLM.Comment: NeurIPS 202",,http://arxiv.org/abs/2305.16934,152499214,on evaluating adversarial robustness of large vision-language models,2023-10-29T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Intelligent Interactive Systems (IIS) is the interdisciplinary field that examines how to devise intuitive systems that give guideline customized to the necessities of individual, the same number of good educators do.  Research in this field has effectively conveyed procedures and systems that give versatile help to cooperation critical thinking in an assortment of spaces. There are, in any case, other association exercises that can profit by individualized PC based help, for example, considering illustrations, investigating intelligent reproductions and playing instructive amusements. Giving individualized help to these exercises postures one of a kind difficulty, since it requires an IIS that can model and adjust to human practices, aptitudes and mental states regularly not as organized and all   around characterized as those engaged with customary critical thinking.  This paper exhibits an assortment of ventures that outline some of these difficulties, proposed arrangements, and future openings. Keywords: Intelligent Interactive Systems, Mind boggling Interactive System (IIS",,https://core.ac.uk/download/234677425.pdf,70341357,intelligent interactive systems,2018-11-01T00:00:00,"The International Institute for Science, Technology and Education (IISTE)",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Backdoor attacks on reinforcement learning implant a backdoor in a victim
agent's policy. Once the victim observes the trigger signal, it will switch to
the abnormal mode and fail its task. Most of the attacks assume the adversary
can arbitrarily modify the victim's observations, which may not be practical.
One work proposes to let one adversary agent use its actions to affect its
opponent in two-agent competitive games, so that the opponent quickly fails
after observing certain trigger actions. However, in multiagent collaborative
systems, agents may not always be able to observe others. When and how much the
adversary agent can affect others are uncertain, and we want the adversary
agent to trigger others for as few times as possible. To solve this problem, we
first design a novel training framework to produce auxiliary rewards that
measure the extent to which the other agents'observations being affected. Then
we use the auxiliary rewards to train a trigger policy which enables the
adversary agent to efficiently affect the others' observations. Given these
affected observations, we further train the other agents to perform abnormally.
Extensive experiments demonstrate that the proposed method enables the
adversary agent to lure the others into the abnormal mode with only a few
actions.Comment: 11 page",,http://arxiv.org/abs/2211.11455,135861316,backdoor attacks on multiagent collaborative systems,2022-11-21T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Algorithmic (including AI/ML) decision-making artifacts are an established
and growing part of our decision-making ecosystem. They are indispensable tools
for managing the flood of information needed to make effective decisions in a
complex world. The current literature is full of examples of how individual
artifacts violate societal norms and expectations (e.g. violations of fairness,
privacy, or safety norms). Against this backdrop, this discussion highlights an
under-emphasized perspective in the literature on assessing value misalignment
in AI-equipped sociotechnical systems. The research on value misalignment has a
strong focus on the behavior of individual tech artifacts. This discussion
argues for a more structured systems-level approach for assessing
value-alignment in sociotechnical systems. We rely primarily on the research on
fairness to make our arguments more concrete. And we use the opportunity to
highlight how adopting a system perspective improves our ability to explain and
address value misalignments better. Our discussion ends with an exploration of
priority questions that demand attention if we are to assure the value
alignment of whole systems, not just individual artifacts.Comment: Original version appeared in Proceedings of the 2020 AAAI ACM
  Conference on AI, Ethics, and Society (AIES '20), February 7-8, 2020, New
  York, NY, USA. 5 pages, 2 figures. Corrected some typos in this versio",10.1145/3375627.3375872,http://arxiv.org/abs/2002.05672,89610142,steps towards value-aligned systems,2020-11-09T00:00:00,'Association for Computing Machinery (ACM)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We present EasyGen, an efficient model designed to enhance multimodal
understanding and generation by harnessing the capabilities of diffusion models
and large language models (LLMs). Unlike existing multimodal models that
predominately depend on encoders like CLIP or ImageBind and need ample amounts
of training data to bridge the gap between modalities, EasyGen is built upon a
bidirectional conditional diffusion model named BiDiffuser, which promotes more
efficient interactions between modalities. EasyGen handles image-to-text
generation by integrating BiDiffuser and an LLM via a simple projection layer.
Unlike most existing multimodal models that are limited to generating text
responses, EasyGen can also facilitate text-to-image generation by leveraging
the LLM to create textual descriptions, which can be interpreted by BiDiffuser
to generate appropriate visual responses. Extensive quantitative and
qualitative experiments demonstrate the effectiveness of EasyGen, whose
training can be easily achieved in a lab setting. The source code is available
at https://github.com/zxy556677/EasyGen",,http://arxiv.org/abs/2310.08949,152049372,making multimodal generation easier: when diffusion models meet llms,2023-10-13T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Artificial intelligence is an important innovation in the rapid development of modern Internet. In the 21st century, human beings have been continuously researching and exploring Internet information technology. All kinds of application forms of Internet informatization begin to appear in our life. The rapid change of technology brings a high upgrade rate of internet products. This marks the technological innovation of some traditional concepts and thinking methods. The development mode of artificial intelligence plus education is an important innovation after the deep development of artificial intelligence technology and the achievement of cross-industry application practice. Robots will be the brains of the future education process. This paper aims to clarify the development trend of the application of artificial intelligence in modern education by analyzing the innovation progress of the combination of artificial intelligence technology and contemporary education. This is of great significance for better use of the advantages of artificial intelligence to build a future-oriented high-tech education system. (DIPF/Orig.",10.25656/01:20491,https://core.ac.uk/download/343128087.pdf,125093972,new advances in the application of ai to education system,2018-01-01T00:00:00,pedocs-Dokumentenserver/DIPF,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Digitalization of all life spheres is the reality of modern world development. The global digitization creates a powerful information environment. Its navigation requires serious tools for structuring, systematizing and processing information. Digital processes, as the most progressive, are in constant development. Artificial Intelligence (AI) is gaining popularity. The latest product that has created a lot of discussion is СhatGPT (Generative Pre-trained Transformer) from OpenAI, which is an artificial intelligence chatbot that demonstrates the ability of digital devices to perform the tasks inherent to intelligent beings. The paper shows some issues of using ChatGPT for making a new course of Law English, a curriculum, a syllabus at the tertiary level removing concerns related to its application and utilization. The purpose of the manuscript is to describe a real case of working out a professional English course for university students applying ChatGPT. The methods of analysis, synthesis, case study, expert assessment were used. The results are as follows: a new course for Law English training, a curriculum, a syllabus and a textbook using content created by ChatGPT were readied. The conclusion is that, nowadays, everything can be taught by a teacher partly with an AI. ChatGPT can be used for a wide variety of educational purposes, including providing information, generating necessary texts, tasks, tests, and answering many questions. Most of the mentioned ChatGPT services are important educational elements in language teaching and learning, they can be used for professional English course development",,https://core.ac.uk/download/599236093.pdf,153696749,chat gpt for professional english course development,2024-01-25T00:00:00,International Federation of Engineering Education Societies (IFEES),[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We present a novel approach to efficiently learn a simultaneous translation
model with coupled programmer-interpreter policies. First, wepresent an
algorithmic oracle to produce oracle READ/WRITE actions for training bilingual
sentence-pairs using the notion of word alignments. This oracle actions are
designed to capture enough information from the partial input before writing
the output. Next, we perform a coupled scheduled sampling to effectively
mitigate the exposure bias when learning both policies jointly with imitation
learning. Experiments on six language-pairs show our method outperforms strong
baselines in terms of translation quality while keeping the translation delay
low.Comment: 9 page",,http://arxiv.org/abs/2002.04306,89610317,"learning coupled policies for simultaneous machine translation using
  imitation learning",2021-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We envisage a world where genetic engineering, artificial intelligence (AI), and quantum computing (QC) will coalesce to bring about a forced speciation of the Homo sapiens. A forced speciation will drastically reduce the emergence time for a new species to a few years compared to Nature’s hundreds of millennia. In this chapter, we explain the basic concepts that would allow a forced speciation of the Homo sapiens to occur and its consequences on life on Earth thereafter. Accelerating speciation mediated by Homo sapiens via domestication, gene splicing, and gene drive mechanisms is now scientifically well understood. Synthetic biology can advance speciation far more rapidly using a combination of clustered regularly interspaced short palindromic repeats (CRISPR) technology, advanced computing technologies, and knowledge creation using AI. The day is perhaps not far off when Homo sapiens itself will initiate its own speciation once it advances synthetic biology to a level where it can safely modify the brain to temper emotion and enhance rational thinking as a means of competing against AI-embedded machines guided by quantum algorithms",10.5772/intechopen.83434,https://core.ac.uk/download/322440760.pdf,10912423,"synthetic biology, artificial intelligence, and quantum computing",2019-01-13T00:00:00,'IntechOpen',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Presentation: Chinese CHI 2017 ConferenceThe emergence of new artificial intelligence systems, especially the advances in the fields of deep learning and computer vision techniques, bring not only technical challenges, but, and more importantly, new questions to the realm of art, and can modify the way in which we creatively use computer systems to produce language.
Even though the use of computers and artificial intelligence techniques is not a novelty in the art world – Harold Cohen (1928-2016), perhaps the most famous and relevant example, worked on his AARON program for 43 years –, the new scenario, bursting with supervised and unsupervised learning techniques makes it possible for algorithms to have sufficient autonomous decision-making power to choose paths that hitherto were only available to programmers and artists.   
Cohen and AARON actively collaborated with one another, and in later years the program provided lines, basic abstract compositions, for the artist to colour in the spaces with colours, taking the program’s input as a starting point. Even in the software’s earlier versions, which could make both abstract and figurative sophisticated pictures, Cohen had the final say on what was or wasn’t aesthetically good. 
The artist devoted a substantial amount of time to teaching AARON to draw and colour in, and hard-coded the decisions that the system could make. Currently, a growing set of libraries has eliminated the need to manually code the neural networks that provide the logic for systems capable of learning semi-autonomously by analysing a large amount of data.   
Thus, we can delegate tasks to increasingly intelligent autonomous systems, including playful and aesthetic tasks. Given these circumstances, this paper reflects on notions such as intelligence, creativity and the role of aesthetics in a future where our relationship with intelligent artificial systems will become one of increasing symbiosis. 
This initial more theoretical discussion is mainly developed in the light of the semiotic and philosophical theories of Charles S Peirce about the concepts of intelligence and abduction, the kind of thinking that, for the philosopher, is the foundation of creative processes. The technical advances in the field of algorithms employed in machine and deep learning are also considered. The final part of the paper analyses two works produced by the text’s author, establishing links between the previous discussion and the creative models of improvisation used to develop both works. 
The first, “Hatred Apparatus”, is a system based on machine learning that autonomously collects comments from readers on websites, classifies them according to the level of hate speech they contain and displays them out of their original contexts. The second, “Apparatus Memories” is based on a deep learning system which carries out image segmentation operations on videos, separating the various elements that constitute the individual frames to assemble new autonomous narratives",,https://core.ac.uk/download/228181902.pdf,18503694,a symbiotic future: art - hci - ai,2017-06-07T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In this paper, we present methods for two types of metacognitive tasks in an
AI system: rapidly expanding a neural classification model to accommodate a new
category of object, and recognizing when a novel object type is observed
instead of misclassifying the observation as a known class. Our methods take
numerical data drawn from an embodied simulation environment, which describes
the motion and properties of objects when interacted with, and we demonstrate
that this type of representation is important for the success of novel type
detection. We present a suite of experiments in rapidly accommodating the
introduction of new categories and concepts and in novel type detection, and an
architecture to integrate the two in an interactive system.Comment: arXiv admin note: substantial text overlap with arXiv:2204.0810",,http://arxiv.org/abs/2211.04555,134590392,"detecting and accommodating novel types and concepts in an embodied
  simulation environment",2022-11-08T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The impact of artificial intelligence (AI) expands relentlessly despite well documented examples of bias in AI systems, from facial recognition failing to differentiate between darker-skinned faces to hiring tools discriminating against female candidates. These biases can be introduced to AI systems in a variety of ways; however, a major source of bias is found in training datasets, the collection of images, text, audio, or information used to build and train AI systems. This Article first grapples with the pressure copyright law exerts on AI developers and researchers to use biased training data to build algorithms, focusing on the potential risk of copyright infringement. Second, it examines how the fair use doctrine, particularly its public benefit consideration, can be applied to AI systems and begin to address the algorithmic bias problem afflicting many of today’s systems. Ultimately, this Article concludes that the social utility and human rights benefits of diversifying AI training data justifies the fair use of copyrighted works",,https://core.ac.uk/download/586173947.pdf,149016689,fair’s fair: how public benefit considerations in the fair use doctrine can patch bias in artificial intelligence systems,2023-07-01T08:00:00,Digital Repository @ Maurer Law,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This text contains some reflections on artificial intelligence (AI). First, we distinguish between strong and weak AI, as well as the concepts related to general and specific AI. Following this, we briefly describe the main current AI models and discuss the need to provide common-sense knowledge to machines in order to advance towards the goal of a general AI. Next, we talk about the current trends in AI based on the analysis of large amounts of data, which has recently allowed experts to make spectacular progress. Finally, we discuss other topics which, now and in the future, will continue to be key in AI, before closing with a brief reflection on the risks of AI",10.7203/metode.9.11145,https://core.ac.uk/download/459219022.pdf,7832675,"towards artificial intelligence : advances, challenges, and risks",2019-01-01T00:00:00,,"[{'title': 'Mètode Revista de difusió de la investigació', 'identifiers': ['2174-9221', 'issn:2174-3487', 'issn:2174-9221', '2174-3487']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Research and application have used human-AI teaming (HAT) as a new paradigm
to develop AI systems. HAT recognizes that AI will function as a teammate
instead of simply a tool in collaboration with humans. Effective human-AI teams
need to be capable of taking advantage of the unique abilities of both humans
and AI while overcoming the known challenges and limitations of each member,
augmenting human capabilities, and raising joint performance beyond that of
either entity. The National AI Research and Strategic Plan 2023 update has
recognized that research programs focusing primarily on the independent
performance of AI systems generally fail to consider the functionality that AI
must provide within the context of dynamic, adaptive, and collaborative teams
and calls for further research on human-AI teaming and collaboration. However,
there has been debate about whether AI can work as a teammate with humans. The
primary concern is that adopting the ""teaming"" paradigm contradicts the
human-centered AI (HCAI) approach, resulting in humans losing control of AI
systems. This article further analyzes the HAT paradigm and the debates.
Specifically, we elaborate on our proposed conceptual framework of human-AI
joint cognitive systems (HAIJCS) and apply it to represent HAT under the HCAI
umbrella. We believe that HAIJCS may help adopt HAI while enabling HCAI. The
implications and future work for HAIJCS are also discussed.
  Insights: AI has led to the emergence of a new form of human-machine
relationship: human-AI teaming (HAT), a paradigmatic shift in human-AI systems;
We must follow a human-centered AI (HCAI) approach when applying HAT as a new
design paradigm; We propose a conceptual framework of human-AI joint cognitive
systems (HAIJCS) to represent and implement HAT for developing effective
human-AI teamingComment: ",,http://arxiv.org/abs/2307.03913,144518952,"applying human-centered ai in developing effective human-ai teaming: a
  perspective of human-ai joint cognitive systems",2023-07-10T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The article of record may be found at https://www.usni.org/magazines/proceedings/2022/february/artificial-intelligence-too-fragile-fightInformation Warfare Essay Contest - First PrizeArtificial intelligence (Al) has become the technical focal point for advancing naval and Department of Defense (DoD) capabilities. Secretary of the Navy Carlos Del Toro listed AI first among his priorities for innovating U.S. naval forces. Chief of Naval Operations Admiral Michael Gilday listed it as his top priority during his Senate confirmation hearing. This focus is appropriate: ai/ offers many promising breakthroughs in battlefield capability and agility in decision making.  Yet, the proposed advances come with substantial risk: automation-including AI- has persistent, critical vulnerabilities that must be thoroughly understood and adequately addressed if defense applications are to remain resilient and effective.Booz Allen Hamilito",,https://core.ac.uk/download/491266435.pdf,123568307,artificial intelligence: too fragile to fight?,2022-02-01T00:00:00,U.S. Naval Institute,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"With the powerful development of pervasive information-based technology, especially intelligent computing, the question arises: How do we imagine a future highly developed and humane (human-centered) intelligent information society? The answer will of course vary depending on time perspective. In a shorter-time perspective, we can try to anticipate based on the existing trends in the development. The first step is to understand the current state of the art of intelligent technology uses towards intelligent society. A longer-term perspective is more uncertain, as new intelligent technologies, especially in combination with biotechnologies and human augmentation and enhancement will be changing both the ways of being human as wellas the structures and behaviors of human societies, as argued by (Wu &amp; Da, 2020) under the heading “The Impact of Intelligent Society on Human Essence and the New Evolution of Humans”. Wu and Da anticipate that the development of widely used AI technologies will lead to the evolution of the “human essence” that will lead to the convergence between social and biological evolution. That is a radically optimistic view that declares equality between the increase in human freedom with the disappearance of the necessity of regular human labor as a means to assure physical existence. In the future intelligent automated society, machines will secure the material basis of existence for everybody. It will remain to humans how to meaningfullyuse this newly conquered space of freedom",,https://core.ac.uk/download/552894392.pdf,138856786,computing information for intelligent society: info-computational approach to decision making,2022-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In recent years and especially in the context of the coronavirus pandemic, digital distance learning increases. But for academic students, the selection of adequate learning materials for educational purposes is becoming more and more complex. This marks only one starting point where the use of artificial intelligence (AI) offers additional value. AI has a great potential to enhance and support research and education in the field of digital humanities (DH). As international organisations have just expressed their thoughts on the subject, AI is the topic par excellence and will decisively shape the future development of educational processes",,https://core.ac.uk/download/386415648.pdf,107420714,supporting learning in art history – artificial intelligence in digital humanities education,2021-01-28T00:00:00,TUDpress,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Today, Internet of Things (IoT) devices are the powerhouse of data generation
with their ever-increasing numbers and widespread penetration. Similarly,
artificial intelligence (AI) and machine learning (ML) solutions are getting
integrated to all kinds of services, making products significantly more
""smarter"". The centerpiece of these technologies is ""data"". IoT device vendors
should be able keep up with the increased throughput and come up with new
business models. On the other hand, AI/ML solutions will produce better results
if training data is diverse and plentiful.
  In this paper, we propose a blockchain-based, decentralized and trustless
data marketplace where IoT device vendors and AI/ML solution providers may
interact and collaborate. By facilitating a transparent data exchange platform,
access to consented data will be democratized and the variety of services
targeting end-users will increase. Proposed data marketplace is implemented as
a smart contract on Ethereum blockchain and Swarm is used as the distributed
storage platform.Comment: Presented at Crypto Valley Conference on Blockchain Technology (CVCBT
  2018), 20-22 June 2018 - published version may diffe",10.1109/cvcbt.2018.00007,http://arxiv.org/abs/1810.00349,54156990,idmob: iot data marketplace on blockchain,2018-09-30T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The ActiveAI project addresses key challenges in AI education for grades 7-9
students by providing an engaging AI literacy learning experience based on the
AI4K12 knowledge framework. Utilizing learning science mechanisms such as
goal-based scenarios, immediate feedback, project-based learning, and
intelligent agents, the app incorporates a variety of learner inputs like
sliders, steppers, and collectors to enhance understanding. In these courses,
students work on real-world scenarios like analyzing sentiment in social media
comments. This helps them learn to effectively engage with AI systems and
develop their ability to evaluate AI-generated output. The Learning Engineering
Process (LEP) guided the project's creation and data instrumentation, focusing
on design and impact. The project is currently in the implementation stage,
leveraging the intelligent tutor design principles for app development. The
extended abstract presents the foundational design and development, with
further evaluation and research to be conducted in the future",,http://arxiv.org/abs/2309.12337,148086574,"activeai: introducing ai literacy for middle school learners with
  goal-based scenario learning",2023-08-21T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Proposed as a solution to mitigate the privacy implications related to the
adoption of deep learning, Federated Learning (FL) enables large numbers of
participants to successfully train deep neural networks without having to
reveal the actual private training data. To date, a substantial amount of
research has investigated the security and privacy properties of FL, resulting
in a plethora of innovative attack and defense strategies. This paper
thoroughly investigates the communication capabilities of an FL scheme. In
particular, we show that a party involved in the FL learning process can use FL
as a covert communication medium to send an arbitrary message. We introduce
FedComm, a novel multi-system covert-communication technique that enables
robust sharing and transfer of targeted payloads within the FL framework. Our
extensive theoretical and empirical evaluations show that FedComm provides a
stealthy communication channel, with minimal disruptions to the training
process. Our experiments show that FedComm successfully delivers 100% of a
payload in the order of kilobits before the FL procedure converges. Our
evaluation also shows that FedComm is independent of the application domain and
the neural network architecture used by the underlying FL scheme.Comment: 18 page",,http://arxiv.org/abs/2201.08786,120255557,fedcomm: federated learning as a medium for covert communication,2022-04-05T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Large language models (LLMs), such as GPT-4, have demonstrated remarkable
capabilities across a wide range of tasks, including health applications. In
this paper, we study how LLMs can be used to scale biomedical knowledge
curation. We find that while LLMs already possess decent competency in
structuring biomedical text, by distillation into a task-specific student model
through self-supervised learning, substantial gains can be attained over
out-of-box LLMs, with additional advantages such as cost, efficiency, and
white-box model access.
  We conduct a case study on adverse drug event (ADE) extraction, which is an
important area for improving care. On standard ADE extraction evaluation, a
GPT-3.5 distilled PubMedBERT model attained comparable accuracy as supervised
state-of-the-art models without using any labeled data. Despite being over
1,000 times smaller, the distilled model outperformed its teacher GPT-3.5 by
over 6 absolute points in F1 and GPT-4 by over 5 absolute points.
  Ablation studies on distillation model choice (e.g., PubMedBERT vs BioGPT)
and ADE extraction architecture shed light on best practice for biomedical
knowledge extraction. Similar gains were attained by distillation for other
standard biomedical knowledge extraction tasks such as gene-disease
associations and protected health information, further illustrating the promise
of this approach",,http://arxiv.org/abs/2307.06439,144628717,"distilling large language models for biomedical knowledge extraction: a
  case study on adverse drug events",2023-07-12T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Artificial Intelligence innovation that truly separates larger degree portrayals from crude information by using accumulating extremely good layers of neuron-like units is referred to as Deep Learning.&nbsp; This stacking considers preserving apart portrayals of step-with the aid of-step complex highlights without tedious, detail production. The ongoing success of profound studying has indicated that it outflanks nice-in-magnificence frameworks in picture handling, voice acknowledgment, net seek, concept frameworks, and so forth We furthermore spread makes use of deep gaining knowledge for photo and video getting prepared, language and content material cloth information examination, social facts investigation, and wearable IoT sensor statistics with an accentuation inside the vicinity of Website frameworks. Graphical delineations and models could be large in analyzing pretty some Web records",10.5281/zenodo.8239478,https://core.ac.uk/download/588476683.pdf,150652044,artificial intelligence and machine vision,2023-07-06T01:00:00,Logical Creations Education Research Institute,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Evaluating the general abilities of foundation models to tackle human-level
tasks is a vital aspect of their development and application in the pursuit of
Artificial General Intelligence (AGI). Traditional benchmarks, which rely on
artificial datasets, may not accurately represent human-level capabilities. In
this paper, we introduce AGIEval, a novel benchmark specifically designed to
assess foundation model in the context of human-centric standardized exams,
such as college entrance exams, law school admission tests, math competitions,
and lawyer qualification tests. We evaluate several state-of-the-art foundation
models, including GPT-4, ChatGPT, and Text-Davinci-003, using this benchmark.
Impressively, GPT-4 surpasses average human performance on SAT, LSAT, and math
competitions, attaining a 95% accuracy rate on the SAT Math test and a 92.5%
accuracy on the English test of the Chinese national college entrance exam.
This demonstrates the extraordinary performance of contemporary foundation
models. In contrast, we also find that GPT-4 is less proficient in tasks that
require complex reasoning or specific domain knowledge. Our comprehensive
analyses of model capabilities (understanding, knowledge, reasoning, and
calculation) reveal these models' strengths and limitations, providing valuable
insights into future directions for enhancing their general capabilities. By
concentrating on tasks pertinent to human cognition and decision-making, our
benchmark delivers a more meaningful and robust evaluation of foundation
models' performance in real-world scenarios. The data, code, and all model
outputs are released in https://github.com/microsoft/AGIEval.Comment: 19 page",,http://arxiv.org/abs/2304.06364,142318070,agieval: a human-centric benchmark for evaluating foundation models,2023-04-13T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Article translated from Russian. First published in: Агеев А.И. Нейротехнологии в системах искусственного интеллекта и применения в сфере управления, в книге Социогуманитарные аспекты цифровых трансформаций искусственного интеллекта под редакцией В.Е. Лепского, А.Н. Райкова. Москва, Когито-Центр. 2022. 308 с. (201-212). (V.E. Lepsky/ A.N. Raikov, Socio-humanitarian Aspects of Digital Transformations and Artificial Intelligence, Kogito Center, Moscow 2022, 201-212)",10.58863/20.500.12424/4276028,https://core.ac.uk/download/582653543.pdf,146586655,brain in the data : neurotechnology in ai systems and management applications,2023-01-01T00:00:00,Globethics Publications,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Decision-based adversarial attacks construct inputs that fool a
machine-learning model into making targeted mispredictions by making only
hard-label queries. For the most part, these attacks have been applied directly
to isolated neural network models. However, in practice, machine learning
models are just a component of a much larger system. By adding just a single
preprocessor in front of a classifier, we find that state-of-the-art
query-based attacks are as much as seven times less effective at attacking a
prediction pipeline than attacking the machine learning model alone. Hence,
attacks that are unaware of this invariance inevitably waste a large number of
queries to re-discover or overcome it. We, therefore, develop techniques to
first reverse-engineer the preprocessor and then use this extracted information
to attack the end-to-end system. Our extraction method requires only a few
hundred queries to learn the preprocessors used by most publicly available
model pipelines, and our preprocessor-aware attacks recover the same efficacy
as just attacking the model alone. The code can be found at
https://github.com/google-research/preprocessor-aware-black-box-attack.Comment: Code can be found at
  https://github.com/google-research/preprocessor-aware-black-box-attac",,http://arxiv.org/abs/2210.03297,132121412,"preprocessors matter! realistic decision-based attacks on machine
  learning systems",2022-10-06T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Te Kore, to Te Pō, to Te Ao MaramaTe reo Māori (the Māori language) is an oral language, so these “Te Kore, to Te Pō, to Te Ao Marama” words are most commonly encountered as spoken. Unlike Western traditions, precontact Māori cultures did not impose Cartesian divisions between nature and culture on the world. Nor does te reo position entities in an oppositional manner, as for instance the Greek prefix ‘in-’ does on the words ‘tangible’ and ‘intangible.’ Similarly, the Greek prefix ‘inter-’ inscribes the possibility that within oppositional entities there is always an in-between. Sound vibrates, resonates and reverberates, sound is always inherent to material movement, both in its generation and propagation. Vibrations are one of the ways that the material world makes itself felt. If language is communication, then in this understanding it is not just a human prerogative",10.34074/junc.23002,https://core.ac.uk/download/591067481.pdf,152280715,aligning the vibrations: resounding matters,2023-11-09T00:00:00,Te Pūkenga Publishing Group | Otago Polytechnic,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Neural language models (NLMs) are susceptible to producing inconsistent output. This paper proposes a new diagnosis as well as a novel remedy for NLMs\u27 incoherence. We train NLMs on synthetic text corpora that are created by simulating text production in a society. For diagnostic purposes, we explicitly model the individual belief systems of artificial agents (authors) who produce corpus texts. NLMs, trained on those texts, can be shown to aggregate the judgments of individual authors during pre-training according to sentence-wise vote ratios (roughly, reporting frequencies), which inevitably leads to so-called discursive dilemmas: aggregate judgments are inconsistent even though all individual belief states are consistent. As a remedy for such inconsistencies, we develop a self-training procedure—inspired by the concept of reflective equilibrium—that effectively reduces the extent of logical incoherence in a model\u27s belief system, corrects global mis-confidence, and eventually allows the model to settle on a new, epistemically superior belief state. Thus, social choice theory helps to understand why NLMs are prone to produce inconsistencies; epistemology suggests how to get rid of them",10.5445/ir/1000153019,https://core.ac.uk/download/548547181.pdf,140436813,"judgment aggregation, discursive dilemma and reflective equilibrium: neural language models as self-improving doxastic agents",2022-10-18T01:00:00,Frontiers Media SA,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The launch of ChatGPT in November 2022 ushered in a new era of generative AI that has taken the world by storm. We wanted to seek the opinion of MWAIS colleagues. We asked the editorial board members of JMWAIS if they wish to respond to the following questions: 1) What is your overall opinion of GPT and similar platforms? 2) GPT’s potential implications for teaching, learning, and other student services? And 3) Have you already seen evidence of GPT in student work or in anything else where it might have come across, like research? This article includes responses we received",10.17705/3jmwa.000083,https://core.ac.uk/download/577862224.pdf,149947792,chatgpt – another hype or out-of-this-world?,2023-07-18T22:01:37,AIS Electronic Library (AISeL),[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Artificial intelligence (AI) has advanced rapidly in the past decade. The arrival of ChatGPT last year has pushed the debate about AI into the public sphere. ChatGPT, and similar tools, do things we once thought were outside the ability of computers. This raises questions for how we educate people about the capability and the limitations of such tools. This article provides an overview of artificial intelligence and explores what ChatGPT is capable of doing. It also raises questions about morality, responsibility, sentience, intelligence, and how humans’ propensity to anthropomorphise makes us gullible and thus ready to believe that this technology is delivering something that it cannot",,https://core.ac.uk/download/588032249.pdf,150256520,artificial intelligence: chatgpt and human gullibility,2023-08-09T01:00:00,Institute for Governance and Policy Studies & the School of Government,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"October 2017 issue of Illuminator, a monthly publication of ODU\u27s Batten College of Engineering and Technology.https://digitalcommons.odu.edu/engineering_newsletter/1017/thumbnail.jp",,https://core.ac.uk/download/226775858.pdf,66346431,"illuminator, volume 1, issue 1",2017-10-01T08:00:00,ODU Digital Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In this work, we extend the instruction-tuned Llama-2 model with end-to-end
general-purpose speech processing and reasoning abilities while maintaining the
wide range of LLM capabilities, without using any carefully curated paired
data. The proposed model can utilize audio prompts as a replacement for text
and sustain a conversation. Such a model also has extended cross-modal
capabilities such as being able to perform speech question answering, speech
translation, and audio summarization amongst many other closed and open-domain
tasks. This is unlike prior approaches in speech, in which LLMs are extended to
handle audio for a limited number of pre-designated tasks. Experiments show
that our end-to-end approach is on par with or outperforms a cascaded system
(speech recognizer + LLM) in terms of modeling the response to a prompt.
Furthermore, unlike a cascade, our approach shows the ability to interchange
text and audio modalities and utilize the prior context in a conversation to
provide better results",,http://arxiv.org/abs/2311.06753,153550013,"towards general-purpose speech abilities for large language models using
  unpaired data",2023-11-12T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Fuelled by Science Fiction and the pronouncements of Silicon Valley gurus such as Elon Musk, the ‘Singularity’ is arguably the biggest geek myth of our time and is distracting us from addressing the numerous problems emerging with the increasing use of Artificial intelligence (AI). Artificial General Intelligence (AGI) is often perceived to mean super human like intelligence such as the ones depicted in movies like Her (2013) and Ex Machina (2014). These anthropomorphic representations of AI besiege our attention away from the very real threat of biases introduced through Machine Learning (ML). In this paper we will consider whether current practices within Human-Centred Design (HCD) permit designers to consider interactions and services in which non-human algorithms play a significant role and consider how approaches inspired by Object Oriented Ontology (OOO) may offer newperspectives for framing design activities concerning AI",10.1080/14606925.2019.1594979,https://core.ac.uk/download/196591310.pdf,18622922,"forget the singularity, its mundane artificial intelligence that should be our immediate concern",2019-04-01T01:00:00,'Informa UK Limited',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This report presents a set of use scenarios based on existing resources that
teachers can use as inspiration to create their own, with the aim of
introducing artificial intelligence (AI) at different pre-university levels,
and with different goals. The Artificial Intelligence Education field (AIEd) is
very active, with new resources and tools arising continuously. Those included
in this document have already been tested with students and selected by experts
in the field, but they must be taken just as practical examples to guide and
inspire teachers creativity.Comment: Developed within the AI in Education working group of the European
  Digital Education Hu",,http://arxiv.org/abs/2309.12320,148087080,use scenarios & practical examples of ai use in education,2023-07-25T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Efficient knowledge retrieval plays a pivotal role in ensuring the success of
end-to-end task-oriented dialogue systems by facilitating the selection of
relevant information necessary to fulfill user requests. However, current
approaches generally integrate knowledge retrieval and response generation,
which poses scalability challenges when dealing with extensive knowledge bases.
Taking inspiration from open-domain question answering, we propose a
retriever-generator architecture that harnesses a retriever to retrieve
pertinent knowledge and a generator to generate system responses.~Due to the
lack of retriever training labels, we propose relying on feedback from the
generator as pseudo-labels to train the retriever. To achieve this, we
introduce a dual-feedback mechanism that generates both positive and negative
feedback based on the output of the generator. Our method demonstrates superior
performance in task-oriented dialogue tasks, as evidenced by experimental
results on three benchmark datasets.Comment: Accepted to EMNLP 2023 (Main Conference",,http://arxiv.org/abs/2310.14528,152815030,dual-feedback knowledge retrieval for task-oriented dialogue systems,2023-10-22T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Robotic events can provide notable amounts of
information regarding a robot’s status, which can be extrapolated
to detect productivity, anomalies, malfunctions and used
for monitorization. However, when problems occur in sensitive
environments like a factory, the logs of a machine may be
discarded because they are susceptible to chances and malicious
intents. In this paper we propose to use RobotChain for anomaly
detection. RobotChain is a method to securely register robotic
events, using a blockchain, which ensures that once an event
gets registered on it, it’s secured and cannot be tampered with.
We show how this system can be leveraged with the module for
anomaly detection, that uses the information contained on the
blockchain to detect anomalies on a UR3 robot.This work was partially supported by the Tezos Fundation through a grant for project Robotchaininfo:eu-repo/semantics/publishedVersio",10.1109/icarsc.2019.8733618,https://core.ac.uk/download/304001843.pdf,84894046,detecting robotic anomalies using robotchain,2019-04-01T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The University of Maine Artificial Intelligence Initiative (UMaine AI) is a unique Maine-based venture that brings together university, industry, government, and community collaborators from Maine and beyond to advance the field of artificial intelligence, and through development of innovative technologies and applications find transformative solutions to enhance human life and societal well-being in Maine and beyond",,https://core.ac.uk/download/482033572.pdf,120095703,education and workforce development,2020-04-29T08:00:00,DigitalCommons@UMaine,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The paper analyses and speculates on what opportunities and challenges will arise from the introduction of learning algorithms (machine learning, neural networks, etc.) in architectural and urban design. The penetration of such class of algorithms in cities and design disciplines is rapid and profound increasing both the thirst for gathering ever larger and more accurate datasets and raising the prospect of automating tasks currently performed by humans. Whilst it is understood that learning algorithms are essential tools to analyse large datasets, design disciplines have paid far less attention to how such processes are carried out, how spatial data are reformatted by algorithms which largely operate on statistical bases and, most importantly, what image of the city emerges from such processes. To unravel the complexity of the issue, it is first necessary to retrace the ideas informing the emergence of numerical procedures at beginning of the twentieth century and Artificial Intelligence in the 1950's as they allow us to project a different paradigm of how space can be analysed, structured, and changed. Finally, the paper will offer some points for speculation and further reflection on how the methods put forward through learning algorithms compare to current approaches to digital design; this will foreground their disruptive potential for a radical transformation of urban design, one that could be deployed to tackle some of the most pressing urban issue.&nbsp",10.17831/enq:arcc.v16i2.1058,https://core.ac.uk/download/429524473.pdf,113685673,"learning algorithms, design, and computed space",2019-11-24T00:00:00,'Enquiry:  The ARCC Journal of Architectural Research',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Written in 2018 by Mimi Onuoha and Mother Cyborg (Diana Nucera), a People's Guide to AI is a comprehensive beginner's guide to understanding AI and other data-driven tech. The guide uses a popular education approach to explore and explain AI-based technologies so that everyone—from youth to seniors, and from non-techies to experts—has the chance to think critically about the kinds of futures automated technologies can bring.The mission of A People's Guide to AI is to open up conversation around AI by demystifying, situating, and shifting the narrative about what types of use cases AI can have for everyday people",,https://core.ac.uk/download/480182418.pdf,127317480,a people's guide to ai : artificial intelligence,2018-08-08T01:00:00,Open Society Foundations,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The article of record as published may be located at https://doi.org/10.1609/aimag.v40i1.2852Artificial intelligence, as a capability enhancer, offers significant improve- ments to our tactical warfighting advantage. AI provides methods for fus- ing and analyzing data to enhance our knowledge of the tactical environment; it provides methods for generating and assessing decision options from multidi- mensional, complex situations; and it provides predictive analytics to identify and examine the effects of tactical courses of action. Machine learning can improve these processes in an evolution- ary manner. Advanced computing tech- niques can handle highly heterogeneous and vast datasets and can synchronize knowledge across distributed warfare assets. This article presents concepts for applying AI to various aspects of tacti- cal battle management and discusses their potential improvements to future warfare",,https://core.ac.uk/download/552240105.pdf,136862614,artificial intelligence — an enabler of naval tactical decision superiority,2019-01-01T00:00:00,'Association for the Advancement of Artificial Intelligence (AAAI)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The opaque and incomprehensible nature of artificial intelligence (AI) raises questions about who can and will take responsibility for AI in organizations. Examining the relation between explainability and responsibility, we explore how AI responsibility attributions unfold when 1) AI shifts tasks and roles of individuals and 2) these individuals lack comprehension of the task elements they are expected to take responsibility for. Through an in-depth qualitative field study in a large organization, we identify three types of responsibility attributions in decision-making with AI: a shared responsibility, a data science-centered responsibility, and a business domain expert-centered responsibility. These three prevalent types of responsibility attributions will be explained by the interaction of different shifts in AI-related tasks and corresponding AI explainability needs and actions in the organization. Our study contributes to the existing literature by demonstrating AI\u27s impact on traditional responsibility assignment in day-to-day organizational practices",,https://core.ac.uk/download/590878874.pdf,153501791,"who takes responsibility for ai? a field study on ai-related task shifts, explainability, and responsibility attributions",2023-12-11T08:00:00,AIS Electronic Library (AISeL),[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Since the eighties, feminists have considered technology a force capable of subverting sexism because of technology’s ability to produce unbiased logic. Most famously, Donna Haraway’s “A Cyborg Manifesto” posits that the cyborg has the inherent capability to transcend gender because of its removal from social construct and lack of loyalty to the natural world. But while humanoids and artificial intelligence have been imagined as inherently subversive to gender, current artificial intelligence perpetuates gender divides in labor and language as their programmers imbue them with traits considered “feminine.” A majority of 21st century AI and humanoids are programmed to fit female stereotypes as they fulfill emotional labor and perform pink-collar tasks, whether through roles as therapists, query-fillers, or companions. This paper examines four specific chat-based AI --ELIZA, XiaoIce, Sophia, and Erica-- and examines how their feminine linguistic patterns are used to maintain the illusion of emotional understanding in regards to the tasks that they perform. Overall, chat-based AI fails to subvert gender roles, as feminine AI are relegated to the realm of emotional intelligence and labor",,https://core.ac.uk/download/322983206.pdf,83385502,designing women: essentializing femininity in ai linguistics,2019-10-01T08:00:00,The Cupola: Scholarship at Gettysburg College,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Algorithmic robustness refers to the sustained performance of a computational
system in the face of change in the nature of the environment in which that
system operates or in the task that the system is meant to perform. Below, we
motivate the importance of algorithmic robustness, present a conceptual
framework, and highlight the relevant areas of research for which algorithmic
robustness is relevant. Why robustness? Robustness is an important enabler of
other goals that are frequently cited in the context of public policy decisions
about computational systems, including trustworthiness, accountability,
fairness, and safety. Despite this dependence, it tends to be under-recognized
compared to these other concepts. This is unfortunate, because robustness is
often more immediately achievable than these other ultimate goals, which can be
more subjective and exacting. Thus, we highlight robustness as an important
goal for researchers, engineers, regulators, and policymakers when considering
the design, implementation, and deployment of computational systems. We urge
researchers and practitioners to elevate the attention paid to robustness when
designing and evaluating computational systems. For many key systems, the
immediate question after any demonstration of high performance should be: ""How
robust is that performance to realistic changes in the task or environment?""
Greater robustness will set the stage for systems that are more trustworthy,
accountable, fair, and safe. Toward that end, this document provides a brief
roadmap to some of the concepts and existing research around the idea of
algorithmic robustness",,http://arxiv.org/abs/2311.06275,153564286,algorithmic robustness,2023-10-17T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system’s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety",10.1142/s2705078521500090,https://core.ac.uk/download/573846340.pdf,145375421,measuring intelligence in natural and artificial systems,2021-01-01T00:00:00,World Scientific Pub Co Pte Lt,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The University of Maine Artificial Intelligence Initiative (UMaine AI) is a unique Maine-based venture that brings together university, industry, government, and community collaborators from Maine and beyond to advance the field of artificial intelligence, and through development of innovative technologies and applications find transformative solutions to enhance human life and societal well-being in Maine and beyond",,https://core.ac.uk/download/482033571.pdf,120095766,"social, ethical, policy, and legal considerations",2020-04-29T08:00:00,DigitalCommons@UMaine,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Over the past years, literature has shown that attacks exploiting the
microarchitecture of modern processors pose a serious threat to the privacy of
mobile phone users. This is because applications leave distinct footprints in
the processor, which can be used by malware to infer user activities. In this
work, we show that these inference attacks are considerably more practical when
combined with advanced AI techniques. In particular, we focus on profiling the
activity in the last-level cache (LLC) of ARM processors. We employ a simple
Prime+Probe based monitoring technique to obtain cache traces, which we
classify with Deep Learning methods including Convolutional Neural Networks. We
demonstrate our approach on an off-the-shelf Android phone by launching a
successful attack from an unprivileged, zeropermission App in well under a
minute. The App thereby detects running applications with an accuracy of 98%
and reveals opened websites and streaming videos by monitoring the LLC for at
most 6 seconds. This is possible, since Deep Learning compensates measurement
disturbances stemming from the inherently noisy LLC monitoring and unfavorable
cache characteristics such as random line replacement policies. In summary, our
results show that thanks to advanced AI techniques, inference attacks are
becoming alarmingly easy to implement and execute in practice. This once more
calls for countermeasures that confine microarchitectural leakage and protect
mobile phone applications, especially those valuing the privacy of their users",10.1145/3321705.3329804,http://arxiv.org/abs/1811.11218,54175568,undermining user privacy on mobile devices using ai,2019-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper summarizes the practical application and development trend of artificial intelligence technology in the field of computer network. Artificial intelligence has been widely used in network communication, management and security, and other aspects, to achieve the network independent optimization, fault self-healing, threat identification and other intelligent capabilities. Artificial intelligence is a key technology to promote the evolution of the next generation network to the direction of adaptive, intelligence and security. The use of artificial intelligence also faces challenges such as algorithm deviations and regulatory constraints. Collaborative innovation algorithms and systems and the establishment of legal ethics systems are needed to promote the healthy development of AI and the progress of computer networks",10.18686/esta.v10i5.539,https://core.ac.uk/download/590981805.pdf,153793469,the practice research of artificial intelligence in computer network technology in the new era,2023-11-20T00:00:00,Universe Scientific Publishing Pte. Ltd.,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Los nuevos enfoques que surgen del análisis de obras de arte con herramientas computacionales tienen el potencial de ofrecer diferentes perspectivas a las obras de arte recreadas en medios digitales. Este artículo pretende revelar las relaciones implícitas entre las composiciones de Mondrian con diferentes representaciones visuales. En el ámbito del estudio, las composiciones completadas entre 1938 y 1943, que tienen una fuerte relación geometría-color, se investigaron primero a través de un enfoque basado en píxeles. En el método de fragmentación empleado a seguir, las similitudes y diferencias se expresan con datos transferidos de píxeles a matrices numéricas en dos pasos diferentes: 1) Entre los artefactos en pares, y 2) Entre un artefacto y todos los demás artefactos seleccionados. La visualización de las matrices estuvo representada por mapas de color 2D y mapas de textura 3D. Estos estilos de interpretación permiten que las composiciones se expresen de lo general a lo específico y nuevamente de lo específico a lo general, adquiriendo un nuevo significado.Novas abordagens emergem da análise de obras com ferramentas computacionais e têm potencial para oferecer diferentes perspectivas para obras recriadas em ambientes digitais. Este estudo visa revelar as relações implícitas entre as composições de Mondrian com diferentes representações visuais. No âmbito do estudo, as composições concluídas entre 1938 e 1943, que possuem uma forte relação geometria-cor, foram discutidas pela primeira vez com uma abordagem baseada em pixels. No método de fragmentação seguido, as semelhanças e diferenças são expressas com dados transferidos de pixels para matrizes numéricas em duas etapas distintas: 1. Entre os artefatos em pares, 2. Entre um artefato e todos os outros artefatos selecionados. A visualização das matrizes foi representada por mapas de cores 2D e mapas de texturas 3D. Esses estilos de interpretação permitem que as composições sejam expressas do geral para o específico e novamente do específico para o geral, ganhando um novo significado.New approaches emerging from the analysis of artworks with computational tools have the potential to offer different perspectives to artworks recreated in digital environments. This study aims to reveal the implicit relationships between Mondrian compositions with different visual representations. In the scope of the study, compositions completed between 1938 and 1943, which have a strong geometry-color relationship, were first investigated through a pixel-based approach. In the fragmentation method followed, the similarities and differences are expressed with data transferred from pixels to numerical matrices in two different steps: 1. Between the artifacts in pairs, 2. Between an artifact and all the other selected artifacts. The visualization of the matrices was represented by 2D color maps and 3D texture maps. These interpretation styles allow the compositions to be expressed from general to specific and again, from specific to general, by gaining a new meaning",,https://core.ac.uk/download/595430001.pdf,153987481,un enfoque computacional para el análisis de composiciones artísticas,2023-11-30T00:00:00,Universidade de São Paulo. Instituto de Arquitetura e Urbanismo,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"NPS NRP Project PosterModeling Large-Scale Warfighter Cognitive Reasoning and Decision- Making Using Machine Learning (ML), Artificial Intelligence (AI), and Game Theory (GT)N8 - Integration of Capabilities & ResourcesThis research is supported by funding from the Naval Postgraduate School, Naval Research Program (PE 0605853N/2098). https://nps.edu/nrpChief of Naval Operations (CNO)Approved for public release. Distribution is unlimited.",,https://core.ac.uk/download/528269933.pdf,125203554,"modeling large-scale warfighter cognitive reasoning and decision- making using machine learning (ml), artificial intelligence (ai), and game theory (gt)",2019-12-01T00:00:00,"Monterey, California. Naval Postgraduate School.",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"With the rapid advancements in artificial intelligence (AI) technology, its deployment in the field of education has gained considerable attention, particularly in the context of mental health education. Addressing the mounting academic and social pressures faced by contemporary students necessitates the utilization of cutting-edge techniques to accurately discern their emotional states and deliver customized learning resources. Existing methodologies for mental health education often fall short due to an over-reliance on educators’ experience and observations, as well as challenges in handling complex multimodal data. This research aims to investigate the integration of multimodal audio-visual features using a transformer architecture for emotion recognition. An enhanced probabilistic matrix factorization (PMF) model has been concurrently developed to facilitate tailored content recommendations for students. The goal is to provide a more accurate and effective approach to health education",,https://core.ac.uk/download/599236030.pdf,153696740,ai-assisted emotion recognition: impacts on mental health education and learning motivation,2023-12-19T00:00:00,International Federation of Engineering Education Societies (IFEES),[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Airlines are critical today for carrying people and commodities on time. Any delay in the schedule of these planes can potentially disrupt the business and trade of thousands of employees at any given time. Therefore, precise flight delay prediction is beneficial for the aviation industry and passenger travel. Recent research has focused on using artificial intelligence algorithms to predict the possibility of flight delays. Earlier prediction algorithms were designed for a specific air route or airfield. Many present flight delay prediction algorithms rely on tiny samples and are challenging to understand, allowing almost no room for machine learning implementation. This research study develops a flight delay prediction system by analyzing data from domestic flights inside the United States of America. The proposed models learn about the factors that cause flight delays and cancellations and the link between departure and arrival delays",,https://core.ac.uk/download/539317140.pdf,126731147,flight delay prediction using deep learning and conversational voice-based agents,2022-08-16T01:00:00,"American Academic Scientific Research Journal for Engineering, Technology, and Sciences",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This article examines the theory and practice of a multi-level system of continuous innovative education. The pedagogical system of multilevel continuous creative education is considered in detail, and sufficient creative pedagogical methods are put forward for the formation of creative thinking and the development of students' creative abilities. Creative approach provides teachers and students with intellectual tools for the formation of creative systems thinking, teaches them to look at the world systematically and manage thought processes. Innovative teaching methods in the continuous formation of a multilevel system of creative thinking provide the basic principles of teaching by changing the structure of the lessons and implementing their original content. Using them, it is possible to significantly accelerate the solution of a pressing problem in Russia: formation of a creative personality of students",10.34069/ai/2021.40.04.17,https://core.ac.uk/download/568030371.pdf,145141411,multifactorial approach to preparing russian young people for a future profession,2021-05-31T01:00:00,'Amazonia Investiga',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Recent advances in large language models (LLMs), such as ChatGPT, have led to
highly sophisticated conversation agents. However, these models suffer from
""hallucinations,"" where the model generates false or fabricated information.
Addressing this challenge is crucial, particularly with AI-driven platforms
being adopted across various sectors. In this paper, we propose a novel method
to recognize and flag instances when LLMs perform outside their domain
knowledge, and ensuring users receive accurate information.
  We find that the use of context combined with embedded tags can successfully
combat hallucinations within generative language models. To do this, we
baseline hallucination frequency in no-context prompt-response pairs using
generated URLs as easily-tested indicators of fabricated data. We observed a
significant reduction in overall hallucination when context was supplied along
with question prompts for tested generative engines. Lastly, we evaluated how
placing tags within contexts impacted model responses and were able to
eliminate hallucinations in responses with 98.88% effectiveness.Comment: 13 pages, 3 Figures, 2 Table",,http://arxiv.org/abs/2306.06085,143298236,trapping llm hallucinations using tagged context prompts,2023-06-09T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"A key challenge for reinforcement learning (RL) consists of learning in
environments with sparse extrinsic rewards. In contrast to current RL methods,
humans are able to learn new skills with little or no reward by using various
forms of intrinsic motivation. We propose AMIGo, a novel agent incorporating --
as form of meta-learning -- a goal-generating teacher that proposes
Adversarially Motivated Intrinsic Goals to train a goal-conditioned ""student""
policy in the absence of (or alongside) environment reward. Specifically,
through a simple but effective ""constructively adversarial"" objective, the
teacher learns to propose increasingly challenging -- yet achievable -- goals
that allow the student to learn general skills for acting in a new environment,
independent of the task to be solved. We show that our method generates a
natural curriculum of self-proposed goals which ultimately allows the agent to
solve challenging procedurally-generated tasks where other forms of intrinsic
motivation and state-of-the-art RL methods fail.Comment: 18 pages, 6 figures, published at The Ninth International Conference
  on Learning Representations (2021",,https://core.ac.uk/download/477686917.pdf,86522416,learning with amigo: adversarially motivated intrinsic goals,2021-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
https://scholarcommons.scu.edu/eng_news/1043/thumbnail.jp,,https://core.ac.uk/download/232208551.pdf,69157728,"engineering news, fall 2019",2019-10-01T08:00:00,Scholar Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Large Language Models (LLMs) are increasingly being used for interactive
decision-making tasks requiring planning and adapting to the environment.
Recent works employ LLMs-as-agents in broadly two ways: iteratively determining
the next action (iterative executors) or generating plans and executing
sub-tasks using LLMs (plan-and-execute). However, these methods struggle with
task complexity, as the inability to execute any sub-task may lead to task
failure. To address these shortcomings, we introduce As-Needed Decomposition
and Planning for complex Tasks (ADaPT), an approach that explicitly plans and
decomposes complex sub-tasks as-needed, i.e., when the LLM is unable to execute
them. ADaPT recursively decomposes sub-tasks to adapt to both task complexity
and LLM capability. Our results demonstrate that ADaPT substantially
outperforms established strong baselines, achieving success rates up to 28.3%
higher in ALFWorld, 27% in WebShop, and 33% in TextCraft -- a novel
compositional dataset that we introduce. Through extensive analysis, we
illustrate the importance of multilevel decomposition and establish that ADaPT
dynamically adjusts to the capabilities of the executor LLM as well as to task
complexity.Comment: Project Page: https://allenai.github.io/adaptll",,http://arxiv.org/abs/2311.05772,153804758,adapt: as-needed decomposition and planning with language models,2023-11-08T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Artificial intelligence (AI) has brought benefits, but it may also cause harm
if it is not appropriately developed. Current development is mainly driven by a
""technology-centered"" approach, causing many failures. For example, the AI
Incident Database has documented over a thousand AI-related accidents. To
address these challenges, a human-centered AI (HCAI) approach has been promoted
and has received a growing level of acceptance over the last few years. HCAI
calls for combining AI with user experience (UX) design will enable the
development of AI systems (e.g., autonomous vehicles, intelligent user
interfaces, or intelligent decision-making systems) to achieve its design goals
such as usable/explainable AI, human-controlled AI, and ethical AI. WHile HCAI
promotion continues, it has not specifically addressed the collaboration
between AI and human-computer interaction (HCI) communities, resulting in
uncertainty about what action should be taken by both sides to apply HCAI in
developing AI systems. This Viewpoint focuses on the collaboration between the
AI and HCI communities, which leads to eight recommendations for effective
collaboration to enable HCAI in developing AI systems",,http://arxiv.org/abs/2111.08460,120221004,"enabling human-centered ai: a new junction and shared journey between ai
  and hci communities",2022-03-20T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Whether we like it or not Artificial Intelligence (AI) is coming, and we are not ready for it.  AI has unimaginable potential and will revolutionize the world over the next few decades, but with this great potential we are faced with choices that could prove detrimental to humanity. This article examines the challenges AI presents and explores possible solutions to make AI align with human interests",,https://core.ac.uk/download/429963118.pdf,40127949,the future of artificial intelligence,2021-05-01T08:00:00,DigitalCommons@Kennesaw State University,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This magazine tells about things happening in the College of Engineering, Computing and Applied Sciences as well as highlighting current students, faculty and alumni of the college",,https://core.ac.uk/download/547500110.pdf,133728786,ideas,2020-04-01T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
https://scholarcommons.scu.edu/eng_news/1052/thumbnail.jp,,https://core.ac.uk/download/561034051.pdf,145997639,"engineering news, fall 2022",2020-10-01T08:00:00,Scholar Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In addition to their security properties, adversarial machine-learning
attacks and defenses have political dimensions. They enable or foreclose
certain options for both the subjects of the machine learning systems and for
those who deploy them, creating risks for civil liberties and human rights. In
this paper, we draw on insights from science and technology studies,
anthropology, and human rights literature, to inform how defenses against
adversarial attacks can be used to suppress dissent and limit attempts to
investigate machine learning systems. To make this concrete, we use real-world
examples of how attacks such as perturbation, model inversion, or membership
inference can be used for socially desirable ends. Although the predictions of
this analysis may seem dire, there is hope. Efforts to address human rights
concerns in the commercial spyware industry provide guidance for similar
measures to ensure ML systems serve democratic, not authoritarian endsComment: Authors ordered alphabetically; 4 page",,https://core.ac.uk/download/578689854.pdf,89610245,politics of adversarial machine learning,2020-01-01T08:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"AI can perform tasks such as identifying patterns in the data more efficiently than humans, enabling businesses to gain more insight out of their data. With the help from AI, massive amounts of data can be analyzed to map poverty and climate change, automate agricultural practices and irrigation, individualize healthcare and learning, predict consumption patterns, streamline energy-usage and waste-management. A meta information can be gathered for these classification techniques and based on these meta information a model of robust for large datasets can be less accurate can be slow for former case. A meta information can be gathered for these classification techniques and based on these meta information a model of robust classifier can be formed which will decide to apply the techniques or their synergic approach based on the requirements of the particular situation",,https://core.ac.uk/download/492114287.pdf,212626,a study on the applications of artificial intelligence - with special reference to application of ai in business,2019-08-30T00:00:00,JConsort,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Artificial intelligence (AI) is rapidly entering health care and serving major roles, from automating drudgery and routine tasks in medical practice to managing patients and medical resources. As developers create AI systems to take on these tasks, several risks and challenges emerge, including the risk of injuries to patients from AI system errors, the risk to patient privacy of data acquisition and AI inference, and more. Potential solutions are complex but involve investment in infrastructure for high-quality, representative data; collaborative oversight by both the Food and Drug Administration and other health-care actors; and changes to medical education that will prepare providers for shifting roles in an evolving system",,https://core.ac.uk/download/572821048.pdf,146484478,risks and remedies for artificial intelligence in healthcare,2019-01-01T08:00:00,University of Michigan Law School Scholarship Repository,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We investigate the challenge of task planning for multi-task embodied agents
in open-world environments. Two main difficulties are identified: 1) executing
plans in an open-world environment (e.g., Minecraft) necessitates accurate and
multi-step reasoning due to the long-term nature of tasks, and 2) as vanilla
planners do not consider how easy the current agent can achieve a given
sub-task when ordering parallel sub-goals within a complicated plan, the
resulting plan could be inefficient or even infeasible. To this end, we propose
""$\underline{D}$escribe, $\underline{E}$xplain, $\underline{P}$lan and
$\underline{S}$elect"" ($\textbf{DEPS}$), an interactive planning approach based
on Large Language Models (LLMs). DEPS facilitates better error correction on
initial LLM-generated $\textit{plan}$ by integrating $\textit{description}$ of
the plan execution process and providing self-$\textit{explanation}$ of
feedback when encountering failures during the extended planning phases.
Furthermore, it includes a goal $\textit{selector}$, which is a trainable
module that ranks parallel candidate sub-goals based on the estimated steps of
completion, consequently refining the initial plan. Our experiments mark the
milestone of the first zero-shot multi-task agent that can robustly accomplish
70+ Minecraft tasks and nearly double the overall performances. Further testing
reveals our method's general effectiveness in popularly adopted non-open-ended
domains as well (i.e., ALFWorld and tabletop manipulation). The ablation and
exploratory studies detail how our design beats the counterparts and provide a
promising update on the $\texttt{ObtainDiamond}$ grand challenge with our
approach. The code is released at https://github.com/CraftJarvis/MC-Planner.Comment: NeurIPS 202",,http://arxiv.org/abs/2302.01560,152498571,"describe, explain, plan and select: interactive planning with large
  language models enables open-world multi-task agents",2023-10-29T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Prompt literacy signifies a major leap in education, offering a potent tool to interact with generative AI systems. As an emerging necessity in the 21st century and beyond, it encompasses the formulation, interpretation, and analysis of AI prompts. Poised to be foundational for all future generations, this discourse brings to light its emergence in parallel with generative AI and its transformative role in pedagogical contexts for the coming decades and beyond",10.7275/3498-wx48,https://core.ac.uk/download/586383236.pdf,149297283,prompt literacy: a pivotal educational skill in the age of ai,2023-01-01T08:00:00,ScholarWorks@UMass Amherst,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Machine Learning~(ML) has provided promising results in recent years across
different applications and domains. However, in many cases, qualities such as
reliability or even safety need to be ensured. To this end, one important
aspect is to determine whether or not ML components are deployed in situations
that are appropriate for their application scope. For components whose
environments are open and variable, for instance those found in autonomous
vehicles, it is therefore important to monitor their operational situation to
determine its distance from the ML components' trained scope. If that distance
is deemed too great, the application may choose to consider the ML component
outcome unreliable and switch to alternatives, e.g. using human operator input
instead. SafeML is a model-agnostic approach for performing such monitoring,
using distance measures based on statistical testing of the training and
operational datasets. Limitations in setting SafeML up properly include the
lack of a systematic approach for determining, for a given application, how
many operational samples are needed to yield reliable distance information as
well as to determine an appropriate distance threshold. In this work, we
address these limitations by providing a practical approach and demonstrate its
use in a well known traffic sign recognition problem, and on an example using
the CARLA open-source automotive simulator",,http://arxiv.org/abs/2207.05078,124463833,"keep your distance: determining sampling and distance thresholds in
  machine learning monitoring",2022-07-11T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"A human-inspired, linguistically sophisticated model of language understanding for intelligent agent systems. One of the original goals of artificial intelligence research was to endow intelligent agents with human-level natural language capabilities. Recent AI research, however, has focused on applying statistical and machine learning approaches to big data rather than attempting to model what people do and how they do it. In this book, Marjorie McShane and Sergei Nirenburg return to the original goal of recreating human-level intelligence in a machine. They present a human-inspired, linguistically sophisticated model of language understanding for intelligent agent systems that emphasizes meaning—the deep, context-sensitive meaning that a person derives from spoken or written language. With Linguistics for the Age of AI, McShane and Nirenburg offer a roadmap for creating language-endowed intelligent agents (LEIAs) that can understand,explain, and learn. They describe the language-understanding capabilities of LEIAs from the perspectives of cognitive modeling and system building, emphasizing “actionability”—which involves achieving interpretations that are sufficiently deep, precise, and confident to support reasoning about action. After detailing their microtheories for topics such as semantic analysis, basic coreference, and situational reasoning, McShane and Nirenburg turn to agent applications developed using those microtheories and evaluations of a LEIA's language understanding capabilities. McShane and Nirenburg argue that the only way to achieve human-level language understanding by machines is to place linguistics front and center, using statistics and big data as contributing resources. They lay out a long-term research program that addresses linguistics and real-world reasoning together, within a comprehensive cognitive architecture",10.7551/mitpress/13618.001.0001,https://core.ac.uk/download/520260179.pdf,126172550,linguistics for the age of ai,2022-02-21T15:13:20,'MIT Press - Journals',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"© 2018, Springer Nature Switzerland AG. Despite significant progress in a variety of vision-and-language problems, developing a method capable of asking intelligent, goal-oriented questions about images is proven to be an inscrutable challenge. Towards this end, we propose a Deep Reinforcement Learning framework based on three new intermediate rewards, namely goal-achieved, progressive and informativeness that encourage the generation of succinct questions, which in turn uncover valuable information towards the overall goal. By directly optimizing for questions that work quickly towards fulfilling the overall goal, we avoid the tendency of existing methods to generate long series of inane queries that add little value. We evaluate our model on the GuessWhat?! dataset and show that the resulting questions can help a standard ‘Guesser’ identify a specific object in an image at a much higher success rate",10.1007/978-3-030-01228-1_12,https://opus.lib.uts.edu.au/bitstream/10453/128536/4/Goal-oriented_VQG.pdf,16173832,goal-oriented visual question generation via intermediate rewards,2018-01-01T00:00:00,'Springer Science and Business Media LLC',"[{'title': None, 'identifiers': ['0302-9743', 'issn:0302-9743']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"17 USC 105 interim-entered record; under review.Computer hosts a virtual roundtable with seven 
experts to discuss the formal specification and 
verification of cyberphysical systems.http://hdl.handle.net/10945/6944",,https://core.ac.uk/download/528266686.pdf,125178770,formal verification of cyberphysical systems,2021-01-01T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Current home automation system merges a family\u27s lifestyle with the latest technology & energy management tools to simplify people\u27s lives. It allows users to easily manipulate a variety of home systems, including appliances, security systems, and environmental systems. Setting up a home automation system confuses many consumers. Multiple product lines and platforms make choosing the best system difficult. Basic requirements of setting up a home automation system and the comparison between different platforms are explained.
An intelligent home automation system makes intelligent decisions to control a home. This type system might use a weather report to adjust a home\u27s lawn watering schedule, as well as adjust the thermostat for temperature control in the home. Traditional home automation systems require human decision making to control the home system. The future intelligent home will require less human interactions, that can do things automatically after it learns patterns from us. A new generation requires more developed AI to control the smart home automation. Based on the technology we have now, the possible consumer-oriented AI technology is predicted in this paper.
When the market is growing rapidly, companies are supposed to have better opportunities to make money. Due to the increasing popularity of home automation systems, the competition is very intense. Companies try the best to take the first mover advantage. Three suggestions are made to help those companies to build their strategies",,https://core.ac.uk/download/228820541.pdf,67047285,"the emergence of artificial intelligence in the home: products, services, and broader developments of consumer oriented ai",2017-03-08T08:00:00,Digital Commons@WOU,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Recent work on transformer-based neural networks has led to impressive
advances on multiple-choice natural language understanding (NLU) problems, such
as Question Answering (QA) and abductive reasoning. Despite these advances,
there is limited work still on understanding whether these models respond to
perturbed multiple-choice instances in a sufficiently robust manner that would
allow them to be trusted in real-world situations. We present four confusion
probes, inspired by similar phenomena first identified in the behavioral
science community, to test for problems such as prior bias and choice
paralysis. Experimentally, we probe a widely used transformer-based
multiple-choice NLU system using four established benchmark datasets. Here we
show that the model exhibits significant prior bias and to a lesser, but still
highly significant degree, choice paralysis, in addition to other problems. Our
results suggest that stronger testing protocols and additional benchmarks may
be necessary before the language models are used in front-facing systems or
decision making with real world consequences",,http://arxiv.org/abs/2210.01258,131755524,"understanding prior bias and choice paralysis in transformer-based
  language representation models through four experimental probes",2022-10-03T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Societal and commercial pressures are impacting more than ever on the methods and techniques by which we assemble today's functional molecules. A holistic appreciation of this complex eco-system necessitates the invention of new tools and stimulates innovative thinking. In particular, the labour intensive and unsustainable practices of the past are being replaced by a more machine-based approach. This engineering of chemistry goes beyond the design of simple, enabling mechanical contrivances to encompass a full range of artificial intelligence (AI) methods, machine learning algorithms, advanced robotics and reaction profiling techniques. Integration of these systems with data collection and evaluation are the new drivers for success. Access to wider process windows, improved mixing and mass and heat transfer methods are providing early kinetic data that aids discovery. Mechanochem, photo-redox and electrochemical devices are further adding to the repertoire of the synthetic chemist. Flow chemistry and continuous processing methods are similarly breaking new ground as delineated by many of authors in this Symposium in Print. Indeed, flow chemistry has proven to be very amenable to automation over several telescoped reaction steps leading to complex natural products and active pharmaceutical ingredients (API's) in particular. The modular nature and flexibility of these systems assists in designing reactor configurations that can accommodate in-line purification, which are increasingly being used in downstream product processing",10.17863/cam.26402,https://core.ac.uk/download/162916094.pdf,52954953,engineering chemistry for the future of organic synthesis,2018-06-21T01:00:00,Tetrahedron,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Research on writing tools started with the increased availability of
computers in the 1970s. After a first phase addressing the needs of programmers
and data scientists, research in the late 1980s started to focus on
writing-specific needs. Several projects aimed at supporting writers and
letting them concentrate on the creative aspects of writing by having the
writing tool take care of the mundane aspects using NLP techniques. Due to
technical limitations at that time the projects failed and research in this
area stopped. However, today's computing power and NLP resources make the ideas
from these projects technically feasible; in fact, we see projects explicitly
continuing from where abandoned projects stopped, and we see new applications
integrating NLP resources without making references to those old projects. To
design intelligent writing assistants with the possibilities offered by today's
technology, we should re-examine the goals and lessons learned from previous
projects to define the important dimensions to be considered.Comment: Final version of the position paper to participate in the Second
  Workshop on Intelligent and Interactive Writing Assistants (colocated with
  the ACM CHI Conference on Human Factors in Computing Systems (CHI 2023) in
  Hamburg",,http://arxiv.org/abs/2303.17894,142114615,writing tools: looking back to look ahead,2023-03-31T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We present MindEye, a novel fMRI-to-image approach to retrieve and
reconstruct viewed images from brain activity. Our model comprises two parallel
submodules that are specialized for retrieval (using contrastive learning) and
reconstruction (using a diffusion prior). MindEye can map fMRI brain activity
to any high dimensional multimodal latent space, like CLIP image space,
enabling image reconstruction using generative models that accept embeddings
from this latent space. We comprehensively compare our approach with other
existing methods, using both qualitative side-by-side comparisons and
quantitative evaluations, and show that MindEye achieves state-of-the-art
performance in both reconstruction and retrieval tasks. In particular, MindEye
can retrieve the exact original image even among highly similar candidates
indicating that its brain embeddings retain fine-grained image-specific
information. This allows us to accurately retrieve images even from large-scale
databases like LAION-5B. We demonstrate through ablations that MindEye's
performance improvements over previous methods result from specialized
submodules for retrieval and reconstruction, improved training techniques, and
training models with orders of magnitude more parameters. Furthermore, we show
that MindEye can better preserve low-level image features in the
reconstructions by using img2img, with outputs from a separate autoencoder. All
code is available on GitHub.Comment: Project Page at https://medarc-ai.github.io/mindeye-website/. Code at
  https://github.com/MedARC-AI/fMRI-reconstruction-NSD",,http://arxiv.org/abs/2305.18274,143137621,"reconstructing the mind's eye: fmri-to-image with contrastive learning
  and diffusion priors",2023-05-29T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The creation of machines with human intelligence is an primary and beneficial aim of artificial intelligence research. One interesting method in developing artificial intelligence is combining a biological method and machine intelligence. Cyborg Intelligence is a new scientific model for the integration of biological and machinery. Brain Machine Interface (BMI) provides an opportunity to integrate both intelligence at various levels. Based on BMI, neural signals can be read for the control of motor actuators and sensory information coding machine can be sent to a specific area of the brain. In fact, Distributed Adaptive Control Theory of Mind and Brain technology is the most advanced brain-based cognitive architecture successfully applied in a wide range of robot tasks. It is expected that by analyzing the cyborg intelligence development can help and facilitate to enhance the knowledge of cyborg intelligence",10.35760/ik.2018.v23i3.2375,https://core.ac.uk/download/287171888.pdf,77850247,towards advanced development of cyborg intelligence,2020-02-08T00:00:00,'Gunadarma University',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Sacred Heart University spent significant funds to establish an AI lab. Initially there is no ongoing research and no real plan for a research agenda. This paper details how the Jack Welch College of Business and Technology created and implemented an active meaningful research plan. It involves two key elements: thinking local and using business connections to foster active, impactful research. Surrounding communities, business connections, area environment, and other Sacred Heart University departments all played a part. The research plan also identifies a specific issue in working with local and business contact sources: the AI researcher almost never gets data that is ready to use. Typically, there are missing or mistaken data points. While one enters a research project thinking of structure, algorithms and potential results, the reality is that a substantial amount of time will be devoted to cleaning data. For business students is an important lesson: structure your AI input so that the results have meaning",,https://core.ac.uk/download/588300003.pdf,148434967,thinking local with original data in ai and machine learning research,2023-01-01T08:00:00,DigitalCommons@SHU,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Accountants have embraced the emission of automation over many years to get better the efficiency and effectiveness of their work. But technology has not been able to replace the need for expert knowledge and decision-making. Earlier generations of ‘intelligent systems have usually demonstrated the progressing power of human expertise and the restrictions of machines. In the upcoming decades, intelligent systems must take over more and better decision-making tasks from humans. While accountant has been using technology for a lot of years to improve what they do and deliver more value to businesses, this is an opportunity to reimagine and radically improve the quality of business and investment decisions which is the ultimate purpose of the profession. Accountants, as expert decision-makers, use both ways of thinking they apply their knowledge to specific situations to make reasoned decisions, although also make quick intuitive decisions based on extensive experience in their field.  Today, AI is being used for image recognition, object identification, detection, classification, and automated geophysical feature detection. These are underlying tasks that once required the input of a human. Focusing on how artificial intelligence will impact accountants, AI will very soon help the organization to automate much of the routine and repetitive activities that are undertaken on a daily, weekly or annual basis. It will also help the organization to empower quick decision-making to create smart insights examine huge quantities of data with ease",10.47742/ijbssr.v2n5p1,https://core.ac.uk/download/480618606.pdf,122836404,towards understanding of artificial intelligence in accounting profession,2021-05-30T01:00:00,The Center for Promoting Education and Research (CPER),[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In this paper, we propose the use of interactive the- orem proving for explainable machine learning. After presenting our proposition, we illustrate it on the dedicated application of explaining security attacks using the Isabelle Infrastructure framework and its process of dependability engineering. This formal framework and process provides the logics for specifi- cation and modeling. Attacks on security of the system are ex- plained by specification and proofs in the Isabelle Infrastructure framework. Existing case studies of dependability engineering in Isabelle are used as feasibility studies to illustrate how different aspects of explanations are covered by the Isabelle Infrastructure framework",10.48550/arxiv.2112.14809,https://core.ac.uk/download/573845783.pdf,145374191,explanation by automated reasoning using the isabelle infrastructure framework,2021-01-01T00:00:00,"Preprint,  arxiv.org",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Background: Code summarization automatically generates the corresponding
natural language descriptions according to the input code. Comprehensiveness of
code representation is critical to code summarization task. However, most
existing approaches typically use coarse-grained fusion methods to integrate
multi-modal features. They generally represent different modalities of a piece
of code, such as an Abstract Syntax Tree (AST) and a token sequence, as two
embeddings and then fuse the two ones at the AST/code levels. Such a coarse
integration makes it difficult to learn the correlations between fine-grained
code elements across modalities effectively. Aims: This study intends to
improve the model's prediction performance for high-quality code summarization
by accurately aligning and fully fusing semantic and syntactic structure
information of source code at node/token levels. Method: This paper proposes a
Multi-Modal Fine-grained Feature Fusion approach (MMF3) for neural code
summarization. We introduce a novel fine-grained fusion method, which allows
fine-grained fusion of multiple code modalities at the token and node levels.
Specifically, we use this method to fuse information from both token and AST
modalities and apply the fused features to code summarization. Results: We
conduct experiments on one Java and one Python datasets, and evaluate generated
summaries using four metrics. The results show that: 1) the performance of our
model outperforms the current state-of-the-art models, and 2) the ablation
experiments show that our proposed fine-grained fusion method can effectively
improve the accuracy of generated summaries. Conclusion: MMF3 can mine the
relationships between crossmodal elements and perform accurate fine-grained
element-level alignment fusion accordingly. As a result, more clues can be
provided to improve the accuracy of the generated code summaries.Comment: 12 pages, 5 figure",,http://arxiv.org/abs/2209.08978,130769966,"mmf3: neural code summarization based on multi-modal fine-grained
  feature fusion",2022-09-19T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Texts appearing in daily scenes that can be recognized by OCR (Optical
Character Recognition) tools contain significant information, such as street
name, product brand and prices. Two tasks -- text-based visual question
answering and text-based image captioning, with a text extension from existing
vision-language applications, are catching on rapidly. To address these
problems, many sophisticated multi-modality encoding frameworks (such as
heterogeneous graph structure) are being used. In this paper, we argue that a
simple attention mechanism can do the same or even better job without any bells
and whistles. Under this mechanism, we simply split OCR token features into
separate visual- and linguistic-attention branches, and send them to a popular
Transformer decoder to generate answers or captions. Surprisingly, we find this
simple baseline model is rather strong -- it consistently outperforms
state-of-the-art (SOTA) models on two popular benchmarks, TextVQA and all three
tasks of ST-VQA, although these SOTA models use far more complex encoding
mechanisms. Transferring it to text-based image captioning, we also surpass the
TextCaps Challenge 2020 winner. We wish this work to set the new baseline for
this two OCR text related applications and to inspire new thinking of
multi-modality encoder design. Code is available at
https://github.com/ZephyrZhuQi/ssbaselin",10.1609/aaai.v35i4.16476,http://arxiv.org/abs/2012.05153,107767801,simple is not easy: a simple strong baseline for textvqa and textcaps,2020-12-09T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Technological advancements have become ubiquitous within landscape architecture. One of the latest advancements is in Artificial Intelligence, including techniques such as Machine Learning, Artificial Neural Networks and problem optimization. These advancements have already worked their way into landscape architecture. In this theoretical paper we briefly identify what the state of the art in AI is, as well as its potential and limitations in the discipline. Specifically, we argue for the need to create a disciplinary ontology to make knowledge explicit and shared amongst humans and machines",10.14627/537705040,https://core.ac.uk/download/567635334.pdf,148140129,pursuing an ai ontology for landscape architecture,2021-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Dialogue act annotations are important to improve response generation quality
in task-oriented dialogue systems. However, it can be challenging to use
dialogue acts to control response generation in a generalizable way because
different datasets and tasks may have incompatible annotations. While
alternative methods that utilize latent action spaces or reinforcement learning
do not require explicit annotations, they may lack interpretability or face
difficulties defining task-specific rewards. In this work, we present a novel
end-to-end latent dialogue act model (DiactTOD) that represents dialogue acts
in a latent space. DiactTOD, when pre-trained on a large corpus, is able to
predict and control dialogue acts to generate controllable responses using
these latent representations in a zero-shot fashion. Our approach demonstrates
state-of-the-art performance across a wide range of experimental settings on
the MultiWOZ dataset, including zero-shot, few-shot, and full data fine-tuning
with both end-to-end and policy optimization configurations.Comment: SIGDial 202",,http://arxiv.org/abs/2308.00878,144971448,"diacttod: learning generalizable latent dialogue acts for controllable
  task-oriented dialogue systems",2023-08-01T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Artificial intelligence is an important innovation in the rapid development of modern Internet. In the 21st century, human beings have been continuously researching and exploring Internet information technology. All kinds of application forms of Internet informatization begin to appear in our life. The rapid change of technology brings a high upgrade rate of internet products. This marks the technological innovation of some traditional concepts and thinking methods. The development mode of artificial intelligence plus education is an important innovation after the deep development of artificial intelligence technology and the achievement of cross-industry application practice. Robots will be the brains of the future education process. This paper aims to clarify the development trend of the application of artificial intelligence in modern education by analyzing the innovation progress of the combination of artificial intelligence technology and contemporary education. This is of great significance for better use of the advantages of artificial intelligence to build a future-oriented high-tech education system",10.2991/iceemt-18.2018.118,https://core.ac.uk/download/343333712.pdf,95222982,analysis of new advances in the application of artificial intelligence to education,2018-01-01T00:00:00,'Anatomische Gesellschaft',"[{'title': None, 'identifiers': ['issn:2352-5398', '2352-5398']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Machine Learning as a Service (MLaaS) platforms have gained popularity due to
their accessibility, cost-efficiency, scalability, and rapid development
capabilities. However, recent research has highlighted the vulnerability of
cloud-based models in MLaaS to model extraction attacks. In this paper, we
introduce FDINET, a novel defense mechanism that leverages the feature
distribution of deep neural network (DNN) models. Concretely, by analyzing the
feature distribution from the adversary's queries, we reveal that the feature
distribution of these queries deviates from that of the model's training set.
Based on this key observation, we propose Feature Distortion Index (FDI), a
metric designed to quantitatively measure the feature distribution deviation of
received queries. The proposed FDINET utilizes FDI to train a binary detector
and exploits FDI similarity to identify colluding adversaries from distributed
extraction attacks. We conduct extensive experiments to evaluate FDINET against
six state-of-the-art extraction attacks on four benchmark datasets and four
popular model architectures. Empirical results demonstrate the following
findings FDINET proves to be highly effective in detecting model extraction,
achieving a 100% detection accuracy on DFME and DaST. FDINET is highly
efficient, using just 50 queries to raise an extraction alarm with an average
confidence of 96.08% for GTSRB. FDINET exhibits the capability to identify
colluding adversaries with an accuracy exceeding 91%. Additionally, it
demonstrates the ability to detect two types of adaptive attacks.Comment: 13 pages, 7 figure",,http://arxiv.org/abs/2306.11338,143670433,"fdinet: protecting against dnn model extraction via feature distortion
  index",2023-06-21T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
The contention of this chapter is that a reactive if understandable response to the harms caused by AI will itself risk feeding into wider social and ecological crises instead of escaping them. The chapter proposes to remedy this with forms of collective organisation as part of a post-AI politics,10.16997/book55.e,https://core.ac.uk/download/490817188.pdf,8161027,"post-humanism, mutual aid",2021-09-20T00:00:00,'University of Westminster Press',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In order to build reliable and trustworthy NLP applications, models need to
be both fair across different demographics and explainable. Usually these two
objectives, fairness and explainability, are optimized and/or examined
independently of each other. Instead, we argue that forthcoming, trustworthy
NLP systems should consider both. In this work, we perform a first study to
understand how they influence each other: do fair(er) models rely on more
plausible rationales? and vice versa. To this end, we conduct experiments on
two English multi-class text classification datasets, BIOS and ECtHR, that
provide information on gender and nationality, respectively, as well as
human-annotated rationales. We fine-tune pre-trained language models with
several methods for (i) bias mitigation, which aims to improve fairness; (ii)
rationale extraction, which aims to produce plausible explanations. We find
that bias mitigation algorithms do not always lead to fairer models. Moreover,
we discover that empirical fairness and explainability are orthogonal.Comment: 15 pages (incl Appendix), 4 figures, 8 table",,http://arxiv.org/abs/2310.16607,153563847,on the interplay between fairness and explainability,2023-11-13T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper explores some of the potential connections between natural and artificial intelligence and natural and artificial consciousness. In humans we use batteries of tests to indirectly measure intelligence. This approach breaks down when we try to apply it to radically different animals and to the many varieties of artificial intelligence. To address this issue people are starting to develop algorithms that can measure intelligence in any type of system. Progress is also being made in the scientific study of consciousness: we can neutralize the philosophical problems, we have data about the neural correlates and we have some idea about how we can develop mathematical theories that can map between physical and conscious states. While intelligence is a purely functional property of a system, there are good reasons for thinking that consciousness is linked to particular spatiotemporal patterns in specific physical materials. This paper outlines some of the weak inferences that can be made about the relationships between intelligence and consciousness in natural and artificial systems. To make real scientific progress we need to develop practical universal measures of intelligence and mathematical theories of consciousness that can reliably map between physical and conscious states",10.1142/s2705078520300017,https://core.ac.uk/download/573847230.pdf,145376158,the relationships between intelligence and consciousness in natural and artificial systems,2020-01-01T00:00:00,World Scientific Publishing Company,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This article navigates the confluence of the age-old constructivist philosophy of education and modern Artificial Intelligence (AI) tools as a means of reconceptualizing teaching and learning methods. While constructivism champions active learning derived from personal experiences and prior knowledge, AI’s adaptive capacities seamlessly align with these principles, offering personalized, dynamic, and enriching learning avenues. By leveraging AI platforms such as ChatGPT, BARD, and Microsoft Bing, educators can elevate constructivist pedagogy, fostering enhanced student engagement, self-reflective metacognition, profound conceptual change, and an enriched learning experience. The article further emphasizes the preservation of humanistic values in the integration of AI, ensuring a balanced, ethical, and inclusive educational environment. This exploration sheds light on the transformative potential of inter-twining traditional educational philosophies with technological advancements, paving the way for a more responsive and effective learning paradigm",10.59652/jetm.v1i3.43,https://core.ac.uk/download/591701204.pdf,152757973,harnessing ai to power constructivist learning: an evolution in educational methodologies,2023-09-05T01:00:00,European Institute of Knowledge and Innovation,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We introduce Lumos, a novel framework for training language agents that
employs a unified data format and a modular architecture based on open-source
large language models (LLMs). Lumos consists of three distinct modules:
planning, grounding, and execution. The planning module breaks down a task into
a series of high-level, tool-agnostic subgoals, which are then made specific by
the grounding module through a set of low-level actions. These actions are
subsequently executed by the execution module, utilizing a range of
off-the-shelf tools and APIs. In order to train these modules effectively,
high-quality annotations of subgoals and actions were collected and are made
available for fine-tuning open-source LLMs for various tasks such as complex
question answering, web tasks, and math problems. Leveraging this unified data
and modular design, Lumos not only achieves comparable or superior performance
to current, state-of-the-art agents, but also exhibits several key advantages:
(1) Lumos surpasses GPT-4/3.5-based agents in complex question answering and
web tasks, while equalling the performance of significantly larger LLM agents
on math tasks; (2) Lumos outperforms open-source agents created through
conventional training methods and those using chain-of-thoughts training; and
(3) Lumos is capable of effectively generalizing to unseen interactive tasks,
outperforming larger LLM-based agents and even exceeding performance of
specialized agents.Comment: Project website: https://allenai.github.io/lumos",,http://arxiv.org/abs/2311.05657,153804245,"lumos: learning agents with unified data, modular design, and
  open-source llms",2023-11-08T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Coming to a Battlefield Near You: Quantum Computing, Artificial Intelligence, & Machine Learning’s Impact on Proportionalit",,https://core.ac.uk/download/286697834.pdf,77675684,"coming to a battlefield near you: quantum computing, artificial intelligence, & machine learning’s impact on proportionality",2020-01-10T08:00:00,Santa Clara Law Digital Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper examines the philosophical foundations of deep learning. By pointing to the beginnings of deep learning and artificial neuron as a logical model of a human neuron, it is possible to claim that artificial intelligence was developed even before its official creation and that it was strongly connected to propositional logic. Bearing in mind some major setbacks in the development of neural networks, we show that deep learning can be treated as the theory of artificial intelligence and that it falls under artificial intelligence paradigm by claiming that everything can be done with learning alone and that all intelligent behavior is learnable. Thus, deep learning is a philosophical or an epistemological approach in which a form of radical empiricism must be advocated. Therefore, there is nothing in the mind that was not in the senses, and there cannot be anything in the mind that is not learnable.U radu se ispituju filozofski temelji dubokog učenja. Ukazivanjem na početke dubokog učenja i umjetnog neurona kao formalnog modela ljudskog neurona moguće je tvrditi da je umjetna inteligencija razvijena i prije njezinog službenog imenovanja te da je bila snažno povezana s propozicionalnom logikom. Imajući na umu neke velike zastoje u razvoju neuronskih mreža, pokazujemo da se dubinsko učenje može tretirati kao teorija umjetne inteligencije te da potpada pod paradigmu umjetne inteligencije jer je za nju dovoljno samo učenje jer se inteligentno ponašanje uči. Dakle, duboko učenje je filozofski ili epistemološki pristup u kojem se mora zagovarati radikalni empirizam. Prema tome, ne samo da ne postoji ništa u umu što nije bilo u osjetilima, već u umu ne postoji ništa što se ne može naučiti",10.32701/dp.23.1.6,https://core.ac.uk/download/491398209.pdf,131810080,prolegomena filozofijskog utemeljenja dubokog učenja kao teorije (umjetne) inteligencije,2021-01-01T00:00:00,'Faculty of Philosophy and Religious Studies',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Deep Neural Networks (DNNs) are being used to solve a wide range of problems
in many domains including safety-critical domains like self-driving cars and
medical imagery. DNNs suffer from vulnerability against adversarial attacks. In
the past few years, numerous approaches have been proposed to tackle this
problem by training networks using adversarial training. Almost all the
approaches generate adversarial examples for the entire training dataset, thus
increasing the training time drastically. We show that we can decrease the
training time for any adversarial training algorithm by using only a subset of
training data for adversarial training. To select the subset, we filter the
adversarially-prone samples from the training data. We perform a simple
adversarial attack on all training examples to filter this subset. In this
attack, we add a small perturbation to each pixel and a few grid lines to the
input image.
  We perform adversarial training on the adversarially-prone subset and mix it
with vanilla training performed on the entire dataset. Our results show that
when our method-agnostic approach is plugged into FGSM, we achieve a speedup of
3.52x on MNIST and 1.98x on the CIFAR-10 dataset with comparable robust
accuracy. We also test our approach on state-of-the-art Free adversarial
training and achieve a speedup of 1.2x in training time with a marginal drop in
robust accuracy on the ImageNet dataset.Comment: 6 pages, 4 figure",,http://arxiv.org/abs/2303.06241,141346860,do we need entire training data for adversarial training?,2023-03-10T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Cognitive science is considered to be the study of mind (consciousness and thought) and intelligence in humans. Under such definition variety of unsolved/unsolvable problems appear. This article argues for a broad understanding of cognition based on empirical results from i.a. natural sciences, self-organization, artificial intelligence and artificial life, network science and neuroscience, that apart from the high level mental activities in humans, includes sub-symbolic and sub-conscious processes, such as emotions, recognizes cognition in other living beings as well as extended and distributed/social cognition. The new idea of cognition as complex multiscale phenomenon evolved in living organisms based on bodily structures that process information, linking cognitivists and EEEE (embodied, embedded, enactive, extended) cognition approaches with the idea of morphological computation (info-computational self-organisation) in cognizing agents, emerging in evolution through interactions of a (living/cognizing) agent with the environment",10.1007/978-3-319-96448-5_2,https://core.ac.uk/download/228134996.pdf,8859014,cognition as embodied morphological computation,2018-01-01T00:00:00,,"[{'title': None, 'identifiers': ['2192-6255']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"UIDB/05021/2020
UIDP/05021/2020The long history of human biological and cultural co-evolution has been, in its entirety, a history of the composition between the human and the non-human, a history of interactions and media- tions between the physical, biological, technological and symbolic dimensions of existence.The full recognition of this reality dictates the need for an extended ecological thinking that also imposes on the humanities. Their contribution to a general ecology is, in fact, crucial, as the latter cannot do without a critique of the Anthropos’s spiritual and cognitive primordiality and his exter- nalization in modes of perceiving, thinking and acting upon the world. Media studies have been central to this critique and to the post-human epistemology that emerged, in particular, through digital culture. Ecological thinking thus requires a cognitive ecol- ogy which, in turn, constitutes itself as a critique of mediation, increasingly necessary, as both cognition and existence are now permeated by informationalization, computation and algorithmic governance, forming a planetary scale digital environment.publishersversionpublishe",,https://core.ac.uk/download/591216000.pdf,150472369,the humanities and the digital,2023-01-01T00:00:00,Instituto Terra e Memória,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Machine vision is one of the main applications of artificial intelligence. In China, the machine vision industry makes up more than a third of the national AI market, and technologies like face recognition, object tracking and automated driving play a central role in surveillance systems and social governance projects relying on the large-scale collection and processing of sensor data. Like other novel articulations of technology and society, machine vision is defined, developed and explained by different actors through the work of imagination. In this article, we draw on the concept of sociotechnical imaginaries to understand how Chinese companies represent machine vision. Through a qualitative multimodal analysis of the corporate websites of leading industry players, we identify a cohesive sociotechnical imaginary of machine vision, and explain how four distinct visual registers contribute to its articulation. These four registers, which we call computational abstraction, human–machine coordination, smooth everyday, and dashboard realism, allow Chinese tech companies to articulate their global ambitions and competitiveness through narrow and opaque representations of machine vision technologies.publishedVersio",10.1007/s00146-023-01733-x,https://core.ac.uk/download/588770005.pdf,150774885,imagining machine vision: four visual registers from the chinese ai industry,2023-01-01T00:00:00,Springer,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"A common practice in knowledge-grounded dialogue generation is to explicitly
utilize intermediate steps (e.g., web-search, memory retrieval) with modular
approaches. However, data for such steps are often inaccessible compared to
those of dialogue responses as they are unobservable in an ordinary dialogue.
To fill in the absence of these data, we develop a self-improving method to
improve the generative performances of intermediate steps without the ground
truth data. In particular, we propose a novel bootstrapping scheme with a
guided prompt and a modified loss function to enhance the diversity of
appropriate self-generated responses. Through experiments on various benchmark
datasets, we empirically demonstrate that our method successfully leverages a
self-improving mechanism in generating intermediate and final responses and
improves the performances on the task of knowledge-grounded dialogue
generation",,http://arxiv.org/abs/2310.06404,152482062,hexa: self-improving for knowledge-grounded dialogue system,2023-10-22T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We study a synthetic corpus-based approach for language models (LMs) to
acquire logical deductive reasoning ability. The previous studies generated
deduction examples using specific sets of deduction rules. However, these rules
were limited or otherwise arbitrary. This can limit the generalizability of
acquired deductive reasoning ability. We rethink this and adopt a well-grounded
set of deduction rules based on formal logic theory, which can derive any other
deduction rules when combined in a multistep way. We empirically verify that
LMs trained on the proposed corpora, which we name $\textbf{FLD}$
($\textbf{F}$ormal $\textbf{L}$ogic $\textbf{D}$eduction), acquire more
generalizable deductive reasoning ability. Furthermore, we identify the aspects
of deductive reasoning ability on which deduction corpora can enhance LMs and
those on which they cannot. Finally, on the basis of these results, we discuss
the future directions for applying deduction corpora or other approaches for
each aspect. We release the code, data, and models",,http://arxiv.org/abs/2308.07336,145455568,learning deductive reasoning from synthetic corpus based on formal logic,2023-08-11T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Generative AI (GenAI) models excel in their ability to recognize patterns in
existing data and generate new and unexpected content. Recent advances have
motivated applications of GenAI tools (e.g., Stable Diffusion, ChatGPT) to
professional practice across industries, including product design. While these
generative capabilities may seem enticing on the surface, certain barriers
limit their practical application for real-world use in industry settings. In
this position paper, we articulate and situate these barriers within two phases
of the product design process, namely ""getting the right design"" and ""getting
the design right,"" and propose a research agenda to stimulate discussions
around opportunities for realizing the full potential of GenAI tools in product
design",,http://arxiv.org/abs/2306.01217,143187330,"generative ai for product design: getting the right design and the
  design right",2023-06-01T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The purpose of this project is to observe the evolution of two artificial agents, a ‘Seeker’ and a ‘Hider’, as they play a simplified version of the game Hide and Seek. These agents will improve through machine learning, and will only be given an understanding of the rules of the game and the ability to navigate through the grid-like space where the game shall be played; they will not be taught or given any strategies, and will be made to learn from a clean slate. Of particular interest is observing the particular playstyle of hider and seeker intelligences as new elements are introduced into the game, such as obstacles, doors, among other environmental influences. Through this observation, I hope to identify not only key strategies in the game of hide and seek, but to achieve a greater understanding of the evolution of machine learning AI searching and hiding patterns, which are relevant to several fields such as networking, artificial intelligence, and cyber security",,https://core.ac.uk/download/479135570.pdf,18980233,observation of the evolution of hide and seek ai,2021-06-01T08:00:00,DigitalCommons@CalPoly,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Article translated from Russian. First published in: Агеев А.И. Этические дилеммы систем искусственного интеллекта, в книге Социогуманитарные аспекты цифровых трансформаций искусственного интеллекта под редакцией В.Е. Лепского, А.Н. Райкова. Москва, Когито-Центр. 2022. Глава 3.5",10.58863/20.500.12424/4276064,https://core.ac.uk/download/582653558.pdf,146586668,ethical dilemmas of artificial intelligence systems,2023-01-01T00:00:00,Globethics Publications,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Despite the existence of various benchmarks for evaluating natural language
processing models, we argue that human exams are a more suitable means of
evaluating general intelligence for large language models (LLMs), as they
inherently demand a much wider range of abilities such as language
understanding, domain knowledge, and problem-solving skills. To this end, we
introduce M3Exam, a novel benchmark sourced from real and official human exam
questions for evaluating LLMs in a multilingual, multimodal, and multilevel
context. M3Exam exhibits three unique characteristics: (1) multilingualism,
encompassing questions from multiple countries that require strong multilingual
proficiency and cultural knowledge; (2) multimodality, accounting for the
multimodal nature of many exam questions to test the model's multimodal
understanding capability; and (3) multilevel structure, featuring exams from
three critical educational periods to comprehensively assess a model's
proficiency at different levels. In total, M3Exam contains 12,317 questions in
9 diverse languages with three educational levels, where about 23\% of the
questions require processing images for successful solving. We assess the
performance of top-performing LLMs on M3Exam and find that current models,
including GPT-4, still struggle with multilingual text, particularly in
low-resource and non-Latin script languages. Multimodal LLMs also perform
poorly with complex multimodal questions. We believe that M3Exam can be a
valuable resource for comprehensively evaluating LLMs by examining their
multilingual and multimodal abilities and tracking their development. Data and
evaluation code is available at \url{https://github.com/DAMO-NLP-SG/M3Exam}",,http://arxiv.org/abs/2306.05179,143298111,"m3exam: a multilingual, multimodal, multilevel benchmark for examining
  large language models",2023-06-08T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Segundo a Organização Mundial da Saúde, as doenças cardiovasculares (DCV) representam 32% do número de mortes no mundo. A redução deste valor pode ser atingida através da deteção precoce que pode levar a um tratamento mais preciso, melhorando a expectativa de vida do paciente. A ausculta cardíaca é a principal técnica utilizada pelos profissionais de saúde para identificar muitas DCV. No entanto, a auscultação dos sons cardíacos é um procedimento difícil, já que muitos sons são fracos e difíceis de detetar, sendo necessário um processo de treino contínuo. Os estetoscópios modernos podem amplificar os sons cardíacos, reduzir o ruído de ambiente, melhorar a percepção do usuário e, mais importante, converter um sinal acústico em digital. Isto permitiu o desenvolvimento de sistemas de decisão assistidos por computador baseados na auscultação. Este documento apresenta uma metodologia que pode detectar automaticamente a existência de DCV através de sons cardíacos obtidos de diferentes partes do coração. Diversas tecnologias foram analisadas, assim como projetos que tentam resolver parte do problema em questão e a partir deles, três alternativas diferentes foram elaboradas e documentadas, assim como a divisão do dataset e métricas a serem usadas nos testes. Essas alternativas visam classificar anomalias na auscultação cardíaca dos pacientes. Vários modelos das duas primeiras alternativas foram implementados e seus resultados apresentados. Também é feita uma comparação entre as experiências desenvolvidas entre si, também com experiências básicas que não utilizam mecanismos inteligentes e com outros trabalhos que tenham o mesmo objetivo. O melhor resultado obtido foi pela primeira abordagem com uma exatidão de 94%, precisão de 81% e recall de 67%.According to World Health Organization, the cardiovascular diseases (CVD) represent 32% of the number of deaths worldwide. Early detection leads to a more accurate treatment plan and improves the patient’s life expectancy. Cardiac auscultation is the main technique used by health professionals to identify many CVD. Nevertheless, heart sound auscultation is a difficult procedure, since it requires continuous training and many heart sounds are faint and hard to detect. However, modern stethoscopes can amplify heart sounds, reduce the environment noise, improve the user’s perception and, more importantly, convert an acoustic signal to a digital one. This allowed, the development of computer assisted decision systems based on auscultation. This document presents a methodology that can automatically detect the existence of CVD through cardiac sounds obtained from different parts of the heart. Several technologies were analysed, as well as projects that try to solve part of the problem in question and from them, three different alternatives were elaborated and documented, as well as the division of test data and the metrics for their evaluation. These alternatives are intended to classify anomalies in patients' cardiac auscultation. Several models of the first two alternatives were implemented and their results presented. A comparison is also made between the experiences developed among themselves, also with basic experiments that do not use intelligent mechanisms and with other works that have the same objective. The best result obtained was by the first approach with an accuracy of 94%, precision of 81% and recall of 67%",,https://core.ac.uk/download/552899849.pdf,138643926,deteção de patologia cardíaca usando machine learning,2022-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper explores a simple idea and asks a simple question: What determines the speed limit of evolutionary processes, and might there be ways to speed up those processes for certain types of systems under certain conditions? Or even more simply, how rapidly can complex systems be rebuilt? To begin with, the universe can be viewed as an evolving ecology of entities. Entities correspond to types of systems - from atoms in stars to organisms on Earth to ideas in the heads of people. Service science is the study of the evolving ecology of service system entities, complex socio-technical systems with rights and responsibilities – such as people, businesses, and nations. We can only scratch the surface in this paper, but our explorations suggest this is an important research question and direction, especially as we enter the cognitive era of smart and wise service systems. For example, it takes a child multiple years of experience to learn language and basic social interactions skills, but could machine learning algorithms with the proper data sets learn those capabilities in a fraction of the time",10.24251/hicss.2017.201,https://core.ac.uk/download/301371008.pdf,17808826,rebuilding evolution: a service science perspective,2017-01-01T00:00:00,AIS Electronic Library (AISeL),[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Cloud computing addresses how to make right resources available to right computation to improve scaling, resiliency and efficiency of the computation. We argue that cloud computing indeed, is a new paradigm for computation with a higher order of artificial intelligence (AI), and put forward cloud automata as a new model for computation. A high-level AI requires infusing features that mimic human functioning into AI systems. One of the central features is that humans learn all the time and the learning is incremental. Consequently, for AI, we need to use computational models, which reflect incremental learning without stopping (sentience). These features are inherent in reflexive, inductive and limit Turing machines. To construct cloud automata, we use the mathematical theory of Oracles, which include Oracles of Turing machines as its special case. We develop a hierarchical approach based on Oracles with different ranks that includes Oracle AI as a special case. Discussing a named-set approach, we describe an implementation of a high-performance edge cloud using hierarchical name-oriented networking and Oracle AI-based orchestration. We demonstrate how cloud automata with a control overlay allows microservice network provisioning, monitoring and reconfiguration to address non-deterministic fluctuations affecting their behavior without interrupting the overall evolution of computation",,https://core.ac.uk/download/pdf/322551506.pdf,85747236,cloud computing and cloud automata as a new paradigm for computation,2019-08-30T01:00:00,PURKH,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"With the widespread of the Internet of things (IoT), algorithms are increasingly managing our everyday life. From navigating our way in cities to keeping track of our health, artificial intelligence has been beneficial to us in many ways. However, its algorithms can also be detrimental as a consequence of biased human programming. The result is that while technological progress delivers more and more human-like artificial intelligence, humans become dehumanised and therefore, disempowered in their everyday interactions with artificial intelligence.The solution(s) is not single-handed and calls for combined interventions at the macro and micro levels. Whilst reviewing recent top-down developments on the front of AI ethics, this article delves into the question of to what extent ordinary citizens can exercise any kind of agency when it comes to artificial intelligence. It does so through a multidimensional approach including analogies and intertextual motions between history, literature, and visual culture. Focussing on the case study of facial recognition software, the article explores the possibilities of imaginative agency as a form of local intelligence capable of dwelling in and contesting [human-made] algorithmic bias",,https://core.ac.uk/download/539113362.pdf,128971824,living with machines. ethical implications and imaginative agency as local tactics of dwelling and resistance in everyday interactions with artificial intelligence,2020-07-20T08:00:00,Technological University Dublin,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The case study of Degenerative Cultures explores how the layering of different forms of logic offers an opportunity for rethinking our human systems and hypothetically remixing the epistemological roots of society—through interventions into our technological systems. In Degenerative Cultures, the living organism Physarum polycephalum partners with an artificial intelligence that compiles and corrupts an archive of human texts. In the iterative art installation, which incorporates the growth cycles of microbiological organisms, protists as well as fungi cover up and effectively remix human texts. Human knowledge, contained within the philosophy books used in the project, becomes the substrate for organic growth. The living organisms grow over an actual book, and the AI, referred to as a “digital fungus,” corrupts texts on the Internet. The artists’ experiment, which links microbiological growth logic to artificial intelligence, is one step in rethinking how human knowledge may become layered and ultimately corrupted and rerouted—a forking of sorts—through integration with nonhuman logic systems, including microbiological and artificial intelligences. By orienting this work to remix theory, the article offers the hypothesis of a multispecies recombination that could, in utopian terms, reformulate the epistemological basis of modernity. In order to pursue this hypothesis, the art collective Cesar & Lois asks what role remix plays in the ongoing emergence of artificial intelligence and machine learning",10.21900/j.median.v17i1.486,https://core.ac.uk/download/490702704.pdf,25442955,case study: remixing knowledge with layered intelligences,2021-01-01T00:00:00,'University of Illinois Main Library',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper represents preliminary work in identifying the foundation for the
discipline of Software Engineering and discovering the links between the
domains of Software Engineering and Information Technology (IT). Our research
utilized IEEE Transactions on Software Engineering (IEEE-TSE), ACM Transactions
on Software Engineering and Methodology (ACM-TOSEM), Automated Software
Engineering (ASE), the International Conference on Software Engineering(ICSE),
and other related journal publication in the software engineering domain to
address our research questions. We explored existing frameworks and described
the need for software engineering as an academic discipline. We went further to
clarify the distinction difference between Software Engineering and Computer
Science. Through this efforts we contribute to an understanding of how evidence
from IT research can be used to improve Software Engineering as a discipline",,http://arxiv.org/abs/2206.09303,133833299,"the framework for the discipline of software engineering in connection
  to information technology discipline",2022-10-27T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"With 5G mobile communication systems been commercially rolled out, research discussions on next generation mobile systems, i.e., 6G, have started. On the other hand, vehicular technologies are also evolving rapidly, from connected vehicles as coined by V2X (vehicle to everything) to autonomous vehicles to the combination of the two, i.e., the networks of connected autonomous vehicles (CAV). How fast the evolution of these two areas will go head-in-head is of great importance, which is the focus of this paper. After a brief overview on technological evolution of V2X to CAV and 6G key technologies, this paper explores two complementary research directions, namely, 6G for CAVs versus CAVs for 6G. The former investigates how various 6G key enablers, such as THz, cell free communication and artificial intelligence (AI), can be utilized to provide CAV mission-critical services. The latter discusses how CAVs can facilitate effective deployment and operation of 6G systems. This paper attempts to investigate the interactions between the two technologies to spark more research efforts in these areas",10.1109/mnet.011.2000541,https://core.ac.uk/download/349055544.pdf,8731706,6g cellular networks and connected autonomous vehicles,2020-10-02T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"“Rethink the theoretical foundations of the IS discipline” is one of the grand challenges for IS research identified in a Delphi study in Business Information Systems Engineering (Becker et al., 2015). This draft addresses that challenge directly through an integrated approach to the operation and evolution of systems. Almost any attempt to articulate a theoretical foundation for IS (a TFIS) would need to cover that topic although other attempts might emphasize other topics and other viewpoints.
The proposed Theoretical Foundation for IS (TFIS) has three main goals:
1) Integration. Build outward from an integrated core. Do not accept the excuse that the IS field is not ready for a serious attempt at integration.
2) Usefulness. Contribute to describing, analyzing, designing, and evaluating systems, developing new tools and methods, and supporting empirical IS research.
3) Near-symmetry. Treat sociotechnical systems (with human participants) and totally automated systems as similarly as possible. Trends toward digitalization, automation, AI, and robotics imply benefits from that type of near-symmetry for understanding changes in the “division of labor.",,https://core.ac.uk/download/428348704.pdf,83502435,a proposed theoretical foundation for the information systems discipline  (version 1. 1),2021-01-01T08:00:00,USF Scholarship: a digital repository @ Gleeson Library | Geschke Center,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The last few years have seen a proliferation of principles for AI ethics. There is substantial overlap between different sets of principles, with widespread agreement that AI should be used for the common good, should not be used to harm people or undermine their rights, and should respect widely held values such as fairness, privacy, and autonomy. While articulating and agreeing on principles is important, it is only a start- ing point. Drawing on comparisons with the field of bioethics, we highlight some of the limitations of principles: in particular, they are often too broad and high-level to guide ethics in practice. We suggest that an important next step for the field of AI ethics is to focus on exploring the tensions that inevitably arise as we try to implement principles in practice. By explicitly recognising these tensions we can begin to make decisions about how they should be resolved in specific cases, and develop frameworks and guidelines for AI ethics that are rigorous and practically relevant. We discuss some different specific ways that tensions arise in AI ethics, and what processes might be needed to resolve them.Work supported by the Nuffield Foundation and Leverhulme Trus",10.17863/cam.37097,https://core.ac.uk/download/187716456.pdf,54536895,the role and limits of principles in ai ethics: towards a focus on tensions,2019-01-01T00:00:00,.,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper presents, as far as the authors are aware, a complete and extended new taxonomy of shape specification modeling techniques and a characterization of shape design systems, all based on the relationship of users’ knowledge to the modeling system they use to generate shapes. In-depth knowledge of this relationship is not usually revealed in the regular university training courses such as bachelor’s, master’s and continuing education. For this reason, we believe that it is necessary to modify the learning process, offering a more global vision of all the currently existing techniques and extending training in those related to algorithmic modeling techniques. We consider the latter to be the most powerful current techniques for modeling complex shapes that cannot be modeled with the usual techniques known to date. Therefore, the most complete training should include everything from the usual geometry to textual programming. This would take us a step further along the way to more powerful design environments. The proposed taxonomy could serve as a guideline to help improve the learning process of students and designers in a complex environment with increasingly powerful requirements and tools. The term “smart” is widely used nowadays, e.g. smart phones, smart cars, smart homes, smart cities... and similar terms such as “smart shape modeling”. Nowadays, the term smart is applied from a marketing point of view, whenever an innovation is used to solve a complex problem. This is the case for what is currently called smart shape modeling. However, in the future; this concept should mean a much better design environment than today. The smart future requires better trained and skilled engineers, architects, designers or technical students. This means that they must be prepared to be able to contribute to the creation of new knowledge, to the use of innovations to solve complex problems of form, and to the extraction of the relevant pieces of intelligence from the growing volume of knowledge and technologies accessible today. Our taxonomy is presented from the point of view of methods that are possibly furthest away from what is considered today as “intelligent shape modeling” to the limit of what is achievable today and which the authors call “Generic Shape Algorithm”. Finally, we discuss the characteristics that a shape modeling system must have to be truly “intelligent”: it must be “proactive” in applying innovative ideas to achieve a solution to a complex problem",10.1007/s12008-022-00872-7,https://core.ac.uk/download/521880824.pdf,131451141,a theoretical reflection on smart shape modeling,2022-01-01T00:00:00,'Springer Science and Business Media LLC',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This chapter proposed a novel design methodology called Value-Sensitive Design and its potential application to the field of artificial intelligence research and design. It discusses the imperatives in adopting a design philosophy that embeds values into the design of artificial agents at the early stages of AI development. Because of the high risk stakes in the unmitigated design of artificial agents, this chapter proposes that even though VSD may turn out to be a less-than-optimal design methodology, it currently provides a framework that has the potential to embed stakeholder values and incorporate current design methods. The reader should begin to take away the importance of a proactive design approach to intelligent agents",10.13140/rg.2.2.17162.77762,https://core.ac.uk/download/146502298.pdf,8864308,a value-sensitive design approach to intelligent agents,2018-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This book establishes the foundations needed to realize the ultimate goals for artificial intelligence, such as autonomy and trustworthiness. Aimed at scientists, researchers, technologists, practitioners, and students, it brings together contributions offering the basics, the challenges and the state-of-the-art on trusted autonomous systems in a single volume. The book is structured in three parts, with chapters written by eminent researchers and outstanding practitioners and users in the field. The first part covers foundational artificial intelligence technologies, while the second part covers philosophical, practical and technological perspectives on trust. Lastly, the third part presents advanced topics necessary to create future trusted autonomous systems. The book augments theory with real-world applications including cyber security, defence and space",10.1007/978-3-319-64816-3,https://core.ac.uk/download/478127285.pdf,128012596,foundations of trusted autonomy,2018-01-01T00:00:00,'Springer Science and Business Media LLC',"[{'title': None, 'identifiers': ['issn:2198-4182', '2198-4182']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The Artificial Intelligence (AI) for Public Health Practice Retreat was a hybrid event held in October 2022 in London, Ontario to achieve three main goals: 1) Identify both the goals of public health practitioners and the tasks that they undertake as part of their practice to achieve those goals that could be supported by AI, 2) Learn from existing examples and the experience of others about facilitators and barriers to AI for public health, and 3) Support new and strengthen existing connections between public health practitioners and AI researchers. The retreat included a keynote presentation, group brainstorming exercises, breakout group activities, case studies, and interspersed breaks for networking and reflection. There were 38 attendees from across Ontario, and a guest speaker from New York. Major themes that emerged from discussions included the need for greater attention to AI applications in public health given the potential benefits and enthusiasm; rigorous data collection, data quality, and data accessibility as a foundational factor that needs urgent attention; and the need for an equitable systems-thinking approach to AI amidst the breadth of public health functions, interventions, and population-based applications. Attendees expressed a desire for continued engagement and collaboration between public health practice and AI researchers",,https://core.ac.uk/download/571283485.pdf,145727630,"inaugural artificial intelligence for public health practice (ai4php) retreat: ontario, canada",2023-04-29T08:00:00,Scholarship@Western,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The advent of artificial intelligence has brought many changes in people\u27s lives, and because of the rise of artificial intelligence, the city has gradually become a smart city. Smart City, as defined in Wikipedia, is an urban area that uses different types of electronic data collection sensors to supply information which is used to manage assets and resources efficiently. It is evident that the city cannot function without water, electricity and air. Especially electricity, due to the development of technology and the internet, has been the most important origin of resource in the city. Under such resources, two important groups are generated: the sharing of people and the resources of electricity. People represents the grouping benefits, which made the sharing economy more rationalized and creative because of the internet platforms. As stated in Wikipedia, sharing is to fully utilize resources for more efficient use, so to raise up the overall efficiency of the resources. So as solar energy, a natural resource, has existed on the earth for a long time like the air. These will be the most important components in a smart city. However, with the current Internet technology platform, the artificial intelligence, AI, will be a tool under the system we are already familiar with. Artificial intelligence such as AI uses the knowledge that the machine obtains from the use of input data and information. It’s a way to let machine learn from the data first and then allows the machine to automatically calculate and judge the corresponding results. Such artificial intelligence is applied in the computing system of many industries, it reduces many possible errors, and relatively improves the efficiency of problem solving, and significantly increased the efficiency of obtaining new messages and information to users. Both supervised and unsupervised learning methods will be applied to the case study of this study. How to make the relationship between platform and consumer supervised, let AI artificial intelligence because supervised learning is only given some training samples of the machine, and inform the sample category, allowing AI judge automatically the conclusion of the samples, and accurately pass it to create information on the shared solar business platform. Consumer psychology is also the focus of this research. Investors’ transparency and simplicity in the application of goods, as well as the most important investment rewards and independency of consumers, will also be a discussion focus of this study. In this paper, the smart city of AI artificial intelligence allows the solar energy to create a business-style analysis of the economy, design, finds a platform model to establish Internet sharing, and achieve a large circulation and sharing of demanders and suppliers. This article uses the traditional field of goods, combined with the needs of multiple resources sharing and co-creation, combined to solve the existing information shortage and cross-domain strangeness. Utilizing the case study of solar energy company\u27s discussion method, the smart city solar energy will create a commercial business entity, so that people can participate and identify with such industry, and then find more business models to create and share, and the realization of smart cities as a sharing platform mechanism all people shall be involved",,https://core.ac.uk/download/301379102.pdf,17861140,ai city\u27s solar energy collaborative commerce and sharing economy,2018-12-06T08:00:00,AIS Electronic Library (AISeL),[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"It is said that Data and Information are the new oil. One, who handles the
data, handles the emerging future of the global economy. Complex algorithms and
intelligence-based filter programs are utilized to manage, store, handle and
maneuver vast amounts of data for the fulfillment of specific purposes. This
paper seeks to find the bridge between artificial intelligence and its impact
on the international policy implementation in the light of geopolitical
influence, global economy and the future of labor markets. We hypothesize that
the distortion in the labor markets caused by artificial intelligence can be
mitigated by a collaborative international foreign policy on the deployment of
AI in the industrial circles. We, in this paper, then proceed to propose a
disposition for the essentials of AI-based foreign policy and implementation,
while asking questions such as 'could AI become the real Invisible Hand
discussed by economists?'.Comment: This is the pre-print versio",10.47305/jlia2020113ob,https://core.ac.uk/download/333817724.pdf,86553330,"turbulence on the global economy influenced by artificial intelligence
  and foreign policy inefficiencies",2020-01-01T00:00:00,"Journal of Liberty and International Affairs, Institute for Research and European Studies - Bitola","[{'title': None, 'identifiers': ['1857-9760', 'issn:1857-9760']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The ‘real world of AI’ is not a fictional place or concept. There is a real world of AI that we should aspire towards, and that is within our reach. A world where the design of technology includes the practice of justice and on the enforcement of limits to power. Franklin’s work offers us a powerful lens for thinking about where we are today—and how we might create a more just and equitable world of technology tomorrow. This paper explores her framing of technology as a system, and her breakdown of the differences between holistic and prescriptive technologies, which give us useful tools for understanding our world, where technology is shaped by a small handful of global companies (e.g. AliBaba and Amazon) and imperial nations (e.g. China and the United States). Franklin’s thinking may also help us find our way towards a world where AI balances the interests of the people who develop tools (often tech companies), the people who wield them (each of us) and society (all of us)",10.17613/59pw-hy37,https://core.ac.uk/download/534870386.pdf,127934154,the real world of ai,2022-01-01T00:00:00,'Modern Language Association',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In this paper we present a novel method for a naive agent to detect novel
objects it encounters in an interaction. We train a reinforcement learning
policy on a stacking task given a known object type, and then observe the
results of the agent attempting to stack various other objects based on the
same trained policy. By extracting embedding vectors from a convolutional
neural net trained over the results of the aforementioned stacking play, we can
determine the similarity of a given object to known object types, and determine
if the given object is likely dissimilar enough to the known types to be
considered a novel class of object. We present the results of this method on
two datasets gathered using two different policies and demonstrate what
information the agent needs to extract from its environment to make these
novelty judgments",,http://arxiv.org/abs/2204.08107,121289997,"exploiting embodied simulation to detect novel object classes through
  interaction",2022-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Large probabilistic models are often shaped by a pool of known individuals (a
universe) and relations between them. Lifted inference algorithms handle sets
of known individuals for tractable inference. Universes may not always be
known, though, or may only described by assumptions such as ""small universes
are more likely"". Without a universe, inference is no longer possible for
lifted algorithms, losing their advantage of tractable inference. The aim of
this paper is to define a semantics for models with unknown universes decoupled
from a specific constraint language to enable lifted and thereby, tractable
inference.Comment: Also accepted at the 9th StarAI Workshop at AAAI-2",10.1007/978-3-030-35288-2_8,http://arxiv.org/abs/2001.02021,89601643,exploring unknown universes in probabilistic relational models,2020-01-07T00:00:00,'Springer Science and Business Media LLC',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Artificial Intelligence (AI) is a kind of intelligent behavior similar to human being which helps human being to participate in dangerous and complicated work directly. The effective application of computer network technology has changed people's production and life style, and technological innovation has paid more attention to intelligence and humanity, leading to that artificial intelligence has become a development trend. This paper analyzes the general situation of artificial intelligence and its application and future development in computer network technology, hoping to provide help for related work",10.18686/utc.v5i1.73,https://core.ac.uk/download/287261724.pdf,77911030,application analysis of artificial intelligence in computer network technology,2019-02-05T00:00:00,'Universe Scientific Publishing Pte. Ltd.',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In this paper I provide an exposition and critique of Johnson and Noorman’s (2014) three conceptualizations of the agential roles artificial systems can play. I argue that two of these conceptions are unproblematic: that of causally efficacious agency and “acting for” or surrogate agency. Their third conception, that of “autonomous agency,” however, is one I have reservations about. The authors point out that there are two ways in which the term “autonomy” can be used: there is, firstly, the engineering sense of the term, which simply refers to the ability of some system to act independently of substantive human control. Secondly, there is the moral sense of the term, which has traditionally grounded many notions of human mor-al responsibility. I argue that the continued usage of “autonomy” in discussions of artificial agency complicates matters unnecessarily. This occurs in two ways: firstly, the condition of autonomy, even in its engineering sense, fails to accurately describe the way “autonomous” systems are developed in practice. Secondly, the continued usage of autonomy in the moral sense introduces unnecessary meta-physical baggage form the free will debate into discussions about moral agency. In order to understand the debate surrounding autonomy, we would therefore first need to settle many seemingly intractable metaphysical questions regarding the existence of free will in human beings",,https://core.ac.uk/download/326247067.pdf,8870239,moral agents or mindless machines? a critical appraisal of agency in artificial systems,2019-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The purpose of this research is to design and build an expert system to diagnose the type of developmental disorder in children early using the certainty factor method. The method of data collection used in this study is observation, interviews, and library studies. The system was built with the Waterfall System Development Method. The stage of the Waterfall method is analysis, design, coding, and testing. This expert system is built using the PHP programming language and MySQL database. The result of this research was to successfully build an expert system to diagnose the type of developmental disorder in children early using the Certainty factor method to facilitate the user in diagnosing developmental disorders in the child quickly, efficiently, and without having to consult a pediatrician",10.47738/ijiis.v1i1.18,https://core.ac.uk/download/480731974.pdf,122949126,expert system for diagnosing early childhood developmental disorders with certainty factor method,2018-09-01T01:00:00,Bright Publisher,"[{'title': None, 'identifiers': ['issn:2579-7069', '2579-7069']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Prompt learning for vision-language models, e.g., CoOp, has shown great
success in adapting CLIP to different downstream tasks, making it a promising
solution for federated learning due to computational reasons. Existing prompt
learning techniques replace hand-crafted text prompts with learned vectors that
offer improvements on seen classes, but struggle to generalize to unseen
classes. Our work addresses this challenge by proposing Federated Text-driven
Prompt Generation (FedTPG), which learns a unified prompt generation network
across multiple remote clients in a scalable manner. The prompt generation
network is conditioned on task-related text input, thus is context-aware,
making it suitable to generalize for both seen and unseen classes. Our
comprehensive empirical evaluations on nine diverse image classification
datasets show that our method is superior to existing federated prompt learning
methods, that achieve overall better generalization on both seen and unseen
classes and is also generalizable to unseen datasets",,http://arxiv.org/abs/2310.06123,152034094,"text-driven prompt generation for vision-language models in federated
  learning",2023-10-09T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This article presents a research on innovative approaches in English language teaching through the application of Artificial Intelligence (AI). The aim is to address the issues found in traditional English language teaching methods by utilizing AI technology. The article begins by identifying the problems in traditional English language teaching and exploring the current applications of AI in education. Then, it specifically discusses the application of AI technology in English language teaching, such as interactive listening training, intelligent error correction and personalized post-class guidance, and cloud-based intelligent English translation teaching. Subsequently, a proposal is put forward to construct a new English language teaching system based on AI technology, including modules for engaging explanations, interactive English assignments, and creating scenarios for cross-cultural communication oral training. Lastly, an evaluation method for assessing the innovation of English language teaching models based on AI is introduced, which includes feedback and perceptions from both teachers and students, as well as an assessment of teaching outcomes. The research findings of this article can provide a more intelligent, personalized, and effective English language teaching approach, thus positively impacting the quality of English language teaching and enhancing students’ interest in learning",10.22158/fet.v6n4p106,https://core.ac.uk/download/599201938.pdf,153566362,research on the innovation of english teaching mode based on artificial intelligence,2023-12-06T00:00:00,SCHOLINK INC.,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The initial question related to this article is: how has art been assimilating the logical procedures of computational algorithms? Our hypothesis is that we are being trained by logical procedures that conform, inform, and form our thought, such as simulations, models, patterns, codes and set of codes, algorithms, devices, interfaces, and these are the core of what we call «Conformed Thought» (Laurentiz 2015,&nbsp;2017,&nbsp;2018&nbsp;and&nbsp;2019). It is important to highlight that saying a thought is «conformed» is not restricted to shapes, physical aspects, expressions of patterns, but is a set of socially defined and common habits or customs, determined by society, community, or group. Therefore,&nbsp;conformed thought&nbsp;causes significant changes and drive our thinking, language and, consequently, our behavior. The aim is to understand how the logic of the algorithms, especially of artificial intelligence, which are present in the conceptual and perceptual models of current works of art, can generate aesthetic dismemberment. The assumption is that an understanding of technological procedures increases the creative possibilities and expressive potential for art projects. This will be reflected in some way in the aesthetic experience, because, changing concepts and techniques, thinking and forms of action also change and, consequently, creative processes and aesthetic results. This is the result of a study that seeks to understand how these procedures affect sensory and cognitive systems, how our minds process this information and consequently how we interact in the world. Our point of view is that the artists have the critical role of not only applying these logical principles in their artworks, but also intervening in these processes in an unconforming way.
&nbsp;La pregunta inicial relacionada con este artículo es: ¿cómo el arte ha ido asimilando los procedimientos lógicos de los algoritmos computacionales? Nuestra hipótesis es que estamos siendo entrenados por procedimientos lógicos que conforman, informan y forman nuestro pensamiento, tales como simulaciones, modelos, patrones, códigos y conjuntos de códigos, algoritmos, dispositivos, interfaces, y estos son el núcleo de lo que llamamos de «pensamiento conformado» (Laurentiz 2015,&nbsp;2017,&nbsp;2018&nbsp;y&nbsp;2019). Es importante resaltar que al decir que un pensamiento está&nbsp;conformado&nbsp;no se limita a formas, aspectos físicos, expresiones de patrones, sino que es un conjunto de hábitos o costumbres comunes y socialmente definidos, determinados por la sociedad, comunidad o grupo. Por lo tanto, el&nbsp;pensamiento conformado&nbsp;provoca cambios significativos e impulsa nuestro pensamiento, lenguaje y, en consecuencia, nuestro comportamiento. El objetivo es comprender cómo la lógica de los algoritmos, especialmente de la inteligencia artificial, que están presentes en los modelos conceptuales y perceptuales de las obras de arte actuales, puede generar un desmembramiento estético. La premisa es que la comprensión de los procedimientos tecnológicos aumenta las posibilidades creativas y el potencial expresivo de los proyectos de arte. Esto se verá reflejado de alguna manera en la experiencia estética, porque, cambiando conceptos y técnicas, también cambian el pensamiento y las formas de acción y, en consecuencia, los procesos creativos y los resultados estéticos. Este es el resultado de un estudio que busca comprender cómo estos procedimientos afectan los sistemas sensoriales y cognitivos, cómo nuestra mente procesa esta información y consecuentemente interactuamos en el mundo. Nuestro punto de vista es que los artistas tienen el papel crítico no solo de aplicar estos principios lógicos en sus obras de arte, sino también de intervenir en estos procesos de manera disconforme",10.3989/arbor.2021.800005,https://core.ac.uk/download/478256235.pdf,122347145,arte en el contexto de los procedimientos de lógica algorítmica,2021-08-01T01:00:00,'Editorial CSIC',"[{'title': 'Arbor', 'identifiers': ['issn:1988-303X', 'issn:0210-1963', '0210-1963', '1988-303x']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"It is well known that arthropods are the most diverse and abundant eukaryotic organisms on the planet. Museum and research collections have huge insect accumulations from expeditions conducted over history that contain specimens of both temporal and spatial value, including hundreds of thousands of species. This biodiversity data is inaccessible to the research community, resulting in a vast amount of “dark data”. The primary objective of this study is to develop an artificial intelligence-driven system for specimen identification that greatly minimizes the time and expertise required to identify specimens in atypical environments. Successful development will have profound impacts on both ecology and biodiversity sciences as it will increase the resolution for ecological studies and allow us to work through the backlog of insect collections, unlocking tremendous amounts of biodiversity data. Development of the system will address multiple challenges in deep learning, including problems associated with limited training data and moving from known domains into unknown. The cutting-edge AI solutions will be a final component in a smart specimen identification system scalable in multiple platforms and across geographic region",,https://core.ac.uk/download/518077896.pdf,68989827,"artificial intelligence system for automatic imaging, quantification, and identification of arthropods in leaf litter and pitfall samples",2022-01-01T08:00:00,ScholarWorks@UARK,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper introduces the topic of Explainable Artificial Intelligence (XAI) and reports on the outcomes of an interdisciplinary workshop exploring it. It reflects on XAI through the frame and concerns of the recordkeeping profession. This paper takes a reflective approach. The origins of XAI are outlined as a way of exploring how it can be viewed and how it is currently taking shape. The workshop and its outcomes are briefly described and reflections on the process of investigating and taking part in conversations about XAI are offered. The article reinforces the value of undertaking interdisciplinary and exploratory conversations with others. It offers new perspectives on XAI and suggests ways in which recordkeeping can productively engage with it, as both a disruptive force on its thinking and a set of newly emerging record forms to be created and managed. The value of this paper comes from the way in which the introduction it provides will allow recordkeepers to gain a sense of what XAI is and the different ways in which they are both already engaging and can continue to engage with it",,https://core.ac.uk/download/323203284.pdf,149014601,working in contexts for which transparency is important: a recordkeeping view of explainable artificial intelligence (xai),2020-01-01T00:00:00,'Emerald',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"On the ability of technologies to capture and structure feelings and experiences that are active, in flux, and situated in the present.
Publication resulting from research workshop at CRASSH, University of Cambridge, organised in collaboration with CRASSH, University of Cambridge and transmediale festival for art and digital culture, Berlin",,https://core.ac.uk/download/287816510.pdf,36357929,a peer-reviewed newspaper about_ machine feeling,2019-01-01T00:00:00,'Aarhus University Library',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Building on Papert (1980)'s idea of children talking to computers, we propose
ChatLogo, a hybrid natural-programming language interface for agent-based
modeling and programming. We build upon previous efforts to scaffold ABM & P
learning and recent development in leveraging large language models (LLMs) to
support the learning of computational programming. ChatLogo aims to support
conversations with computers in a mix of natural and programming languages,
provide a more user-friendly interface for novice learners, and keep the
technical system from over-reliance on any single LLM. We introduced the main
elements of our design: an intelligent command center, and a conversational
interface to support creative expression. We discussed the presentation format
and future work. Responding to the challenges of supporting open-ended
constructionist learning of ABM & P and leveraging LLMs for educational
purposes, we contribute to the field by proposing the first constructionist
LLM-driven interface to support computational and complex systems thinking.Comment: Constructionism 2023 Conferenc",,http://arxiv.org/abs/2308.08102,145456286,"chatlogo: a large language model-driven hybrid natural-programming
  language interface for agent-based modeling and programming",2023-08-15T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Label smoothing -- using softened labels instead of hard ones -- is a widely
adopted regularization method for deep learning, showing diverse benefits such
as enhanced generalization and calibration. Its implications for preserving
model privacy, however, have remained unexplored. To fill this gap, we
investigate the impact of label smoothing on model inversion attacks (MIAs),
which aim to generate class-representative samples by exploiting the knowledge
encoded in a classifier, thereby inferring sensitive information about its
training data. Through extensive analyses, we uncover that traditional label
smoothing fosters MIAs, thereby increasing a model's privacy leakage. Even
more, we reveal that smoothing with negative factors counters this trend,
impeding the extraction of class-related information and leading to privacy
preservation, beating state-of-the-art defenses. This establishes a practical
and powerful novel way for enhancing model resilience against MIAs.Comment: 23 pages, 8 tables, 8 figure",,http://arxiv.org/abs/2310.06549,152034822,"be careful what you smooth for: label smoothing can be a privacy shield
  but also a catalyst for model inversion attacks",2023-10-10T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Extreme speech is a critical conceptual framework that aims to uncover vitriolic online cultures through comparative and ethnographic excavations of digital practices. It is not one more new definition or a term replaceable with extremist speech. Rather, it is a conceptual framework developed to foreground historical awareness, critical deconstruction of existing categories, and a grounded understanding of evolving practices in online communities, in ways to holistically analyze the contours and consequences of contemporary digital hate cultures. This framework suggests that the close contextualization of proximate contexts - of media affordances in use or situated speech cultures - should accompany deep contextualization, which accounts for grave historical continuities and technopolitical formations unfolding on a planetary scale. Through such elaborate forays into everyday practices and deeper histories, extreme speech theory proposes to nuance normative and regulatory efforts to classify and isolate hate speech and disinformation",10.48541/dcr.v12.14,https://core.ac.uk/download/565923753.pdf,145047768,extreme speech,2023-01-01T00:00:00,Berlin,"[{'title': None, 'identifiers': ['2198-7610', 'issn:2198-7610']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper investigates how intuitions about scientific discovery using artificial intelligence (AI) can be used to improve our understanding of scientific discovery more generally. Traditional accounts of discovery have been agent-centred: they place emphasis on identifying a specific agent who is responsible for conducting all, or at least the important part, of a discovery process. We argue that these accounts experience difficulties capturing scientific discovery involving AI and that similar issues arise for human discovery. We propose an alternative, collective-centred view as superior for understanding discovery, with and without AI. This view maintains that discovery is performed by a collective of agents and entities, each making contributions that differ in significance and character, and that attributing credit for discovery depends on various finer-grained properties of the contributions made. Detailing its conceptual resources, we argue that this view is considerably more compelling than its agent-centred alternative. Considering and responding to several theoretical and practical challenges, we point to concrete avenues for further developing the view we propose",10.15488/13596,https://core.ac.uk/download/568237453.pdf,145343838,decentring the discoverer: how ai helps us rethink scientific discovery,2022-01-01T00:00:00,Dordrecht [u.a.] : Springer Science + Business Media B.V,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Generative commonsense reasoning which aims to empower machines to generate
sentences with the capacity of reasoning over a set of concepts is a critical
bottleneck for text generation. Even the state-of-the-art pre-trained language
generation models struggle at this task and often produce implausible and
anomalous sentences. One reason is that they rarely consider incorporating the
knowledge graph which can provide rich relational information among the
commonsense concepts. To promote the ability of commonsense reasoning for text
generation, we propose a novel knowledge graph augmented pre-trained language
generation model KG-BART, which encompasses the complex relations of concepts
through the knowledge graph and produces more logical and natural sentences as
output. Moreover, KG-BART can leverage the graph attention to aggregate the
rich concept semantics that enhances the model generalization on unseen concept
sets. Experiments on benchmark CommonGen dataset verify the effectiveness of
our proposed approach by comparing with several strong pre-trained language
generation models, particularly KG-BART outperforms BART by 5.80, 4.60, in
terms of BLEU-3, 4. Moreover, we also show that the generated context by our
model can work as background scenarios to benefit downstream commonsense QA
tasks.Comment: 10 pages, 7 figures, Appear in AAAI 202",10.1609/aaai.v35i7.16796,http://arxiv.org/abs/2009.12677,89631880,"kg-bart: knowledge graph-augmented bart for generative commonsense
  reasoning",2021-01-21T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Technologic evolutions of the last two decades, such as the development of the &nbsp;internet, had a strong disruptive effect to the society and the economy. However, because of the flexible concepts of the civil law codifications a disruptive effect in the private law until now did not exist. Especially the legal consequences&nbsp; of the internet were integrated into the private law without bigger categorial or structural changes. This applies equally to most of the cases of the use of artificial intelligence (AI) in recent times. With more advanced development of AI-systems, though, it may not be possible anymore to apply the traditional terms of the private law to the use of AI without leaving the constitutional law background of the private law. This article discusses the impact of the use of a future advanced independent AI on the concept of the private autonomy in the contract law. Furthermore, it gives an overview on the new legislative approach of a human centric use of AI in the European Union.&nbsp",10.25299/uirlrev.2021.vol5(1).6890,https://core.ac.uk/download/478487594.pdf,122398239,machine acting and contract law – the disruptive factor of artificial intelligence for the freedom concept of the private law,2021-04-25T01:00:00,'UIR Press',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper focuses on the research field of machine ethics and how it relates to a technological singularity—a hypothesized, futuristic event where artificial machines will have greater-than-human-level intelligence. One problem related to the singularity centers on the issue of whether human values and norms would survive such an event. To somehow ensure this, a number of artificial intelligence researchers have opted to focus on the development of artificial moral agents, which refers to machines capable of moral reasoning, judgment, and decision-making. To date, different frameworks on how to arrive at these agents have been put forward. However, there seems to be no hard consensus as to which framework would likely yield a positive result. With the body of work that they have contributed in the study of moral agency, philosophers may contribute to the growing literature on artificial moral agency. While doing so, they could also think about how the said concept could affect other important philosophical concepts",,https://core.ac.uk/download/186329952.pdf,8857742,a case for machine ethics in modeling human-level intelligent agents,2018-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Learning from free-text human feedback is essential for dialog systems, but
annotated data is scarce and usually covers only a small fraction of error
types known in conversational AI. Instead of collecting and annotating new
datasets from scratch, recent advances in synthetic dialog generation could be
used to augment existing dialog datasets with the necessary annotations.
However, to assess the feasibility of such an effort, it is important to know
the types and frequency of free-text human feedback included in these datasets.
In this work, we investigate this question for a variety of commonly used
dialog datasets, including MultiWoZ, SGD, BABI, PersonaChat,
Wizards-of-Wikipedia, and the human-bot split of the Self-Feeding Chatbot.
Using our observations, we derive new taxonomies for the annotation of
free-text human feedback in dialogs and investigate the impact of including
such data in response generation for three SOTA language generation models,
including GPT-2, LLAMA, and Flan-T5. Our findings provide new insights into the
composition of the datasets examined, including error types, user response
types, and the relations between them.Comment: Accepted to be presented at EMNLP 202",,http://arxiv.org/abs/2310.15758,152482931,"learning from free-text human feedback -- collect new datasets or extend
  existing ones?",2023-10-24T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Explainable AI was born as a pathway to allow humans to explore and understand the inner working of complex systems. Though, establishing what is an explanation and objectively evaluating explainability, are not trivial tasks. With this paper, we present a new model-agnostic metric to measure the Degree of Explainability of (correct) information in an objective way, exploiting a specific theoretical model from Ordinary Language Philosophy called the Achinstein’s Theory of Explanations, implemented with an algorithm relying on deep language models for knowledge graph extraction and information retrieval. In order to understand whether this metric is actually behaving as explainability is expected to, we have devised an experiment on two realistic Explainable AI-based systems for healthcare and finance, using famous AI technology including Artificial Neural Networks and TreeSHAP. The results we obtained suggest that our proposed metric for measuring the Degree of Explainability is robust on several scenario",10.1109/fuzz-ieee55066.2022.9882574,https://core.ac.uk/download/564349374.pdf,144841047,how to quantify the degree of explainability: experiments and practical implications,2022-01-01T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Artificial Intelligence (AI) is transforming the insurance industry and there are many examples in the business press and at industry conferences. However, there is a paucity of detailed conceptual analysis and evaluation of AI technology that places AI in a strategic context and considers how different AI applications fit together and form a coherent picture. In this paper, a detailed case study of BGL group, a leading European insurance firm, is presented. A general business process model of insurance companies is used to structure the analysis. Five AI applications are described using an insurance firm-customer data flow diagram, which illustrates the marketing impact of AI technology and shows the nature of the business value creation process. The results are generalized into an AI customer lifecycle model, which has broad applicability to digital transformation projects. The likely future direction of AI in insurance is outlined and further research opportunities are identified",10.24251/hicss.2022.553,https://core.ac.uk/download/489426047.pdf,19014383,artificial intelligence (ai) and digital transformation in the insurance market: a case study analysis of bgl group,2022-01-03T08:00:00,'HICSS Conference Office',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Object Detection (OD) in surveillance video is the way of automatically detecting and tracking object classes of interest within the video recording. It includes the application of a Computer Vision (CV) technique to analyze the video frame and identify the classes of objects or the presence of specific objects. Various OD techniques are used to find objects within the footage video. This algorithm analyzes the visual feature of the frames and employs Machine Learning (ML) approaches namely Deep Neural Network (DNN), to detect and track objects. It is worth mentioning that the accuracy and performance of OD in surveillance video depends on factors including the choice of algorithms and models, the availability of labelled training data, and the quality of the video frame for the specific object of interest. This study introduces a new modeling of Intelligent Object Recognition and Classification by employing Aquila Optimizer with Deep Learning (IODC-AODL) approach in Surveillance Video. The goal of the IODC-AODL technique is to integrate the DL model with the hyperparameter tuning process for object detection and classification. In the proposed IODC-AODL approach, a Faster RCNN method is enforced for the process of OD. Next, Long Short-Term Memory (LSTM) networking approach is implemented for the object classification process. At last, the AO approach is enforced for the optimum hyperparameter tuning of the LSTM network and it assists in improving the classifier rate. A widespread simulation sets are performed to exhibit the superior performance of the IODC-AODL approach. The experimental result analysis portrayed the supremacy of the IODC-AODL algorithm over other models",,https://core.ac.uk/download/591405223.pdf,152503926,modelling of intelligent object detection and classification using aquila optimizer with deep learning on surveillance videos,2023-11-02T00:00:00,Auricle Global Society of Education and Research,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Analyzing natural language-based Customer Satisfaction (CS) is a tedious process. This issue is practically true if one is to manually categorize large datasets. Fortunately, the advent of supervised machine learning techniques has paved the way toward the design of efficient categorization systems used for CS. This paper presents the feasibility of designing a text categorization model using two popular and robust algorithms â€“ the Support Vector Machine (SVM) and Long Short-Term Memory (LSTM) Neural Network, in order to automatically categorize complaints, suggestions, feedbacks, and commendations. The study found that, in terms of training accuracy, SVM has best rating of 98.63% while LSTM has best rating of 99.32%. Such results mean that both SVM and LSTM algorithms are at par with each other in terms of training accuracy, but SVM is significantly faster than LSTM by approximately 35.47s. The training performance results of both algorithms are attributed on the limitations of the dataset size, high-dimensionality of both English and Tagalog languages, and applicability of the feature engineering techniques used. Interestingly, based on the results of actual implementation, both algorithms are found to be 100% effective in accurately predicting the correct CS categories. Hence, the extent of preference between the two algorithms boils down on the available dataset and the skill in optimizing these algorithms through feature engineering techniques and in implementing them toward actual text categorization applications",,https://core.ac.uk/download/480425408.pdf,10998167,categorizing natural language-based customer satisfaction: an implementation method using support vector machine and long short-term memory neural network,2021-04-08T00:00:00,'Penerbit UTHM',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Human workers are envisioned to work alongside robots and other intelligent factory modules, and fulfill supervision tasks in future smart factories. Technological developments, during the last few years, in the field of smart factory automation have introduced the concept of cyber-physical systems, which further expanded to cyber-physical production systems. In this context, the role of collaborative robots is significant and depends largely on the advanced capabilities of collision detection, impedance control, and learning new tasks based on artificial intelligence. The system components, collaborative robots, and humans need to communicate for collective decision-making. This requires processing of shared information keeping in consideration the available knowledge, reasoning, and flexible systems that are resilient to the real-time dynamic changes on the industry floor as well as within the communication and computer network infrastructure. This article presents an ontology-based approach to solve industrial scenarios for safety applications in cyber-physical production systems. A case study of an industrial scenario is presented to validate the approach in which visual cues are used to detect and react to dynamic changes in real time. Multiple scenarios are tested for simultaneous detection and prioritization to enhance the learning surface of the intelligent production system with the goal to automate safety-based decisions",10.1177/1687814019897228,https://core.ac.uk/download/286352696.pdf,7800853,exploiting visual cues for safe and flexible cyber-physical production systems,2019-12-01T00:00:00,'SAGE Publications',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Introduction: The scientific publishing landscape is expanding rapidly,
creating challenges for researchers to stay up-to-date with the evolution of
the literature. Natural Language Processing (NLP) has emerged as a potent
approach to automating knowledge extraction from this vast amount of
publications and preprints. Tasks such as Named-Entity Recognition (NER) and
Named-Entity Linking (NEL), in conjunction with context-dependent semantic
interpretation, offer promising and complementary approaches to extracting
structured information and revealing key concepts.
  Results: We present the SourceData-NLP dataset produced through the routine
curation of papers during the publication process. A unique feature of this
dataset is its emphasis on the annotation of bioentities in figure legends. We
annotate eight classes of biomedical entities (small molecules, gene products,
subcellular components, cell lines, cell types, tissues, organisms, and
diseases), their role in the experimental design, and the nature of the
experimental method as an additional class. SourceData-NLP contains more than
620,000 annotated biomedical entities, curated from 18,689 figures in 3,223
papers in molecular and cell biology. We illustrate the dataset's usefulness by
assessing BioLinkBERT and PubmedBERT, two transformers-based models, fine-tuned
on the SourceData-NLP dataset for NER. We also introduce a novel
context-dependent semantic task that infers whether an entity is the target of
a controlled intervention or the object of measurement.
  Conclusions: SourceData-NLP's scale highlights the value of integrating
curation into publishing. Models trained with SourceData-NLP will furthermore
enable the development of tools able to extract causal hypotheses from the
literature and assemble them into knowledge graphs",,http://arxiv.org/abs/2310.20440,152502772,"the sourcedata-nlp dataset: integrating curation into scientific
  publishing for training large language models",2023-10-31T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Christopher Alexander was often characterized - and sometimes seemed to characterize himself - as ""sui generis,"" a radical and perhaps even eccentric thinker on architecture, technology, culture, and nature. That perception in turn has led many to dismiss Alexander's work as too idiosyncratic to be operationalized in the pragmatic world of planning and building. Here we show, however, that Alexander's core ideas have strong parallels in contemporary network science, mathematics, physics, and philosophy, and in the pragmatic world of technological design (including computer software). We highlight a remaining gap in translating Alexander's work into practical tools and strategies for implementation - a gap that is tantalizingly near to being bridged",10.17645/up.v8i3.6688,https://core.ac.uk/download/590381068.pdf,149596345,"patterns of growth: operationalizing alexander's ""web way of thinking""",2023-01-01T00:00:00,PRT,"[{'title': 'Urban Planning', 'identifiers': ['issn:2183-7635', '2183-7635']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper presents a substantial extension of our work published at ICLR.
Our ICLR work advocated for enhancing transferability in adversarial examples
by incorporating a Bayesian formulation into model parameters, which
effectively emulates the ensemble of infinitely many deep neural networks,
while, in this paper, we introduce a novel extension by incorporating the
Bayesian formulation into the model input as well, enabling the joint
diversification of both the model input and model parameters. Our empirical
findings demonstrate that: 1) the combination of Bayesian formulations for both
the model input and model parameters yields significant improvements in
transferability; 2) by introducing advanced approximations of the posterior
distribution over the model input, adversarial transferability achieves further
enhancement, surpassing all state-of-the-arts when attacking without model
fine-tuning. Moreover, we propose a principled approach to fine-tune model
parameters in such an extended Bayesian formulation. The derived optimization
objective inherently encourages flat minima in the parameter space and input
space. Extensive experiments demonstrate that our method achieves a new
state-of-the-art on transfer-based attacks, improving the average success rate
on ImageNet and CIFAR-10 by 19.14% and 2.08%, respectively, when comparing with
our ICLR basic Bayesian method. We will make our code publicly available",,http://arxiv.org/abs/2307.11334,144856237,improving transferability of adversarial examples via bayesian attacks,2023-07-20T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Just as humans can draw conclusions responsibly or irresponsibly, so too can computers. Machine learning systems that have been trained on data sets that include irresponsible judgments are likely to yield irresponsible predictions as outputs. In this paper I focus on a particular kind of inference a computer system might make: identification of the intentions with which a person acted on the basis of photographic evidence. Such inferences are liable to be morally objectionable, because of a way in which they are presumptuous. After elaborating this moral concern, I explore the possibility that carefully procuring the training data for image recognition systems could ensure that the systems avoid the problem. The lesson of this paper extends beyond just the particular case of image recognition systems and the challenge of responsibly identifying a person’s intentions. Reflection on this particular case demonstrates the importance (as well as the difficulty) of evaluating machine learning systems and their training data from the standpoint of moral considerations that are not encompassed by ordinary assessments of predictive accuracy",10.1007/978-3-030-01800-9_14,https://core.ac.uk/download/199234979.pdf,8855731,machine learning and irresponsible inference: morally assessing the training data for image recognition systems,2019-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The 43rd UID conference, held in Genova, takes up the theme of ‘Dialogues’ as practice and debate on many fundamental topics in our social life, especially in these complex and not yet resolved times. The city of Genova offers the opportunity to ponder on the value of comparison and on the possibilities for the community, naturally focused on the aspects that concern us, as professors, researchers, disseminators of knowledge, or on all the possibile meanings of the discipline of representation and its dialogue with ‘others’, which we have broadly catalogued in three macro areas: History, Semiotics, Science / Technology. Therefore, “dialogue” as a profitable exchange based on a common language, without which it is impossible to comprehend and understand one another; and the graphic sign that connotes the conference is the precise transcription of this concept: the title ‘translated’ into signs, derived from the visual alphabet designed for the visual identity of the UID since 2017. There are many topics which refer to three macro sessions: - Witnessing (signs and history) - Communicating (signs and semiotics) - Experimenting (signs and sciences) Thanks to the different points of view, an exceptional resource of our disciplinary area, we want to try to outline the prevailing theoretical-operational synergies, the collaborative lines of an instrumental nature, the recent updates of the repertoires of images that attest and nourish the relations among representation, history, semiotics, sciences",10.3280/oa-832-c160,https://core.ac.uk/download/552147576.pdf,138850350,chapter strumenti vpl per la scomposizione geometrico-semantica di figure piane complesse,2022-12-09T16:43:42,'Franco Angeli',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Building machines that can replicate human thinking and behavior has fascinated people for hundreds of years. Stories about robots date from ancient history through da Vinci to the present. Whether designed to save labor or lives, to provide companionship or protection, loyal, capable, productive machines are a dream of humanity.
The modern manifestation of this interest in using human-like technology to advance social interests is artificial intelligence (AI). This is a paper about what that interest in AI means and how it might develop in the world of national security.
This abstract has been adapted from the author\u27s introduction",,https://scholarship.law.wm.edu/cgi/viewcontent.cgi?article=2001&amp;context=wmborj,130798131,"if you think ai won\u27t eclipse humanity, you\u27re probably just a human",2021-12-01T08:00:00,William & Mary Law School Scholarship Repository,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Graphics processing units (GPUs) are widely used in many high-performance
computing (HPC) applications such as imaging/video processing and training
deep-learning models in artificial intelligence. GPUs installed in HPC systems
are often heavily used, and GPU failures occur during HPC system operations.
Thus, the reliability of GPUs is of interest for the overall reliability of HPC
systems. The Cray XK7 Titan supercomputer was one of the top ten supercomputers
in the world. The failure event times of more than 30,000 GPUs in Titan were
recorded and previous data analysis suggested that the failure time of a GPU
may be affected by the GPU's connectivity location inside the supercomputer
among other factors. In this paper, we conduct in-depth statistical modeling of
GPU failure times to study the effect of location on GPU failures under
competing risks with covariates and spatially correlated random effects. In
particular, two major failure types of GPUs in Titan are considered. The
connectivity locations of cabinets are modeled as spatially correlated random
effects, and the positions of GPUs inside each cabinet are treated as
covariates. A Bayesian framework is used for statistical inference. We also
compare different methods of estimation such as the maximum likelihood, which
is implemented via an expectation-maximization algorithm. Our results provide
interesting insights into GPU failures in HPC systems.Comment: 45 pages, 25 figure",,http://arxiv.org/abs/2303.16369,141819324,"a spatially correlated competing risks time-to-event model for
  supercomputer gpu failure data",2023-03-28T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"As deep neural networks (DNNs) are being applied to a wide range of edge
intelligent applications, it is critical for edge inference platforms to have
both high-throughput and low-latency at the same time. Such edge platforms with
multiple DNN models pose new challenges for scheduler designs. First, each
request may have different service level objectives (SLOs) to improve quality
of service (QoS). Second, the edge platforms should be able to efficiently
schedule multiple heterogeneous DNN models so that system utilization can be
improved. To meet these two goals, this paper proposes BCEdge, a novel
learning-based scheduling framework that takes adaptive batching and concurrent
execution of DNN inference services on edge platforms. We define a utility
function to evaluate the trade-off between throughput and latency. The
scheduler in BCEdge leverages maximum entropy-based deep reinforcement learning
(DRL) to maximize utility by 1) co-optimizing batch size and 2) the number of
concurrent models automatically. Our prototype implemented on different edge
platforms shows that the proposed BCEdge enhances utility by up to 37.6% on
average, compared to state-of-the-art solutions, while satisfying SLOs",,http://arxiv.org/abs/2305.01519,142718427,"bcedge: slo-aware dnn inference services with adaptive batching on edge
  platforms",2023-04-30T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"For the education industry, Chat GPT is predicted to change the way of teaching and learning. Adapting to Chat GPT will be a challenge for teaching, but it can also be an opportunity for universities to improve the education and teaching of political theory subjects. The article analyzes and clarifies the basic content of transforming political theory education methods under the impact of ChatGPT in Vietnam today. The results show that political theory education plays an important role in ideological orientation and personality formation for future generations in the context of innovation and development. With the development of technology, ChatGPT can be considered as an educational virtual assistant by helping learners quickly look up lessons and learning materials related to the topic of learning political theory subjects. In addition, the article has also pointed out and analyzed issues that need specific concern about changing teaching methods of political theory subjects before the impact of ChatGPT, related to: on the part of lecturers; change the way it is tested and evaluated; towards students. The limitation of this study is that it has not shown and analyzed solutions to improve the transformation of educational methods of political theory subjects before the impact of ChatGPT in Vietnam today.Para a indústria da educação, prevê-se que o Chat GPT mude a forma de ensinar e aprender. Adaptar-se ao Chat GPT será um desafio para o ensino, mas também pode ser uma oportunidade para as universidades melhorarem o ensino e o ensino das disciplinas de teoria política. O artigo analisa e esclarece o conteúdo básico da transformação dos métodos de educação em teoria política sob o impacto do ChatGPT no Vietnã hoje. Os resultados mostram que a educação em teoria política desempenha um papel importante na orientação ideológica e na formação da personalidade das gerações futuras no contexto da inovação e do desenvolvimento. Com o desenvolvimento da tecnologia, o ChatGPT pode ser considerado um assistente virtual educacional, ajudando os alunos a procurar rapidamente lições e materiais didáticos relacionados ao tópico de aprendizagem de assuntos de teoria política. Além disso, o artigo também apontou e analisou questões que precisam de atenção específica sobre a mudança de métodos de ensino de disciplinas de teoria política antes do impacto do ChatGPT, relacionadas a: por parte dos palestrantes; mudar a forma como é testado e avaliado; em relação aos alunos. A limitação deste estudo é que ele não mostrou e analisou soluções para melhorar a transformação dos métodos educacionais de disciplinas de teoria política antes do impacto do ChatGPT no Vietnã hoje",,https://core.ac.uk/download/578387686.pdf,148390111,transformando métodos educacionais de teoria política antes do impacto do chatgpt no vietnã hoje,2023-07-17T01:00:00,'Centro Universitario La Salle - UNILASALLE',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Rapid development of digital technology has changed the skills required in the job. Universities are, without question, making attempts to change in facing the challenges in the era of industrial revolution 4.0. In the first part of this paper, the rapid changing of the technology, highlighting the rapid change in industry and education, is discussed along with the exponential growth of innovations. The Presence of Artificial Intelligence that has changed jobs and skills required in the industries and other areas are addressed in the second part. The last section of this paper, some tips on how to face the rapid changes of technology and how to continue learning beyond the classroom wall are discussed",,https://core.ac.uk/download/322573891.pdf,85666661,technology empowered students “prepare yourself for interconnected world”,2019-07-26T01:00:00,PROSIDING SEMINAR NASIONAL PROGRAM PASCASARJANA UNIVERSITAS PGRI PALEMBANG,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Our paradigm for the use of artificial agents to teach requires among other things that they persist through time in their interaction with human students, in such a way that they “teleport” or “migrate” from an embodiment at one time t to a different embodiment at later time t\u27. In this short paper, we report on initial steps toward the formalization of such teleportation, in order to enable an overseeing AI system to establish, mechanically, and verifiably, that the human students in question will likely believe that the very same artificial agent has persisted across such times despite the different embodiments. The system achieves this by demonstrating to the students that different embodiments share one or more privileged beliefs that only one single agent can possess",,https://core.ac.uk/download/234622161.pdf,132563151,toward formalizing teleportation of pedagogical artificial agents,2019-01-04T19:00:37,Montclair State University Digital Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This article connects the concepts and phenomena of Design AI, AI in creative
industries and AIs capacity for creativity. It links Design AI to UX design and
UX designer discourse. Its vagueness and the prominence of UX designers as
speakers and writers in the spectacle of cultural AI discourse. The article
then, draws comparisons between the Theatre of the Absurd and the UX designer
performances of design AI. It additionally sheds light on ToA and the human
condition in terms of existentialism, present within the practice of engaging
in design that intends to link human experience to technological system logic.
This is a theoretical article that utilises examples from UX events published
on Youtube, as well as UX designer blogs, in order to illustrate the mechanics
of the ToA present within contemporary AI and UX designer discourse.Comment: 14 pages, 6 figures, Nordic network for research on communicative
  product design (Nordcode) seminar 201",,http://arxiv.org/abs/2304.10878,142491410,"ai design, design ai, human-centred ai and the theatre of the absurd the
  language, life and times of a ux designer",2023-04-21T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Mobile communications have been undergoing a generational change every ten
years. Whilst we are just beginning to roll out 5G networks, significant
efforts are planned to standardize 6G that is expected to be commercially
introduced by 2030. This paper looks at the use cases for 6G and their impact
on the network architecture to meet the anticipated performance requirements.
The new architecture is based on integrating various network functions in
virtual cloud environments, leveraging the advancement of artificial
intelligence in all domains, integrating different sub-networks constituting
the 6G system, and on enhanced means of exposing data and services to third
parties.Comment: 7 pages, 5 figures, one tabl",,http://arxiv.org/abs/2210.03286,132121419,perspectives on a 6g architecture,2022-10-06T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Group decision-making is strengthened by the varied knowledge and perspectives that each member brings, yet teams often fail to capitalize on their diversity. This paper describes how Swarm AI, a novel collaborative intelligence technology modeled on the decision-making process of honey bee swarms, enables networked human groups to more effectively leverage their combined insights. Through an empirical study conducted on 60 small teams, each of 3 to 6 members, we demonstrate the capacity of Swarm AI to significantly amplify the collective intelligence of human groups. A well-known testing instrument—the Reading the Mind in the Eyes (RME) test —was used to measure the social intelligence of each team—a key indicator of collective intelligence. The study compares the RME performance of (i) individuals, (ii) teams working by majority vote, and (iii) teams using an interactive software platform that employs Swarm AI technology",,https://core.ac.uk/download/479135749.pdf,18956964,amplifying the collective intelligence of teams with swarm ai,2019-06-01T08:00:00,DigitalCommons@CalPoly,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The purpose of this paper is to identify the implications of ethics in the evolution of technology. This article aims to define and analyze concepts such as: Big Data, Artificial Intelligence and Bioinformatics. Also, this article presents the applicability of Artificial Intelligence and discover the future trend of jobs in the coming years, the importance of adapting to changes and learning more skills that help to support future jobs",,https://core.ac.uk/download/329082400.pdf,87694038,evolution and ethics of digital technology in marketing,2020-08-17T01:00:00,"Agora University of Oradea, Romania",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We present rectified flow, a surprisingly simple approach to learning
(neural) ordinary differential equation (ODE) models to transport between two
empirically observed distributions \pi_0 and \pi_1, hence providing a unified
solution to generative modeling and domain transfer, among various other tasks
involving distribution transport. The idea of rectified flow is to learn the
ODE to follow the straight paths connecting the points drawn from \pi_0 and
\pi_1 as much as possible. This is achieved by solving a straightforward
nonlinear least squares optimization problem, which can be easily scaled to
large models without introducing extra parameters beyond standard supervised
learning. The straight paths are special and preferred because they are the
shortest paths between two points, and can be simulated exactly without time
discretization and hence yield computationally efficient models. We show that
the procedure of learning a rectified flow from data, called rectification,
turns an arbitrary coupling of \pi_0 and \pi_1 to a new deterministic coupling
with provably non-increasing convex transport costs. In addition, recursively
applying rectification allows us to obtain a sequence of flows with
increasingly straight paths, which can be simulated accurately with coarse time
discretization in the inference phase. In empirical studies, we show that
rectified flow performs superbly on image generation, image-to-image
translation, and domain adaptation. In particular, on image generation and
translation, our method yields nearly straight flows that give high quality
results even with a single Euler discretization step",,http://arxiv.org/abs/2209.03003,128646074,"flow straight and fast: learning to generate and transfer data with
  rectified flow",2022-09-07T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Recent years have brought about a renewed interest in commonsense
representation and reasoning in the field of natural language understanding.
The development of new commonsense knowledge graphs (CSKG) has been central to
these advances as their diverse facts can be used and referenced by machine
learning models for tackling new and challenging tasks. At the same time, there
remain questions about the quality and coverage of these resources due to the
massive scale required to comprehensively encompass general commonsense
knowledge.
  In this work, we posit that manually constructed CSKGs will never achieve the
coverage necessary to be applicable in all situations encountered by NLP
agents. Therefore, we propose a new evaluation framework for testing the
utility of KGs based on how effectively implicit knowledge representations can
be learned from them.
  With this new goal, we propose ATOMIC 2020, a new CSKG of general-purpose
commonsense knowledge containing knowledge that is not readily available in
pretrained language models. We evaluate its properties in comparison with other
leading CSKGs, performing the first large-scale pairwise study of commonsense
knowledge resources. Next, we show that ATOMIC 2020 is better suited for
training knowledge models that can generate accurate, representative knowledge
for new, unseen entities and events. Finally, through human evaluation, we show
that the few-shot performance of GPT-3 (175B parameters), while impressive,
remains ~12 absolute points lower than a BART-based knowledge model trained on
ATOMIC 2020 despite using over 430x fewer parameters",10.1609/aaai.v35i7.16792,http://arxiv.org/abs/2010.05953,91147025,comet-atomic 2020: on symbolic and neural commonsense knowledge graphs,2021-05-18T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Machine learning (ML) models for molecules and materials commonly rely on a
decomposition of the global target quantity into local, atom-centered
contributions. This approach is convenient from a computational perspective,
enabling large-scale ML-driven simulations with a linear-scaling cost, and also
allow for the identification and post-hoc interpretation of contributions from
individual chemical environments and motifs to complicated macroscopic
properties. However, even though there exist practical justifications for these
decompositions, only the global quantity is rigorously defined, and thus it is
unclear to what extent the atomistic terms predicted by the model can be
trusted. Here, we introduce a quantitative metric, which we call the local
prediction rigidity (LPR), that allows one to assess how robust the locally
decomposed predictions of ML models are. We investigate the dependence of LPR
on the aspects of model training, particularly the composition of training
dataset, for a range of different problems from simple toy models to real
chemical systems. We present strategies to systematically enhance the LPR,
which can be used to improve the robustness, interpretability, and
transferability of atomistic ML models",,http://arxiv.org/abs/2306.15638,143786842,robustness of local predictions in atomistic machine learning models,2023-06-27T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"A generative adversarial learning (GAL) algorithm is presented to overcome the manipulations that take place in adversarial data and to result in a secured convolutional neural network (CNN). The main objective of the generative algorithm is to make some changes to initial data with positive and negative class labels in testing, hence the CNN results in misclassified data. An adversarial algorithm is used to manipulate the input data that represents the boundaries of learner’s decision-making process. The algorithm generates adversarial modifications to the test dataset using a multiplayer stochastic game approach, without learning how to manipulate the data during training. Then the manipulated data is passed through a CNN for evaluation. The multi-player game consists of an interaction between adversaries which generates manipulations and retrains the model by the learner. The Nash equilibrium game theory (NEGT) is applied to Canadian Institute for Advance Research (CIFAR) dataset. This was done to produce a secure CNN output that is more robust to adversarial data manipulations. The experimental results show that proposed NEGT-GAL achieved a grater mean value of 7.92 and takes less wall clock time of 25,243 sec. Therefore, the proposed NEGT-GAL outperforms the compared existing methods and achieves greater performance",10.11591/ijece.v13i6.pp6351-6360,https://core.ac.uk/download/588487854.pdf,150583340,generative adversarial deep learning in images using nash equilibrium game theory,2023-12-01T00:00:00,Institute of Advanced Engineering and Science,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Industry 4.0 vision and associated technologies are rapidly adopted in several industrial sectors to gain the benefits of creating smart cyber-physical systems and operations. Some sectors, e.g. manufacturing, oil and gas, offshore wind energy, have progressed in developing digitization strategies, executing pilot projects and progressing toward mature implementation of industry 4.0 vision. Offshore Oil and Gas industry highly believes in the potential industrial and societal impacts of digital transformation, due to the need for stochastic and remote operations. Azerbaijan as one of the countries that heavily depend on the Oil and Gas industry is developing more projects in the Caspian Sea. There are several worldwide challenges, mainly, lack of standards, business models, ready products/services and competent and skilled employees. Fortunately, specific developed countries are working hard to standardize industry 4.0 architecture. Moreover, large-scale companies are creating alliances to create a trustful and long-term business model. Furthermore, large-scale companies of information and operational technology are creating robust products and services to be commercially available off the shelf. In terms of education and training, many worldwide universities are upgrading their programs, curriculums, teaching approaches with the goal to support the industry with competent future employees and entrepreneurs. Therefore, the purpose of this paper is, to present the status of engineering education programs in adapting the industry 4.0 vision in Azerbaijan and address the skills that are required for future employment. In order to present the targeted status, the curriculums of all engineering education programs at the master level were collected and analyzed. However, five of them were directly adapting industry 4.0 vision and relevant for industry 4.0. Moreover, a semi-structured interview with industrial managers was applied to extract the future required skills. This study can be considered as a first step in developing a roadmap for engineering education, particularly industrial engineering, to adopt industry 4.0 vision at the national level.acceptedVersio",10.1088/1757-899x/700/1/012063,https://core.ac.uk/download/328020558.pdf,18493203,a summary of adapting industry 4.0 vision into engineering education in azerbaijan,2019-01-01T00:00:00,'IOP Publishing',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Research around AI for Science has seen significant success since the rise of
deep learning models over the past decade, even with longstanding challenges
such as protein structure prediction. However, this fast development inevitably
made their flaws apparent -- especially in domains of reasoning where
understanding the cause-effect relationship is important. One such domain is
drug discovery, in which such understanding is required to make sense of data
otherwise plagued by spurious correlations. Said spuriousness only becomes
worse with the ongoing trend of ever-increasing amounts of data in the life
sciences and thereby restricts researchers in their ability to understand
disease biology and create better therapeutics. Therefore, to advance the
science of drug discovery with AI it is becoming necessary to formulate the key
problems in the language of causality, which allows the explication of
modelling assumptions needed for identifying true cause-effect relationships.
  In this attention paper, we present causal drug discovery as the craft of
creating models that ground the process of drug discovery in causal reasoning.Comment: Main paper: 6 pages, References: 1.5 pages. Main paper: 3 figure",,http://arxiv.org/abs/2212.12560,137357841,on how ai needs to change to advance the science of drug discovery,2022-12-23T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The 43rd UID conference, held in Genova, takes up the theme of ‘Dialogues’ as practice and debate on many fundamental topics in our social life, especially in these complex and not yet resolved times. The city of Genova offers the opportunity to ponder on the value of comparison and on the possibilities for the community, naturally focused on the aspects that concern us, as professors, researchers, disseminators of knowledge, or on all the possibile meanings of the discipline of representation and its dialogue with ‘others’, which we have broadly catalogued in three macro areas: History, Semiotics, Science / Technology. Therefore, “dialogue” as a profitable exchange based on a common language, without which it is impossible to comprehend and understand one another; and the graphic sign that connotes the conference is the precise transcription of this concept: the title ‘translated’ into signs, derived from the visual alphabet designed for the visual identity of the UID since 2017. There are many topics which refer to three macro sessions: - Witnessing (signs and history) - Communicating (signs and semiotics) - Experimenting (signs and sciences) Thanks to the different points of view, an exceptional resource of our disciplinary area, we want to try to outline the prevailing theoretical-operational synergies, the collaborative lines of an instrumental nature, the recent updates of the repertoires of images that attest and nourish the relations among representation, history, semiotics, sciences",10.3280/oa-832-c100,https://core.ac.uk/download/552148088.pdf,138851130,chapter il fulmine e la “reazione nera”: disegno naturale e artificiale dei pattern tra golgi e simondon,2022-01-01T00:00:00,'Franco Angeli',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Bullying and cyberbullying are phenomena which, due to their growing diffusion, have become a real social emergency. In this context, artificial intelligence can be a powerful weapon to identify episodes of violence and fight bullying both in the
virtual and in the real world. Through machine learning, it is possible to detect the language patterns used by bullies and their victims and develop rules to detect cyberbullying content automatically. The BullyBuster project merges the know-how of four interdisciplinary research groups to develop a framework useful for maintaining psycho-physical well-being in educational contexts",,https://core.ac.uk/download/587991088.pdf,148301030,leveraging artificial intelligence to fight (cyber)bullying for human well-being: the bullybuster project,2023-01-01T00:00:00,place:Aachen,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Large Language Models (LLMs) have demonstrated remarkable performance on a
wide range of Natural Language Processing (NLP) tasks, often matching or even
beating state-of-the-art task-specific models. This study aims at assessing the
financial reasoning capabilities of LLMs. We leverage mock exam questions of
the Chartered Financial Analyst (CFA) Program to conduct a comprehensive
evaluation of ChatGPT and GPT-4 in financial analysis, considering Zero-Shot
(ZS), Chain-of-Thought (CoT), and Few-Shot (FS) scenarios. We present an
in-depth analysis of the models' performance and limitations, and estimate
whether they would have a chance at passing the CFA exams. Finally, we outline
insights into potential strategies and improvements to enhance the
applicability of LLMs in finance. In this perspective, we hope this work paves
the way for future studies to continue enhancing LLMs for financial reasoning
through rigorous evaluation",,http://arxiv.org/abs/2310.08678,152049184,"can gpt models be financial analysts? an evaluation of chatgpt and gpt-4
  on mock cfa exams",2023-10-12T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Probabilistic model checking is a useful technique for specifying and
verifying properties of stochastic systems including randomized protocols and
reinforcement learning models. Existing methods rely on the assumed structure
and probabilities of certain system transitions. These assumptions may be
incorrect, and may even be violated by an adversary who gains control of system
components.
  In this paper, we develop a formal framework for adversarial robustness in
systems modeled as discrete time Markov chains (DTMCs). We base our framework
on existing methods for verifying probabilistic temporal logic properties and
extend it to include deterministic, memoryless policies acting in Markov
decision processes (MDPs). Our framework includes a flexible approach for
specifying structure-preserving and non structure-preserving adversarial
models. We outline a class of threat models under which adversaries can perturb
system transitions, constrained by an $\varepsilon$ ball around the original
transition probabilities.
  We define three main DTMC adversarial robustness problems: adversarial
robustness verification, maximal $\delta$ synthesis, and worst case attack
synthesis. We present two optimization-based solutions to these three problems,
leveraging traditional and parametric probabilistic model checking techniques.
We then evaluate our solutions on two stochastic protocols and a collection of
Grid World case studies, which model an agent acting in an environment
described as an MDP. We find that the parametric solution results in fast
computation for small parameter spaces. In the case of less restrictive
(stronger) adversaries, the number of parameters increases, and directly
computing property satisfaction probabilities is more scalable. We demonstrate
the usefulness of our definitions and solutions by comparing system outcomes
over various properties, threat models, and case studies.Comment: To Appear, 35th IEEE Computer Security Foundations Symposium (2022",,http://arxiv.org/abs/2110.02125,124978236,"adversarial robustness verification and attack synthesis in stochastic
  systems",2022-07-31T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This commentary aims to discuss perspectives on narrative-centered learning and metaphors of AI-based learning environments. To this end, the commentary draws from James Lester’s keynote and an interview with a focus on the narrative element that underlies the use of AI in Learning. In both texts, Lester offers an account of the narrative-centered learning environments that he has been developing with his research group. One example of such environments is Crystal Island, an AI-based game for K-12 students learning science. Along with Crystal Island, more metaphors of learning emerge. Based on these, this chapter uses Paul Ricoeur’s narrative theory and metaphor theory to reflect on the role of characters and the narrative plot in relation to Lester’s visualization of the future of learning with AI-based technologies. In this process, new roles in AI-based learning are introduced. One such example is the role of drama manager. The drama manager is a novel metaphor in game-based learning. In addition, more conventional metaphors, such as the tutorial dialogue, are brought forward as well as technological metaphors. The multiplicity of metaphors have agency at the core, as connecting tissue. Agency, although not explicitly articulated in the keynote and the interview, is an all-encompassing metaphor in learning. As technological advancement shakes the boundaries of thinking about agency nowadays, new dynamic metaphors are needed in AI-based learning. Toward this direction, the commentary draws from new materialist and post-humanist thinkers to raise these issues and the need to take the narrative furtherPeer reviewe",10.1007/978-3-031-09687-7_8,https://core.ac.uk/download/554076909.pdf,139622613,perspectives and metaphors of learning : a commentary on james lester’s narrative-centered ai-based environments,2022-11-27T00:00:00,"Springer, Cham",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Perception, localization, planning, and control, high-level functions often
organized in a so-called pipeline, are amongst the core building blocks of
modern autonomous (ground, air, and underwater) vehicle architectures. These
functions are increasingly being implemented using learning-enabled components
(LECs), i.e., (software) components leveraging knowledge acquisition and
learning processes such as deep learning. Providing quantified component-level
assurance as part of a wider (dynamic) assurance case can be useful in
supporting both pre-operational approval of LECs (e.g., by regulators), and
runtime hazard mitigation, e.g., using assurance-based failover configurations.
This paper develops a notion of assurance for LECs based on i) identifying the
relevant dependability attributes, and ii) quantifying those attributes and the
associated uncertainty, using probabilistic techniques. We give a practical
grounding for our work using an example from the aviation domain: an autonomous
taxiing capability for an unmanned aircraft system (UAS), focusing on the
application of LECs as sensors in the perception function. We identify the
applicable quantitative measures of assurance, and characterize the associated
uncertainty using a non-parametric Bayesian approach, namely Gaussian process
regression. We additionally discuss the relevance and contribution of LEC
assurance to system-level assurance, the generalizability of our approach, and
the associated challenges.Comment: 8 pp, 4 figures, Appears in the proceedings of EDCC 201",10.1109/edcc.2019.00021,http://arxiv.org/abs/2301.08980,138154064,towards quantification of assurance for learning-enabled components,2023-01-21T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"EC3 Reports;22The objective of this report is to present a list of proceedings (conferences, workshops, symposia, meetings) in the areas of Computer Science, Electrical & Electronic Engineering, and Communications covered by Google Scholar Metrics and ranked according to their h-index. Google Scholar Metrics only displays publications that have published at least 100 papers and have received at least one citation in the last five years (2012-2016). The currently were conducted between the 18th and 22th of December, 2017. A total of 1,918 queries proceedings have been identified.Delgado López-Cózar, E.; Orduña Malea, E. (2017). Proceedings Scholar Metrics 2017: H Index of proceedings on Computer Science, Electrical & Electronic Engineering, and Communications according to Google Scholar Metrics (2012-2016). http://hdl.handle.net/10251/11237",,https://riunet.upv.es/bitstream/10251/112372/1/EC3-Reports%20%2822%29%20Proceedings-scholar-metrics%20%282012-2016%29.pdf,11814376,"proceedings scholar metrics 2017: h index of proceedings on computer science, electrical & electronic engineering, and communications according to google scholar metrics (2012-2016)",2017-12-27T00:00:00,'Universitat Politecnica de Valencia',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The aim of this project is to understand the concepts underlying machine learning and how to implement those. To achieve this purpose, an exhaustive study of the origins of this technology has been made, describing the most popular types of neural networks, their history, and the architectures and subsequent implementations. Three implementations of neural networks are presented, using world-known datasets. In the last implementation, an exhaustive study has been realized to achieve the best performance algorithm taking into account different settings. In the second part of the project, Detectron2 has been used, an advanced machine learning program that performs object detection. We have worked with this program and executed a study of the motion of moving airplanes, implementing a new method to track objects given a set of images extracted from a given video",,https://core.ac.uk/download/334552129.pdf,89389689,machine learning on deep neural networks and object tracking applied to motion of airplanes,2020-09-14T01:00:00,Universitat Politècnica de Catalunya,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The stages of digital technology readiness are viewed through the lens of three contemporary and widely discussed examples, namely distributed ledger technology, machine learning, and the internet of things. I use these examples to clarify when there is really just an old technology being re-branded, when there is something genuinely new and useful, and whether there may be over-claiming",10.17863/cam.60402,https://core.ac.uk/download/360296906.pdf,101808924,how to tell when a digital technology is not ready for you.,2020-04-10T01:00:00,Patterns (N Y),[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"[EN] Digital Twins (DTs) are starting to be exploited to improve the management of water distribution systems (WDSs) and, in the future, they will be crucial for decision making. In this paper, the authors propose several requirements that a DT of a water distribution system should accomplish. Developing a DT is a challenge, and a continuous process of adjustments and learning is required. Due to the advantages of having a DT of the WDS always available, during the last years a strategy to build and maintain a DT of the water distribution network of Valencia (Spain) and its Metropolitan Area (1.6 million inhabitants) was developed. This is one of the first DTs built of a water utility, being currently in operation. The great benefits of their use in the daily operation of the system ensure that they will begin to be usual in the most advanced smart cities.Conejos Fuertes, P.; Martínez Alzamora, F.; Hervás-Carot, M.; Alonso Campos, JC. (2020). Building and exploiting a Digital Twin for the management of drinking water distribution networks. Urban Water Journal. 17(8):704-713. https://doi.org/10.1080/1573062X.2020.1771382S704713178Chacón Ramírez, E., Albarrán, J. C., & Cruz Salazar, L. A. (2019). The Control of Water Distribution Systems as a Holonic System. Studies in Computational Intelligence, 352-365. doi:10.1007/978-3-030-27477-1_27Grieves, M., et al. 2015. Virtually Intelligent Product Systems: Digital and Physical Twins. In Complex Systems Engineering: Theory and Practice, edited by S. Flumerfelt, et al., 175–200. American Institute of Aeronautics and Astronautics.Hatchett, S., J. Uber, D. Boccelli, T. Haxton, R. Janke, A. Kramer, A. Matracia, and S. Panguluri. 2011. “Real-Time Distribution System Modeling: Development, Application, and Insights.” Urban Water Management: Challenges and Oppurtunities - 11thInternational Conference on Computing and Control for the Water Industry, CCWI 2011 July.Kartakis, S., Abraham, E., & McCann, J. A. (2015). WaterBox. Proceedings of the 1st ACM International Workshop on Cyber-Physical Systems for Smart Water Networks. doi:10.1145/2738935.2738939Lin, J., Sedigh, S., & Miller, A. (2009). Towards Integrated Simulation of Cyber-Physical Systems: A Case Study on Intelligent Water Distribution. 2009 Eighth IEEE International Conference on Dependable, Autonomic and Secure Computing. doi:10.1109/dasc.2009.140Qi, Q., & Tao, F. (2018). Digital Twin and Big Data Towards Smart Manufacturing and Industry 4.0: 360 Degree Comparison. IEEE Access, 6, 3585-3593. doi:10.1109/access.2018.2793265Alac, M. (2008). Working with Brain Scans. Social Studies of Science, 38(4), 483-508. doi:10.1177/0306312708089715Shi, Y., Xu, J., & Du, W. (2019). Discussion on the New Operation Management Mode of Hydraulic Engineering Based on the Digital Twin Technique. Journal of Physics: Conference Series, 1168, 022044. doi:10.1088/1742-6596/1168/2/022044Tao, F., Zhang, H., Liu, A., & Nee, A. Y. C. (2019). Digital Twin in Industry: State-of-the-Art. IEEE Transactions on Industrial Informatics, 15(4), 2405-2415. doi:10.1109/tii.2018.2873186Tao, F., Cheng, J., Qi, Q., Zhang, M., Zhang, H., & Sui, F. (2017). Digital twin-driven product design, manufacturing and service with big data. The International Journal of Advanced Manufacturing Technology, 94(9-12), 3563-3576. doi:10.1007/s00170-017-0233-1Tao, F., & Qi, Q. (2019). Make more digital twins. Nature, 573(7775), 490-491. doi:10.1038/d41586-019-02849-1Uber, J., S. Hatchett, S. Hooper, D. Boccelli, H. Woo, and R. Janke. 2014. Water Utility Case Study of Real-Time Network Hydaulic and Water Qualilty Modeling Using EPANET-RTX Libraries. EPA 6007R-14/350 Report. Cincinnati, Ohio: Environmental Protection Agency.Wang, Z., Song, H., Watkins, D. W., Ong, K. G., Xue, P., Yang, Q., & Shi, X. (2015). Cyber-physical systems for water sustainability: challenges and opportunities. IEEE Communications Magazine, 53(5), 216-222. doi:10.1109/mcom.2015.710566",10.1080/1573062x.2020.1771382,https://riunet.upv.es/bitstream/10251/162857/3/Conejos%3bMart%c3%adnez%3bHerv%c3%a1s-Carot%20-%20Building%20and%20exploiting%20a%20Digital%20Twin%20for%20the%20management%20of%20drin....pdf,109692356,building and exploiting a digital twin for the management of drinking water distribution networks,2020-09-13T01:00:00,'Informa UK Limited',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Computational learning theory states that many classes of boolean formulas
are learnable in polynomial time. This paper addresses the understudied subject
of how, in practice, such formulas can be learned by deep neural networks.
Specifically, we analyse boolean formulas associated with the decision version
of combinatorial optimisation problems, model sampling benchmarks, and random
3-CNFs with varying degrees of constrainedness. Our extensive experiments
indicate that: (i) regardless of the combinatorial optimisation problem,
relatively small and shallow neural networks are very good approximators of the
associated formulas; (ii) smaller formulas seem harder to learn, possibly due
to the fewer positive (satisfying) examples available; and (iii) interestingly,
underconstrained 3-CNF formulas are more challenging to learn than
overconstrained ones. Source code and relevant datasets are publicly available
(https://github.com/machine-reasoning-ufrgs/mlbf)",,http://arxiv.org/abs/2009.05908,89008516,understanding boolean function learnability on deep neural networks,2020-09-12T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Activities of Daily Living (ADL) systems have been playing an important role in assessing and monitoring the quality of life of elderly people for many years. With the recent advancement and integration of Internet of Things (IoT) devices within the ADL systems, the number and quality of services offered has increased significantly. One of these vital services is abnormal behaviour detection based on the data collected from IoT devices within smart homes. However, the IoT data collected could have enormous privacy implications on smart home users if the data is not handled properly. We address this issue by analysing a generic ADL system for abnormal behaviour detection, including its entities and their interactions. We highlight three major privacy issues: (i) identity privacy, (ii) data confidentiality, and (iii) metadata data leakage. These issues are particularly relevant to ADL systems and we propose potential countermeasures to tackle them. Finally, we sketch a privacy-preserving version of a state-of-the-art ADL system to demonstrate the effectiveness of our proposed countermeasures, before suggesting future research directions",10.1109/iotm.0001.2000169,https://core.ac.uk/download/482025969.pdf,8978225,iot-based activities of daily living for abnormal behaviour detection: privacy issues and potential countermeasures,2021-05-17T01:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We are now living an exciting time in which astonishing results coming from the A.I. field trigger the usualexpectations and fears about intelligent man-machinerelationship. Some believe that the basic ingredientsfor the artificial general intelligence are already hereand, in their opinion, it is just a matter of putting it alltogether. It seems that we do not have to programcomputers anymore; they will program themselves.Should this statement frighten us?Our position is both of recognizing the big potentialities of new A.I. developments and, simultaneously,to warn against yet another overselling and possiblydamaging stage in the A.I. field.We advocate that, intelligent systems, relying inevolving machine learning algorithms, fully autonomoussoftware agents or robots, should always follow the""human in the loop"" principle, ensuring that theresponsibility for all future intelligent entity activitiescan be traced back to some recognized and accountableindividuals or organizations",,https://core.ac.uk/download/143404743.pdf,45423804,on the verge of a new relationship between man and artificial learning machines?,2017-03-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The widespread use of artificial intelligence (AI)-based systems has raised several concerns about their deployment in safety-critical systems. Industry standards, such as ISO26262 for automotive, require detecting hardware faults during the mission of the device. Similarly, new standards are being released concerning the functional safety of AI systems (e.g., ISO/IEC CD TR 5469). Hardware solutions have been proposed for the in-field testing of the hardware executing AI applications; however, when used in applications such as Convolutional Neural Networks (CNNs) in image processing tasks, their usage may increase the hardware cost and affect the application performances. In this paper, for the very first time, a methodology to develop high-quality  test images, to be interleaved with the normal inference process of the CNN application is proposed. An Image Test Library (ITL) is developed targeting the  on-line test of GPU functional units. The proposed approach does not require changing the actual CNN (thus incurring in costly memory loading operations) since it is able to exploit the actual CNN structure. Experimental results show that a 6-image ITL is able to achieve about 95\% of stuck-at test coverage on the floating-point multipliers in a GPU. The obtained ITL requires a very low test application time, as well as a very low memory space for storing the test images and the golden test responses",10.1109/ets56758.2023.10174176,https://core.ac.uk/download/567878605.pdf,150254182,image test libraries for the on-line self-test of functional units in gpus running cnns,2023-01-01T00:00:00,IEEE,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Deep learning has been widely used in source code classification tasks, such
as code classification according to their functionalities, code authorship
attribution, and vulnerability detection. Unfortunately, the black-box nature
of deep learning makes it hard to interpret and understand why a classifier
(i.e., classification model) makes a particular prediction on a given example.
This lack of interpretability (or explainability) might have hindered their
adoption by practitioners because it is not clear when they should or should
not trust a classifier's prediction. The lack of interpretability has motivated
a number of studies in recent years. However, existing methods are neither
robust nor able to cope with out-of-distribution examples. In this paper, we
propose a novel method to produce \underline{Rob}ust \underline{in}terpreters
for a given deep learning-based code classifier; the method is dubbed Robin.
The key idea behind Robin is a novel hybrid structure combining an interpreter
and two approximators, while leveraging the ideas of adversarial training and
data augmentation. Experimental results show that on average the interpreter
produced by Robin achieves a 6.11\% higher fidelity (evaluated on the
classifier), 67.22\% higher fidelity (evaluated on the approximator), and
15.87x higher robustness than that of the three existing interpreters we
evaluated. Moreover, the interpreter is 47.31\% less affected by
out-of-distribution examples than that of LEMNA.Comment: To be published in the 38th IEEE/ACM International Conference on
  Automated Software Engineering (ASE 2023",,http://arxiv.org/abs/2309.10644,148053594,"robin: a novel method to produce robust interpreters for deep
  learning-based code classifiers",2023-09-19T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"International audienceIndividuation and organization in complex living multi-level ecosystem occurs as dynamical processes from early ontogeny. The notion of living “holon” displaying dynamic self-assertion and integration is used here to explain the ecosystems dynamic processes. The update of the living holon state according to the continuous change of the dynamic system allows for its viability. This is interpreted as adaptation, selection and organization by the human that observes the system at posteriori from its level. Our model concerns the complex dynamics of the adaptive immune system, integrating holon-lymphocytes that collectively preserve the identity and integrity of the organism. Each lymphocyte individualizes as a dynamic holon-lymphocyte, with somatic gene individuation leading to an individual, singular antigen immunoreceptor type, promoting the self-assertion. In turn, the “Immunoception” allows for perception of the environmental antigenic context, thus integration of the holon in its environment. The self-assertion/integration of holon-lymphocyte starts from fetal stages and is influenced by mother Lamarckian acquired historicity transmissions, a requisite for the integrity of the holobiont-organism. We propose a dynamic model of the perception by holon-lymphocyte, and at the supra-clonal level of the immune system functions that sustain the identity and integrity of the holon-holobiont organism",10.1007/s10441-019-09364-w,https://core.ac.uk/download/228097061.pdf,66750790,individuation and the organization in complex living ecosystem: recursive integration and self-assertion by holon-lymphocytes,2019-01-01T00:00:00,'Springer Science and Business Media LLC',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Various research domains use machine learning approaches because they can solve complex tasks by learning from data. Deploying machine learning models, however, is not trivial and developers have to implement complete solutions which are often installed locally and include Graphical User Interfaces (GUIs). Distributing software to various users on-site has several problems. Therefore, we propose a concept to deploy software in the cloud. There are several frameworks available based on Representational State Transfer (REST) which can be used to implement cloud-based machine learning services. However, machine learning services for scientific users have special requirements that state-of-the-art REST frameworks do not cover completely. We contribute an EasyMLServe software framework to deploy machine learning services in the cloud using REST interfaces and generic local or web-based GUIs. Furthermore, we apply our framework on two real-world applications, i. e., energy time-series forecasting and cell instance segmentation. The EasyMLServe framework and the use cases are available on GitHub",10.5445/ir/1000154156,https://core.ac.uk/download/552972880.pdf,137756113,easymlserve: easy deployment of rest machine learning services,2022-12-23T00:00:00,KIT Scientific Publishing,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In several reinforcement learning (RL) scenarios, mainly in security
settings, there may be adversaries trying to interfere with the reward
generating process. In this paper, we introduce Threatened Markov Decision
Processes (TMDPs), which provide a framework to support a decision maker
against a potential adversary in RL. Furthermore, we propose a level-$k$
thinking scheme resulting in a new learning framework to deal with TMDPs. After
introducing our framework and deriving theoretical results, relevant empirical
evidence is given via extensive experiments, showing the benefits of accounting
for adversaries while the agent learns.Comment: Extends the verson published at the Proceedings of the AAAI
  Conference on Artificial Intelligence 33,
  https://www.aaai.org/ojs/index.php/AAAI/article/view/510",10.1609/aaai.v33i01.33019939,http://arxiv.org/abs/1809.01560,52353567,reinforcement learning under threats,2019-07-17T01:00:00,'Association for the Advancement of Artificial Intelligence (AAAI)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Computing the future, as life and research moves to the Internet, we are engaged increasingly in digital encounters from present to past and into the future with real people, events and documents. This paper focuses on the newly born-digital relationship between Alan Turing, father of computer science, and Leonardo da Vinci, master of Renaissance art and science – both revered as visionary geniuses, prophets of the future. Given the continued growth of digitised materials that are daily entering global consciousness, it is only relatively recently that both da Vinci’s notebooks and paintings, and Turing’s archive, are online and searchable. Thus we are able for the first time to relatively easily juxtapose and compare their work, and see that they have much in common in terms of what it means to human in science, art and the natural world, from da Vinci’s in-depth studies of the mechanisms of the human body, mind, and soul, foundational to his art, and to Turing’s discoveries in Artificial Intelligence (AI), machine learning, and morphogenesis. Considering their points of concurrence in the digital world brings into focus our global network of digital places and spaces, where science, art, and nature, including real and artificial life, become unbounded",10.14236/ewic/eva2020.3,https://core.ac.uk/download/388607036.pdf,36366860,computing the future: digital encounters in art and science when da vinci meets turing,2020-01-01T00:00:00,'BCS Learning and Development Limited',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"On November 21, 2022, Dr. Ryan Prox, Adjunct Professor in the School of Criminology at Simon Fraser University, presented Data &amp; Infrastructure Security: The Risk of AI Enabled Cyber Attacks and Quantum Hacking.  A question-and-answer period with the audience and CASIS Vancouver executives followed the presentation. The key topics discussed were the evolution of data and infrastructure security, the increasing interconnectedness of critical infrastructure, and the need to increase resilience in the face of revolutionary technological advancements.  
 
Received: 2023-01-23Revised: 2023-01-2",,https://core.ac.uk/download/555204777.pdf,141445566,data & infrastructure security: the risk of ai enabled cyber attacks and quantum hacking,2023-02-03T00:00:00,"Simon Fraser University Library, Canada & Canadian Association for Security and Intelligence Studies",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Human feedback can prevent overtly harmful utterances in conversational
models, but may not automatically mitigate subtle problematic behaviors such as
a stated desire for self-preservation or power. Constitutional AI offers an
alternative, replacing human feedback with feedback from AI models conditioned
only on a list of written principles. We find this approach effectively
prevents the expression of such behaviors. The success of simple principles
motivates us to ask: can models learn general ethical behaviors from only a
single written principle? To test this, we run experiments using a principle
roughly stated as ""do what's best for humanity"". We find that the largest
dialogue models can generalize from this short constitution, resulting in
harmless assistants with no stated interest in specific motivations like power.
A general principle may thus partially avoid the need for a long list of
constitutions targeting potentially harmful behaviors. However, more detailed
constitutions still improve fine-grained control over specific types of harms.
This suggests both general and specific principles have value for steering AI
safely",,http://arxiv.org/abs/2310.13798,152815629,specific versus general principles for constitutional ai,2023-10-20T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Criminal investigations are guided by repetitive and time-consuming information retrieval tasks, often with high risk and high consequence. If Artificial intelligence (AI) systems can automate lines of inquiry, it could reduce the burden on analysts and allow them to focus their efforts on analysis. However, there is a critical need for algorithmic transparency to address ethical concerns. In this paper, we use data gathered from Cognitive Task Analysis (CTA) interviews of criminal intelligence analysts and perform a novel analysis method to elicit question networks. We show how these networks form an event tree, where events are consolidated by capturing analyst intentions. The event tree is simplified with a Dynamic Chain Event Graph (DCEG) that provides a foundation for transparent autonomous investigations",10.1177/1071181320641057,https://core.ac.uk/download/573846524.pdf,144981037,providing a foundation for interpretable autonomous agents through elicitation and modeling of criminal investigation pathways,2020-01-01T00:00:00,SAGE Publications,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Our desire and fascination with intelligent machines dates back to the
antiquity's mythical automaton Talos, Aristotle's mode of mechanical thought
(syllogism) and Heron of Alexandria's mechanical machines and automata.
However, the quest for Artificial General Intelligence (AGI) is troubled with
repeated failures of strategies and approaches throughout the history. This
decade has seen a shift in interest towards bio-inspired software and hardware,
with the assumption that such mimicry entails intelligence. Though these steps
are fruitful in certain directions and have advanced automation, their singular
design focus renders them highly inefficient in achieving AGI. Which set of
requirements have to be met in the design of AGI? What are the limits in the
design of the artificial? Here, a careful examination of computation in
biological systems hints that evolutionary tinkering of contextual processing
of information enabled by a hierarchical architecture is the key to build AGI.Comment: Theoretical perspective on AGI (Artificial General Intelligence",,http://arxiv.org/abs/1703.02245,42846520,"design of the artificial: lessons from the biological roots of general
  intelligence",2017-03-08T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The Steve and Jamie Chen Center for Innovation and Inquiry (IN2) features a 6,400 square foot state-of-the-art transformational center. The center provides collaborative programming and events in Science, Technology, Engineering, and Mathematics (STEM), Makerspace and Entrepreneurship programs for middle and high school students.
The IN2 team follows methods in its programming which provides: Design Thinking, Experience Design, Practice-based Participatory Learning and the Lean Startup methodology (build, measure, and learn) and iterates program ideas from ideation to growth.
The center’s programs and activities ignites collaboration among students, educators, businesses and communities to advance the human condition through innovation and entrepreneurship",,https://core.ac.uk/download/287162181.pdf,77844075,comed final grant report: imsa innovation center programs,2019-01-01T08:00:00,DigitalCommons@IMSA,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"A lot of Machine Learning (ML) and Deep Learning (DL) research is of an
empirical nature. Nevertheless, statistical significance testing (SST) is still
not widely used. This endangers true progress, as seeming improvements over a
baseline might be statistical flukes, leading follow-up research astray while
wasting human and computational resources. Here, we provide an easy-to-use
package containing different significance tests and utility functions
specifically tailored towards research needs and usability",,https://core.ac.uk/download/541291184.pdf,130725010,deep-significance - easy and meaningful statistical significance testing in the age of neural networks,2022-04-14T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This contribution aims to chart how the future looked to the Italian world of education in the 1960s and 1970s, by analyzing articles published in Scuola Italiana Moderna, a specialist journal for teachers with Catholic leanings. We examine studies and opinions regarding new technologies and AI (Artificial Intelligence) in relation to the concepts of school, education and teaching. Our aim is to focus on perceptions of how technology, computer science and the idea of AI might change the experience of education and teaching in the future. We also look at the utopianprojective aspect of a line of reasoning that tried to imagine the impact of AI: how it might affect people’s lives; whether it would be useful in training courses and institutions; and how it would shape the children of the future. The concerns of a moral order that accompanied such considerations are also examined",10.26106/qj24-v272,https://core.ac.uk/download/553601473.pdf,138588288,education and the future : relations between new technologies and the world of teaching in twenty years of the scuola italiana moderna journal,2022-01-01T00:00:00,,"[{'title': None, 'identifiers': ['issn:2353-3900', '2353-3900']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Traffic accidents pose an increasing threat to society, and researchers are dedicated to preventing accidents and reducing fatalities, as highlighted by the World Health Organ-ization. One significant cause of accidents is drowsy driving, which often leads to severe injuries and loss of life. The objective of this research is to create a fatigue detection sys-tem that can effectively minimize accidents associated with exhaustion. The system uti-lizes facial recognition technology to identify drowsy drivers by analyzing eye patterns through video processing. When the level of fatigue surpasses a predetermined thresh-old, the system alerts the driver and adjusts the vehicle's acceleration accordingly. The implementation of OpenCv libraries, such as Haar-cascade, along with Raspberry Pi fa-cilitates seamless integration of the system. This dissertation evaluates advancements in computational engineering for the development of a fatigue detection system to miti-gate accidents caused by drowsiness. It offers valuable insights and recommendations to enhance comprehension and optimize the system's effectiveness, ultimately leading to safer road travel",10.54060/jieee.v4i1.88,https://core.ac.uk/download/577864239.pdf,149765891,using machine learning to determine the motorist somnolence,2023-04-25T01:00:00,A2Z Journals,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Adding ethics courses to engineering curricula seeks to equip students with the critical mindset that enables careers committed to serving humanity. Yet, the knowledge of ethical theories is neither a necessary, let alone sufficient condition for being good [1]. There is no automatism that translates ethical knowledge into action, overriding attitudes that were developed during the enculturation of a student. However, we deem teaching assemblage theory a promising means to achieve a sustained commitment to responsible innovation practice. We base our argument on assemblage theory’s (cf. [2, 3]) capacity to conceptualize the interplay of human actors and technological artefacts in terms of dynamic evolutionary systems. The notion of an assemblage as a collection of potentially heterogeneous elements that—despite displaying consistency—remains malleable through reorganization, interconnection and, (re- )attribution forms the ontological basis that guides a conceptual approach to thinking in-between the extremes of technological determinism and social constructivism. Information algorithms, e.g., can be regarded as having the power to facilitate ethical action as part of a larger assemblage [4] and artificial intelligence can arguably only be understood as “trustworthy” within sociotechnological systems in which a shared responsibility realizes both epistemic and moral conditions for trust [5]. Ultimately, we intend engineering students to realize the extent of their influence on the world and, therefore, their responsibility for contributing to a prosperous community. Thus, ethics is not only taught by conveying its classical normative theories but rather explored by discovering the entangledness of technology and society",10.5821/conference-9788412322262.1390.,https://core.ac.uk/download/559250518.pdf,150038285,teaching ethics through the back door? employing ideas from assemblage theory to foster a responsible innovation mindset,2022-09-01T01:00:00,Universitat Politècnica de Catalunya,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"© 2019 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.Well understanding the access behavior of hot data is significant for NAND flash memory due to its crucial impact on the efficiency of garbage collection (GC) and wear leveling (WL), which respectively dominate the performance and life span of SSD. Generally, both GC and WL rely greatly on the recognition accuracy of hot data identification (HDI). However, in this paper, the first time we propose a novel concept of hot data prediction (HDP), where the conventional HDI becomes unnecessary. First, we develop a hybrid optimized echo state network (HOESN), where sufficiently unbiased and continuously shrunk output weights are learnt by a sparse regression based on L2 and L1/2 regularization. Second, quantum-behaved particle swarm optimization (QPSO) is employed to compute reservoir parameters (i.e., global scaling factor, reservoir size, scaling coefficient and sparsity degree) for further improving prediction accuracy and reliability. Third, in the test on a chaotic benchmark (Rossler), the HOESN performs better than those of six recent state-of-the-art methods. Finally, simulation results about six typical metrics tested on five real disk workloads and on-chip experiment outcomes verified from an actual SSD prototype indicate that our HOESN-based HDP can reliably promote the access performance and endurance of NAND flash memories.Peer reviewe",10.1109/tcsi.2019.2960015,https://core.ac.uk/download/287582402.pdf,8788116,self-learning hot data prediction: where echo state network meets nand flash memories,2020-01-03T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',"[{'title': 'IEEE Transactions on Circuits and Systems I Regular Papers', 'identifiers': ['1549-8328', 'issn:1549-8328']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Not only is Artificial Intelligence (AI) present everywhere in people’s lives, but the technology is also now capable of making unpredictable decisions in novel situations. AI poses issues for the United States’ traditional criminal law system because this system emphasizes mens rea’s importance in determining criminal liability. When AI makes unpredictable decisions that lead to crimes, it will be impractical to determine what mens rea to ascribe to the human agents associated with the technology, such as AI’s creators, owners, and users. To solve this issue, the United States’ legal system must hold AI’s creators, owners, and users strictly liable for their AI’s actions and also create standards that can provide these agents immunity from strict liability. Although other legal scholars have proposed solutions that fit within the United States’ traditional criminal law system, these proposals fail to strike the right balance between encouraging AI’s development and holding someone criminally liable when AI causes harm.
This Note illuminates this issue by exploring an artificially intelligent trolley problem. In this problem, an AI-powered self-driving car must decide between running over and killing five pedestrians or swerving out of the way and killing its one passenger; ultimately, the AI decides to kill the five pedestrians. This Note explains why the United States’ traditional criminal law system would struggle to hold the self-driving car’s owner, programmers, and creator liable for the AI’s decision, because of the numerous human agents this problem brings into the criminal liability equation, the impracticality of determining these agents’ mens rea, and the difficulty in satisfying the purposes of criminal punishment. Looking past the artificially intelligent trolley problem, these issues can be extended to most criminal laws that require a mens rea element. Criminal law serves as a powerful method of regulating new technologies, and it is essential that the United States’ criminal law system adapts to solve the issues that AI poses",,https://core.ac.uk/download/551437779.pdf,135576579,the artificially intelligent trolley problem: understanding our criminal law gaps in a robot driven world,2023-01-01T08:00:00,UC Hastings Scholarship Repository,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The 4th Industrial evolution has brought along a lot of technological achievements which can change the form of humanity. Peer-to-peer networks (Distributed networks), network of sensors (Internet of Things), algorithms capable to take decisions (Artificial Intelligence), computers with the ability of self-learning (Machine Learning), more complex queries for analyzing the data, that we are collecting since the birth of internet (Data Science) and new electronic money(cryptocurrencies) are some of the characteristics of those new technologies. But the adoption of those achievements (known as Digital Transformation or Digitization) demands Managers open-minded, well-educated on those technologies and ready to trace the new possible Risks. They must also be capable to use the Systems Thinking, as the Blockchain Technologies have created an Ecosystem (Sociotechnical Systems); the combination of Social Systems (Organizations - Companies), whose behavior is not predictable, and Mechanical Systems (technical equipment) with a predefined way of function. So, this kind of Systems (Sociotechnical) need a more delicate approach using a combination of, not only Systemic methodologies and technics, but also other theories and proper tools. We are going to publish a series of articles in which we are going to specify the proper theories and methodologies in each phase of the digital transformation. Thus, the purpose of this study is to explain to the new generation of Managers how the Systems Thinking, DCSYM Methodology and VSM Model, are applied on those Ecosystems",10.14428/aes.v9i1.56063,https://core.ac.uk/download/327207432.pdf,86814684,systems thinking for the transition of existing technologies to blockchain technologies,2020-07-07T01:00:00,'Universite Catholique de Louvain',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Anticipatory thinking drives our ability to manage risk - identification and
mitigation - in everyday life, from bringing an umbrella when it might rain to
buying car insurance. As AI systems become part of everyday life, they too have
begun to manage risk. Autonomous vehicles log millions of miles, StarCraft and
Go agents have similar capabilities to humans, implicitly managing risks
presented by their opponents. To further increase performance in these tasks,
out-of-distribution evaluation can characterize a model's bias, what we view as
a type of risk management. However, learning to identify and mitigate
low-frequency, high-impact risks is at odds with the observational bias
required to train machine learning models. StarCraft and Go are closed-world
domains whose risks are known and mitigations well documented, ideal for
learning through repetition. Adversarial filtering datasets provide difficult
examples but are laborious to curate and static, both barriers to real-world
risk management. Adversarial robustness focuses on model poisoning under the
assumption there is an adversary with malicious intent, without considering
naturally occurring adversarial examples. These methods are all important steps
towards improving risk management but do so without considering open-worlds. We
unify these open-world risk management challenges with two contributions. The
first is our perception challenges, designed for agents with imperfect
perceptions of their environment whose consequences have a high impact. Our
second contribution are cognition challenges, designed for agents that must
dynamically adjust their risk exposure as they identify new risks and learn new
mitigations. Our goal with these challenges is to spur research into solutions
that assess and improve the anticipatory thinking required by AI agents to
manage risk in open-worlds and ultimately the real-world.Comment: 4 pages, 3 figures, appeared in the non-archival AAAI 2022 Spring
  Syposium on ""Designing Artificial Intelligence for Open Worlds",,http://arxiv.org/abs/2306.13157,143606487,anticipatory thinking challenges in open worlds: risk management,2023-06-22T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Adversaries may exploit a range of vulnerabilities in Internet of Things (IoT) environments. These vulnerabilities are typically exploited to carry out attacks, such as denial-of-service (DoS) attacks, either against the IoT devices themselves, or using the devices to perform the attacks. These attacks are often successful due to the nature of the protocols used in the IoT. One popular protocol used for machine-to-machine IoT communications is the Message Queueing Telemetry Protocol (MQTT). Countermeasures for attacks against MQTT include testing defenses with existing datasets. However, there is a lack of real-world test datasets in this area. For this reason, this paper introduces a DoS/DDoS-MQTT-IoT dataset—that contains various DoS/DDoS attack scenarios using MQTT traffic—to help develop and test countermeasures against such attacks. To this end, a physical IoT testbed was constructed and a large volume of IoT data was generated that included standard MQTT traffic as well as 10 DoS scenarios. The usability of the dataset has been evaluated via machine learning",10.1016/j.comnet.2023.109809,https://core.ac.uk/download/576837283.pdf,147740168,dos/ddos-mqtt-iot: a dataset for evaluating intrusions in iot networks using the mqtt protocol,2023-07-01T08:00:00,"Edith Cowan University, Research Online, Perth, Western Australia",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"There is a vast literature within philosophy of mind that focuses on artificial intelligence, but hardly mentions methodological questions. There is also a growing body of work in philosophy of science about modeling methodology that hardly mentions examples from cognitive science. Here these discussions are connected. Insights developed in the philosophy of science literature about the importance of idealization provide a way of understanding the neural implausibility of connectionist networks. Insights from neurocognitive science illuminate how relevant similarities between models and targets are picked out, how modeling inferences are justified, and the metaphysical status of models",,https://core.ac.uk/download/pdf/295733020.pdf,82143418,from implausible artificial neurons to idealized cognitive models: rebooting philosophy of artificial intelligence,2019-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Psoriasis is an autoimmune skin disorder that causes skin plaques to develop into red and scaly patches. It affects millions of people globally. Dermatologists currently employ visual and haptic methods to determine a medical issue's severity. Intelligent medical imaging-based diagnosis systems are now a possibility because of the relatively recent development of deep learning technologies for medical image processing. These systems can help a human expert make better decisions about a patient's health. Convolutional neural networks, or CNNs, on the other hand, have achieved imaging performance levels comparable to, if not better than, those of humans. In the paper, a Dermnet dataset is used. Image preprocessing, fuzzy c-mean-based segmentation, MobileNet-based feature extraction, and a support vector machine (SVM) classification are used for skin disease classification. Dermnet's dataset was investigated for images of skin conditions using three classes Psoriasis, Dermatofibroma, and Melanoma are studied. The performance metrics such as accuracy, precision-recall, and f1-score are evaluated and compared for three classes of skin diseases. Despite working with a smaller dataset, MobileNet with Support Vector Machine outperforms ResNet in terms of accuracy (99.12%), precision (98.65%), and recall (99.66%)",,https://core.ac.uk/download/588567846.pdf,150665784,psoriasis skin disease classification based on clinical images,2023-10-07T01:00:00,Auricle Global Society of Education and Research,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Graph modeling allows numerous security problems to be tackled in a general
way, however, little work has been done to understand their ability to
withstand adversarial attacks. We design and evaluate two novel graph attacks
against a state-of-the-art network-level, graph-based detection system. Our
work highlights areas in adversarial machine learning that have not yet been
addressed, specifically: graph-based clustering techniques, and a global
feature space where realistic attackers without perfect knowledge must be
accounted for (by the defenders) in order to be practical. Even though less
informed attackers can evade graph clustering with low cost, we show that some
practical defenses are possible.Comment: ACM CCS 201",10.1145/3133956.3134083,http://arxiv.org/abs/1708.09056,44595370,practical attacks against graph-based clustering,2017-08-29T00:00:00,'Association for Computing Machinery (ACM)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
Artificial intelligence is becoming a more prevalent part of our society. This presentation seeks to explore some of the dangers of AI in relation to gender and racial bias from the sociological perspective.https://digitalcommons.tacoma.uw.edu/gender_studies/1082/thumbnail.jp,,https://core.ac.uk/download/478979302.pdf,122083554,how ai is socialized to exhibit bias,2021-08-15T08:00:00,UW Tacoma Digital Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper deals with the issue of the governance of artificial intelligence from two aspects; the first one is the artificial intelligence as an essential component of the life of today’s world, whether at the level of individuals or societies; its history, effects, benefits, fields and fears arising from it, and consequently the importance of the principal of the governance of artificial intelligence in maximizing advantages and preventing disadvantages. The second aspect deals with the efforts of the Kingdom of Saudi Arabia in the field of the governance of artificial intelligence as one of the leading countries in Middle East in implementing and investing of artificial intelligence applications for the sake of Saudi society and individuals. As well as to provide opportunities for companies and institutions from entire world to collaborate inside the kingdom and benefit the world. The Kingdom of Saudi Arabia’s efforts are expressed through talking about the Saudi’s giant project NEOM, through the discussion of the founding council’s vision and message, as well as NEOM’s features and sectors",10.12731/2227-930x-2019-1-64-81,https://core.ac.uk/download/270170861.pdf,10712966,governance of artificial intelligence in ksa (neom as a model),2019-03-04T00:00:00,'Science and Innovation Center',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Emotional biosensing is rising in daily life: Data and categories claim to know how people feel and suggest what they should do about it, while CSCW explores new biosensing possibilities. Prevalent approaches to emotional biosensing are too limited, focusing on the individual, optimization, and normative categorization. Conceptual shifts can help explore alternatives: toward materiality, from representation toward performativity, inter-action to intra-action, shifting biopolitics, and shifting affect/desire. We contribute (1) synthesizing wide-ranging conceptual lenses, providing analysis connecting them to emotional biosensing design, (2) analyzing selected design exemplars to apply these lenses to design research, and (3) offering our own recommendations for designers and design researchers. In particular we suggest humility in knowledge claims with emotional biosensing, prioritizing care and affirmation over self- improvement, and exploring alternative desires. We call for critically questioning and generatively re- imagining the role of data in configuring sensing, feeling, ‘the good life,’ and everyday experience",,https://core.ac.uk/download/286028155.pdf,77594252,emotional biosensing: exploring critical alternatives,2018-01-01T00:00:00,"eScholarship, University of California",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This chapter is republished with permission by the author from: Song, B., How Chinese Philosophers Think about Artificial Intelligence, in: Song, B (Eds) (et al.). Intelligence and Wisdom, CITIC Press Corp., Springer, Singapore, 2021, 1-14, https://doi.org/10.1007/978-981-16-2309-7_",10.58863/20.500.12424/4276022,https://core.ac.uk/download/582653538.pdf,146586650,artificial intelligence and chinese philosophers,2023-01-01T00:00:00,Globethics Publications,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Cloud-edge systems are vulnerable to thermal attacks as the increased energy consumption may remain undetected, while occurring alongside normal, CPU-intensive applications. The purpose of our research is to study thermal effects on modern edge systems. We also analyze how performance is affected from the increased heat and identify preventative measures. We speculate that due to the technology being a recent innovation, research on cloud-edge devices and thermal attacks is scarce. Other research focuses on server systems rather than edge platforms. In our paper, we use a Raspberry Pi 4 and a CPU-intensive application to represent thermal attacks on cloud-edge systems. We performed several experiments with the Raspberry Pi 4 and used stress-ng, a benchmarking tool available on Linux distributions, to simulate the attacks. The resulting effects displayed drastic increases in the temperature and power consumption. The key impact of our research is to highlight the following risks and mitigation plans: the vulnerability of cloud-edge systems from thermal attacks, the capability for the attacks to go unnoticed, to further the understanding of edge devices as well as the prevention of these attacks",,https://core.ac.uk/download/480449195.pdf,40126138,an empirical study of thermal attacks on edge platforms,2021-08-31T22:06:37,DigitalCommons@Kennesaw State University,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The ongoing rise in cyberattacks and the lack of skilled professionals in the
cybersecurity domain to combat these attacks show the need for automated tools
capable of detecting an attack with good performance. Attackers disguise their
actions and launch attacks that consist of multiple actions, which are
difficult to detect. Therefore, improving defensive tools requires their
calibration against a well-trained attacker. In this work, we propose a model
of an attacking agent and environment and evaluate its performance using basic
Q-Learning, Naive Q-learning, and DoubleQ-Learning, all of which are variants
of Q-Learning. The attacking agent is trained with the goal of exfiltrating
data whereby all the hosts in the network have a non-zero detection
probability. Results show that the DoubleQ-Learning agent has the best overall
performance rate by successfully achieving the goal in $70\%$ of the
interactions",10.5220/0011684500003393,http://arxiv.org/abs/2302.03768,141346946,"catch me if you can: improving adversaries in cyber-security with
  q-learning algorithms",2023-02-07T00:00:00,'Scitepress',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The number of functionalities controlled by software on every critical real-time product is on the rise in domains like automotive, avionics and space. To implement these advanced functionalities, software applications increasingly adopt artificial intelligence algorithms that manage massive amounts of data transmitted from various sensors. This translates into unprecedented memory performance requirements in critical systems that the commonly used DRAM memories struggle to provide. High-Bandwidth Memory (HBM) can satisfy these requirements offering high bandwidth, low power and high-integration capacity features. However, it remains unclear whether the predictability and isolation properties of HBM are compatible with the requirements of critical embedded systems. In this work, we perform to our knowledge the first timing analysis of HBM. We show the unique structural and timing characteristics of HBM with respect to DRAM memories and how they can be exploited for better time predictability, with emphasis on increased isolation among tasks and reduced worst-case memory latency.This work has been partially supported by the Spanish Ministry of Science and Innovation under grant 
PID2019-107255GB-C21/AEI/10.13039/501100011033; the European Union’s Horizon 2020 Framework Programme under grant agreement No. 878752 (MASTECS) and agreement No. 779877 (Mont-Blanc 2020); the European Research Council (ERC) grant agreement No. 772773
(SuPerCom); and the Natural Sciences and Engineering Research Council of Canada (NSERC)Peer ReviewedPostprint (author's final draft",10.1109/iccad51958.2021.9643473.,https://core.ac.uk/download/491489822.pdf,133411220,demystifying the characteristics of high bandwidth memory for real-time systems,2021-12-01T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',"[{'title': None, 'identifiers': ['issn:1558-2434', '1558-2434']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Knowledge distillation (KD) is a simple and successful method to transfer
knowledge from a teacher to a student model solely based on functional
activity. However, current KD has a few shortcomings: it has recently been
shown that this method is unsuitable to transfer simple inductive biases like
shift equivariance, struggles to transfer out of domain generalization, and
optimization time is magnitudes longer compared to default non-KD model
training. To improve these aspects of KD, we propose Hard Augmentations for
Robust Distillation (HARD), a generally applicable data augmentation framework,
that generates synthetic data points for which the teacher and the student
disagree. We show in a simple toy example that our augmentation framework
solves the problem of transferring simple equivariances with KD. We then apply
our framework in real-world tasks for a variety of augmentation models, ranging
from simple spatial transformations to unconstrained image manipulations with a
pretrained variational autoencoder. We find that our learned augmentations
significantly improve KD performance on in-domain and out-of-domain evaluation.
Moreover, our method outperforms even state-of-the-art data augmentations and
since the augmented training inputs can be visualized, they offer a qualitative
insight into the properties that are transferred from the teacher to the
student. Thus HARD represents a generally applicable, dynamically optimized
data augmentation technique tailored to improve the generalization and
convergence speed of models trained with KD",,http://arxiv.org/abs/2305.14890,142995073,hard: hard augmentations for robust distillation,2023-05-24T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Constrained clustering, such as k -means with instance-level Must-Link (ML) and Cannot-Link (CL) auxiliary information as the constraints, has been extensively studied recently, due to its broad applications in data science and AI. Despite some heuristic approaches, there has not been any algorithm providing a non-trivial approximation ratio to the constrained k -means problem. To address this issue, we propose an algorithm with a provable approximation ratio of O(logk) when only ML constraints are considered. We also empirically evaluate the performance of our algorithm on real-world datasets having artificial ML and disjoint CL constraints. The experimental results show that our algorithm outperforms the existing greedy-based heuristic methods in clustering accuracy",10.26599/tst.2022.9010056,https://core.ac.uk/download/590735656.pdf,149752710,efficient algorithm for the k-means problem with must-link and cannot-link constraints,2023-01-01T00:00:00,Tsinghua University,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The grand aim of having a single robot that can manipulate arbitrary objects
in diverse settings is at odds with the paucity of robotics datasets. Acquiring
and growing such datasets is strenuous due to manual efforts, operational
costs, and safety challenges. A path toward such an universal agent would
require a structured framework capable of wide generalization but trained
within a reasonable data budget. In this paper, we develop an efficient system
(RoboAgent) for training universal agents capable of multi-task manipulation
skills using (a) semantic augmentations that can rapidly multiply existing
datasets and (b) action representations that can extract performant policies
with small yet diverse multi-modal datasets without overfitting. In addition,
reliable task conditioning and an expressive policy architecture enable our
agent to exhibit a diverse repertoire of skills in novel situations specified
using language commands. Using merely 7500 demonstrations, we are able to train
a single agent capable of 12 unique skills, and demonstrate its generalization
over 38 tasks spread across common daily activities in diverse kitchen scenes.
On average, RoboAgent outperforms prior methods by over 40% in unseen
situations while being more sample efficient and being amenable to capability
improvements and extensions through fine-tuning. Videos at
https://robopen.github.io",,http://arxiv.org/abs/2309.01918,146407319,"roboagent: generalization and efficiency in robot manipulation via
  semantic augmentations and action chunking",2023-09-04T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"With the enhanced usage of Artificial Intelligence (AI) driven applications, the researchers often face challenges in improving the accuracy of the data classification models, while trading off the complexity. In this paper, we address the classification of time series data using the Long Short-Term Memory (LSTM) network while focusing on the activation functions. While the existing activation functions such as sigmoid and tanh are used as LSTM internal activations, the customizability of these activations stays limited. This motivates us to propose a new family of activation functions, called log-sigmoid, inside the LSTM cell for time series data classification, and analyze its properties. We also present the use of a linear transformation (e.g., log tanh) of the proposed log-sigmoid activation as a replacement of the traditional tanh function in the LSTM cell. Both the cell activation as well as recurrent activation functions inside the LSTM cell are modified with log-sigmoid activation family while tuning the log bases. Further, we report a comparative performance analysis of the LSTM model using the proposed and the state-of-the-art activation functions on multiple public time-series databases",10.1109/tai.2023.3265641,https://core.ac.uk/download/567883577.pdf,153736716,sigmoid activation-based long short-term memory for time series data classification,2023-01-01T08:00:00,Scholars\u27 Mine,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Industry 4.0 is the latest stage in the Industrial Revolution and is reflected in the digital transformation and use of emergent technologies including the Internet of Things, Big Data, Robotic automation of processes, 3D printing and additive manufacturing, drones and Artificial Intelligence (AI) in the manufacturing industry. The implementation of these technologies in the Shipbuilding and Ship Repair Industry is currently in a nascent stage. Considering this, there is huge potential to increase cost savings, decrease production timelines, and drive down inefficiencies in Lifecyle management of ships. However, the implementation of these Industry 4.0 technologies is hindered by a noticeable gap in workforce capability and capacity. The shipbuilding and ship repair industry is projected to lose approximately 33% of skilled workforce and 48% of management by 2028. With an aging workforce and an incoming digital generation that excels in tech savviness, flexibility, global thinking, and multi-tasking it is crucial to be innovative in workforce development. The Virginia Digital Shipbuilding Program responds to this need by providing a process and platform to address education, training, adoption of innovative new technology and the ability to provide real-time solutions to current and future industry problems. This paper will focus on the three pillars of Digital Shipbuilding – Career Pathway Mapping and Curriculum Development, Outreach and Workforce Development, and Research and Development. Additionally, this paper will address how the team is ensuring that stackable, transferable education and certification processes are implemented between military and industry to facilitate the transition of veterans to the civilian workforce",,https://core.ac.uk/download/552144602.pdf,137609625,virginia digital shipbuilding program (vdsp): building an agile modern workforce to improve performance in the shipbuilding and ship repair industry,2020-06-01T08:00:00,ODU Digital Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Modern technology has excelled at an unprecedented rate. The rise of artificial intelligence raises many ethical questions and concerns for humanity, as it has incited many pressing debates between philosophers, computer scientists, and social critics who share concerns for the future of humanity but conflict with one another regarding whether or not we should rely on technology to govern human affairs and control society\u27s infrastructures. Drawing from Martin Heidegger, Jacques Ellul, Hubert Dreyfus, and others, this project weighs out the probabilities and problems of the technological singularity posited by Ray Kurzweil, confronting our habits of addressing technology and the way we model ourselves off of computational AI. And then, finally, what it means to regain human agency and remain spiritually and ethically accountable for the roles we play",,https://core.ac.uk/download/586157606.pdf,149015401,cutting the puppet strings: confronting the singularity,2023-01-01T08:00:00,Bard Digital Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Without writing a single line of code by a human, an example Monte Carlo
simulation based application for stochastic dependence modeling with copulas is
developed using a state-of-the-art large language model (LLM) fine-tuned for
conversations. This includes interaction with ChatGPT in natural language and
using mathematical formalism, which, under careful supervision by a
human-expert, led to producing a working code in MATLAB, Python and R for
sampling from a given copula model, evaluation of the model's density,
performing maximum likelihood estimation, optimizing the code for parallel
computing for CPUs as well as for GPUs, and visualization of the computed
results. In contrast to other emerging studies that assess the accuracy of LLMs
like ChatGPT on tasks from a selected area, this work rather investigates ways
how to achieve a successful solution of a standard statistical task in a
collaboration of a human-expert and artificial intelligence (AI). Particularly,
through careful prompt engineering, we separate successful solutions generated
by ChatGPT from unsuccessful ones, resulting in a comprehensive list of related
pros and cons. It is demonstrated that if the typical pitfalls are avoided, we
can substantially benefit from collaborating with an AI partner. For example,
we show that if ChatGPT is not able to provide a correct solution due to a lack
of or incorrect knowledge, the human-expert can feed it with the correct
knowledge, e.g., in the form of mathematical theorems and formulas, and make it
to apply the gained knowledge in order to provide a solution that is correct.
Such ability presents an attractive opportunity to achieve a programmed
solution even for users with rather limited knowledge of programming
techniques",,http://arxiv.org/abs/2303.18116,142115224,"pair programming with large language models for sampling and estimation
  of copulas",2023-03-31T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The article highlights the issues of personalized learning as the global
trend of the modern ICTbased educational systems development. The notion, the
main stages of evolution, the main features and principles of adaptive learning
systems application for teachers training are outlined. It is emphasized that
the use and elaboration of the adaptive cloud-based learning systems are
essential to provide sustainable development of teachers education. The current
trends and peculiarities of the cloud-based adaptive learning systems
development and approach of their implementation for teachers training are
considered. The general model of the adaptive cloud-based learning system
structure is proposed. The main components of the model are described; the
issues of tools and services selection are outlined. The methods of the
cloudbased learning components introduction within the adaptive systems of
teacher training are considered. The current research developments of modeling
and implementation of the adaptive cloud-based systems are outlined.Comment: 8 pages, 2 figures, E3S Web of Conferences (166). ISSN 2267-124",10.1051/e3sconf/202016610015,https://core.ac.uk/download/543480800.pdf,86254288,"personalization of learning through adaptive technologies in the context
  of sustainable development of teachers education",2020-01-01T00:00:00,'EDP Sciences',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"© Springer International Publishing AG 2017. This paper describes the use of Intelligent Agents and Ontologies to implement knowledge navigation and learner choice when interacting with complex information locations. The paper is in two parts: the first looks at how Agent Based Semantic Technology can be used to give users a more personalised experience as an individual. The paper then looks to generalise this technology to allow users to work with agents in hybrid group scenarios. In the context of University Learners, the paper outlines how we employ an Ontology of Student Characteristics to personalise information retrieval specifically suited to an individual’s needs. Choice is not a simple “show me your hand and make me a match” but a deliberative artificial intelligence (AI) that uses an ontologically informed agent society to consider the weighted solution paths before choosing the appropriate best. The aim is to enrich the student experience and significantly re-route the student’s journey. The paper uses knowledge-level interoperation of agents to personalise the learning space of students and deliver to them the information and knowledge to suite them best. The aim is to personalise their learning in the presentation/format that is most appropriate for their needs. The paper then generalises this Semantic Technology Framework using shared vocabulary libraries that enable individuals to work in groups with other agents, which might be other people or actually be AIs. The task they undertake is a formal assessment but the interaction mode is one of informal collaboration. Pedagogically this addresses issues of ensuring fairness between students since we can ensure each has the same experience (as provided by the same set of Agents) as each other and an individual mark may be gained. This is achieved by forming a hybrid group of learner and AI Software Agents. Different agent architectures are discussed and a worked example presented. The work here thus aims at fulfilling the student’s needs both in the context of matching their needs but also in allowing them to work in an Agent Based Synthetic Group. This in turn opens us new areas of potential collaborative technology",10.1007/978-3-319-58515-4_27,https://core.ac.uk/download/151162193.pdf,17700999,collaborative hybrid agent provision of learner needs using ontology based semantic technology,2017-05-16T00:00:00,'Springer Science and Business Media LLC',"[{'title': None, 'identifiers': ['0302-9743']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Increased dependence of the maritime industry on information and
communication networks has made shipboard power systems vulnerable to stealthy
cyber-attacks. One such attack variant, called rootkit, can leverage system
knowledge to hide its presence and allow remotely located malware handlers to
gain complete control of infected subsystems. This paper presents a
comprehensive evaluation of the threat landscape imposed by such attack
variants on Medium Voltage DC (MVDC) shipboard microgrids, including a
discussion of their impact on the overall maritime sector in general, and
provides several simulation results to demonstrate the same. It also analyzes
and presents the actions of possible defense mechanisms, with specific emphasis
on evasion, deception, and detection frameworks, that will help ship operators
and maritime cybersecurity professionals protect their systems from such
attacks.Comment: 2023 IEEE Electric Ship Technologies Symposium (ESTS",,http://arxiv.org/abs/2305.18667,143043383,"lost at sea: assessment and evaluation of rootkit attacks on shipboard
  microgrids",2023-05-29T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The main purpose of this research is to investigate the effects of artificial intelligence, which has increased its popularity in recent years, on the purchasing behaviors of consumers, which have existed since the first ages, in order to meet their needs. In the study, primarily consumer behaviors are explained. Afterward, a literature search was conducted on the emergence and development of artificial intelligence. Finally, the effects of these two concepts on each other were analyzed",10.22158/ibes.v5n2p52,https://core.ac.uk/download/567826271.pdf,148239436,a theoretical approach to artificial intelligence in consumer behavior,2023-04-04T01:00:00,"'Scholink Co, Ltd.'",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Until the beginning of the twentieth century, history, as a core concept of the political project of modernity, was highly concerned with the future. The many crimes, genocides, and wars perpetuated in the name of historical progress eventually caused unavoidable fractures in the way Western philosophies of history have understood change over time, leading to a depoliticization of the future and a greater emphasis on matters of the present. However, the main claim of the “Historical Futures” project is that the future has not completely disappeared from the focus of historical thinking, and some modalities of the future that have been brought to the attention of historical thought relate to a more-than-human reality. This article aims to confront the prospects of a technological singularity through the eyes of peoples who already live in a world of more-than-human agency. The aim of this confrontation is to create not just an alternative way to think about the future but a stance from which we can explore ways to inhabit and therefore repoliticize historical futures. This article contains a comparative study that has been designed to challenge our technologized imaginations of the future and, at the same time, to infuse the theoretical experiment with contingent historical experiences. Could we consider artificial intelligence as a new historical subject? What about as an agent in a “more-than-human” history? To what extent can we read this new condition through ancient Amerindian notions of time? Traditionally, the relationship between Western anthropocentrism and Amerindian anthropomorphism has been framed in terms of an opposition. We intend to prefigure a less hierarchical and more horizontal relation between systems of thought, one devoid of a fixed center or parameter of reference. Granting the same degree of intellectual dignity to the works of Google engineers and the views of Amazonian shamans, we nevertheless foster an intercultural dialogue (between these two “traditions of reasoning”) about a future in which history can become more-than-human. We introduce potential history as the framework not only to conceptualize Amerindian experiences of time but also to start building an intercultural dialogue that is designed to discuss AI as a historical subject",10.17169/refubium-37866,https://core.ac.uk/download/568239099.pdf,145345484,potential history: reading artificial intelligence from indigenous knowledges,2023-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Large language models (LLMs) such as ChatGPT are increasingly being used for
various use cases, including text content generation at scale. Although
detection methods for such AI-generated text exist already, we investigate
ChatGPT's performance as a detector on such AI-generated text, inspired by
works that use ChatGPT as a data labeler or annotator. We evaluate the
zero-shot performance of ChatGPT in the task of human-written vs. AI-generated
text detection, and perform experiments on publicly available datasets. We
empirically investigate if ChatGPT is symmetrically effective in detecting
AI-generated or human-written text. Our findings provide insight on how ChatGPT
and similar LLMs may be leveraged in automated detection pipelines by simply
focusing on solving a specific aspect of the problem and deriving the rest from
that solution. All code and data is available at
\url{https://github.com/AmritaBh/ChatGPT-as-Detector}.Comment: to appear in SIGKDD Exploration",,http://arxiv.org/abs/2308.01284,144970985,fighting fire with fire: can chatgpt detect ai-generated text?,2023-08-02T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Student newspaper of the University of Montana, Missoula.https://scholarworks.umt.edu/studentnewspaper/11118/thumbnail.jp",,https://core.ac.uk/download/571288805.pdf,145731287,"montana kaimin, april 13, 2023",2023-04-13T08:00:00,ScholarWorks at University of Montana,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Artificially Intelligent (AI) communicators represent a new type of actor within public discourse. These entities have played influential roles in recent elections in the U.S. and Europe. This Article examines expression rights for AI actors through the lenses provided by the foundational assumptions of the marketplace of ideas theory and existing free-expression-related rationales regarding non-human actors in the U.S. and European legal systems. The Article contends that the fundamental assumptions of the marketplace model must be revised to focus on the flow of information, the development of truth, rather than the more Enlightenment-oriented competition of ideas that leads to the discovery of truth. Such a shift would allow limitations on AI that harm the flow of ideas, but otherwise protect AI expression that contributes to democratic discourse",,https://scholarship.law.wm.edu/cgi/viewcontent.cgi?article=1937&amp;context=wmborj,73561364,saving the marketplace from market failure: reorienting marketplace theory in the era of ai communicators,2020-06-18T20:50:43,William & Mary Law School Scholarship Repository,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"System logs record detailed information about system operation and are important for analyzing the system\u27s operational status and performance. Rapid and accurate detection of system anomalies is of great significance to ensure system stability. However, large-scale distributed systems are becoming more and more complex, and the number of system logs gradually increases, which brings challenges to analyze system logs. Some recent studies show that logs can be unstable due to the evolution of log statements and noise introduced by log collection and parsing. Moreover, deep learning-based detection methods take a long time to train models. Therefore, to reduce the computational cost and avoid log instability we propose a new Word2Vec-based log unsupervised anomaly detection method (LogUAD). LogUAD does not require a log parsing step and takes original log messages as input to avoid the noise. LogUAD uses Word2Vec to generate word vectors and generates weighted log sequence feature vectors with TF-IDF to handle the evolution of log statements. At last, a computationally efficient unsupervised clustering is exploited to detect the anomaly. We conducted extensive experiments on the public dataset from Blue Gene/L (BGL). Experimental results show that the F1-score of LogUAD can be improved by 67.25% compared to LogCluster",,https://core.ac.uk/download/480766118.pdf,11576589,loguad: log unsupervised anomaly detection based on word2vec,2022-01-01T08:00:00,ZU Scholars,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"As digital technologies become the dominant driver of the global economy, Africa finds itself once again faced with the prospect of developmental stagnation. In an increasingly technological age, parallels to the colonial era can be made, particularly in reference to the detrimental impact on the African economy and the continent’s developmental trajectory. AI, which drives these technologies, is informed by algorithms. The biases inherent in these algorithms lead to digital discrimination. This discrimination has resulted in a new form of colonialism, referred to as digital neocolonialism, which denotes the exclusionary barrier that has been created by algorithms. This work challenges algorithmic bias through the application of postcolonial theory, which calls for a dismantling of colonial imposition by reimagining and reframing the concept of the ‘other’. The gaps in current AI systems, and the power imbalances created, are interrogated through an analysis of bias and its impact. Through a postcolonial lens, a call is made for more inclusive AI systems, and datasets that challenges the assumed neutrality of algorithms",10.2218/scrip.20.2.2023.8980,https://core.ac.uk/download/588477053.pdf,152516317,postcolonial differentials in algorithmic bias: challenging digital neo-colonialism in africa,2023-08-10T01:00:00,University of Edinburgh,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The twenty-ninth edition of the SEBD (Italian Symposium on Advanced Database Systems), held on 5-9 September 2021 in Pizzo (Calabria Region, Italy), included a joint seminar on “Reminiscence of TIDB 1981” with invited talks given by some of the participants to the Advanced Seminar on Theoretical Issues in Databases (TIDB), which took place in the same region exactly forty years earlier. The joint seminar was concluded by a Panel on “The Past and the Future of Computer Science Theory” with the participation of four distinguished computer science theorists (Ronald Fagin, Georg Gottlob, Christos Papadimitriou and Moshe Vardi), who were interviewed by Giorgio Ausiello, Maurizio Lenzerini, Luigi Palopoli, Domenico Saccà and Francesco Scarcello. This paper reports the summaries of the four interviews",,https://core.ac.uk/download/567874982.pdf,144987455,panel on “past and future of computer science theory”,2021-10-31T01:00:00,CEUR Workshop Proceedings,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The Tech Policy Lab at the University of Washington has become an indispensable source for tech policy research, education, and local, national, and international thought leadership. The Lab has worked directly with policymakers, published research and guides on emerging technologies, and provided opportunities for the public to learn from experts.https://digitalcommons.law.uw.edu/techlab/1011/thumbnail.jp",,https://core.ac.uk/download/287178296.pdf,77854723,"annual report, 2018",2018-08-01T08:00:00,UW Law Digital Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper presents an agent responsibility framework that can be used to identify, describe, and analyze many possible roles that algorithmic agents might perform for information systems and other work systems, including those involving robotic process automation. The two dimensions of the framework are 1) a spectrum of possible roles for algorithmic agents and 2) a set of facets of work to which algorithmic agents might be applied in work systems. This paper explains those ideas, applies two examples to illustrate their potential use, discusses alternative ways to use the framework, and identifies areas for future research",,https://core.ac.uk/download/529573435.pdf,128989323,responsibility modeling for operational contributions of algorithmic agents,2022-08-10T08:00:00,AIS Electronic Library (AISeL),[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We propose a method to fuse frozen text-only large language models (LLMs)
with pre-trained image encoder and decoder models, by mapping between their
embedding spaces. Our model demonstrates a wide suite of multimodal
capabilities: image retrieval, novel image generation, and multimodal dialogue.
Ours is the first approach capable of conditioning on arbitrarily interleaved
image and text inputs to generate coherent image (and text) outputs. To achieve
strong performance on image generation, we propose an efficient mapping network
to ground the LLM to an off-the-shelf text-to-image generation model. This
mapping network translates hidden representations of text into the embedding
space of the visual models, enabling us to leverage the strong text
representations of the LLM for visual outputs. Our approach outperforms
baseline generation models on tasks with longer and more complex language. In
addition to novel image generation, our model is also capable of image
retrieval from a prespecified dataset, and decides whether to retrieve or
generate at inference time. This is done with a learnt decision module which
conditions on the hidden representations of the LLM. Our model exhibits a wider
range of capabilities compared to prior multimodal language models. It can
process image-and-text inputs, and produce retrieved images, generated images,
and generated text -- outperforming non-LLM based generation models across
several text-to-image tasks that measure context dependence.Comment: Project page: http://jykoh.com/gil",,http://arxiv.org/abs/2305.17216,143042654,generating images with multimodal language models,2023-05-26T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"With the advent of cloud computing, the Internet of Things (IoT), and mobile computing, CS faculty are continuously revamping the curriculum material to address such burgeoning set of technologies in practical and relatable ways. Raspberry Pi (RPi) devices represent an ideal hardware/software framework that embodies all these technologies through its simple architecture, small form factor (that minimizes the volume and footprint of a desktop computer), and ability to integrate various sensors that network together and connect to the Cloud. Therefore, one of the strategies of Computer Science Department, to enhance depth of learning concepts, has been to infuse Raspberry Pi (RPi) in computer science courses. RPi has been incorporated since 2016 in targeted courses, notably, Computer Organization & Assembly Language, Computer Architecture, Database Management Design & Implementation, Unix/Linux Programming, Internet Programming, and Senior Project. An inexpensive credit card sized computer, an RPi lends itself to allow depth of learning of concepts. From implementing firewalls, intrusion detection systems, scripting, client-server based computing, distributed computing, to interfacing with sensors and actuators, a student is guided to polish concepts taught in a class through RPi Project Based Learning (RPBL). Computer science curriculum already provides breadth of learning. The infusion of RPi in key courses provides depth in targeted concepts. There are peripheral desirable consequences as well, including a student learning prevalently used Linux environment even though a targeted course may have nothing directly to do with Linux. Furthermore, RPi provides an opportunity for students to realize that software programs can be interfaced with sensors and actuators to provide immersed experience in programming. From simply interfacing a switch and a Light Emitting Diode (LED) to getting data from sensors, buffering, and uploading to the cloud, a student already would have touched upon multiple disciplines in computer science. This paper provides a blueprint to infusing RPi in the targeted courses, and how each RPi based project provides depth to a targeted concept",,https://core.ac.uk/download/335268322.pdf,89848071,infusing raspberry pi in the computer science curriculum for enhanced learning,2020-06-22T08:00:00,ScholarWorks @ UTRGV,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We consider the problem of a neural network being requested to classify
images (or other inputs) without making implicit use of a ""protected concept"",
that is a concept that should not play any role in the decision of the network.
Typically these concepts include information such as gender or race, or other
contextual information such as image backgrounds that might be implicitly
reflected in unknown correlations with other variables, making it insufficient
to simply remove them from the input features. In other words, making accurate
predictions is not good enough if those predictions rely on information that
should not be used: predictive performance is not the only important metric for
learning systems. We apply a method developed in the context of domain
adaptation to address this problem of ""being right for the right reason"", where
we request a classifier to make a decision in a way that is entirely 'agnostic'
to a given protected concept (e.g. gender, race, background etc.), even if this
could be implicitly reflected in other attributes via unknown correlations.
After defining the concept of an 'agnostic model', we demonstrate how the
Domain-Adversarial Neural Network can remove unwanted information from a model
using a gradient reversal layer.Comment: Author's original versio",10.1007/978-3-030-01768-2_14,https://core.ac.uk/download/161770328.pdf,52212881,right for the right reason: training agnostic networks,2018-06-16T01:00:00,'Springer Science and Business Media LLC',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The unclear development direction of human society is a deep reason for that
it is difficult to form a uniform ethical standard for human society and
artificial intelligence. Since the 21st century, the latest advances in the
Internet, brain science and artificial intelligence have brought new
inspiration to the research on the development direction of human society.
Through the study of the Internet brain model, AI IQ evaluation, and the
evolution of the brain, this paper proposes that the evolution of population
knowledge base is the key for judging the development direction of human
society, thereby discussing the standards and norms for the construction of
artificial intelligence ethics.Comment: 12 pages, 6 figures,1 tabl",10.1007/978-3-030-01313-4_48,http://arxiv.org/abs/1806.10095,52214958,"research on artificial intelligence ethics based on the evolution of
  population knowledge base",2018-11-02T00:00:00,'Springer Science and Business Media LLC',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In the early months of 2020, the SARS-CoV-2 Coronavirus took the world by surprise, resulting in the COVID-19 pandemic that has caused significant loss of lives and challenged the sustainability of our health care systems. In mid-March, it became obvious that government and communities had to react immediately. Under the lead of the Mayo Clinic and The MITRE Corporation, the COVID-19 Healthcare Coalition (C19HCC) was established as a coordinated public-interest, private-sector response. The coalition brought healthcare organizations, technology firms, nonprofits, academia, and startups to support supply chains, inform coordinated social policies, and provide data-driven insights to protect people and preserve the healthcare delivery system. The coalition quickly reached more than 1000 member organizations, many of them working in computational fields. Although the efforts focused on the United States, we had several international partners who not only observed, but also contributed to the efforts",10.1109/mcse.2020.3036586,https://core.ac.uk/download/580021465.pdf,148550429,computational decision support for the covid-19 healthcare coalition,2021-01-01T08:00:00,ODU Digital Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper hypothesizes that harmful utterances need to be judged in the context of whole sentences, and the authors extract features of harmful expressions using a general-purpose language model. Based on the extracted features, the authors propose a method to predict the presence or absence of harmful categories. In addition, the authors believe that it is possible to analyze users who incite others by combining this method with research on analyzing the personality of the speaker from statements on social networking sites. The results confirmed that the proposed method can judge the possibility of harmful comments with higher accuracy than simple dictionary-based models or models using a distributed representation of words. The relationship between personality patterns and harmful expressions was also confirmed by an analysis based on a harmful judgment model",,https://core.ac.uk/download/521170723.pdf,126024670,relationship between personality patterns and harmfulness : analysis and prediction based on sentence embedding,2022-02-28T00:00:00,'IGI Global',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"From July 16-to November 8, 2019, the Aida digital libraries research team at the University of Nebraska-Lincoln collaborated with the Library of Congress on “Digital Libraries, Intelligent Data Analytics, and Augmented Description: A Demonstration Project.“ This demonstration project sought to (1) develop and investigate the viability and feasibility of textual and image-based data analytics approaches to support and facilitate discovery; (2) understand technical tools and requirements for the Library of Congress to improve access and discovery of its digital collections; and (3) enable the Library of Congress to plan for future possibilities. In pursuit of these goals, we focused our work around two areas: extracting and foregrounding visual content from Chronicling America (chroniclingamerica.loc.gov) and applying a series of image processing and machine learning methods to minimally processed manuscript collections featured in By the People (crowd.loc.gov). We undertook a series of explorations and investigated a range of issues and challenges related to machine learning and the Library’s collections.
This final report details the explorations, addresses social and technical challenges with regard to the explorations and that are critical context for the development of machine learning in the cultural heritage sector, and makes several recommendations to the Library of Congress as it plans for future possibilities. We propose two top-level recommendations. First, the Library should focus the weight of its machine learning efforts and energies on social and technical infrastructures for the development of machine learning in cultural heritage organizations, research libraries, and digital libraries. Second, we recommend that the Library invest in continued, ongoing, intentional explorations and investigations of particular machine learning applications to its collections. Both of these top-level recommendations map to the three goals of the Library’s 2019 digital strategy.
Within each top-level recommendation, we offer three more concrete, short- and medium-term recommendations. They include, under social and technical infrastructures: (1) Develop a statement of values or principles that will guide how the Library of Congress pursues the use, application, and development of machine learning for cultural heritage. (2) Create and scope a machine learning roadmap for the Library that looks both internally to the Library of Congress and its needs and goals and externally to the larger cultural heritage and other research communities. (3) Focus efforts on developing ground truth sets and benchmarking data and making these easily available. Nested under the recommendation to support ongoing explorations and investigations, we recommend that the Library: (4) Join the Library of Congress’s emergent efforts in machine learning with its existing expertise and leadership in crowdsourcing. Combine these areas as “informed crowdsourcing” as appropriate. (5) Sponsor challenges for teams to create additional metadata for digital collections in the Library of Congress. As part of these challenges, require teams to engage across a range of social and technical questions and problem areas. (6) Continue to create and support opportunities for researchers to partner in substantive ways with the Library of Congress on machine learning explorations. Each of these recommendations speak to the investigation and challenge areas identified by Thomas Padilla in Responsible Operations: Data Science, Machine Learning, and AI in Libraries.
This demonstration project—via its explorations, discussion, and recommendations—shows the potential of machine learning toward a variety of goals and use cases, and it argues that the technology itself will not be the hardest part of this work. The hardest part will be the myriad challenges to undertaking this work in ways that are socially and culturally responsible, while also upholding responsibility to make the Library of Congress’s materials available in timely and accessible ways. Fortunately, the Library of Congress is in a remarkable position to advance machine learning for cultural heritage organizations, through its size, the diversity of its collections, and its commitment to digital strategy",,https://core.ac.uk/download/345177580.pdf,96086140,"digital libraries, intelligent data analytics, and augmented description: a demonstration project",2020-01-10T08:00:00,DigitalCommons@University of Nebraska - Lincoln,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The future of the arts and artificial intelligence (AI) is promising as
technology advances. As the use of AI in design becomes more widespread, art
practice may not be a human-only art form and could instead become a digitally
integrated experience. With enhanced creativity and collaboration, arts and AI
could work together towards creating artistic outputs that are visually
appealing and meet the needs of the artist and viewer. While it is uncertain
how far the integration will go, arts and AI will likely influence one another.
This workshop pictorial puts forward first-person research that shares
interactions between an HCI researcher and AI as they try to escape the
creative block. The pictorial paper explores two questions: How can AI support
artists' creativity, and what does it mean to be explainable in this context?
HIs, ChatGPT and Midjourney were engaged; the result was a series of
reflections that require further discussion and explorations in the XAIxArts
community: Transparency of attribution, the creation process, ethics of asking,
and inspiration vs copying.Comment: 1st International Workshop on Explainable AI for the Arts (XAIxArts),
  ACM Creativity and Cognition (C&C) 2023. Online, 6 pages.
  https://xaixarts.github.i",,http://arxiv.org/abs/2308.11424,146202696,"aixartist: a first-person tale of interacting with artificial
  intelligence to escape creative block",2023-08-22T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Abstract—The main objective is development of hybrid systems for adaptive designing and supply chain management / strategizing of team decision “packages” for design work based on the use of soft computing technologies and system-creative thinking (SCT). An algorithm is proposed, and the results of case studies on predicting the effectiveness and optimal organization of team thinking, as well as designing team solutions using the technical package of social technologies are presented. They are exemplified by developing a system of products and marketing channels (points of contact) of an employer brand (EB) of an organization for individual stakeholder groups. An algorithm has been developed for using a system of hybrid “soft computing” technologies and system-creative thinking in supply chain process of project teamwork; practical calculations have been carried out using this algorithm. The algorithm and systems of models for using “soft computing” for supply chain developed allow us to obtain a synergistic effect from controlling a system of hybrid technologies at various stages of teamwork. The package includes a “basic” technology comprising “training teams”, and also the formation of a KPI system that characterize team work (units 1 and 2), “product” technologies comprising analysis of team organization thinking, forecasting team performance, team productivity management, as well as supply chain management of project (units 4, 5, 6), and also “closing” technology being a strategizing (adaptive management) of team work (dynamic control of the algorithm as a whole)",,https://core.ac.uk/download/354476137.pdf,99630301,hybrid systems of soft computing technologies in designing team decision for supply chain management systems of organizations,2020-08-28T01:00:00,International Journal of Supply Chain Management,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Communication protocols are central to engineering decentralized multiagent systems. Modern protocol languages are typically formal and address aspects of decentralization, such as asynchrony. However, modern languages differ in important ways in their basic abstractions and operational assumptions. This diversity makes a comparative evaluation of protocol languages a challenging task. We contribute a rich evaluation of diverse and modern protocol languages. Among the selected languages, Scribble is based on session types; Trace-C and Trace-F on trace expressions; HAPN on hierarchical state machines, and BSPL on information causality. Our contribution is four-fold. One, we contribute important criteria for evaluating protocol languages. Two, for each criterion, we compare the languages on the basis of whether they are able to specify elementary protocols that go to the heart of the criterion. Three, for each language, we map our findings to a canonical architecture style for multiagent systems, highlighting where the languages depart from the architecture. Four, we identify design principles for protocol languages as guidance for future research",10.1613/jair.1.12212,https://core.ac.uk/download/345683982.pdf,18623932,an evaluation of communication protocol languages for engineering multiagent systems,2020-08-04T01:00:00,'AI Access Foundation',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Online discussion forums are widely used for active textual interaction between lecturers and students, and to see how the students have progressed in a learning process. The objective of this study is to compare appropriate machine-learning models to assess sentiments and Bloom’s epistemic taxonomy based on textual comments in educational discussion forums. The proposed method is called the hierarchical approach of Bloom-Epistemic and Sentiment Analysis (BE-Sent). The research methodology consists of three main steps. The first step is the data collection from the internal discussion forum and YouTube comments of a Web Programming channel. The next step is text preprocessing to annotate the text and clear unimportant words. Furthermore, with the text dataset that has been successfully cleaned, sentiment analysis and epistemic categorization will be done in each sentence of the text. Sentiment analysis is divided into three categories: positive, negative, and neutral. Bloom’s epistemic is divided into six categories: remembering, understanding, applying, analyzing, evaluating, and creating. This research has succeeded in producing a course learning subsystem that assesses opinions based on text reviews of discussion forums according to the category of sentiment and epistemic analysis",10.11591/ijere.v13i1.26024,https://core.ac.uk/download/593767928.pdf,152045319,bloom-epistemic and sentiment analysis hierarchical classification in course discussion forums,2024-02-01T00:00:00,Institute of Advanced Engineering and Science,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Self-modification is an ancient human practice; however, for the first time in history, technology is enabling us to modify our lives not only at an existential or experiential level, but also at an informational level. This paper discusses Foucault’s concept of “technologies of the self” as well as some of its recent interpretations within contemporary philosophy of technology. It shows how ICTs have opened new dimensions for humans to transform their bodies, minds, and self-conception. It argues that while ‘traditional’ self-modification is being revolutionised and popularised by ICTs, these systems are also exposing us to potent, and unintentional forms of ontological tinkering. Ultimately, this paper shows how Foucault’s concept can serve as a valuable tool for understanding contemporary human-technology relations",10.7559/citarj.v9i3.423,https://core.ac.uk/download/480542248.pdf,122814563,technology and self-modification: understanding technologies of the self after foucault,2017-09-01T01:00:00,'Universidade Catolica Portuguesa',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"High Performance Computing (HPC) is the ability to process data and perform complex calculations at extremely high speeds. Current HPC platforms can achieve calculations on the order of quadrillions of calculations per second with quintillions on the horizon. The past three decades witnessed a vast increase in the use of HPC across different scientific, engineering and business communities, for example, sequencing the genome, predicting climate changes, designing modern aerodynamics, or establishing customer preferences. Although HPC has been well incorporated into science curricula such as bioinformatics, the same cannot be said for most computing programs. This working group will explore how HPC can make inroads into computer science education, from the undergraduate to postgraduate levels. The group will address research questions designed to investigate topics such as identifying and handling barriers that inhibit the adoption of HPC in educational environments, how to incorporate HPC into various curricula, and how HPC can be leveraged to enhance applied critical thinking and problem solving skills. Four deliverables include: (1) a catalog of core HPC educational concepts, (2) HPC curricula for contemporary computing needs, such as in artificial intelligence, cyberanalytics, data science and engineering, or internet of things, (3) possible infrastructures for implementing HPC coursework, and (4) HPC-related feedback to the CC2020 project",10.1145/3341525.3394989,https://core.ac.uk/download/595487864.pdf,152278944,toward high performance computing education,2020-06-15T08:00:00,Smith ScholarWorks,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We present two novel algorithms for learning formulas in Linear Temporal
Logic (LTL) from examples. The first learning algorithm reduces the learning
task to a series of satisfiability problems in propositional Boolean logic and
produces a smallest LTL formula (in terms of the number of subformulas) that is
consistent with the given data. Our second learning algorithm, on the other
hand, combines the SAT-based learning algorithm with classical algorithms for
learning decision trees. The result is a learning algorithm that scales to
real-world scenarios with hundreds of examples, but can no longer guarantee to
produce minimal consistent LTL formulas. We compare both learning algorithms
and demonstrate their performance on a wide range of synthetic benchmarks.
Additionally, we illustrate their usefulness on the task of understanding
executions of a leader election protocol",10.23919/fmcad.2018.8603016,http://arxiv.org/abs/1806.03953,52265419,learning linear temporal properties,2018-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The proposed work focuses on the path planning for Unmanned Surface Vehicles
(USVs) in the ocean enviroment, taking into account various spatiotemporal
factors such as ocean currents and other energy consumption factors. The paper
proposes the use of Gaussian Process Motion Planning (GPMP2), a Bayesian
optimization method that has shown promising results in continuous and
nonlinear path planning algorithms. The proposed work improves GPMP2 by
incorporating a new spatiotemporal factor for tracking and predicting ocean
currents using a spatiotemporal Bayesian inference. The algorithm is applied to
the USV path planning and is shown to optimize for smoothness, obstacle
avoidance, and ocean currents in a challenging environment. The work is
relevant for practical applications in ocean scenarios where an optimal path
planning for USVs is essential for minimizing costs and optimizing performance.Comment: 9 pages and 7 figures, submitted for IEEE Transactions on Man,
  systems ,and Cybernetic",,http://arxiv.org/abs/2307.03355,144552331,optimized path planning for usvs under ocean currents,2023-07-06T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The argument essay, “Just Trust Me,” covers a range of sources, motives, and technologies involved in the spread of disinformation. From Google search results to AI generated content and deep fakes, Wall ultimately argues for regulation of AI and intervention from government organizations rather than banning information. Her argument focuses on the consequences, such as voting or health decisions that can stem from unregulated practices of disinformation.https://digitalcommons.cortland.edu/rhetdragonsargument/1004/thumbnail.jp",,https://core.ac.uk/download/587867957.pdf,149969932,just trust me (2023-2024),2023-01-01T08:00:00,Digital Commons @ Cortland,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In Artificial Intelligence we often seek to identify an unknown target
function of many variables $y=f(\mathbf{x})$ giving a limited set of instances
$S=\{(\mathbf{x^{(i)}},y^{(i)})\}$ with $\mathbf{x^{(i)}} \in D$ where $D$ is a
domain of interest. We refer to $S$ as the training set and the final quest is
to identify the mathematical model that approximates this target function for
new $\mathbf{x}$; with the set $T=\{ \mathbf{x^{(j)}} \} \subset D$ with $T
\neq S$ (i.e. thus testing the model generalisation). However, for some
applications, the main interest is approximating well the unknown function on a
larger domain $D'$ that contains $D$. In cases involving the design of new
structures, for instance, we may be interested in maximizing $f$; thus, the
model derived from $S$ alone should also generalize well in $D'$ for samples
with values of $y$ larger than the largest observed in $S$. In that sense, the
AI system would provide important information that could guide the design
process, e.g., using the learned model as a surrogate function to design new
lab experiments.
  We introduce a method for multivariate regression based on iterative fitting
of a continued fraction by incorporating additive spline models. We compared it
with established methods such as AdaBoost, Kernel Ridge, Linear Regression,
Lasso Lars, Linear Support Vector Regression, Multi-Layer Perceptrons, Random
Forests, Stochastic Gradient Descent and XGBoost. We tested the performance on
the important problem of predicting the critical temperature of superconductors
based on physical-chemical characteristics.Comment: Submitted to IEEE Transactions on Artificial Intelligence (TAI",,http://arxiv.org/abs/2012.03774,107766941,"learning to extrapolate using continued fractions: predicting the
  critical temperature of superconductor materials",2021-11-07T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Prediction of material behavior using machine learning (ML) requires consistent, accurate, and, representative large data for training. However, such consistent and reliable experimental datasets are not always available for materials. To address this challenge, we synergistically integrate ML with high-throughput reactive molecular dynamics (MD) simulations to elucidate the constitutive relationship of calcium–silicate–hydrate (C–S–H) gel—the primary binding phase in concrete formed via the hydration of ordinary portland cement. Specifically, a highly consistent dataset on the nine elastic constants of more than 300 compositions of C–S–H gel is developed using high-throughput reactive simulations. From a comparative analysis of various ML algorithms including neural networks (NN) and Gaussian process (GP), we observe that NN provides excellent predictions. To interpret the predicted results from NN, we employ SHapley Additive exPlanations (SHAP), which reveals that the influence of silicate network on all the elastic constants of C–S–H is significantly higher than that of water and CaO content. Additionally, the water content is found to have a more prominent influence on the shear components than the normal components along the direction of the interlayer spaces within C–S–H. This result suggests that the in-plane elastic response is controlled by water molecules whereas the transverse response is mainly governed by the silicate network. Overall, by seamlessly integrating MD simulations with ML, this paper can be used as a starting point toward accelerated optimization of C–S–H nanostructures to design efficient cementitious binders with targeted properties",,https://core.ac.uk/download/361260546.pdf,40560943,elucidating the constitutive relationship of calcium–silicate–hydrate gel using high throughput reactive molecular simulations and machine learning,2020-01-01T08:00:00,DigitalCommons@URI,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Prediction of material behavior using machine learning (ML) requires consistent, accurate, and, representative large data for training. However, such consistent and reliable experimental datasets are not always available for materials. To address this challenge, we synergistically integrate ML with high-throughput reactive molecular dynamics (MD) simulations to elucidate the constitutive relationship of calcium–silicate–hydrate (C–S–H) gel—the primary binding phase in concrete formed via the hydration of ordinary Portland cement. Specifically, a highly consistent dataset on the nine elastic constants of more than 300 compositions of C–S–H gel is developed using high-throughput reactive simulations. From a comparative analysis of various ML algorithms including neural networks (NN) and Gaussian process (GP), we observe that NN provides excellent predictions. To interpret the predicted results from NN, we employ SHapley Additive exPlanations (SHAP), which reveals that the influence of silicate network on all the elastic constants of C–S–H is significantly higher than that of water and CaO content. Additionally, the water content is found to have a more prominent influence on the shear components than the normal components along the direction of the interlayer spaces within C–S–H. This result suggests that the in-plane elastic response is controlled by water molecules whereas the transverse response is mainly governed by the silicate network. Overall, by seamlessly integrating MD simulations with ML, this paper can be used as a starting point toward accelerated optimization of C–S–H nanostructures to design efficient cementitious binders with targeted properties",,https://digitalcommons.georgefox.edu/cgi/viewcontent.cgi?article=1115&context=mece_fac,134109306,elucidating the costitutive relationship of calcium-silicate-hydrate gel using high throughput reactive molecular simulations and machine learning,2020-01-01T08:00:00,Digital Commons @ George Fox University,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"As a result of the analysis of dispatcher intelligence centers and aerial, land, underground, underwater, universal, and functionally focused artificial intelligence robotics systems, the problems of rational control, due to be performed under specific conditions of uncertainties, are chosen for probabilistic study. The choice covers the problems of planning the possibilities of functions performance on the base of monitored information about events and conditions and the problem of robot route optimization under limitations on risk of “failure” in conditions of uncertainties. These problems are resolved with a use of the proposed probabilistic approach. The proposed methods are based on selected probabilistic models (for “black box” and complex systems), which are implemented effectively in wide application areas. The cognitive solving of problems consists in improvements, accumulation, analysis, and use of appearing knowledge. The described analytical solutions are demonstrated by practical examples",10.5772/intechopen.89168,https://core.ac.uk/download/322444658.pdf,10908326,probabilistic methods for cognitive solving of some problems in artificial intelligence systems,2019-09-28T00:00:00,'IntechOpen',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We evaluated ChatGPT 3.5, 4, and 4 with Code Interpreter on a set of
college-level engineering-math and electromagnetism problems, such as those
often given to sophomore electrical engineering majors. We selected a set of 13
problems, and had ChatGPT solve them multiple times, using a fresh instance
(chat) each time. We found that ChatGPT-4 with Code Interpreter was able to
satisfactorily solve most problems we tested most of the time -- a major
improvement over the performance of ChatGPT-4 (or 3.5) without Code
Interpreter. The performance of ChatGPT was observed to be somewhat stochastic,
and we found that solving the same problem N times in new ChatGPT instances and
taking the most-common answer was an effective strategy. Based on our findings
and observations, we provide some recommendations for instructors and students
of classes at this level.Comment: Main text and appendice",,http://arxiv.org/abs/2309.08881,148053022,"chatgpt-4 with code interpreter can be used to solve introductory
  college-level vector calculus and electromagnetism problems",2023-09-16T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Over the past decade, perovskite solar cells have become one of the major research interests of the photovoltaic community, and they are now on the brink of catching up with the classical inorganic solar cells, with efficiency now reaching up to 25%. However, significant improvements are still achievable by reducing recombination losses. The aim of this work is to develop a fast and easy-to-use tool to pinpoint the main losses in perovskite solar cells. We use large-scale drift-diffusion simulations to get a better understanding of the light intensity dependence of the open-circuit voltage and how it correlates to the dominant recombination process. We introduce an automated identification tool using machine learning methods to pinpoint the dominant loss using the light intensity-dependent performances as an input. The machine learning was trained using >2 million simulations and gives an accuracy of the prediction up to 82%. Le Corre et al. demonstrate the application of machine learning methods to identify the dominant recombination process in perovskite solar cells with 82% accuracy. The machine learning algorithms are trained and tested using large-scale drift-diffusion simulations, and their applicability on real solar cells is also demonstrated on devices previously reported",10.1016/j.xcrp.2021.100346,https://core.ac.uk/download/534954413.pdf,128076436,identification of the dominant recombination process for perovskite solar cells based on machine learning,2021-02-24T00:00:00,'Elsevier BV',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Augmented reality is currently a great interest in biomedical health informatics. At the same time, several challenges have been appeared, in particular with the rapid progress of smart sensors technologies, and medical artificial intelligence. This yields the necessity of new needs in biomedical health informatics. Collaborative learning and privacy are some of the challenges of augmented reality technology in biomedical health informatics. This paper introduces a novel secure collaborative augmented reality framework for biomedical health informatics-based applications. Distributed deep learning is first performed across a multi-agent system platform. The privacy strategy is developed for ensuring better communications of the different intelligent agents in the system. In this research work, a system of multiple agents is created for the simulation of the collective behaviours of the smart components of biomedical health informatics. Augmented reality is also incorporated for better visualization of the resulted medical patterns. A novel privacy strategy based on blockchain is investigated for ensuring the confidentiality of the learning process. Experiments are conducted on the real use case of the biomedical segmentation process. Our strong experimental analysis reveals the strength of the proposed framework when directly compared to state-of-the-art biomedical health informatics solutions.acceptedVersio",10.1109/jbhi.2021.3139575,https://core.ac.uk/download/539603641.pdf,127024467,secure collaborative augmented reality framework for biomedical informatics,2021-01-01T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The continued advancement in innovation and technology continues to radically change what is believed to be possible. The progress of technology particularly in the field of entertainment has been most profound. In 1995, British musician, David Bowie and a colleague, Ty Roberts, created the Verbalizer – a program which could take up to 25 sentences and groups of words, rearrange them aleatorically into different combination and by so doing, create new lyrics. In 2016 researchers at Sony took the concept of Artificial Intelligence music a step further. Using a software called Flow Machines they created a melody in the style of The Beatles. In this article we consider the place of works created by Artificial Intelligence, the status of such works as intellectual property and who the owners of such intellectual property should be where Artificial Intelligence is involved in the creative process. This article argues that works created by artificial intelligence software and robots ought to qualify as intellectual property provided other requirements (such as originality) are met. The article however queries whether such intellectual property rights should lie with human inventors or the artificial intelligence. This work also recommends that the extant laws on the recognition and protection of intellectual property rights be amended to reflect the growing involvement of artificial intelligence in the field of intellectual property",,https://core.ac.uk/download/551549149.pdf,138459520,works created by artificial intelligence: intellectual property or not?,2022-12-12T00:00:00,The Nigerian Bar Association,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Throughout the fifth edition of the International Forum of Agricultural Robots (FIRA) in December 2020, more than 1,500 farmers, manufacturers, advanced technology suppliers, innovators, investors, journalists and experts from 71 countries around the world gathered to ask questions, share stories and exchange ideas about agricultural robots. This book is a journey into the state of the art of this industry in 2020, and includes 27 agricultural robot information sheets. It is designed to provide a nuanced look at the industry’s most pressing topics, from the overarching impact of the global food crisis to the everyday influence of semi-autonomous tractors on a family-owned farm in France. The book achieves this goal by taking a deep dive into the perspectives shared by FIRA 2020 presenters and panelists",10.35690/978-2-7592-3382-3,https://core.ac.uk/download/487599544.pdf,120409351,agricultural robotics: part of the new deal?,2021-12-02T16:25:52,'EDITIONS QUAE',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Estimating depth information from endoscopic images is a prerequisite for a
wide set of AI-assisted technologies, such as accurate localization and
measurement of tumors, or identification of non-inspected areas. As the domain
specificity of colonoscopies -- deformable low-texture environments with
fluids, poor lighting conditions and abrupt sensor motions -- pose challenges
to multi-view 3D reconstructions, single-view depth learning stands out as a
promising line of research. Depth learning can be extended in a Bayesian
setting, which enables continual learning, improves decision making and can be
used to compute confidence intervals or quantify uncertainty for in-body
measurements. In this paper, we explore for the first time Bayesian deep
networks for single-view depth estimation in colonoscopies. Our specific
contribution is two-fold: 1) an exhaustive analysis of scalable Bayesian
networks for depth learning in different datasets, highlighting challenges and
conclusions regarding synthetic-to-real domain changes and supervised vs.
self-supervised methods; and 2) a novel teacher-student approach to deep depth
learning that takes into account the teacher uncertainty.Comment: 11 page",,http://arxiv.org/abs/2112.08906,124585873,on the uncertain single-view depths in colonoscopies,2022-07-20T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Large scale cloud services use Key Performance Indicators (KPIs) for tracking
and monitoring performance. They usually have Service Level Objectives (SLOs)
baked into the customer agreements which are tied to these KPIs. Dependency
failures, code bugs, infrastructure failures, and other problems can cause
performance regressions. It is critical to minimize the time and manual effort
in diagnosing and triaging such issues to reduce customer impact. Large volume
of logs and mixed type of attributes (categorical, continuous) in the logs
makes diagnosis of regressions non-trivial.
  In this paper, we present the design, implementation and experience from
building and deploying DeCaf, a system for automated diagnosis and triaging of
KPI issues using service logs. It uses machine learning along with pattern
mining to help service owners automatically root cause and triage performance
issues. We present the learnings and results from case studies on two large
scale cloud services in Microsoft where DeCaf successfully diagnosed 10 known
and 31 unknown issues. DeCaf also automatically triages the identified issues
by leveraging historical data. Our key insights are that for any such diagnosis
tool to be effective in practice, it should a) scale to large volumes of
service logs and attributes, b) support different types of KPIs and ranking
functions, c) be integrated into the DevOps processes.Comment: To be published in the proceedings of ICSE-SEIP '20, Seoul, Republic
  of Kore",10.1145/3377813.3381353,http://arxiv.org/abs/1910.05339,89578406,"decaf: diagnosing and triaging performance issues in large-scale cloud
  services",2020-02-02T00:00:00,'Association for Computing Machinery (ACM)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The object of this research is the Big Data (BD) analysis processes. One of the most problematic places is the lack of a clear classification of BD analysis methods, the presence of which will greatly facilitate the selection of an optimal and efficient algorithm for analyzing these data depending on their structure.In the course of the study, Data Mining methods, Technologies Tech Mining, MapReduce technology, data visualization, other technologies and analysis techniques were used. This allows to determine their main characteristics and features for constructing a formal analysis model for Big Data. The rules for analyzing Big Data in the form of an ontological knowledge base are developed with the aim of using it to process and analyze any data.A classifier for forming a set of Big Data analysis rules has been obtained. Each BD has a set of parameters and criteria that determine the methods and technologies of analysis. The very purpose of BD, its structure and content determine the techniques and technologies for further analysis. Thanks to the developed ontology of the knowledge base of BD analysis with Protégé 3.4.7 and the set of RABD rules built in them, the process of selecting the methodologies and technologies for further analysis is shortened and the analysis of the selected BD is automated. This is due to the fact that the proposed approach to the analysis of Big Data has a number of features, in particular ontological knowledge base based on modern methods of artificial intelligence.Thanks to this, it is possible to obtain a complete set of Big Data analysis rules. This is possible only if the parameters and criteria of a specific Big Data are analyzed clearly.Исследованы процессы анализа Big Data. Используя разработанную формальную модель и проведенный критический анализ методов и технологий анализа Big Data, построена онтология анализа Big Data. Исследованы методы, модели и инструменты для усовершенствования онтологии аналитики Big Data и эффективной поддержки разработки структурных элементов модели системы поддержки принятия решений по управлению Big Data.Досліджені процеси аналізу Big Data. Використовуючи розроблену формальну модель та проведений критичний аналіз методів і технологій аналізу Big Data, побудовано онтологію аналізу Big Data. Досліджено методи, моделі та інструменти для удосконалення онтології аналітики Big Data та ефективнішої підтримки розроблення структурних елементів моделі системи підтримки прийняття рішень з керування Big Data",10.15587/2312-8372.2018.123612,https://core.ac.uk/download/288836898.pdf,78603302,онтологія аналізу big data,2017-12-28T00:00:00,'Private Company Technology Center',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Even when concepts similar to emergence have been used since antiquity, we
lack an agreed definition. However, emergence has been identified as one of the
main features of complex systems. Most would agree on the statement ``life is
complex''. Thus, understanding emergence and complexity should benefit the
study of living systems.
  It can be said that life emerges from the interactions of complex molecules.
But how useful is this to understand living systems? Artificial life (ALife)
has been developed in recent decades to study life using a synthetic approach:
build it to understand it. ALife systems are not so complex, be them soft
(simulations), hard (robots), or wet (protocells). Then, we can aim at first
understanding emergence in ALife, for then using this knowledge in biology.
  I argue that to understand emergence and life, it becomes useful to use
information as a framework. In a general sense, I define emergence as
information that is not present at one scale but is present at another scale.
This perspective avoids problems of studying emergence from a materialist
framework, and can be also useful in the study of self-organization and
complexity.Comment: 28 pages, 1 figur",,http://arxiv.org/abs/2105.03216,131013937,emergence in artificial life,2022-09-23T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Primary and secondary education is a crucial stage to build a strong
foundation before diving deep into specialised subjects in colleges and
universities. To excel in the current education system, students are required
to have a deep understanding of knowledge according to standardized curriculums
and syllabus, and exam-related problem solving skills. In current school
settings, this learning normally occurs in large classes of 30-40 students per
class. Such a ``one size fits all'' approach may not be effective, as different
students proceed on their learning in different ways and pace. To address this
problem, we propose the Self-Evolving Adaptive Learning (SEAL) system for
personalized education at scale",10.1145/3406865.3418326,http://arxiv.org/abs/2005.02164,85602884,self-evolving adaptive learning for personalized education,2020-08-28T01:00:00,'Association for Computing Machinery (ACM)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The 60s was the age of freedom and boldness. According to John Lennon, the legendary singer-songwriter, who said in his last interview for RKO, “The thing the sixties did was to show us the possibilities and the responsibility that we all had. It wasn’t the answer. It just gave us a glimpse of the possibility”.10 Various technologies and cultures were developing boundlessly at an unprecedented speed during this time. Movements for civil rights due to racial discrimination, movements for women’s rights due to feminism, liberation movements for bodily autonomy, and student movements&nbsp;(Mai 68) in France due to the education system, influenced and challenged the conservative thought and systems in the society which people were used to. With the flourishing development of high-end technology, during the cold war period, the US and Russia were still competing to be the world leaders in technological development. The battlefields of the well-known space race included not only the terrain of the earth but also the surface of the moon. For the general public, the impact of rapid technological development, plus the discovery of chaos theory in Science and the gradual advancement of computer technology, opened the door towards all kinds of imagination about how the future world will look. The influential pop art movement, gave new birth to art which was no longer bigwigs’ assets hung on the walls of a royal palace and high-end art galleries, but relatively closer to people’s daily lives by using common substances and materials for creating art pieces. In addition, with the growth of the underground hippy culture and rock ‘n roll music, it was the golden age when people gradually had the courage to explore, to experiment, to express personal opinions, and dare to imagine and expect a future life of their own. And this was also the time when Archigram was born",10.7480/abe.2018.1.3749,https://core.ac.uk/download/268413247.pdf,74920743,from interactive to intra-active body,2018-12-20T00:00:00,TU Delft Open,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Affective computing has been shown effective and useful in a range of use cases by now, including human–computer interaction, emotionally intelligent tutoring, or depression monitoring. While these could be very useful to the younger among us—including in particular also earlier recognition of developmental disorders, usually research and even working demonstrators have been largely targeting an adult population. Only a few studies, including the first-ever competitive emotion challenge, were based on children’s data. In times where fairness is a dominating topic in the world of artificial intelligence, it seems timely to widen up to include children and youth more broadly as a user group and beneficiaries of the promises affective computing holds. To best support according to algorithmic and technological development, here, we summarize the emotional development of this group over the years, which poses considerable challenges for automatic emotion recognition, generation, and processing engines. We also provide a view on the steps to be taken to best cope with these, including drifting target learning, broadening up on the “vocabulary” of affective states modeled, transfer, few-shot, zero-shot, reinforced, and life-long learning in affective computing besides trustability",10.1109/mis.2022.3209047,https://core.ac.uk/download/565837484.pdf,144995735,child and youth affective computing - challenge accepted,2022-01-01T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Materials discovery and design typically proceeds through iterative
evaluation (both experimental and computational) to obtain data, generally
targeting improvement of one or more properties under one or more constraints
(e.g., time or budget). However, there can be great variation in the quality
and cost of different data, and when they are mixed together in what we here
call multifidelity data the optimal approaches to their utilization are not
established. It is therefore important to develop strategies to acquire and use
multifidelity data to realize the most efficient iterative materials
exploration. In this work, we assess the impact of using multifidelity data
through mock demonstration of designing solar cell materials, using the
electronic bandgap as the target property. We propose a new approach of using
multifidelity data through leveraging machine learning models of both low- and
high-fidelity data, where using predicted low-fidelity data as an input feature
in the high-fidelity model can improve the impact of a multifidelity data
approach. We show how tradeoffs of low- versus high-fidelity measurement cost
and acquisition can impact the materials discovery process, and find that the
use of multifidelity data has maximal impact on the materials discovery
campaign when approximately five low-fidelity measurements per high-fidelity
measurement are performed, and when the cost of low-fidelity measurements is
approximately 5% or less than that of high-fidelity measurements. This work
provides practical guidance and useful qualitative measures for improving
materials discovery campaigns that involve multifidelity data",,http://arxiv.org/abs/2310.16168,152482771,"role of multifidelity data in sequential active learning materials
  discovery campaigns: case study of electronic bandgap",2023-10-24T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Cyber attacks has always been of a great concern. Websites and services with
poor security layers are the most vulnerable to such cyber attacks. The
attackers can easily access sensitive data like credit card details and social
security number from such vulnerable services. Currently to stop cyber attacks,
various different methods are opted from using two-step verification methods
like One-Time Password and push notification services to using high-end
bio-metric devices like finger print reader and iris scanner are used as
security layers. These current security measures carry a lot of cons and the
worst is that user always need to carry the authentication device on them to
access their data. To overcome this, we are proposing a technique of using
keystroke dynamics (typing pattern) of a user to authenticate the genuine user.
In the method, we are taking a data set of 51 users typing a password in 8
sessions done on alternate days to record mood fluctuations of the user.
Developed and implemented anomaly-detection algorithm based on distance metrics
and machine learning algorithms like Artificial Neural networks (ANN) and
convolutional neural network (CNN) to classify the users. In ANN, we
implemented multi-class classification using 1-D convolution as the data was
correlated and multi-class classification with negative class which was used to
classify anomaly based on all users put together. We were able to achieve an
accuracy of 95.05% using ANN with Negative Class. From the results achieved, we
can say that the model works perfectly and can be bought into the market as a
security layer and a good alternative to two-step verification using external
devices. This technique will enable users to have two-step security layer
without worrying about carry an authentication device",,http://arxiv.org/abs/2304.03958,142187653,keydetect --detection of anomalies and user based on keystroke dynamics,2023-04-08T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper presents a simple technique for performing Batik image retrieval using the Convolutional Neural Network (CNN) approach. Two CNN models, i.e. supervised and unsupervised learning approach, are considered to perform end-to-end feature extraction in order to describe the content of Batik image. The distance metrics measure the similarity between the query and target images in database based on the feature generated from CNN architecture. As reported in the experimental section, the proposed supervised CNN model achieves better performance compared to unsupervised CNN in the Batik image retrieval system. In addition, image feature composed from the proposed CNN model yields better performance compared to that of the handcrafted feature descriptor. Yet, it demonstrates the superiority performance of deep learning-based approach in the Batik image retrieval system",10.12928/telkomnika.v17i6.12701,https://core.ac.uk/download/295345108.pdf,81984419,batik image retrieval using convolutional neural network,2019-12-01T00:00:00,'Universitas Ahmad Dahlan',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper introduces our collective work “Patterns in Between Intelligences”, a performance piece that builds an artistic practice between live coding sounds and coding through dance, mediated and shaped through e-textile sensors. This creates a networked system of which both live coded processes and human bodies are part. The paper describes in detail the implementations of technology used in the prototype performance performed at No Bounds Festival in Sheffield UK, October 2022, as well as discussions and concerns the team had related to the use of AI technology on stage. The paper concludes with a narrative reflection on the Sheffield performance, and reflections on it",10.5281/zenodo.7843540,https://core.ac.uk/download/586148868.pdf,147683350,"mosaick: staging contemporary ai performance - connecting live coding, e-textiles and movement",2023-04-18T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Deep Learning (DL) , a variant of the neural network algorithms originally
proposed in the 1980s, has made surprising progress in Artificial Intelligence
(AI), ranging from language translation, protein folding, autonomous cars, and
more recently human-like language models (CHATbots), all that seemed
intractable until very recently. Despite the growing use of Deep Learning (DL)
networks, little is actually understood about the learning mechanisms and
representations that makes these networks effective across such a diverse range
of applications. Part of the answer must be the huge scale of the architecture
and of course the large scale of the data, since not much has changed since
1987. But the nature of deep learned representations remain largely unknown.
Unfortunately training sets with millions or billions of tokens have unknown
combinatorics and Networks with millions or billions of hidden units cannot
easily be visualized and their mechanisms cannot be easily revealed. In this
paper, we explore these questions with a large (1.24M weights; VGG) DL in a
novel high density sample task (5 unique tokens with at minimum 500 exemplars
per token) which allows us to more carefully follow the emergence of category
structure and feature construction. We use various visualization methods for
following the emergence of the classification and the development of the
coupling of feature detectors and structures that provide a type of graphical
bootstrapping, From these results we harvest some basic observations of the
learning dynamics of DL and propose a new theory of complex feature
construction based on our results",,http://arxiv.org/abs/2307.10991,144857181,dense sample deep learning,2023-07-21T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"As machine learning becomes more influential in everyday life, we must begin addressing potential shortcomings. A current problem area is word embeddings, frameworks that transform words into numbers, allowing the algorithmic analysis of language. Without a method for filtering implicit human bias from the documents used to create these embeddings, they contain and propagate stereotypes. Previous work has shown that one commonly used and distributed word embedding model trained on articles from Google News contained prejudice between gender and occupation (Bolukbasi 2016). While unsurprising, the use of biased data in machine learning models only serves to amplify the problem. Although attempts have been made to remove or reduce these biases, a true solution has yet to be found. Hiring models, tools trained to identify well-fitting job candidates, show the impact of gender stereotypes on occupations. Companies like Amazon have abandoned these systems due to flawed decision-making, even after years of development.
I investigated whether the technique of word embedding adjustments from Bolukbasi 2016 made a difference in the results of an emulated hiring model. After collecting and cleaning resumes and job postings, I created a model that predicted whether candidates were a good fit for a job based on a training set of resumes from those already hired. To assess differences, I built the same model with different word vectors, including the original and adjusted word2vec embedding. Results were expected to show some form of bias on classification. I conclude with potential improvements and additional work being done",,https://core.ac.uk/download/233191873.pdf,69648755,assessing bias removal from word embeddings,2019-05-07T08:00:00,Eagle Scholar,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The goal of this paper is to elaborate swarm intelligence for business intelligence decision making and the business rules management improvement. The paper introduces the decision making model which is based on the application of Artiﬁcial Neural Networks (ANNs) and Particle Swarm Optimization (PSO) algorithm. Essentially the business spatial data illustrate the group behaviors. The swarm optimization, which is highly influenced by the behavior of creature, performs in group. The Spatial data is defined as data that is represented by 2D or 3D images. SQL Server supports only 2D images till now. As we know that location is an essential part of any organizational data as well as business data: enterprises maintain customer address lists, own property, ship goods from and to warehouses, manage transport flows among their workforce, and perform many other activities. By means to say a lot of spatial data is used and processed by enterprises, organizations and other bodies in order to make the things more visible and self-descriptive. From the experiments, we found that PSO is can facilitate the intelligence in social and business behaviour",10.9781/ijimai.2014.268,https://core.ac.uk/download/287123711.pdf,77817157,business and social behaviour intelligence analysis using pso,2020-01-29T11:31:37,'Universidad Internacional de La Rioja',"[{'title': 'International Journal of Interactive Multimedia and Artificial Intelligence', 'identifiers': ['issn:1989-1660', '1989-1660']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"When inferring the goals that others are trying to achieve, people
intuitively understand that others might make mistakes along the way. This is
crucial for activities such as teaching, offering assistance, and deciding
between blame or forgiveness. However, Bayesian models of theory of mind have
generally not accounted for these mistakes, instead modeling agents as mostly
optimal in achieving their goals. As a result, they are unable to explain
phenomena like locking oneself out of one's house, or losing a game of chess.
Here, we extend the Bayesian Theory of Mind framework to model boundedly
rational agents who may have mistaken goals, plans, and actions. We formalize
this by modeling agents as probabilistic programs, where goals may be confused
with semantically similar states, plans may be misguided due to
resource-bounded planning, and actions may be unintended due to execution
errors. We present experiments eliciting human goal inferences in two domains:
(i) a gridworld puzzle with gems locked behind doors, and (ii) a block-stacking
domain. Our model better explains human inferences than alternatives, while
generalizing across domains. These findings indicate the importance of modeling
others as bounded agents, in order to account for the full richness of human
intuitive psychology.Comment: Accepted to CogSci 2021. 6 pages, 5 figures. (Appendix: 1 page, 1
  figure",,http://arxiv.org/abs/2106.13249,115649103,"modeling the mistakes of boundedly rational agents within a bayesian
  theory of mind",2021-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The second webinar in a series of seminars organized by AIS and AACSB MaCuDE project’s IS task force provides the members of the IS community a preliminary overview of the findings of Stage II of the project. These findings highlight industry needs for big data and analytics based on interviews of around 25 big data / machine learning industry experts and leaders around the globe. The webinar offers also an opportunity for an in-depth discussion on the implications of these findings for future IS curricula. The seminar summarizes initial results of the in-depth interviews of industry experts and discusses some implications for future educational needs. Building on the key observations, the webinar welcomes the participants to join in a conversation to interpret the meaning of these findings for the IS discipline. The discussion particularly focuses on the role of advanced analytics and AI in future business school curricula and the ways in which developments in these areas of study and practice are impacting the field of IS in the business school context. The outcomes of the conversation inform the MaCuDE IS task force’s Stage II report to this AACSB project as a whole. The seminar will also include commentary notes from some eminent industry experts",,https://core.ac.uk/download/479740221.pdf,17827451,industry expectations for transforming is education—discussion on aacsb macude is task force finding,2021-06-09T08:00:00,AIS Electronic Library (AISeL),[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
Peer reviewe,10.7551/mitpress/13375.003.0008,https://core.ac.uk/download/554075299.pdf,139622115,learning computational thinking in phenomenon-based co-creation projects : perspectives from finland,2022-01-01T00:00:00,MIT Press,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Technology has shifted humans from their highly calculated ‘older’ traditions of orthogonal thinking…to a more developed machine-age where we can now benefit from utilising machines and their assets to assist in repetitive design tasks in a more precise and automated manner. Through the interoperation of computer systems, we are in a beneficial position to be able to lead machines and Ai to think critically using our data in an intelligent way. So that humans can benefit from the innovations and technological creations derived by our own kind. Architects and designers must find new ways of constructing significance from data to benefit our future existence on earth - assisted by ‘Creative Machines’. Developing the intersection of innovative design with cutting-edge technologies will enable humans to respond effectively towards existing globalclimate-challenges beyond our own native capacities",10.24384/jtre-vn88,https://core.ac.uk/download/341768679.pdf,18767265,creative machines,2020-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Graph is powerful for representing various types of real-world data. The
topology (edges' presence) and edges' features of a graph decides the message
passing mechanism among vertices within the graph. While most existing
approaches only manually define a single-value edge to describe the
connectivity or strength of association between a pair of vertices,
task-specific and crucial relationship cues may be disregarded by such manually
defined topology and single-value edge features. In this paper, we propose the
first general graph representation learning framework (called GRATIS) which can
generate a strong graph representation with a task-specific topology and
task-specific multi-dimensional edge features from any arbitrary input. To
learn each edge's presence and multi-dimensional feature, our framework takes
both of the corresponding vertices pair and their global contextual information
into consideration, enabling the generated graph representation to have a
globally optimal message passing mechanism for different down-stream tasks. The
principled investigation results achieved for various graph analysis tasks on
11 graph and non-graph datasets show that our GRATIS can not only largely
enhance pre-defined graphs but also learns a strong graph representation for
non-graph data, with clear performance improvements on all tasks. In
particular, the learned topology and multi-dimensional edge features provide
complementary task-related cues for graph analysis tasks. Our framework is
effective, robust and flexible, and is a plug-and-play module that can be
combined with different backbones and Graph Neural Networks (GNNs) to generate
a task-specific graph representation from various graph and non-graph data. Our
code is made publicly available at
https://github.com/SSYSteve/Learning-Graph-Representation-with-Task-specific-Topology-and-Multi-dimensional-Edge-Features",,http://arxiv.org/abs/2211.12482,135844634,"gratis: deep learning graph representation with task-specific topology
  and multi-dimensional edge features",2022-11-19T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"States are investing heavily in artificial intelligence (AI) technology, and are actively incorporating AI tools across the full spectrum of their decision-making processes. However, AI tools are currently deployed without a full understanding of their impact on individuals or society, and in the absence of effective domestic or international regulatory frameworks. Although this haste to deploy is understandable given AI's significant potential, it is unsatisfactory. The inappropriate deployment of AI technologies risks litigation, public backlash, and harm to human rights. In turn, this is likely to delay or frustrate beneficial AI deployments. This essay suggests that human rights law offers a solution. It provides an organizing framework that states should draw on to guide their decisions to deploy AI (or not), and can facilitate the clear and transparent justification of those decisions",10.1017/aju.2020.30,https://core.ac.uk/download/323060191.pdf,8729386,using human rights law to inform states' decisions to deploy ai,2020-04-27T00:00:00,'Cambridge University Press (CUP)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"While 5G is being tested worldwide and anticipated to be rolled out gradually in 2019, researchers around the world are beginning to turn their attention to what 6G might be in 10+ years time, and there are already initiatives in various countries focusing on the research of possible 6G technologies. This article aims to extend the vision of 5G to more ambitious scenarios in a more distant future and speculates on the visionary technologies that could provide the step changes needed for enabling 6G",10.1109/mwc.001.1900488,https://core.ac.uk/download/334959745.pdf,77703820,a speculative study on 6g,2020-08-01T01:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This article introduces the case that it does not seem plausible that AI can come to be presented as interchangeable with human intellect, as if its processes could pass as natural, as much as our intellectual exercise of understanding reality is. The paper shows that even though AI reproduces the structure of human knowledge yet misses subjectivity. And in that sense, strong AI could not overcome human knowledge, because it is not able to see itself as an active spectator of itself, nor protagonist or responsible for its actions. Though some think that the human being’s own lies in a dynamic combination of different characteristics such as vulnerable corporeality, autonomous rationality, and interdependent sociability. It is of no interest to AI to imitate our biographical temporal vulnerability, although it would be interested in imitating rational autonomy; and it does not need interdependent sociability either.Este artículo introduce el caso de que no parece plausible que la IA pueda llegar a presentarse como intercambiable con el intelecto humano, como si sus procesos pudieran pasar tan naturales como lo es nuestro ejercicio intelectual de comprensión de la realidad. El documento muestra que, aunque la IA reproduce la estructura del conocimiento humano, aún pierde la subjetividad. Y en ese sentido, la IA fuerte no podría superar al conocimiento humano, porque no es capaz de verse a sí misma como espectadora activa de sí misma, ni protagonista ni responsable de sus actos. Aunque algunos piensan que la propia del ser humano radica en una combinación dinámica de diferentes características como la corporeidad vulnerable, la racionalidad autónoma y la sociabilidad interdependiente. A la IA no le interesa imitar nuestra vulnerabilidad temporal biográfica, aunque sí le interesaría imitar la autonomía racional; y tampoco necesita la sociabilidad interdependiente",,https://core.ac.uk/download/588471080.pdf,150527701,¿una inteligencia artificial natural? algunas notas sobre la biomímesis computacional de la inteligencia humana,2023-07-27T01:00:00,Universidad de Málaga - UPAEP Universidad,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This presentation to Library of Congress staff, delivered onsite on January 10, 2020, presents a tour through the demonstration project pursued by the Aida digital libraries research team with the Library of Congress in 2019-2020. In addition to providing an overview and analysis of the specific machine learning projects scoped and explored, this presentation includes a number of high-level take-aways and recommendations designed to influence and inform the Library of Congress\u27s machine learning efforts going forward",,https://core.ac.uk/download/345177577.pdf,96087486,"final presentation to the library of congress on digital libraries, intelligent data analytics, and augmented description",2020-01-10T08:00:00,DigitalCommons@University of Nebraska - Lincoln,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"As the impact of AI on various scientific fields is increasing, it is crucial
to embrace interdisciplinary knowledge to understand the impact of technology
on society. The goal is to foster a research environment beyond disciplines
that values diversity and creates, critiques and develops new conceptual and
theoretical frameworks. Even though research beyond disciplines is essential
for understanding complex societal issues and creating positive impact it is
notoriously difficult to evaluate and is often not recognized by current
academic career progression. The motivation for this paper is to engage in
broad discussion across disciplines and identify guiding principles fir AI
research beyond disciplines in a structured and inclusive way, revealing new
perspectives and contributing to societal and human wellbeing and
sustainability",,http://arxiv.org/abs/2302.06655,140144524,on the importance of ai research beyond disciplines,2023-02-13T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"A non-standard romanization of Arabic script, known as Arbizi, is widely used in Arabic online and SMS/chat communities. However, since state-of-the-art tools and applications for Arabic NLP expects Arabic to be written in Arabic script, handling contents written in Arabizi requires a special attention either by building customized tools or by transliterating them into Arabic script. The latter approach is the more common one and this work presents two significant contributions in this direction. The first one is to collect and publicly release the first large-scale “Arabizi to Arabic script” parallel corpus focusing on the Jordanian dialect and consisting of more than 25 k pairs carefully created and inspected by native speakers to ensure highest quality. Second, we present Atar, an attention-based encoder-decoder model for Arabizi transliteration. Training and testing this model on our dataset yields impressive accuracy (79%) and BLEU score (88.49)",10.11591/ijece.v11i3.pp2327-2334,https://core.ac.uk/download/335272823.pdf,10897009,atar: attention-based lstm for arabizi transliteration,2021-06-01T01:00:00,Institute of Advanced Engineering and Science,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"As per the global digital report, 52.9% of the world population is using the internet, and 42% of the world population is actively using e-commerce, banking, and other online applications. Web servicesare software components accessed using networked communications and provide services to end users. Software developers provide a high quality of web service. To meet the demands of user requirements, it is necessary for a developer to ensure quality architecture and quality of services. To meet the demands of user measure service quality by the ranking of web services, in this paper, we analyzed QWS datasetand found important parameters are best practices, successability, availability, response time, reliability and throughput, and compliance. We have used various data mining techniques and conductedexperiments to classify QWS data set into four categorical values as class1, 2, 3, and 4. The results are compared with various techniques random forest, artificial neural network, J48 decision tree, extremegradient boosting, K-nearest neighbor, and support vector machine. Multiple classifiers analyzed, and it was observed that the classifier technique eXtreme gradient boosting got the maximum accuracy of98.44%, and random forest got the accuracy of 98.13%. In future, we can extend the quality of web service for mixed attributes",10.12928/telkomnika.v17i6.11510,https://core.ac.uk/download/295344583.pdf,81983859,classification of web services using data mining algorithms and improved learning model,2019-12-01T00:00:00,'Universitas Ahmad Dahlan',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper presents a new approach to engaging children in Nigeria to share
their views of AI. This approach is centered on an inclusive writing contest
for children in a secondary school in Abuja to write about AI to compete for
prizes and share their writings with others. A preliminary analysis of the
first 11 articles we received exhibits diverse gender and ethnic representation
that conveys cultural values and perspectives distinct from those of the
children in the western countries. This finding suggests future work to conduct
in-depth cross-cultural analysis of the articles and to replicate similar
writing contests to engage children in other underrepresented countries",,http://arxiv.org/abs/2303.13544,141821408,"empower children in nigeria to design the future of artificial
  intelligence (ai) through writing",2023-03-15T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Revolusi Industri 4.0 dan era society 5.0 saat ini sedang kita hadapi. Seiring dengan hal tersebut, maka riset biologi juga berkembang pesat. STEM berperan penting dalam menggali potensi Biodiversitas dan riset biologi melalui berbagai model pembelajaran yang mengasah kemampuan berfikir kritis, berfikir kreatif, berkomunikasi dengan baik, berfikir tingkat tinggi (HOTS), berkolaborasi dalam proses pendidikan. Pelaksanaan Project base learning, Problem Base Learning, inquiry learning, Discovery Learning, Case Methode menjadi terintegrasi dengan proses pendidikan melalui STEM. Metaverse menawarkan cara baru bagi pengguna khusunya pada bidang pendidikan  untuk berkolaborasi secara virtual dan berperan didalamnya. Di dunia riset dan edukasi, metaverse membawa dampak, khusunya pada Biodiversitas Indonesia yang dapat divisualisasikan secara virtual.Kata kunci: Revolusi Industri 4.0, STEM, Metavers",10.22373/pbio.v11i1.19410,https://core.ac.uk/download/577864098.pdf,149950115,riset biologi berbasis stem di era metaverse,2023-06-12T01:00:00,"Universitas Islam Negeri Ar-Raniry Banda Aceh, Aceh, Indonesia.",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In recent years great attention has been paid to studies on artificial intelligence since it can be applied easily to several areas like medical diagnosis, engineering and economics, among others. In this paper we present an example in medicine which aims to diagnose the patients with high prostate cancer risk using a multi-criteria decision making method.Our datas set is prostate specific antigen (PSA), free prostate specific antigen (fPSA), prostate volume (PV) and age factors of 78 patients from Necmettin Erbakan University Meram Medicine Faculty. An artificial neural network related to the consistency of convergence coefficients calculated by the Fuzzy TOPSIS method [32] is established.Thus, we understand the accuracy of the results from the Fuzzy TOPSIS method.Publisher's Versio",,https://core.ac.uk/download/421651163.pdf,112107731,consistency measurement using the artificial neural network of the results obtained with fuzzy topsis method for the diagnosis of prostate cancer,2021-01-01T00:00:00,Işık University Press,"[{'title': 'TWMS Journal of Applied and Engineering Mathematics', 'identifiers': ['issn:2146-1147', '2587-1013', 'issn:2587-1013', '2146-1147']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"First published in German: Eduard Kaeser, Würmer essen ist «widerlich», Wokeness ablehnen «schlecht»: Vom Versuch, künstlicher Intelligenz Moral beizubringen, Neue Zürcher Zeitung, 31 Oct .2022. Translation by the editors",10.58863/20.500.12424/4276024,https://core.ac.uk/download/582653539.pdf,146586652,teaching ethics to robots : trying to teach morality to artificial intelligence,2023-01-01T00:00:00,Globethics Publications,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The emergence of the Internet of Things (IoT) technology provides new directions and contents for the development of smart homes, breaks the time and space barriers between people and home systems, and the application of IoT technology realizes the integration and management of information between smart home devices, prompting people\u27s home life to be safe, comfortable and intelligent, exploring the life needs of contemporary users, and building a harmonious relationship between people and smart home systems. At present, smart home is developing rapidly and has a greater impact on people\u27s home life. This paper will elaborate on the development status of smart homes in the context of the Internet of Things and explore and study the significance and development trend of Internet of Things technology in the field of the smart home",,https://core.ac.uk/download/491250886.pdf,17872791,research on the development status and the trend of smart home,2021-12-03T08:00:00,AIS Electronic Library (AISeL),[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper presents the Never Ending Open Learning Adaptive Framework
(NEOLAF), an integrated neural-symbolic cognitive architecture that models and
constructs intelligent agents. The NEOLAF framework is a superior approach to
constructing intelligent agents than both the pure connectionist and pure
symbolic approaches due to its explainability, incremental learning,
efficiency, collaborative and distributed learning, human-in-the-loop
enablement, and self-improvement. The paper further presents a compelling
experiment where a NEOLAF agent, built as a problem-solving agent, is fed with
complex math problems from the open-source MATH dataset. The results
demonstrate NEOLAF's superior learning capability and its potential to
revolutionize the field of cognitive architectures and self-improving adaptive
instructional systems",,http://arxiv.org/abs/2308.03990,145070973,"neolaf, an llm-powered neural-symbolic cognitive architecture",2023-08-07T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Current computer vision models, unlike the human visual system, cannot yet
achieve general-purpose visual understanding. Existing efforts to create a
general vision model are limited in the scope of assessed tasks and offer no
overarching framework to perform them holistically. We present a new
comprehensive benchmark, General-purpose Visual Understanding Evaluation
(G-VUE), covering the full spectrum of visual cognitive abilities with four
functional domains $\unicode{x2014}$ Perceive, Ground, Reason, and Act. The
four domains are embodied in 11 carefully curated tasks, from 3D reconstruction
to visual reasoning and manipulation. Along with the benchmark, we provide a
general encoder-decoder framework to allow for the evaluation of arbitrary
visual representation on all 11 tasks. We evaluate various pre-trained visual
representations with our framework and observe that (1) Transformer-based
visual backbone generally outperforms CNN-based backbone on G-VUE, (2) visual
representations from vision-language pre-training are superior to those with
vision-only pre-training across visual tasks. With G-VUE, we provide a holistic
evaluation standard to motivate research toward building general-purpose visual
systems via obtaining more general-purpose visual representations",,http://arxiv.org/abs/2211.15402,136323472,"perceive, ground, reason, and act: a benchmark for general-purpose
  visual representation",2022-11-28T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In response to the global challenge of mental health problems, we proposes a
Logical Neural Network (LNN) based Neuro-Symbolic AI method for the diagnosis
of mental disorders. Due to the lack of effective therapy coverage for mental
disorders, there is a need for an AI solution that can assist therapists with
the diagnosis. However, current Neural Network models lack explainability and
may not be trusted by therapists. The LNN is a Recurrent Neural Network
architecture that combines the learning capabilities of neural networks with
the reasoning capabilities of classical logic-based AI. The proposed system
uses input predicates from clinical interviews to output a mental disorder
class, and different predicate pruning techniques are used to achieve
scalability and higher scores. In addition, we provide an insight extraction
method to aid therapists with their diagnosis. The proposed system addresses
the lack of explainability of current Neural Network models and provides a more
trustworthy solution for mental disorder diagnosis.Comment: ACL 202",,http://arxiv.org/abs/2306.03902,143188627,"utterance classification with logical neural network: explainable ai for
  mental disorder diagnosis",2023-06-06T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Research on digital reality has been extensive in recent years, covering a wide range of topics and leading to new ways to approach and deal with complex situations. Within the Society 5.0 paradigm, people and machines establish a positive relationship to find solutions for social aspects and problems. This perspective establishes a strong interconnection between physical and virtual space, making the user an active player for better life and society. In these terms, digital systems and virtual and augmented reality technologies enable multi-dimensional scenarios and additional levels of interdisciplinary collaboration to create a highly inclusive communication network and social framework. The Handbook of Research on Implementing Digital Reality and Interactive Technologies to Achieve Society 5.0 provides an overview of methods, processes, and tools adopted to achieve super-smart society needs by exploiting digital reality and interactive technologies. It includes case studies that illustrate applications that place people’s quality of life at the center of the digitalization process, accessing and managing different information and data domains. Covering topics such as cultural heritage, interactive learning, and virtual participation, this major reference work is a comprehensive resource for business executives and managers, IT managers, government officials, community leaders, arts and performance organizers, healthcare administrators and professionals, faculty and administrators of both K-12 and higher education, students of higher education, researchers, and academicians",10.4018/978-1-6684-4854-0,https://core.ac.uk/download/539314810.pdf,141539106,handbook of research on implementing digital reality and interactive technologies to achieve society 5.0,2022-01-01T00:00:00,'IGI Global',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Treball desenvolupat en el marc del programa ""European Project Semester"".The growing population around the world and increase of seniors, as well as a demand for high quality services create new problems and challenges, especially in a healthcare sector. Patient treatment is very often a difficult and time consuming process, however, in today’s society people lack time in every aspect of their lives. Shortage of medical staff is only deepening the problem of long waiting time needed to acquire medical assistance. To fulfil the requirements of patients, governments must invest into finding innovative, efficient and yet affordable solutions that will increase efficiency of healthcare systems. The aim of this paper is to describe how smart solutions can be implemented in order to cope with challenges of the healthcare sector. The research was focused on organisational and technological problems that are present in this sector. Though there are various existing solutions to these problems, which will be presented in this report, the main part of it will be devoted to description of the proprietary system that was developed by the team named Salutem, throughout the course of European Project Semester. The solution is a distributed system consisting of two main components, a Web Application and a Mobile Application that communicate with each other. The Web Application is aimed to provide a management tool for health centre employees, as well as an online reservation system for patients. It copes with a problem of long waiting time in queues to doctor’s office by finding an optimal time of a visit for each patient registered for a given doctor. This is done with use of self-learning Artificial Intelligence (AI) algorithm that is embedded in the system. The Mobile Application is using Near Field Communication(NFC) technology to monitor patients that come for a visit, which includes gathering time data that will be used for the process of AI learning. NFC is also used to instantly provide patient data to doctors once a patient is detected in a doctor’s office. The system was created to ensure security and privacy of patients’ data. The report will conclude with a summary of the system, gained experience and possible future development of the solution.Outgoin",,https://core.ac.uk/download/534166418.pdf,133566227,smart healthcare for smart cities,2018-06-19T01:00:00,Universitat Politècnica de Catalunya,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Whenever humans use tools human performance is enhanced. Cognitive systems
are a new kind of tool continually increasing in cognitive capability and are
now performing high level cognitive tasks previously thought to be explicitly
human. Usage of such tools, known as cogs, are expected to result in ever
increasing levels of human cognitive augmentation. In a human cog ensemble, a
cooperative, peer to peer, and collaborative dialog between a human and a
cognitive system, human cognitive capability is augmented as a result of the
interaction. The human cog ensemble is therefore able to achieve more than just
the human or the cog working alone. This article presents results from two
studies designed to measure the effect information supplied by a cog has on
cognitive accuracy, the ability to produce the correct result, and cognitive
precision, the propensity to produce only the correct result. Both cognitive
accuracy and cognitive precision are shown to be increased by information of
different types (policies and rules, examples, and suggestions) and with
different kinds of problems (inventive problem solving and puzzles). Similar
effects shown in other studies are compared.Comment: 12 pages, 7 figures, 4 table",,http://arxiv.org/abs/2308.08581,145572494,"on the augmentation of cognitive accuracy and cognitive precision in
  human/cog ensembles",2023-08-16T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In order to advance the field of procedural content generation, and transfer knowledge from academic research to everyday use, we need to develop tools that make generative systems easier to understand and control. In this paper we introduce Danesh, a plugin to the Unity game development environment. We describe Danesh's various features, including automatic analysis and visualisation tools, and provide reflections on both our development of the tool and our experiences of using it in educational contexts",10.1109/tg.2021.3078323,https://core.ac.uk/download/477975519.pdf,8906390,danesh: interactive tools for understanding procedural content generators,2021-01-01T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',"[{'title': 'IEEE Transactions on Games', 'identifiers': ['2475-1502', 'issn:2475-1502']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Contesting Paul Scharre’s influential vision of “centaur warfighting” and the idea that autonomous weapon systems will replace human warfighters, this article proposes that the manned-unmanned teams of the future are more likely to be minotaurs, teams of humans under the control, supervision, or command of artificial intelligence. It examines the likely composition of the future force and prompts a necessary conversation about the ethical issues raised by minotaur warfighting",10.55540/0031-1723.3207,https://core.ac.uk/download/555495741.pdf,142062054,"minotaurs, not centaurs: the future of manned-unmanned teaming",2023-03-01T00:00:00,USAWC Press,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"During the last decades, learning has once again become a key topic. However, this time, not only for students and professors but also in political and economic contexts. One reason for this is that a high level of education and skills of nations, organizations, and individuals are considered both necessary and crucially competitive advantages in the present knowledge society and the globalized market. Therefore, obtaining a quality education is fundamental for all of us in today\u27s competitive business world. In particular, adult learning within the maritime sector has been important for the success of this industry for ages. The question now is how to streamline and facilitate the learning process for the learners, the lecturers, the authors, and the learning institutions. TERP has taken on the challenge of improving this learning process by introducing Abooks, electronic textbooks based on principles of pedagogy (the science of learning), and andragogy (the science of learning focusing on adults) that adapt to the learner through artificial intelligence. Abooks also introduces the opportunity of utilizing immersive techniques. This is being developed in the AIM project; Adapting to the Individual through Machine learning, a research project led by the research department in TERP in collaboration with the University of Stavanger and the Norwegian Computing Center",,https://core.ac.uk/download/482129040.pdf,120179253,abooks and the aim project,2021-12-05T08:00:00,The Maritime Commons: Digital Repository of the World Maritime University,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This article proposes an algorithm for a servo motor that controls the
movement of an autonomous terrestrial mobile robot using Paraconsistent Logic.
The design process of mechatronic systems guided the robot construction phases.
The project intends to monitor the robot through its sensors that send
positioning signals to the microcontroller. The signals are adjusted by an
embedded technology interface maintained in the concepts of Paraconsistent
Annotated Logic acting directly on the servo steering motor. The electric
signals sent to the servo motor were analyzed, and it indicates that the
algorithm paraconsistent can contribute to the increase of precision of
movements of servo motors",10.5121/csit.2020.101115,http://arxiv.org/abs/2009.14192,89633027,"analysis of the displacement of terrestrial mobile robots in corridors
  using paraconsistent annotated evidential logic e{\tau}",2020-09-29T01:00:00,'Academy and Industry Research Collaboration Center (AIRCC)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"There has recently been talk of algorithms that predict decisions in legal cases being used by the judiciary to improve the predictability and consistency of judicial decision making. We argue that their use may minimise the error rate of decisions in the long run, but that this would require not only major technical advances but also major changes in legal thinking about what is the most important objective of judicial decision-making: optimising individual justice in a particular case or reducing errors in the long run. We further argue that if algorithmic decision predictors give any useful information in individual cases to judges at all, this is not in its predictions but in its explanation",10.3233/faia210338,https://core.ac.uk/download/518782342.pdf,128067909,can predictive justice improve the predictability and consistency of judicial decision-making?,2021-01-01T00:00:00,'IOS Press',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In this paper, we re-examine the task of cross-modal clip-sentence retrieval,
where the clip is part of a longer untrimmed video. When the clip is short or
visually ambiguous, knowledge of its local temporal context (i.e. surrounding
video segments) can be used to improve the retrieval performance. We propose
Context Transformer (ConTra); an encoder architecture that models the
interaction between a video clip and its local temporal context in order to
enhance its embedded representations. Importantly, we supervise the context
transformer using contrastive losses in the cross-modal embedding space. We
explore context transformers for video and text modalities. Results
consistently demonstrate improved performance on three datasets: YouCook2,
EPIC-KITCHENS and a clip-sentence version of ActivityNet Captions. Exhaustive
ablation studies and context analysis show the efficacy of the proposed method.Comment: Accepted in ACCV 202",,https://core.ac.uk/download/551626530.pdf,132291097,contra: (con)text (tra)nsformer for cross-modal video retrieval,2022-10-09T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Humans and gods alike have since the dawn of time created objects in their own image. From clay fgures and wooden toys—some granted life in myths and movies but also dead representations of their creators—to modern-day robots that mimic their creators in more than appearance. These objects tell the story of how we perceive ourselves, and in this article, I examine how they also change us. Robotomorphy describes what occurs when we project the characteristics and capabilities of robots onto ourselves, to make sense of the complicated and mysterious beings that we are. Machines are, after all, relatively comprehensible and help dispel the discomfort associated with complex human concepts such as consciousness, free will, the soul, etc. I then argue that using robots as the mirror image by which we understand ourselves entails an unfortunate reductionism. When robots become the blueprint for humanity, they simultaneously become benchmarks and ideals to live up to, and suddenly the things we make are no longer representations of ourselves, but we of them. This gives rise to a recursive process in which the mirror mirrors itself and infuences both the trajectory for machine development and human self-perception.publishedVersio",10.1007/s43681-021-00092-x,https://core.ac.uk/download/479746409.pdf,18468137,robotomorphy: becoming our creations,2021-01-01T00:00:00,'Springer Science and Business Media LLC',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Significant challenges are posed in talent acquisition and recruitment by
processing and analyzing unstructured data, particularly resumes. This research
presents a novel approach for orphan entity allocation in resume processing
using knowledge graphs. Techniques of association mining, concept extraction,
external knowledge linking, named entity recognition, and knowledge graph
construction are integrated into our pipeline. By leveraging these techniques,
the aim is to automate and enhance the efficiency of the job screening process
by successfully bucketing orphan entities within resumes. This allows for more
effective matching between candidates and job positions, streamlining the
resume screening process, and enhancing the accuracy of candidate-job matching.
The approach's exceptional effectiveness and resilience are highlighted through
extensive experimentation and evaluation, ensuring that alternative measures
can be relied upon for seamless processing and orphan entity allocation in case
of any component failure. The capabilities of knowledge graphs in generating
valuable insights through intelligent information extraction and
representation, specifically in the domain of categorizing orphan entities, are
highlighted by the results of our research.Comment: In Proceedings of the 2023 IEEE International Conference on
  Artificial Intelligence in Engineering and Technology (IICAIET",,http://arxiv.org/abs/2310.14093,152815458,"leveraging knowledge graphs for orphan entity allocation in resume
  processing",2023-10-21T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
The development of increasingly intelligent and autonomous technologies will eventually lead to these systems having to face morally problematic situations. This is particularly true of artificial systems that are used in geriatric care environments. The goal of this article is to describe how one can approach the design of an elder care robot which is capable of moral decision-making and moral learning. A conceptual design for the development of such a system is provided and the steps that are necessary to implement it are described,10.14746/eip.2019.2.7,https://core.ac.uk/download/335340145.pdf,10904795,a softwaremodule for an ethical elder care robot. design and implementation,2019-01-01T00:00:00,'Adam Mickiewicz University Poznan',"[{'title': 'ETHICS IN PROGRESS', 'identifiers': ['issn:2084-9257', '2084-9257']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Experiential learning through games is becoming increasingly relevant as games exert an enormous influence on the imaginarium of newer generations. This paper details the use of a game-based learning process focusing on game-making in relation to ethical issues of digitalization for graduate education in digital service innovation. Within the context of a masters education, students from diverse knowledge backgrounds learned about and reflected upon ethical issues related to social media usage by playing, remixing and designing games using the Design Games Framework. This paper illustrates that game-making can enable non-designer students to work with ethical issues. There are good possibilities to explore ethics through designing tabletop games, and having diverse groups of participants can be advantageous. Using a qualitative approach based on observation and interviews, the paper contributes to the body of literature focusing on experiential learning through game-based approaches and to the consolidation of the Design Games Framework",,https://core.ac.uk/download/552657573.pdf,137210208,turtles and ethics: experiential learning through game-making,2023-01-03T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Developers use models to design real world distributed applications that often are subject to Service Level Agreements to find a good balance between the quality of the service and its resource usage. Executable models has been used to observe and study such applications using, e.g., the Real Time ABS language, an executable and object-oriented modelling language.For complex models, due to the high number and dependencies between the parameters, it is very difficult to understand the best possible setting that leads the system towards a desired quality of service, while minimising the usage of computing resources. In this work we present POPT, a parameter optimiser tool that starting from Real Time ABS models, by using AI techniques, searches in an automatic way for the best possible setting to satisfy the developer’s expectations",,https://core.ac.uk/download/327107687.pdf,86761321,automatic parameter optimisation of service quality and resource usage,2018-08-08T01:00:00,NIKT Foundation,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Smart Waste Monitoring: To track the amount of waste in bins and containers, IOT-enabled garbage management systems use sensors and connected devices. These sensors can communicate real-time data to a centralized monitoring system and can identify the fill level. This data aids in streamlining waste collection routes, cutting back on pointless pickups, and enhancing garbage management effectiveness as a whole. Effective Resource Allocation: By giving precise data on waste generation patterns and trends, IOT-based garbage management systems enable optimal resource allocation. This information can be used by municipal authorities to make well-informed decisions on waste collection schedules, resource deployment, and staffing levels. IOT-based waste management solutions have the potential to make trash management procedures more effective and efficient while also being more affordable. The best garbage collection routes, operational cost reductions, and resource utilization may all be achieved with the aid of research into the best deployment strategies for IOT sensors and devices. Environmental Impact and Sustainability: Research Objective: Clearly identify the research objective, for example, by assessing how well IOT-based garbage management systems gather waste and allocate resources. Data gathering: Compile pertinent information on the methods used for trash generation, collection, and resource use. On-site observations, employee interviews, and database access for waste management operations are all effective ways to accomplish this. Gather information on IOT sensor technologies and their capabilities as well. Taken As alternative for Smart Waste Bins, Waste Level, Sensors, AI Recycling, Robots, E-Waste Kiosks. Taken for Evaluation preference is Reliability, Mobility, Service Continuity, User Convenience., and Energy Efficiency. Smart Waste Bins has performed more when compare to with other Real-Time Monitoring: The Internet of Things (IOT) can be used in waste management to enable real-time monitoring of trash cans or bins can be used to enhance garbage sorting procedures. Smart bins with cameras and sensors can automatically recognize and sort various types of rubbish. These smart bins can identify and categorise rubbish by utilizing IOT technology.&nbsp; on their material composition or recycling category",,https://core.ac.uk/download/591405299.pdf,152503922,evaluation of garbage management based on iot,2023-11-02T00:00:00,Auricle Global Society of Education and Research,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"AI methods are used in societally important settings, ranging from credit to
employment to housing, and it is crucial to provide fairness in regard to
algorithmic decision making. Moreover, many settings are dynamic, with
populations responding to sequential decision policies. We introduce the study
of reinforcement learning (RL) with stepwise fairness constraints, requiring
group fairness at each time step. Our focus is on tabular episodic RL, and we
provide learning algorithms with strong theoretical guarantees in regard to
policy optimality and fairness violation. Our framework provides useful tools
to study the impact of fairness constraints in sequential settings and brings
up new challenges in RL.Comment: Fairness, Reinforcement Learnin",,http://arxiv.org/abs/2211.03994,134596984,reinforcement learning with stepwise fairness constraints,2022-11-07T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Expert System is a part of Artificial Intelligence that contains the knowledge and experience put by many experts into a certain area of knowledge so that everyone can use it to solve specific problems. The implementation of expert systems is widely used in the health sector, for example by making diagnoses such as diagnosing nutritional levels. For example, diagnosing calcium levels in broccoli. Diagnosis is the process of examining something using certain methods and techniques. Diagnosis is done to explain whether the object experiences / suffer certain things. Diagnosing the levels is done to explain whether broccoli vegetables have calcium. It is hoped that with this system, ordinary people can solve certain problems both slightly complicated even without the help of experts in the field. As for experts, this system can be used as an experienced assistant. This developed application aims to make it easier to analyze the data. By using the Certainty Factor method, it will be easier to find out the diagnosis of calcium levels in broccoli. This method is the right method used in expert systems",,https://core.ac.uk/download/487570675.pdf,122976040,application of calcium level expansion systems in broccoli using the certainty factor method,2019-12-30T00:00:00,ASEAN Institute for Health Development,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Digital transformation can enable the creation of substantial business and societal value. However, it entails more than simply the use and application of technology. Digital transformation implies a change in mindset, attitudes, and culture, and doing so successfully requires leaders to overcome many challenges. New technologies such as artificial intelligence and machine learning are accelerating the pace of this transformation, and leaders must position their organizations strategically to exploit them. For society, the critical sectors of healthcare and education are poised at an inflection point of digital transformation today, further precipitated by the global pandemic of 2020. Educators must ensure that tomorrow’s leaders are equipped to drive digital transformation as an urgent strategic imperative in their organizations.La transformación digital puede permitir la generación sustancial de valor social y de negocio. Sin embargo, implica más que el simple uso y aplicación de la tecnología. La transformación digital implica un cambio de mentalidad, actitudes y cultura, y hacerlo de forma exitosa le exige a los líderes superar muchos retos. Las nuevas tecnologías como la inteligencia artificial y el aprendizaje de máquinas están acelerando el paso de la transformación y los líderes deben posicionar sus organizaciones estratégicamente para explotarlas. Para la sociedad, los sectores críticos de la salud y la educación están hoy en un punto de inflexión de la transformación digital, precipitado por la pandemia global de 2020. Los educadores deben asegurarse de que los líderes del mañana estén preparados para dirigir la transformación digital en sus organizaciones",10.22430/24223182.1700,https://core.ac.uk/download/328165262.pdf,87176268,transformación digital: un camino al valor económico y social,2020-07-30T01:00:00,'Instituto Tecnologico Metropolitano (ITM)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The article investigates various kinds of the strategies of technosensation in artistic project based on bio-parametrisation’s techniques. The category of technosensation is in the article referred to the considerations of Luciana Parisi and Marie-Luise Angerer to define the relationship between body affectivity and computational systems (primarily in relation to automated decision-making systems and machine learning processes). The context for these considerations is the reflection on “technological redlining” as a strategy for racial, gender, and (dis)ability profiling of computational systems, which generate social exclusion, inequalities and oppressiveness. In the article, the author considers (with reference to the considerations of Parisi, Bernard Stiegler, Yuk Hui and Gabbrielle M. Johnson) to what extent the algorithmic biases are the result of automation, and to what extent they result from the absorption of uncertainty, randomness and technodiversity. Technosensation strategies are considered in relation to the artistic practices of Zach Blas, Maja Smrekar, Marija Griniuk and others, pointing to subversive, critical and affirmative variants of technological functionality and agency. The presented projects prove that the functionality of computational technologies is not bipolar, but it is developing as a spectrum of nuanced mechanisms, both in the area of oppressive-exclusionary systems and emancipatory strategies",10.4467/20843860pk.22.026.16615,https://core.ac.uk/download/555544745.pdf,141812148,feeding the algorithm? strategies of technosensation in artistic project based on bio-parametrisation’s techniques,2022-01-01T00:00:00,'Uniwersytet Jagiellonski - Wydawnictwo Uniwersytetu Jagiellonskiego',"[{'title': 'Przegląd Kulturoznawczy', 'identifiers': ['2084-3860', 'issn:2084-3860', '1895-975x', 'issn:1895-975X']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
The Internet of Things (IoT) has grown from devices being connected to and controlled through the Internet to autonomous platforms and networked devices that communicate with each other. The utilization of Artificial Intelligence with IoT (AIoT) has further increased the capabilities and services provided by devices but also imposed various challenges such as data interoperability. This panel is composed of leading experts in academia and industry that will discuss the current state and future directions of AIoT along with data interoperability to identify opportunities and challenges along with future directions in research,,https://core.ac.uk/download/479740939.pdf,17829169,artificial iot and data interoperability:  future directions and research agenda,2021-08-13T08:00:00,AIS Electronic Library (AISeL),[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Interpretable models are designed to make decisions in a human-interpretable
manner. Representatively, Concept Bottleneck Models (CBM) follow a two-step
process of concept prediction and class prediction based on the predicted
concepts. CBM provides explanations with high-level concepts derived from
concept predictions; thus, reliable concept predictions are important for
trustworthiness. In this study, we address the ambiguity issue that can harm
reliability. While the existence of a concept can often be ambiguous in the
data, CBM predicts concepts deterministically without considering this
ambiguity. To provide a reliable interpretation against this ambiguity, we
propose Probabilistic Concept Bottleneck Models (ProbCBM). By leveraging
probabilistic concept embeddings, ProbCBM models uncertainty in concept
prediction and provides explanations based on the concept and its corresponding
uncertainty. This uncertainty enhances the reliability of the explanations.
Furthermore, as class uncertainty is derived from concept uncertainty in
ProbCBM, we can explain class uncertainty by means of concept uncertainty. Code
is publicly available at https://github.com/ejkim47/prob-cbm.Comment: International Conference on Machine Learning (ICML) 202",,http://arxiv.org/abs/2306.01574,143186859,probabilistic concept bottleneck models,2023-06-02T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The human world continues to be ever more entangled with the nebulous realms of the digital. The digital lives of humans are constantly viewed, analyzed, and organized by the use of Machine Learning (ML) and Artificial Intelligence (AI) as tools of governments, institutions, and corporations. Digital-machines are able to harvest massive swaths of data from users the world over including discursive elements and biometrics; accumulating the essences of what it means to dwell in a digital world. Although such digital-machines, and the algorithms on which they operate, are becoming more and more complex, they are still viewed as a tool with what Martin Heidegger deemed a  readiness-to-hand  type of Being. By reconsidering the subject-object paradigm, the potential for digital-machines to be subjects in and of themselves open the doors for questions relating to the existence of non-human digital-machine-Beings. One such question is that of what the digital-machine actually  sees.  This act of the digital-machine  seeing  is deemed the Machine Gaze. Therefore thinking through what the digital-machine may  see  and contemplating how contemporary framing of it within the bounds of  readiness-to-hand ; offers new and exciting perspectives on future human and digital-machine interaction. Furthermore, this effort considers the role of anthropocentrism in the way in which the Machine Gaze has encountered data as a primary factor in how digital-machines will view and act in the world of Being. This is important because such Posthumanist thinking (or a lack thereof) may affect how the digital-machine dwells in the world, iterates itself, and reframes Being for itself and for humans",,https://core.ac.uk/download/519922212.pdf,125851847,the digital gaze: anthropomorphic reflections of future posthuman reality,2021-01-01T08:00:00,ODU Digital Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The systematic criticism of articles providing evidence that fish and invertebrates can feel pain is discussed. Beliefs are known to be stronger than evidence in the human mind, and could generate this outcry, while from another perspective, the criticisms appear as a territorial move by fishermen against a perceived threat to their domain. The scientific inconsistency in which consciousness is granted to machines but not to fish and invertebrates, purely due to political bias, is pointed out. No basis exists for denying sentience to any life form as long as science is ignorant of the nature and source of consciousness",10.51291/2377-7478.1324,https://core.ac.uk/download/480652920.pdf,84507747,"fish sentience, consciousness, and ai",2018-01-01T08:00:00,WBI Studies Repository,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Volume 159, Issue 25https://scholarworks.sjsu.edu/spartan_daily_2022/1069/thumbnail.jp",,https://core.ac.uk/download/541291512.pdf,130720911,"spartan daily, october 19, 2022",2022-10-19T08:00:00,SJSU ScholarWorks,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Coral reefs play a vital role in maintaining the ecological balance of the
marine ecosystem. Various marine organisms depend on coral reefs for their
existence and their natural processes. Coral reefs provide the necessary
habitat for reproduction and growth for various exotic species of the marine
ecosystem. In this article, we discuss the most important parameters which
influence the lifecycle of coral and coral reefs such as ocean acidification,
deoxygenation and other physical parameters such as flow rate and surface area.
Ocean acidification depends on the amount of dissolved Carbon dioxide (CO2).
This is due to the release of H+ ions upon the reaction of the dissolved CO2
gases with the calcium carbonate compounds in the ocean. Deoxygenation is
another problem that leads to hypoxia which is characterized by a lesser amount
of dissolved oxygen in water than the required amount for the existence of
marine organisms. In this article, we highlight the importance of physical
parameters such as flow rate which influence gas exchange, heat dissipation,
bleaching sensitivity, nutrient supply, feeding, waste and sediment removal,
growth and reproduction. In this paper, we also bring out these important
parameters and propose an ensemble machine learning-based model for analyzing
these parameters and provide better rates that can help us to understand and
suitably improve the ocean composition which in turn can eminently improve the
sustainability of the marine ecosystem, mainly the coral reefsComment: 8 pages, 18 figure",,http://arxiv.org/abs/2111.04003,138154215,"predictive model for gross community production rate of coral reefs
  using ensemble learning methodologies",2023-01-23T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Stackelberg equilibria arise naturally in a range of popular learning
problems, such as in security games or indirect mechanism design, and have
received increasing attention in the reinforcement learning literature. We
present a general framework for implementing Stackelberg equilibria search as a
multi-agent RL problem, allowing a wide range of algorithmic design choices. We
discuss how previous approaches can be seen as specific instantiations of this
framework. As a key insight, we note that the design space allows for
approaches not previously seen in the literature, for instance by leveraging
multitask and meta-RL techniques for follower convergence. We propose one such
approach using contextual policies, and evaluate it experimentally on both
standard and novel benchmark domains, showing greatly improved sample
efficiency compared to previous approaches. Finally, we explore the effect of
adopting algorithm designs outside the borders of our framework",,http://arxiv.org/abs/2210.11942,140345053,"oracles & followers: stackelberg equilibria in deep multi-agent
  reinforcement learning",2023-02-15T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Understanding the meaning of a text is a fundamental challenge of natural
language understanding (NLU) research. An ideal NLU system should process a
language in a way that is not exclusive to a single task or a dataset. Keeping
this in mind, we have introduced a novel knowledge driven semantic
representation approach for English text. By leveraging the VerbNet lexicon, we
are able to map syntax tree of the text to its commonsense meaning represented
using basic knowledge primitives. The general purpose knowledge represented
from our approach can be used to build any reasoning based NLU system that can
also provide justification. We applied this approach to construct two NLU
applications that we present here: SQuARE (Semantic-based Question Answering
and Reasoning Engine) and StaCACK (Stateful Conversational Agent using
Commonsense Knowledge). Both these systems work by ""truly understanding"" the
natural language text they process and both provide natural language
explanations for their responses while maintaining high accuracy.Comment: Preprint. Accepted by the 35th AAAI Conference (AAAI-21) Main Track",10.1609/aaai.v35i14.17488,http://arxiv.org/abs/2101.11707,107780662,"knowledge-driven natural language understanding of english text and its
  applications",2021-01-27T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Popular models such as Transformers and LSTMs use tokens as its unit of
information. That is, each token is encoded into a vector representation, and
those vectors are used directly in a computation. However, humans frequently
consider spans of tokens (i.e., phrases) instead of their constituent tokens.
In this paper we introduce Treeformer, an architecture inspired by the CKY
algorithm and Transformer which learns a composition operator and pooling
function in order to construct hierarchical encodings for phrases and
sentences. Our extensive experiments demonstrate the benefits of incorporating
a hierarchical structure into the Transformer, and show significant
improvements compared to a baseline Transformer in machine translation,
abstractive summarization, and various natural language understanding tasks",,http://arxiv.org/abs/2207.06960,124463918,forming trees with treeformers,2022-07-14T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This article explores whether narrative texts may help learners grapple with what it means to be human or indeed posthuman in a Volatile, Uncertain, Complex, Ambiguous (VUCA) world inclusive of biotechnology and developing artificial intelligence (AI). Narratives with a posthuman hero may provide access to a post-anthropocentric view described by Braidotti (2016) as life-force egalitarianism inclusive of all human, non-human, geo, cross-species, and transversal alliances. Definitions are broad – narrative includes novels, film, television series, visual art; hero is beyond gender, accessible and encompassing all with life force; posthumanism refers to popular culture and critical theory, with links to transhumanism. Underpinning this article is the notion that a hero or protagonist of a narrative may influence the learner, providing a metaphorical window to other lives, a sliding glass door to future possibilities or a mirror that reflects the audience. Therefore, learners who experience narrative texts through reading/viewing may empathetically grow their understanding of different characters who may confront or influence their thinking",,https://core.ac.uk/download/232792973.pdf,69409537,posthuman heroes,2019-06-13T21:07:20,UR Scholarship Repository,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
The Data Science Symposium at Haus der Wissenschaft on 8/9 November 2021 in Bremen was the 6th Symposium in this series since 2017,,https://core.ac.uk/download/511508015.pdf,26151739,6th data science symposium abstracts,2021-11-08T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper describes the early stages of the developments of Tracks, an initiative to create,implement and evaluate a new educational model where the structure of the education isdeveloped to give students the opportunity to create multi- and interdisciplinary competencies,meet their expectations and need for a more individualized study plan and shorten the leadtimes for changing the education to embrace new technologies. The new education model isbased on the creation of tracks with different themes lying between existing programs notbelonging to a specific department or school. The idea is to create individual and flexible studyopportunities by introducing Track-courses within the themes. These courses address specificchallenges that may be broad societal and profound research-driven. Tracks also include largeinvestments in Chalmers learning environment. The paper focuses on Tracks as a largechange initiative, strategies to manage the complexity of this change as well as developmentphilosophy and working methods in the early phases of the initiative. Change at universitieshas been discussed previously, but this is a unique opportunity to study how large change maybe managed over time, including both the content of the education and the learningenvironments. Through action research, where interventions may be done to influence theinitiative, it is possible to develop practical contributions for other universities in need of similardevelopment. The research has been conducted over approximately a year and includes datafrom interviews and action research, where the authors are the main people working with thisinitiative. The close contact with the data gives a unique understanding of how differentactivities within the initiative influence the outcome. Thus, this paper will contribute to theunderstanding of how large institutional change initiatives are facilitated by a flexible and agileapproach contrasting the traditional and somewhat slower university culture",,https://core.ac.uk/download/347173544.pdf,97024936,"tracks for change, flexibility, interdisciplinarity and creativity in engineering education",2020-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The article investigates the concept “information” and its elements in the general creative activity conception of the French writer Bernard Werber through the analysis of his original work “The Encyclopedia of Relative and Absolute Knowledge”, each short story represents a narrative, a recommendation, a principle, a formula from various fields of popular science. It is pointed out that the author presents some scientific data in a simplified way, other facts are given in a purely professional one, thereby Bernard Werber demonstrates his own competence in the fields of history, mathematics, biology, astronomy, etc., as well as journalistic skills. It is stated that such diverse correlations exist due to the writer's passion for science and history, personal life experience in these areas, and all this ultimately stimulates readers' thinking, which is the main goal of Werber's creative activity. The article explores the correlative plane, which combines data from many branches of science in a historical context, that generally forms an informative complex containing the issues about the history of tribes and peoples (Maya, Aztecs, Arabs, Chinese, etc.), their legends and beliefs (Atlanteans, the origin of a man, pyramids, etc.), wars (episodes of individual military stalemate), religions (conflicts between paganism and Christianity, the Inquisition, etc.), technology and architecture (erection and structure of historical monuments, temples), the natural world (features of physiology) people, ants, dinosaurs), games (particularly about chess combining psychological and historical components). “The Encyclopedia of Relative and Absolute Knowledge” also includes the facts about many historical figures who have made significant contributions to the study and formation of the general noosphere. It is concluded that the writer by providing an array of diverse information in “The Encyclopedia of Relative and Absolute Knowledge” gets the reader not only to be a recipient of ready knowledge, but also to set up new tasks that need to be solved, and the main one among them is life mission understanding",10.34069/ai/2021.40.04.26,https://core.ac.uk/download/568030381.pdf,145141405,the concept “information” as a factor in bernard werber’s style,2021-05-31T01:00:00,'Amazonia Investiga',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The objective of this final degree project is to develop a model able to detect automatically the 
presence or not of ischemia and infection in the wound produced by diabetic foot disease. The work 
consists of an introduction of the mentioned disease as well as some statistical data that motivates
this work. Next, the reader is introduced to all the theoretical concepts used to carry out the mentioned 
task. The model based on computer vision methods will be deduced after analizing different studies 
focused on diabetic foot ulcer detection. This method is exposed paying special attention to all stages 
from data collection to the results exposition which are later suitably analized. At the end of the 
project, the obtained conclusions and possible improvements are presented.Escuela Técnica Superior de Ingeniería IndustrialUniversidad Politécnica de Cartagen",,https://core.ac.uk/download/547496691.pdf,133709764,automatic diabetic foot wound detection based on computer vision methods,2022-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The development of machine learning models requires a large amount of
training data. Data marketplaces are essential for trading high-quality,
private-domain data not publicly available online. However, due to growing data
privacy concerns, direct data exchange is inappropriate. Federated Learning
(FL) is a distributed machine learning paradigm that exchanges data utilities
(in form of local models or gradients) among multiple parties without directly
sharing the raw data. However, several challenges exist when applying existing
FL architectures to construct a data marketplace: (i) In existing FL
architectures, Data Acquirers (DAs) cannot privately evaluate local models from
Data Providers (DPs) prior to trading; (ii) Model aggregation protocols in
existing FL designs struggle to exclude malicious DPs without ""overfitting"" to
the DA's (possibly biased) root dataset; (iii) Prior FL designs lack a proper
billing mechanism to enforce the DA to fairly allocate the reward according to
contributions made by different DPs. To address above challenges, we propose
martFL, the first federated learning architecture that is specifically designed
to enable a secure utility-driven data marketplace. At a high level, martFL is
powered by two innovative designs: (i) a quality-aware model aggregation
protocol that achieves robust local model aggregation even when the DA's root
dataset is biased; (ii) a verifiable data transaction protocol that enables the
DA to prove, both succinctly and in zero-knowledge, that it has faithfully
aggregates the local models submitted by different DPs according to the
committed aggregation weights, based on which the DPs can unambiguously claim
the corresponding reward. We implement a prototype of martFL and evaluate it
extensively over various tasks. The results show that martFL can improve the
model accuracy by up to 25% while saving up to 64% data acquisition cost",,http://arxiv.org/abs/2309.01098,146439897,"martfl: enabling utility-driven data marketplace with a robust and
  verifiable federated learning architecture",2023-09-03T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Counterfactual Thinking is a human cognitive ability studied in a wide
variety of domains. It captures the process of reasoning about a past event
that did not occur, namely what would have happened had this event occurred,
or, otherwise, to reason about an event that did occur but what would ensue had
it not. Given the wide cognitive empowerment of counterfactual reasoning in the
human individual, the question arises of how the presence of individuals with
this capability may improve cooperation in populations of self-regarding
individuals. Here we propose a mathematical model, grounded on Evolutionary
Game Theory, to examine the population dynamics emerging from the interplay
between counterfactual thinking and social learning (i.e., individuals that
learn from the actions and success of others) whenever the individuals in the
population face a collective dilemma. Our results suggest that counterfactual
reasoning fosters coordination in collective action problems occurring in large
populations, and has a limited impact on cooperation dilemmas in which
coordination is not required. Moreover, we show that a small prevalence of
individuals resorting to counterfactual thinking is enough to nudge an entire
population towards highly cooperative standards.Comment: 18 page",10.1007/978-3-030-32722-4_5,http://arxiv.org/abs/1912.08946,89597235,counterfactual thinking in cooperation dynamics,2019-12-18T00:00:00,'Springer Science and Business Media LLC',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Reuse of data in new contexts beyond the purposes for which it was originally
collected has contributed to technological innovation and reducing the consent
burden on data subjects. One of the legal mechanisms that makes such reuse
possible is purpose compatibility assessment. In this paper, I offer an
in-depth analysis of this mechanism through a computational lens. I moreover
consider what should qualify as repurposing apart from using data for a
completely new task, and argue that typical purpose formulations are an
impediment to meaningful repurposing. Overall, the paper positions
compatibility assessment as a constructive practice beyond an ineffective
standard.Comment: To appear in the Special Issue of the Journal of Institutional and
  Theoretical Economics on ""Machine Learning and the Law"". Written for the
  Symposium on Machine Learning and the Law of the Max Planck Institute for
  Research on Collective Goods: https://www.coll.mpg.de/329557/segovia?c=6765",,http://arxiv.org/abs/2309.00939,146441582,data repurposing through compatibility: a computational perspective,2023-09-02T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"During the last years we can see how AI (Artificial Intelligence) is reappearing because of technological improvements. These improvements make possible the management of large groups of information with acceptable reply times.On the other hand, cost reductions in technology make possible that an investigation field like AI becomes to an inversion field closer to scale economies, that's why it'll be economically profitable to invert in this type of applications.One of the fastest consequences is the AI implantation in a big amount of devices of our environment, cell telephones, palms and of course, in the video game industry.This is the reason that took us to develop EvoWild, a simulation about wild life that has video game format and tools but at the same time implements AI algorithms like genetic algorithms and reasoning based in cases",,https://core.ac.uk/download/228342213.pdf,66805965,evowild: a demo­simulator about wild life,2019-09-19T10:05:39,International Journal of Interactive Multimedia and Artificial Intelligence (IJIMAI),"[{'title': 'International Journal of Interactive Multimedia and Artificial Intelligence', 'identifiers': ['issn:1989-1660', '1989-1660']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This dissertation explores staying with the trouble through design as a design theory of intimacy and intimate technology. To research and design with the subject of intimacy is to trouble and to ask for trouble, and by staying with the trouble of intimacy, to paraphrase Donna Haraway, I articulate and perform a way of designing not as a way out of trouble, but as a way of making trouble and staying with the trouble. I argue that by staying with the trouble, designers may learn to be “truly present” and respond to social, cultural and political issues of intimate technology.The methodology interweaves design research, feminist technoscience, critical theory and software studies into a critical-feminist design methodology. As a response to design and designing intimate technology I have engaged in Donna Haraway’s “Staying with the Trouble” (Donna J. Haraway 2016) and solutionism as a critique of technology development, as well as feminist theories on fantasies of “the good life” and gender and technology, and critical theories on the role of intimacy in digital culture.Within the field of interaction design research, this dissertation’s contribution can be divided into three parts: 1) an exploration of the role of intimate technologies in our everyday lives and ways of being, 2) a critical and feminist design methodology of staying with the trouble through design, and 3) design proposals that stay with the trouble of designing with intimacy.My design research has evolved through four design projects that interweave different intimate topics and technologies through varied design practices: 1. PeriodShare: an internet-connected menstrual cup. 2. Marcelle: a wearable sex toy reacting on wifi-activity. 3. Ingrid: a woman living with electromagnetic hypersensitivity. And 4. Intimate Futures: two digital personal assistants where one is pushing back on sexual harassment and the other is assisting with hormone level tracking.The main contribution of the dissertation is the design methodology staying with the trouble through design, which is an anti-solutionist approach to design that interweaves the situated, personal and political role of design. By responding to/with trouble, rather than designing solutions to problems, staying with the trouble through design aims to better understand the conflicts and responsibilities involved in complex social, cultural and political issues, in order to imagine and design still possible futures. The design methodology interweaves three practices that unfold the self-reflective, ethnographic and collaborative process of staying with the trouble through design. The first practice, the willful practice of Staying with the Wrong, is a continuous process of becoming a feminist designer and it includes actively learning to be present; question the given as given, stay with the feelings you wish would go away, continuously practice self-reflection on own positionality and using feminist humour when designing with taboos. The second practice, Curious Visiting, encourages the designer to go beyond their own positionality, by listening to stories of pleasure and pain and visiting ongoing pasts and alternatives nows. This challenges the designer’s notion of the present by interweaving fact and fiction, and it highlights that this practice is never innocent but involves risks. Lastly, the third practice Collective Imagining highlights how design by proposing future change can respond to and/or with trouble and how we collectively can engage with futures to rewrite collective imaginings and tell other possible stories within and across social and cultural contexts. Together, these three interwoven practices propose a way of staying with the trouble through design, as a feminist contribution to current critical approaches within interaction design.",10.7146/aul.289.203,https://core.ac.uk/download/229217501.pdf,67302493,staying with the trouble through design: critical-feminist design of intimate technology,2018-12-03T00:00:00,'Aarhus University Library',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Nowadays, there is an ever-increasing number of artificial intelligence inference workloads pushed and executed on the cloud. To effectively serve and manage the computational demands, data center operators have provisioned their infrastructures with accelerators. Specifically for GPUs, support for efficient management lacks, as state-of-the-art schedulers and orchestrators, threat GPUs only as typical compute resources ignoring their unique characteristics and application properties. This phenomenon combined with the GPU over-provisioning problem leads to severe resource under-utilization. Even though prior work has addressed this problem by colocating applications into a single accelerator device, its resource agnostic nature does not manage to face the resource under-utilization and quality of service violations especially for latency critical applications.
In this paper, we design a resource aware GPU scheduling framework, able to efficiently colocate applications on the same GPU accelerator card. We integrate our solution with Kubernetes, one of the most widely used cloud orchestration frameworks. We show that our scheduler can achieve 58.8% lower end-to-end job execution time 99%-ile, while delivering 52.5% higher GPU memory usage, 105.9% higher GPU utilization percentage on average and 44.4% lower energy consumption on average, compared to the state-of-the-art schedulers, for a variety of ML representative workloads",10.4230/oasics.parma-ditam.2021.4,https://core.ac.uk/download/395342814.pdf,39975885,resource aware gpu scheduling in kubernetes infrastructure,2021-01-01T00:00:00,OASIcs - OpenAccess Series in Informatics. 12th Workshop on Parallel Programming and Run-Time Management Techniques for Many-core Architectures and 10th Workshop on Design Tools and Architectures for Multicore Embedded Computing Platforms (PARMA-DITAM 2021),[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This research aimed at designing a lesson plan in elementary social studies that enhances interactivity by utilizing information and communications technology (ICT). Taking into consideration that lessons created along with students and ICT-based elementary social studies classes enhance students’ learning, and based on the features of iPad, applications, and Zoom, a lesson for the fifth grade—called “Agriculture in Japan-Smart Agriculture in Yabu City, National Strategic Special Zone”—was designed. To clarify the actual situation pertaining to ICT utilization in the classroom, the lesson plan was examined from the perspectives of “information gathering,” “information examination/thinking,” and “reflection.” Information gathering enabled searching the Web for supplementary/additional materials using learning content-related keywords, and also helped share information and enhance teaching materials. Information examination/thinking enabled the use of map-based applications to improve reading skills. Zoom also enabled interaction with persons mentioned in the learning and teaching materials. This way, students could apply their learning beyond the classroom to the real world. LoiLoNote, a class-support application, helped organize thoughts on cards. Like a portfolio, students were able to build a learning history on their own. All these made instant sharing of classmates’ learning possible. Thus, utilizing ICT contributed to upgrading teaching and learning style and designing elementary school social-studies lessons to enhance interactivity",,https://core.ac.uk/download/539979523.pdf,128511693,improving interactivity in instructional design by developing an ict-based social studies plan: case study of smart agriculture in the national strategic special zone of hyogo prefecture’s yabu city,2022-01-01T00:00:00,The International Social Studies Assosiation,"[{'title': None, 'identifiers': ['issn:2434-1797', '2434-1797']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The role of computing has aided humankind for over thousands of years, helping them with calculating and crunching large numbers with ease. Although it has been around for millenniums, the advancement we had in these past few decades has been significantly greater than the past century. Intel 4004 was leading the technology revolution, creating the first ever single chip microprocessor containing 2300 transistors and producing 60,000 instructions per second. Consequently, the computing power exponentially grew to achieve a performance rate of over four million times the speed of the original microprocessor. The advancement of computing has allowed us to solve all different types of problems in various fields. With the development of computation power, pure scientists, doctors, economists, engineers, and even musicians can use the power of computation to solve problems they would never have been able to solve before. The advancement of computing gives birth to several new fields all under the name of Interdisciplinary computing. Interdisciplinary computing is the foundation for solving all sorts of problems faced in different types of fields",,https://core.ac.uk/download/303928167.pdf,84852988,the interdisciplinary aspects of computing,2019-06-17T17:49:12,ScholarSpace @ JCCC,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Text evaluation has historically posed significant challenges, often
demanding substantial labor and time cost. With the emergence of large language
models (LLMs), researchers have explored LLMs' potential as alternatives for
human evaluation. While these single-agent-based approaches show promise,
experimental results suggest that further advancements are needed to bridge the
gap between their current effectiveness and human-level evaluation quality.
Recognizing that best practices of human evaluation processes often involve
multiple human annotators collaborating in the evaluation, we resort to a
multi-agent debate framework, moving beyond single-agent prompting strategies.
The multi-agent-based approach enables a group of LLMs to synergize with an
array of intelligent counterparts, harnessing their distinct capabilities and
expertise to enhance efficiency and effectiveness in handling intricate tasks.
In this paper, we construct a multi-agent referee team called ChatEval to
autonomously discuss and evaluate the quality of generated responses from
different models on open-ended questions and traditional natural language
generation (NLG) tasks. Our analysis shows that ChatEval transcends mere
textual scoring, offering a human-mimicking evaluation process for reliable
assessments. Our code is available at https://github.com/chanchimin/ChatEval",,http://arxiv.org/abs/2308.07201,145311684,chateval: towards better llm-based evaluators through multi-agent debate,2023-08-14T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Making sense of familiar yet new situations typically involves making
generalizations about causal schemas, stories that help humans reason about
event sequences. Reasoning about events includes identifying cause and effect
relations shared across event instances, a process we refer to as causal schema
induction. Statistical schema induction systems may leverage structural
knowledge encoded in discourse or the causal graphs associated with event
meaning, however resources to study such causal structure are few in number and
limited in size. In this work, we investigate how to apply schema induction
models to the task of knowledge discovery for enhanced search of
English-language news texts. To tackle the problem of data scarcity, we present
Torquestra, a manually curated dataset of text-graph-schema units integrating
temporal, event, and causal structures. We benchmark our dataset on three
knowledge discovery tasks, building and evaluating models for each. Results
show that systems that harness causal structure are effective at identifying
texts sharing similar causal meaning components rather than relying on lexical
cues alone. We make our dataset and models available for research purposes.Comment: 8 pages, appendi",,http://arxiv.org/abs/2303.15381,141821533,causal schema induction for knowledge discovery,2023-03-27T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The COVID-19 has changed the way we work and the way we entertain ourselves. It has forced us to remain locked up in our houses, observing and communicating worldwide through digital windows. During the period of isolation that we are experiencing, the need for social connection is greater than ever.  The physical world is experiencing a slowdown and an unprecedented phenomenon is taking place in the history of the performing arts, but culture does not stop in the digital world",10.24451/arbor.13061,https://core.ac.uk/download/354981288.pdf,99766160,music goes digital in the age of social distancing,2020-10-01T01:00:00,BFH,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Artificial intelligence is an effort to transfer intelligence that is added to a system that can be regulated in a scientific context or can be called artificial intelligence so that machines (computers) can do work as humans can do. Lung disease is a condition in which the lungs cannot function normally. Some of the most common include asthma, chronic obstructive pulmonary disease (COPD), pneumonia, tuberculosis, and lung cancer. The Dempster-Shafer method was first introduced by Dempster, who experimented with uncertainty models with a range of probabilities rather than a single probability. Application of the Dempster-Shafer method to diagnose lung disease, it can be concluded that inference techniques are easy to use in designing expert systems to get a conclusion but, it has weaknesses in finding these conclusions if the system has a large enough knowledge base and this will be very much use time and hinder the consultation process",,https://core.ac.uk/download/487571484.pdf,122920304,implementation of forward inference reasoning implementing the dempster-shafer method for diagnosis of lung disease symptoms,2021-06-01T01:00:00,ASEAN Institute for Health Development,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Large language models (LLMs) can understand human instructions, showing their
potential for pragmatic applications beyond traditional NLP tasks. However,
they still struggle with complex instructions, which can be either complex task
descriptions that require multiple tasks and constraints, or complex input that
contains long context, noise, heterogeneous information and multi-turn format.
Due to these features, LLMs often ignore semantic constraints from task
descriptions, generate incorrect formats, violate length or sample count
constraints, and be unfaithful to the input text. Existing benchmarks are
insufficient to assess LLMs' ability to understand complex instructions, as
they are close-ended and simple. To bridge this gap, we propose CELLO, a
benchmark for evaluating LLMs' ability to follow complex instructions
systematically. We design eight features for complex instructions and construct
a comprehensive evaluation dataset from real-world scenarios. We also establish
four criteria and develop corresponding metrics, as current ones are
inadequate, biased or too strict and coarse-grained. We compare the performance
of representative Chinese-oriented and English-oriented models in following
complex instructions through extensive experiments. Resources of CELLO are
publicly available at https://github.com/Abbey4799/CELLO",,http://arxiv.org/abs/2309.09150,148052663,can large language models understand real-world complex instructions?,2023-09-17T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The article presents a comparative analysis of the fundamental neuroevolutional methods, which are widely applied for the intellectualization of the decision making support systems under uncertainty. Based on this analysis the new neuroevolutionary method is introduced. It is intended to modify both the topology and the parameters of the neural network, and not to impose additional constraints on the individual. The results of the experimental evaluation of the performance of the methods based on the series of benchmark tasks of adaptive control, classification and restoration of damaged data are carried out. As criteria of the methods evaluation the number of failures and the total number of evolution epochs are used",,https://core.ac.uk/download/215370515.pdf,62525150,neuroevolutional methods for decision support under uncertainty,2019-02-28T08:00:00,NSUWorks,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"One impact of the industrial revolution is the development of computer systems, including the birth of ChatGPT. ""ChatGPT (Generative Pre-trained Transformer) is a large-scale natural language processing model developed by OpenAI to generate text similar to human language. The model is trained on massive textual data and can produce diverse text output, including chatbot responses, article summaries, concept explanations, and more."" (OpenAI, 2022). The ability of ChatGPT influences the way of writing, including scientific writing",10.20956/icon.v7i2.25634,https://core.ac.uk/download/555362999.pdf,140121028,"editorial: chatgpt, the blade in scientific  writing",2023-02-28T00:00:00,"'Hasanuddin University, Faculty of Law'",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Constraint satisfaction problems (CSPs) are about finding values of variables
that satisfy the given constraints. We show that Transformer extended with
recurrence is a viable approach to learning to solve CSPs in an end-to-end
manner, having clear advantages over state-of-the-art methods such as Graph
Neural Networks, SATNet, and some neuro-symbolic models. With the ability of
Transformer to handle visual input, the proposed Recurrent Transformer can
straightforwardly be applied to visual constraint reasoning problems while
successfully addressing the symbol grounding problem. We also show how to
leverage deductive knowledge of discrete constraints in the Transformer's
inductive learning to achieve sample-efficient learning and semi-supervised
learning for CSPs.Comment: 22 pages. The Eleventh International Conference on Learning
  Representations (ICLR 2023",,http://arxiv.org/abs/2307.04895,144519778,"learning to solve constraint satisfaction problems with recurrent
  transformer",2023-07-10T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper encompasses three contributions by industry professionals and university researchers. The contributions describe different trends in automotive products, including both manufacturing test and run-time reliability strategies. The subjects considered in this session deal with critical factors, from optimizing the final test before shipment to market to in-field reliability during operative life",10.1109/ets54262.2022.9810388,https://core.ac.uk/download/539314548.pdf,141538825,"test, reliability and functional safety trends for automotive system-on-chip",2022-01-01T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Author\u27s Foreword: I “wrote” this article while taking a bath with a bottle of champagne, by submitting the questions in bold to ChatGPT and copying its responses. I did not bother providing citations for ChatGPT’s claims, because they would obviously be superfluous.
Editor-in-Chief\u27s Foreword: In 2023, the question is unavoidable: when it comes to scholarship, and in our case, legal scholarship, what do we do about artificial intelligence (AI) like ChatGPT? Do we need to do anything? In the Comment that follows, author Brian L. Frye and ChatGPT tried to provide an answer to these questions. Actually, ChatGPT did most of the answering, responding to the questions Professor Frye asked it late last year.
When the opportunity came to present the results of that “interview,” we could not say no. At the same time, we would be lying if we said that we knew exactly how to present the piece. This remained a topic of discussion throughout its publication process, from seemingly simple questions like “How do we label this?” to ones that turned out surprisingly complex, like “Does this need footnotes?” Being a student law journal, of course we landed on adding footnotes: they are our lifeblood. Not only do the claims ChatGPT make warrant some version of fact-checking, but also even though it assembles its answers from piles of existing data out there in the world, readers deserve some context surrounding those answers and those piles. How do we, as editors, edit ChatGPT’s sentences when those sentences are basically just statistically-likely strings of words? Suffice it to say, our editorial team still has differences of opinion on those questions and a whole lot more.
That said, this piece has far fewer citations than a traditional article, and most are tangential to their related “proposition” in the text. As ChatGPT describes its own operation below, it essentially uses everything as a source; and if everything is a source, how can one cite anything? Therefore, many citations will point not necessarily to support for any given “proposition,” but rather to writing by Professor Frye on similar subject matter—after all, his queries generated the responses—or other sources of commentary that can further inform the reader about the issues raised. Is it worth asking whether these are “propositions” at all, or simply an assortment of symbols that has some appearance of intentional ordering, almost like the English-language equivalent of a successfully completed Sudoku? Probably. Citations also dwindle in the piece’s latter half; at that point ChatGPT appears to start cannibalizing and/or reusing its own answers, so providing citations seemed . . . inapposite.
There are some things we do know for sure: while his scholarship has covered numerous topics, Professor Frye has written extensively on the problems of originality, the potential obsolescence of copyright, and the embrace of plagiarism, continuously challenging our conventional wisdom on those subjects—as well as the usefulness of traditional academic writing in the first place. (You will see reference to his works below.) Within that context, this Comment serves as a new provocation, in every sense of the term, requiring us to ask some uncomfortable questions about how we see authorship, creativity, and scholarship.
And it is in this light that we ask readers to approach what follows by keeping the following questions in mind—questions we continue to ask ourselves: what do we think of when we think of originality? Does authorship require a human presence? If ChatGPT can appear to make academic sense—even though it has no conception of the reality the words it uses refers to—what does that say about the current form of scholarship? Whatever your answers might be, what follows is our attempt to present the conversation between Professor Frye and ChatGPT in a good-natured way by adding a little context, providing some additional resources, and poking a little fun at everyone involved. We are (pretty) sure ChatGPT would appreciate the joke . . . if it knew what a joke was.
Text written by the author appears in bold type; text generated by ChatGPT appears in italics. We hope you enjoy",,https://core.ac.uk/download/572722475.pdf,146471160,should using an ai text generator to produce academic writing be plagiarism?,2023-01-01T08:00:00,FLASH: The Fordham Law Archive of Scholarship and History,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"IRL Programs Debut; Short & Sweet Pandemic Film Fest; New MS in Artificial Intelligence; Virtual Experts Talks; DePaul Trustee Producing Documentary; DemonHacks Hackathon; Silicon Valley 2.0: The DePaul Innovation Development Lab connects students and companies to spark solutions to technological challenges; Code Warrior: Ovetta Sampson has risen to challenges in digital design, journalism and athletics while inspiring others; Pattern Recognition: A CDM health informatics team joins a global race to advance COVID-19 diagnostics through X-ray insight",,https://core.ac.uk/download/428374061.pdf,113274313,spring 2021,2021-05-05T08:00:00,DePaul University,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We present a framework able to combine exposure indicators and predictive analytics using AI-tools and big data architectures for threats detection inside a real industrial IoT sensors network. The described framework, able to fill the gaps between these two worlds, provides mechanisms to internally assess and evaluate products, services and share results without disclosing any sensitive and private information. We analyze the actual state of the art and a possible future research on top of a real case scenario implemented into a technological platform being developed under the H2020 ECHO project, for sharing and evaluating cybersecurity relevant informations, increasing trust and transparency among different stakeholders",10.1109/metroind4.0iot48571.2020.9138184,https://core.ac.uk/download/541660227.pdf,134362925,combining exposure indicators and predictive analytics for threats detection in real industrial iot sensor networks,2020-01-01T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"La amenaza híbrida es un concepto que aparece en documentos oficiales y estrategias de seguridad de los estados. Tanto la UE como la OTAN han tomado medidas serias para contrarrestar la actividad relacionada con las amenazas híbridas. Este monográfico sobre comunicación digital y amenazas híbridas tiene como objetivo avanzar en la comprensión de cómo los actores de amenazas híbridas utilizan y pueden potencialmente explotar el entorno de la información para atacar las sociedades democráticas y los procesos de toma de decisiones en diferentes niveles, para diferentes propósitos. Las TIC han traído avances notables en la forma en que obtenemos información y construimos conciencia sobre el mundo y sus eventos e interactuamos con los demás, pero al mismo tiempo crean oportunidades para realizar operaciones&nbsp; e influenciar con una intención hostil. La guerra política, las medidas activas y las acciones encubiertas dirigidas por la comunicación no son nuevas, y la propaganda se ha utilizado a lo largo de la historia en situaciones de conflicto y guerra. Estas herramientas son empleadas por actores autoritarios hostiles y / o en una escala que ha interferido en procesos democráticos como las elecciones, erosiona la confianza en las instituciones, polariza y divide las sociedades de manera malsana. Dado que los seres humanos toman decisiones basadas en sus representaciones sobre el mundo y la información disponible a través de interacciones simbólicas interpersonales y a través de los diferentes medios, la información puede ser utilizada deliberadamente para actividades malignas que produzcan efectos cognitivos, afectivos y conductuales.Hybrid Threats is a concept that has entered to many states official documents and security strategies. Both the EU and NATO have taken serious measures to counter hybrid threats related activity. This special issue on digital communication and hybrid threats aims to advance our understanding of how hybrid threat actors use and can potentially exploit the information environment for targeting our democratic societies and decision-making processes at different levels for different purposes. Information and communication technologies have brought remarkable advances in the ways we obtain information and build awareness on the world and its events and interact with the others, but at the same time these developments create opportunities for conducting information and influence operations with a hostile intent at an unprecedent scale.Political warfare, active measures, and communication-led covert actions operations are not new, and propaganda has been used throughout the history in conflict and war like situations.However today our digital communication environment and the communication tools that we employ for legitimate purposes are also being employed by hostile authoritarian actors and / or their proxies at scale that has interfered in our democratic processes like elections, erode trust in our institutions, polarize and divide our societies in an unhealthy ways and sow animosities between states and international partner countries. Since human beings make decisions based on their representations about the world and the information available through interpersonal symbolic interactions and through the different media, information can be deliberately utilized for malign activity to produce cognitive, affective and behavioral effects.Ameaças híbridas é um conceito que entrou em documentos oficiais e estratégias de segurança de muitos estados. Tanto a UE como a OTAN tomaram medidas sérias para combater a atividade relacionada com ameaças híbridas. Esta edição especial sobre comunicação digital e ameaças híbridas tem como objetivo avançar nossa compreensão de como os atores de ameaças híbridas usam e podem explorar o ambiente de informações para direcionar nossas sociedades democráticas e processos de tomada de decisão em diferentes níveis para diferentes fins. As tecnologias de informação e comunicação trouxeram avanços notáveis ​​nas maneiras como obtemos informações e construímos consciência sobre o mundo e seus eventos e interagimos com os outros, mas, ao mesmo tempo, esses desenvolvimentos criam oportunidades para conduzir informações e influenciar operações com uma intenção hostil em um escala sem precedentes.&nbsp;A guerra política, as medidas ativas e as operações de ações secretas conduzidas pela comunicação não são novas, e a propaganda foi usada ao longo da história em conflitos e situações semelhantes à guerra. No entanto, hoje nosso ambiente de comunicação digital e as ferramentas de comunicação que empregamos para fins legítimos também estão sendo empregados por atores autoritários hostis e / ou seus representantes em escala que tem interferido em nossos processos democráticos como eleições, corroendo a confiança em nossas instituições, polarizando e dividindo nossas sociedades de forma prejudicial à saúde e semeiam animosidades entre Estados e países parceiros internacionais.&nbsp",10.7195/ri14.v19i1.1662,https://core.ac.uk/download/386290751.pdf,107342636,comunicação digital e ameaças híbridas,2021-01-01T00:00:00,'Asociacion Cientifica ICONO14',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Email threat is a serious issue for enterprise security, which consists of
various malicious scenarios, such as phishing, fraud, blackmail and
malvertisement. Traditional anti-spam gateway commonly requires to maintain a
greylist to filter out unexpected emails based on suspicious vocabularies
existed in the mail subject and content. However, the signature-based approach
cannot effectively discover novel and unknown suspicious emails that utilize
various hot topics at present, such as COVID-19 and US election. To address the
problem, in this paper, we present Holmes, an efficient and lightweight
semantic based engine for anomalous email detection. Holmes can convert each
event log of email to a sentence through word embedding then extract
interesting items among them by novelty detection. Based on our observations,
we claim that, in an enterprise environment, there is a stable relation between
senders and receivers, but suspicious emails are commonly from unusual sources,
which can be detected through the rareness selection. We evaluate the
performance of Holmes in a real-world enterprise environment, in which it sends
and receives around 5,000 emails each day. As a result, Holmes can achieve a
high detection rate (output around 200 suspicious emails per day) and maintain
a low false alarm rate for anomaly detection",,http://arxiv.org/abs/2104.08044,121309612,"holmes: an efficient and lightweight semantic based anomalous email
  detector",2021-12-02T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This research believes that understanding the relationship between Interactive Architecture and the principles of biology will become a mainstream research area in future architectural design. Aiming towards achieving the goal of “making architecture as organic bodies”, almost all the current digital techniques in architectural design are executed using computational simulation: digital fabrication technologies and physical computing. Based on its’ main biological inspirations, Evolutionary Development Biology (Evo-Devo), this research intends to propose a novel bio-inspired design thinking wherein architecture should become analogs to the growing process of living organisms (Figure 6.1). Instead of being born from static optimization results most of the architecture seems content at aiming for nowadays, this research is looking towards designing dynamic architectural bodies which can adapt to the constantly changing environments and are thus seeking optimization in real-time. In other words, architecture should come “alive” as a living creature in order to actively optimize itself with respect to dynamic environmental conditions and user behavior’ requirements in real-time. Following the notion of “architecture as organic bodies”, six major topics were derived from the publication of “New Wombs: Electric Bodies and Architectural Disorders” (Palumbo, 2000). These topics are aimed at initiating critical discussions between body and space, which, are used here to re-interpret six&nbsp;main traits of being an interactive architecture: Dis-measurement, Uprooting, Fluidity, Visceral Nature, Virtuality, and Sensitivity. These six topics merge diverse key points from aforementioned chapters including outlining the vision of active interacting architecture, the transformation of human bodies under digital culture, the profound biological inspiration from Evo-Devo and the fundamental componential notion of swarm, which leads to the ultimate notion of embodying organic body-like interactive Bio-architecture.
Dis-measurement: Acknowledging the premise of “architecture (technology) as an extension of human bodies” proposed by Marshall McLuhan (McLuhan, Understanding Media: The Extensions of Man, 1964), it is, still difficult to explicitly define the boundary of a space, especially in the context of a borderless cyberspace (the Internet). Space in such a context expands more than ever before and thus makes traditional measurements techniques unfeasible. With cyberspace, people can be virtually present in different places at the same time, thus breaking existing physical boundaries of a space. From another point of view, space as an extension of our bodies constantly adapting to environmental conditions and user demands, creates an intimate linkage between physical bodies and spatial bodies. Interaction in such instances can be seen from a micro-scale: between biological cells and intelligent architectural components to the macro-scale: between physical organic bodies and spatial bodies/architectural space.
Uprooting: Apart from further extending the “Dis-measurement” idea by directly plugging into cyberspace (the Internet), “Uprooting” is also interpreted as adaptation devoid of any site/location constraints. In other words, the idea of “Uprooting” implies, generating an architecture that can adjust/modify in accordance with its existing surroundings by interactions between its smallest intelligent components like cells in a body searching for dynamic equilibrium. In this case, architecture has no particular reason to be designed as “rooted” on sites.
Fluidity: With the neural system inside the body, most of the messages can be transmitted, received and sent within less than a millionth of a second. To envision architecture as an information processor, which has abilities to react to dynamic environmental conditions and user demands, efficient information protocols must be built into such an organic architectural body to create seamless exterior/interior transformations.
Visceral Nature: Visceral can be interpreted in the form of an embodied organ. This implies envisioning architecture in the form of a living-entity. It is no longer the case of mimicking a natural form and thus claiming a building to be organic, but rather instigates one to look deeper into the principles of a natural form’s morphogenesis&nbsp;and apply these to generate a truly organic space. Through the study of Evo-Devo, several principles will be applied to generate an interactive organic Bio-architecture. It is thus not an organic looking shape that matters, but the principles behind the shape, which matter. For instance, principles of self-organization, self-assembly, and self-adaptation, providing possibilities of making body-like architectures with multi-directional and multi-modal communications both inside out and outside in. An intelligent architecture, should “live” in the environment just as how the body lives with its’ Visceral Nature.
Virtuality: It is impossible to talk about physical space without mentioning virtual space nowadays. From cyberspace, augmented reality to virtual reality, “Virtuality” is related to “interaction” since the beginning and has gradually become an inevitable aspect of our daily lives. In fact, virtual space has to still use constraints from the physical world to enhance experiential aspects. The ultimate goal of virtual reality here is not to end up with a VR helmet and keep constantly being stimulated by electronic messages, but to bring the physical to the virtual and in the process, attempt to search for a dynamic balance between the virtual and real by merging them together. With the assistance of virtual reality, novel unrealistic space can still be realized into creative tangible immersive and fascinating spaces, which, earlier was not possible.
Sensitivity: The notion of “architecture is an extension of human bodies”, is crucial to embrace, if we consider enhancing the sensing abilities of the space as a body not only externally but also internally. In a digital space, active sensing can be achieved by attaching specific devices. In an interactive space, like an organic body, the sensing capabilities of the space have to be fast, accurate, intuitive, and predictive. The sensing system should thus not only work externally to sense the surrounding environment but also internally in order to fulfill the users’ demands in time. With such a connection between human bodies and spatial bodies, it should become relatively understandable for the space to know the requirements of the users by means of hand gestures instead of verbal cues. The sensitivity, in this case, should rely on local information distribution as a bottom-up system rather than a top-down centralized demanding structure",10.7480/abe.2018.1.3753,https://core.ac.uk/download/268413251.pdf,74920788,hypercell,2018-12-20T00:00:00,TU Delft Open,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We present an exact Bayesian inference method for discrete statistical
models, which can find exact solutions to many discrete inference problems,
even with infinite support and continuous priors. To express such models, we
introduce a probabilistic programming language that supports discrete and
continuous sampling, discrete observations, affine functions, (stochastic)
branching, and conditioning on events. Our key tool is probability generating
functions: they provide a compact closed-form representation of distributions
that are definable by programs, thus enabling the exact computation of
posterior probabilities, expectation, variance, and higher moments. Our
inference method is provably correct, fully automated and uses automatic
differentiation (specifically, Taylor polynomials), but does not require
computer algebra. Our experiments show that its performance on a range of
real-world examples is competitive with approximate Monte Carlo methods, while
avoiding approximation errors",,http://arxiv.org/abs/2305.17058,146326715,"exact bayesian inference on discrete models via probability generating
  functions: a probabilistic programming approach",2023-08-24T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Deep learning-based solutions and, in particular, deep neural networks (DNNs) are at the heart of several functionalities in critical-real time embedded systems (CRTES) from vision-based perception (object detection and tracking) systems to trajectory planning. As a result, several DNN instances simultaneously run at any time on the same computing platform. However, while modern GPUs offer a variety of computing elements (e.g. CPUs, GPUs, and specific accelerators) in which those DNN tasks can be executed depending on their computational requirements and temporal constraints, current DNNs are mainly programmed to exploit one of them, namely, regular cores in the GPU. This creates resource imbalance and under-utilization of GPU resources when executing several DNN instances, causing an increase in DNN tasks\u27 execution time requirements. In this paper, (a) we develop different variants (implementations) of well-known DNN libraries used in the Apollo Autonomous Driving (AD) software for each of the computing elements of the latest NVIDIA Xavier SoC. Each variant can be configured to balance resource requirements and performance: the regular CPU core implementation that can run on 2, 4, and 6 cores; the GPU regular and Tensor core variants that can run in 4 or 8 GPU\u27s Streaming Multiprocessors (SM); and 1 or 2 NVIDIA\u27s Deep Learning Accelerators (NVDLA); (b) we show that each particular variant/configuration offers a different resource utilization/performance point; finally, (c) we show how those heterogeneous computing elements can be exploited by a static scheduler to sustain the execution of multiple and diverse DNN variants on the same platform",10.4230/lipics.ecrts.2019.23,https://core.ac.uk/download/222445917.pdf,39971656,generating and exploiting deep learning variants to increase heterogeneous resource utilization in the nvidia xavier,2019-01-01T00:00:00,LIPIcs - Leibniz International Proceedings in Informatics. 31st Euromicro Conference on Real-Time Systems (ECRTS 2019),"[{'title': None, 'identifiers': ['1868-8969', 'issn:1868-8969']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Complex systems have become a research area with increasing interest over the last years. The emergence of new technologies, the increase in computational power with reduced resources and cost, the integration of the physical world with computer based systems has created the possibility of significantly improving the quality of life of humans. While a significant degree of automation within these systems exists and has been provided in the past decade with examples of the smart homes and energy efficient buildings, a paradigm shift towards autonomy has been noted. The need for autonomy requires the extraction of a model; while a strict mathematical formulation usually exists for the individual subsystems, finding a complete mathematical formulation for the complex systems is a near impossible task to accomplish.
For this reason, methods such as the Fuzzy Cognitive Maps (FCM) have emerged that are able to provide with a description of the complex system. The system description results from empirical observations made from experts in the related subject – integration of expert’s knowledge – that provide the required cause-effect relations between the interacting components that the FCM needs in order to be formulated. Learning methods are employed that are able to improve the formulated model based on measurements from the actual system. The FCM method, that is able to inherently integrate uncertainties, is able to provide an adequate model for the study of a complex system.
With the required system model, the next step towards the development of a autonomous systems is the creation of a control scheme. While FCM can provide with a system model, the system representation proves inadequate to be utilized to design classic model based controllers that require a state space or frequency domain representation. In state space representation, the state vector contains the variables of the system that can describe enough about the system to determine its future behavior in absence of external variables. Thus, within the components – the nodes of the FCM, ideally those can be identified that constitute the state vector of the system.
In this work the authors propose the creation of a state feedback control law of complex systems via Fuzzy Cognitive Maps. Given the FCM representation of a system, initially the components-states of the system are identified. Given the identified states, a FCM representation of the controller occurs where the controller parameters are the weights of the cause-effect relations of the system. The FCM of the system then is augmented with the FCM of the controller. An example of the proposed methodology is given via the use of the cart-pendulum system, a common benchmark system for testing the efficiency of control systems",,https://core.ac.uk/download/268078670.pdf,74685084,state feedback of complex systems using fuzzy cognitive maps,2017-10-27T21:00:00,UBT Knowledge Center,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Ever since the concept of the Internet was born, it has experienced a massive increase in the number of users. Similarly, there has been an exponential increase in the amount of information that they transmit, partly because of new technologies and services that have emerged, such as cloud and real-time communication. Customers do now demand a fast and reliable interaction, without any data loss or undesired delays. In order to meet these needs and keep up with the constantly-evolving technologies different non-profit organizations needed to devise a new technology, and this is when Software-Defined Networking (SDN) was born. Unlike traditional networks to date, it decouples the control layer from the data layer, leaving the act of forwarding traffic to the network device and delegating all network decisions to a controller, thus centralizing all the decisions, which improves network operability and agility. Despite all the improvements made with this technology, we still encounter the same problems of traditional networks regarding traffic routing. Conventional algorithms such as Dijkstra and Least Loaded (LL) based on the occupancy of the links, allocate traffic without considering the impact the chosen path could have if future traffic were to be introduced in the network. The objective of this project is to create an algorithm capable of routing traffic taking into account the future impact. To evaluate the proposed mechanism of Dijkstra, we will first obtain some experimental results using the default link weights and then base these weights on the occupancy of the links, using the Open Network Operating System (ONOS) as the SDN controller and the Multi-Generator (MGEN) tool to generate traffic. After these results, this research will use Reinforcement Learning (RL), a subcategory of Artificial Intelligence (AI), to train a RL model in Python using a network of eight interconnected switches. After the agent is trained, we have made a comparison between RL, LL, and SP, in which we have run a series of files containing flows of different rates. In conclusion, this research will exhibit that, on average, the RL algorithm consistently beats the other two algorithms by 16%, when it comes to reducing the data loss, which will improve the efficiency of the network",,https://core.ac.uk/download/576861842.pdf,150042286,reinforcement learning-based routing in sdn networks,2023-06-22T01:00:00,Universitat Politècnica de Catalunya,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"""Pneumonia is a type of acute respiratory infection
caused by microbes, and viruses that affect the lungs. Pneumonia
is the leading cause of infant mortality in the world, accounting
for 81% of deaths in children under five years of age. There are
approximately 1.2 million cases of pneumonia in children under
five years of age and 180 000 died in 2016. Early detection of
pneumonia can help reduce mortality rates. Therefore, this paper
presents four convolutional neural network (CNN) models to
detect pneumonia from chest X-ray images. CNNs were trained
to classify X-ray images into two types: normal and pneumonia,
using several convolutional layers. The four models used in this
work are pre-trained: VGG16, VGG19, ResNet50, and
InceptionV3. The measures that were used for the evaluation of
the results are Accuracy, recall, and F1-Score. The models were
trained and validated with the dataset. The results showed that
the Inceptionv3 model achieved the best performance with 72.9%
accuracy, recall 93.7%, and F1-Score 82%. This indicates that
CNN models are suitable for detecting pneumonia with high
accuracy.",10.14569/ijacsa.2022.0130963,https://core.ac.uk/download/568132204.pdf,145304527,convolutional neural networks with transfer learning for pneumonia detection,2022-01-01T00:00:00,'The Science and Information Organization',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The intersection of digital and physical security is critical to the future security of our military and national defense. Coming technological advances widen the attack plain over the next decade including cyber, physical and kinetic vulnerabilities.  Visualizing what the future will hold and what new threat vectors will emerge is a task that traditional military planning mechanisms struggle to accomplish given the wicked problem space.
Helping to understand and plan for the future operating environment is the basis of a research effort known as Threatcasting.  Arizona State University’s School for the Future of Innovation in Society in collaboration with the Army Cyber Institute at West Point use the threatcasting process to give researchers a structured way to envision and plan for risks ten years in the future. For many organization the scope of this problem can seem overwhelming.  Threatcasting, as an analytic technique, focuses on the intersection between cyber and physical domains and how it can revolutionize or paralyze the future.
Threatcasting uses inputs from social science, technical research, cultural history, economics, trends, expert interviews, and even a little science fiction. These inputs allow the creation of potential futures. By placing the threats into an effects based model (e.g. a person in a place with a problem), it allows organizations to understand what needs to be done immediately and also in the future to disrupt possible threats. The Threatcasting framework also exposes what events could happen that indicate the progression towards an increasingly possible threat landscape.
Threatcasting draws strength from futures studies, a field that provides theoretical and applied tools designed to shed light on deep uncertainties and complexities that futures hold. Foresight tools are rooted in exploratory, rather than predictive, methods of futures thinking, learning, and strategy as a means to prepare and plan for long-term outcomes that are difficult to imagine and impossible to predict. Such methods often stand in contrast to causal, linear, ‘plan and predict’ thinking that characterizes many contemporary practices of making and knowing futures.
As national security and technological possibilities change rapidly, new threats and opportunities become ever present. Threatcasting is a means to make-sense and anticipate military futures so that relevant institutions are able to anticipate, manage, navigate uncertainty and complexity ahead.  This chapter will use the weaponization of artificial intelligence as a case study to walk readers through the research technique and results.  Specifically, we will outline two case studies where the technique was applied with specific results.  One case study focuses on the digital and physical supply chain in private industry (Cisco Systems) and the second investigates similar threats to the military’s supply chain (Military Logistics Officers).
The weaponization of any organization\u27s supply chain and logistics systems poses a significant threat to national and global economic security. The very systems that are the engine of economies and the lifeline of goods and services to the world’s population could and most probably will be turned against the very people and organizations that they serve.  This new threat landscape and associated challenges will affect industry, militaries and governments through loss of revenue, productivity and even loss of life.  This weaponization will allow adversities whether they are criminal, state sponsored, terrorists or hacktivists to transform these systems from engines of productivity to enemies on the inside.
Upon reading this chapter, the student/practitioner will:
-       Have an understanding of the threatcasting methodology so to be able to apply it against other problems of interest
-       Appreciate the close ties between the advancement of technology and the effect to society, economies, and national security
-       Apply the Threatcasting methodology to the specific problem of supply chains and the weaponization of Artificial Intelligence
-      Create powerful narratives and fact-based illustrations to provide decision makers on the resultshttps://digitalcommons.usmalibrary.org/aci_books/1022/thumbnail.jp",10.1201/9780429467219-6,https://core.ac.uk/download/553286233.pdf,138171064,threatcasting in a military setting,2020-01-01T00:00:00,USMA Digital Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The Engineering Skills Special Interest Group (SIG) ran a workshop on the current challenges in teaching engineering skills. This workshop employed the “world café” participatory method where attendees visited three tables for a structured discussion with a member of the SIG. Each table posed a different question: On the What? table we discussed which skills are most relevant for future practitioners. The Who? table focussed on the differences in the way that various professional skills are conceptualised by main stakeholders. Finally, at the How? table we discussed the facilitators and barriers in designing and delivering skills education. The outcome of the workshop presented here is a mapping of skills in terms of present and future importance to attendees and their countries, and a classification of stakeholders in terms of macro, meso, micro level when considering their influence over skill conceptualisation and realisation",10.21427/rc9v-gt53,https://core.ac.uk/download/590877420.pdf,153464981,"who, what, how? tackling skills challenges: future relevance, stakeholder differences, and teaching hurdles",2023-10-10T08:00:00,Technological University Dublin,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Image classification is usually done using deep learning algorithms. Deep learning architectures are set deterministically. The aim of this paper is to propose an evolutionary computation paradigm that optimises a deep learning neural network’s architecture. A set of chromosomes are randomly generated, after which selection, recombination, and mutation are applied. At each generation the fittest chromosomes are kept. The best chromosome from the last generation determines the deep learning architecture. We have tested our method on a second trimester fetal morphology database. The proposed model is statistically compared with DenseNet201 and ResNet50, proving its competitiveness",10.15837/ijccc.2022.5.4886,https://core.ac.uk/download/539380242.pdf,126852764,evolutionary computation paradigm to determine deep neural networks architectures,2022-09-29T01:00:00,'Agora University of Oradea',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Ensuring reliable confidence scores from deep networks is of pivotal
importance in critical decision-making systems, notably in the medical domain.
While recent literature on calibrating deep segmentation networks has led to
significant progress, their uncertainty is usually modeled by leveraging the
information of individual pixels, which disregards the local structure of the
object of interest. In particular, only the recent Spatially Varying Label
Smoothing (SVLS) approach addresses this issue by softening the pixel label
assignments with a discrete spatial Gaussian kernel. In this work, we first
present a constrained optimization perspective of SVLS and demonstrate that it
enforces an implicit constraint on soft class proportions of surrounding
pixels. Furthermore, our analysis shows that SVLS lacks a mechanism to balance
the contribution of the constraint with the primary objective, potentially
hindering the optimization process. Based on these observations, we propose a
principled and simple solution based on equality constraints on the logit
values, which enables to control explicitly both the enforced constraint and
the weight of the penalty, offering more flexibility. Comprehensive experiments
on a variety of well-known segmentation benchmarks demonstrate the superior
performance of the proposed approach.Comment: Under revie",,http://arxiv.org/abs/2303.06268,141346882,trust your neighbours: penalty-based constraints for model calibration,2023-03-10T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"As the product of combining Internet of Things (IoT), cloud computing, and traditional healthcare, Intelligent IoT Healthcare (IIoTH) brings us a lot of convenience, meanwhile security and privacy issues have attracted great attention. Dynamic searchable symmetric encryption (DSSE) technique can make the user search the dynamic healthcare information from IIoTH system under the condition that the privacy is protected. In this article, a novel privacy-preserving DSSE scheme for IIoTH system is proposed. It is the first DSSE scheme designed for personal health record (PHR) files database with forward security. We construct the secure index based on hash chain and realize trapdoor updates for resisting file injection attacks. In addition, we realize fine-grained search over encrypted PHR files database of attribute-value type. When the user executes search operations, he/she gets only a matched attribute value instead of the whole file. As a result, the communication cost is reduced and the disclosure of patient's privacy is minimized. The proposed scheme also achieves attribute access control, which allows users have different access authorities to attribute values. The specific security analysis and experiments show the security and the efficiency of the proposed scheme",10.1109/tii.2021.3100873,https://core.ac.uk/download/492534655.pdf,70041001,achieving privacy-preserving dsse for intelligent iot healthcare system,2022-03-01T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"I, Copyrigh",,https://core.ac.uk/download/216973899.pdf,63229249,"i, copyright",2018-11-13T08:00:00,Santa Clara Law Digital Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The emergence of big data requires powerful computational resources and memory subsystems that can be scaled efficiently to accommodate its demands. Cloud is a new well-established computing paradigm that can offer customized computing and memory resources to meet the scalable demands of big data applications. In addition, the flexible pay-as-you-go pricing model offers opportunities for using large scale of resources with low cost and no infrastructure maintenance burdens. High performance computing (HPC) on the other hand also has powerful infrastructure that has potential to support big data applications. In this dissertation, we explore the application and system co-optimization opportunities to support big data in both cloud and HPC environments. 
Specifically, we explore the unique features of both application and system to seek overlooked optimization opportunities or tackle challenges that are difficult to be addressed by only looking at the application or system individually. Based on the characteristics of the workloads and their underlying systems to derive the optimized deployment and runtime schemes, we divide the workflow into four categories: 1) memory intensive applications; 2) compute intensive applications; 3) both memory and compute intensive applications; 4) I/O intensive applications.When deploying memory intensive big data applications to the public clouds, one important yet challenging problem is selecting a specific instance type whose memory capacity is large enough to prevent out-of-memory errors while the cost is minimized without violating performance requirements. In this dissertation, we propose two techniques for efficient deployment of big data applications with dynamic and intensive memory footprint in the cloud. The first approach builds a performance-cost model that can accurately predict how, and by how much, virtual memory size would slow down the application and consequently, impact the overall monetary cost. The second approach employs a lightweight memory usage prediction methodology based on dynamic meta-models adjusted by the application's own traits. The key idea is to eliminate the periodical checkpointing and migrate the application only when the predicted memory usage exceeds the physical allocation. When applying compute intensive applications to the clouds, it is critical to make the applications scalable so that it can benefit from the massive cloud resources.  In this dissertation, we first use the Kirchhoff law, which is one of the most widely used physical laws in many engineering principles, as an example workload for our study. The key challenge of applying the Kirchhoff law to real-world applications at scale lies in the high, if not prohibitive, computational cost to solve a large number of nonlinear equations. In this dissertation, we propose a high-performance deep-learning-based approach for Kirchhoff analysis, namely HDK. HDK employs two techniques to improve the performance: (i) early pruning of unqualified input candidates which simplify the equation and select a meaningful input data range; (ii) parallelization of forward labelling which execute steps of the problem in parallel. When it comes to both memory and compute intensive applications in clouds, we use blockchain system as a benchmark. Existing blockchain frameworks exhibit a technical barrier for many users to modify or test out new research ideas in blockchains. To make it worse, many advantages of blockchain systems can be demonstrated only at large scales, which are not always available to researchers. In this dissertation, we develop an accurate and efficient emulating system to replay the execution of large-scale blockchain systems on tens of thousands of nodes in the cloud. For I/O intensive applications, we observe one important yet often neglected side effect of lossy scientific data compression. Lossy compression techniques have demonstrated promising results in significantly reducing the scientific data size while guaranteeing the compression error bounds, but the compressed data size is often highly skewed and thus impact the performance of parallel I/O. Therefore, we believe it is critical to pay more attention to the unbalanced parallel I/O caused by lossy scientific data compression",,https://core.ac.uk/download/534445763.pdf,152609829,big data application and system co-optimization in cloud and hpc environment,2022-06-28T02:21:15,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Visuals are a core part of our experience of music, owing to the way they can
amplify the emotions and messages conveyed through the music. However, creating
music visualization is a complex, time-consuming, and resource-intensive
process. We introduce Generative Disco, a generative AI system that helps
generate music visualizations with large language models and text-to-image
models. Users select intervals of music to visualize and then parameterize that
visualization by defining start and end prompts. These prompts are warped
between and generated according to the beat of the music for audioreactive
video. We introduce design patterns for improving generated videos:
""transitions"", which express shifts in color, time, subject, or style, and
""holds"", which encourage visual emphasis and consistency. A study with
professionals showed that the system was enjoyable, easy to explore, and highly
expressive. We conclude on use cases of Generative Disco for professionals and
how AI-generated content is changing the landscape of creative work",,http://arxiv.org/abs/2304.08551,142421460,generative disco: text-to-video generation for music visualization,2023-04-17T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"3D pose estimation is a challenging problem in computer vision. Most of the
existing neural-network-based approaches address color or depth images through
convolution networks (CNNs). In this paper, we study the task of 3D human pose
estimation from depth images. Different from the existing CNN-based human pose
estimation method, we propose a deep human pose network for 3D pose estimation
by taking the point cloud data as input data to model the surface of complex
human structures. We first cast the 3D human pose estimation from 2D depth
images to 3D point clouds and directly predict the 3D joint position. Our
experiments on two public datasets show that our approach achieves higher
accuracy than previous state-of-art methods. The reported results on both ITOP
and EVAL datasets demonstrate the effectiveness of our method on the targeted
tasks",10.1109/jsen.2020.2999849,http://arxiv.org/abs/2212.12910,137358655,learning to estimate 3d human pose from point cloud,2022-12-25T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"To analyse the previous website which means the original website. Trying to make more attractive and interesting. Methods: Analyse the old website. A website redesign shouldn’t just change the overall look of your website. It should enhance the ways in which it functions. Find out what is working on the current website. Building the website design plan. Added strong visual features and elements. Findings: website overall feels outdated i.e., make it more attractive and add some animated clip. Applications: the study highlighted various issues, redesign a IBM company website and you’re going to see that with very small tweaks to the layout and composition and have a dramatic impact on the webs design. The first thing notice is I’m overwhelmed, right in terms of graphic design terms of hierarchies there are so many things here they just try to grab attention, there is a image, styling so that grab my attention so many things are competing for my attention that just overwhelmed so, this is not a good user experience. First thing that that we were thinking about even before trying to get into what we do they even do here on the website is how can we simplify what’s going on here how can we create very clear hierarchies. We were thinking about how we can simplify this visually. A lot of times there’s so many things we can do here such as illustration, 3D rendering of this, do custom photography there’s so many ways to approach this. We can present it in a very interesting wa",10.17762/ijritcc.v10i2.5499,https://core.ac.uk/download/539909799.pdf,133372681,website redesign with animation,2022-03-04T00:00:00,"'Auricle Technologies, Pvt., Ltd.'",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"System of education, included vocational education is seen as one important barometer for ensuring the national education system of a nation. In this context, the quality of teachers, including vocational teachers is the main factor affecting the quality of educational systems. This research focuses on the implementation of a multi entry multi exit system in Vocational Secondary School (VSS) in West Java. This system of learning is the development of integrated and sustainable industry-based learning. It is expected to build a balance between developing competencies and developing work character/culture that support each other to produce vocational graduates ready to work quality and competitiveness. The method used is descriptive evaluative with CIPP (Context, Input, Process and Product) design. The case of this study is to evaluate about how much is the significance of the implementation of the multi entry and exit system implemented at SMK and industry by graduates ready to work. The results of the evaluation of the above problems identified thath the multi entry multi exit system can increase 1-2% of graduates absorbed by the industry. The discussion of this study formulated the need for inovating multi entry multi exit systemby carrying out a series of activities as follows; synchronize curriculum, integrating learning with industry and industry class program, internship teacher and student at industry, self-service work development and or entrepreneurship as a condition to get a diploma",10.22158/asir.v4n2p70,https://core.ac.uk/download/327125193.pdf,86772563,a study of multi entry and multi exit education system in increasing vocational high school graduates skills,2020-05-27T01:00:00,"'Scholink Co, Ltd.'",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This report describes the process and results of futures clinique Surprising Energy Futures: Anticipating Discontinuities and Testing Resilience of Renewable Energy World with Black Swans, held on 17 May 2017 at Sitra, Helsinki. The event was the fifth futures clinique within the foresight part of the research project Neo-Carbon Enabling Neo-Growth Society – Transformative Scenarios 2050, conducted by Finland Futures Research Centre. The aim of the event was to contribute to the four transformative societal scenarios of Neo-Carbon Energy project. The event consisted of presentations and intermittent working sessions. Dr. Karlheinz Steinmüller discussed the topic of Black Swans and VUCA World, with comments by Prof. Jarno Limnéll",,https://core.ac.uk/download/200332681.pdf,58926968,surprising energy futures : neo-carbon energy futures clinique v,2019-05-21T01:00:00,"fi=Turun yliopisto. Turun kauppakorkeakoulu|en=University of Turku, Turku School of Economics|",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Valuing chess squares and determining the placement of pieces on the board
are the main objectives of our study. With the emergence of chess AI, it has
become possible to accurately assess the worth of positions in a game of chess.
The conventional approach assigns fixed values to pieces $(\symking=\infty,
\symqueen=9, \symrook=5, \symbishop=3, \symknight=3, \sympawn=1)$. We enhance
this analysis by introducing marginal valuations for both pieces and squares.
We demonstrate our method by examining the positioning of Knights and Bishops,
and also provide valuable insights into the valuation of pawns. Notably,
Nimzowitsch was among the pioneers in advocating for the significance of Pawn
structure and valuation. Finally, we conclude by suggesting potential avenues
for future research",10.3390/e25101374,http://arxiv.org/abs/2307.05330,144519167,the value of chess squares,2023-07-08T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Driven by networked Electronic Health Record systems, Artificial Intelligence, real-time data from wearable devices with an overlay of invisible user interfaces and improved analytics, a revolution is afoot in the healthcare industry. Over the next few years, it is likely to fundamentally change how healthcare is delivered and how the outcomes are measured. The focus on collaboration, coherence, and convergence will make healthcare more predictive and personalised. This revolution is called Health 4.0. Data portability allows patients and their physicians to access it anytime anywhere and enhanced analytics allows for differential diagnosis and medical responses that can be predictive, timely, and innovative. Health 4.0 allows the value of data more consistently and effectively. It can pinpoint areas of improvement and enable decisions that are more informed. What it also does is help move the entire healthcare industry from a system that is reactive and focused on fee-for-service to a system that is value-based, which measures outcomes and ensures proactive prevention (Thuemmler, Bai, 2017). In this paper, the authors discuss how digitisation is paving the way for data-driven innovation in the healthcare systems. They elaborate on the opportunities and challenges for all stakeholders involved and discuss how emerging technologies can help overcome the inherent rigidity of today’s healthcare ecosystem. Following on from this, the authors explain the importance of research on the actual design of smart healthcare products and product service systems of the future and the challenges faced from the viewpoint of design practice",,https://core.ac.uk/download/288393311.pdf,8217141,health 4.0: how digitisation drives innovation in the healthcare sector,2019-01-01T00:00:00,The Society of Systematic Innovation,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In the paper we define three new complexity classes for Turing Machine
undecidable problems inspired by the famous Cook/Levin's NP-complete complexity
class for intractable problems. These are U-complete (Universal complete),
D-complete (Diagonalization complete) and H-complete (Hypercomputation
complete) classes. We started the population process of these new classes. We
justify that some super-Turing models of computation, i.e., models going beyond
Turing machines, are tremendously expressive and they allow to accept arbitrary
languages over a given alphabet including those undecidable ones. We prove also
that one of such super-Turing models of computation -- the \$-Calculus,
designed as a tool for automatic problem solving and automatic programming, has
also such tremendous expressiveness. We investigate also completeness of cost
metrics and meta-search algorithms in \$-calculus",,http://arxiv.org/abs/2106.15969,115654865,"on completeness of cost metrics and meta-search algorithms in
  \$-calculus",2021-06-30T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"A key feature of federated learning (FL) is to preserve the data privacy of
end users. However, there still exist potential privacy leakage in exchanging
gradients under FL. As a result, recent research often explores the
differential privacy (DP) approaches to add noises to the computing results to
address privacy concerns with low overheads, which however degrade the model
performance. In this paper, we strike the balance of data privacy and
efficiency by utilizing the pervasive social connections between users.
Specifically, we propose SCFL, a novel Social-aware Clustered Federated
Learning scheme, where mutually trusted individuals can freely form a social
cluster and aggregate their raw model updates (e.g., gradients) inside each
cluster before uploading to the cloud for global aggregation. By mixing model
updates in a social group, adversaries can only eavesdrop the social-layer
combined results, but not the privacy of individuals. We unfold the design of
SCFL in three steps. \emph{i) Stable social cluster formation. Considering
users' heterogeneous training samples and data distributions, we formulate the
optimal social cluster formation problem as a federation game and devise a fair
revenue allocation mechanism to resist free-riders. ii) Differentiated
trust-privacy mapping}. For the clusters with low mutual trust, we design a
customizable privacy preservation mechanism to adaptively sanitize
participants' model updates depending on social trust degrees. iii) Distributed
convergence}. A distributed two-sided matching algorithm is devised to attain
an optimized disjoint partition with Nash-stable convergence. Experiments on
Facebook network and MNIST/CIFAR-10 datasets validate that our SCFL can
effectively enhance learning utility, improve user payoff, and enforce
customizable privacy protection",,http://arxiv.org/abs/2212.13992,137400259,"social-aware clustered federated learning with customized privacy
  preservation",2022-12-25T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Digital transformations are taking place across enterprises in every industry. Becoming digital is both essential to compete and virtually unstoppable. All previous major technological disruptions have led to financial intelligence being altered to ensure more effective decision making in the face of change. This article considers issues that organizations going digital need to address in relation to accounting information provision. It discusses several points: accounting’s need to move toward the delivery of predictive information rather than relying on extrapolations of historical data; the recognition that machines make more decisions that alter accounting information needs, structures, and contents; the importance of recognizing the “data-learning-action” loop that is emerging; the emergence of “strat-perational” information contexts; and the relevance of prioritizing qualitative insights in decision making",,https://core.ac.uk/download/598035958.pdf,154003511,is accounting keeping pace with digitalization?,2023-11-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper focuses on current progress for the understanding of human cognition. Here different models have been considered such as MLP, FLANN, PNN, MLR, and HSN for recognition of one of the state of mind. It is argued that in addition to other models, PSO occupies a prominent place in the future of cognitive science, and that cognitive scientists should play an active role in the process. Baysian Approach in the same context has also discussed. The special case of predicting harm doing in a particular mental state has been experimented taking different models into account in depicting decision making as a process of probabilistic, knowledge-driven inference",,https://core.ac.uk/download/480908232.pdf,127147035,metacognition revealed computationally,2020-08-27T12:41:43,Institute for Project Management Pvt. Ltd,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In Open Information Structure Approach, a learning content is described as an operable information structure. The information structure is then provided to a learner as operable external representation. The operations for the external representation can be interpreted as corresponding the learner’s thought on the content. Furthermore, the representation and operations can be expected to encourage computational thinking because they should be defined computationally. In this paper, this approach is described as an investigation of learning contents from information science and computationalization of learning content.教育システム情報学会中国支部第19回研究発表会, 開催日: 2019年10月26日(土), 開催場所: 広島大学附属福山中・高等学",,https://core.ac.uk/download/334499060.pdf,127237747,investigation of learning contents from information science: computationalization for computational thinking,2019-10-26T01:00:00,教育システム情報学会,"[{'title': None, 'identifiers': ['issn:2185-3738', '2185-3738']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Weird, unusual, and uncanny images pique the curiosity of observers because
they challenge commonsense. For example, an image released during the 2022
world cup depicts the famous soccer stars Lionel Messi and Cristiano Ronaldo
playing chess, which playfully violates our expectation that their competition
should occur on the football field. Humans can easily recognize and interpret
these unconventional images, but can AI models do the same? We introduce
WHOOPS!, a new dataset and benchmark for visual commonsense. The dataset is
comprised of purposefully commonsense-defying images created by designers using
publicly-available image generation tools like Midjourney. We consider several
tasks posed over the dataset. In addition to image captioning, cross-modal
matching, and visual question answering, we introduce a difficult explanation
generation task, where models must identify and explain why a given image is
unusual. Our results show that state-of-the-art models such as GPT3 and BLIP2
still lag behind human performance on WHOOPS!. We hope our dataset will inspire
the development of AI models with stronger visual commonsense reasoning
abilities. Data, models and code are available at the project website:
whoops-benchmark.github.i",,http://arxiv.org/abs/2303.07274,144645014,"breaking common sense: whoops! a vision-and-language benchmark of
  synthetic and compositional images",2023-07-13T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"All EU nations and the rest of the globe have been undergoing a massive digital transformation since Germany introduced and put into practice the Industry 4.0 concept in 2011. This entails not only boosting production by incorporating all current means of production, such as modern ICT solutions and robotics, but also introducing new expert profiles and ways of working. And, as that process became increasingly intensive, a new phrase, Industry 5.0, emerged in 2015. This concept focuses on the human potential as well as various IoT and Big Data applications to enhance human job and talent. Its objective is to connect individuals who work with robots in automated industrial settings. It is obvious that protecting worker safety and wellbeing at work entails not just maintaining physical health but also maintaining mental health, autonomy, dignity, privacy, and inclusion. Thanks to new technologies and the concept of Industry 5.0, we can have safer and more productive workplaces where the skills and creativity of workers come to the fore.Otkako je Njemačka 2011. uvela i u praksu stavila koncept Industrije 4.0, sve zemlje EU-a i ostatak svijeta prolaze kroz intenzivnu digitalnu transformaciju. To ne podrazumijeva samo jačanje proizvodnje uključivanjem svih trenutnih sredstava proizvodnje, kao što su moderna ICT rješenja i robotika, već i uvođenje novih stručnih profila i načina rada. Dok je taj proces postajao sve intenzivniji, nova fraza, Industrija 5.0, pojavila se 2015. godine. Ova koncepcija fokusirana je na ljudski potencijal, kao i na razne IoT i Big Data aplikacije za poboljšanje ljudskog rada i vještina. Cilj ove nove koncepcije je povezati pojedince koji rade zajedno s robotima u automatiziranim industrijskim sustavima. Očito je da zaštita sigurnosti i dobrobiti radnika na poslu ne podrazumijeva samo očuvanje fizičkog zdravlja, već i očuvanje mentalnog zdravlja, autonomije, dostojanstva, privatnosti i uključivosti. Zahvaljujući novim tehnologijama i koncepciji Industrije 5.0, može se osigurati sigurnija i produktivnija radna mjesta gdje vještine i kreativnost radnika dolaze do izražaja",10.31306/s.65.3.8,https://core.ac.uk/download/588875735.pdf,152822431,zaštita na radu u sklopu industrije 5.0 - quo vadis,2023-01-01T00:00:00,Institute of safety research and development,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We present Tactician, a tactic learner and prover for the Coq Proof
Assistant. Tactician helps users make tactical proof decisions while they
retain control over the general proof strategy. To this end, Tactician learns
from previously written tactic scripts and gives users either suggestions about
the next tactic to be executed or altogether takes over the burden of proof
synthesis. Tactician's goal is to provide users with a seamless, interactive,
and intuitive experience together with robust and adaptive proof automation. In
this paper, we give an overview of Tactician from the user's point of view,
regarding both day-to-day usage and issues of package dependency management
while learning in the large. Finally, we give a peek into Tactician's
implementation as a Coq plugin and machine learning platform.Comment: 19 pages, 2 figures. This is an extended version of a paper published
  in CICM-2020. For the project website, see https://coq-tactician.github.i",10.1007/978-3-030-53518-6_17,http://arxiv.org/abs/2008.00120,86834468,"the tactician (extended version): a seamless, interactive tactic learner
  and prover for coq",2020-07-31T01:00:00,'Springer Science and Business Media LLC',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Transferability captures the ability of an attack against a machine-learning
model to be effective against a different, potentially unknown, model.
Empirical evidence for transferability has been shown in previous work, but the
underlying reasons why an attack transfers or not are not yet well understood.
In this paper, we present a comprehensive analysis aimed to investigate the
transferability of both test-time evasion and training-time poisoning attacks.
We provide a unifying optimization framework for evasion and poisoning attacks,
and a formal definition of transferability of such attacks. We highlight two
main factors contributing to attack transferability: the intrinsic adversarial
vulnerability of the target model, and the complexity of the surrogate model
used to optimize the attack. Based on these insights, we define three metrics
that impact an attack's transferability. Interestingly, our results derived
from theoretical analysis hold for both evasion and poisoning attacks, and are
confirmed experimentally using a wide range of linear and non-linear
classifiers and datasets",,https://core.ac.uk/download/220682584.pdf,54150011,"why do adversarial attacks transfer? explaining transferability of
  evasion and poisoning attacks",2019-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In this paper, key elements about the Fourth Industrial Revolution are set under examination. Concerns, challenges, and opportunities related to the Industry 4.0 are analyzed, and specific policies to deal with the challenges and take advantage from the opportunities are proposed. Other issues that are set under consideration in this paper are the rate at which the human labor is threatened by the technological achievements, the main factors that increase workers’ exposure to the risk of automation, the jobs that are more at risk due to automation, and the basic factors that make political intervention necessary in order to deal with the unpredictable consequences of the technological progress such as the threat of a nuclear disaster and a possible income and social inequality gap widening. Finally, a special reference is done for the case of Greece",10.5772/intechopen.90412,https://core.ac.uk/download/322445985.pdf,10915003,"fourth industrial revolution: opportunities, challenges, and proposed policies",2020-01-21T00:00:00,'IntechOpen',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Law codes and regulations help organise societies for centuries, and as AI systems gain more autonomy, we question how human-agent systems can operate as peers under the same norms, especially when resources are contended. We posit that agents must be accountable and explainable by referring to which rules justify their decisions. The need for explanations is associated with user acceptance and trust. This paper's contribution is twofold: i) we propose an argumentation-based human-agent architecture to map human regulations into a culture for artificial agents with explainable behaviour. Our architecture leans on the notion of argumentative dialogues and generates explanations from the history of such dialogues; and ii) we validate our architecture with a user study in the context of human-agent path deconfliction. Our results show that explanations provide a significantly higher improvement in human performance when systems are more complex. Consequently, we argue that the criteria defining the need of explanations should also consider the complexity of a system. Qualitative findings show that when rules are more complex, explanations significantly reduce the perception of challenge for humans.L3Harris ASV and the Royal Commission for the Exhibition of 185",10.17863/cam.50772,https://core.ac.uk/download/288348037.pdf,78415323,culture-based explainable human-agent deconfliction,2019-11-22T00:00:00,AAMAS '20: Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The aim of this paper is to depict some of the impacts of the ongoing digital transition on security considering human factors, resilience, cyber and hybrid threats. After a short description of literature and related works the paper focus on the term “security” to better clarify the meaning, than introduces the process of digital transition and related aspects including “datafication” and potential harms to cybersecurity and the potential resilience breaches due to the concentration of tasks based on digital technology including production chains and digital manufacturing.
The impact of DT on Cybersecurity due to the boost generated by the pandemic and the increasing number of “digitally divided” citizens forced to “go digital” and related need to foster a culture of cybersecurity since the primary schools. This section includes an overview on different approaches to the “securesation” of the cyber space. Back to security in a broad sense freedom of expression is the first aspect considered including hate, fake news and propaganda, influence on opinion dynamics potentially applicable to the social and political sectors, as a kind of technological extension the combined use of big data and machine learning to activate nudging as a silent weapon, the risks directly connected to the concentration in few countries of online platforms directly connected with the last topic that is the emerging Internet of behaviour that thanks to the incredible amount of users’ data can monitor ad address citizens’ behaviours.
The list of impacts included will simply provide an idea about some of the potential threats, but they are not limited to this set",,https://core.ac.uk/download/567635227.pdf,148140231,"cyber resilience, its relevance, and cyber capacity building",2022-01-01T00:00:00,place:New Delhi,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The backpropagation algorithm has experienced remarkable success in training large-scale artificial neural networks; however, its biological plausibility has been strongly criticized, and it remains an open question whether the brain employs supervised learning mechanisms akin to it. Here, we propose correlative information maximization between layer activations as an alternative normative approach to describe the signal propagation in biological neural networks in both forward and backward directions. This new framework addresses many concerns about the biological-plausibility of conventional artificial neural networks and the backpropagation algorithm. The coordinate descent-based optimization of the corresponding objective, combined with the mean square error loss function for fitting labeled supervision data, gives rise to a neural network structure that emulates a more biologically realistic network of multi-compartment pyramidal neurons with dendritic processing and lateral inhibitory neurons. Furthermore, our approach provides a natural resolution to the weight symmetry problem between forward and backward signal propagation paths, a significant critique against the plausibility of the conventional backpropagation algorithm. This is achieved by leveraging two alternative, yet equivalent forms of the correlative mutual information objective. These alternatives intrinsically lead to forward and backward prediction networks without weight symmetry issues, providing a compelling solution to this long-standing challenge",,https://core.ac.uk/download/590811094.pdf,154079333,"correlative information maximization: a biologically

plausible approach to supervised deep neural

networks without weight symmetry",2023-09-21T01:00:00,NeurIPS,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The accelerated growth of the percentage of elder people and persons with brain injury-related conditions and who are intellectually challenged are some of the main concerns of the developed countries. These persons often require special cares and even almost permanent overseers that help them to carry out diary tasks. With this issue in mind, we propose an automated schedule system which is deployed on a social robot. The robot keeps track of the tasks that the patient has to fulfill in a diary basis. When a task is triggered, the robot guides the patient through its completion. The system is also able to detect if the steps are being properly carried out or not, issuing alerts in that case. To do so, an ensemble of deep learning techniques is used. The schedule is customizable by the carers and authorized relatives. Our system could enhance the quality of life of the patients and improve their self-autonomy. The experimentation, which was supervised by the ADACEA foundation, validates the achievement of these goalsThe accelerated growth of the percentage of elder people and persons with brain injury-related conditions and who are intellectually challenged are some of the main concerns of the developed countries. These persons often require special cares and even almost permanent overseers that help them to carry out diary tasks. With this issue in mind, we propose an automated schedule system which is deployed on a social robot. The robot keeps track of the tasks that the patient has to fulfill in a diary basis. When a task is triggered, the robot guides the patient through its completion. The system is also able to detect if the steps are being properly carried out or not, issuing alerts in that case. To do so, an ensemble of deep learning techniques is used. The schedule is customizable by the carers and authorized relatives. Our system could enhance the quality of life of the patients and improve their self-autonomy. The experimentation, which was supervised by the ADACEA foundation, validates the achievement of these goal",,https://core.ac.uk/download/287061739.pdf,77809778,geoffrey: an automated schedule system on a social robot for the intellectually challenged,2018-02-12T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In today\u27s world, manufacturing companies face many challenges due to the uncertainty and complexity of environmental influences as well as increasing competitive pressures. The pandemic has clearly illustrated how volatile and fragile our supply chains have become. One way to overcome these chal-lenges together is to collaborate with other companies in the value network. 
						Collaborations, i.e. successful cooperation with strategic partners and customers to achieve common goals, will continue to gain in importance.  Instead of individual companies, entire value chains and networks will therefore compete with each other in the future. This will require a shift toward fast and seamless data exchange between the players in the value network. 
						Advancing digitization and thus a generally increasingly networked world are increasingly supporting such collaborations, as the sharing and collaborative use of data is becom-ing much simpler. At the same time, the right handling of data will be decisive for competition. Digitization is moving from being a driver of change to an enabler of change. Innovative business models and the exploita-tion of the potential hidden in data will make it possible to realize reliable, flexible and, at the same time, resource-conserving value creation. 
						The number of existing cloud-based collaboration platforms is growing steadily. Small and medium-sized enterprises in particular have to serve many different customer platforms at the same time, while they them-selves are still struggling with internal digitization challenges. Standardization initiatives for secure data rooms in the industry, such as GAIA-X, therefore hold great potential. 
						In addition to these fundamental infrastructural issues, there are further challenges with regard to collaboration projects. Particular importance is attached to the competent handling of data protection and data security. There are often reservations that the disclosure of data and information will result in the loss of hard-earned expertise and com-petitive advantages that have been built up over time. At the same time, however, users from an engineering environment are only able to assess the risks of digital collaboration to a limited extent. In order to secure one\u27s own competitive position in the long term, digital competencies must therefore be built up and barriers to collaboration overcome. 
					Success stories and clear recommendations for action can provide an important impetus for the implementation of successful collaboration projects, showing how collaborations can be approached in practice and what added value they generate. That is why we would like to provide manufacturing compa-nies with such guidance in the form of this action guide. The collaboration projects explained below and the best practices derived from them are intended to help companies find their own strategies on the path to more collaboration. We hope you enjoy reading this guide and are always available for questions and discussions",10.5445/ir/1000144272,https://core.ac.uk/download/521172682.pdf,134392446,"successful collaboration in global production networks - fair, secured, connected",2022-03-28T01:00:00,wbk Institut für Produktionstechnik,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In the twenty first century, there have been various scientific discoveries which have helped in addressing some of the fundamental health issues. Specifically, the discovery of machines which are able to assess the internal conditions of individuals has been a significant boost in the medical field. This paper or case study is the continuation of a previous research which aimed to create artificial models using support vector machines (SVM) to classify MS and normal brain MRI images, analyze the effectiveness of these models and their potential to use them in Multiple Sclerosis (MS) diagnosis. In the previous study presented at the Cognitive InfoCommunication (CogInfoCom 2019) conference, we intend to show that 3D images can be converted into 2D and by considering machine learning techniques and SVM tools. The previous paper concluded that SVM is a potential method which can be involved during MS diagnosis, however, in order to confirm this statement more research and other potentially effective methods should be included in the research and need to be tested. First, this study continues the research of SVM used for classification and Cellular Learning Automata (CLA), then it expands the research to other method such as Artificial Neural Networks (ANN) and k-Nearest Neighbor (k-NN) and then compares the results of these",10.36244/icj.2020.1.6,https://core.ac.uk/download/324184642.pdf,86305733,multiple sclerosis lesion detection via machine learning algorithm based on converting 3d to 2d mri images,2020-01-01T00:00:00,'Infocommunications Journal',"[{'title': 'Infocommunications journal', 'identifiers': ['issn:2061-2079', '2061-2079']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper presents a preliminary sketching of research in progress, namely how computers were designed in all best interest of serving human social interaction, how they grew out of their imagined functions, becoming the revolutionary tool of cybernetic capitalism. A few years after their introduction in the United States, in early 1980s Japan, microcomputers were developed, produced en masse, and sold to their first users. But to archive their use as an extension of the factory, a tool to gain unlimited access to what Marx has called the workers “social disposable time, ” the computer machine had to be constantly interconnected to the other “limbs” of the factory machine. The creation of the first computer network in Japan, the MARS seat reservation system was based on cybernetics, creating a complex system to automatize Japanese National Railways—a threat that to its trade union was beyond comprehension. Beyond automation, in the 1980s, a student computer club at Kyoto University created PLANET, a network of different home computers (maikon) to democratize computer use. Their humanistic approach created a standardized and unified system, creating a machine which operation would revolutionize its economic base",10.14989/262934,https://core.ac.uk/download/429790102.pdf,113788868,"<articles>maikon and cyber-capitalism: some preliminary remarks on a history of computerization in japan, 1960–1990",2021-03-01T00:00:00,Institute for Research in Humanities Kyoto University,"[{'title': None, 'identifiers': ['issn:0084-5515', '0084-5515']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The advent of videogames, and the new forms of expressions they offered, sprouted the
possibility of presenting narratives in ways that could capitalize on unique qualities of the
media, most notably the agency found in their interactive nature.
In spite of many people in the game studies’ field interested in how far said novelty could bring
narrative experiences, most approached the creation of narrative systems from a structural
approach (especially the classical Aristotelian one), and concurrently, with a bottom-up
(characters defining a world) or top-down (world defining characters) perspective.
While those more mainstream takes have been greatly progressing what interactive digital
narrative can be, this research intended to take a bit of a detour, proposing a functionally similar
system that emphasized thematic coherence and responsiveness above all else. Once the
theoretical formulation was done, taking into consideration previously similar or tangential
systems, a prototype would be developed to make a first step towards validating the proposal,
and contribute to building a better understanding of the field’s possibilities",,https://core.ac.uk/download/576861978.pdf,150042355,dynamic theme-based narrative systems,2022-07-12T01:00:00,Universitat Politècnica de Catalunya,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The data and internet are highly growing which causes problems in management of the big-data. For these kinds of problems, there are many software frameworks used to increase the performance of the distributed system. This software is used for the availability of large data storage. One of the most beneficial software frameworks used to utilize data in distributed systems is Hadoop. This paper introduces Apache Hadoop architecture, components of Hadoop, their significance in managing vast volumes of data in a distributed system. Hadoop Distributed File System enables the storage of enormous chunks of data over a distributed network. Hadoop Framework maintains fsImage and edits files, which supports the availability and integrity of data. This paper includes cases of Hadoop implementation, such as monitoring weather, processing bioinformatics",10.30564/ssid.v4i1.4619,https://core.ac.uk/download/524153425.pdf,122211614,"apache hadoop architecture, applications, and hadoop distributed  file system",2022-05-18T01:00:00,'Bilingual Publishing Co.',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The relationship between business activities and digital technologies is extensive and continuesto grow exponentially, especially now, in the time of a global pandemic. All and any activities invarious areas, have now adapted online platforms in light of social distancing measures. TheCOVID-19 pandemic has been compared to the Second World War, as well as the Great Depressionin terms of the way it has impacted human behavior. Consequently, many changes havebeen made to enforce the COVID-19 safety measures, that rely on digital technologies. With this,come vast new opportunities and needs for research as well as innovation and upgrading existingsystems in the field of information technology.Artificial intelligence, also known as AI, is a general purpose technology that can be used to betterefficiency, quality, safety, and solve problems faster than the traditional employee. In this paper,we will direct our attention at the problems that arise in the field of accounting and audit becauseof the ongoing pandemic and how they can be fixed or eliminated with the use od artificial intelligence.We will look at how the pandemic impacts the way financial reports are prepared and whatchanges were necessary in order to adapt and function normally and most efficiently in this time.We will also look at the possibility of eventually replacing an accountant or auditor with the systemof AI and the risk it may pose to the traditional worker. Knowing that in a time of a pandemic, it ispreferable that all and any activities that can be remote, should be completed as such. This paperwill come to the conclusion that the system of artificial intelligence is of enormous use in the timeof the pandemic, as well as in non extraordinary circumstances therefore, many business needto be urged to implement this kind, or a similar kind of system to help and better everyday workand improve performances. We will also see how AI can better the performance of the auditorsand accountants with limiting the risk of mistakes and lowering the time needed to finish a task",10.46763/joe2160240m,https://core.ac.uk/download/478750319.pdf,141529602,how artificial inteligence can help the sector of accounting and audit deal with covid-19,2021-08-16T01:00:00,'Goce Delchev University - Shtip',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Disputes over how to regulate artificial intelligence have rapidly risen up the global agenda in the last few years. But is a single set of global, or even just transatlantic rules the way to address the issue? Daniel Mügge argues that for the European Union, with its towering ethical ambitions, the answer may be ‘No’",,https://core.ac.uk/download/491168707.pdf,18736490,cooperation á la carte is the way forward for eu ai regulation,2021-11-26T00:00:00,London School of Economics and Political Science,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Deep neural networks (DNN) have been widely used and play a major role in the field of computer vision and autonomous navigation. However, these DNNs are computationally complex and their deployment over resource-constrained platforms is difficult without additional optimizations and customization.
In this manuscript, we describe an overview of DNN architecture and propose methods to reduce computational complexity in order to accelerate training and inference speeds to fit them on edge computing platforms with low computational resources",,https://core.ac.uk/download/524878644.pdf,123375845,computational complexity reduction of deep neural networks,2022-04-28T15:50:34,USMA Digital Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Question Generation (QG) is an essential component of the automatic
intelligent tutoring systems, which aims to generate high-quality questions for
facilitating the reading practice and assessments. However, existing QG
technologies encounter several key issues concerning the biased and unnatural
language sources of datasets which are mainly obtained from the Web (e.g.
SQuAD). In this paper, we propose an innovative Examination-type Question
Generation approach (EQG-RACE) to generate exam-like questions based on a
dataset extracted from RACE. Two main strategies are employed in EQG-RACE for
dealing with discrete answer information and reasoning among long contexts. A
Rough Answer and Key Sentence Tagging scheme is utilized to enhance the
representations of input. An Answer-guided Graph Convolutional Network (AG-GCN)
is designed to capture structure information in revealing the inter-sentences
and intra-sentence relations. Experimental results show a state-of-the-art
performance of EQG-RACE, which is apparently superior to the baselines. In
addition, our work has established a new QG prototype with a reshaped dataset
and QG method, which provides an important benchmark for related research in
future work. We will make our data and code publicly available for further
research.Comment: Accepted by AAAI-202",10.1609/aaai.v35i14.17553,http://arxiv.org/abs/2012.06106,107768704,eqg-race: examination-type question generation,2020-12-10T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Collective Intelligence, the book in French, that Pierre Levy wrote before the existence of the worldwide web, when only the Internet existed, it's a philosophical vision of the future, a philosophical vision of what could be a global civilization based on the digital and the general interconnection of all the computers. In the interview, Levy addresses the creation o the WWW by Tim Berners Lee as a form of collective intelligence. He then discusses Berners Lee's proposal for a reform of the WWW to avoid its confiscation by the big platforms, such as Google, Facebook, and Amazon. Then, he introduces his most recent project the IELM as a tool for semantic metadata and a code between the natural languages and the algorithms, and all the apparatus of computations",10.5399/uo/hsda.6.1.2,https://core.ac.uk/download/276540580.pdf,76246855,"collective intelligence, the future of internet and the ieml",2019-12-31T00:00:00,'Oregon State University',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The objective of the chapter is to show current trends in robot navigation systems related to indoor environments. Navigation systems depend on the level of abstraction of the environment representation. The three main techniques for representing the environment will be described: geometric, topological, and semantic. The geometric representation of the environment is closer to the sensor and actuator world and it is the best one to perform local navigation. Topological representation of the environment uses graphs to model the environment and it is used in large navigation tasks. The semantic representation is the most abstract representation model and adds concepts such as utilities or meanings of the environment elements in the map representation. In addition, regardless of the representation used for navigation, perception plays a significant role in terms of understanding and moving through the environment",10.5772/intechopen.79842,https://core.ac.uk/download/322439468.pdf,10911511,"mobile robot navigation in indoor environments: geometric, topological, and semantic navigation",2018-11-05T00:00:00,'IntechOpen',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The purpose of this study is to see the feasibility of LMS as a means of Hybird Learning in improving Student numerical Literacy and Critical Thinking Skills, to describe the practicality of LMS as a means of Hybird Learning in improving Student Numerical Literacy and Critical Thinking Skills, and to describe the effectiveness of LMS LMS as a means of Hybird Learning in improving Student Numerical Literacy and Critical Thinking Skills. The sample in this study was composed of Mathematics Department students who were taking Basic Mathematics courses at Medan State University, for a total of 37 people.The research stages carried out in this study refer to the ADDIE development model (Analysis, Design, Develop, Implement, and Evaluate) developed by Reiser and Mollend.The results of the study in terms of the feasibility of the material validation results show a value of 3.38 with very feasible criteria, and the media validation results show a value of 3.28 with feasible criteria. In terms of practicality, based on the results of the student response questionnaire, a score of 2.74 was obtained in the practical category. From the results of the response questionnaire analysis, 100% of students stated that the LMS was practical to use in learning basic mathematics, and 23 students strongly agreed that the LMS was easy to use (practical). The effectiveness of the LMS was seen from the results of learning mathematics, with a recapitulation of the average ability of students' mathematical literacy and critical thinking of 80.09 and a completeness level of 83.9% (31 of 37 students completed). Keywords: Development, LMS, hybrid learning, numeracy literacy, critical thinking DOI: 10.7176/JEP/14-23-01 Publication date:August 31st 202",,https://core.ac.uk/download/586376078.pdf,151503536,development of lms as a hybrid learning facility assisted by augmented reality to improve students' numerical literacy and critical thinking skills,2023-09-03T01:00:00,"The International Institute for Science, Technology and Education (IISTE)",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We propose DISC-LawLLM, an intelligent legal system utilizing large language
models (LLMs) to provide a wide range of legal services. We adopt legal
syllogism prompting strategies to construct supervised fine-tuning datasets in
the Chinese Judicial domain and fine-tune LLMs with legal reasoning capability.
We augment LLMs with a retrieval module to enhance models' ability to access
and utilize external legal knowledge. A comprehensive legal benchmark,
DISC-Law-Eval, is presented to evaluate intelligent legal systems from both
objective and subjective dimensions. Quantitative and qualitative results on
DISC-Law-Eval demonstrate the effectiveness of our system in serving various
users across diverse legal scenarios. The detailed resources are available at
https://github.com/FudanDISC/DISC-LawLLM",,http://arxiv.org/abs/2309.11325,149790978,"disc-lawllm: fine-tuning large language models for intelligent legal
  services",2023-09-23T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This white paper aims at presenting the ideas emerging from the different fields pertaining to transport and mobility, to describe the capacities of current state-of-the-art digital technologies and the perspectives that are expected to shape the future of transport and mobility",10.1007/978-3-030-37752-6_1,https://core.ac.uk/download/343623139.pdf,43025168,"digital technologies for transport and mobility: challenges, trends and perspectives",2020-01-01T00:00:00,'Springer Science and Business Media LLC',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper specifically addresses the resource allocation challenges encountered in wireless sensor networks that incorporate RF energy harvesting capabilities, commonly referred to as RF-energy harvesting networks (RF-EHNs). RF energy harvesting and transmission techniques bring substantial advantages for applications requiring Quality of Service (QoS) support, as they enable proactive replenishment of&nbsp; wireless devices. We commence by providing an overview of RF-EHNs, followed by an in-depth examination of the resource allocation challenges associated with this technology. In addition, we present a case study that focuses on the design of an efficient operating strategy for RF-EHN receivers. Our investigation highlights the critical aspects of service differentiation and QoS support, which have received limited attention in previous research. Besides, we explore previously unexplored areas within these domains",10.17762/ijritcc.v11i7s.6990,https://core.ac.uk/download/579951256.pdf,150665500,resource allocation challenges and strategies for rf-energy harvesting networks supporting qos,2023-07-13T01:00:00,Auricle Global Society of Education and Research,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Looking out of Information Science (IS) it´s a dangerous attempt to compare this relative new science direct with Philosophy.  Here you find a first circumspective trial of an investigation of the traditionally named “queen of science”, Philosophy, two thousand years old and - direct opposite - the only a half century old Information Science. For me it is till now not yet clear how to do this in a serious scientific manner. I worked in Applied Informatics for 30 years and make Information Science since about 15 years. Here I dare to publish for first time the results.    SOKRATES (469 – 399 b.Chr.), PLATON (428/27- 348/47 b.Chr.) und ARISTOTELES (384 - 322 b.Chr.) as inventors of our traditional occidental Philosophy, have founded the search of the sense of our Human Life, Thinking and Acting as an own science.  They set the Joy of Life on top of their way of thinking. PLATON has separated this special new thinking from the „Sophists“ who had a very good public image too at his time. But they were thinking more about common business facts and knowledge only. Today we would call them manufacturer, qualified skilled workers or even bachelors of special sciences. 
           
          Philosophy has (since over 20 centuries) till today first of all the smart and high duty to serve Religion and Ethics as mental, spirit- and language-grounded science-base.  In other direction it was used to overthink our whole surrounding nature theoretically and completely by our best Human Mind. It´s our traditional science on our mental highest level. All sciences can be related by Philosophy.  That´s possible by our human ability to Learn, Think, Understand and finally Know any interesting new fact.    
           
          Where and how do we have now to integrate this new own science Information Science? We search consciously term-oriented and make an abstract science-theoretical comparison to find answers and definitions",,https://core.ac.uk/download/158370790.pdf,8864723,information science and philosophy,2018-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We present MM-Navigator, a GPT-4V-based agent for the smartphone graphical
user interface (GUI) navigation task. MM-Navigator can interact with a
smartphone screen as human users, and determine subsequent actions to fulfill
given instructions. Our findings demonstrate that large multimodal models
(LMMs), specifically GPT-4V, excel in zero-shot GUI navigation through its
advanced screen interpretation, action reasoning, and precise action
localization capabilities. We first benchmark MM-Navigator on our collected iOS
screen dataset. According to human assessments, the system exhibited a 91\%
accuracy rate in generating reasonable action descriptions and a 75\% accuracy
rate in executing the correct actions for single-step instructions on iOS.
Additionally, we evaluate the model on a subset of an Android screen navigation
dataset, where the model outperforms previous GUI navigators in a zero-shot
fashion. Our benchmark and detailed analyses aim to lay a robust groundwork for
future research into the GUI navigation task. The project page is at
https://github.com/zzxslp/MM-Navigator.Comment: Work in progres",,http://arxiv.org/abs/2311.07562,153739440,"gpt-4v in wonderland: large multimodal models for zero-shot smartphone
  gui navigation",2023-11-13T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"With the rapid development of AI hardware accelerators, applying deep
learning-based algorithms to solve various low-level vision tasks on mobile
devices has gradually become possible. However, two main problems still need to
be solved: task-specific algorithms make it difficult to integrate them into a
single neural network architecture, and large amounts of parameters make it
difficult to achieve real-time inference. To tackle these problems, we propose
a novel network, SYENet, with only $~$6K parameters, to handle multiple
low-level vision tasks on mobile devices in a real-time manner. The SYENet
consists of two asymmetrical branches with simple building blocks. To
effectively connect the results by asymmetrical branches, a Quadratic
Connection Unit(QCU) is proposed. Furthermore, to improve performance, a new
Outlier-Aware Loss is proposed to process the image. The proposed method proves
its superior performance with the best PSNR as compared with other networks in
real-time applications such as Image Signal Processing(ISP), Low-Light
Enhancement(LLE), and Super-Resolution(SR) with 2K60FPS throughput on Qualcomm
8 Gen 1 mobile SoC(System-on-Chip). Particularly, for ISP task, SYENet got the
highest score in MAI 2022 Learned Smartphone ISP challenge",,http://arxiv.org/abs/2308.08137,145456249,"syenet: a simple yet effective network for multiple low-level vision
  tasks with real-time performance on mobile device",2023-08-16T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Adaptive methods such as Adam and RMSProp are widely used in deep learning
but are not well understood. In this paper, we seek a crisp, clean and precise
characterization of their behavior in nonconvex settings. To this end, we first
provide a novel view of adaptive methods as preconditioned SGD, where the
preconditioner is estimated in an online manner. By studying the preconditioner
on its own, we elucidate its purpose: it rescales the stochastic gradient noise
to be isotropic near stationary points, which helps escape saddle points.
Furthermore, we show that adaptive methods can efficiently estimate the
aforementioned preconditioner. By gluing together these two components, we
provide the first (to our knowledge) second-order convergence result for any
adaptive method. The key insight from our analysis is that, compared to SGD,
adaptive methods escape saddle points faster, and can converge faster overall
to second-order stationary points.Comment: Update Theorem 4.1 and proof to use martingale concentration bounds,
  i.e. matrix Freedma",,http://arxiv.org/abs/1901.09149,54192023,escaping saddle points with adaptive gradient methods,2020-02-03T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Some thinkers have claimed that expert performance with technology is characterized by a kind of disappearance of that technology from conscious experience, that is, by the transparency of the tools and equipment through which we sense and manipulate the world. This is a claim that may be traced to phenomenological philosophers such as Heidegger and Merleau-Ponty, but it has been influential in user interface design where the transparency of technology has often been adopted as a mark of good design. Moreover, in the philosophy of cognitive science, such transparency has been advanced as necessary for extended cognition (the situation in which the technology with which we couple genuinely counts as a constitutive part of our cognitive machinery, along with our brains). By reflecting on concrete examples of our contemporary engagement with technology, I shall argue that the epistemic challenges posed by smart artefacts (those that come equipped with artificial-intelligencebased applications) should prompt a reassessment of the drive for transparency in the design of some cases of technology-involving cognition. This has consequences for the place of extended minds in the contemporary technological context",10.1007/s00146-018-0824-x,https://core.ac.uk/download/132200267.pdf,18778947,"the reappearing tool: transparency, smart technology, and the extended mind",2019-12-01T00:00:00,'Springer Science and Business Media LLC',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Predicting waiting times in A&E is a critical tool for controlling the flow of patients in the department. The most used method (rolling average) does not account for the complex context of the A&E. Using retrospective data of patients visiting an A&E service from 2017 to 2019 (pre-pandemic). An AI-enabled method is used to predict waiting times in this study. A random forest and XGBoost regression methods were trained and tested to predict the time to discharge before the patient arrived at the hospital. When applying the final models to the 68,321 observations and using the complete set of features, the random forest algorithm’s performance measurements are RMSE=85.31 and MAE=66.71. The XGBoost model obtained a performance of RMSE=82.66 and MAE=64.31. The approach might be a more dynamic method to predict waiting times",,https://core.ac.uk/download/578730267.pdf,154077233,prediction of waiting times in a&e,2023-07-02T01:00:00,'IOS Press',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper highlights several key principles of the work of Michel Serres and considers them in relation to life in contemporary socio-technical worlds, e.g. notions of relationality, noise, bodies, sense and data. A journey with Serres involves seeking novelty in spaces ‘outside’ of existing knowledge producing practices. This paper highlights how, for Serres, mediation as noise does not operate via a singular universal interface, but is multiple and processual – in essence, everything is mediation. Using contemporary examples of new technologies (e.g. AI and play writing; AI and emotion) the paper considers the value of a Serrian mode of thought for understanding emerging relations between bodies and technologies. It concludes with acknowledging the growing political focus on Serres’ later work, in which he became increasingly concerned to (re)define the contract between humanity and the world. His notion of appropriation through pollution encompasses notions of information and data as forms of algorithmic appropriation, as much if not more, than physical pollution",,https://core.ac.uk/download/477903616.pdf,8218846,"(re)thinking body-technology relations with michel serres:  emotion, sense and the emergence of algorithmic appropriation",2021-01-01T00:00:00,Media Theory,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Reinforcement learning (RL) has been applied to robotics and many other domains which a system must learn in real-time and interact with a dynamic environment. In most studies the state- action space that is the key part of RL is predefined. Integration of RL with deep learning method has however taken a tremendous leap forward to solve novel challenging problems such as mastering a board game of Go. The surrounding environment to the agent may not be fully visible, the environment can change over time, and the feedbacks that agent receives for its actions can have a fluctuating delay. In this paper, we propose a Generic Online Learning (GOL) system for such environments. GOL is based on RL with a hierarchical structure to form abstract features in time and adapt to the optimal solutions. The proposed method has been applied to load balancing in 5G cloud random access networks. Simulation results show that GOL successfully achieves the system objectives of reducing cache-misses and communication load, while incurring only limited system overhead in terms of number of high-level patterns needed. We believe that the proposed GOL architecture is significant for future online learning of dynamic, partially visible environments, and would be very useful for many autonomous control systems",,https://core.ac.uk/download/129533291.pdf,9459484,generic online learning for partial visible & dynamic environment with delayed feedback,2017-04-01T07:00:00,SJSU ScholarWorks,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In this work, we introduce a differentially private method for generating
synthetic data from vertically partitioned data, \emph{i.e.}, where data of the
same individuals is distributed across multiple data holders or parties. We
present a differentially privacy stochastic gradient descent (DP-SGD) algorithm
to train a mixture model over such partitioned data using variational
inference. We modify a secure multiparty computation (MPC) framework to combine
MPC with differential privacy (DP), in order to use differentially private MPC
effectively to learn a probabilistic generative model under DP on such
vertically partitioned data.
  Assuming the mixture components contain no dependencies across different
parties, the objective function can be factorized into a sum of products of the
contributions calculated by the parties. Finally, MPC is used to compute the
aggregate between the different contributions. Moreover, we rigorously define
the privacy guarantees with respect to the different players in the system. To
demonstrate the accuracy of our method, we run our algorithm on the Adult
dataset from the UCI machine learning repository, where we obtain comparable
results to the non-partitioned case",,http://arxiv.org/abs/2010.09293,128562938,privacy-preserving data sharing on vertically partitioned data,2022-09-02T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Deep neural networks (DNNs) have achieved tremendous success in various
applications including video action recognition, yet remain vulnerable to
backdoor attacks (Trojans). The backdoor-compromised model will mis-classify to
the target class chosen by the attacker when a test instance (from a non-target
class) is embedded with a specific trigger, while maintaining high accuracy on
attack-free instances. Although there are extensive studies on backdoor attacks
against image data, the susceptibility of video-based systems under backdoor
attacks remains largely unexplored. Current studies are direct extensions of
approaches proposed for image data, e.g., the triggers are
\textbf{independently} embedded within the frames, which tend to be detectable
by existing defenses. In this paper, we introduce a \textit{simple} yet
\textit{effective} backdoor attack against video data. Our proposed attack,
adding perturbations in a transformed domain, plants an \textbf{imperceptible,
temporally distributed} trigger across the video frames, and is shown to be
resilient to existing defensive strategies. The effectiveness of the proposed
attack is demonstrated by extensive experiments with various well-known models
on two video recognition benchmarks, UCF101 and HMDB51, and a sign language
recognition benchmark, Greek Sign Language (GSL) dataset. We delve into the
impact of several influential factors on our proposed attack and identify an
intriguing effect termed ""collateral damage"" through extensive studies",,http://arxiv.org/abs/2308.11070,146203003,"temporal-distributed backdoor attack against video based action
  recognition",2023-08-21T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We propose an efficient method to ground pretrained text-only language models
to the visual domain, enabling them to process arbitrarily interleaved
image-and-text data, and generate text interleaved with retrieved images. Our
method leverages the abilities of language models learnt from large scale
text-only pretraining, such as in-context learning and free-form text
generation. We keep the language model frozen, and finetune input and output
linear layers to enable cross-modality interactions. This allows our model to
process arbitrarily interleaved image-and-text inputs, and generate free-form
text interleaved with retrieved images. We achieve strong zero-shot performance
on grounded tasks such as contextual image retrieval and multimodal dialogue,
and showcase compelling interactive abilities. Our approach works with any
off-the-shelf language model and paves the way towards an effective, general
solution for leveraging pretrained language models in visually grounded
settings.Comment: Published in ICML 2023. Project page: https://jykoh.com/fromag",,http://arxiv.org/abs/2301.13823,143138731,grounding language models to images for multimodal inputs and outputs,2023-06-01T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Understanding Prompt Literacy and Its Role in STEM Education
● Workshop focuses on prompt literacy, a pivotal skill for educators in the digital age.
● Discuss fundamentals of prompt crafting, interpret and critique AI prompts
● Hands-on activities for prompt crafting, using CAST model
● Workshop participant backgrounds include:   Edtech, speech-language, GenEd, Special Ed, Inclusion, AP Language, English, Business, World Languages, STEM Education, and more, across various grade level",10.7275/bxk0-af51,https://core.ac.uk/download/586383632.pdf,149297192,prompt literacy for stem educators.  enhance your teaching and learning with generative ai,2023-01-01T08:00:00,ScholarWorks@UMass Amherst,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"To prepare the community to face Society 5.0, cooperation is needed from various parties, including the education sector. The development of the education sector is crucial today, as it provides optimal and quality educational services and facilitates technological advancements. Regarding educational technology, a system utilized to support learning and achieve desired outcomes, it is important to associate it with the Society 5.0 era. One form of technological development in education that can be used as a learning medium is e-learning. This research adopts a quantitative approach. The research subjects consist of secondary data from a Kaggle dataset titled ""Students Adaptability Level in Online Education,"" which was collected by Md. Aktaruzzaman Pramanik and Nishat Ahmed Samrin. The data includes 530 students who participated in online learning at schools. The results of this research indicate that the development of information technology in the Society 5.0 era can be utilized by the education sector, such as through e-learning as a learning medium. The impact of these research findings can be observed in the quality of education in Indonesia, where all aspects of life coexist with digital media",10.51276/edu.v4i3.438,https://core.ac.uk/download/568382221.pdf,145425057,analysis of e-learning activities as school learning media in the era of society 5.0 using big data,2023-06-11T01:00:00,Natural Aceh,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"A subset of AI is, evolutionary algorithm (EA) which involves evolutionary computation, a generic populationbased meta heuristic optimization algorithm. An EA uses some mechanisms inspired by biological evolution: reproduction, mutation, recombination, and selection. A genetic algorithm (GA) is a search technique used in computing to find exact or approximate solutions to optimization and search problems. Working of a search engine deals with searching for the indexed pages and referring to the related pages within a very short span of. Search engines commonly work through indexing. The paper deals with how a search engine works and how evolutionary algorithms can be used to develop a search engine that feeds on previous user requests to retrieve  alternative  documents that may not be returned by more conventional search engines",,https://core.ac.uk/download/480908362.pdf,127146770,search engines using evolutionary algorithms,2020-07-30T18:41:47,Institute for Project Management Pvt. Ltd,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This study aimed to differentiate individuals with Parkinson's disease (PD) from those with other neurological disorders (ND) by analyzing voice samples, considering the association between voice disorders and PD. Voice samples were collected from 76 participants using different recording devices and conditions, with participants instructed to sustain the vowel /a/ comfortably. PRAAT software was employed to extract features including autocorrelation (AC), cross-correlation (CC), and Mel frequency cepstral coefficients (MFCC) from the voice samples. Principal component analysis (PCA) was utilized to reduce the dimensionality of the features. Classification Tree (CT), Logistic Regression, Naive Bayes (NB), Support Vector Machines (SVM), and Ensemble methods were employed as supervised machine learning techniques for classification. Each method provided distinct strengths and characteristics, facilitating a comprehensive evaluation of their effectiveness in distinguishing PD patients from individuals with other neurological disorders. The Naive Bayes kernel, using seven PCA-derived components, achieved the highest accuracy rate of 86.84% among the tested classification methods. It is worth noting that classifier performance may vary based on the dataset and specific characteristics of the voice samples. In conclusion, this study demonstrated the potential of voice analysis as a diagnostic tool for distinguishing PD patients from individuals with other neurological disorders. By employing a variety of voice analysis techniques and utilizing different machine learning algorithms, including Classification Tree, Logistic Regression, Naive Bayes, Support Vector Machines, and Ensemble methods, a notable accuracy rate was attained. However, further research and validation using larger datasets are required to consolidate and generalize these findings for future clinical applications.Przedstawione badanie miało na celu różnicowanie osób z chorobą Parkinsona (PD) od osób z innymi zaburzeniami neurologicznymi poprzez analizę próbek głosowych, biorąc pod uwagę związek między zaburzeniami głosu a PD. Próbki głosowe zostały zebrane od 76 uczestników przy użyciu różnych urządzeń i warunków nagrywania, a uczestnicy byli instruowani, aby wydłużyć samogłoskę /a/ w wygodnym tempie. Oprogramowanie PRAAT zostało zastosowane do ekstrakcji cech, takich jak autokorelacja (AC), krzyżowa korelacja (CC) i współczynniki cepstralne Mel (MFCC) z próbek głosowych. Analiza składowych głównych (PCA) została wykorzystana w celu zmniejszenia wymiarowości cech. Jako techniki nadzorowanego uczenia maszynowego wykorzystano drzewa decyzyjne (CT), regresję logistyczną, naiwny klasyfikator Bayesa (NB), maszyny wektorów nośnych (SVM) oraz metody zespołowe. Każda z tych metod posiadała swoje unikalne mocne strony i charakterystyki, umożliwiając kompleksową ocenę ich skuteczności w rozróżnianiu pacjentów z PD od osób z innymi zaburzeniami neurologicznymi. Naiwny klasyfikator Bayesa, wykorzystujący siedem składowych PCA, osiągnął najwyższy wskaźnik dokładności na poziomie 86,84% wśród przetestowanych metod klasyfikacji. Należy jednak zauważyć, że wydajność klasyfikatora może się różnić w zależności od zbioru danych i konkretnych cech próbek głosowych. Podsumowując, to badanie wykazało potencjał analizy głosu jako narzędzia diagnostycznego do rozróżniania pacjentów z PD od osób z innymi zaburzeniami neurologicznymi. Poprzez zastosowanie różnych technik analizy głosu i wykorzystanie różnych algorytmów uczenia maszynowego, takich jak drzewa decyzyjne, regresja logistyczna, naiwny klasyfikator Bayesa, maszyny wektorów nośnych i metody zespołowe, osiągnięto znaczący poziom dokładności. Niemniej jednak, konieczne są dalsze badania i walidacja na większych zbiorach danych w celu skonsolidowania i uogólnienia tych wyników dla przyszłych zastosowań klinicznych",,https://core.ac.uk/download/588312631.pdf,150392677,klasyfikacja choroby parkinsona i innych zaburzeń neurologicznych z wykorzystaniem ekstrakcji cech głosowych i technik redukcji,2023-09-30T01:00:00,'Politechnika Lubelska',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"What is the best way to define algorithmic fairness? While many definitions
of fairness have been proposed in the computer science literature, there is no
clear agreement over a particular definition. In this work, we investigate
ordinary people's perceptions of three of these fairness definitions. Across
two online experiments, we test which definitions people perceive to be the
fairest in the context of loan decisions, and whether fairness perceptions
change with the addition of sensitive information (i.e., race of the loan
applicants). Overall, one definition (calibrated fairness) tends to be more
preferred than the others, and the results also provide support for the
principle of affirmative action.Comment: To appear at AI Ethics and Society (AIES) 201",10.1145/3306618.3314248,http://arxiv.org/abs/1811.03654,54169277,"how do fairness definitions fare? examining public attitudes towards
  algorithmic definitions of fairness",2019-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper belongs to the area of roboethics and responsible robotics. It discusses the conceptual and practical separation of humans and robots in designing and implementing robots into real-world environments. We argue here that humans are often seen as a component that is only optional in design thinking, and in some cases even an obstacle to the successful robot performance. Such an approach may vary from viewing humans as a factor that does not belong to the robotics domain, through attempts to ‘adjust’ humans to robot requirements, to the overall replacement of humans with robots. Such separation or exclusion of humans poses serious ethical challenges, including the very exclusion of ethics from our thinking about robots",10.1145/3349537.3352801,https://core.ac.uk/download/287585750.pdf,18506467,human-robot dichotomy,2019-08-08T01:00:00,'Association for Computing Machinery (ACM)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The paper is focused on solving the problem of assessing the impact of repair-building works on the technical condition of objects near which these works were or are being carried out. Particular attention is paid to the analysis of the problems that accompany the creation of expert systems for supporting forensic building-technical expertise.
The main aim of the work:&nbsp;conceptual modeling of an expert system for supporting forensic building-technical expertise.
Object of research:&nbsp;the process of execution of forensic building-technical expertise and expert research.
Solved problem:&nbsp;automation of a system capable of functioning in conditions of fuzzy uncertainty caused by the non-uniformity of the logic of the process of performing forensic building-technical expertise and the ambiguity and inconsistency of the information provided for research.
Main scientific results:&nbsp;a model of a knowledge-based system is proposed and the use of neuro-fuzzy networks is justified to solve the problem of supporting the decision to assess the impact of repair-building works on the technical condition of the object, which has become the subject of expertise.
Field of practical use of research results:&nbsp;forensic activities in the framework of building-technical expertise to determine the possible causes of deterioration in the technical condition of structural elements of buildings and their individual premises.
Innovative technological product:&nbsp;a support system for forensic building-technical expertise based on knowledge and neuro-fuzzy models.
Scope of application of an innovative technological product:&nbsp;forensic and investigative practice in resolving issues requiring the use of special knowledge in assessing the impact of repair-building works on the technical condition of nearby facilities",10.21303/2313-8416.2020.001278,https://core.ac.uk/download/387020256.pdf,107666409,the use of neuro-fuzzy models in expert support systems for forensic building-technical expertise,2020-04-30T01:00:00,Scientific Route OÜ,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Temporally language grounding in untrimmed videos is a newly-raised task in
video understanding. Most of the existing methods suffer from inferior
efficiency, lacking interpretability, and deviating from the human perception
mechanism. Inspired by human's coarse-to-fine decision-making paradigm, we
formulate a novel Tree-Structured Policy based Progressive Reinforcement
Learning (TSP-PRL) framework to sequentially regulate the temporal boundary by
an iterative refinement process. The semantic concepts are explicitly
represented as the branches in the policy, which contributes to efficiently
decomposing complex policies into an interpretable primitive action.
Progressive reinforcement learning provides correct credit assignment via two
task-oriented rewards that encourage mutual promotion within the
tree-structured policy. We extensively evaluate TSP-PRL on the Charades-STA and
ActivityNet datasets, and experimental results show that TSP-PRL achieves
competitive performance over existing state-of-the-art methods.Comment: To appear in AAAI202",10.1609/aaai.v34i07.6924,http://arxiv.org/abs/2001.06680,89602944,"tree-structured policy based progressive reinforcement learning for
  temporally language grounding in video",2020-01-18T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Within the realm of image recognition, a specific category of multi-label
classification (MLC) challenges arises when objects within the visual field may
occlude one another, demanding simultaneous identification of both occluded and
occluding objects. Traditional convolutional neural networks (CNNs) can tackle
these challenges; however, those models tend to be bulky and can only attain
modest levels of accuracy. Leveraging insights from cutting-edge neural science
research, specifically the Holistic Bursting (HB) cell, this paper introduces a
pioneering integrated network framework named HB-net. Built upon the foundation
of HB cell clusters, HB-net is designed to address the intricate task of
simultaneously recognizing multiple occluded objects within images. Various
Bursting cell cluster structures are introduced, complemented by an evidence
accumulation mechanism. Testing is conducted on multiple datasets comprising
digits and letters. The results demonstrate that models incorporating the HB
framework exhibit a significant $2.98\%$ enhancement in recognition accuracy
compared to models without the HB framework ($1.0298$ times, $p=0.0499$).
Although in high-noise settings, standard CNNs exhibit slightly greater
robustness when compared to HB-net models, the models that combine the HB
framework and EA mechanism achieve a comparable level of accuracy and
resilience to ResNet50, despite having only three convolutional layers and
approximately $1/30$ of the parameters. The findings of this study offer
valuable insights for improving computer vision algorithms. The essential code
is provided at https://github.com/d-lab438/hb-net.git",,http://arxiv.org/abs/2310.11834,152217445,"hb-net: holistic bursting cell cluster integrated network for occluded
  multi-objects recognition",2023-10-18T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"As design practitioners researchers and educators, we constantly find ourselves shuffled between humanities and sciences. In fact, the design departments in the universities around the globe are sometimes placed under the formers, sometimes under the latters, thus becoming a meeting point for academics and professionals coming from both realms. The synergy resulting from the varieties of backgrounds and expertise creates a fertile ground for explorations on both a conceptual and a technical level. This paper reflects on the potential benefits of combining engineering and art research. The authors of this paper look at the increasingly delicate role that technicians, engineers and computer programmers play in developing technologies that impact our social, emotional and intimal lives, and advocate for art as a context and tool to help those professional developing their sensitivity and critical sense, besides their skills. In doing so, the paper makes a contribution to the STEM vs. STEAM conundrum, encouraging an education that merges arts and humanities disciplines with scientific and technical subjects",10.21606/drs.2018.304,https://core.ac.uk/download/327072306.pdf,36351444,why we need engineers to make art,2018-06-28T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Previous work on the automatic identification of fallacies in natural language text has typically approached the problem in constrained experimental setups that make it difficult to understand the applicability and usefulness of the proposals in the real world. In this paper, we present the first analysis of the limitations that these data-driven approaches could show in real situations. For that purpose, we first create a validation corpus consisting of natural language argumentation schemes. Second, we provide new empirical results to the emerging task of identifying fallacies in natural language text. Third, we analyse the errors observed outside of the testing data domains considering the new validation corpus. Finally, we point out some important limitations observed in our analysis that should be taken into account in future research in this topic. Specifically, if we want to deploy these systems in the Wild",,https://core.ac.uk/download/597041949.pdf,153798116,detecting argumentative fallacies in the wild:problems and limitations of large language models,2023-12-10T00:00:00,'Association for Computational Linguistics (ACL)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Although business process management systems (BPM) have been used over the years, their performance in unpredicted situations has not been adequately solved. In these cases, it is common to request user assistance or invoke predefined procedures. In this paper, we propose using the Active Semantic Model (ASM) to detect and handle exceptions. This is a specifically developed semantic network model for modeling of semantic features of the business processes. ASM is capable of classifying new situations based on their similarities with existing ones. Within BPM systems this is then used to classify new situations as exceptions and to handle the exceptions by changing the process based on ASM’s previous experience. This enables automatic detection and handling of exceptions which significantly improves the performance of bpm systems",,https://core.ac.uk/download/524099236.pdf,122024480,detection and handling exceptions in business process management systems using active semantic model,2022-05-26T01:00:00,'University of Nis - Faculty of Philosophy',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Federated learning has become a widely used paradigm for collaboratively
training a common model among different participants with the help of a central
server that coordinates the training. Although only the model parameters or
other model updates are exchanged during the federated training instead of the
participant's data, many attacks have shown that it is still possible to infer
sensitive information such as membership, property, or outright reconstruction
of participant data. Although differential privacy is considered an effective
solution to protect against privacy attacks, it is also criticized for its
negative effect on utility. Another possible defense is to use secure
aggregation which allows the server to only access the aggregated update
instead of each individual one, and it is often more appealing because it does
not degrade model quality. However, combining only the aggregated updates,
which are generated by a different composition of clients in every round, may
still allow the inference of some client-specific information. In this paper,
we show that simple linear models can effectively capture client-specific
properties only from the aggregated model updates due to the linearity of
aggregation. We formulate an optimization problem across different rounds in
order to infer a tested property of every client from the output of the linear
models, for example, whether they have a specific sample in their training data
(membership inference) or whether they misbehave and attempt to degrade the
performance of the common model by poisoning attacks. Our reconstruction
technique is completely passive and undetectable. We demonstrate the efficacy
of our approach on several scenarios which shows that secure aggregation
provides very limited privacy guarantees in practice. The source code will be
released upon publication.Comment: Workshop on Privacy in the Electronic Society (WPES'23), held in
  conjunction with CCS'2",,http://arxiv.org/abs/2303.03908,152502319,"client-specific property inference against secure aggregation in
  federated learning",2023-10-27T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The digital relies on computation. Programming uses algorithms. Algorithms are sets of rules that solve problems in a finite number of steps. In this sense, the digital world is governed by quantities, numbers, fixed rules. The degree of freedom seems to be very limited. Artistic agency and creativity, on the other hand, rely on openness, freedom, and qualitative experiences. Such experiences are not only vital to artistic expression but also to everyday life. Technological life-worlds as they are represented through current technologies (e.g. smart homes or automated driving) and science fiction do not seem to accommodate such open structures. The philosophy of technology is divided: Many hold that to a large extent technology determines human cognition (such as Mark B.N. Hansen, Bernard Stiegler) and thus subordinate human cognition to mechanical organizations. Others take a different approach and reflect on the creative potential of new technologies (e.g. Erin Manning, Jaime del Val).
This article discusses theories that address the human-machine relationship as complex structures that go beyond the dystopian idea of humans being transcended or incorporated by technology. Such approaches are central to the discussion on the future of human beings and cultural-political shaping of life-worlds. To understand how human-machine relationships can be framed as open and creative processes, I present epistemological accounts of embodied cognition, artistic examples of performance strategies with algorithmic set-ups, and finally embed these aspects within a broader picture of conceptualizing technology and human life as a continuum rather than standing in opposition or being determined by the other.Lo digital descansa en la computación. La programación utiliza algoritmos. Los algoritmos son el conjunto de reglas que resuelven problemas en un número finito de pasos. En este sentido, el mundo digital está regido por cantidades, números, reglas fijas. El grado de libertad parece muy limitado. Por el contrario, la actividad artística y la creatividad descansan en la apertura, la libertad y en experiencias cualitativas. Estas experiencias no solo son vitales para la expresión artística, sino para la vida cotidiana. Los mundos-vitales tecnológicos tal como se representan en tecnologías actuales (por ejemplo, en las casas inteligentes o en la conducción automática) o en la ciencia ficción no parecen dar cabida a estas estructuras abiertas. La filosofía de la tecnología está dividida: muchos sostienen que la tecnología determina en gran medida la cognición humana (como Mark B. N. Hansen, Bernard Stiegle) y, consiguientemente, subordina la cognición humana a las organizaciones maquinales. Otros adoptan una aproximación diferente y reflexionan sobre el potencial creativo de las nuevas tecnologías (Erin Mannig, Jaime del Val).
Este artículo discute teorías que abordan la relación humano-máquina en tanto que estructuras complejas que van más allá de la visión distópica del ser humano siendo trascendido o incorporado por la tecnología. Estas aproximaciones son centrales para discutir el futuro del ser humano y la conformación político-cultural de los mundos vitales. Para entender cómo las relaciones humano-máquina pueden considerarse como procesos abiertos y creativos, presento narrativas de cognición corporalizada, ejemplos artísticos de estrategias de performance con sistemas algorítmicos, y finalmente engarzo estos aspectos en un panorama más amplio sobre la conceptualización de la tecnología y la vida humana como un continuo, en vez de una sostenida oposición o un estar determinado por el otro",10.3989/arbor.2021.800004,https://core.ac.uk/download/478256234.pdf,122347169,colorear por números: la tecnología digital y el arte de vivir,2021-08-01T01:00:00,'Editorial CSIC',"[{'title': 'Arbor', 'identifiers': ['issn:1988-303X', 'issn:0210-1963', '0210-1963', '1988-303x']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Contrastive learning is a powerful framework for learning self-supervised
representations that generalize well to downstream supervised tasks. We show
that multiple existing contrastive learning methods can be reinterpreted as
learning kernel functions that approximate a fixed positive-pair kernel. We
then prove that a simple representation obtained by combining this kernel with
PCA provably minimizes the worst-case approximation error of linear predictors,
under a straightforward assumption that positive pairs have similar labels. Our
analysis is based on a decomposition of the target function in terms of the
eigenfunctions of a positive-pair Markov chain, and a surprising equivalence
between these eigenfunctions and the output of Kernel PCA. We give
generalization bounds for downstream linear prediction using our Kernel PCA
representation, and show empirically on a set of synthetic tasks that applying
Kernel PCA to contrastive learning models can indeed approximately recover the
Markov chain eigenfunctions, although the accuracy depends on the kernel
parameterization as well as on the augmentation strength.Comment: Published at ICLR 202",,http://arxiv.org/abs/2210.01883,140144988,"contrastive learning can find an optimal basis for approximately
  view-invariant functions",2023-02-14T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The International Workshop on Science, Technology and Innovation Roadmaps for Sustainable Development Goals (SDGs) took place in Kigali, January 9th-10th 2020. It was the first Workshop organised by the European Commission Joint Research Centre (JRC) that addressed Smart Specialisation for Territorial and Industrial Development in Rwanda. 
In line with the EU Green Deal and the objectives of the Government of Rwanda, the workshop emphasised the sharing of best practices between various countries and taking an evidence-based approach, with localisation of actions and prioritisation of efforts. 
Follow-up Smart Specialisation cooperation with Rwanda is now taking place in the framework of the JRC Exploratory Research activity on “Smart Specialisation in Innovative and Informal African Economies”.JRC.B.3-Territorial Developmen",10.2760/954014,https://core.ac.uk/download/322747943.pdf,85734439,sti roadmaps for sdgs: smart specialisation for territorial and industrial development in rwanda,2020-04-03T01:00:00,'Publications Office of the European Union',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"There is an increasing concern that generative AI models may produce outputs
that are remarkably similar to the copyrighted input content on which they are
trained. This worry has escalated as the quality and complexity of generative
models have immensely improved, and the availability of large datasets
containing copyrighted material has increased. Researchers are actively
exploring strategies to mitigate the risk of producing infringing samples, and
a recent line of work suggests to employ techniques such as differential
privacy and other forms of algorithmic stability to safeguard copyrighted
content.
  In this work, we examine the question whether algorithmic stability
techniques such as differential privacy are suitable to ensure the responsible
use of generative models without inadvertently violating copyright laws. We
argue that there are fundamental differences between privacy and copyright that
should not be overlooked. In particular we highlight that although algorithmic
stability may be perceived as a practical tool to detect copying, it does not
necessarily equate to copyright protection. Therefore, if it is adopted as
standard for copyright infringement, it may undermine copyright law intended
purposes",,http://arxiv.org/abs/2305.14822,142995426,can copyright be reduced to privacy?,2023-05-24T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Optimization is a process to discover the most effective element or solution from a set of all possible resources or solutions. Currently, there are various biological problems such as extending from biomolecule structure prediction to drug discovery that can be elevated by opting standard protocol for optimization. Particle swarm optimization (PSO) process, purposed by Dr. Eberhart and Dr. Kennedy in 1995, is solely based on population stochastic optimization technique. This method was designed by the researchers after inspired by social behavior of flocking bird or schooling fishes. This method shares numerous resemblances with the evolutionary computation procedures such as genetic algorithms (GA). Since, PSO algorithms is easy process to subject with minor adjustment of a few restrictions, it has gained more attention or advantages over other population based algorithms. Hence, PSO algorithms is widely used in various research fields like ranging from artificial neural network training to other areas where GA can be used in the system",10.5772/intechopen.73606,https://core.ac.uk/download/322435041.pdf,10955142,new trends in artificial intelligence: applications of particle swarm optimization in biomedical problems,2018-02-13T00:00:00,'IntechOpen',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
A look at the history of Natural Language Processing (NLP) and how machines learn to understand humans,,https://core.ac.uk/download/323047978.pdf,125814907,machines and human language,2020-05-05T22:15:16,RED: a Repository of Digital Collections,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The quality of research is the lifeline to get a good wood science, as science generally; embracing a ‘publish but don’t perish’ stance might be a valuable insight to stride this science forward. A focus on quality rather than quantity of published material would greatly reinvigorate our science and entrepreneurial capabilities, ensure continued public trust in the academic enterprise, address the needs and expectations of the 21st-century society, and help to secure a truly sustainable future, one that responsibly maintains the well-being of nature and people. Stimulating wood-based innovation certainly develops a fundamental niche in such sustainable future fitting the main goals of the sustainable development",10.12899/asr-2407,https://core.ac.uk/download/542870568.pdf,129348972,"under the “publish or perish” mantra and the race for grants, insights to catalyze research into wood science",2022-01-01T00:00:00,CREA Forestry and Wood,"[{'title': None, 'identifiers': ['2284-354x', 'issn:2284-354X']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"From the initial analysis of John Morris in 1976 about if computers can
lie, I have presented my own treatment of the problem using what can be called a
computational lying procedure. One that uses two Turing Machines. From there, I
have argued that such a procedure cannot be implemented in a Turing Machine
alone. A fundamental difficulty arises, concerning the computational representation
of the self-knowledge a machine should have about the fact that it is lying. Contrary
to Morris’ claim, I have thus suggested that computers – as far as they are Turing
Machines – cannot lie. Consequently, I have claimed that moral agency attribution
to a robot or any other automated AI system, cannot be made, strictly grounded on
imitating behaviors. Self-awareness as an ontological grounding for moral
attribution must be evoked. This can pose a recognition problem from our part,
should the sentient system be the only agent capable of acknowledging its own
sentience.info:eu-repo/semantics/publishedVersio",10.2478/kjps-2020-0009,https://core.ac.uk/download/482272676.pdf,40571930,"lying, computers and self-awareness",2021-10-14T01:00:00,'Walter de Gruyter GmbH',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The use of data to govern education is increasingly supported by the use of knowledge-based technologies, including algorithms, artificial intelligence (AI), and tracking technologies. Rather than accepting these technologies as possibilities to improve, reform, or more efficiently practice education, this intra-view discusses how these technologies portend possibilities to escape education. The intra-view revolves around Luciana Parisi’s idea of “digital contagions” and participants muse about the contagious opportunities to escape the biopolitical, colonial, and historical rationalities that contemporary education now uses to govern populations in ways that are automated, modulated, and wearable",,https://core.ac.uk/download/521889433.pdf,126366833,contagious education,2022-02-25T00:00:00,'Edicions de la Universitat de Barcelona',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"HUMANS
Blessings Outnumbering The Autumn Leaves, Savannah Tyler
The James White Library Archives, Grace No
ARTS & ENTERTAINMENT
A Charlie Brown Thanksgiving!, Lexie Dunham
Art: Reclaiming the Narrative, Madison Vath
A Trip to Detroit Through Nandi Comer\u27s Eyes, Ameilia Stefanescu
NEWS
Taking Flight at Acrofest, Nate Miller
Andrews Celebrates Veterans, Andrew Francis
Instruments of His Peace in a Broken World, Anna Rybachek
IDEAS
Are Aliens Real?, Katie Davis
Stay Vaccinated for the Sassy Man Epidemic, Charisse Lapuebla
The Thanksgiving Debate, Ruben Colón
PULSE
Artificial Intelligence: Are We Playing God?, Alyssa Caruthers
How Mission Work Impacts the Missionary: Advice for SMs, Caitlin Adap
Moral Conflict Part 2, Katie Davis,
The Illusion of Romantic Love, Nicole Compton-Gray
LAST WORD
The Joys of Journaling, Ian Freemanhttps://digitalcommons.andrews.edu/sm-108/1008/thumbnail.jp",,https://core.ac.uk/download/591343137.pdf,152403508,the student movement volume 108 issue 9: perfect landing: acrofest comes to andrews university,2023-11-17T08:00:00,Digital Commons @ Andrews University,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Deep neural networks (DNNs) are vulnerable to adversarial attack which is
maliciously implemented by adding human-imperceptible perturbation to images
and thus leads to incorrect prediction. Existing studies have proposed various
methods to detect the new adversarial attacks. However, new attack methods keep
evolving constantly and yield new adversarial examples to bypass the existing
detectors. It needs to collect tens of thousands samples to train detectors,
while the new attacks evolve much more frequently than the high-cost data
collection. Thus, this situation leads the newly evolved attack samples to
remain in small scales. To solve such few-shot problem with the evolving
attack, we propose a meta-learning based robust detection method to detect new
adversarial attacks with limited examples. Specifically, the learning consists
of a double-network framework: a task-dedicated network and a master network
which alternatively learn the detection capability for either seen attack or a
new attack. To validate the effectiveness of our approach, we construct the
benchmarks with few-shot-fashion protocols based on three conventional
datasets, i.e. CIFAR-10, MNIST and Fashion-MNIST. Comprehensive experiments are
conducted on them to verify the superiority of our approach with respect to the
traditional adversarial attack detection methods.Comment: 10 pages, 2 figures, accepted as the conference paper of Proceedings
  of the 27th ACM International Conference on Multimedia (MM'19",10.1145/3343031.3350887,http://arxiv.org/abs/1908.02199,89560614,metaadvdet: towards robust detection of evolving adversarial attacks,2019-08-06T01:00:00,'Association for Computing Machinery (ACM)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We present a highly compact run-time monitoring approach for deep computer
vision networks that extracts selected knowledge from only a few (down to
merely two) hidden layers, yet can efficiently detect silent data corruption
originating from both hardware memory and input faults. Building on the insight
that critical faults typically manifest as peak or bulk shifts in the
activation distribution of the affected network layers, we use strategically
placed quantile markers to make accurate estimates about the anomaly of the
current inference as a whole. Importantly, the detector component itself is
kept algorithmically transparent to render the categorization of regular and
abnormal behavior interpretable to a human. Our technique achieves up to ~96%
precision and ~98% recall of detection. Compared to state-of-the-art anomaly
detection techniques, this approach requires minimal compute overhead (as
little as 0.3% with respect to non-supervised inference time) and contributes
to the explainability of the model",10.1007/978-3-031-40923-3_7,http://arxiv.org/abs/2310.20349,153428750,"a low-cost strategic monitoring approach for scalable and interpretable
  error detection in deep neural networks",2023-10-31T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Background; This article explores the results of a three-year ethnographic study of how semiotic infrastructures-or digital standards and frameworks such as taxonomies, schemas, and ontologies that encode the meaning of data-are designed. Analysis: It examines debates over best practices in semiotic infrastructure design, such as how much complexity adopted languages should characterize versus how restrictive they should be. It also discusses political and pragmatic considerations that impact what and how information is represented in an information system. Conclusion and implications: This article suggests that all databased representations are forms of data power, and that examining semiotic infrastructure design provides insight into how culturally informed conceptions of difference structure how we access knowledge about our social and material worlds",10.22230/cjc.2019v44n3a3455,https://core.ac.uk/download/568199101.pdf,145304081,classification as catachresis: double binds of representing difference with semiotic infrastructure,2019-01-01T08:00:00,'CISP Journal Services',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"&lt;jats:title&gt;Abstract&lt;/jats:title&gt;&lt;jats:p&gt;The global carbon-climate system is a complex dynamical system with multiple feedbacks among components, and to steer this system away from dangerous climate change, it may not be enough to prescribe action according to long-term scenarios of fossil fuel emissions. We introduce here concepts from control theory, a branch of applied mathematics that is effective at steering complex dynamical systems to desired states, and distinguish between open- and closed-loop control. We attempt (1) to show that current scientific work on carbon-climate feedbacks and climate policy more closely resembles the conceptual model of open- than closed-loop control, (2) to introduce a mathematical generalization of the carbon-climate system as a compartmental dynamical system that can facilitate the formal treatment of the closed-loop control problem, and (3) to formulate carbon-climate control as a congestion control problem, discussing important concepts such as observability and controllability. We also show that most previous discussions on climate change mitigation and policy development have relied on an implicit assumption of open-loop control that does not consider frequent corrections due to deviations of goals from observations. Using a reduced complexity model, we illustrate that the problem of managing the global carbon cycle can be abstracted as a network congestion problem, accounting for nonlinear behavior and feedback from a global carbon monitoring system. As opposed to &lt;jats:italic&gt;scenarios&lt;/jats:italic&gt;, the goal of closed-loop control is to develop &lt;jats:italic&gt;rules&lt;/jats:italic&gt; for continuously steering the global carbon-climate system away from dangerous climate change.&lt;/jats:p&gt",10.17169/refubium-39903,https://core.ac.uk/download/578698421.pdf,148449654,prediction of stroke risk based on left atrial appendage morphology: from pareidolia to artificial intelligence,2021-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The paper presents the main characteristics and a preliminary implementation
of a novel computational framework named CompLog. Inspired by probabilistic
programming systems like ProbLog, CompLog builds upon the inferential
mechanisms proposed by Simplicity Theory, relying on the computation of two
Kolmogorov complexities (here implemented as min-path searches via ASP
programs) rather than probabilistic inference. The proposed system enables
users to compute ex-post and ex-ante measures of unexpectedness of a certain
situation, mapping respectively to posterior and prior subjective
probabilities. The computation is based on the specification of world and
mental models by means of causal and descriptive relations between predicates
weighted by complexity. The paper illustrates a few examples of application:
generating relevant descriptions, and providing alternative approaches to
disjunction and to negation",,http://arxiv.org/abs/2307.15453,144954839,from probabilistic programming to complexity-based programming,2023-07-28T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Research in neural networks in the field of computer vision has achieved
remarkable accuracy for point estimation. However, the uncertainty in the
estimation is rarely addressed. Uncertainty quantification accompanied by point
estimation can lead to a more informed decision, and even improve the
prediction quality. In this work, we focus on uncertainty estimation in the
domain of crowd counting. With increasing occurrences of heavily crowded events
such as political rallies, protests, concerts, etc., automated crowd analysis
is becoming an increasingly crucial task. The stakes can be very high in many
of these real-world applications. We propose a scalable neural network
framework with quantification of decomposed uncertainty using a bootstrap
ensemble. We demonstrate that the proposed uncertainty quantification method
provides additional insight to the crowd counting problem and is simple to
implement. We also show that our proposed method exhibits the state of the art
performances in many benchmark crowd counting datasets.Comment: Accepted in AAAI 2020 (Main Technical Track",10.1609/aaai.v34i07.6852,http://arxiv.org/abs/1903.07427,58960136,crowd counting with decomposed uncertainty,2020-04-03T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"La creciente exponencial de datos está afectando profundamente el entorno físico, y su proliferación descontrolada continuará reconfigurando y alterando el paisaje. Sin embargo, estas afectaciones pueden no ser inmediatamente aparentes.
Este proyecto tiene como objetivo explorar y representar visualmente el impacto de la producción masiva de datos en el paisaje físico, diseñando una ciudad especulativa para que los datos la habiten para ilustrar las posibles implicaciones de esta posibilidad en el futuro. El objetivo es estudiar el estado actual de la producción de datos, comprender sus efectos en el medio ambiente y crear una representación visual que resalte las posibles consecuencias del crecimiento de los datos.
A través de la investigación, el análisis y el diseño, este proyecto pretende contribuir al discurso sobre las implicaciones ambientales de la producción de datos y ofrecer ideas sobre los posibles escenarios futuros que esperan a nuestro entorno construido. Se invita a realizar un examen crítico de nuestras prácticas digitales y se fomenta un enfoque responsable y sostenible en la producción y consumo de datos.The exponential rise in data is profoundly affecting the physical environment, and its uncontrolled proliferation will continue to reshape and alter the landscape. However, these impacts may not be immediately apparent.
This project aims to explore and visually represent the impact of massive data production on the physical landscape by designing a speculative city for data to inhabit, illustrating the potential implications of this impact in the future. The objective is to study the current state of data production, understand its effects on the environment, and create a compelling visual representation that highlights the potential consequences of data growth.
Through research, analysis, and design, this project aims to contribute to the discourse on the environmental implications of data production and offer insights into potential future scenarios that await our built environment. It calls for a critical examination of our digital practices and encourages responsible and sustainable approaches to data production and consumption",,https://core.ac.uk/download/576867671.pdf,150044761,datascape: speculative city for data to inhabit,2023-07-11T01:00:00,Universitat Politècnica de Catalunya,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"While most task-oriented dialogues assume conversations between the agent and
one user at a time, dialogue systems are increasingly expected to communicate
with multiple users simultaneously who make decisions collaboratively. To
facilitate development of such systems, we release the Multi-User MultiWOZ
dataset: task-oriented dialogues among two users and one agent. To collect this
dataset, each user utterance from MultiWOZ 2.2 was replaced with a small chat
between two users that is semantically and pragmatically consistent with the
original user utterance, thus resulting in the same dialogue state and system
response. These dialogues reflect interesting dynamics of collaborative
decision-making in task-oriented scenarios, e.g., social chatter and
deliberation. Supported by this data, we propose the novel task of multi-user
contextual query rewriting: to rewrite a task-oriented chat between two users
as a concise task-oriented query that retains only task-relevant information
and that is directly consumable by the dialogue system. We demonstrate that in
multi-user dialogues, using predicted rewrites substantially improves dialogue
state tracking without modifying existing dialogue systems that are trained for
single-user dialogues. Further, this method surpasses training a medium-sized
model directly on multi-user dialogues and generalizes to unseen domains.Comment: To Appear in EMNLP-Findings 202",,http://arxiv.org/abs/2310.20479,152502522,multi-user multiwoz: task-oriented dialogues among multiple users,2023-10-31T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Explainability and causality are becoming increasingly relevant in Machine Learning research. On the one hand, given the growing use of models in decision-making
processes, the way in which they make predictions needs to be more thoroughly understood. On the other hand, a rising interest exists in formalising and introducing the
causal relationships present in the real world into those same models. This work addresses both aspects through the use of Shapley values, a concept that is at the origin
of SHAP, one of the most popular explainability techniques. Different methods for
calculating Shapley values to explain predictions are introduced that take into account
the dependence and the causal structure of the data. These methods are illustrated
and compared through a series of experiments using a database whose causal structure is known. They show that differences can be observed when taking causality into
account.La explicabilidad y la causalidad son áreas cada vez más relevantes en la investigación en Aprendizaje Automático. Por un lado, dado el creciente uso de los modelos
en los procesos de toma de decisión, es necesario comprender mejor la forma en que
realizan las predicciones. Por otro lado, existe un creciente interés por formalizar
e introducir en esos mismos modelos las relaciones causales presentes en el mundo
real. Este trabajo aborda ambos aspectos mediante el uso de los valores de Shapley,
concepto que está en el origen de SHAP, una de las técnicas de explicabilidad más
populares. Se exponen diferentes métodos de cálculo de valores de Shapley para explicar las predicciones que tienen en cuenta la dependencia y la estructura causal de
los datos. Estos métodos se ilustran y comparan mediante una serie de experimentos
que utilizan una base de datos cuya estructura causal se conoce. De ellos se pueden
observar que existen diferencias cuando se tiene en cuenta la causalidad.Universidad de Sevilla. Doble Grado en Matemáticas y Estadístic",,https://core.ac.uk/download/560384309.pdf,148775792,explainability and causality in machine learning through shapley values,2022-06-02T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"One of the recently proposed algorithms in the field of bio-inspired algorithm is the Hungry Roach Infestation Optimization (HRIO) algorithm. Haven has developed optimization algorithms HRIO that is inspired by recent discoveries in the social behaviour of cockroaches. Result showed that HRIO was effective at finding the global optima of a suite of test functions. However, there is no researcher who has observed HRIO for solving discrete problems. Therefore, we try to develop a discrete-cockroach algorithm (DCA) as the modification of HRIO for solving discrete optimization problem. We test the algorithm to solve bio-computation problem using single and multi-objectives optimization. The results showed DCA has better performance compared to the existed bio-inspired optimization algorithms such as genetic algorithms (GA) and discrete-particle swarm optimization (discrete-PSO)",10.11591/eecsi.v5.1639,https://core.ac.uk/download/296976184.pdf,10564920,development of discrete-cockroach algorithm (dca) for feature selection optimization,2019-09-18T00:00:00,'Institute of Advanced Engineering and Science',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Memes are a modern form of communication and meme templates possess a base
semantics that is customizable by whomever posts it on social media. Machine
learning systems struggle with memes, which is likely due to such systems
having insufficient context to understand memes, as there is more to memes than
the obvious image and text. Here, to aid understanding of memes, we release a
knowledge base of memes and information found on www.knowyourmeme.com, which we
call the Know Your Meme Knowledge Base (KYMKB), composed of more than 54,000
images. The KYMKB includes popular meme templates, examples of each template,
and detailed information about the template. We hypothesize that meme templates
can be used to inject models with the context missing from previous approaches.
To test our hypothesis, we create a non-parametric majority-based classifier,
which we call Template-Label Counter (TLC). We find TLC more effective than or
competitive with fine-tuned baselines. To demonstrate the power of meme
templates and the value of both our knowledge base and method, we conduct
thorough classification experiments and exploratory data analysis in the
context of five meme analysis tasks.Comment: 9 pages, 11 supplemental pages, 6 Tables, 10 Figure",,http://arxiv.org/abs/2311.06649,153550710,a template is all you meme,2023-11-11T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper presents a developer’s overview of the Thertact system that combines virtual reality, brain-computer-interface and thermal-tactile stimulation in a gait training simulator for a reha- bilitation protocol focused in promoting neurological recovery in spinal cord injured patients. We describe each part of the system, with special focus on aspects that have impact on the resulting overall sense of embodiment. The system comprises innovative aspects, such as the simulation of exoskeleton gait movement and thermal-tactile haptic feedback, and have shown promising results on a first case study with one patient in real hospital setting",10.62036/isd.2023.55,https://core.ac.uk/download/587843579.pdf,153501749,thertact-system: a virtual reality exoskeleton gait training simulator controlled by brain-computer interface,2023-10-05T11:15:49,AIS Electronic Library (AISeL),[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Narrative summarization aims to produce a distilled version of a narrative to
describe its most salient events and characters. Summarizing a narrative is
challenging as it requires an understanding of event causality and character
behaviors. To encourage research in this direction, we propose NarraSum, a
large-scale narrative summarization dataset. It contains 122K narrative
documents, which are collected from plot descriptions of movies and TV episodes
with diverse genres, and their corresponding abstractive summaries. Experiments
show that there is a large performance gap between humans and the
state-of-the-art summarization models on NarraSum. We hope that this dataset
will promote future research in summarization, as well as broader studies of
natural language understanding and generation. The dataset is available at
https://github.com/zhaochaocs/narrasum.Comment: EMNLP Findings 202",,http://arxiv.org/abs/2212.01476,143786833,narrasum: a large-scale dataset for abstractive narrative summarization,2023-06-28T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
open access articleThe article reviews the author’s personal development in relation to art made by algorithmic machines and discusses both the nature of such systems and the future implications for art,10.3390/arts7010003,https://core.ac.uk/download/228188011.pdf,66768785,algorithmic art machines,2018-01-01T00:00:00,'MDPI AG',"[{'title': 'Arts', 'identifiers': ['issn:2076-0752', '2076-0752']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In the realm of software applications in the transportation industry,
Domain-Specific Languages (DSLs) have enjoyed widespread adoption due to their
ease of use and various other benefits. With the ceaseless progress in computer
performance and the rapid development of large-scale models, the possibility of
programming using natural language in specified applications - referred to as
Application-Specific Natural Language (ASNL) - has emerged. ASNL exhibits
greater flexibility and freedom, which, in turn, leads to an increase in
computational complexity for parsing and a decrease in processing performance.
To tackle this issue, our paper advances a design for an intermediate
representation (IR) that caters to ASNL and can uniformly process
transportation data into graph data format, improving data processing
performance. Experimental comparisons reveal that in standard data query
operations, our proposed IR design can achieve a speed improvement of over
forty times compared to direct usage of standard XML format data",,http://arxiv.org/abs/2307.06983,144628426,"ir design for application-specific natural language: a case study on
  traffic data",2023-07-13T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Large language models (LLMs) have demonstrated an impressive ability to
generate codes on competitive programming tasks. However, with limited sample
numbers, LLMs still suffer from poor accuracy. Inspired by the process of human
programming, we propose a generate-and-edit approach named Self-Edit that
utilizes execution results of the generated code from LLMs to improve the code
quality on the competitive programming task. We execute the generated code on
the example test case provided in the question and wrap execution results into
a supplementary comment. Utilizing this comment as guidance, our fault-aware
code editor is employed to correct errors in the generated code. We perform
extensive evaluations across two competitive programming datasets with nine
different LLMs. Compared to directly generating from LLMs, our approach can
improve the average of pass@1 by 89\% on APPS-dev, 31\% on APPS-test, and 48\%
on HumanEval over nine popular code generation LLMs with parameter sizes
ranging from 110M to 175B. Compared to other post-processing methods, our
method demonstrates superior accuracy and efficiency.Comment: Accepted by ACL202",,http://arxiv.org/abs/2305.04087,143188549,self-edit: fault-aware code editor for code generation,2023-06-05T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"166-190The known in collaboration with the prevalent helps explore the variations of problems and helps derive the best possible solution from amongst the comprehensible ability of mankind. Nevertheless, this perception of the problem as well as the projected solution might not be the best-isolated pair if observed from a neutral window of infinite possibilities. The unknown, therefore, holds answers which must be explored. This paper attempts to elaborate the significance of investigating the Unknown or the Fictitious in the real world, considering examples, exemplars and prospects",,https://core.ac.uk/download/298011704.pdf,83115920,a route to a better tomorrow: the power of science fiction,2019-07-01T01:00:00,"NISCAIR-CSIR, India",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Our economies and societies are becoming more and more knowledge based which
implies that increasing numbers of people need to be educated and trained on new
subjects and processes. Thus, the reduction of the effort needed to design and prepare
educational and training programmes that meet the needs of the society and the
market is of paramount importance. To achieve this goal, first, we define a learning
programme model so that programme designers can easily exchange and re-use programme
structures and learning materials. The proposed model additionally enables
easier creation of interdisciplinary programmes which is another need of today’s
market. Second, we deploy a web-based tool that adopts this model towards facilitating
the re-use of structures and materials. Third, to reduce the time required for the
training actors to sense the market needs, we propose the establishment of an educational
programme marketplace. All three endeavours have been validated in the
energy transition sector and (positively) evaluated by experts during an international
workshop",10.1007/s43545-021-00087-9,https://core.ac.uk/download/541669841.pdf,139830565,designing an innovative educational toolbox to support the transition to new technologies,2021-01-01T00:00:00,'Springer Science and Business Media LLC',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Fictional narratives concerning science and technology, and specifically science fictionnarratives, are centred upon questions of difference, alterity and Otherness. Thoughnot representing classical science fiction texts, the analyzed novels display a key roleattributed to technological advancement and thus incorporate and discuss that centralquestion of Otherness in external and internal representation. Firstly, Ian McEwan’snovel Machines Like Me (2019) and Kazuo Ishiguro’s novel Klara and the Sun (2021)superficially deal with human-machine interaction, but also more subtly mirrorhumaneness in contrast to a perfectionist Machine Otherness that, in turn, questionshuman morality. Secondly, Juli Zeh’s novel Leere Herzen (Empty Hearts) (2017) andJulia von Lucadou’s novel Die Hochhausspringerin (The High Rise Diver) (2018)subconsciously display the more disruptive influences of Artificial Intelligence onsocieties. The conception of Otherness is thus not rooted in the opposition betweenmachines and human beings, but in a steady process of self-alienation.Fictional narratives concerning science and technology, and specifically science fiction narratives, are centred upon questions of difference, alterity and Otherness. Though not representing classical science fiction texts, the analyzed novels display a key role attributed to technological advancement and thus incorporate and discuss that central question of Otherness in external and internal representation. Firstly, Ian McEwan’s novel Machines Like Me (2019) and Kazuo Ishiguro’s novel Klara and the Sun (2021) superficially deal with human-machine interaction, but also more subtly mirror humaneness in contrast to a perfectionist Machine Otherness that, in turn, questions human morality. Secondly, Juli Zeh’s novel Leere Herzen (Empty Hearts) (2017) and Julia von Lucadou’s novel Die Hochhausspringerin (The High Rise Diver) (2018) subconsciously display the more disruptive influences of Artificial Intelligence on societies. The conception of Otherness is thus not rooted in the opposition between machines and human beings, but in a steady process of self-alienation",,https://core.ac.uk/download/524741613.pdf,126782143,representations of otherness – how literature reflects implications of digitalization and artificial intelligence on humaneness and societies,2022-01-01T00:00:00,interculture journal: online journal for intercultural studies,"[{'title': None, 'identifiers': ['issn:2196-9485', '2196-9485']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Maximalism in art refers to drawing on and combining multiple different
sources for art creation, embracing the resulting collisions and heterogeneity.
This paper discusses the use of maximalism in game design and particularly in
data games, which are games that are generated partly based on open data. Using
Data Adventures, a series of generators that create adventure games from data
sources such as Wikipedia and OpenStreetMap, as a lens we explore several
tradeoffs and issues in maximalist game design. This includes the tension
between transformation and fidelity, between decorative and functional content,
and legal and ethical issues resulting from this type of generativity. This
paper sketches out the design space of maximalist data-driven games, a design
space that is mostly unexplored.Comment: 9 pages, 2 Figures, Accepted in ICCC 201",,https://core.ac.uk/download/231681156.pdf,51506664,data-driven design: a case for maximalist game design,2018-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This study evaluates the GPT-4 Large Language Model's abductive reasoning in
complex fields like medical diagnostics, criminology, and cosmology. Using an
interactive interview format, the AI assistant demonstrated reliability in
generating and selecting hypotheses. It inferred plausible medical diagnoses
based on patient data and provided potential causes and explanations in
criminology and cosmology. The results highlight the potential of LLMs in
complex problem-solving and the need for further research to maximize their
practical applications.Comment: The article is 12 pages long and has one figure. It also includes a
  link to some ChatGPT dialogues that show the experiments that support the
  article's findings. The article will be published in V. Bambini and C.
  Barattieri di San Pietro (eds.), Sistemi Intelligenti, Special Section
  ""Multidisciplinary perspectives on ChatGPT and the family of Large Language
  Models",,http://arxiv.org/abs/2307.10250,144847336,"abductive reasoning with the gpt-4 language model: case studies from
  criminal investigation, medical practice, scientific research",2023-07-17T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Logical reasoning is a fundamental aspect of human intelligence and a key
component of tasks like problem-solving and decision-making. Recent
advancements have enabled Large Language Models (LLMs) to potentially exhibit
reasoning capabilities, but complex logical reasoning remains a challenge. The
state-of-the-art, solver-augmented language models, use LLMs to parse natural
language logical questions into symbolic representations first and then adopt
external logical solvers to take in the symbolic representations and output the
answers. Despite their impressive performance, any parsing errors will
inevitably result in the failure of the execution of the external logical
solver and no answer to the logical questions. In this paper, we introduce
LoGiPT, a novel language model that directly emulates the reasoning processes
of logical solvers and bypasses the parsing errors by learning to strict
adherence to solver syntax and grammar. LoGiPT is fine-tuned on a newly
constructed instruction-tuning dataset derived from revealing and refining the
invisible reasoning process of deductive solvers. Experimental results on two
public deductive reasoning datasets demonstrate that LoGiPT outperforms
state-of-the-art solver-augmented LMs and few-shot prompting methods on
competitive LLMs like ChatGPT or GPT-4.Comment: Preprin",,http://arxiv.org/abs/2311.06158,153804414,language models can be logical solvers,2023-11-10T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In this paper, we research the new topic of object effects recommendation in
micro-video platforms, which is a challenging but important task for many
practical applications such as advertisement insertion. To avoid the problem of
introducing background bias caused by directly learning video content from
image frames, we propose to utilize the meaningful body language hidden in 3D
human pose for recommendation. To this end, in this work, a novel human pose
driven object effects recommendation network termed PoseRec is introduced.
PoseRec leverages the advantages of 3D human pose detection and learns
information from multi-frame 3D human pose for video-item registration,
resulting in high quality object effects recommendation performance. Moreover,
to solve the inherent ambiguity and sparsity issues that exist in object
effects recommendation, we further propose a novel item-aware implicit
prototype learning module and a novel pose-aware transductive hard-negative
mining module to better learn pose-item relationships. What's more, to
benchmark methods for the new research topic, we build a new dataset for object
effects recommendation named Pose-OBE. Extensive experiments on Pose-OBE
demonstrate that our method can achieve superior performance than strong
baselines",,http://arxiv.org/abs/2209.08353,130766071,human pose driven object effects recommendation,2022-09-17T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The research reveals practical side of a twin green and digital transition in terms of a global path to climate neutral economy. Digitalization is considered as a driving force behind the transition towards a low-carbon economy. The article focuses on wide international experience of IT implementation for industrial decarbonization. Analytical database of the research covers more than 200 different eco-digital projects in various areas of climate regulations given by international organizations. This allows to outline international framework of eco-digital projects based on geolocation, regional features, IT decisions, level of technological support and climate influence. International differentiation of climate-digital projects was established by region. Comprehensive analysis of these data is provided to identify the gap in digital capabilities and climate targets. The rating of IT applied in climate-digital projects was built. As a result, the research proposes key project ways of the twin green and digital transition that are the most attractive for achieving climate neutrality on a global scale.  ",10.17770/etr2023vol1.7291,https://core.ac.uk/download/578075660.pdf,149982072,digital solutions for a climate neutral economy: international framework of eco-digital projects,2023-06-13T01:00:00,Rezekne Academy of Technologies,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"A natural way of estimating heteroscedastic label noise in regression is to
model the observed (potentially noisy) target as a sample from a normal
distribution, whose parameters can be learned by minimizing the negative
log-likelihood. This formulation has desirable loss attenuation properties, as
it reduces the contribution of high-error examples. Intuitively, this behavior
can improve robustness against label noise by reducing overfitting. We propose
an extension of this simple and probabilistic approach to classification that
has the same desirable loss attenuation properties. Furthermore, we discuss and
address some practical challenges of this extension. We evaluate the
effectiveness of the method by measuring its robustness against label noise in
classification. We perform enlightening experiments exploring the inner
workings of the method, including sensitivity to hyperparameters, ablation
studies, and other insightful analyses",,http://arxiv.org/abs/2304.02849,145193369,logistic-normal likelihoods for heteroscedastic label noise,2023-08-14T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"It will be observed that before the COVID-19 pandemic, online education was not popular in Nigeria’s higher and lower educational institutions of learning, either due to a lack of awareness, finance, or outright negligence by the authorities concerned. During the pandemic, most educational institutions were directed to study virtually (online), even when there were no previous plans. The remote learning idea failed to meet the needs of many students/learners in Nigeria, and some other parts of the globe alike. Many schools in Nigeria, if not all were shut down, and many educators noticed that the emergency virtual/remote learning option negatively influenced students’ and teachers’ social, emotional, and academic well-being. Because of these problems encountered, the Nigerian government cannot just watch, because online learning has become the in-thing, and has the potential to unlock every possibility in the Nigerian education system. So, the technological innovations of the 21st century have entrenched into most of all modern life activities, of which the education sector is now embedded in technology. Therefore, human beings need to keep pace with social change by adapting to the availability of these new technologies. Virtual learning has become one of these outcomes of technological innovations/inventions of the century in the field of education that has come to alleviate many educational challenges of citizens, especially in the Nigerian education system. Consequently, this paper, based on the evidence from the literature attempts to find out the importance, benefits, and pitfalls of a virtual learning environment in the Nigerian educational institutions’ context. Finally, the four learning theories that enhance or enable electronic learning were discussed, and in an attempt to discuss the characteristics of virtual learning, the author concisely highlighted the futuristic of online learning in Nigerian educational institutions",10.52155/ijpsat.v35.2.4798,https://core.ac.uk/download/596879742.pdf,152947599,icts in education industry: understanding virtual learning pedagogy: evidence from literature,2022-12-05T00:00:00,Scholar AI LLC,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In the context of the computational and algorithmic revolution, the digital image more than ever elevates the status of representations to the sphere of processes and operations. In a more general context, images can be seen as cultural agents, progressively developing new habits by promoting mediations between multiple subjects, whether human or nonhuman. From this perspective, we may question what characterizes the dynamics of those images. Can we consider digital images to be semiotic agents? Admitting this premise implies highlighting images not only as results or instruments but as integrated participants in processes. In light of this, we explore the digital image as a semiotic agent, from a Peircean semiotic perspective, from which the digital image can be seen as a sign, a dialogical being inserted in a network of relations",10.34632/jsta.2020.8195,https://core.ac.uk/download/480542301.pdf,122814641,digital image as a semiotic agent,2020-04-22T01:00:00,Universidade Católica Portuguesa,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In this work, we propose a novel method to improve the generalization ability
of CNN-based face forgery detectors. Our method considers the feature anomalies
of forged faces caused by the prevalent blending operations in face forgery
algorithms. Specifically, we propose a weakly supervised Second Order Local
Anomaly (SOLA) learning module to mine anomalies in local regions using deep
feature maps. SOLA first decomposes the neighborhood of local features by
different directions and distances and then calculates the first and second
order local anomaly maps which provide more general forgery traces for the
classifier. We also propose a Local Enhancement Module (LEM) to improve the
discrimination between local features of real and forged regions, so as to
ensure accuracy in calculating anomalies. Besides, an improved Adaptive Spatial
Rich Model (ASRM) is introduced to help mine subtle noise features via
learnable high pass filters. With neither pixel level annotations nor external
synthetic data, our method using a simple ResNet18 backbone achieves
competitive performances compared with state-of-the-art works when evaluated on
unseen forgeries",,http://arxiv.org/abs/2209.15490,131755699,learning second order local anomaly for general face forgery detection,2022-09-30T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Over the last few years, neural image compression has gained wide attention
from research and industry, yielding promising end-to-end deep neural codecs
outperforming their conventional counterparts in rate-distortion performance.
Despite significant advancement, current methods, including attention-based
transform coding, still need to be improved in reducing the coding rate while
preserving the reconstruction fidelity, especially in non-homogeneous textured
image areas. Those models also require more parameters and a higher decoding
time. To tackle the above challenges, we propose ConvNeXt-ChARM, an efficient
ConvNeXt-based transform coding framework, paired with a compute-efficient
channel-wise auto-regressive prior to capturing both global and local contexts
from the hyper and quantized latent representations. The proposed architecture
can be optimized end-to-end to fully exploit the context information and
extract compact latent representation while reconstructing higher-quality
images. Experimental results on four widely-used datasets showed that
ConvNeXt-ChARM brings consistent and significant BD-rate (PSNR) reductions
estimated on average to 5.24% and 1.22% over the versatile video coding (VVC)
reference encoder (VTM-18.0) and the state-of-the-art learned image compression
method SwinT-ChARM, respectively. Moreover, we provide model scaling studies to
verify the computational efficiency of our approach and conduct several
objective and subjective analyses to bring to the fore the performance gap
between the next generation ConvNet, namely ConvNeXt, and Swin Transformer.Comment: arXiv admin note: substantial text overlap with arXiv:2307.02273.
  text overlap with arXiv:2307.0609",,http://arxiv.org/abs/2307.06342,144628678,"convnext-charm: convnext-based transform for efficient neural image
  compression",2023-07-12T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"As active network defence systems, honeypots are commonly used as a decoy to inspect attackers and their attack tactics in order to improve the cybersecurity infrastructure of an organisation. A honeypot may be successful provided that it disguises its identity. However, cyberattackers continuously endeavour to discover honeypots for evading any deception and bolstering their attacks. Active fingerprinting attack is one such technique that may be used to discover honeypots by sending specially designed traffic. Preventing a fingerprinting attack is possible but doing that may hinder the process of dealing with the attackers, counteracting the purpose of a honeypot. Instead, detecting an attempted fingerprinting attack in real-time can enhance a honeypot’s capability, uninterruptedly managing any immediate consequences and preventing the honeypot being identified. Nevertheless, it is difficult to detect and predict an attempted fingerprinting attack due to the challenge of isolating it from other similar attacks, particularly when imprecise observations are involved in the monitoring of the traffic. Dynamic fuzzy rule interpolation (D-FRI) enables an adaptive approach for effective reasoning with such situations by exploiting the best of both inference and interpolation. The dynamic rules produced by D-FRI facilitate approximate reasoning with perpetual changes that often occur in this type of application, where dynamic rules are required to cover new network conditions. This paper proposes a D-FRI-Honeypot, an enhanced honeypot running D-FRI framework in conjunction with Principal Component Analysis, to detect and predict an attempted fingerprinting attack on honeypots. This D-FRI-Honeypot works with a sparse rule base but is able to detect active fingerprinting attacks when it does not find any matching rules. Also, it learns from current network conditions and offers a dynamically enriched rule base to support more precise detection. This D-FRI-Honeypot is tested against five popular fingerprinting tools (namely, Nmap, Xprobe2, NetScanTools Pro, SinFP3 and Nessus), to demonstrate its successful applications",10.1109/tetci.2020.3023447,https://core.ac.uk/download/346636335.pdf,8173755,d-fri-honeypot:a secure sting operation for hacking the hackers using dynamic fuzzy rule interpolation,2021-12-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"El propòsit d’aquest projecte és la investigació i subseqüent programació i
implementació d’un agent intel·ligent capaç de jugar a un videojoc de supervivència.
El projecte consisteix en dues parts principals. La primera se centra en l’estudi del
camp de la intel·ligència artificial espontània, supervisada i no supervisada, entenent
els mètodes comuns i extraient informació crucial amb la intenció d’implementar-los,
si és possible, en el nostre entorn. La segona consisteix a emprar tot el coneixement
adquirit per aconseguir fer l’agent el més adaptat possible a l’entorn on se
l’introdueixi.
No s’intentarà obtenir una perfecta optimització de tasques, ja que aquesta disciplina
ja s’ha explorat amb profunditat i de fer-ho el projecte es limitaria al seguiment d’un
camí ja recorregut. En canvi, el que s’intentarà de debò serà fer que l’agent
evolucioni de la manera més autònoma possible i esperar que sigui capaç d’innovar
a l’hora de trobar solucions originals per als problemes que li presentem.
L’agent hauria de ser capaç d’analitzar el seu voltant i reconèixer-hi altres entitats o
agents en les seves respectives localitzacions. A partir d’aquestes observacions i en
conjunt amb l’experiència adquirida prèviament, haurà de decidir quines accions
prendre utilitzant únicament controls convencionals. S’intentarà “imitar” el procés
d’aprenentatge dels éssers vius i no necessàriament seguir aproximacions purament
matemàtiques.
L’objectiu últim és doncs introduir-se en el camp dels agents intel·ligents en entorns
de 3 dimensions amb el propòsit de fer-ne un d’indistingible a les persones.El propósito de este proyecto es la investigación y subsecuente programación e
implementación de un agente inteligente capaz de jugar a un videojuego de
supervivencia.
El proyecto consiste de dos partes principales. La primera se centra en el estudio
del campo de la inteligencia artificial espontánea, supervisada y no supervisada,
entender los métodos más comunes y extraer información crucial con la intención de
implementarlos, a ser posible, en nuestro entorno. La segunda consiste en usar todo
el conocimiento adquirido para conseguir hacer el agente lo más adaptado posible al
entorno donde se le introduzca.
No se intentará conseguir ninguna perfecta optimización de tareas, ya que esta
disciplina ya se ha explorado en profundidad y de hacerlo el proyecto se limitaría al
seguimiento de un camino ya recorrido. En cambio, lo que se intentará en realidad
será hacer que el agente evolucione de la manera más autónoma posible y esperar
que sea capaz de innovar a la hora de encontrar soluciones originales a los
problemas que se le presenten.
El agente debería ser capaz de analizar sus alrededores y reconocer otras
entidades o agentes en sus respectivas localizaciones. A partir de esas
observaciones y en conjunto con la experiencia adquirida con anterioridad, deberá
decidir qué acciones tomar utilizando únicamente controles convencionales. Se
intentará “imitar” el proceso de aprendizaje de los seres vivos y no necesariamente
se seguirán aproximaciones puramente matemáticas.
El objetivo último es entonces introducirse en el campo de los agentes inteligentes
en entornos de 3 dimensiones con el propósito de hacer uno indistinguible a las
personas.The purpose of this project is the investigation and subsequent programming and
deployment of an intelligent agent capable of playing a survival video game.
It will consist of two main parts. The first focus will be to dive into the territory of
spontaneous, unsupervised Artificial Intelligence. Understanding the common
methods and extracting insights with the intent of hopefully implementing them into
our environment. The second part will consist in using the gathered knowledge for
making the agent as adapted as possible to the environment it is put into.
We will not be aiming for a perfect optimization of tasks as this discipline has already
been largely explored, and thus this project would be limited to the following of an
already established path. We will instead try to make the agent evolve as
autonomously as possible, and expect it to come up with unforeseen and not
necessarily optimal solutions to the problems we present it with.
The agent should be capable of analyzing its surroundings and recognizing other
entities or agents in their respective locations. From those and together with the
experience gathered previously, it will have to decide which actions to take by using
conventional controls. We intend it to “mimic” the learning process of living beings
and not necessarily follow strictly mathematical approaches.
Hence, the final goal is to get inside the field of smart agents in 3d virtual
environments with the purpose of making one closer to being indistinguishable from
humans",,https://core.ac.uk/download/534169943.pdf,133595318,"programació d'un agent intel·ligent capaç de sobreviure en un videojoc ""sandbox"" de 3dimensions",2022-06-27T01:00:00,Universitat Politècnica de Catalunya,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Due to the unequivocal need for understanding the decision processes of deep learning networks, both modal-dependent and model-agnostic techniques have become very popular. Although both of these ideas provide transparency for automated decision making, most methodologies focus on either using the modal-gradients (model- dependent) or ignoring the model internal states and reasoning with a model's behavior/outcome (model-agnostic) to instances. In this work, we propose a unified explanation approach that given an instance combines both model-dependent and agnostic explanations to produce an explanation set. The generated explanations are not only consistent in the neighborhood of a sample but can highlight causal relationships between image content and the outcome. We use Wireless Capsule Endoscopy (WCE) domain to illustrate the effectiveness of our explanations. The saliency maps generated by our approach are comparable or better on the softmax information score",,https://core.ac.uk/download/554841151.pdf,140003377,this changes to that: combining causal and non-causal explanations to generate disease progression in capsule endoscopy.,2023-02-15T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"There is a great deal of study and discussion about the character of future wars. Such a study is absolutely essential so that we are not caught in the trap of fighting the last war and finding ourselves on the losing side. However, it is also recognised that predicting future conflicts is not the easiest of tasks. Perhaps we can heed the words of Michael Howard, the eminent military historian, who said, that, “the purpose of future gazing in war is not to get it right but to avoid getting it terribly wrong.""
In assessing the future, we must analyse ongoing conflicts as these provide the best possible lessons in a live environment that cannot be replicated in wargames and exercises. However, we must also be mindful that wars occur in specific political, geographic, and strategic settings. What happens in one context may not be directly applicable in another. When the US was engaged in wars in Iraq and Afghanistan, it was predicted that the future of warfare would be insurgencies and countering terrorism. Wars between states were considered unlikely, with the greatest danger of such a war primarily in the Middle East and South Asia. The traditional thinking in the Indian military leadership was that conventional wars would be “short and swift.”
&nbsp;
&nbsp",,https://core.ac.uk/download/555483905.pdf,141976078,visualising the context  and contours of india’s future wars,2022-12-31T00:00:00,"Centre For Land Warfare Studies (CLAWS), New Delhi, India",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Nowadays, artificial intelligence (AI) became a special concern in language teaching for the reason that it can assist and enhance language learning for all levels of education. Again, it had beneficial roles for supplementing language teaching like ELSA Speak App one of Automatic Speech Recognition (ASR) used for teaching pronunciation. It studied how students heard, voiced, uttered, vocalized, and asserted the English words in the oral language, but the students often pronounced incorrect words with the result that the uttered words had faulty meaning. This study aimed to carry out English Language Speech Assistant (ELSA) Speak App to improve English language pronunciation skills to higher education learners that were the English Department Students of Nahdlatul Ulama University of Yogyakarta (UNU). The data were collected using a test of pronunciation and interview. The researcher also taught in the classroom. The results showed that ELSA Speak can increase the students’ pronunciation skills. It can be seen from the average scores obtained from the teaching cycles from two to four in grade. Clearly, ELSA Speak helped the students pronounce diverse words more easily and comprehensively. Also, the available features offered by this app like instant feedback enabled the students to pronounce precisely. In conclusion, ELSA Speak can improve the students’ pronunciation skills well and effectively. Indeed, it can motivate the students to engage in learning to pronounce",10.32332/joelt.v9i1.2723,https://core.ac.uk/download/427156762.pdf,112598472,elsa speak app: automatic speech recognition (asr) for supplementing english pronunciation skills,2021-05-02T01:00:00,'IAIN Metro Lampung',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The file attached to this record is the author's final peer reviewed version. The Publisher's final version can be found by following the DOI link.For the technologist it is easy to remain in safe technological enclaves with a bespoke language, a community of like minds and a familiar knowledge base. However, progress requires pushing the boundaries, thinking beyond the traditional and the ordinary, and questioning accepted norms. It requires opening of minds. It may surprise the reader that poetry can offer the key to unlock the closed mind. This potential is explored through a variety of poems dealing, in a novel manner, with the social impact of technology",10.1145/3381025,https://core.ac.uk/download/287585260.pdf,18506535,poetical potentials: the value of poems in social impact education,2019-12-26T00:00:00,'Association for Computing Machinery (ACM)',"[{'title': 'ACM Inroads', 'identifiers': ['2153-2184', 'issn:2153-2184']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The central aim of this article is to sketch and outline a brief and critical presentation, overview and assessment of the (radically ambivalent) dynamics of the large family of technological developments pertaining to the Fourth Industrial Revolution (Industry 4.0), as well as of the so-called digitalisation of society. This assessment attempts to comprehensively overcome relevant analytical dualisms and the one-sided “either-or” logic, in favor of a synthetic, open and creative “both-and” framework of interdisciplinary thought",,https://core.ac.uk/download/518120601.pdf,136398487,industry 4.0 and the digitalisation of society: curse or cure?,2018-09-28T01:00:00,Virtual Reality Internet Research and eLearning Laboratory,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Chatbots have become popular and are being used in the most diverse areas. The most
common use for chatbot are the ones integrated in our smartphones, like Google Assistant
and Siri. This kind of technology evolved significantly in the past few years and now the
users have the feeling to be talking to another human being. In a near future, most of the
interaction between large organisations and their users will be mediated by AI agents.
A market that benefited a lot from this arising technology are the e-commerce websites.
Sometimes, it can be a struggle to find a product in a web site due to bad interface designs.
When integrated in these websites, the clients have immediate access to a seller that is
able to help them find the product they want or clarify some doubts that they might have.
Despite the great evolution in the responsiveness of these systems, when talking about
the User Interface (UI) of the systems, there are no major changes. Normally, chatbots are
represented using the common chat box in the bottom right corner of the screen.
In the scope of iFetch project, that the main focus is revolutionise the chatbot assistance
in online sales, it is proposed for this dissertation the development of a user
interface for a chatbot with multimodal interaction, making the user experience more
interactive and engaging. This interface is a representation of a virtual room where the
user can see the products that he/she wants to buy. The is also a component of image
processing to be able to use the 2D images for the generation of their 3D representation.Atualmente, a utilização de chatbots alargou-se para as mais diversas áreas. O exemplo
mais comum são os chatbots integrados nos smartphones como o Google assistant ou a
Siri. Esta tecnologia tem evoluído significativamente nos últimos anos, dando a sensação
ao utilizador que está a falar com outro ser humano. Num futuro próximo, a maioria das
interações entre os clientes e as empresas será feito através de agentes AI.
Uma área que tem beneficiado muito com a introdução desta tecnologia, são os websites
de vendas online. Por vezes, poderá ser complicado um utilizador encontrar o produto
que pretende no site da loja, devido ao mau design da interface. Assim, os chatbot permitem
que os seus clientes tenham acesso rápido a um vendedor a qualquer momento, que
os ajudará a encontrar o artigo pretendido e tirar possíveis dúvidas que tenham.
Apesar de ser notória uma grande evolução na capacidade de resposta destes sistema,
no que toca a interface digital dos chatbots, não se tem notado grande inovação. A maioria
dos chatbots que encontramos hoje em dia, são a típica caixa de texto que se encontra no
canto inferior do ecrã.
Assim, dentro do contexto do projecto iFetch, que pretende desenvolver um chatbot
para a assistência no mundo das vendas online, surge este trabalho cujo objetivo passa
por desenvolver uma interface inovadora multimodal que permita tornar a experiência
dos utilizadores do website mais interativa. Esta interface consistirá numa loja virtual
onde o utilizador poderá visualizar os produtos que pretende comprar. Existe também
uma componente de processamento de imagem para que seja possível a visualização das
imagens 2D em manequins 3D",,https://core.ac.uk/download/543393708.pdf,130684841,multimodal interaction techniques for chatbots,2022-02-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Scale variation has been a challenge from traditional to modern approaches in
computer vision. Most solutions to scale issues have a similar theme: a set of
intuitive and manually designed policies that are generic and fixed (e.g. SIFT
or feature pyramid). We argue that the scaling policy should be learned from
data. In this paper, we introduce ELASTIC, a simple, efficient and yet very
effective approach to learn a dynamic scale policy from data. We formulate the
scaling policy as a non-linear function inside the network's structure that (a)
is learned from data, (b) is instance specific, (c) does not add extra
computation, and (d) can be applied on any network architecture. We applied
ELASTIC to several state-of-the-art network architectures and showed consistent
improvement without extra (sometimes even lower) computation on ImageNet
classification, MSCOCO multi-label classification, and PASCAL VOC semantic
segmentation. Our results show major improvement for images with scale
challenges. Our code is available here: https://github.com/allenai/elasticComment: CVPR 2019 oral, code available https://github.com/allenai/elasti",10.1109/cvpr.2019.00236,http://arxiv.org/abs/1812.05262,54209878,elastic: improving cnns with dynamic scaling policies,2019-04-08T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Semantic segmentation arises as the backbone of many vision systems, spanning
from self-driving cars and robot navigation to augmented reality and
teleconferencing. Frequently operating under stringent latency constraints
within a limited resource envelope, optimising for efficient execution becomes
important. At the same time, the heterogeneous capabilities of the target
platforms and the diverse constraints of different applications require the
design and training of multiple target-specific segmentation models, leading to
excessive maintenance costs. To this end, we propose a framework for converting
state-of-the-art segmentation CNNs to Multi-Exit Semantic Segmentation (MESS)
networks: specially trained models that employ parametrised early exits along
their depth to i) dynamically save computation during inference on easier
samples and ii) save training and maintenance cost by offering a post-training
customisable speed-accuracy trade-off. Designing and training such networks
naively can hurt performance. Thus, we propose a novel two-staged training
scheme for multi-exit networks. Furthermore, the parametrisation of MESS
enables co-optimising the number, placement and architecture of the attached
segmentation heads along with the exit policy, upon deployment via exhaustive
search in <1 GPUh. This allows MESS to rapidly adapt to the device capabilities
and application requirements for each target use-case, offering a
train-once-deploy-everywhere solution. MESS variants achieve latency gains of
up to 2.83x with the same accuracy, or 5.33 pp higher accuracy for the same
computational budget, compared to the original backbone network. Lastly, MESS
delivers orders of magnitude faster architectural customisation, compared to
state-of-the-art techniques.Comment: (Extended version) Accepted at ECCV 202",,http://arxiv.org/abs/2106.03527,124956944,multi-exit semantic segmentation networks,2022-07-31T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Nowadays there is a recurring buzzword: Digital Transformation (DX or DT) – it is an opportunity or a nightmare? The pandemic strengthened this trend, digital transformation helps to mitigate the effects of the crisis, improve resilience. “Resilience”, by the way, another recurring term in the pandemic time. We all agree on the meaning of the term “transformation” but “Digital” has different meanings. Jim Swanson, CIO of Johnson &amp; Johnson says, “Digital is a loaded word that means many things to many people”.
“Say 'digital' to persons and they think of going paperless; another might think of data analytics and artificial intelligence; another might picture Agile teams; and yet another might think of open-plan offices"". A comprehensive definition of the term Digital transformation should be the integration of digital technology into all areas of activity, from business to public sector, fundamentally changing how we operate and deliver value to customers or citizens. The adoption of digital technology represented a true competitive advantage, literally “Competitive advantage refers to factors that allow a company to produce goods or services better or more cheaply than its competitors. These factors allow the productive entity to generate more sales or superior margins compared to its market competitors.” 
It is evident that digital transformation it is not a process “one size fits all”, each specific sector and even activity requires a particular approach and custom solution; this starting from the three main branches: citizens, companies, public administrations. Because digital transformation will look different for every company, it can be hard to pinpoint a definition that applies to all. Sometimes this means walking away from long-standing business processes that companies were built upon in favour of relatively new practices that are still being defined. In such a situation the “trial and error ” finding by continues improvements the optimal solution is the practical approach. Let’s now try to depict some of the potential tangible or intangible impacts. Of course the following one is not a complete list of impacts but provides a first glance",,https://core.ac.uk/download/567634715.pdf,148139819,need for today’s time  data economy & connected challenges,2022-01-01T00:00:00,place:New Delhi,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Existing analyses of neural network training often operate under the
unrealistic assumption of an extremely small learning rate. This lies in stark
contrast to practical wisdom and empirical studies, such as the work of J.
Cohen et al. (ICLR 2021), which exhibit startling new phenomena (the ""edge of
stability"" or ""unstable convergence"") and potential benefits for generalization
in the large learning rate regime. Despite a flurry of recent works on this
topic, however, the latter effect is still poorly understood. In this paper, we
take a step towards understanding genuinely non-convex training dynamics with
large learning rates by performing a detailed analysis of gradient descent for
simplified models of two-layer neural networks. For these models, we provably
establish the edge of stability phenomenon and discover a sharp phase
transition for the step size below which the neural network fails to learn
""threshold-like"" neurons (i.e., neurons with a non-zero first-layer bias). This
elucidates one possible mechanism by which the edge of stability can in fact
lead to better generalization, as threshold neurons are basic building blocks
with useful inductive bias for many tasks.Comment: 31 pages, 13 figures, Published at NeurIPS 202",,http://arxiv.org/abs/2212.07469,152092056,"learning threshold neurons via the ""edge of stability""",2023-10-19T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The purpose of this report is to share lessons from an international research workshop dedicated to post- automation. Twenty-seven researchers from eleven different countries in Africa, Asia, Latin America and Europe, met at the Science Policy Research Unit at Sussex University on 11-13 September 2019, where we discussed empirical research papers and explored post-automation in group activities. We write this report primarily for researchers, but also for activists and policy advisors looking for more imaginative approaches to governing technology, work and sustainability in society, compared to those dominant agendas adapting automatically to the interests behind automation.

The report is structured as follows. Section two introduces the workshop topic and papers presented, and which leads into two related areas that became a focus for discussion. First, some challenges in the foundations

of automation theory (section three). And second, post-automation as a more constructive proposition to the challenges of automation, and that is happening right now (section four). Section five summarises some key points arising from the workshop, based on empirical observations from the margins of digital technology development, and that give both a flavour of the workshop and help elaborate the post-automation proposition. Some analytical and strategic themes are discussed in section six. We conclude in section seven with proposals for a post-automation agenda",,https://core.ac.uk/download/305117901.pdf,8038296,post-automation: report from an international workshop,2020-04-05T00:00:00,Science Policy Research Unit,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The recent pandemic has had an impact not only on the health and economy of citizens but boosted the digital transition. This paper summarises some of the impacts due to the increasing use of digital solutions, the list of impacts included will simply provide an idea about some of the impacts, but they are not limited to this set",,https://core.ac.uk/download/567636189.pdf,148140714,digital entrapment: tangible and intangible impact,2022-01-01T00:00:00,place:Moscow,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"One important issue in multi-agent systems is how to define agents’ interaction strategies in dynamic open environments. Generally, agents’ behaviors, such as being cooperative/altruistic or competitive/adversarial, are defined a priori by their creators. However, this is a weak premise when considering interaction among anonymous self-interested agents. Whenever agents meet, there is always a decision to be made: what is the best group interaction strategy? We argue that the answer depends on the amount of information required to make a decision and on the deadline proximity for accomplishing the task in hand. In certain situations, it is to the agents’ advantage to exchange information with others, while in other situations there are no incentives for them to spend time doing so. Understanding effective behaviors according to the decision- making scenario is still an open issue in multi-agent systems. In this paper, we present a multi-agent simulator (ACoPla) to understand the correlations between agents’ interaction strategy, decision-making context and successful task accomplishment rate. Additionally, we develop a case study in the domain of site evacuation to exemplify our findings. Through this study, we detect the types of conditions under which cooperation becomes the preferred strategy, as the environment changes",,https://core.ac.uk/download/211494723.pdf,61128159,acopla: a multiagent simulator to study individual strategies in dynamic situations,2018-01-01T00:00:00,Ediciones Universidad de Salamanca (España),"[{'title': 'ADCAIJ ADVANCES IN DISTRIBUTED COMPUTING AND ARTIFICIAL INTELLIGENCE JOURNAL', 'identifiers': ['issn:2255-2863', '2255-2863']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"There are many different notions of models in different areas of science that are often not aligned, making it difficult to discuss them across disciplines. In this study, we look at the differences between physical models and mental models as well as the difference between static and dynamic models. Semiotics provides a philosophical underpinning by explaining meaning-making. This allows for identifying a common ground between models in different areas. We use examples from natural sciences and linguistics to illustrate different approaches and concepts and to find commonalities. This study distinguishes between systems, models, and descriptions of models. This distinction allows us to understand the commonalities of mental and physical models in different areas.publishedVersio",10.3389/fcomp.2023.1031807,https://core.ac.uk/download/567631238.pdf,148149552,"models, systems, and descriptions - a cross-disciplinary reflection on models",2023-01-01T00:00:00,'Frontiers Media SA',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"How should we intervene on an unknown structural equation model to maximize a
downstream variable of interest? This setting, also known as causal Bayesian
optimization (CBO), has important applications in medicine, ecology, and
manufacturing. Standard Bayesian optimization algorithms fail to effectively
leverage the underlying causal structure. Existing CBO approaches assume
noiseless measurements and do not come with guarantees. We propose the
model-based causal Bayesian optimization algorithm (MCBO) that learns a full
system model instead of only modeling intervention-reward pairs. MCBO
propagates epistemic uncertainty about the causal mechanisms through the graph
and trades off exploration and exploitation via the optimism principle. We
bound its cumulative regret, and obtain the first non-asymptotic bounds for
CBO. Unlike in standard Bayesian optimization, our acquisition function cannot
be evaluated in closed form, so we show how the reparameterization trick can be
used to apply gradient-based optimizers. The resulting practical implementation
of MCBO compares favorably with state-of-the-art approaches empirically.Comment: 24 pages, 8 figures, accepted at ICLR 202",,http://arxiv.org/abs/2211.10257,141346558,model-based causal bayesian optimization,2023-03-10T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The existing deepfake detection methods have reached a bottleneck in
generalizing to unseen forgeries and manipulation approaches. Based on the
observation that the deepfake detectors exhibit a preference for overfitting
the specific primary regions in input, this paper enhances the generalization
capability from a novel regularization perspective. This can be simply achieved
by augmenting the images through primary region removal, thereby preventing the
detector from over-relying on data bias. Our method consists of two stages,
namely the static localization for primary region maps, as well as the dynamic
exploitation of primary region masks. The proposed method can be seamlessly
integrated into different backbones without affecting their inference
efficiency. We conduct extensive experiments over three widely used deepfake
datasets - DFDC, DF-1.0, and Celeb-DF with five backbones. Our method
demonstrates an average performance improvement of 6% across different
backbones and performs competitively with several state-of-the-art baselines.Comment: 12 pages. Code and Dataset: https://github.com/xaCheng1996/PRL",,http://arxiv.org/abs/2307.12534,144926121,"towards generalizable deepfake detection by primary region
  regularization",2023-07-24T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Health sciences curricular planners are challenged to add new content to established education programs. There is increasing pressure for content in public health, health systems, global health, and planetary health. These important areas often compete for curricular time. What is needed is a convergence model that builds a common framework within which students can integrate areas and better align this knowledge to the individual client or patient who they have responsibility to support. A population health framework is proposed for health sciences education programs that supports a common conceptual understanding of population health. The framework links five thematic areas that have influence on health and wellbeing and a sixth element that defines the range of methodologies essential to understanding health and wellbeing, from the individual to the population. The five areas providing convergence are: (1) the biopsychosocial development of the individual, (2) the socioeconomic factors that influence health and wellbeing, (3) the physical natural and built environment including climate, (4) the continuum of public health and health care systems, and (5) the nation state and global relationships. Using this framework, students are encouraged to think and understand individual health and wellbeing in context to the population and to utilize the appropriate methodological tools to explore these relationships. Planning for a new undergraduate medicine program illustrates the curricular elements that will be used to support student learning with foundation knowledge applied and tracked throughout the program. The proposed framework has application across health sciences disciplines and serves to build a common understanding that supports cross professional communication and collaboration",,https://core.ac.uk/download/552576469.pdf,137618943,medical education and population health—a framework in the design of a new undergraduate program,2022-12-01T08:00:00,eCommons@AKU,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The occurrence of diseases that impact the leaves of corn plants presents a substantial obstacle in agriculture, leading to a reduction in the overall yield of crops. This study aims to perform a comparative analysis of transfer learning methodologies by employing three distinct ResNet architectures: ResNet18, ResNet50, and ResNet101. The dataset utilized by the author consists of a compilation of images portraying corn leaves that demonstrate varying levels of disease severity. Transfer learning refers to leveraging a pre-existing ResNet model and retraining the network by employing the corn leaf dataset. The experimental results demonstrate that the ResNet18, ResNet50, and ResNet101 models achieved accuracy rates of 96.68%, 95.73%, and 95.26%, respectively. The ResNet101 model shows superior performance in terms of precision and recall metrics. This research indicates that utilizing a more complex and sophisticated network structure can improve the effectiveness of disease identification in corn plant leaves. The result above is essential in promoting sustainable agricultural methodologies and efficiently managing corn plant diseases",10.20527/jtiulm.v8i2.174,https://core.ac.uk/download/590810627.pdf,149872948,"comparison of detection with transfer learning architecture restnet18, restnet50, restnet101 on corn leaf disease",2023-11-05T00:00:00,Fakultas Teknik Universitas Lambung Mangkurat,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Training large language models (LLM) with open-domain instruction following
data brings colossal success. However, manually creating such instruction data
is very time-consuming and labor-intensive. Moreover, humans may struggle to
produce high-complexity instructions. In this paper, we show an avenue for
creating large amounts of instruction data with varying levels of complexity
using LLM instead of humans. Starting with an initial set of instructions, we
use our proposed Evol-Instruct to rewrite them step by step into more complex
instructions. Then, we mix all generated instruction data to fine-tune LLaMA.
We call the resulting model WizardLM. Human evaluations on a
complexity-balanced test bed show that instructions from Evol-Instruct are
superior to human-created ones. By analyzing the human evaluation results of
the high complexity part, we demonstrate that outputs from our WizardLM model
are preferred to outputs from OpenAI ChatGPT. Even though WizardLM still lags
behind ChatGPT in some aspects, our findings suggest that fine-tuning with
AI-evolved instructions is a promising direction for enhancing large language
models. Our codes and generated data are public at
https://github.com/nlpxucan/WizardLMComment: large language model, instruction fine-tun",,http://arxiv.org/abs/2304.12244,142491357,"wizardlm: empowering large language models to follow complex
  instructions",2023-04-24T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Justice, Autonomy, Freedom, Democracy, Equality, Privacy and the Common Good are all values that can be supported or threatened by computer technology. Considering that computer technologies are the fundamental infrastructure of the Information Age, ethical questions arise regarding access and control, privacy, property, identity and professional responsibility. It is important as a future Computer Scientist and Game Developer that I understand the ethical boundaries involved in software development. In this course, I will examine these values as issues that arise at the intersection of ethics, computers, technology, and society are addressed. I will also be closely studying (and presenting a project) on Artificial Intelligence",,https://core.ac.uk/download/231066280.pdf,132950950,advanced computer ethics: a study of artificial intelligence,2017-04-21T21:00:00,DigitalCommons@SHU,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper is divided into two realms. The first portion aims at addressing the post-humanist developments that continually assay to evolve whilst ambivalently opining about the castaways of the world who are the end products of tech-chrysalis. Simultaneously, the second section tries to focus on those very machines that try hard and fast to aid the émigré and refugees. It also attempts to understand the conflicting positions of politics, technology and humanity",,https://core.ac.uk/download/483691456.pdf,121904040,robunism:: introspecting the conjunction of human and humane mechanics,2021-11-01T00:00:00,"Ratnabali, Kolkata",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The digital transformation that the world is facing
has a strong impact in the professional occupations and job
profiles in the factories of the future context, requiring the need
of upskilling and re-qualification of the workforce. Taking this
into account, an Industrial Collaborative Educational Design
(ICoED) is presented comprising three stages and eight steps,
and considering a democratic and collaborative participation of
the different stakeholders, namely the managers, educators and
learners, each one providing its own perspective on the design of
the training programme. In this co-design process, the analysis
of the skills’ gap is a crucial task to prepare the initial stage
of the process, particularly identifying the needs in terms of
soft and hard skills. The proposed ICoED process was applied
to solve an upskilling problem of an industrial metal stamping
company, with the participants performing three workshops to
execute the eight steps, reaching a training programme with five
modules, each one settled with proper activities, resources and
infrastructures.This work is part of the FIT4FoF project that has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement n. 820701.info:eu-repo/semantics/publishedVersio",10.1109/iecon48115.2021.9589528,https://core.ac.uk/download/512050321.pdf,39407691,co-design process for upskilling the workforce in the factories of the future,2021-01-01T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The recent global technological and social disruptions are changing the game of innovation management. Indeed, knowledge sharing in its ideation, collaboration, and

deployment phases is becoming increasingly gamified by nature: a more diverse and

ad-hoc pool of contributors emerge under the culture of individual entrepreneurship.

The World Innovation Stock Exchange (W-ISE) structures metaverstic collaborative

innovation management while fully potentializing the outcomes of Globalisation 5.0.

This exchange facilitates physical and moral individuals’ interactions and socioeconomic discussions. Furthermore, it frames the intervention of computing systems

as managing forces in project management and innovation development. Yet, this

first conceptualization has limitations in addressing the facilitation of all stages of

innovation management. To clarify the development of the W-ISE domain, this paper

describes in detail how the World Innovation Stock Exchange Democratic Incubator (WISE-DI) operates conceptually and how it could be gamified for an improved

immersive and engaging experience in R&D activities",,https://core.ac.uk/download/533457803.pdf,149551163,metaverstic innovation management: the world innovation stock exchange democratic incubator,2022-01-01T00:00:00,AHFE International,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Detecting digital face manipulation in images and video has attracted
extensive attention due to the potential risk to public trust. To counteract
the malicious usage of such techniques, deep learning-based deepfake detection
methods have been employed and have exhibited remarkable performance. However,
the performance of such detectors is often assessed on related benchmarks that
hardly reflect real-world situations. For example, the impact of various image
and video processing operations and typical workflow distortions on detection
accuracy has not been systematically measured. In this paper, a more reliable
assessment framework is proposed to evaluate the performance of learning-based
deepfake detectors in more realistic settings. To the best of our
acknowledgment, it is the first systematic assessment approach for deepfake
detectors that not only reports the general performance under real-world
conditions but also quantitatively measures their robustness toward different
processing operations. To demonstrate the effectiveness and usage of the
framework, extensive experiments and detailed analysis of three popular
deepfake detection methods are further presented in this paper. In addition, a
stochastic degradation-based data augmentation method driven by realistic
processing operations is designed, which significantly improves the robustness
of deepfake detectors",,http://arxiv.org/abs/2304.06125,142318348,assessment framework for deepfake detection in real-world situations,2023-04-12T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Aiming at the occurrence of long-term and ultra-low frequency oscillations in the hydropower network system, this paper derives the generalized turbine transfer function speed control system model including the flow factor Tpq based on the generalized turbine model, and analyzes the influence of Tpq and PID parameters on the ultra-low frequency damping of the hydraulic turbine governing system. In order to better suppress the ultra-low frequency oscillation caused by improper PID parameter settings, a comprehensive optimization objective function reflecting damping and turbine speed deviation index (ITAE) in ultra-low frequency band is established. Based on the fast and efficient optimization strategy of Beetle Antennae Search, an improved beetle antennae particle swarm optimization is constructed. In single-machine and multi-machine systems, the improved algorithm is compared with different optimization algorithms. The simulation results show that the improved algorithm can overcome the slow convergence speed and easily fall into local optimization problem, effectively improve the damping level of hydraulic turbine governing system in ultra-low frequency, and is more effective and superior than other optimization algorithms. It provides a new way of thinking and technical means to suppress the ultra-low frequency oscillation by optimizing the parameters of the speed control system",10.17559/tv-20201012123041,https://core.ac.uk/download/481997914.pdf,123212519,optimal control strategy of turbine governor parameters based on improved beetle antennae search algorithm,2021-01-01T00:00:00,'Mechanical Engineering Faculty in Slavonski Brod',"[{'title': 'Tehnicki vjesnik - Technical Gazette', 'identifiers': ['1330-3651', '1848-6339', 'issn:1848-6339', 'issn:1330-3651']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Large language models (LLMs) have demonstrated solid zero-shot reasoning
capabilities, which is reflected in their performance on the current test
tasks. This calls for a more challenging benchmark requiring highly advanced
reasoning ability to be solved. In this paper, we introduce such a benchmark,
consisting of 191 long-form (1200 words on average) mystery narratives
constructed as detective puzzles. Puzzles are sourced from the ""5 Minute
Mystery"" platform and include a multiple-choice question for evaluation. Only
47% of humans solve a puzzle successfully on average, while the best human
solvers achieve over 80% success rate. We show that GPT-3 models barely
outperform random on this benchmark (with 28% accuracy) while state-of-the-art
GPT-4 solves only 38% of puzzles. This indicates that there is still a
significant gap in the deep reasoning abilities of LLMs and humans and
highlights the need for further research in this area. Our work introduces a
challenging benchmark for future studies on reasoning in language models and
contributes to a better understanding of the limits of LLMs' abilities.Comment: 5 pages, to appear at *SE",,http://arxiv.org/abs/2212.10114,143186630,"true detective: a deep abductive reasoning benchmark undoable for gpt-3
  and challenging for gpt-4",2023-06-01T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Humans are highly adaptable, swiftly switching between different modes to
progressively handle different tasks, situations and contexts. In Human-object
interaction (HOI) activities, these modes can be attributed to two mechanisms:
(1) the large-scale consistent plan for the whole activity and (2) the
small-scale children interactive actions that start and end along the timeline.
While neuroscience and cognitive science have confirmed this multi-mechanism
nature of human behavior, machine modeling approaches for human motion are
trailing behind. While attempted to use gradually morphing structures (e.g.,
graph attention networks) to model the dynamic HOI patterns, they miss the
expeditious and discrete mode-switching nature of the human motion. To bridge
that gap, this work proposes to model two concurrent mechanisms that jointly
control human motion: the Persistent process that runs continually on the
global scale, and the Transient sub-processes that operate intermittently on
the local context of the human while interacting with objects. These two
mechanisms form an interactive Persistent-Transient Duality that
synergistically governs the activity sequences. We model this conceptual
duality by a parent-child neural network of Persistent and Transient channels
with a dedicated neural module for dynamic mechanism switching. The framework
is trialed on HOI motion forecasting. On two rich datasets and a wide variety
of settings, the model consistently delivers superior performances, proving its
suitability for the challenge.Comment: Accepted at ICCV 202",,http://arxiv.org/abs/2307.12729,144926337,"persistent-transient duality: a multi-mechanism approach for modeling
  human-object interaction",2023-07-24T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper highlights the need to bring document classification benchmarking
closer to real-world applications, both in the nature of data tested ($X$:
multi-channel, multi-paged, multi-industry; $Y$: class distributions and label
set variety) and in classification tasks considered ($f$: multi-page document,
page stream, and document bundle classification, ...). We identify the lack of
public multi-page document classification datasets, formalize different
classification tasks arising in application scenarios, and motivate the value
of targeting efficient multi-page document representations. An experimental
study on proposed multi-page document classification datasets demonstrates that
current benchmarks have become irrelevant and need to be updated to evaluate
complete documents, as they naturally occur in practice. This reality check
also calls for more mature evaluation methodologies, covering calibration
evaluation, inference complexity (time-memory), and a range of realistic
distribution shifts (e.g., born-digital vs. scanning noise, shifting page
order). Our study ends on a hopeful note by recommending concrete avenues for
future improvements.}Comment: 8 pages, under revie",,http://arxiv.org/abs/2308.12896,146341522,"beyond document page classification: design, datasets, and challenges",2023-08-29T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In this paper, we study the problem of secret language in NLP, where current
language models (LMs) seem to have a hidden vocabulary that allows them to
interpret absurd inputs as meaningful concepts. We investigate two research
questions: ``Does the secret language phenomenon exist in different language
models?'' and ``Does secret language depend on specific context?'' To answer
these questions, we introduce a novel method named \textit{SecretFinding}, a
gradient-based approach that can automatically discover secret languages in
LMs. We conduct experiments on five representative models (Electra, ALBERT,
Roberta, DistillBERT, and CLIP) finetuned on four NLP benchmarks (SST-2, MRPC,
SNLI, and SQuAD) and a language-grounding benchmark (MSCOCO). Our experimental
results show that even when we replace the most important words with others
that are semantically dissimilar to the original words in a sentence, LMs do
not consider the new sentence semantically dissimilar to the original, as the
output does not change with a high probability. This phenomenon holds true
across the five models and five tasks and gives a positive answer to the first
research question. As for the second research question, we find that the secret
language discovered by \textit{SecretFinding} is quite general and could even
be transferred to other models in the black-box settings, such as GPT-3 and
ChatGPT. Finally, we discuss the causes of secret language, how to eliminate
it, the potential connection to memorization, and ethical implications.
Examples of secret language found by SecretFinding are available on
https://huggingface.co/spaces/anonymousauthors/ACL23_SecretLanguage",,http://arxiv.org/abs/2307.12507,144925546,"investigating the existence of ""secret language'' in language models",2023-07-23T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Pretrained masked language models (MLMs) require finetuning for most NLP
tasks. Instead, we evaluate MLMs out of the box via their pseudo-log-likelihood
scores (PLLs), which are computed by masking tokens one by one. We show that
PLLs outperform scores from autoregressive language models like GPT-2 in a
variety of tasks. By rescoring ASR and NMT hypotheses, RoBERTa reduces an
end-to-end LibriSpeech model's WER by 30% relative and adds up to +1.7 BLEU on
state-of-the-art baselines for low-resource translation pairs, with further
gains from domain adaptation. We attribute this success to PLL's unsupervised
expression of linguistic acceptability without a left-to-right bias, greatly
improving on scores from GPT-2 (+10 points on island effects, NPI licensing in
BLiMP). One can finetune MLMs to give scores without masking, enabling
computation in a single inference pass. In all, PLLs and their associated
pseudo-perplexities (PPPLs) enable plug-and-play use of the growing number of
pretrained MLMs; e.g., we use a single cross-lingual model to rescore
translations in multiple languages. We release our library for language model
scoring at https://github.com/awslabs/mlm-scoring.Comment: ACL 2020 camera-ready (presented July 2020",10.18653/v1/2020.acl-main.240,http://arxiv.org/abs/1910.14659,85778821,masked language model scoring,2020-01-01T00:00:00,'Association for Computational Linguistics (ACL)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper examines the regulation of technology platform companies providing a platform for user-generated media content while playing an increasingly dominant role in the global flow of news and information. In doing so, platform companies play a crucial role in modern civic life, by deciding which content will reach users, engage the public\u27s attention, and be deemed credible. It is therefore crucial that we choose means of regulation that foster democratic values and robust civic engagement. In this paper we focus on the regulation of ‘computational propaganda\u27, including misinformation and ‘fake news\u27, the rise of synthetic media and so-called ‘deep fakes\u27, and novel forms of algorithmic injustice, such as the manipulation of search engine results and their effect on elections. We argue that many existing regulations fall short in that they adopt an approach that views regulation as a battle between two competing powers, or ‘empires’–that of the regulatory state versus the big tech companies. Accordingly, they approach regulation as a means of redistributing power between these two players, while discounting the end user, and they often involve unjustified restrictions of free speech through the imposition of content controls. © 2020 Informa UK Limited, trading as Taylor & Francis Group",,https://core.ac.uk/download/323494050.pdf,86039442,the clash of empires: regulating technological threats to civil society,2020-02-26T08:00:00,"Edith Cowan University, Research Online, Perth, Western Australia",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We would like to acknowledge the financial support obtained from North Portugal Regional Operational Programme (NORTE 2020), Portugal 2020 and the European Regional Development Fund (ERDF) from European Union through the project Symbiotic technology for societal efficiency gains: Deus ex Machina (DEM), NORTE-01-0145-FEDER-000026. We would like to acknowledge as well the projects AHA CMUP-ERI/HCI/0046 and INSIDE CMUP-ERI/HCI/051/2013 both financed by Fundcao para a Ciencia e Tecnologia (FCT).Nowadays, data scientists are capable of manipulating and extracting complex information from time series data, given the current diversity of tools at their disposal. However, the plethora of tools that target data exploration and pattern search may require an extensive amount of time to develop methods that correspond to the data scientist's reasoning, in order to solve their queries. The development of new methods, tightly related with the reasoning and visual analysis of time series data, is of great relevance to improving complexity and productivity of pattern and query search tasks. In this work, we propose a novel tool, capable of exploring time series data for pattern and query search tasks in a set of 3 symbolic steps: Pre-Processing, Symbolic Connotation and Search. The framework is called SSTS (Symbolic Search in Time Series) and uses regular expression queries to search the desired patterns in a symbolic representation of the signal. By adopting a set of symbolic methods, this approach has the purpose of increasing the expressiveness in solving standard pattern and query tasks, enabling the creation of queries more closely related to the reasoning and visual analysis of the signal. We demonstrate the tool's effectiveness by presenting 9 examples with several types of queries on time series. The SSTS queries were compared with standard code developed in Python, in terms of cognitive effort, vocabulary required, code length, volume, interpretation and difficulty metrics based on the Halstead complexity measures. The results demonstrate that this methodology is a valid approach and delivers a new abstraction layer on data analysis of time series.publishersversionpublishe",10.1016/j.ipm.2018.09.001,https://core.ac.uk/download/553621983.pdf,138647945,ssts: a syntactic tool for pattern search on time series,2019-01-01T00:00:00,'Elsevier BV',"[{'title': 'Information Processing & Management', 'identifiers': ['issn:0306-4573', '0306-4573']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In the context of the intelligent and digital society, there are changes in the competencies and role of legal professionals, who, in addition to the essential legal and procedural knowledge, also have to acquire skills to understand and use technological tools that allow the implementation of new behaviors and relevant acts in the legal world such as smart contracts. The purpose of the article is to describe the main challenges facing the law in Colombia in the context of the intelligent and digital society through the documentary analysis of the corresponding regulations and jurisprudenceEn el contexto de la sociedad inteligente y digital se presentan cambios en las competencias y el papel de los profesionales del derecho, los cuales además de los conocimientos jurídicos esenciales y procesales, también han de adquirir habilidades para la comprensión y uso de herramientas tecnológicas que permiten la implementación y desarrollo de nuevas conductas y actos relevantes en el mundo jurídico como los contratos inteligentes. La finalidad del artículo es describir los principales retos que afronta el derecho en Colombia frente al contexto de la sociedad inteligente y digital mediante el análisis documental de la normativa y jurisprudencia correspondiente",10.5281/zenodo.4278404,https://core.ac.uk/download/367979955.pdf,69357607,innovación–inteligencia artificial: retos del derecho frente a una sociedad digital,2020-01-01T00:00:00,Corporación Universidad de la Costa,"[{'title': None, 'identifiers': ['1316-5216', '2477-9555', 'issn:2477-9555', 'issn:1316-5216']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Large language models have become a potential pathway toward achieving
artificial general intelligence. Recent works on multi-modal large language
models have demonstrated their effectiveness in handling visual modalities. In
this work, we extend the research of MLLMs to point clouds and present the
LAMM-Dataset and LAMM-Benchmark for 2D image and 3D point cloud understanding.
We also establish an extensible framework to facilitate the extension of MLLMs
to additional modalities. Our main contribution is three-fold: 1) We present
the LAMM-Dataset and LAMM-Benchmark, which cover almost all high-level vision
tasks for 2D and 3D vision. Extensive experiments validate the effectiveness of
our dataset and benchmark. 2) We demonstrate the detailed methods of
constructing instruction-tuning datasets and benchmarks for MLLMs, which will
enable future research on MLLMs to scale up and extend to other domains, tasks,
and modalities faster. 3) We provide a primary but potential MLLM training
framework optimized for modalities' extension. We also provide baseline models,
comprehensive experimental observations, and analysis to accelerate future
research. Codes and datasets are now available at
https://github.com/OpenLAMM/LAMM.Comment: 37 pages, 33 figures. Code available at
  https://github.com/OpenLAMM/LAMM ; Project page: https://openlamm.github.io",,http://arxiv.org/abs/2306.06687,143474874,"lamm: language-assisted multi-modal instruction-tuning dataset,
  framework, and benchmark",2023-06-18T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
https://digitalcommons.usu.edu/covid/1048/thumbnail.jp,,https://core.ac.uk/download/545810788.pdf,133452125,interview with eric hawley,2022-12-01T08:00:00,DigitalCommons@USU,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper investigates the kind of sign making that goes on in text-based human–computer interaction, between human users and chatbots, from the point of view of integrational linguistics. A chatbot serves as a “conversational” user interface, allowing users to control computer programs in “natural language”. From the user’s perspective, the interaction is a case of semiologically integrated activity, but even if the textual traces of a chat may look like a written conversation between two humans the correspondence is not one-to-one. It is argued that chatbots cannot engage in communication processes, although they may display communicative behaviour. They presuppose a (second-order) language model, they can only communicate at the level of sentences, not utterances, and they implement communicational sequels by selecting from an inventory of executable skills. Instead of seeing them as interlocutors in silico, chatbots should be seen as powerful devices for humans to make signs with.&nbsp;
&nbsp;
&nbsp",10.12697/sss.2020.48.1.05,https://core.ac.uk/download/328898899.pdf,87553635,chatting with chatbots: sign making in text-based human–computer interaction,2020-01-01T00:00:00,'University of Tartu',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In Romania, both the business environment stakeholders and the academics consider that the path on reaching the average level of development of the European Union and implicitly the adoption of the Euro currency, can be achieved only by improving the standard of living that is the citizens’ income, which can be reached only by increasing labour productivity. One of the objectives of the European Union is to reduce the disparities between regions, as confirmed by the evolution of GDP/ capita in the less prosperous Eastern Europe countries in comparison with the more developed EU Members States from Western Europe. There are a number of factors impacting the labour productivity and wage incomes, and the onset of the COVID 19 pandemic has accelerated the adoption of automation, digitalisation and remote work, which will significantly contribute to the disappearance of less skilled jobs and the consolidation of those who are highly qualified ones, the latter being less sensitive to the adoption of new technologies.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp",,https://core.ac.uk/download/539380161.pdf,126851002,some issues on the correlation between wage income and labour productivity,2022-02-14T00:00:00,"Agora University of Oradea, Romania",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"With the advancement in face manipulation technologies, the importance of
face forgery detection in protecting authentication integrity becomes
increasingly evident. Previous Vision Transformer (ViT)-based detectors have
demonstrated subpar performance in cross-database evaluations, primarily
because fully fine-tuning with limited Deepfake data often leads to forgetting
pre-trained knowledge and over-fitting to data-specific ones. To circumvent
these issues, we propose a novel Forgery-aware Adaptive Vision Transformer
(FA-ViT). In FA-ViT, the vanilla ViT's parameters are frozen to preserve its
pre-trained knowledge, while two specially designed components, the Local-aware
Forgery Injector (LFI) and the Global-aware Forgery Adaptor (GFA), are employed
to adapt forgery-related knowledge. our proposed FA-ViT effectively combines
these two different types of knowledge to form the general forgery features for
detecting Deepfakes. Specifically, LFI captures local discriminative
information and incorporates these information into ViT via
Neighborhood-Preserving Cross Attention (NPCA). Simultaneously, GFA learns
adaptive knowledge in the self-attention layer, bridging the gap between the
two different domain. Furthermore, we design a novel Single Domain Pairwise
Learning (SDPL) to facilitate fine-grained information learning in FA-ViT. The
extensive experiments demonstrate that our FA-ViT achieves state-of-the-art
performance in cross-dataset evaluation and cross-manipulation scenarios, and
improves the robustness against unseen perturbations",,http://arxiv.org/abs/2309.11092,148053537,forgery-aware adaptive vision transformer for face forgery detection,2023-09-20T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"As a new paradigm in machine learning, self-supervised learning (SSL) is
capable of learning high-quality representations of complex data without
relying on labels. In addition to eliminating the need for labeled data,
research has found that SSL improves the adversarial robustness over supervised
learning since lacking labels makes it more challenging for adversaries to
manipulate model predictions. However, the extent to which this robustness
superiority generalizes to other types of attacks remains an open question.
  We explore this question in the context of backdoor attacks. Specifically, we
design and evaluate CTRL, an embarrassingly simple yet highly effective
self-supervised backdoor attack. By only polluting a tiny fraction of training
data (<= 1%) with indistinguishable poisoning samples, CTRL causes any
trigger-embedded input to be misclassified to the adversary's designated class
with a high probability (>= 99%) at inference time. Our findings suggest that
SSL and supervised learning are comparably vulnerable to backdoor attacks. More
importantly, through the lens of CTRL, we study the inherent vulnerability of
SSL to backdoor attacks. With both empirical and analytical evidence, we reveal
that the representation invariance property of SSL, which benefits adversarial
robustness, may also be the very reason making \ssl highly susceptible to
backdoor attacks. Our findings also imply that the existing defenses against
supervised backdoor attacks are not easily retrofitted to the unique
vulnerability of SSL.Comment: The 2023 International Conference on Computer Vision (ICCV '23",,http://arxiv.org/abs/2210.07346,145193670,an embarrassingly simple backdoor attack on self-supervised learning,2023-08-13T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Philosophers are not generally credited with being clairvoyant, and yet because they recognise, record and reflect on trends in their society, their observations can often appear prescient. In the field of the ethics of technology, there is, perhaps, no philosopher whose perspective on these issues is worth examining in detail more than that of Hannah Arendt, who can offer real perspective on the challenges we are facing with technologies in the twenty-first century. Arendt, a thinker of Jewish-German origin, student of Martin Heidegger and Karl Jaspers, encountered her life turning point when she was forced into becoming a refugee as the world was shaken by a force of unimaginable brutality that she was one of the first to name “totalitarianism” (Baerh, 2010). She was an independent thinker, separating herself from schools of thought or ideology. Investigating totalitarianism was her ruling passion, and as such her political thought often overshadows her major contribution to other branches of philosophy. Arendt is best known for her accounts of Adolf Eichmann and his trial, and the concept of “banality of evil”, though her perspective on politics was driven by a precise and original theory of action. While the latter is inextricably connected to her political perspective, it is also supported by a sharp ontological reflection of social structures and anthropological reflections",,https://core.ac.uk/download/482671444.pdf,126588948,are we in the digital dark times? how the philosophy of hannah arendt can illuminate some of the ethical dilemmas posed by modern digital technologies,2021-01-01T00:00:00,Dublin Institute of Technology,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper presents a perspective on some issues related to safety in the context of autonomous surgical robots. To meet the challenge of safety certification and bring about acceptance of the technology by the public, we propose principles for a design paradigm that goes in the direction of safety by construction: design with certification in mind, clearly distinguish the notion of safety from that of responsibility, view the human component as scaffolding in the progressive transfer of decision-making to the machine, preserve interpretability by renouncing black-box approaches, leverage interpretability to assign responsibility, and take corrective action only when the semantic of the human-machine interface is violated",10.1109/isr50024.2021.9419378,https://core.ac.uk/download/401893549.pdf,109876653,design for interpretability: meeting the certification challenge for surgical robots,2021-01-01T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Digital mobile devices and cultural heritage should be framed within the traditional knowledge management system as an informal learning tool in supporting cultural digital literacy to help build a comprehensive picture of a nation's identity. To this end, the paper develops a mobile cultural heritage application for the traditional knowledge management system of the Dayak tribe in Borneo. The method for its development refers to the 5R Architecture Framework. Information contents for the knowledge management system refer to the cultural heritage domain in UNESCO and the domain of the Indonesian Archipelago Culture Initiatives (IACI) organization. The result was the development of a prototype of a mobile cultural heritage app. It was presented to demonstrate how the use of a cultural framework can offer insight into how 5R adaptation features and IACI content are able to complement traditional cultural heritage pedagogies by providing mobile learning at the Right Time, in the Right Location, to the Right Users, with the right Device and the Right Content",10.6092/issn.1973-9494/10627,https://core.ac.uk/download/291663000.pdf,10426879,"mobile cultural heritage apps for the digital literacy of the dayak tribe, borneo, indonesia",2020-03-18T00:00:00,"Dipartimento dei Beni Culturali, Alma Mater Studiorum, Università di Bologna (Ravenna)",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In person re-identification (ReID) tasks, many works explore the learning of
part features to improve the performance over global image features. Existing
methods extract part features in an explicit manner, by either using a
hand-designed image division or keypoints obtained with external visual
systems. In this work, we propose to learn Discriminative implicit Parts (DiPs)
which are decoupled from explicit body parts. Therefore, DiPs can learn to
extract any discriminative features that can benefit in distinguishing
identities, which is beyond predefined body parts (such as accessories).
Moreover, we propose a novel implicit position to give a geometric
interpretation for each DiP. The implicit position can also serve as a learning
signal to encourage DiPs to be more position-equivariant with the identity in
the image. Lastly, a set of attributes and auxiliary losses are introduced to
further improve the learning of DiPs. Extensive experiments show that the
proposed method achieves state-of-the-art performance on multiple person ReID
benchmarks",,http://arxiv.org/abs/2212.13906,137399010,dip: learning discriminative implicit parts for person re-identification,2022-12-24T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Treball final de Grau en Disseny i Desenvolupament de Videojocs. Codi: VJ1241. Curs acadèmic: 2019/2020This document presents the project report of the Video Games Design and Development
Degree Final project by Jon Hodei Martínez Soto. It is a videogame titled Zombies Are
Dumb that consists on exploring how to include genetic algorithms applied to a group of
agents with the objective of being able to learn the player patterns and adapt to them.
This will create a greater challenge considering that the AI will change its behavior
depending on how the player plays.
Besides, the project also integrate swarm behaviors to create a sense of group and
coordination between the agents. These two main ideas will cause an unpredictable
playing environment for the player and, therefore, an unique and different experience
each time",,https://core.ac.uk/download/373288549.pdf,45999424,application of genetic algorithms and swarm behaviors for the development of npc's in video games,2020-06-10T01:00:00,'Universitat Jaume I',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"[Excerpt] One of the largest problems facing companies today is the shortage of available and qualified talent. This skills gap is largely going unaddressed with 60% of executives reporting that they cannot keep their workforce current on necessary skills. In the future, this problem is likely to intensify as millions of workers are forced to reskill or change jobs or industries due to technical innovation.
For these reasons, companies need to expand their understanding of qualified candidates both internally and externally. One way of doing this is to abandon the traditional signals such as experience and education in favor of a more direct approach",,https://core.ac.uk/download/288436265.pdf,78451809,what best practices are emerging to understand and measure skills in the talent pool?,2019-11-01T00:00:00,DigitalCommons@ILR,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This article explores the relatively underexplored potential for physicalisations to materialise qualitative data related to human experiences and knowledge domains. Our reading of ‘data’ in this context extends from imperceptible systems and infrastructures to mental models and the phenomenological dimensions of experiences themselves. Physical objects can be regarded as a form of knowledge with which to inquire about human life, bring about improved conditions, and imagine alternative realities. Objects are made of materials, which are manipulated materials into various configurations. The materials used in the process of externalisation have a profound influence on the resulting forms, and through them on how knowledge is constructed and internalised. We pay detailed attention to the characteristics of materials and how they are combined, in the context of interdisciplinary exchange. We are motivated by the need for a shared understanding of what work materials can do in the making of physicalisations. We suggest this work is useful in the analysis of physicalisations, specifically where they seek to articulate the phenomena of lived experience",10.1109/mcg.2020.3027591,https://ualresearchonline.arts.ac.uk/id/eprint/15633/1/ThinkingWithThings_IEEECGA%20%28F%29.pdf,18757767,"thinking with things: landscapes, connections and performances as modes of building shared understanding",2020-09-29T01:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"CHI 2019: The ACM CHI Conference on Human Factors in Computing Systems - Weaving the Threads of CHI, Glasgow, United Kingdom, 4-9 May 2019The use of speech as an interaction modality has grown considerably through the integration of Intelligent Personal Assistants (IPAs- e.g. Siri, Google Assistant) into smartphones and voice based devices (e.g. Amazon Echo). However, there remain significant gaps in using theoretical frameworks to understand user behaviours and choices and how they may applied to specific speech interface interactions. This part-day multidisciplinary workshop aims to critically map out and evaluate the- oretical frameworks and methodological approaches across a number of disciplines and establish directions for new paradigms in understanding speech interface user behaviour. In doing so, we will bring together participants from HCI and other speech related domains to establish a cohesive, diverse and collaborative community of researchers from academia and industry with interest in exploring theoretical and methodological issues in the field.Irish Research Counci",10.1145/3290607.3299009,https://core.ac.uk/download/327988994.pdf,8596692,mapping theoretical and methodological perspectives for understanding speech interface interactions,2019-01-01T00:00:00,'Association for Computing Machinery (ACM)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The project aims to design and implement a software framework for controlling and monitoring drones through a web application, built using the Vue.js framework. With this, I offer a contribution to the Drone Engineering Ecosystem (DEE) , an ecosystem dedicated to the control and monitoring of drones through different technologies in which students of the EETAC, a university that belongs to the UPC, can contribute and enhance the ecosystem while doing their bachelor or masters degree final project. Currently, there is a desktop application in the ecosystem that does the tasks of drone monitoring, control and mission planning. However, as the technology evolves, there is a need for web app as the advantages of a web platform for drone control and monitoring are numerous and compelling. The main benefit is the enhanced accessibility as the only needs are Internet connection and a browser, that no matter whether it is in the laptop, tablet or on a smartphone. As technology continues to evolve, web applications undoubtedly stand at the forefront of innovation in all domains. So, the focus of this project is to provide a web platform for drone controlling and monitoring. The culmination emerges as a remarkably professional and contemporary web application that empowers the user with countless levels of control over drone operations. Notably, users have the freedom to decide the drone's movements and actions, ensuring a seamless and intuitive interface that facilitates effortless navigation. The capabilities extend beyond mere control, as users can devise a diverse range of missions. One standout attribute is the ability to create geofences, a vital tool for ensuring safe and responsible drone operations. Moreover, the web app enables users to fine tune drone's flying parameters. This level of customization guarantees that the drone's performance aligns precisely with the intended goals. The outcome of the efforts yield a high level of satisfaction as the web platform has been successfully built, enhancing the basic functionalities of the desktop application while introducing additional features. However, the broader implication is that the Drone Engineering Ecosystem now boasts a new platform for drone control and monitoring. This achievement marks a significant stride forward for the DEE.Objectius de Desenvolupament Sostenible::9 - Indústria, Innovació i Infraestructur",,https://core.ac.uk/download/590921025.pdf,153731476,drone control and monitoring by means of a web application,2023-09-13T01:00:00,Universitat Politècnica de Catalunya,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"As ultra-realistic face forgery techniques emerge, deepfake detection has
attracted increasing attention due to security concerns. Many detectors cannot
achieve accurate results when detecting unseen manipulations despite excellent
performance on known forgeries. In this paper, we are motivated by the
observation that the discrepancies between real and fake videos are extremely
subtle and localized, and inconsistencies or irregularities can exist in some
critical facial regions across various information domains. To this end, we
propose a novel pipeline, Cross-Domain Local Forensics (XDLF), for more general
deepfake video detection. In the proposed pipeline, a specialized framework is
presented to simultaneously exploit local forgery patterns from space,
frequency, and time domains, thus learning cross-domain features to detect
forgeries. Moreover, the framework leverages four high-level forgery-sensitive
local regions of a human face to guide the model to enhance subtle artifacts
and localize potential anomalies. Extensive experiments on several benchmark
datasets demonstrate the impressive performance of our method, and we achieve
superiority over several state-of-the-art methods on cross-dataset
generalization. We also examined the factors that contribute to its performance
through ablations, which suggests that exploiting cross-domain local
characteristics is a noteworthy direction for developing more general deepfake
detectors",,http://arxiv.org/abs/2211.03346,134910303,cross-domain local characteristic enhanced deepfake video detection,2022-11-07T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We study whether language models can evaluate the validity of their own
claims and predict which questions they will be able to answer correctly. We
first show that larger models are well-calibrated on diverse multiple choice
and true/false questions when they are provided in the right format. Thus we
can approach self-evaluation on open-ended sampling tasks by asking models to
first propose answers, and then to evaluate the probability ""P(True)"" that
their answers are correct. We find encouraging performance, calibration, and
scaling for P(True) on a diverse array of tasks. Performance at self-evaluation
further improves when we allow models to consider many of their own samples
before predicting the validity of one specific possibility. Next, we
investigate whether models can be trained to predict ""P(IK)"", the probability
that ""I know"" the answer to a question, without reference to any particular
proposed answer. Models perform well at predicting P(IK) and partially
generalize across tasks, though they struggle with calibration of P(IK) on new
tasks. The predicted P(IK) probabilities also increase appropriately in the
presence of relevant source materials in the context, and in the presence of
hints towards the solution of mathematical word problems. We hope these
observations lay the groundwork for training more honest models, and for
investigating how honesty generalizes to cases where models are trained on
objectives other than the imitation of human writing.Comment: 23+17 pages; refs added, typos fixe",,http://arxiv.org/abs/2207.05221,124586646,language models (mostly) know what they know,2022-07-16T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In over 30 years, the forms of public legal education activities have become increasingly rich. However, with the technology refresh, the traditional public legal education model characterized by one-way communication has gradually become out of touch, which can not adapt to the return of the people’s subjectivity and meet the personalized needs of different groups of people. As an important part of advancing the Rule of Law in China, public legal education should be timely innovated with the help of new technology. By combining the knowledge graph technology in the era of artificial intelligence with the work of public legal education, this paper studies how to use the knowledge graph technology to build public legal education network platform, introduce customized legal education content, and establish a sound mechanism for intelligent public legal education work, so that users can complete the important transformation from the object of legal education to the subject of law learning. This will enrich the theoretical research results of public legal education",10.22158/ape.v6n2p23,https://core.ac.uk/download/567826224.pdf,148239476,dilemma and breakthrough: innovation on models of public legal education in china based on knowledge graph,2023-04-03T01:00:00,"'Scholink Co, Ltd.'",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In this paper a Gray Wolf Optimization (GWO) algorithm is presented to solve the Competitive Traveling Salesman Problem (CTSP). In CTSP, there are numbers of non-cooperative salesmen their goal is visiting a larger possible number of cities with lowest cost and most gained benefit. Each salesman will get a benefit when he visits unvisited city before all other salesmen. Two approaches have been used in this paper, the first one called static approach, it is mean evenly divides the cities among salesmen. The second approach is called parallel at which all cities are available to all salesmen and each salesman tries to visit as much as possible of the unvisited cities. The algorithms are executed for 1000 times and the results prove that the GWO is very efficient giving an indication of the superiority of GWO in solving CTSP",10.21533/pen.v8i3.1462,https://core.ac.uk/download/327263601.pdf,86839611,solving competitive traveling salesman problem using gray wolf optimization algorithm,2020-07-16T01:00:00,'International University of Sarajevo',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"With the application of big data in the information age, the popularization of artificial intelligence and the coming of the network society, the traditional university education model has been severely impacted and challenged. It is an inevitable trend for higher education to adapt to the new social development reality and make corresponding adjustment and reform. Traditional university education pays attention to the imparts of theoretical knowledge and the cultivation of practical ability, but in the information age, students can get rich information and knowledge through the Internet, thus weakening the monopoly of traditional education. In addition, the popularity of artificial intelligence technology also means that some traditional teaching activities can be replaced by automation and intelligence, and the value chain of traditional education has been reshaped. The rise of the network society has also posed new challenges to the traditional university education model. The network society is characterized by a high degree of information sharing and exchange, and students can access various online educational resources and learning opportunities through the network platform. Therefore, traditional university education needs to find a new positioning and role, pay more attention to cultivating innovative ability, practical ability and teamwork ability, and provide students with more competitive comprehensive ability. Faced with these challenges, higher education must make corresponding adjustments and changes. The article carries out relevant research and puts forward specific countermeasures, mainly to update the educational concept, change the educational mode, and focus on cultivating students’ innovative thinking and problem-solving ability. It is necessary to develop diversified educational resources, meet social needs, strengthen cooperation with industries and enterprises, and provide professional education that matches market demand. At the same time, it is also necessary to actively develop online and distance education, make full use of online platforms and technological means, and provide flexible and diverse learning opportunities",10.22158/wjeh.v5n4p196,https://core.ac.uk/download/599202031.pdf,153566557,bridging theory and practice in private higher education: pedagogical innovations for the digital age,2023-11-28T00:00:00,"Scholink Co., LTD",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"open access journalThe Internet of Things (IoT) can includes many resource-constrained devices, with most usually needing to securely communicate with their network managers, which are more resource-rich devices in the IoT network. We propose a resource-efficient security scheme that includes authentication of devices with their network managers, authentication between devices on different networks, and an attack-resilient key establishment procedure. Using automated validation with internet security protocols and applications tool-set, we analyse several attack scenarios to determine the security soundness of the proposed solution, and then we evaluate its performance analytically and experimentally. The performance analysis shows that the proposed solution occupies little memory and consumes low energy during the authentication and key generation processes respectively. Moreover, it protects the network from well-known attacks (man-in-the-middle attacks, replay attacks, impersonation attacks, key compromission attacks and denial of service attacks)",10.1109/access.2019.2955604,https://core.ac.uk/download/287585929.pdf,18504484,resource efficient authentication and session key establishment procedure for low-resource iot devices,2019-11-14T00:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',"[{'title': 'IEEE Access', 'identifiers': ['issn:2169-3536', '2169-3536']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We propose to perform video question answering (VideoQA) in a Contrastive
manner via a Video Graph Transformer model (CoVGT). CoVGT's uniqueness and
superiority are three-fold: 1) It proposes a dynamic graph transformer module
which encodes video by explicitly capturing the visual objects, their relations
and dynamics, for complex spatio-temporal reasoning. 2) It designs separate
video and text transformers for contrastive learning between the video and text
to perform QA, instead of multi-modal transformer for answer classification.
Fine-grained video-text communication is done by additional cross-modal
interaction modules. 3) It is optimized by the joint fully- and self-supervised
contrastive objectives between the correct and incorrect answers, as well as
the relevant and irrelevant questions respectively. With superior video
encoding and QA solution, we show that CoVGT can achieve much better
performances than previous arts on video reasoning tasks. Its performances even
surpass those models that are pretrained with millions of external data. We
further show that CoVGT can also benefit from cross-modal pretraining, yet with
orders of magnitude smaller data. The results demonstrate the effectiveness and
superiority of CoVGT, and additionally reveal its potential for more
data-efficient pretraining. We hope our success can advance VideoQA beyond
coarse recognition/description towards fine-grained relation reasoning of video
contents. Our code is available at https://github.com/doc-doc/CoVGT.Comment: Accepted by IEEE T-PAMI'2",,http://arxiv.org/abs/2302.13668,144518749,contrastive video question answering via video graph transformer,2023-07-11T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Inspired by the relation between deep neural network (DNN) and partial
differential equations (PDEs), we study the general form of the PDE models of
deep neural networks. To achieve this goal, we formulate DNN as an evolution
operator from a simple base model. Based on several reasonable assumptions, we
prove that the evolution operator is actually determined by
convection-diffusion equation. This convection-diffusion equation model gives
mathematical explanation for several effective networks. Moreover, we show that
the convection-diffusion model improves the robustness and reduces the
Rademacher complexity. Based on the convection-diffusion equation, we design a
new training method for ResNets. Experiments validate the performance of the
proposed method",,http://arxiv.org/abs/2307.12333,144926572,an axiomatized pde model of deep neural networks,2023-07-23T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Cardiovascular diseases are the leading cause of death worldwide. Early diagnosis of heart disease can reduce this large number of deaths so that treatment can be carried out. Many decision-making systems have been developed, but they are too complex for medical professionals. To target these objectives, we develop an explainable neutrosophic clinical decision-making system for the timely diagnose of cardiovascular disease risk. We make our system transparent and easy to understand with the help of explainable artificial intelligence techniques so that medical professionals can easily adopt this system. Our system is taking thirtyfive symptoms as input parameters, which are, gender, age, genetic disposition, smoking, blood pressure, cholesterol, diabetes, body mass index, depression, unhealthy diet, metabolic disorder, physical inactivity, pre-eclampsia, rheumatoid arthritis, coffee consumption, pregnancy, rubella, drugs, tobacco, alcohol, heart defect, previous surgery/injury, thyroid, sleep apnea, atrial fibrillation, heart history, infection, homocysteine level, pericardial cysts, marfan syndrome, syphilis, inflammation, clots, cancer, and electrolyte imbalance and finds out the risk of coronary artery disease, cardiomyopathy, congenital heart disease, heart attack, heart arrhythmia, peripheral artery disease, aortic disease, pericardial disease, deep vein thrombosis, heart valve disease, and heart failure. There are five main modules of the system, which are neutrosophication, knowledge base, inference engine, de-neutrosophication, and explainability. To demonstrate the complete working of our system, we design an algorithm and calculates its time complexity. We also present a new de-neutrosophication formula, and give comparison of our the results with existing methods",,https://core.ac.uk/download/368628791.pdf,103767855,a neutrosophic clinical decision-making system for cardiovascular diseases risk analysis,2020-08-01T08:00:00,UNM Digital Repository,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Experts advising decision-makers are likely to display expertise which varies
as a function of the problem instance. In practice, this may lead to
sub-optimal or discriminatory decisions against minority cases. In this work we
model such changes in depth and breadth of knowledge as a partitioning of the
problem space into regions of differing expertise. We provide here new
algorithms that explicitly consider and adapt to the relationship between
problem instances and experts' knowledge. We first propose and highlight the
drawbacks of a naive approach based on nearest neighbor queries. To address
these drawbacks we then introduce a novel algorithm - expertise trees - that
constructs decision trees enabling the learner to select appropriate models. We
provide theoretical insights and empirically validate the improved performance
of our novel approach on a range of problems for which existing methods proved
to be inadequate.Comment: Proceedings of the 40th International Conference on Machine Learning
  (2023",10.5555/3618408.3618413,http://arxiv.org/abs/2305.01063,152873549,"expertise trees resolve knowledge limitations in collective
  decision-making",2023-05-04T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Neural algorithmic reasoners are parallel processors. Teaching them
sequential algorithms contradicts this nature, rendering a significant share of
their computations redundant. Parallel algorithms however may exploit their
full computational power, therefore requiring fewer layers to be executed. This
drastically reduces training times, as we observe when comparing parallel
implementations of searching, sorting and finding strongly connected components
to their sequential counterparts on the CLRS framework. Additionally, parallel
versions achieve strongly superior predictive performance in most cases.Comment: 8 pages, 5 figures, To appear at the KLR Workshop at ICML 202",,http://arxiv.org/abs/2307.04049,144553103,parallel algorithms align with neural execution,2023-07-08T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
n.a,10.20853/33-6-3777,https://core.ac.uk/download/268425295.pdf,74927181,the fourth industrial revolution reconsidered: on advancing cosmopolitan education,2019-01-01T00:00:00,'Stellenbosch University',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In modern days, cyber networks need continuous monitoring to keep the network secure and available to legitimate users. Cyber attackers use reconnaissance mission to collect critical network information and using that information, they make an advanced level cyber-attack plan. To thwart the reconnaissance mission and counterattack plan, the cyber defender needs to come up with a state-of-the-art cyber defense strategy. In this paper, we model a dynamic deception system (DDS) which will not only thwart reconnaissance mission but also steer the attacker towards fake network to achieve a fake goal state. In our model, we also capture the attacker’s capability using a belief matrix which is a joint probability distribution over the security states and attacker types. Experiments conducted on the prototype implementation of our DDS confirm that the defender can make the decision whether to spend more resources or save resources based on attacker types and thwart reconnaissance mission",10.4108/eai.13-7-2018.162808,https://core.ac.uk/download/571401514.pdf,145749025,attacker capability based dynamic deception model for large-scale networks,2019-01-01T08:00:00,'European Alliance for Innovation n.o.',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"There is growing interest in the language developed by agents interacting in
emergent-communication settings. Earlier studies have focused on the agents'
symbol usage, rather than on their representation of visual input. In this
paper, we consider the referential games of Lazaridou et al. (2017) and
investigate the representations the agents develop during their evolving
interaction. We find that the agents establish successful communication by
inducing visual representations that almost perfectly align with each other,
but, surprisingly, do not capture the conceptual properties of the objects
depicted in the input images. We conclude that, if we are interested in
developing language-like communication systems, we must pay more attention to
the visual semantics agents associate to the symbols they use.Comment: 2018 Conference on Empirical Methods in Natural Language Processin",10.18653/v1/d18-1119,http://arxiv.org/abs/1808.10696,52342919,"how agents see things: on visual representations in an emergent language
  game",2018-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Challenges associated with leadership practices are rapidly increasing, thereby assigning more qualities to leaders. One of the recent theoretical issues that interest many scholars is ethical leadership development, using industrial revolution 4.0. This method does not only follow the traditional leadership styles, rather it is associated with universal qualities such as respect, service, fairness, honesty, and responsibility. For communities, increasing assertions is one of the essential foundations used to help leaders influence their subordinates' actions. This means that ethical leadership is the motto of the spirit of service leadership, especially for Vietnam leaders, a country with a strong transformation from a planned economy to a socialist-oriented market. Therefore, leadership values need to be adjusted, supplemented, and developed to keep up with the Industrial Revolution's requirements 4.0",10.24036/00167za0002,https://core.ac.uk/download/327261841.pdf,86838960,requirements for developing ethical leaderships in vietnam,2020-05-28T01:00:00,'Universitas Negeri Padang (UNP)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The main aim of a foreign language teacher is to form a student’s communicative competence, which is a complex of other competencies such as linguistic, discursive and linguocultural.&nbsp; For successful psychological and social adaptation in a new cultural and linguistic space for a foreign student is extremely important at the initial level of education begin to master the basic linguistic and cultural concepts that reflect the culture of the speakers of the studied language and leads to the adoption of a different worldview.&nbsp; Thus, for successful communication, you need not only use phonetic, grammatical, syntactic and pragmatic rules of the language, but also you should have a clear idea of the conceptual picture of the world of the people, who speaks this language.&nbsp; It follows that the study of any foreign language should occur inextricably linked with the knowledge of culture, values and understanding of the native people of this language. The objective of the work is to formulate the key linguocultural principles of teaching Russian as a foreign language. To achieve this objective, the works of leading researchers in the field of linguistics, didactics, methods of teaching Russian as a foreign language have been analyzed. The research object is an inextricable link between learning a foreign language and the culture of its speakers. The research result is the proof of the need to learn a foreign language as being inextricably linked with knowledge of the culture, values and world outlook of the people - speakers of this language, as well as a list of basic linguocultural principles, on which teaching a foreign language, including Russian as a foreign language, should be based",10.34069/ai/2020.28.04.47,https://core.ac.uk/download/pdf/328005712.pdf,87084757,the link between language and culture on the lessons of russian as a foreign language,2020-04-21T01:00:00,'Amazonia Investiga',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The concept of a smart city imposes a unique set of requirements for the underlying ICT technologies for a successful implementation of services and applications for citizens. At the core of these requirements lies the complex data platform architecture which must be carefully designed. The selection of a particular data platform architecture incurs significant technical debt to be serviced in the future, as well as the integration challenges involving hundreds of stakeholders. Since services developed within the smart city ecosystem have significant impact on human well-being and quality of life, the process of designing data platform must be robust. Data mesh paradigm is a new approach for building complex information systems. It is particularly suited as the blueprint for designing data platforms for smart cities. In this paper we present the overview of the data mesh concept. Building upon 25 years of experience of developing applications and providing data infrastructure for the city of Poznan, we identify key challenges when using the data mesh approach to build data platform tailored to a smart city. We provide guidelines for successful introduction of the data mesh at sociological, technological, and infrastructure level. We also point to the usability of the data mesh paradigm in the context of digital twins, a promising vision of future services for smart cities",,https://core.ac.uk/download/552658167.pdf,137208450,introducing data mesh paradigm for smart city platforms design,2023-01-03T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"ABSTRAK
Perkembangan ilmu pengetahuan dan teknologi yang sangat pesat di era revolusi industri 4.0, berdampak luar biasa terhadap kehidupan manusia, salah satunya pada bidang Pendidikan. Teknologi digital berimbas pada system pendidikan di Indonesia, khususnya Bahasa Inggris, mengingatkemampuan berkomunikasi bahasa asing menjadi bagian tak terpisahkan dari pemanfaatan teknologi. Dalam hal ini, guru Bahasa Inggris memiliki peran yang dapat menentukan keberhasilan pendidikan bahasa. Peran-peran tersebut dapat memperlengkapi siswa-siswi dengan literasi baru meliputi literasi data, teknologi, dan sumber daya manusia, keterampilan, dan karakter bangsa sehingga mereka bias menjadi agen perubahan yang bijaksana dalam menyikapi dan menggunakan kecanggihan teknologi, dengan tetap memperhatikan nilai kemanusian. Meskipun memberikan banyak manfaat bagi kehidupan dan menyediakan kemudahan bagi manusia, revolusi industry ini memberikan tantangan yang cukup kompleks pada para praktisi pendidikan, khususnya para guru Bahasa Inggris. Selainitu, revolusi ini juga membawa implikasi pada dunia pendidikan, terutamanya pada pembelajaran Bahasa.
Kata kunci: guru Bahasa Inggris, RevolusiIndustri 4.0, peran
ABSTRACT
The rapid development of science and technology in the era of industrial revolution 4.0, has tremendous impacts on human life, one of them in the field of Education. Digital technology causes a shift on the education system in Indonesia, especially English education, since the ability to communicate in foreign languages is an integral part of the technology utilization. In this case, English teachers have particular roleswhich can determine the success of the language education. These roles can equip students with new literacies including data literacy, technology literacy, and human literacy, skills, and national characters,which make them become wise agents of change in addressing and using technological sophistication, without neglecting human values. Although, it provides many benefits and conveniencesfor human beings, this industrial revolution provides quite complex challenges for education practitioners, especially English teachers. In addition, this revolution also bears implications toward the world of education, especially in language learning.
Key words: English teacher, Industrial Revolution 4.0, role",10.51212/jdp.v11i3.896,https://core.ac.uk/download/236428596.pdf,71482277,"being an englishteacher in industrial revolution 4.0: an overview about roles, challenges, and implications",2019-01-25T00:00:00,"Jurnal DInamika Pendidikan, FKIP Universitas Kristen Indonesia",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The purpose of the electronic instructional materials and course requirements by the discipline «Computer science» (EIMCR) is to develop theoretical systemic and practical knowledge in different fields of Computer science. Features of structuring and submission of educational material: EIMCR includes the following sections: theoretical, practical, knowledge control, auxiliary. The theoretical section presents lecture material in accordance with the main sections and topics of the syllabus. The practical section of the EIMCR contains materials for conducting practical classes aimed to develop modern computational thinking, basic skills in computing and making decisions in the field of the fundamentals of computer theory and many computer science fields. The knowledge control section of the EIMCR contains: guidelines for the implementation of the control work aimed at developing the skills of independent work on the course under study, developing the skills of selecting, analyzing and writing out the necessary material, as well as the correct execution of the tasks; list of questions for the credit by the discipline. The auxiliary section of the EIMCR contains the following elements of the syllabus: explanatory note; thematic lectures plan; tables of distribution of classroom hours by topics and informational and methodological part. EIMCR contains active links to quickly find the necessary material",,https://core.ac.uk/download/328378918.pdf,87243657,"electronic instructional materials and course requirements ""computer science"" for specialty: 1-53 01 01 «automation of technological processes and production»",2020-01-01T00:00:00,BNTU,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Recent studies have revealed some issues of Multi-Head Attention (MHA), e.g.,
redundancy and over-parameterization. Specifically, the heads of MHA were
originally designed to attend to information from different representation
subspaces, whereas prior studies found that some attention heads likely learn
similar features and can be pruned without harming performance. Inspired by the
minimum-redundancy feature selection, we assume that focusing on the most
representative and distinctive features with minimum resources can mitigate the
above issues and lead to more effective and efficient MHAs. In particular, we
propose Grouped Head Attention, trained with a self-supervised group constraint
that group attention heads, where each group focuses on an essential but
distinctive feature subset. We additionally propose a Voting-to-Stay procedure
to remove redundant heads, thus achieving a transformer with lighter weights.
Moreover, our method achieves significant performance gains on three
well-established tasks while considerably compressing parameters.Comment: In Proceedings of the Annual Meeting of the Association for
  Computational Linguistics (ACL 2023",,http://arxiv.org/abs/2305.14380,152048351,finding the pillars of strength for multi-head attention,2023-10-15T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"A statistical hypothesis test determines whether a hypothesis should be
rejected based on samples from populations. In particular, randomized
controlled experiments (or A/B testing) that compare population means using,
e.g., t-tests, have been widely deployed in technology companies to aid in
making data-driven decisions. Samples used in these tests are collected from
users and may contain sensitive information. Both the data collection and the
testing process may compromise individuals' privacy. In this paper, we study
how to conduct hypothesis tests to compare population means while preserving
privacy. We use the notation of local differential privacy (LDP), which has
recently emerged as the main tool to ensure each individual's privacy without
the need of a trusted data collector. We propose LDP tests that inject noise
into every user's data in the samples before collecting them (so users do not
need to trust the data collector), and draw conclusions with bounded type-I
(significance level) and type-II errors (1 - power). Our approaches can be
extended to the scenario where some users require LDP while some are willing to
provide exact data. We report experimental results on real-world datasets to
verify the effectiveness of our approaches.Comment: Full version of an AAAI 2018 conference pape",10.1609/aaai.v32i1.11301,http://arxiv.org/abs/1803.09027,50748175,"comparing population means under local differential privacy: with
  significance and power",2018-03-23T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The Winograd Schema (WS) challenge, proposed as an alternative to the Turing Test, has become the new standard for evaluating progress in natural language understanding (NLU). In this paper we will not however be concerned with how this challenge might be addressed. Instead, our aim here is threefold: (i) we will first formally „situate‟ the WS challenge in the data-information-knowledge continuum, suggesting where in that continuum a good WS resides; (ii) we will show that a WS is just a special case of a more general phenomenon in language understanding, namely the missing text phenomenon (henceforth, MTP) - in particular, we will argue that what we usually call thinking in the process of language understanding involves discovering a significant amount of „missing text‟ - text that is not explicitly stated, but is often implicitly assumed as shared background knowledge; and (iii) we conclude with a brief discussion on why MTP is inconsistent with the data-driven and machine learning approach to language understanding",,https://core.ac.uk/download/295732485.pdf,82144428,on the winograd schema: situating language understanding in the data-information-knowledge continuum,2019-05-01T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The papers in this special section focus on designing technologies to support professional and workplace learning in situated practices. In an era of global, organizational, and technological change, all of which are transforming the world of work, professional and workplace learning are critical for employability and organizational competitiveness. A range of fundamental transformations is changing how people work. Digital technologies are replacing human labor and, at the same time, are accelerating the expansion of job roles and work practices. Work is becoming increasingly specialized, which means that professionals in collaborative and networked ways across discipline and organization boundaries. In parallel, labor is increasingly decentralized, making decisionmaking more distributed and raising the need for remote communication and collaboration. Subsequently, work is becoming more independent from time and place, as people connect, collaborate, and work via digital technologies. These changes come with a need for substantial and continuous workplace learning, and with the need for changes in how workplace learning happens. Of course, digital technologies are already used to provide learning and training in workplaces. However, most of these learning technologies have been developed for formal education (e.g., K- 12 and higher education) rather than in workplace contexts. There is a need to understand and evidence workplace learning needs and to further develop technologies that can support and scale workplace learning",,https://core.ac.uk/download/564422597.pdf,154078869,designing technologies to support professional and workplace learning for situated practice,2022-10-23T01:00:00,'Institute of Electrical and Electronics Engineers (IEEE)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This chapter explores how the Italian engineer and artist Leonardo da Vinci conceptualised forms of violence in nature, to nature, or by nature. In using the term ‘natural violence’, this chapter aims to capture Da Vinci’s broad-ranging consideration of such violence related to the natural world upon which he reflected across his work and to which he gave varied and ongoing responses over the course of his life. It argues that his perception of temporality, emotion, and gender were important aspects that helped Da Vinci make sense of natural violence. In doing so, the chapter suggests that while Da Vinci may have been radical in some aspects of thinking, in others he was representative of his era, and that investigating his conceptualisation of natural violence brings these distinctions into sharper focus",10.2307/jj.3610951.5,https://core.ac.uk/download/590735151.pdf,149752015,"temporality, emotion, and gender in leonardo da vinci's conceptualisation of natural violence",2023-01-01T00:00:00,Amsterdam University Press,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This article discusses incorporating live coding as part of a new Foundation pathway for music production at a UK university that started in September 2022. The inclusion of live coding, using the application Sonic Pi, is situated alongside music production using a DAW, initially through the process of drum programming. The role of Sonic Pi is also to provide a means for producers to take their productions into the live performance space. This article’s contribution is in three areas. The first is to provide a short history of live coding at the current institution coupled with a longer account of my fragmented journey into live coding to provide some context. For the second discussion area, information about the foundation, its structure and how it fits into the overall degree programme is discussed. This section also includes some short code examples to illustrate the approach and links to video materials. For the last discussion area I outline an area of crossover between production and live coding which opens up a number of critical discussion points. This concerns the use of a breakbeat, what this means when used in productions, in live coding and when shipped with paid for or free software",10.1017/s1355771823000419,https://core.ac.uk/download/580092131.pdf,146305265,live coding and music production as hybrid practice,2023-01-01T00:00:00,Cambridge University Press,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Facial recognition technology (“FRT”)—once a futuristic fantasy—is more pervasive than ever and shows no signs of becoming less prevalent. While this technology has its upsides, it elicits the notion of an omnipresent being that is watching and tracking us all the time. FRTs encroach on the First Amendment right to anonymous speech by revealing the identity of speakers and chilling speech. Yet, First Amendment doctrine does not provide much solace, since the right to anonymous speech regulates the government’s ability to force disclosure of a speaker’s identity rather than preventing it from collecting publicly available facial data. The right to anonymous speech also clashes with private actors’ right to collect and disseminate information, which provides an avenue for private actors to destroy anonymity. And private actors’ First Amendment rights allow them to collect and develop FRT they can use in private spaces.
In addition to inadequate speech rights, litigating FRTs’ impacts on the right to anonymous speech is likely to face significant barriers in court. Specifically, plaintiffs will find it hard to show they have been affected by these systems and that their speech has been chilled, giving them no standing. Further, courts’ deference to the legislative and executive branches on issues of crime control and national security might justify an encroachment on the right to anonymous speech. Finally, private parties’ rights to collect and disseminate information pose serious barriers to challenge privately-operated FRTs and provides the government an additional avenue to gather facial data and track individuals. Prophylactic legislation is a stronger solution to remedy the issues caused by FRT. Such legislation can regulate the government’s use of FRT, private actors’ implementations of FRT, and the very creation of FRTs themselves",,https://core.ac.uk/download/519794768.pdf,83324145,the public square has eyes (or cameras): anonymous speech under the first and fourth amendments in the age of facial recognition,2022-01-01T08:00:00,FLASH: The Fordham Law Archive of Scholarship and History,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"With the rising of technology, occupations will have to face growth, reduction or redesign: therefore, changes in organizations, human capital and processes involving people will occur. We focus on the main Trade Union operating in Italy. At first, we present an analysis of this organization. Then, we describe a training course addressed to a sample of Trade Union Executive Board. Finally, we provide suggestions about some possible development scenarios. As a result, we may underline three critical issues: a) People minimize the potential effects of automation on jobs and on their own career and they are not prepared to this change; 2) The organization is losing its bargaining power and risks to disappear, leaving a gap in the intermediary function between the employer and the employees; 3) The Executive Board fails in making forecasts and strategic planning, to effectively negotiate with the employer. The main output of the course is a Project Work which contains a description of a strategic intervention which could be implemented in the organization to effectively deal with the future changes",10.20319/pijss.2018.42.14751496,https://core.ac.uk/download/497888292.pdf,13973615,what is the fate of trade unions in italy? results of a training course addressed to the executive board,2018-09-20T01:00:00,'Global Research & Development Services',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
The current education system was designed in the 19th century to support the first industrial revolution. Does it still meet the needs of the 21st century,10.5281/zenodo.4719668,https://core.ac.uk/download/421123226.pdf,134981174,rethinking education,2021-01-01T00:00:00,HiPEAC,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Generating natural language descriptions of images is an important capability
for a robot or other visual-intelligence driven AI agent that may need to
communicate with human users about what it is seeing. Such image captioning
methods are typically trained by maximising the likelihood of ground-truth
annotated caption given the image. While simple and easy to implement, this
approach does not directly maximise the language quality metrics we care about
such as CIDEr. In this paper we investigate training image captioning methods
based on actor-critic reinforcement learning in order to directly optimise
non-differentiable quality metrics of interest. By formulating a per-token
advantage and value computation strategy in this novel reinforcement learning
based captioning model, we show that it is possible to achieve the state of the
art performance on the widely used MSCOCO benchmark",,https://core.ac.uk/download/159079457.pdf,8944065,actor-critic sequence training for image captioning.,2017-11-27T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"With reference to Smart Manufacturing and Industry 4.0 in general, a Digital Thread connects the data and processes for smarter products, smarter production, and smarter integrated ecosystems. While the tangible goods (products and production lines) are understood as needing a Digital Twin as an executable model, i.e. an in-silico entity on which to virtually explore design, production, quality, and lifetime maintenance, the immaterial goods like software and analytics artefacts are not yet treated on par. For the new Digital Thread paradigm to enter the mainstream, models need to be coupled with AI, ML and Data Analytics capabilities, to provide an integrated platform for automatic transformations, generations, and analyses that take advantage of the formalized knowledge about the immaterial and material entities. The formalized knowledge needs to include a variety of models together with Domain Specific Languages that use semantic types at their core. The objective of this overall work is to develop a service-oriented Domain Specific Language (DSL) platform for knowledge management (KM-DSL) especially concerning sustainability and risk management, and then apply it in the context of the Digital Thread platform and demonstrators currently under development in the research group. The KM-DSL is the basis for the design of the smart and aligned processes and workflows that will describe and characterize the collaboration of humans and machines in the future advanced production environments. This paper will examine two strands of that work looking at business logic and understanding along with knowledge harvesting that concentrate on two case studies that will underpin future research to create the aforementioned DSL platform for knowledge management",10.14279/tuj.eceasst.81.1194,https://core.ac.uk/download/544236846.pdf,132938498,the qualitative background of why a dsl knowledge based platform is needed in the context of sustainability,2022-11-22T00:00:00,European Association of Software Science and Technology,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"With their recent development, large language models (LLMs) have been found
to exhibit a certain level of Theory of Mind (ToM), a complex cognitive
capacity that is related to our conscious mind and that allows us to infer
another's beliefs and perspective. While human ToM capabilities are believed to
derive from the neural activity of a broadly interconnected brain network,
including that of dorsal medial prefrontal cortex (dmPFC) neurons, the precise
processes underlying LLM's capacity for ToM or their similarities with that of
humans remains largely unknown. In this study, we drew inspiration from the
dmPFC neurons subserving human ToM and employed a similar methodology to
examine whether LLMs exhibit comparable characteristics. Surprisingly, our
analysis revealed a striking resemblance between the two, as hidden embeddings
(artificial neurons) within LLMs started to exhibit significant responsiveness
to either true- or false-belief trials, suggesting their ability to represent
another's perspective. These artificial embedding responses were closely
correlated with the LLMs' performance during the ToM tasks, a property that was
dependent on the size of the models. Further, the other's beliefs could be
accurately decoded using the entire embeddings, indicating the presence of the
embeddings' ToM capability at the population level. Together, our findings
revealed an emergent property of LLMs' embeddings that modified their
activities in response to ToM features, offering initial evidence of a parallel
between the artificial model and neurons in the human brain",,http://arxiv.org/abs/2309.01660,146405907,"unveiling theory of mind in large language models: a parallel to single
  neurons in the human brain",2023-09-04T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Technology encourages collaboration in creative ways in the classroom. Specifically, social robots may offer new opportunities for greater innovation in teaching. In this study, we combined the established literature on co-teaching teams with the developing field of machine actors used in education to investigate the impressions students had of different team configurations that included both a human and a robot. Participants saw one of three teams composed of a human and a social robot with different responsibilities present a short, prerecorded lecture (i.e., human as lead teacher-robot as teaching assistant, robot as lead teacher-human as teaching assistant, human and robot as co-teachers). Overall, students rated the human-led team as more appealing and having more credibility than the robot-led team. The data suggest that participants would be more likely to take a course led by a human instructor than a social robot. Previous studies have investigated machine actors in the classroom, but the current findings are unique in that they compare the individual roles and power structures of human-robot teams leading a course",10.31446/jcp.2021.1.12,https://core.ac.uk/download/481662531.pdf,77225526,human-robot teaming configurations: a study of interpersonal communication perceptions and affective learning in higher education,2021-09-29T19:45:41,ScholarWorks at WMU,"[{'title': 'Journal of Communication Pedagogy', 'identifiers': ['issn:2578-2568', '2640-4524', '2578-2568', 'issn:2640-4524']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Treballs finals del Màster en Matemàtica Avançada, Facultat de Matemàtiques, Universitat de Barcelona: Curs: 2022-2023.  Director: Carles Casacuberta i Polyxeni Gkontra[en] The present research project aims to study the topology of time varying Cardiovascular Magnetic Resonance images (CMR) for disease diagnosis. CMR is a non-invasive technique that involves the acquisition of multiple 3D images at different cardiac phases throughout the cardiac cycle. Nonetheless, conventional assessment of CMR images typically involves the quantification of parameters related to the volumes, and more recently to the shape
and texture by means of radiomics (Raisi-Estabragh, 2020), of the cardiac chambers at only two static time-point points: the end-systole and the enddiastole. Therefore, potentially rich information regarding the cardiac function and structure from other phases of the cardiac cycle might be lost.
To overcome this limitation, we propose to leverage Topological Data Analysis (TDA) to optimally exploit information from the entire cardiac cycle, by measuring the variation of persistence descriptors. This approach
seems promising since a time series might not exhibit relevant geometrical features in its respective point cloud embedding, but it may rather display topological cyclic patterns and their respective variations that can be captured with the proposed machinery. Subsequently, the novel TDA-based CMR descriptors encompassing the entire cardiac cycle are used to feed supervised machine learning classifiers for cardiovascular disease diagnosis.
A full framework from data gathering, to image processing, mathematical modelling and classifier implementation is presented for this purpose.
The performance of the proposed approach based on TDA features and ML is limited. Nonetheless, the approach could be easily adapted to other diseases and scenario where the integration of ML and TDA could be more
beneficial",,https://diposit.ub.edu/dspace/bitstream/2445/203762/1/tfm_prada_malagon_juan_david.pdf,151497256,time-dependent topological snalysis for cardiovascular disease diagnosis using magnetic resonance,2023-09-01T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Salah satu sumber daya yang menjadi pertimbangan kritis adalah sistem file. Hampir semuanya terlibat dalam menghubungkan pengguna dengan sistem file. Manajemen pengguna, file dan konfigurasi akan menjadi fokus permasalahan jika dikaitkan dengan keamanan. Pengguna pada sistem file dianggap memiliki identitas ketika terhubung dengan sistem. Disamping itu, atribut izin dan hak yang ada pada pengguna sebagai pelengkap identitas.  Saat ini terjadi peningkatan aktiftas dalam sistem file sehingga menjadi lebih kompleks . Sistem yang kompleks  dan pengguna yang belum terkelola dengan baik maka berpotensi ancaman keamanan file. Dalam studi ini, telah dilakukan penelusuran dan investigasi pada aktivitas  dengan log riwayat aktivitas  pengguna dalam sistem file khususnya pendekatan data mining . Metode klustering ditujukan untuk menganalisis dengan menghasilkan luaran pengetahuan berupa kluster. Pembentukan kluster ditunjang dengan teknik K-Means. Hasil pengelompokan menjadi segmentasi terhadap pengguna pada sistem file.  Hasil akhir merepresentasikan adanya 5 kluster pada teknik K-Means.  Model dengan teknik K-Means terbukti menjadi model yang efektif dibuktikan dengan nilai akurasi pada metode Davies Bouldin Index (DBI). Tambahan pengukuran lain adalah dengan F- Measures untuk meninjau hasil akurasi penempatan kluster pada kasus dengan teknik K-Means. Dengan demikian, metode klustering dengan teknik K-Means merupakan metode yang dianggap handal ketika mensegmentasikan data pengguna terkait dengan aktivitas pada sistem file",10.26418/jp.v8i1.52233,https://core.ac.uk/download/522347433.pdf,126419122,data mining dengan segmentasi pengguna pada keamanan sistem file,2022-04-18T01:00:00,'Tanjungpura University',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Federated adversarial training can effectively complement adversarial
robustness into the privacy-preserving federated learning systems. However, the
high demand for memory capacity and computing power makes large-scale federated
adversarial training infeasible on resource-constrained edge devices. Few
previous studies in federated adversarial training have tried to tackle both
memory and computational constraints simultaneously. In this paper, we propose
a new framework named Federated Adversarial Decoupled Learning (FADE) to enable
AT on heterogeneous resource-constrained edge devices. FADE differentially
decouples the entire model into small modules to fit into the resource budget
of each device, and each device only needs to perform AT on a single module in
each communication round. We also propose an auxiliary weight decay to
alleviate objective inconsistency and achieve better accuracy-robustness
balance in FADE. FADE offers theoretical guarantees for convergence and
adversarial robustness, and our experimental results show that FADE can
significantly reduce the consumption of memory and computing power while
maintaining accuracy and robustness.Comment: Preprint versio",,http://arxiv.org/abs/2209.03839,142586524,"fade: enabling federated adversarial training on heterogeneous
  resource-constrained edge devices",2023-04-25T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"286
196
162
What is the pattern or relationship? What do these numbers mean?
286
196
162
Come on...this is a mathematics academy…Would it help if I told you that these numbers have something to do with June 1, 2019?
286 is the number of all days between today and June 1, 2019. Does anyone know the significance of June 1, 2019?
196 is the number of all business days, excluding weekends and holidays between today and June 1, 2019 Graduation day for the class of 2019. Are they in the house?
And 162 days is the number of all classroom days, excluding weekends and holidays, excluding extended weekends, and excluding final exams between today and June 1, 2019--graduation day for which class? 2019!
Good morning and welcome to Convocation 2018",,https://core.ac.uk/download/233997250.pdf,69964971,convocation 2018: opening remarks,2018-08-20T08:00:00,DigitalCommons@IMSA,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The authors argue that, in the research trajectory of cultural historical psychology,
there are nuclear aspects of Vygotsky’s theory that have been insufficiently considered.
Three of these aspects are herein discussed: the intense and rapid changes to
mediational processes and their influence on human psyche; meaningful findings
on neuroplasticity that require a neuropsychological approach; and, perhaps most
importantly, the need for cultural historical approach, and for psychology at large, to
return to the study of the direction and meaning of human life",10.1007/s12124-021-09649-1,https://core.ac.uk/download/541362149.pdf,128501045,cultural historical psychology and the reset of history,2021-01-01T00:00:00,'Springer Science and Business Media LLC',"[{'title': 'Integrative Psychological and Behavioral Science', 'identifiers': ['1932-4502', 'issn:1932-4502']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Recent advances in large-scale vision-language models have achieved very
impressive performance in various zero-shot image classification tasks. While
prior studies have demonstrated significant improvements by introducing
few-shot labelled target samples, they still require labelling of target
samples, which greatly degrades their scalability while handling various visual
recognition tasks. We design NtUA, a Noise-tolerant Unsupervised Adapter that
allows learning superior target models with few-shot unlabelled target samples.
NtUA works as a key-value cache that formulates visual features and predicted
pseudo-labels of the few-shot unlabelled target samples as key-value pairs. It
consists of two complementary designs. The first is adaptive cache formation
that combats pseudo-label noises by weighting the key-value pairs according to
their prediction confidence. The second is pseudo-label rectification, which
corrects both pair values (i.e., pseudo-labels) and cache weights by leveraging
knowledge distillation from large-scale vision language models. Extensive
experiments show that NtUA achieves superior performance consistently across
multiple widely adopted benchmarks",,http://arxiv.org/abs/2309.14928,148088127,noise-tolerant unsupervised adapter for vision-language models,2023-09-26T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The Global Dispute Resolution Conference brought together scholars, students, attorneys, and professionals from across the country. Co-hosted by Pepperdine’s Straus Institute for Dispute Resolution and Prince Mohammad Bin Fahd University, the event drew perspectives from a wide range of cultures, areas of ADR, and career experiences. Grouped into two full days with distinct focuses, the conference covered topics from commercial ADR to the significance of history, culture, and faith. To open the discussion, Professor Muamar Salameh of PMU spoke to the audience on the importance of accepting the global differences in legal systems within international dispute resolution. His remarks were followed by Pepperdine’s President Jim Gash, who highlighted the need for compassion and actively willing the good of the other for the other as global parties work together to find common ground. This paper provides highlights of the major dispute resolution topics and trends addressed throughout the conference, as well as key takeaways for the continuous development of the field",,https://core.ac.uk/download/344667601.pdf,45246839,"global dispute resolution conference: reflections, trends, and continued development",2020-10-19T23:07:29,Pepperdine Digital Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The term “metaverse” has become commonly used as a synonym for an immersive, interconnected and interoperable space capable of changing the ordinary distinction between real and virtual. The metaverse is a large and ambitious project, which for the moment does not exist, and which is characterized by innovative features compared to the virtual worlds we know. It can be understood as an interoperable and large-scale network of three-dimensional virtual worlds represented in real time, which can be experienced in a synchronous and unlimited way by a boundless number of users and with continuity of data.326 Interoperability assumes a fundamental importance in the construction of this evolution of the “internet”, and is embodied in the close interconnection between multiple computer systems. Persistence, meanwhile, is the property that allows the metaverse to operate in such a way that it does not need to be paused. This feature will allow operators to create an immersive and constant space where users can carry out any type of activity.327 These preliminary definitions allow us to understand how the metaverse will be the sum of all publicly accessible virtual worlds. The achievement of this new form of reality, which will happen in the near to medium term, introduces new critical issues with regard to the protection of the fundamental rights of users. The right to privacy is certainly among those that are most exposed to the dangers associated with the development of this permanent and immersive infrastructure. Indeed, users will be forced to give up a significant amount of personal data in order to access the metaverse. The potential transposition of many individual activities into this virtual network could affect the essence of the right to privacy and its corollaries",,https://core.ac.uk/download/590921798.pdf,150014538,the metaverse and privacy: new critical issues on the horizon,2023-10-26T01:00:00,Goce Delcev University,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Summary and Recommendations on Big Data of the Ethics Commission of the Academy of Technologies of France. Originally published in French:Synthèse et recommendations, in Académie des Technologies, Big Data: Questions éthiques, Oct 2019, 9-20, available from:https://www.academie-technologies.fr/publications/big-data-questions-ethiques. Translation by the editors",10.58863/20.500.12424/4276027,https://core.ac.uk/download/582653542.pdf,146586534,big data in health and other sectors : ethical questions,2023-01-01T00:00:00,Globethics Publications,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"With this short essay, we aim to raise awareness of the NTU Institute of Science and Technology for Humanity (NISTH) initiative and to invite our colleagues to partake in the research programs we hope to see initiated at NISTH in years to come. In particular, building on the launch of the Institute, supplemented by the extraordinary global experience of COVID-19, we suggest ways in which STS scholars from around the world might contribute to the public conversation regarding the 4IR and thereby also to the ways in which the relationships between technology, states, and citizens might be imagined with specific reference to Asia’s future",10.1080/18752160.2021.1877034,https://core.ac.uk/download/523297231.pdf,132410315,science and technology for humanity: an sts view from singapore,2021-01-01T00:00:00,'Informa UK Limited',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We introduce Question-Answer Meaning Representations (QAMRs), which represent
the predicate-argument structure of a sentence as a set of question-answer
pairs. We also develop a crowdsourcing scheme to show that QAMRs can be labeled
with very little training, and gather a dataset with over 5,000 sentences and
100,000 questions. A detailed qualitative analysis demonstrates that the
crowd-generated question-answer pairs cover the vast majority of
predicate-argument relationships in existing datasets (including PropBank,
NomBank, QA-SRL, and AMR) along with many previously under-resourced ones,
including implicit arguments and relations. The QAMR data and annotation code
is made publicly available to enable future work on how best to model these
complex phenomena.Comment: 8 pages, 6 figures, 2 table",10.18653/v1/n18-2089,http://arxiv.org/abs/1711.05885,45159323,crowdsourcing question-answer meaning representations,2017-11-15T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We will reduce the task of creating AI to the task of finding an appropriate
language for description of the world. This will not be a programing language
because programing languages describe only computable functions, while our
language will describe a somewhat broader class of functions. Another
specificity of this language will be that the description will consist of
separate modules. This will enable us look for the description of the world
automatically such that we discover it module after module. Our approach to the
creation of this new language will be to start with a particular world and
write the description of that particular world. The point is that the language
which can describe this particular world will be appropriate for describing any
world",,http://arxiv.org/abs/2010.16243,107754741,language for description of worlds,2021-06-24T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Speech-to-speech translation systems today do not adequately support use for
dialog purposes. In particular, nuances of speaker intent and stance can be
lost due to improper prosody transfer. We present an exploration of what needs
to be done to overcome this. First, we developed a data collection protocol in
which bilingual speakers re-enact utterances from an earlier conversation in
their other language, and used this to collect an English-Spanish corpus, so
far comprising 1871 matched utterance pairs. Second, we developed a simple
prosodic dissimilarity metric based on Euclidean distance over a broad set of
prosodic features. We then used these to investigate cross-language prosodic
differences, measure the likely utility of three simple baseline models, and
identify phenomena which will require more powerful modeling. Our findings
should inform future research on cross-language prosody and the design of
speech-to-speech translation systems capable of effective prosody transfer.Comment: Accepted to Interspeech 202",,http://arxiv.org/abs/2307.04123,144553287,towards cross-language prosody transfer for dialog,2023-07-09T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In a context of continuous miniaturization and technological advancement, the combination of digital and analog media is becoming an element of increasing importance. The so called “IoT revolution” represents one of the major technological breakthroughs of our times that re-framed the way we interact with our surroundings, now becoming data-rich and sensor-infused environments. The boardgames field, however, appears untouched by this revolution, even though an object- based system such as a tabletop offers an interesting scenario for smart interactions. The research in the field and the development of a prototype lead to a series of ground rules, best practices and problematics related to operations of hybridisation of digital means in an analog play experience",,https://core.ac.uk/download/237171846.pdf,71831894,hybrid board game: possibilities and implications from an interaction design perspective,2019-01-01T00:00:00,CEUR,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper proposes that intuitive technologies play a vital role in cognition and cultural reception. The case of music is considered in particular. The perceived temporality of contemporary technology is shown to be an artificial barrier to the acknowledgement of longer-term dynamics.
The increased role of explanatory metaphors from technology is traced across various fields of study. Processes of sense-making – conscious or otherwise – are seen as an informal, unreflected repertory of mechanisms ranging from predictive models to instrumental metaphors. It is suggested that these derive by assimilation and induction from the technological milieu within which the subject develops and operates. The acquisition of these models and metaphors is itself an imaginative process, based on experience ranging from partial expertise to fantastical extrapolation",10.1007/s00146-020-01126-4,https://core.ac.uk/download/573846672.pdf,144981703,"music, discourse and intuitive technology",2021-01-01T00:00:00,Springer Verlag,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper summarizes the music demixing (MDX) track of the Sound Demixing
Challenge (SDX'23). We provide a summary of the challenge setup and introduce
the task of robust music source separation (MSS), i.e., training MSS models in
the presence of errors in the training data. We propose a formalization of the
errors that can occur in the design of a training dataset for MSS systems and
introduce two new datasets that simulate such errors: SDXDB23_LabelNoise and
SDXDB23_Bleeding1. We describe the methods that achieved the highest scores in
the competition. Moreover, we present a direct comparison with the previous
edition of the challenge (the Music Demixing Challenge 2021): the best
performing system under the standard MSS formulation achieved an improvement of
over 1.6dB in signal-to-distortion ratio over the winner of the previous
competition, when evaluated on MDXDB21. Besides relying on the
signal-to-distortion ratio as objective metric, we also performed a listening
test with renowned producers/musicians to study the perceptual quality of the
systems and report here the results. Finally, we provide our insights into the
organization of the competition and our prospects for future editions.Comment: under revie",,http://arxiv.org/abs/2308.06979,145193345,the sound demixing challenge 2023 $\unicode{x2013}$ music demixing track,2023-08-14T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The University of Maine recently gained Carnegie R1 status, a level of recognition that speaks to the quality and scale of research happening at Maine’s land grant, sea grant, and space grant institution, and across the state as a whole. Research institutes, centers and labs established because of NSF EPSCoR RII Track-1 grants have created a significant and lasting impact in Maine. These entities include the Advanced Structures and Composites Center, Frontier Institute for Research in Sensor Technologies, Forest Bioproducts Research Institute, and Mitchell Center for Sustainability Solutions, which have generated over 500 million dollars in new R&D funding for the state following the completion of their RII Track-1 support.
Maine EPSCoR’s current NSF EPSCoR RII Track-1 grant, Maine-eDNA, is set to embark on a full field season with work occurring throughout the state. We recognize the researchers, staff, graduate students, and undergraduate students who continue to actively participate in this work. Their effort and resilience in the face of uncertain and changing circumstances is inspiring and makes real contributions in our efforts to expand educational opportunities in STEM, drive workforce development, and strengthen research capacity in the state of Maine",,https://core.ac.uk/download/519803622.pdf,131067430,"maine epscor, vol. 1, issue 1",2022-01-01T08:00:00,DigitalCommons@UMaine,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Robust obstacle avoidance is one of the critical steps for successful
goal-driven indoor navigation tasks.Due to the obstacle missing in the visual
image and the possible missed detection issue, visual image-based obstacle
avoidance techniques still suffer from unsatisfactory robustness. To mitigate
it, in this paper, we propose a novel implicit obstacle map-driven indoor
navigation framework for robust obstacle avoidance, where an implicit obstacle
map is learned based on the historical trial-and-error experience rather than
the visual image. In order to further improve the navigation efficiency, a
non-local target memory aggregation module is designed to leverage a non-local
network to model the intrinsic relationship between the target semantic and the
target orientation clues during the navigation process so as to mine the most
target-correlated object clues for the navigation decision. Extensive
experimental results on AI2-Thor and RoboTHOR benchmarks verify the excellent
obstacle avoidance and navigation efficiency of our proposed method. The core
source code is available at https://github.com/xwaiyy123/object-navigation.Comment: 9 pages, 7 figures, 43 references. This paper has been accepted for
  ACM MM 202",10.1145/3581783.3612100,http://arxiv.org/abs/2308.12845,146326643,"implicit obstacle map-driven indoor navigation model for robust obstacle
  avoidance",2023-08-24T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Black-box Large Language Models (LLMs) have shown great power in solving
various tasks and are considered general problem solvers. However, LLMs still
fail in many specific tasks although understand the task instruction. In this
paper, we focus on the problem of boosting the ability of black-box LLMs to
solve downstream tasks. We propose ExpNote, an automated framework to help LLMs
better adapt to unfamiliar tasks through reflecting and noting experiences from
training data and retrieving them from external memory during testing. We
evaluate ExpNote on multiple tasks and the experimental results demonstrate
that the proposed method significantly improves the performance of black-box
LLMs. The data and code are available at
https://github.com/forangel2014/ExpNoteComment: EMNLP 2023 finding",,http://arxiv.org/abs/2311.07032,153740175,"expnote: black-box large language models are better task solvers with
  experience notebook",2023-11-12T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In simultaneous speech translation (SimulST), finding the best trade-off
between high translation quality and low latency is a challenging task. To meet
the latency constraints posed by the different application scenarios, multiple
dedicated SimulST models are usually trained and maintained, generating high
computational costs. In this paper, motivated by the increased social and
environmental impact caused by these costs, we investigate whether a single
model trained offline can serve not only the offline but also the simultaneous
task without the need for any additional training or adaptation. Experiments on
en->{de, es} indicate that, aside from facilitating the adoption of
well-established offline techniques and architectures without affecting
latency, the offline solution achieves similar or better translation quality
compared to the same model trained in simultaneous settings, as well as being
competitive with the SimulST state of the art",,https://core.ac.uk/download/558854524.pdf,121290303,does simultaneous speech translation need simultaneous models?,2022-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"A lot of things need to be repaired and a lot of relationships are in need of a knowledgeable mending. Can we start to talk/write about them? This invitation - sent by one of the authors to the others - led us, as feminist women in academia, to join together in an experimental writing about the effects of COVID-19 on daily social practices and on potential (and innovative) ways for repairing work in different fields of social organization. By diffractively intertwining our embodied experiences of becoming together-with Others, we foreground a multiplicity of repair (care) practices COVID-19 is making visible. Echoing one another, we take a stand and say that we need to prevent the future from becoming the past. We are not going back to the past; our society has already changed and there is a need to cope with innovation and repairing practices that do not reproduce the past.Funding Agencies|European Research Council (ERC) under the European Unions Horizon 2020 research and innovation programmeEuropean Research Council (ERC) [715950]</p",10.1111/gwao.12524,https://core.ac.uk/download/328776434.pdf,8682021,covid-19 as a breakdown in the texture of social practices,2020-01-01T00:00:00,'Wiley',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In the field of Naturalistic Decision Making, the Data-Frame Model (DFM) has proven to be a popular and useful way of thinking about sensemaking. DFM provides a parsimonious account of how ‘sensemakers’ interact with the data in their environment in order to make sense of what is happening. In this paper, however, we argue that it is useful to elaborate DFM in several ways. We begin by arguing for the idea of sensemaking as a quest for coherence, an idea that we see as entirely consistent with the DFM. We then present some examples of sensemaking studies and use these to motivate a Distributed Resources Model of Sensemaking. This model uses the notion of resources for action, as  resources that can be flexibly drawn upon in both choosing courses of action and accounting for the actions of oneself and of others (as opposed to prescriptions or mechanisms that determine behaviour in any strict way). It describes resources involved in sensemaking in terms of three domains: Knowledge and Beliefs, Values and Goals, and Action. Knowledge and beliefs are concerned with how things are; Values and Goals are concerned with how things are desired to be; and Action provides the means for redressing the gap. Central to the model is the idea that these resources can be distributed across a cognitive work system across actors and representational media. Hence, it aims to provide a framework for analysing sensemaking as Distributed Cognition",10.1007/s10111-018-0529-4,https://core.ac.uk/download/573849982.docx,145383733,a resources model for distributed sensemaking,2018-01-01T00:00:00,Springer,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Higher Education Institutions are committed to developing innovative pedagogical practices that open the doors to collaboration between students, who are seen as talents; teaching staff, who become their facilitators; and partner entities that present them with societal challenges, in different fields, and call for intercultural, multidisciplinary, proactive, multi-stakeholder action. This is the setting of the virtual learning environments that the Demola Portugal Initiative has embraced and cherished in a network of 14 Portuguese Polytechnic Institutions. Our study focuses on a real-world challenge project that was part of the first batch developed at the Polytechnic Institute of Viseu, together with ACERT, a cultural and recreational association from the region that struggled with a fall in activity caused by the pandemic. Using design thinking and co-creation, a team of six students came up with a few solutions that would make young generations reconnect and participate in cultural activities. The aim of this paper is, thus, to present a case study that portrays how Higher Education Institutions are being reframed to become more innovative, humanising and transformative spaces that extend beyond the classroom walls to scaffold learning through meaningful tasks and partnerships. With this study, we may conclude that this project empowered the team and made them feel like true change-makers, whilst developing skills for their future that they can put into practice in the workplace.info:eu-repo/semantics/publishedVersio",10.1016/j.ssaho.2023.100729,https://core.ac.uk/download/591072197.pdf,152123081,‘now open for action!’ – a real-world challenge project developed at the polytechnic institute of viseu,2023-11-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Automatic evaluation of natural language generation has long been an elusive
goal in NLP.A recent paradigm fine-tunes pre-trained language models to emulate
human judgements for a particular task and evaluation criterion. Inspired by
the generalization ability of instruction-tuned models, we propose a learned
metric based on instruction tuning. To test our approach, we collected HEAP, a
dataset of human judgements across various NLG tasks and evaluation criteria.
Our findings demonstrate that instruction tuning language models on HEAP yields
good performance on many evaluation tasks, though some criteria are less
trivial to learn than others. Further, jointly training on multiple tasks can
yield additional performance improvements, which can be beneficial for future
tasks with little to no human annotated data.Comment: 11 pages, 1 figur",,http://arxiv.org/abs/2310.20072,152502966,automatic evaluation of generative models with instruction tuning,2023-10-30T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Dialog engines based on multi-agent architectures usually select a single agent, deemed to be the most suitable for a given scenario or for responding to a specific request, and disregard the answers from all of the other available agents. In this work, we present a multi-agent plug-and-play architecture that: (i) enables the integration of different agents; (ii) includes a decision maker module, responsible for selecting a suitable answer out of the responses of different agents. As usual, a single agent can be chosen to provide the final answer, but the latter can also be obtained from the responses of several agents, according to a voting scheme. We also describe three case studies in which we test several agents and decision making strategies; and show how new agents and a new decision strategy can be easily plugged in and take advantage of this platform in different ways. Experimentation also confirms that considering several agents contributes to better responses",10.4230/oasics.slate.2021.7,https://core.ac.uk/download/480431473.pdf,39976819,muahah: taking the most out of simple conversational agents,2021-01-01T00:00:00,"OASIcs - OpenAccess Series in Informatics. 10th Symposium on Languages, Applications and Technologies (SLATE 2021)",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We consider Markov logic networks and relational logistic regression as two fundamental representation formalisms in statistical relational artificial intelligence that use weighted formulas in their specification. However, Markov logic networks are based on undirected graphs, while relational logistic regression is based on directed acyclic graphs. We show that when scaling the weight parameters with the domain size, the asymptotic behaviour of a relational logistic regression model can be described by a single Bayesian network and is transparently controlled by the provided weights. We also show using two examples that this is not true for Markov logic networks. We also discuss using several examples, mainly from the literature, how the application context can help the user to decide when such scaling is appropriate and when using the raw unscaled parameters might be preferable. We highlight random sampling as a particularly promising area of application for scaled models and expound possible avenues for further research",,https://core.ac.uk/download/322382872.pdf,29023227,scaling the weight parameters in markov logic networks and relational logistic regression models,2020-04-17T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The pre-training architectures of large language models encompass various
types, including autoencoding models, autoregressive models, and
encoder-decoder models. We posit that any modality can potentially benefit from
a large language model, as long as it undergoes vector quantization to become
discrete tokens. Inspired by GLM, we propose a General Point Model (GPM) which
seamlessly integrates autoencoding and autoregressive tasks in point cloud
transformer. This model is versatile, allowing fine-tuning for downstream point
cloud representation tasks, as well as unconditional and conditional generation
tasks. GPM enhances masked prediction in autoencoding through various forms of
mask padding tasks, leading to improved performance in point cloud
understanding. Additionally, GPM demonstrates highly competitive results in
unconditional point cloud generation tasks, even exhibiting the potential for
conditional generation tasks by modifying the input's conditional information.
Compared to models like Point-BERT, MaskPoint and PointMAE, our GPM achieves
superior performance in point cloud understanding tasks. Furthermore, the
integration of autoregressive and autoencoding within the same transformer
underscores its versatility across different downstream tasks",,http://arxiv.org/abs/2310.16861,152873441,general point model with autoencoding and autoregressive,2023-10-25T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The ever increasing amount of personal data accumulated by companies offering innovative services through the cloud, Internet of Things devices and, more recently, social robots has started to alert consumers and legislative authorities. In the advent of the first modern laws trying to protect user privacy, such as the European Union General Data Protection Regulation, it is still unclear what are the tools and techniques that the industry should employ to comply with regulations in a transparent and cost effective manner. We propose an architecture for a public blockchain based ledger that can provide strong evidence of policy compliance. To address scalability concerns, we define a new type of off-chain channel that is based on general state channels and offers verification for information external to the blockchain. We also create a model of the business relationships in a smart home setup that includes a social robot and suggest a sticky policy mechanism to monitor cross-boundary policy compliance",,https://core.ac.uk/download/427572995.pdf,41667666,"dependable public ledger for policy compliance, a blockchain based approach",2019-01-01T08:00:00,e-Publications@Marquette,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"UNESCO defines Transdisciplinarity as an effort to understand, define, and solve complex problems through the integration and transformation of multiple fields of knowledge from various perspectives. UNESCO's definition of transdisciplinarity indirectly confirms that humanity has been facing increasingly complex issues. This article attempts to explain digital literacy as part of the Transdisciplinary paradigm through a literature and library study approach with discourse and content analysis methods. Various literature, research reports, and related materials are discussed and analyzed to gain an understanding of the importance and position of digital literacy from a transdisciplinary perspective. The importance of digital literacy in the Society 5.0 era and how a transdisciplinary approach can enrich our understanding of digital literacy is something that students must realize and strive for. Digital literacy is not just about technology but also about critical, creative, and responsible abilities in dealing with the ever-growing complexity of the digital world",,https://core.ac.uk/download/587867871.pdf,149966520,transdisciplinarity: the urgency of digital literacy  in the era of society 5.0.,2023-10-08T01:00:00,Proceeding International Seminar and Conference on Islamic Studies  (ISCIS),[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"There would seem to be a potential regulatory problem with the crash algorithms for connected and autonomous vehicles that (normally) ""kick in"" should a crash be inevitable. Although the general regulatory considerations which have been put forward tend to seek a ""fair balance"" that would protect various users of the roads, a configuration which shielded other parties at the cost of the car user could be seen as posing an existential threat to the user by encroaching on his or her right to self-preservation. ""Hacking the system"" (i.e. modifying the configuration in order to obtain a more favourable outcome for the user) could therefore be understood as acting on one's instinct for self-preservation and - though illegal - could in certain situations turn out to be an action that is not punishable in law. The present article argues that in certain real post-crash situations, a person who has modified the code for his or her own benefit could be exonerated on the basis of existing legal provisions and thus go unpunished. This could create unforeseen flaws in the connected autonomous vehicles regulatory system.Peer reviewe",10.1016/j.techsoc.2022.102127,https://core.ac.uk/download/543232219.pdf,127370682,problems with the prospective connected autonomous vehicles regulation : finding a fair balance versus the instinct for self-preservation,2022-01-01T00:00:00,,"[{'title': 'Technology in Society', 'identifiers': ['0160-791x', 'issn:0160-791X', '1879-3274', 'issn:1879-3274']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"At present there is a clear distinction between robots and persons. In this article I explore the possibility that this distinction may not hold in perpetuity, as some robots attain personhood. I argue that personhood is an emergent property in both the development of individuals and the evolution of life, that personhood may not require a carbon-based existence, and that, given that robots are being made with ever greater powers of cognition, at some point these powers of cognition may reach the point at which we need to start talking of robots as having minds and being persons. This will have implications for how we treat robots, for how we design robots and for how we understand ourselves and other creatures. There are also implications for moral education that may need to be taken seriously",,https://core.ac.uk/download/323206055.pdf,149025430,robots as persons? implications for moral education,2021-01-01T00:00:00,'Informa UK Limited',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The unpredictable Anthropocene poses the challenge of imagining a radically different, equitable and sustainable world. Looking 100 years ahead is not easy, and especially as millennials, it appears quite bleak. This paper is the outcome of a visioning exercise carried out in a 2-day workshop, attended by 33 young early career professionals under the auspices of IPBES. The process used Nature Futures Framework in an adapted visioning method from the Seeds of Good Anthropocene project. Four groups envisioned more desirable future worlds; where humanity has organised itself, the economy, politics and technology, to achieve improved nature-human well-being. The four visions had differing conceptualisations of this future. However, there were interesting commonalities in their leverage points for transformative change, including an emphasis on community, fundamentally different economic systems based on sharing and technological solutions to foster sustainability and human-nature connectedness. Debates included questioning the possibility of maintaining local biocultural diversity with increased connectivity globally and the prominence of technology for sustainability outcomes. These visions are the first step towards a wider galvanisation of youth visions for a brighter future, which is often missing in the arena where it can be taken seriously, to trigger more transformative pathways towards meeting global goals",10.1080/26395916.2020.1821095,https://core.ac.uk/download/334954043.pdf,8018231,the voices of youth in envisioning positive futures for nature and people,2020-01-01T00:00:00,'Informa UK Limited',"[{'title': 'Ecosystems and People', 'identifiers': ['issn:2639-5908', 'issn:2639-5916', '2639-5908', '2639-5916']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The authors add to the debate about whether sport and numbers can cohabitate in modern day athletics, three areas are explored (albeit briefly) in the present paper. The first area focuses on the newness (or lack thereof) of analytics. The second area focuses the objectivity of analytics. The third area focuses on the idea that athletic competition is somehow sacred and should not be soiled by applying various statistical methods to practical sport performance problems",,https://core.ac.uk/download/555439754.pdf,141753171,sport isn’t sacred and analytics isn’t new: challenging common notions about sports analytics,2022-12-01T08:00:00,TRACE: Tennessee Research and Creative Exchange,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Skriftlig del av bacheloroppgave, avdeling Kunst og håndverk 202",,https://core.ac.uk/download/539602737.pdf,127025695,transenvironmentals: future bodies,2022-01-01T00:00:00,Kunsthøgskolen i Oslo,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"With the widespread applications of the deep neural network (DNN), how to
covertly transmit the DNN models in public channels brings us the attention,
especially for those trained for secret-learning tasks. In this paper, we
propose deep network steganography for the covert communication of DNN models.
Unlike the existing steganography schemes which focus on the subtle
modification of the cover data to accommodate the secrets, our scheme is
learning task oriented, where the learning task of the secret DNN model (termed
as secret-learning task) is disguised into another ordinary learning task
conducted in a stego DNN model (termed as stego-learning task). To this end, we
propose a gradient-based filter insertion scheme to insert interference filters
into the important positions in the secret DNN model to form a stego DNN model.
These positions are then embedded into the stego DNN model using a key by side
information hiding. Finally, we activate the interference filters by a partial
optimization strategy, such that the generated stego DNN model works on the
stego-learning task. We conduct the experiments on both the intra-task
steganography and inter-task steganography (i.e., the secret and stego-learning
tasks belong to the same and different categories), both of which demonstrate
the effectiveness of our proposed method for covert communication of DNN
models.Comment: 8 pages. arXiv admin note: text overlap with arXiv:2302.1452",,http://arxiv.org/abs/2307.03444,144552446,towards deep network steganography: from networks to networks,2023-07-07T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The gigamaps relating full-scale prototypes series in this article are synthesising a work developed within the framework of Systemic Approach to Architectural Performance (SAAP) research by design field. Gigamapping serves as a tool for complexity codesigning through relations mapping and has no strict recipe (Sevaldson, 2018b). It is project and participation specific. The particularity of SAAP is that it develops theories and methods through experimental practice. SAAP involves Time-Based Eco‐Systemic Co‐Design that is performed by both living and non-living agents. Gigamapping is central to SAAP because it is a tool that relates the complexity within collaborative design-research processes and its coperformances. It maps and generates their relations, meaning environmental, societal and cultural aspects and processes across past, current and future habitats and edible landscapes of- and across- different species and other agencies involved. SAAP’s ambition is to co- and re- design these complexities. Thus, SAAP is based in full-scale prototyping related with gigamapping, both placed into ‘real life’ environments, the “real life codesign laboratories” (Davidová, Pánek, & Pánková, 2018). SAAP is therefore considering gigamaps as well as the full-scale prototypes as ”prototypical urban interventions” that can drive extensive generative agencies across various communities (Doherty, 2005) and agents; and while doing that, across much larger systems, introducing the necessary transition towards Post-Anthropocene of bio-climatic layers of cultural landscapes, their territories and life-cycles",10.4013/sdrj.2020.132.06,https://core.ac.uk/download/323987785.pdf,86254273,"cocreative roles, agencies and relations in post-anthropocene: the real life gigamaps and full-scale prototypes of saap",2020-10-29T00:00:00,'UNISINOS - Universidade do Vale do Rio Dos Sinos',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In a previous work (Lucchiari and Folgieri, 2015) we considered communication among young people. New digital-natives do not communicate in a traditional way, but they choose different means and ways. It is not a surprising conclusion that a large part of digital-natives considers obsolete both Web sites\u2019 structure and Internet navigation modes, learning instruments and paradigms and communication tools, choosing, instead, fast and immediate media like mobile phone communication, social networking and so on (Croitoru et al. 2011). Notwithstanding we could think they lack of communication skills, actually, they communicate with each other much more than ever done, using not only the verbal language, but also images, videos, sounds, and especially emotions. We named this phenomenon telepatheia or, better, sympateia, meaning that they seem to keep in contact independently by the mean. Of course, on our intention, this does not mean that we are observing a new organic evolution, but surely a kind of evolution can be traced: an era in which human and machines are evolving, influencing one each other, determining a specific kind of communication strongly influenced and related to technology.
In this paper, starting from our previous studies and from our concept of \u201csympateia\u201d, we performed a new experiment related to brain rhythms synchronization.
Through our experiment, described in the following chapter, We want to explore the communication mechanisms of telepathy (in the ancient Greek assumption of \u201ctelepatia\u201d\uf020that is [tele]=\u201ddistance\u201d and [pateia]=\u201demotion, feeling\u201d). This does not mean that we are trying to make humans telepathic, but we aim to deeply understand communication mechanisms among humans through human-computer interaction BCI devices. This means to change the point of view of brain and Information Technology researches, stressing the point of view of self-understanding of the own brain",10.14236/ewic/eva2018.22,https://core.ac.uk/download/187990430.pdf,54703938,brainwaves and sound synchronization in a dance performance,2018-01-01T00:00:00,'BCS Learning and Development Limited',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Generative steganography is the process of hiding secret messages in
generated images instead of cover images. Existing studies on generative
steganography use GAN or Flow models to obtain high hiding message capacity and
anti-detection ability over cover images. However, they create relatively
unrealistic stego images because of the inherent limitations of generative
models. We propose Diffusion-Stego, a generative steganography approach based
on diffusion models which outperform other generative models in image
generation. Diffusion-Stego projects secret messages into latent noise of
diffusion models and generates stego images with an iterative denoising
process. Since the naive hiding of secret messages into noise boosts visual
degradation and decreases extracted message accuracy, we introduce message
projection, which hides messages into noise space while addressing these
issues. We suggest three options for message projection to adjust the trade-off
between extracted message accuracy, anti-detection ability, and image quality.
Diffusion-Stego is a training-free approach, so we can apply it to pre-trained
diffusion models which generate high-quality images, or even large-scale
text-to-image models, such as Stable diffusion. Diffusion-Stego achieved a high
capacity of messages (3.0 bpp of binary messages with 98% accuracy, and 6.0 bpp
with 90% accuracy) as well as high quality (with a FID score of 2.77 for 1.0
bpp on the FFHQ 64$\times$64 dataset) that makes it challenging to distinguish
from real images in the PNG format",,http://arxiv.org/abs/2305.18726,143043298,"diffusion-stego: training-free diffusion generative steganography via
  message projection",2023-05-30T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The in vitro fertilization procedure called intracytoplasmic sperm injection can be used to help fertilize an egg by injecting a single sperm cell directly into the cytoplasm of the egg. In order to evaluate, refine and improve the method in the fertility clinic, the procedure is usually observed at the clinic. Alternatively, a video of the procedure can be examined and labeled in a time-consuming process. To reduce the time required for the assessment, we propose an unsupervised method that automatically clusters video frames of the intracytoplasmic sperm injection procedure. Deep features are extracted from the video frames and form the basis for a clustering method. The method provides meaningful clusters representing different stages of the intracytoplasmic sperm injection procedure. The clusters can lead to more efficient examinations and possible new insights that can improve clinical practice. Further on, it may also contribute to improved clinical outcomes due to increased understanding about the technical aspects and better results of the procedure. Despite promising results, the proposed method can be further improved by increasing the amount of data and exploring other types of features",10.1007/978-3-031-17030-0_9,https://core.ac.uk/download/590214626.pdf,149292506,automatic unsupervised clustering of videos of the intracytoplasmic sperm injection (icsi) procedure,2023-02-02T00:00:00,Springer Nature,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Today, the security of many domains rely on the use of Machine Learning to
detect threats, identify vulnerabilities, and safeguard systems from attacks.
Recently, transformer architectures have improved the state-of-the-art
performance on a wide range of tasks such as malware detection and network
intrusion detection. But, before abandoning current approaches to transformers,
it is crucial to understand their properties and implications on cybersecurity
applications. In this paper, we evaluate the robustness of transformers to
adversarial samples for system defenders (i.e., resiliency to adversarial
perturbations generated on different types of architectures) and their
adversarial strength for system attackers (i.e., transferability of adversarial
samples generated by transformers to other target models). To that effect, we
first fine-tune a set of pre-trained transformer, Convolutional Neural Network
(CNN), and hybrid (an ensemble of transformer and CNN) models to solve
different downstream image-based tasks. Then, we use an attack algorithm to
craft 19,367 adversarial examples on each model for each task. The
transferability of these adversarial examples is measured by evaluating each
set on other models to determine which models offer more adversarial strength,
and consequently, more robustness against these attacks. We find that the
adversarial examples crafted on transformers offer the highest transferability
rate (i.e., 25.7% higher than the average) onto other models. Similarly,
adversarial examples crafted on other models have the lowest rate of
transferability (i.e., 56.7% lower than the average) onto transformers. Our
work emphasizes the importance of studying transformer architectures for
attacking and defending models in security domains, and suggests using them as
the primary architecture in transfer attack settings.Comment: Accepted to IEEE Military Communications Conference (MILCOM), AI for
  Cyber Workshop, 202",,http://arxiv.org/abs/2310.11597,152091762,"the efficacy of transformer-based adversarial attacks in security
  domains",2023-10-17T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This report provides distinct storylines envisioning Europe's potential futures up to 2030. Contrary to traditional binary evaluations, these four scenarios avoid direct labeling as ""good"" or ""bad."" They delve into crucial drivers, from labor market integration to global affairs such as Russia-Ukraine conflict and Europe-China relations. Addressing the urgent need for ""futures literacy"" among policymakers and experts, this initiative by DGAP experts offers interpretative frameworks for upcoming challenges. Rather than predicting specifics, the scenarios prompt reconsideration of narratives and introduce counter-intuitive thinking modes for addressing global shifts and foreign policy challenges",,https://core.ac.uk/download/590382199.pdf,149597627,europe's multiple futures: four futurescapes for europe's geopolitical positioning in 2030,2023-01-01T00:00:00,'Botanic Garden & Botanical Museum Berlin-Dahlem BGBM',"[{'title': None, 'identifiers': ['issn:2198-5936', '2198-5936']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Neural network models are an invaluable tool to understand brain function since they allow us to connect the cellular and circuit levels with behaviour. Neural networks usually comprise a huge number of parameters, which must be chosen carefully such that networks reproduce anatomical, behavioural, and neurophysiological data. These parameters are usually fitted with off-the-shelf optimization algorithms that iteratively change network parameters and simulate the network to evaluate its performance and improve fitting. Here we propose to invert the fitting process by proceeding from the network dynamics towards network parameters. Firing state transitions are chosen according to the transition graph associated with the solution of a task. Then, a system of linear equations is constructed from the network firing states and membrane potentials, in a way that guarantees the consistency of the system. This allows us to uncouple the dynamical features of the model, like its neurons firing rate and correlation, from the structural features, and the task-solving algorithm implemented by the network. We employed our method to probe the structure–function relationship in a sequence memory task. The networks obtained showed connectivity and firing statistics that recapitulated experimental observations. We argue that the proposed method is a complementary and needed alternative to the way neural networks are constructed to model brain function.Fil: Mininni, Camilo Juan. Consejo Nacional de Investigaciones Científicas y Técnicas. Instituto de Biología y Medicina Experimental. Fundación de Instituto de Biología y Medicina Experimental. Instituto de Biología y Medicina Experimental; Argentina. Universidad de Buenos Aires. Facultad de Ingeniería. Instituto de Ingeniería Biomédica.; ArgentinaFil: Zanutto, Bonifacio Silvano. Consejo Nacional de Investigaciones Científicas y Técnicas. Instituto de Biología y Medicina Experimental. Fundación de Instituto de Biología y Medicina Experimental. Instituto de Biología y Medicina Experimental; Argentina. Universidad de Buenos Aires. Facultad de Ingeniería. Instituto de Ingeniería Biomédica.; Argentin",10.1038/s41598-021-82964-0,https://core.ac.uk/download/480285176.pdf,41068657,probing the structure–function relationship with neural networks constructed by solving a system of linear equations,2021-12-01T00:00:00,'Springer Science and Business Media LLC',"[{'title': 'Scientific Reports', 'identifiers': ['2045-2322', 'issn:2045-2322']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This curriculum, developed as the final project for the Creative Commons for Academic Librarians Certificate course, is designed for students in introductory Library and Information Science courses. The unit offers a broad overview of fundamental concepts in copyright, fair use, and open licensing. The materials include readings, multimedia resources, discussion questions, and practical assignments. The curriculum emphasizes adaptability, catering to diverse audiences and educational settings. The curriculum addresses real-world challenges faced by librarians, explores the nuances of open licenses, and guides students through hands-on activities, fostering a deeper understanding of copyright issues in the digital age",,https://core.ac.uk/download/595867166.pdf,154141736,copyright and open licenses: a unit for lis students,2023-12-04T08:00:00,Scholarship & Creative Works @ Digital UNC,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In the year 1978, the 1976 Copyright Act had just entered into effect. Marshall Leaffer, whom this article will affectionately refer to by his first name, had just completed his duties as an attorney advisor at the U.S. Copyright Office. On his way to academia, he, like the fictional character Captain William “Buck” Rogers, was to experience cosmic forces beyond all comprehension. In a freak mishap, his car veered off a rarely used mountain road and was frozen by temperatures beyond imagination. He did not return to academia until more than forty years later. What will he discover upon his return? Will he find the developments in the intervening decades interesting or surprising? What observations would he make had he not been frozen in 1978",,https://core.ac.uk/download/543554725.pdf,131105940,marshalling copyright knowledge to understand four decades of berne,2022-11-01T07:00:00,Digital Repository @ Maurer Law,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"학위논문 (박사) -- 서울대학교 대학원 : 공과대학 전기·정보공학부, 2021. 2. 김장우.Modern neural-network (NN) accelerators have been successful by accelerating a small number of basic operations (e.g., convolution, fully-connected, feedback) comprising the specific target neural-network models (e.g., CNN, RNN). However, this approach no longer works for the emerging full-scale natural language processing (NLP)-based neural network models (e.g., Memory networks, Transformer, BERT), which consist of different combinations of complex and heterogeneous operations (e.g., self-attention, multi-head attention, large-scale feed-forward). Existing acceleration proposals cover only the proposal-specific basic operations and/or customize them for specific models only, which leads to the low performance improvement and the narrow model coverage. Therefore, an ideal NLP accelerator should first identify all performance-critical operations required by different NLP models and support them as a single accelerator to achieve a high model coverage, and can adaptively optimize its architecture to achieve the best performance for the given model.
To address these scalability and model/config diversity issues, the dissertation introduces two novel projects (i.e., MnnFast and NLP-Fast) to efficiently accelerate a wide spectrum of full-scale NLP models. First, MnnFast proposes three novel optimizations to resolve three major performance problems (i.e., high memory bandwidth, heavy computation, and cache contention) in memory-augmented neural networks. Next, NLP-Fast adopts three optimization techniques to resolve the huge performance variation due to the model/config diversity in emerging NLP models. We implement both MnnFast and NLP-Fast on different hardware platforms (i.e., CPU, GPU, FPGA) and thoroughly evaluate their performance improvement on each platform.자연어 처리의 중요성이 대두됨에 따라 여러 기업 및 연구진들은 다양하고 복잡한 종류의 자연어 처리 모델들을 제시하고 있다. 즉 자연어 처리 모델들은 형태가 복잡해지고,로규모가 커지며, 종류가 다양해지는 양상을 보여준다. 본 학위논문은 이러한 자연어 처리 모델의 복잡성, 확장성, 다양성을 해결하기 위해 여러 핵심 아이디어를 제시하였다. 각각의 핵심 아이디어들은 다음과 같다. (1) 다양한 종류의 자연어 처리 모델의 성능 오버헤드 분포도를 알아내기 위한 정적/동적 분석을 수행한다. (2) 성능 분석을 통해 알아낸 주된 성능 병목 요소들의 메모리 사용을 최적화 하기 위한 전체론적 모델 병렬화 기술을 제시한다. (3) 여러 연산들의 연산량을 감소하는 기술과 연산량 감소로 인한 skewness 문제를 해결하기 위한 dynamic scheduler 기술을 제시한다. (4) 현 자연어 처리 모델의 성능 다양성을 해결하기 위해 각 모델에 최적화된 디자인을 제시하는 기술을 제시한다. 이러한 핵심 기술들은 여러 종류의 하드웨어 가속기 (예: CPU, GPU, FPGA, ASIC) 에도 범용적으로 사용될 수 있기 때문에 매우 효과적이므로, 제시된 기술들은 자연어 처리 모델을 위한 컴퓨터 시스템 설계 분야에 광범위하게 적용될 수 있다. 본 논문에서는 해당 기술들을 적용하여 CPU, GPU, FPGA 각각의 환경에서, 제시된 기술들이 모두 유의미한 성능향상을 달성함을 보여준다.1 INTRODUCTION 1
2 Background 6
 2.1 Memory Networks 6
 2.2 Deep Learning for NLP 9
3 A Fast and Scalable System Architecture for Memory-Augmented Neural Networks 14
 3.1 Motivation & Design Goals 14
  3.1.1 Performance Problems in MemNN - High Off-chip Memory Bandwidth Requirements 15
  3.1.2 Performance Problems in MemNN - High Computation 16
  3.1.3 Performance Problems in MemNN - Shared Cache Contention 17
  3.1.4 Design Goals 18
 3.2 MnnFast 19
  3.2.1 Column-Based Algorithm 19
  3.2.2 Zero Skipping 22
  3.2.3 Embedding Cache 25
 3.3 Implementation 26
  3.3.1 General-Purpose Architecture - CPU 26
  3.3.2 General-Purpose Architecture - GPU 28
  3.3.3 Custom Hardware (FPGA) 29
 3.4 Evaluation 31
  3.4.1 Experimental Setup 31
  3.4.2 CPU 33
  3.4.3 GPU 35
  3.4.4 FPGA 37
  3.4.5 Comparison Between CPU and FPGA 39
 3.5 Conclusion 39
4 A Fast, Scalable, and Flexible System for Large-Scale Heterogeneous NLP Models 40
 4.1 Motivation & Design Goals 40
  4.1.1 High Model Complexity 40
  4.1.2 High Memory Bandwidth 41
  4.1.3 Heavy Computation 42
  4.1.4 Huge Performance Variation 43
  4.1.5 Design Goals 43
 4.2 NLP-Fast 44
  4.2.1 Bottleneck Analysis of NLP Models 44
  4.2.2 Holistic Model Partitioning 47
  4.2.3 Cross-operation Zero Skipping 51
  4.2.4 Adaptive Hardware Reconfiguration 54
 4.3 NLP-Fast Toolkit 56
 4.4 Implementation 59
  4.4.1 General-Purpose Architecture - CPU 59
  4.4.2 General-Purpose Architecture - GPU 61
  4.4.3 Custom Hardware (FPGA) 62
 4.5 Evaluation 64
  4.5.1 Experimental Setup 65
  4.5.2 CPU 65
  4.5.3 GPU 67
  4.5.4 FPGA 69
 4.6 Conclusion 72
5 Related Work 73
 5.1 Various DNN Accelerators 73
 5.2 Various NLP Accelerators 74
 5.3 Model Partitioning 75
 5.4 Approximation 76
 5.5 Improving Flexibility 78
 5.6 Resource Optimization 78
6 Conclusion 80
Abstract (In Korean) 106Docto",,https://core.ac.uk/download/567568138.pdf,148024066,이종 자연어 처리 모델을 위한 확장형 컴퓨터 시스템 설계,2021-02-01T00:00:00,서울대학교 대학원,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We present three enhancements to existing encoder-decoder models for
open-domain conversational agents, aimed at effectively modeling coherence and
promoting output diversity: (1) We introduce a measure of coherence as the
GloVe embedding similarity between the dialogue context and the generated
response, (2) we filter our training corpora based on the measure of coherence
to obtain topically coherent and lexically diverse context-response pairs, (3)
we then train a response generator using a conditional variational autoencoder
model that incorporates the measure of coherence as a latent variable and uses
a context gate to guarantee topical consistency with the context and promote
lexical diversity. Experiments on the OpenSubtitles corpus show a substantial
improvement over competitive neural models in terms of BLEU score as well as
metrics of coherence and diversity",10.18653/v1/d18-1432,http://arxiv.org/abs/1809.06873,54153265,"better conversations by modeling,filtering,and optimizing for coherence
  and diversity",2018-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This discussion paper investigates two questions: To what extend can Tesla be regarded as a digital firm, and do we - as a result - see elements of a distinct ""Tesla production system""? While the EV-startup is widely approached as a competing automaker focusing on the electric drive train, which it certainly is, this paper argues that it can only fully be understood as a digital firm - a digital car company with a digital product embedded in a digital ecosystem. Its roots in Silicon Valley, its software-first approach, and its strategic exploitation of user activity data point into this direction. In the second part, this paper explores to what extent Tesla's rootedness in software and its Silicon-Valley ancestry gave reason to introduce methods borrowed from software development on the shop floor. To a certain degree, concepts from agile software development found their way to the very assembly-line at Tesla. Although it might be exaggerated to speak of a distinct ""Tesla Production system"", indications for a considerable and possibly enduring alteration of Lean Production paradigm can be determined",10.34669/wi.ws/31,https://core.ac.uk/download/551603490.pdf,136928665,"agile methods on the shop floor: towards a ""tesla production system""?",2022-01-01T00:00:00,Berlin,"[{'title': None, 'identifiers': ['issn:2748-5587', '2748-5587']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"HUMANS
Best of Bon Appetit, Nora Martin
Interview with the Dean of Lamson and Meier Halls, Interviewed by: Grace No
The Joy of Japan, Interviewed by: Gloria Oh
ARTS & ENTERTAINMENT
A Creation Adventure, Nathaniel Reid
Currently: Velma, Solana Campbell
Suite Dreams for Sweet Dreams, Skylor Stark
Where do I Find God? Part II, Anonymous
NEWS
AUSA Celebrates 100 Years of Student-Led Action, Andrew Francis
Response to  A House Divided  Story, Christon Arthur, Provost
Where\u27s the Harm in True Crime?. Abigail Kim
IDEAS
Redefining Free Agency in Sports, Andrew Francis
Flying Cars of 2030, Rachel Ingram-Clay
The Spooky Nature of Our Physical World, Alexander Navarro
The State of AI, Abby Shim
PULSE
Debunking Myths Surrounding J.N. Andrews Honors Program, Gloria Oh
Our Dear AU: A Spirit Week Tour, Lexie Dunham
Romance and Reading, Gloria Oh
LAST WORD
An Ode to Tea, Alexander J. Hesshttps://digitalcommons.andrews.edu/sm-107/1012/thumbnail.jp",,https://core.ac.uk/download/553610492.pdf,138566590,the student movement volume 107 issue 13: we\u27ve got the spirit: students celebrate dr. luxton,2023-01-26T08:00:00,Digital Commons @ Andrews University,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"While drawing from the philosophy of Bernard Stiegler throughout the paper, I commence by highlighting Zoltan Istvan’s representation of transhumanism in the light of its role in politics. I continue by elaborating on the notion of the promise of eternal life. After that I differentiate between subjects that are proper for philosophy (such as the mind or whether life is worth living) and science (measurable and replicable). The arguments mostly concern mind-uploading and at the same time I elaborate on a simple critique of mind-body dualism, which is one of the key imagined orders exploitable by technologies in the narratives of transhumanism present in popular culture. This is reframed as a problem of action. The focus of this article is on the claim that certain transhumanisms are dangerous forms of Neo-Darwinism. It comes from a critical assessment of capital and the exploitation of bodies through market forces. Entropy is a process of growing disorder, while neganthropy is an anthropological struggle against exploitation, not only of bodies, but of all ecosystems of the Earth. The arguments of Stiegler from a collection of lectures are recapitulated, and his claims are presented through the prism of transhuman narrative, with a particular focus on Christian Salmon's position in the book Storytelling: Bewitching the Modern Mind",,https://core.ac.uk/download/275570936.pdf,8877988,a stieglerianesque critique of transhumanisms: on narratives and neganthropocene,2019-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This study assesses that there are similarities between the Bauhaus movement and computational design. The similarities are discussed under the titles of hands-on activities, interdisciplinary studies and relation with technology for both Bauhaus and computational design. Digital technology is changing rapidly, and to catch the developing technology up the education system must be updated. Bauhaus can be a pathfinder for computational design education. Within this context, three educational organizations, KTU CODE FAB, IAAC and ICD, which were experienced personally, are examined. As a result of the study, it is reduced that; the innovative spirit of Bauhaus, which focuses on doing and hands-on activities, is also important for computational design education. The well-trained architects that accustomed to the new technology can be graduated with the integration with industry, similarly to the Bauhaus system",10.25034/ijcua.2019.v3n3-3,https://core.ac.uk/download/268449555.pdf,75122367,thinking on the correlation between bauhaus and computational design education,2019-01-01T00:00:00,'Alanya Hamdullah Emin Pasa Universitesi',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The world is now connected virtual and mobile, it is currently going through a fundamental transformation in the way we humans work, perform tasks and activities. Automation and ‘thinking machines’ are replacing basic human tasks and jobs, and changing the skills that organizations are looking for in their people. In this paper, the authors discuss current technological innovations and how our world is changing rapidly in all aspects. New set of skills is needed; hence the authors focus on crucial practices and skills that are needed to be taught to harness our children for the future. The authors emphasis on teachers and proposed an innovative model the TTT (Training Teachers to Train) model that could be used to train teachers on how to teach these skills to their students and how to embrace and connect effectively with the world. Innovations are discussed, crucial skills are identified and an innovative model is proposed",,https://core.ac.uk/download/346492861.pdf,96650466,towards an innovative approach for teacher education: training teacher to train (ttt) model,2018-01-01T08:00:00,ODU Digital Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Digital design tools are rapidly changing and blurring the boundaries between design disciplines. By extension, the relationship between humans and products is also changing, to the point where opportunities are emerging for products that can co-evolve with their human users over time. This chapter highlights how these ‘4D products' respond to the vision laid out three decades ago for ubiquitous computing, and have the potential to enhance human experiences by creating more seamless human-centered relationships with technology. These developments are examined in context with broader shifts in sociocultural and environmental concerns, as well as similar developments being researched in Responsive Architecture, 4D printing and systems designed to empower individuals during the design process through interactive, parametric model platforms. Technology is fundamentally changing the way designers create physical products, and new understandings are needed to positively guide these changes.Arts, Education & Law Group, Queensland College of ArtNo Full Tex",10.4018/978-1-5225-2838-8.ch018,http://dro.deakin.edu.au/eserv/DU:30120553/novak-digitaltechnologies-2018.pdf,39826576,digital technologies and 4d customized design: challenging conventions with responsive design,2018-01-01T00:00:00,'IGI Global',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Malicious actors exploit social media to inflate stock prices, sway
elections, spread misinformation, and sow discord. To these ends, they employ
tactics that include the use of inauthentic accounts and campaigns. Methods to
detect these abuses currently rely on features specifically designed to target
suspicious behaviors. However, the effectiveness of these methods decays as
malicious behaviors evolve. To address this challenge, we propose a general
language for modeling social media account behavior. Words in this language,
called BLOC, consist of symbols drawn from distinct alphabets representing user
actions and content. The language is highly flexible and can be applied to
model a broad spectrum of legitimate and suspicious online behaviors without
extensive fine-tuning. Using BLOC to represent the behaviors of Twitter
accounts, we achieve performance comparable to or better than state-of-the-art
methods in the detection of social bots and coordinated inauthentic behavior",,http://arxiv.org/abs/2211.00639,133980795,a general language for modeling social media account behavior,2022-11-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Digital education has been catalyzing educational transition, transforming the educational views and instructional techniques while also providing opportunities for high-quality educational development. This is a subject that all nations throughout the world are concerned about. The worldwide practice of integrating digital technologies in teaching has yielded positive results. The Global Digital Education Conference, which was held in Beijing, China, in 2023, called for global collaboration on digital education development. This paper sought to illustrate the significance of digital education for educational reform and to investigate ways for digital education development in this context, using China’s smart education practice as evidence",10.15354/sief.23.or095,https://core.ac.uk/download/555483890.pdf,141976096,development of digital education in the age of digital transformation: citing china’s practice in smart education as a case study,2023-02-28T00:00:00,'Bonoi Science Advancement and Education LLC',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Cross-Modal learning tasks have picked up pace in recent times. With plethora
of applications in diverse areas, generation of novel content using multiple
modalities of data has remained a challenging problem. To address the same,
various generative modelling techniques have been proposed for specific tasks.
Novel and creative image generation is one important aspect for industrial
application which could help as an arm for novel content generation. Techniques
proposed previously used Generative Adversarial Network(GAN), autoregressive
models and Variational Autoencoders (VAE) for accomplishing similar tasks.
These approaches are limited in their capability to produce images guided by
either text instructions or rough sketch images decreasing the overall
performance of image generator. We used state of the art diffusion models to
generate creative art by primarily leveraging text with additional support of
rough sketches. Diffusion starts with a pattern of random dots and slowly
converts that pattern into a design image using the guiding information fed
into the model. Diffusion models have recently outperformed other generative
models in image generation tasks using cross modal data as guiding information.
The initial experiments for this task of novel image generation demonstrated
promising qualitative results.Comment: Report Submitted for degree completion of Master of Science in
  Applied Computing at University of Toront",,http://arxiv.org/abs/2307.04978,144519355,diffusion idea exploration for art generation,2023-07-10T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In this work we focus on multi-turn passage retrieval as a crucial component
of conversational search. One of the key challenges in multi-turn passage
retrieval comes from the fact that the current turn query is often
underspecified due to zero anaphora, topic change, or topic return. Context
from the conversational history can be used to arrive at a better expression of
the current turn query, defined as the task of query resolution. In this paper,
we model the query resolution task as a binary term classification problem: for
each term appearing in the previous turns of the conversation decide whether to
add it to the current turn query or not. We propose QuReTeC (Query Resolution
by Term Classification), a neural query resolution model based on bidirectional
transformers. We propose a distant supervision method to automatically generate
training data by using query-passage relevance labels. Such labels are often
readily available in a collection either as human annotations or inferred from
user interactions. We show that QuReTeC outperforms state-of-the-art models,
and furthermore, that our distant supervision method can be used to
substantially reduce the amount of human-curated data required to train
QuReTeC. We incorporate QuReTeC in a multi-turn, multi-stage passage retrieval
architecture and demonstrate its effectiveness on the TREC CAsT dataset.Comment: SIGIR 2020 full conference pape",10.1145/3397271.3401130,https://core.ac.uk/download/489778616.pdf,85955747,query resolution for conversational search with limited supervision,2020-01-01T00:00:00,'Association for Computing Machinery (ACM)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"With each passing day, consumers, particularly students, expect more intelligent and personalized services. The key to providing such services is the concept of a personalized model. Applying appropriate personalized learning models to students is a process that is filled with many challenges. The main purpose of the current report is to explore the challenges that impede the design and implementation of models that are strictly customized to the interests of students. In order to achieve this goal, it is necessary to explore the contemporary factors that are essential in designing personalization models. The factors are mainly related to the requirements of the business towards professionalism among students, as well as the goals set by the state for the education improvement. In order to achieve this goal, it is also necessary to investigate the technologies by which the personalization of models is realized and by which successful implementation of the personalized models is ensured in the students' education",,https://core.ac.uk/download/389007630.pdf,108586741,modern challenges in the application of personalized models in student education for the benefit of business and society,2020-10-15T01:00:00,Izvestia Journal of the Union of Scientists - Varna. Economic Sciences Series,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The main purpose of this opening lecture is to clarify and comment on a number of aspects of the genesis, structure and use of the ATD that I believe deserve clarification. The current weight of common opinion in didactics, in fact, has sometimes led either to the forgetting of certain key elements of the anthropological theory of the didactic, or to a somewhat limited understanding of what it implies. The most visible effect of this phenomenon is the fact that the theoretical and practical use of the theory does not always seem optimal. In the following, I have therefore tried to identify and cope with a selection of these difficulties of reception, that I felt it was possible to address in a meaningful way in the context of this presentation",,https://core.ac.uk/download/529939063.pdf,130227191,on using the atd: some clarifications and comments,2019-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper presents the development and delivery of educational summer intensive programs for high school students that are designed to encourage students’ interests in the STEM-related fields and the motivation to pursue a STEM-related degrees in college. BLAST (Building Leaders to Advance Science and Technology) is designed as a summer-intensive, residential, on-campus STEM-learning experience for rising ninth and tenth graders. With the intention of improving the STEM-related workforce pipeline in the Commonwealth of Virginia, Virginia Space Grant Consortium (VSGC) offers multiple BLAST programs across the Commonwealth. BLAST programs are designed as intensive three-day, STEM-related three-hour lecture-lab experiences that are reinforced by evening STEM-related events. Funded by a grant by the National Aeronautics and Space Administration (NASA), VSGC targets approximately three hundred students annually who have a C+ or better average, and who have had no previous STEM-related experience. It is surmised that if more students are exposed to STEM-related fields, they may become more interested in and motivated to one-day pursue a STEM-related discipline which would help to alleviate the STEM-related workforce shortages in Virginia. BLAST is offered at three public universities in Virginia including the University of Virginia, Virginia Tech, and Old Dominion University. Faculty and graduate students at each of the respective universities design and implement programs that draw upon their respective faculty interests and strengths. In this paper, a content analysis of the various BLAST programs and interviews with the directors and faculty involved were conducted to identify common and unique strengths across the different BLAST programs. Impacts of COVID on the development and delivery of the BLAST programs are addressed, as are suggestions for program improvements. The purpose of this paper is to share the results of perceived impacts of the BLAST programs on increasing high school students\u27 interest in STEM-related fields and to increase their motivation in the pursuit of STEM-related college degrees. If the U.S. is to be successful at improving its STEM-ready workforce, one solution is to increase the number of high school students pursuing a STEM-related degree and career",,https://core.ac.uk/download/553612388.pdf,138594074,"blast-building leaders for advancing science and technology: a partnership between the virginia space grant consortium and the university of virginia, virginia polytechnic institute, and old dominion university",2022-01-01T08:00:00,ODU Digital Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"© 2018 Elsevier B.V. Community Question Answering (CQA) websites can be claimed as the most major venues for knowledge sharing, and the most effective way of exchanging knowledge at present. Considering that massive amount of users are participating online and generating huge amount data, management of knowledge here systematically can be challenging. Expert recommendation is one of the major challenges, as it highlights users in CQA with potential expertise, which may help match unresolved questions with existing high quality answers while at the same time may help external services like human resource systems as another reference to evaluate their candidates. In this paper, we in this work we propose to exploring experts in CQA websites. We take advantage of recent distributed word representation technology to help summarize text chunks, and in a semantic view exploiting the relationships between natural language phrases to extract latent knowledge domains. By domains, the users’ expertise is determined on their historical performance, and a rank can be compute to given recommendation accordingly. In particular, Stack Overflow is chosen as our dataset to test and evaluate our work, where inclusive experiment shows our competence",10.1016/j.patrec.2018.10.030,https://opus.lib.uts.edu.au/bitstream/10453/130239/1/SO-with-cover.pdf,16185354,software expert discovery via knowledge domain embeddings in a collaborative network,2020-01-01T00:00:00,'Elsevier BV',"[{'title': 'Pattern Recognition Letters', 'identifiers': ['issn:0167-8655', '0167-8655']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This paper argues that machine translation and a symbiotic ecosystem of authorship are central to the poetic works of Aaron Tucker and reveal larger ethical paths for machine-human relationships. In particular, the elements of chance alongside the intersemiotic translative acts that are the nature of human-computer relationships give space to a potential futurity that challenges a human-centric understanding of “reading” and “writing” and generates a type of literature that encourages a reader to better understand their own interactions within their daily digital environments",,https://core.ac.uk/download/232143708.pdf,7965624,machine co-authorship(s) via translative creative writing,2019-09-24T00:41:55,RIT Scholar Works,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In this Strategic Update, General Sir Richard Barrons warns that our military capabilities must be comprehensively rethought, or we will all be at risk. He sets out 8 principles for how to create an effective military for the digital age",,https://core.ac.uk/download/360309428.pdf,18718070,victors and victims: creating a military for the digital age,2018-02-01T00:00:00,"LSE IDEAS, London School of Economics and Political Science",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This article studies orientalism constructed in the novel of Digital Fortress that is written by Dan Brown. Orientalism discourse appears in the literary works through narrative events and conversations of the Western and the Eastern. Ensei Tankado, a Japanese character, will be presented in this study in the lens of Western. The aim is to explore orientalism discourse in the novel to get an understanding of the ideology interest as part of the Western power. Theory of Orientalism by Edward Said is applied in this study. It modifies Foucauldian discourse theory and Gramscian hegemony. The four concept of Orientalism discourse including political power, intellectual power, cultural power and moral power will be used in this study. How the Eastern subject is positioned by the Western in Digital Fortress becomes the focus. Japanese and the United States in the novel can be related to the contextual condition that cultural domination and hegemony still occur between Japan-USA since World War II. Orientalism in the literary works is a new imperialism. The goal of this study is to reveal that the novel brings cultural domination",10.20961/hsb.v6i1.57158,https://core.ac.uk/download/523116521.pdf,121466712,the construction of orientalism in dan brown’s digital fortress,2022-06-27T01:00:00,'Universitas Sebelas Maret',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Recommendation algorithms play an increasingly central role in our societies.
However, thus far, these algorithms are mostly designed and parameterized
unilaterally by private groups or governmental authorities. In this paper, we
present an end-to-end permissionless collaborative algorithmic governance
method with security guarantees. Our proposed method is deployed as part of an
open-source content recommendation platform https://tournesol.app, whose
recommender is collaboratively parameterized by a community of (non-technical)
contributors. This algorithmic governance is achieved through three main steps.
First, the platform contains a mechanism to assign voting rights to the
contributors. Second, the platform uses a comparison-based model to evaluate
the individual preferences of contributors. Third, the platform aggregates the
judgements of all contributors into collective scores for content
recommendations. We stress that the first and third steps are vulnerable to
attacks from malicious contributors. To guarantee the resilience against fake
accounts, the first step combines email authentication, a vouching mechanism, a
novel variant of the reputation-based EigenTrust algorithm and an adaptive
voting rights assignment for alternatives that are scored by too many untrusted
accounts. To provide resilience against malicious authenticated contributors,
we adapt Mehestan, an algorithm previously proposed for robust sparse voting.
We believe that these algorithms provide an appealing foundation for a
collaborative, effective, scalable, fair, contributor-friendly, interpretable
and secure governance. We conclude by highlighting key challenges to make our
solution applicable to larger-scale settings.Comment: 31 pages, 5 figure",,http://arxiv.org/abs/2211.01179,133994539,"tournesol: permissionless collaborative algorithmic governance with
  security guarantees",2022-10-30T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Passive microwave radiometry (MWR) measures natural emissions in the range 1–10 GHz from proteins, cells, organs and the whole human body. The intensity of intrinsic emission is determined by biochemical and biophysical processes. The nature of this process is still not very well known. Infrared thermography (IRT) can detect emission several microns deep (skin temperature), whereas MWR allows detection of thermal abnormalities down to several centimeters (internal or deep temperature). MWR is noninvasive and inexpensive. It requires neither fluorescent nor radioactive labels, nor ionizing or other radiation. MWR can be used in early drug discovery as well as preclinical and clinical studies",10.1016/j.drudis.2020.01.016,https://core.ac.uk/download/354517999.pdf,9017260,passive microwave radiometry in biomedical studies,2020-01-28T00:00:00,'Elsevier BV',"[{'title': 'Drug Discovery Today', 'identifiers': ['1359-6446', 'issn:1359-6446']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"E-marketplaces have become an essential part of e-commerce. In our research a decentralised agent-based e-marketplace platform was devised. The goal of our research is to improve overall supply chain service quality by allowing companies\u27 agents to evaluate the service quality of their partners through the history of their transactions. Consequently, since more informed decisions are taking place continuously and autonomously, supply chain service quality is being improved along the whole supply chain. In the article a service quality evaluation model of a supply chain is empirically evaluated",10.17559/tv-20171201150248,https://core.ac.uk/download/212499608.pdf,61602370,an approach to e-marketplace automation,2019-01-01T00:00:00,'Mechanical Engineering Faculty in Slavonski Brod',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Manipulated videos often contain subtle inconsistencies between their visual
and audio signals. We propose a video forensics method, based on anomaly
detection, that can identify these inconsistencies, and that can be trained
solely using real, unlabeled data. We train an autoregressive model to generate
sequences of audio-visual features, using feature sets that capture the
temporal synchronization between video frames and sound. At test time, we then
flag videos that the model assigns low probability. Despite being trained
entirely on real videos, our model obtains strong performance on the task of
detecting manipulated speech videos. Project site:
https://cfeng16.github.io/audio-visual-forensicsComment: CVPR 202",,http://arxiv.org/abs/2301.01767,141820123,self-supervised video forensics by audio-visual anomaly detection,2023-03-27T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"An important constraint of Fuzzy Inference Systems (FIS) is their structured
rules defined based on evaluating all input variables. Indeed, the length of
all fuzzy rules and the number of input variables are equal. However, in many
decision-making problems evaluating some conditions on a limited set of input
variables is sufficient to decide properly (unstructured rules). Therefore,
this constraint limits the performance, generalization, and interpretability of
the FIS. To address this issue, this paper presents a neuro-fuzzy inference
system for classification applications that can select different sets of input
variables for constructing each fuzzy rule. To realize this capability, a new
fuzzy selector neuron with an adaptive parameter is proposed that can select
input variables in the antecedent part of each fuzzy rule. Moreover, in this
paper, the consequent part of the Takagi-Sugeno-Kang FIS is also changed
properly to consider only the selected set of input variables. To learn the
parameters of the proposed architecture, a trust-region-based learning method
(General quasi-Levenberg-Marquardt (GqLM)) is proposed to minimize
cross-entropy in multiclass problems. The performance of the proposed method is
compared with some related previous approaches in some real-world
classification problems. Based on these comparisons the proposed method has
better or very close performance with a parsimonious structure consisting of
unstructured fuzzy",,http://arxiv.org/abs/2211.00599,133983227,"unfis: a novel neuro-fuzzy inference system with unstructured fuzzy
  rules for classification",2022-10-28T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"International audienceIn a variety of reasoning tasks, one estimates the likelihood of events by means of volumes of sets they define. Such sets need to be measurable, which is usually achieved by putting bounds, sometimes ad hoc, on them. We address the question how unbounded or unmeasurable sets can be measured nonetheless. Intuitively, we want to know how likely a randomly chosen point is to be in a given set, even in the absence of a uniform distribution over the entire space. To address this, we follow a recently proposed approach of taking intersection of a set with balls of increasing radius, and defining the measure by means of the asymptotic behavior of the proportion of such balls taken by the set. We show that this approach works for every set definable in first-order logic with the usual arithmetic over the reals (addition, multiplication, exponentiation, etc.), and every uniform measure over the space, of which the usual Lebesgue measure (area, volume, etc.) is an example. In fact we establish a correspondence between the good asymptotic behavior and the finiteness of the VC dimension of definable families of sets. Towards computing the measure thus defined, we show how to avoid the asymptotics and characterize it via a specific subset of the unit sphere. Using definability of this set, and known techniques for sampling from the unit sphere, we give two algorithms for estimating our measure of unbounded unmeasurable sets, with deterministic and probabilistic guarantees, the latter being more efficient. Finally we show that a discrete analog of this measure exists and is similarly well-behaved",10.24963/kr.2020/27,https://core.ac.uk/download/363992435.pdf,9017169,reasoning about measures of unmeasurable sets,2020-09-12T00:00:00,'International Joint Conferences on Artificial Intelligence',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"“Fintech” refers to a variety of digital assets, technologies, and infrastructure that deal with the operation of today’s financial markets. The regulation of this presents both legal and regulatory challenges. This article examines the regulatory responses to fintech disruption; specifically, the “experimentation” approach, the “incorporation” approach, and the “accommodation” approach. These approaches provide a baseline for further discussion and policy analysis in response to “Fintech.",,https://core.ac.uk/download/323868161.pdf,86201791,dealing with disruption: emerging approaches to fintech regulation,2020-01-01T08:00:00,Scholarship@Cornell Law: A Digital Repository,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Modernity and Contemporaneity is the 3rd volume in the Hellenic-Serbian Philosophical Dialogue Series, a project that was initiated as an emphatic token of the will and commitment to establish permanent and fruitful collaboration between two strongly bonded Departments of Philosophy, this of the National and Kapodistrian University of Athens, and that of the University of Novi Sad respectively. This collaboration was founded from the very beginning upon friendship, mutual respect and strong engagement, as well us upon our firm resolution to establish a solid continuity in the editing project. The publication of this volume allows us to entertain feelings of contentment and confidence that this objective of the project has been accomplished.Publishe",10.12681/aprlp.82,https://core.ac.uk/download/534900387.pdf,131204008,modernity and contemporaneity,2022-09-03T02:04:53,'National Documentation Centre (EKT)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Erich Fromm (1900-1980) was a Marxist psychoanalyst, philosopher and socialist humanist. This paper asks: How can Fromm’s critical theory of communication be used and updated to provide a critical perspective in the age of digital and communicative capitalism?
In order to provide an answer, the article discusses elements from Fromm’s work that allow us to better understand the human communication process. The focus is on communication (section 2), ideology (section 3), and technology (section 4). Fromm’s approach can inform a critical theory of communication in multiple respects: His notion of the social character allows to underpin such a theory with foundations from critical psychology. Fromm’s distinction between the authoritarian and the humanistic character can be used for discerning among authoritarian and humanistic communication. Fromm’s work can also inform ideology critique: The ideology of having shapes life, thought, language and social action in capitalism. In capitalism, technology (including computing) is fetishized and the logic of quantification shapes social relations. Fromm’s quest for humanist technology and participatory computing can inform contemporary debates about digital capitalism and its alternatives",10.1177/0160597620930157,https://core.ac.uk/download/266398550.pdf,8386911,erich fromm and the critical theory of communication,2020-01-01T00:00:00,'SAGE Publications',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Architecture's privileged position as the technology of space-making is challenged by the current proliferation of a wide range of mobile, embedded, networked and distributed media, communication and information systems. Our interactions with (and through) these location-based, context-aware and otherwise ”situated” technologies are beginning to alter the way we perceive, navigate and socialize within the built environment. Prompting a reconfiguration of material boundaries, organizational adjacencies, and public/private relations, these technologies (and the ways in which we engage them) have significant implications for how we conceive, design and experience space. In this paper, we identify three vectors for architectural research that explore the spatial opportunities presented by what we call Situated Technologies. Working across the overlapping boundaries of media, architecture and computing, this research attempts to articulate how architects might play a critical role in shaping evolving techno-social spaces increasingly governed by both material and immaterial processes. As exploratory research, it aims less to propose solutions to known problems than to arrive at precise questions that help us better identify and structure new problems for architecture presented by recent developments in ubiquitous/ pervasive computing",,https://core.ac.uk/download/295185702.pdf,126430522,situated technologies,2019-06-14T01:00:00,Architectural Research Centers Consortium,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Parameter-shared pre-trained language models (PLMs) have emerged as a
successful approach in resource-constrained environments, enabling substantial
reductions in model storage and memory costs without significant performance
compromise. However, it is important to note that parameter sharing does not
alleviate computational burdens associated with inference, thus impeding its
practicality in situations characterized by limited stringent latency
requirements or computational resources. Building upon neural ordinary
differential equations (ODEs), we introduce a straightforward technique to
enhance the inference efficiency of parameter-shared PLMs. Additionally, we
propose a simple pre-training technique that leads to fully or partially shared
models capable of achieving even greater inference acceleration. The
experimental results demonstrate the effectiveness of our methods on both
autoregressive and autoencoding PLMs, providing novel insights into more
efficient utilization of parameter-shared models in resource-constrained
settings.Comment: EMNLP 2023 Finding",,http://arxiv.org/abs/2310.12818,152091285,"boosting inference efficiency: unleashing the power of parameter-shared
  pre-trained language models",2023-10-19T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The evaluation of noisy binary classifiers on unlabeled data is treated as a
streaming task: given a data sketch of the decisions by an ensemble, estimate
the true prevalence of the labels as well as each classifier's accuracy on
them. Two fully algebraic evaluators are constructed to do this. Both are based
on the assumption that the classifiers make independent errors. The first is
based on majority voting. The second, the main contribution of the paper, is
guaranteed to be correct. But how do we know the classifiers are independent on
any given test? This principal/agent monitoring paradox is ameliorated by
exploiting the failures of the independent evaluator to return sensible
estimates. A search for nearly error independent trios is empirically carried
out on the \texttt{adult}, \texttt{mushroom}, and \texttt{two-norm} datasets by
using the algebraic failure modes to reject evaluation ensembles as too
correlated. The searches are refined by constructing a surface in evaluation
space that contains the true value point. The algebra of arbitrarily correlated
classifiers permits the selection of a polynomial subset free of any
correlation variables. Candidate evaluation ensembles are rejected if their
data sketches produce independent estimates too far from the constructed
surface. The results produced by the surviving ensembles can sometimes be as
good as 1\%. But handling even small amounts of correlation remains a
challenge. A Taylor expansion of the estimates produced when independence is
assumed but the classifiers are, in fact, slightly correlated helps clarify how
the independent evaluator has algebraic `blind spots'.Comment: 23 pages, 5 figure",,http://arxiv.org/abs/2306.01726,143551657,"streaming algorithms for evaluating noisy judges on unlabeled data --
  binary classification",2023-06-02T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Large Language Models (LLMs) have not only exhibited exceptional performance
across various tasks, but also demonstrated sparks of intelligence. Recent
studies have focused on assessing their capabilities on human exams and
revealed their impressive competence in different domains. However, cognitive
research on the overall knowledge structure of LLMs is still lacking. In this
paper, based on educational diagnostic assessment method, we conduct an
evaluation using MoocRadar, a meticulously annotated human test dataset based
on Bloom Taxonomy. We aim to reveal the knowledge structures of LLMs and gain
insights of their cognitive capabilities. This research emphasizes the
significance of investigating LLMs' knowledge and understanding the disparate
cognitive patterns of LLMs. By shedding light on models' knowledge, researchers
can advance development and utilization of LLMs in a more informed and
effective manner.Comment: Findings of EMNLP 2023 (Short Paper",,http://arxiv.org/abs/2310.08172,152091506,"exploring the cognitive knowledge structure of large language models: an
  educational diagnostic assessment approach",2023-10-18T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Programming environments have evolved from purely text based to using graphical user interfaces, and now we see a move towards web based interfaces, such as Jupyter. Web based interfaces allow for the creation of interactive documents that consist of text and programs, as well as their output. The output can be rendered using web technology as, e.g., text, tables, charts or graphs. This approach is particularly suitable for capturing data analysis  workflows  and  creating  interactive  educational  material.  This  article  describes SWISH, a web front-end for Prolog that consists of a web server implemented in SWI-Prolog and a client web application written in JavaScript. SWISH provides a web server where multiple users can manipulate and run the same material, and it can be adapted to support Prolog extensions. In this paper we describe the architecture of SWISH, and

describe two case studies of extensions of Prolog, namely Probabilistic Logic Programming (PLP) and Logic Production System (LPS), which have used SWISH to provide tutorial sites",,https://core.ac.uk/download/301650884.pdf,84375725,using swish to realise interactive web based tutorials for logic based languages,2018-08-24T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Technological developments and global competition are challenges in this digital era that require Indonesia’s young generation preparing themselves to compete in this disruptive era. The Merdeka Curriculum (Freedom to Learn) at Schools and the Merdeka Belajar Kampus Merdeka (MBKM) Curriculum (Freedom to Learn) at Universities in Indonesia are implemented to prepare students to have future competencies consisting of knowledge, skills, attitudes, and values which are called as the 2030 Learning Compass. This study aims to describe the relationship between the Management policies of Merdeka and the MBKM curriculum with Learning Compass 2030. Eight policy documents related to the management of the aforementioned curriculum were analyzed through the document analysis method with an interpretive approach to reveal how the latest curriculum management policies can achieve the goals of Learning Compass 2030. The results obtained are regulations issued by the Indonesian government regarding curriculum management possibly achieving competencies consisting of knowledge, skills, attitudes, and values if planning, implementing, evaluating, and controlling are in ideal condition",10.17977/um072v4i22023p93-106,https://core.ac.uk/download/578581519.pdf,148415521,relation of learning compass 2030 and management regulation of merdeka curriculum for school and higher education in indonesia,2023-06-24T01:00:00,Universitas Negeri Malang,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
https://soundideas.pugetsound.edu/thetrail_all/3504/thumbnail.jp,,https://core.ac.uk/download/216863555.pdf,80482088,"the trail, 2018-11-09",2018-11-09T08:00:00,Sound Ideas,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The events of Do Not Say We Have Nothing by Madeleine Thien and Their Eyes Were Watching God by Zora Neale Hurston depict characters who, through subversive approaches to storytelling and meaning-making, refute the stereotypes attributed to them by oppressive sociopolitical systems. Whether the story extends through families and generations in China or simply from one friend to another on a porch in Eatonville, Florida, the story complicates listeners’ initial assumptions about individual and cultural mechanisms",,https://core.ac.uk/download/229377139.pdf,132707175,stories to the remote reader: shaping cultural narratives in  do not say we have nothing  and  their eyes were watching god,2018-10-01T08:00:00,Pillars at Taylor University,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Nowadays, we can see a huge amount of
customized services in lots of applications. A more customized
experience get a real full satisfaction to the customers.
The project was born with the aim of providing this kind of
service. Thus a client takes part in the decision‐ making of the
local songs, creating a playlist with songs ordered as the
customer’s data preferences.
The way is easy: a customer who enters the premises, install
the software that local provides and then he has to indicate their
customer likes and get it transmitted via Bluetooth. This
information is received by the customer attention server and it
generates a playlist with personalized songs",,https://core.ac.uk/download/228342211.pdf,66805046,imusic: a bluetooth music application,2019-09-18T13:50:11,International Journal of Interactive Multimedia and Artificial Intelligence (IJIMAI),"[{'title': 'International Journal of Interactive Multimedia and Artificial Intelligence', 'identifiers': ['issn:1989-1660', '1989-1660']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Reasoning is a distinctive human capacity, enabling us to address complex
problems by breaking them down into a series of manageable cognitive steps.
Yet, complex logical reasoning is still cumbersome for language models. Based
on the dual process theory in cognitive science, we are the first to unravel
the cognitive reasoning abilities of language models. Our framework employs an
iterative methodology to construct a Cognitive Tree (CogTree). The root node of
this tree represents the initial query, while the leaf nodes consist of
straightforward questions that can be answered directly. This construction
involves two main components: the implicit extraction module (referred to as
the intuitive system) and the explicit reasoning module (referred to as the
reflective system). The intuitive system rapidly generates multiple responses
by utilizing in-context examples, while the reflective system scores these
responses using comparative learning. The scores guide the intuitive system in
its subsequent generation step. Our experimental results on two popular and
challenging reasoning tasks indicate that it is possible to achieve a
performance level comparable to that of GPT-3.5 (with 175B parameters), using a
significantly smaller language model that contains fewer parameters (<=7B) than
5% of GPT-3.5.Comment: emnlp 202",,http://arxiv.org/abs/2311.06754,153550177,"from complex to simple: unraveling the cognitive tree for reasoning with
  small language models",2023-11-12T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"© 2023 IEEE. This is the accepted manuscript version of an article which has been published in final form at https://doi.org/10.1109/TG.2023.3329763Game content has long been created using procedural generation. However, many of these systems are currently designed in an ad-hoc manner, and there is a lack of knowledge around the design criteria that lead to generators producing the most successful results. In this study, we conduct a qualitative examination of the comments left by judges for the 2018--2020 \textit{Generative Design in Minecraft} competition. Using abductive thematic analysis, we identify the core design criteria that contribute to a generator that creates ``good'' content -- here defined as interesting or engaging. By performing this study, we have identified that the core design criteria that create and interesting settlement are usability of the settlement environment, the thematic coherence within the settlement, and an anchoring in real-world simulacra.Peer reviewe",10.1109/tg.2023.3329763,https://core.ac.uk/download/590957394.pdf,150059041,an examination of the hidden judging criteria in the generative design in minecraft competition,2023-11-07T00:00:00,,"[{'title': 'IEEE Transactions on Games', 'identifiers': ['2475-1502', 'issn:2475-1502']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Treball final de Grau en Disseny i Desenvolupament de Videojocs. Codi: VJ1241. Curs acadèmic: 2021/2022This document presents the final report for the Video Games Design and Development
Degree Final Project by Jesús Otero Benítez. It describes the development and design path of a third-person exploration and action videogame with the provisional title
""Walker"". It is an exercise that aims to explore in depth what it means to carry out design and worldbuilding work. A performance that seeks to awaken the player’s curiosity
and interest in the game",,https://core.ac.uk/download/570977569.pdf,150486059,videogame design and writing of a complete project,2022-07-13T01:00:00,'Universitat Jaume I',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Imagine yourself wherever you were 20 years ago, and that an entrepreneurial, fresh-faced, and friendly young newsboy comes to your doorstep. He asks you to subscribe to the local paper. There is no cost to this subscription, he says, but, in exchange for community news, the boy must be allowed to come into your house and look at all of your photos, even the most intimate ones, making duplicates for his boss as he sees fit. As a part of this transaction, he also gets to copy down all of the details from your desk calendar, your Rolodex, your letters, your diary, your to-do lists, your bookcase, your documents from work, anything he comes across that he finds interesting. He gets to follow you around and gather even more information about what you do, where you go, and when. He can do all of this for as long as he wants, in whatever depth he wants, and however he wants, and then can use this information freely for some vague commercial purpose. For just a free subscription, would you have taken this deal",10.1177/1077699019898773,https://core.ac.uk/download/544229881.pdf,132916664,"locative-media ethics: a call for protocols to guide interactions of people, place, and technologies",2020-01-01T00:00:00,Clemson University Libraries,"[{'title': 'Journalism & Mass Communication Quarterly', 'identifiers': ['issn:1077-6990', '1077-6990']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Aquest projecte aporta el disseny i la construcció d’un vehicle de tipus submarí per tal de rastrejar o visualitzar el fons marí amb fins arqueològics, d´inspecció i de presa de dades en zones marines sensibles. el rov (vehicle operat remotament) està pensat per ser dotat amb un sistema electrònic a bord per tal d’aconseguir tals funcions. el projecte ha estat desenvolupat amb criteris de disseny naval per tal d’assolir l’acompliment dels propòsits a sota l’aigua, garantint la integritat del vehicle i dels sensors instal·lats. el document conté els plànols generats de forma clara i concisa. a més a més, s’ha creat una web amb una base de dades, constituïda per diferents ordinadors, que connectats entre sí poden comunicar-se, i a través de la presa de dades amb els diferents dispositius electrònics generen aquesta base de dades. també s’ha aconseguit fer funcionar els diferents propulsors amb un comandament de playstation. aquest control, mitjançant la interfície gràfica, també creada explícitament per aquest projecte, permet visualitzar en pantalla les diferents tasques que realitza el dispositiu. aquest projecte persegueix el format d’accés obert, significant això que tots els dibuixos i la informació necessària i desenvolupada en aquest projecte són accessibles per tal d’aconseguir el producte que es presenta a continuació. els arxius necessaris i tot el codi desenvolupat es troben tant en aquest mateix document com al següent enllaç: https://github.com/crodriguezconde/finaldegreeprojec",,https://core.ac.uk/download/237677973.pdf,72004570,design and implementation of a remotely operated vehicle for marine exploration and archaeological research,2019-10-01T01:00:00,Universitat Politècnica de Catalunya,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
https://dc.suffolk.edu/sam/1051/thumbnail.jp,,https://core.ac.uk/download/480665324.pdf,129715969,"suffolk university alumni magazine, fall 2020",2020-01-01T08:00:00,Digital Collections @ Suffolk,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The joint task of Dialog Sentiment Classification (DSC) and Act Recognition
(DAR) aims to predict the sentiment label and act label for each utterance in a
dialog simultaneously. However, current methods encode the dialog context in
only one direction, which limits their ability to thoroughly comprehend the
context. Moreover, these methods overlook the explicit correlations between
sentiment and act labels, which leads to an insufficient ability to capture
rich sentiment and act clues and hinders effective and accurate reasoning. To
address these issues, we propose a Bi-directional Multi-hop Inference Model
(BMIM) that leverages a feature selection network and a bi-directional
multi-hop inference network to iteratively extract and integrate rich sentiment
and act clues in a bi-directional manner. We also employ contrastive learning
and dual learning to explicitly model the correlations of sentiment and act
labels. Our experiments on two widely-used datasets show that BMIM outperforms
state-of-the-art baselines by at least 2.6% on F1 score in DAR and 1.4% on F1
score in DSC. Additionally, Our proposed model not only improves the
performance but also enhances the interpretability of the joint sentiment and
act prediction task.Comment: Accepted by NLPCC 202",,http://arxiv.org/abs/2308.04424,145193880,"a bi-directional multi-hop inference model for joint dialog sentiment
  classification and act recognition",2023-08-12T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This chapter examines the “object-disoriented ontology” of Jacques Lacan and Georg Wilhelm Friedrich Hegel in relation to Spike Jonze’s film, Her (2013), and the recent objectal turn in contemporary philosophy. It argues that the smartphone AI of Jonze’s technofable presents what Lacan calls the “lathouse” (object-cause of desire governed by science) according to a Lacanian “masculine” logic that relies on reference to the beyond, which is equally found in Quentin Meillassoux’s “speculative materialism”. This is critiqued through the dialectical materialism of the Slovene School, which instead situates both subject and object as immanent to a “feminine” logic of contradiction",10.14361/9783839464762,https://core.ac.uk/download/595949564.pdf,152447236,"that obscure object of ontology: lacan, la femme, lathouse and her",2023-01-01T00:00:00,Transcript Verlag,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Abstrak. Penggunaan media sosial semakin meningkat dari tahun ke tahun, namun demikian tidak semua konten media sosial memiliki sisi positif. Beberapa dampak negatif penggunaan media sosial seperti penyebaran berita bohong (hoax), ujaran kebencian (hate speech), perundungan (cyberbullying) dan konten negatiflainnya merupakan bentuk-bentuk penyalahgunaan media sosial menjadi keprihatinan masyarakat karena telah memasuki  ranah sosial, politik, ekonomi dan bahkan keagamaan. Hal ini tidak terlepas dari kapitalisasi koorporasi media sosial yang terus berkembang dengan terpaan yang semakin meluas melintasi batas negara dan bangsa, masuk dalam kehidupan berbagai generasi, strata sosial ekonomi, tingkat pendidikan dan latar belakang pendidikan serta pengalaman. Metode yang digunakan dalam tulisan ini adalah teoritis kualitatif yang didasarkan pada pengamatan terhadap isi media sosial dan kajian teoritis yang berusaha menjelaskan pengaruh isi media terhadap perilaku masyarakat dalam bermedia sebagai bahan pengayaan  (enrichment) bagi kegiatan literasi media sosial di kalangan masyarakat bagi para pegiat literasi. Penjelasan teoritis yang dipakai meliputi aspek positif dan negatif dilihat dari aspek sosial, politik, psikologi, pendidikan dan kebudayaan. Hasilnya konten budaya lokal memiliki peluang mengisi konten dalam ruang media sosial dan konten budaya lokal yang selektif, kreatif, edukatif, dan sekaligus menghibur  dapat digunakan untuk meminimalkan dampak negatif globalisasi dan kapitalisme media sosial. Manfaat lain dari sosialisasi dari promosi budaya lokal di media sosial adalah untuk meningkatkan integrasi masyarakat karena didalamnya terdapat nilai-nilai kearifan lokal yang memiliki nilai bersifat nasional bahkan universal.Abstract. Social media uses have been increasing from year to year. However, not all social media content has a positive side. Some negative effects of social media from hoaxes, hate speech, cyberbullying to other negative content are the forms of abuse of social media. It is concern to the public because these have entered the social, political, economic and religious spheres. It is definitely inseparable from the capitalization of a social media corporation. It has been developing with increasingly widespread exposure across national borders, and it has been entering into the lives of various generations, socio-economic strata, education levels and educational backgrounds and experiences as well. The research method used in this research was a qualitative theoretical approach based on observations of social media content and theoretical studies. It aims at seeking to explain the influence of media content on people's behavior in their media use as the enrichment material for social media literacy activities in society for literacy activists. The theoretical explanations used in this research include positive and negative aspects. In this matter the social, political, psychological, educational and cultural perspectives will see the aspects. Moreover, the research results show that local cultural content has the opportunity to fill content in the social media space. Selective, creative, educative, and entertaining local cultural content can be used to minimize the negative effects of globalization and social media capitalism. Another benefit of socialization of local culture promotion on social media is to increase social integration because in the local culture there are local wisdom values and national or universal values as well",10.14421/pjk.v13i1.1742,https://core.ac.uk/download/352901991.pdf,129220489,local culture-based social media literation: local culture content on social media as strengthening social integration,2020-01-01T00:00:00,'Al-Jamiah Research Centre',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Autoregressive Transformers are strong language models but incur O(T)
complexity during per-token generation due to the self-attention mechanism.
Recent work proposes kernel-based methods to approximate causal self-attention
by replacing it with recurrent formulations with various update rules and
feature maps to achieve O(1) time and memory complexity. We explore these
approaches and find that they are unnecessarily complex, and propose a simple
alternative - decaying fast weights - that runs fast on GPU, outperforms prior
methods, and retains 99% of attention's performance for GPT-2. We also show
competitive performance on WikiText-103 against more complex attention
substitutes",,http://arxiv.org/abs/2210.04243,132290609,fine-tuning pre-trained transformers into decaying fast weights,2022-10-09T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We present an approach for detecting human-object interactions (HOIs) in
images, based on the idea that humans interact with functionally similar
objects in a similar manner. The proposed model is simple and efficiently uses
the data, visual features of the human, relative spatial orientation of the
human and the object, and the knowledge that functionally similar objects take
part in similar interactions with humans. We provide extensive experimental
validation for our approach and demonstrate state-of-the-art results for HOI
detection. On the HICO-Det dataset our method achieves a gain of over 2.5%
absolute points in mean average precision (mAP) over state-of-the-art. We also
show that our approach leads to significant performance gains for zero-shot HOI
detection in the seen object setting. We further demonstrate that using a
generic object detector, our model can generalize to interactions involving
previously unseen objects.Comment: AAAI 202",10.1609/aaai.v34i07.6616,http://arxiv.org/abs/1904.03181,58966340,detecting human-object interactions via functional generalization,2020-04-03T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We introduce DEsignBench, a text-to-image (T2I) generation benchmark tailored
for visual design scenarios. Recent T2I models like DALL-E 3 and others, have
demonstrated remarkable capabilities in generating photorealistic images that
align closely with textual inputs. While the allure of creating visually
captivating images is undeniable, our emphasis extends beyond mere aesthetic
pleasure. We aim to investigate the potential of using these powerful models in
authentic design contexts. In pursuit of this goal, we develop DEsignBench,
which incorporates test samples designed to assess T2I models on both ""design
technical capability"" and ""design application scenario."" Each of these two
dimensions is supported by a diverse set of specific design categories. We
explore DALL-E 3 together with other leading T2I models on DEsignBench,
resulting in a comprehensive visual gallery for side-by-side comparisons. For
DEsignBench benchmarking, we perform human evaluations on generated images in
DEsignBench gallery, against the criteria of image-text alignment, visual
aesthetic, and design creativity. Our evaluation also considers other
specialized design capabilities, including text rendering, layout composition,
color harmony, 3D design, and medium style. In addition to human evaluations,
we introduce the first automatic image generation evaluator powered by GPT-4V.
This evaluator provides ratings that align well with human judgments, while
being easily replicable and cost-efficient. A high-resolution version is
available at
https://github.com/design-bench/design-bench.github.io/raw/main/designbench.pdf?download=Comment: Project page at https://design-bench.github.io",,http://arxiv.org/abs/2310.15144,152813572,"designbench: exploring and benchmarking dall-e 3 for imagining visual
  design",2023-10-23T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"+ Data is not a property but a relation

+ Beyond data anxiety

+ Data citizens: emerging socialities and sovereignties

+ The rise and enclosure of user-generated publics

+ Dispossessing data

+ Dataism and the legitimacy of claim",10.4324/9780429196515,https://core.ac.uk/download/372706707.pdf,8161705,introduction: data is not a property but a relation,2020-06-10T00:00:00,'Informa UK Limited',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Volume 160, Issue 11https://scholarworks.sjsu.edu/spartan_daily_2023/1010/thumbnail.jp",,https://core.ac.uk/download/556168093.pdf,142212961,"spartan daily, february 21, 2023",2023-02-21T08:00:00,SJSU ScholarWorks,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"One of the main motivations for having a compositional semantics is the account of the productivity of natural languages. Formal languages are often part of the account of productivity, i.e., of how beings with finite capaci- ties are able to produce and understand a potentially infinite number of sen- tences, by offering a model of this process. This account of productivity con- sists in the generation of proofs in a formal system, that is taken to represent the way speakers grasp the meaning of an indefinite number of sentences. The informational basis is restricted to what is represented in the lexicon. This constraint is considered as a requirement for the account of productivity, or at least of an important feature of productivity, namely, that we can grasp auto- matically the meaning of a huge number of complex expressions, far beyond what can be memorized. However, empirical results in psycholinguistics, and especially particular patterns of ERP, show that the brain integrates informa- tion of different sources very fast, without any felt effort on the part of the speaker. This shows that formal procedures do not explain productivity. How- ever, formal models are still useful in the account of how we get at the seman- tic value of a complex expression, once we have the meanings of its parts, even if there is no formal explanation of how we get at those meanings. A practice-oriented view of modeling gives an adequate interpretation of this re- sult: formal compositional semantics may be a useful model for some ex- planatory purposes concerning natural languages, without being a good model for dealing with other explananda",,https://core.ac.uk/download/151393222.pdf,8857824,does the principle of compositionality explain productivity? for a pluralist view of the role of formal languages as models,2017-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Smart contracts are self-executing digital transactions using decentralized cryptographic mechanisms for enforcement. They were theorized more than twenty years ago, but the recent development of Bitcoin and blockchain technologies has rekindled excitement about their potential among technologists and industry. Startup companies and major enterprises alike are now developing smart contract solutions for an array of markets, purporting to offer a digital bypass around traditional contract law. For legal scholars, smart contracts pose a significant question: Do smart contracts offer a superior solution to the problems that contract law addresses? In this article, we aim to understand both the potential and the limitations of smart contracts. We conclude that smart contracts offer novel possibilities, may significantly alter the commercial world, and will demand new legal responses. But smart contracts will not displace contract law. Understanding why not brings into focus the essential role of contract law as a remedial institution. In this way, smart contracts actually illuminate the role of contract law more than they obviate it",,https://core.ac.uk/download/213019716.pdf,40821331,contracts ex machina,2017-11-21T08:00:00,Duke University School of Law,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Psychologists and child education experts always remind the importance of knowing interests and talents from an early age to provide a stimulus to children from an early age, because the provision of the stimulus affects the future of children. This study aims to (1) To make calculations in mathematical models to calculate and analyze the interests of children's talents using applications. (2) To create a web-based information system that can facilitate teachers and parents in determining the interests of children's talents at the Al-Ikhlas Taqwa Plus Elementary School using the Certainty Factor method. The method used in this research is the research and development (R&amp;D) method using the certainty factor. The population in this study were all students of SD Plus Al Ikhlas Taqwa Medan T.P 2021/2022 starting from grades 3-6. Sampling was done by purposive sampling technique. Data collection was carried out by interviews, material expert test questionnaires, and media experts, and the results of the children's talent interest questionnaire were processed using the Certainty Factor. The results of this study are the results of interest and talent analysis based on 7 intelligence criteria and also the highest summary results from several criteria with one of the tests yielding a percentage of 93.58% in the field of linguistics",10.30598/barekengvol17iss1pp0457-0466,https://core.ac.uk/download/568074518.pdf,145178141,certainty factor methods in identifying interests and talents of elementary school children al ikhlas taqwa,2023-04-20T01:00:00,'Universitas Pattimura',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This study focuses on implementing a log analysis strategy that combines a neural network algorithm and wavelet transform. Wavelet transform allows us to extract the important hidden information and features of the original time series log data and offers a precise framework for the analysis of input information. While neural network algorithm constitutes a powerfulnonlinear function approximation which can provide detection and prediction functions. The combination of the two techniques is based on the idea of using wavelet transform to denoise the log data by decomposing it into a set of coefficients, then feed the denoised data into a neural network. The experimental outputs reveal that this strategy can have a better ability to identify the patterns among problems in a log dataset, and make predictions with a better accuracy. This strategy can help the platform maintainers to adopt corresponding actions to eliminate risks before the occurrence of serious damages",,https://core.ac.uk/download/153384811.pdf,39989673,virtualized cloud platform management using a combined neural network and wavelet transform strategy,2018-03-01T08:00:00,CSUSB ScholarWorks,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Multiple experts decision-making (MEDM) can be regarded as a
situation where a group of experts are invited to provide their
opinions by evaluating the given alternatives, and then select the
optimal alternative(s). As a useful linguistic expression model, linguistic
preference orderings (LPOs) were established in which the
order of alternatives and the relationships between two adjacent
alternatives are fused well. Considering that prospect theory has
the superiority in depicting risk attitudes (risk seeking for losses
and risk aversion for gains) during the uncertain decision-making
process, this paper develops a consensus model based on prospect
theory to deal with MEDM problems with LPOs. Firstly, each
LPO provided by expert is transformed into the responding
DHLPR with complete consistency. Then, the reference point of
expert is determined and the prospect preference matrix is established.
Moreover, we can obtain the overall prospect consensus
degree for a MEDM problem by calculating the similarity degree
between individual and collective prospect preference matrix.
Furthermore, a consensus improvement method is developed to
complete the consensus reaching process. Finally, we apply the
proposed method to deal with a practical MEDM problem involving
the construction project investment, and make some comparative
analyses with existing methods.National Natural Science Foundation of China (NSFC)

71771155China Postdoctoral Science Foundation

2020M680151Sichuan Postdoctoral Science special FoundationSichuan University Postdoctoral Interdisciplinary Innovation Startup FoundationFundamental Research Funds for the Central Universities

YJ202015European Union (EU)

TIN2016-75850-RSichuan Province System Science and Enterprise Development Research Center 	
Xq20B0",10.1080/1331677x.2020.1868324,https://core.ac.uk/download/395154341.pdf,109702066,the risk assessment of construction project investment based on prospect theory with linguistic preference orderings,2021-01-01T00:00:00,'Informa UK Limited',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Containing twelve scenarios for the world in 2030, this report offers insights into how the EU can maintain and build up its capacity to act in the face of the major disruptive changes that are likely to come over this decade. It is being released in the run-up to German elections in September 2021 that will serve as a kind of referendum on ten years of government-heavy crisis management",,https://core.ac.uk/download/483985252.pdf,123727248,building european resilience and capacity to act: lessons for 2030,2021-01-01T00:00:00,'Botanic Garden & Botanical Museum Berlin-Dahlem BGBM',"[{'title': None, 'identifiers': ['issn:1866-9182', '1866-9182']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In this manifesto, we make the case that Exercise Science can and must do more to improve the health of the public and the planet. Post pandemic, our vision for Exercise Science is one of a maturing scientific discipline reaching outwards from a base of strong empirical evidence to have a profound and sustained positive global impact on health. In each of the three main areas of the discipline–research, teaching, and professional practice–a new and distinctive approach is needed. We propose 12 points of action, in no particular order, for a). quality, rigour, and professional standing, and b). reach, relevance, and public engagement and make numerous suggestions for action and change. We encourage the teachers, researchers and practitioners of Exercise Science to consider and act on these recommendations. We hope that this manifesto can help create a shared sense of purpose amongst the global Exercise Science community and further the principles of equality, diversity and inclusion. To act on these principles, we need to cultivate a discipline that encourages more women, people who experience racism and other forms of discrimination, and people with a disability to become involved in the discipline",10.1080/02640414.2022.2049083,https://core.ac.uk/download/492527618.pdf,18818590,a manifesto for exercise science–a vision for improving the health of the public and planet,2022-01-01T00:00:00,'Informa UK Limited',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Whilst digital education is becoming a reality for schools there is a role for CCI research to move beyond researcher-led school engagements to other types of research that support schools and their staff to lead on the appropriation of digital technologies. One way to advance our understanding of this issue is to examine and consolidate reflections from cases of school technology appropriation. This half-day workshop seeks to capture the enabling practices as well as those that posed barriers within the school. The work will be oriented to further identify necessary changes at different levels: e.g., the organizational level (school), the level of the practitioners (teachers) the level the school community. The mind-set of all the involved actors will also be explored aiming to identify the structures and mechanisms that can support a culture of participation and of collective responsibility by including also students and their families in the process of technology integration and appropriation. Note: This workshop is offered in conjunction with ""For the Long Run: Promoting Sustainable Use of Learning Technologies in Schools""to form a full day workshop exploring both the technical characteristics and the contextual factors of sustainable integration of learning technologies in schools",10.1145/3501712.3536383,https://core.ac.uk/download/533458050.pdf,149532593,embedding digital technologies in the school practice: schools as agents of technology integration,2022-06-27T01:00:00,'American College of Medical Physics (ACMP)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In addition to the focus of research selected as a Final Project material, the selection of lecturers as student's supervisor becomes very important. The lecturer's competence related to the focus of student research and the supervising style of lecturers is also very influential on the final results. Measurement of style appropriateness between students' learning styles and supervising lecturers' styles can benchmark the quality of the final project's implementation, especially higher education institutions. This study has applied fuzzy-based assessment to build objective perceptions of students' learning characteristics and lecturers' characteristics (Visual (V), Auditory (A), Kinesthetic (K)) as supervisors through questionnaire processing that has designed in such away. Hence, it is suitable for this study. The measuring technique of the percentage of overlapping areas under the curves and the correlation test between a pair of curves have been used as performance measurement metrics. In general, the study results indicate a significant level of coverage adequacy for all research variables regarding existing conditions. It means that the process of Final Project activities in terms of students' and lecturers' learning characteristics as supervisors and their distribution is at a reasonable level (88.38%). It has also been shown by the results of the correlation test of the appropriateness of choice, both supervisors selected by students (0.8657) and students chosen by lecturers (0.9897) who are at a very significant level of similarity. Correlation tests conducted for similarities between students' and lecturers' learning characteristics as supervisors show almost no significant correlation between them (0.4064)",10.26555/jifo.v15i1.a17389,https://core.ac.uk/download/389387984.pdf,108545746,performance measurement of the relationship between students' learning with lecturers' characteristics as supervisors based on fuzzy-based assessment,2021-01-28T00:00:00,"'Universitas Ahmad Dahlan, Kampus 3'",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The artistic research project The Treasure Hunt is an speculative investigation into the reward-oriented logics of contemporary capitalism, where treasure refers to both the ‘cultural treasures’ of the art market and the everyday incentives of the nudge economy. Drawing on the tradition of the essay film, but attempting to expand it both spatially and conceptually, the project explores the connections between an array of seemingly disparate phenomena: the global antiquities trade, the history of metal detecting, the expansion of cognitive capitalism, and the legacies of behaviourism in everyday ‘gamification’ of contemporary globalised culture, ranging from leisure to war",,https://core.ac.uk/download/544248762.pdf,133009452,the treasure hunt,2022-01-01T00:00:00,Kunsthøgskolen i Oslo,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"What kinds of arguments do people make, and what effect do they have on
others? Normative constraints on argument-making are as old as philosophy
itself, but little is known about the diversity of arguments made in practice.
We use NLP tools to extract patterns of argument-making from the Reddit site
""Change My View"" (r/CMV). This reveals six distinct argument patterns: not just
the familiar deductive and inductive forms, but also arguments about
definitions, relevance, possibility and cause, and personal experience. Data
from r/CMV also reveal differences in efficacy: personal experience and, to a
lesser extent, arguments about causation and examples, are most likely to shift
a person's view, while arguments about relevance are the least. Finally, our
methods reveal a gradient of argument-making preferences among users: a
two-axis model, of ""personal--impersonal"" and ""concrete--abstract"", can account
for nearly 80% of the strategy variance between individuals.Comment: 7 pages, 5 tables. Accepted as paper with oral presentation to CogSci
  2022, Toronto. Proceedings of the Annual Meeting of the Cognitive Science
  Society, 4",,http://arxiv.org/abs/2205.07938,136809472,"the diversity of argument-making in the wild: from assumptions and
  definitions to causation and anecdote in reddit's ""change my view""",2022-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"“Short film is where innovative storytelling is born”, the website shortoftheweek.com, a curated short film website, boldly and proudly declares. Short films often lead a Cinderella existence but engaging with them can be immensely rewarding and, due to their length, they can be ideal conversation partners in the religious studies and sociology classroom. The speculative fiction short film, the science fiction short film, and the documentary short film are particularly able to document, address, visualize – and thus render visible – structures and hierarchies of power, financial and economic interests, gender, or resource distribution, and the fears and anxieties about what it means to be human. This contribution demonstrates that short films, in particular science fiction short films, can act as conversation partners in the religious studies and sociology class-room, even if the student-audience might not be particularly avid science fiction film fans. I make reference to three short films, Rise (David Karlak, US 2016, 5′), Code 8 (Jeff Chan, US/CA 2016, 10′), and Black Sheep (Ed Perkins, UK 2018, 26′), and provide a more in-depth discussion of the use of Rise in the classroom",10.25364/05.8,https://core.ac.uk/download/548503686.pdf,134172249,“short film is where innovative storytelling is born” using the science fiction short film in the religious studies and sociology classroom,2022-11-15T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Treball final de Grau en Disseny i Desenvolupament de Videojocs. Codi: VJ1241. Curs acadèmic: 2021/2022This is the memory of the final degree project in Video Game Design and Development bachelor’s degree at the Jaume I University.
In this document there will be presented all aspects related to the development of
""UniPurge"", a Third Person Stealth Game set in a procedurally generated city in the
contemporary age where the objective is to catch and remove a multiversal threat from
the timeline.
The city is generated everytime a new playthrough takes place, randomizing all elements
of the structure of the environment, simulating a parallel universe different to the last
one. Since the main character is able to manipulate the universe fabric, some elements
may vary while remaining quite familiar each time an alteration is generated.
In order to accomplish their objective, the player has access to various tools to alter and
modify other character behaviours by tricking them",,https://core.ac.uk/download/570977568.pdf,150486118,unipurge implementation of landscape generation algorithms to create or modify video game scenery in order to simulate parallel universes,2022-07-15T01:00:00,'Universitat Jaume I',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This  article  first  reports  a  victory  of  technosolutionism over  the  other  alternatives,  the  degrowth for instance, to the ongoing collapse (species extinction, ecosystems depletion...). The victory is considered double: extraction can continue to increase (quantity and scope) and the devices made by technoscience are accepted as a solution to the problems caused by intensive exploitation (which they  also  increase).  Exploitation  is  extended,  following  Achille  Mbembé's  proposal,  to  humans,  non-human  animals,  and  the  earth  (in  a  geological  sense),  retaining  the  terms  fracturing,  extraction,  depletion. Four works are analyzed as epistemological shifts to technosolutionism. David Claerbout's “The Pure Necessity” (2016) is an animated cartoon of animals with a streamlined behavior depicted with the  graphic  style  of  Disney.  The  complex  interlocking  of  eras,  styles,  behaviors  (human  and  non-human)  is  envisaged  as  resistance  to  fracking  and  exploitation.  “Animal  Cinema”  (2017)  by  Emilio  Vavarella is a short film made from rushes produced by non-human animals. It is emphasized that the frugal production method opposes the spectacular logics of big-budget animal reporting. It adopts the animal  point  of  view  while  respecting  their  means  of  production.  It  is  also  seductive  by  a  fluid  and  hypnotizing editing more easily accessible to humans. Emilio Vavarella's Amazon's “Cabinet of Curiosity” (2019) is an installation with a strict protocol: the artist asks what he should order to make an artistic production. He then buys each suggestion until his budget is exhausted. By its absence, the commercial behavior  of  the  so-called  intelligent  device  is  underlined.  The  artist  also  resists  fracturing  and  exploitation by reducing himself to a demand. Finally, She Was Called Petra (2020) by myself is a multi-media installation. In this one, language is re-interrogated  and  a  zone  of  contact  is  set  up  to  cohabit  with a hybrid presence.Este artículo da cuenta en primer lugar de una victoria del tecnosolucionismo frente a otras alternativas al colapso en curso (extinción de especies, agotamiento de ecosistemas...). La victoria se considera  doble:  la  extracción  puede  seguir  aumentando  (en  cantidad  y  alcance)  y  los  dispositivos  fabricados por la tecnociencia se aceptan como solución a los problemas causados por la explotación intensiva  (que  también  requieren).  La  explotación  se  extiende,  siguiendo  la  propuesta  de  Achille  Mbembé, a los seres humanos, los animales no humanos y la tierra (en sentido geológico), conservando los    términos    fracturación,    extracción,    agotamiento.    Se    analizan    cuatro    obras    como    giros    epistemológicos  hacia  el  tecnosolucionismo.  “The  Pure  Necessity”  (2016),  de  David  Claerbout,  es  una  caricatura  de  animales  con  un  estilo  gráfico  similar  al  de  Disney.  El  complejo  entrelazamiento  de  épocas, estilos, comportamientos (humanos y no humanos) se vislumbra como resistencia al frackingy  la  explotación.  “Animal  Cinema”  (2017) de Emilio Vavarella es un cortometraje realizado a partir de juncos producidos por animales no humanos. Se hace hincapié en que el frugal método de producción se opone a la lógica espectacular de los reportajes sobre animales de gran presupuesto. Adopta el punto de  vista  de  los  animales  respetando  sus  medios  de  producción.  También  resulta  atractivo  por  su  montaje  fluido  e  hipnótico,  más  accesible  a  los  humanos.  “Amazon's  Cabinet  of  Curiosity”  (2019),  de  Emilio Vavarella, es una instalación con un estricto protocolo: el artista pregunta qué debería encargar para realizar una producción artística. Luego compra cada sugerencia hasta agotar su presupuesto. La fuerte retracción subraya el comportamiento comercial del llamado dispositivo inteligente. El artista también  se  resiste  al  fracking  y  a  la  explotación  reduciéndose  a  una  demanda.  Por  último,  “She  Was  Called Petra” (2020), de mi autoría, es una instalación multimedia. En ella se reinterroga el lenguaje y se crea una zona de contacto/intercambio para cohabitar y pensar en una presencia híbrida",10.37536/ecozona.2023.14.2.5069,https://core.ac.uk/download/595326153.pdf,153841765,facing depletion. artworks for an epistemological shift in the collapse era,2023-01-01T00:00:00,Universidad de Alcalá,"[{'title': 'Ecozon European Journal of Literature Culture and Environment', 'identifiers': ['2171-9594', 'issn:2171-9594']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This article addresses Inderpal Grewal and Caren Kaplan’s call for transnational feminist research that makes visible “the material conditions that structure women’s lives in diverse locations” (17). The author argues that videogames can contribute to feminist scholarship by creating virtual spaces that simulate how a transnational politics of location plays out on women’s bodies. This article provides a spatial analysis of three videogames, République, Horizon: Zero Dawn, and Alien: Isolation, to show how the games’ procedures can persuade audiences to empathize with the surveillance and precarity of women’s bodies in real-life transnational experiences. While the games focus on “stealth,” the limitations provided by the gameplay simulate the different ways in which women’s bodies must “sneak” around national identities and rules, thus showing the ways in which a transnational politics of location creates “contradictory positions. . . [for women who] inhibit unitary identities” (Grewal and Kaplan 7)",10.26262/gramma.v25i0.6593,https://core.ac.uk/download/267933374.pdf,74583713,stealth and a transnational politics of location in videogames,2018-10-04T01:00:00,School of English Language and Literature - A.U.Th.,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
Big report of the Startup EDR Project. See how the project promoted interregional collaboration and development for startups within the Ems-Dollart region,,https://core.ac.uk/download/596351355.pdf,152588818,forget amsterdam and berlin:start your business in the ems-dollart-region,2022-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Purpose: The purpose of this research paper is to explore Peter Drucker’s principles, philosophies, and practices. Knowledge workers and thought leaders are explained and knowledge and wealth are differentiated. The paper advises how everyone can excel as a knowledge worker and implores the augmentation of a knowledge pipeline. It outlines competencies for 21st -century managers and offers a strategy in an unpredictable world. Despite rapid changes in technology, the impact of Drucker’s ideas is shown to endure as his ideas on humanity, technology and prosperity are still relevant today. This article outlines his leadership lessons and equips the reader with his fundamental management tools. Drucker’s resonance reveals that individuals are mortal and ideas are immortal. The discourse substantiates that Peter Drucker is more relevant today and his ideas and insights continue to inspire the world, calling upon management thinkers, scholars, and practitioners to keep his legacy alive and carry it forward to build a better world.
Research Limitations/Implications: The manuscript covers knowledge workers and management applying objectives from Peter Drucker’s perspectiv",,https://core.ac.uk/download/475616756.pdf,82148714,"peter drucker’s principles, philosophies, and practices",2021-07-09T22:04:38,ValpoScholar,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The design choices in Transformer feed-forward neural networks have resulted
in significant computational and parameter overhead. In this work, we emphasize
the importance of hidden dimension in designing lightweight FFNs, a factor
often overlooked in previous architectures. Guided by this principle, we
introduce PartialFormer, a parameter-efficient Transformer architecture
utilizing multiple smaller FFNs to reduce parameters and computation while
maintaining essential hidden dimensions. These smaller FFNs are integrated into
a multi-head attention system to enable effective collaboration. We also
propose a tailored head scaling strategy to enhance PartialFormer's
capabilities. Furthermore, we present a residual-like attention calculation to
improve depth scaling within PartialFormer. Extensive experiments on 9
translation tasks and 1 abstractive summarization task validate the
effectiveness of our PartialFormer approach. Our code would be available at:
\url{https://github.com/zhengkid/PartialFormer}.Comment: 11 pages, 5 figure",,http://arxiv.org/abs/2310.14921,152814806,partialformer: modeling part instead of whole,2023-10-23T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Previous work has shown that artificial neural agents naturally develop
surprisingly non-efficient codes. This is illustrated by the fact that in a
referential game involving a speaker and a listener neural networks optimizing
accurate transmission over a discrete channel, the emergent messages fail to
achieve an optimal length. Furthermore, frequent messages tend to be longer
than infrequent ones, a pattern contrary to the Zipf Law of Abbreviation (ZLA)
observed in all natural languages. Here, we show that near-optimal and
ZLA-compatible messages can emerge, but only if both the speaker and the
listener are modified. We hence introduce a new communication system,
""LazImpa"", where the speaker is made increasingly lazy, i.e. avoids long
messages, and the listener impatient, i.e.,~seeks to guess the intended content
as soon as possible.Comment: Accepted to CoNLL 202",10.18653/v1/2020.conll-1.26,https://core.ac.uk/download/362228843.pdf,89634080,"""lazimpa"": lazy and impatient neural agents learn to communicate
  efficiently",2020-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The frameworks of cyber, technology and data sovereignty have become some of the most influential alternative technological imaginaries. Developed by states and civil society groups, such frameworks are seducing a broad range of actors seeking to reassert their autonomy and self-determination in relation to digital technology and infrastructure. Against this backdrop, this article interrogates the alleged transformative character of digital sovereignty. Do these frameworks support alternative planetary futures, or do they involve a mere change in the actors who are privileging from the technological status quo? To answer this question, I examine the rhetoric and realisation of digital sovereignty frameworks by the Chinese state, the European Union (EU) and Latin American civil society in light of Walter Mignolo's decolonial option. The decolonial option gets inspiration from decolonial praxis and aims at enabling polycentric, noncapitalist and nonanthropocentric planetary futures. As I show, there is some degree of alignment between digital sovereignty frameworks and the decolonial option in the sphere of international politics, but less so in the world economy and the environment. While in some areas the formulations by the Chinese state and the EU can exacerbate coloniality, the Latin American civil society one constitutes a promising attempt at appropriating digital sovereignty from below and promoting peaceful forms of coexistence with the environment although needs further development",10.1177/20539517231221778,https://core.ac.uk/download/598040358.pdf,153425858,an alternative planetary future?: digital sovereignty frameworks and the decolonial option,2024-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Social robots are on the brink of entering our lives. However, little knowledge is available about how best to design them. This introductory chapter discusses the real-life social robots of the present as well as of possible futures—without, of course, forgetting the history of robots and their origins in fiction. From a design perspective, robots are promising and challenging. They suggest a technological other (“otherware”). Unlike conventional technologies that directly extend the physical and cognitive abilities of their users, robots engage in social exchange with humans. The authors present an overview of possible starting points for designing meaningful relationships with robots. Recurring themes are contextualized and cross cut, e.g., the influence of science fiction on robot design is discussed and the strategy of anthropomorphization is called into question. The authors respond to these relevant issues by arguing for robots with hybrid forms and unique “superpowers”. They present a new model for human-robot interaction, establishing three different kinds of interactions in terms of the meaning conveyed by robots to humans (delegating, cooperating, and socializing). Rather than imitating and thus replacing humans or animals, the authors conclude, robots should invite their own particular ways of being with us",10.1201/9781003287445-1,https://core.ac.uk/download/543578170.pdf,131198442,chapter 1 towards designing meaningful relationships with robots,2022-11-16T10:11:41,'Informa UK Limited',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The relationship between work organization and technology has been conceptualized in economic and sociological studies in a variety of ways, depending on the authors’ ontological premises and use of terminology (e.g., Leonardi &amp; Barley, 2010; Mackenzie &amp; Wajcman, 1985). For one thing, many economic analyses have not even regarded work organization as an analytical entity in itself but rather as a subcategory under an umbrella category of ‘technology’. In cases like this, the concept of technology has been used in the broad sense, also referring to human activities and know-how to do things. In many classical and modern sociological studies of work, the analytical distinction between work organization and technology has been of crucial importance, often based on a narrower concept of technology as a set of physical objects (...",,https://core.ac.uk/download/233676673.pdf,69843033,work organization and technology: introduction to the theme of the special issue,2018-04-12T01:00:00,"Aalborg University, Denmark",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The relationship between work organization and technology has been conceptualized in economic and sociological studies in a variety of ways, depending on the authors’ ontological premises and use of terminology (e.g., Leonardi & Barley, 2010; Mackenzie & Wajcman, 1985). For one thing, many economic analyses have not even regarded work organization as an analytical entity in itself but rather as a subcategory under an umbrella category of ‘technology’. In cases like this, the concept of technology has been used in the broad sense, also referring to human activities and know-how to do things. In many classical and modern sociological studies of work, the analytical distinction between work organization and technology has been of crucial importance, often based on a narrower concept of technology as a set of physical objects (...)Non peer reviewe",10.18291/njwls.v8is3.105273,https://core.ac.uk/download/224633961.pdf,39386700,work organization and technology : introduction to the theme of the special issue,2018-04-01T01:00:00,,"[{'title': 'Nordic Journal of Working Life Studies', 'identifiers': ['2245-0157', 'issn:2245-0157']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This technical document presents the committee driven innovation modeling
methodology ""Innovation Modeling Grid"" in detail. This document is the
successor of three publications on IMoG and focuses on presenting all details
of the methodologyComment: ~170p, many figures, technical documen",,http://arxiv.org/abs/2309.16507,151805420,innovation modeling grid,2023-09-28T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Dogwhistles are coded expressions that simultaneously convey one meaning to a
broad audience and a second one, often hateful or provocative, to a narrow
in-group; they are deployed to evade both political repercussions and
algorithmic content moderation. For example, in the sentence 'we need to end
the cosmopolitan experiment,' the word 'cosmopolitan' likely means 'worldly' to
many, but secretly means 'Jewish' to a select few. We present the first
large-scale computational investigation of dogwhistles. We develop a typology
of dogwhistles, curate the largest-to-date glossary of over 300 dogwhistles
with rich contextual information and examples, and analyze their usage in
historical U.S. politicians' speeches. We then assess whether a large language
model (GPT-3) can identify dogwhistles and their meanings, and find that
GPT-3's performance varies widely across types of dogwhistles and targeted
groups. Finally, we show that harmful content containing dogwhistles avoids
toxicity detection, highlighting online risks of such coded language. This work
sheds light on the theoretical and applied importance of dogwhistles in both
NLP and computational social science, and provides resources for future
research in modeling dogwhistles and mitigating their online harms.Comment: ACL 2023, see https://dogwhistles.allen.ai/ for the glossary and
  other material",,http://arxiv.org/abs/2305.17174,143042680,"from dogwhistles to bullhorns: unveiling coded rhetoric with language
  models",2023-05-26T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"International audienceAbstract In a previous paper, we have shown that clause sets belonging to the Horn Bernays-Schönfinkel fragment over simple linear real arithmetic (HBS(SLR)) can be translated into HBS clause sets over a finite set of first-order constants. The translation preserves validity and satisfiability and it is still applicable if we extend our input with positive universally or existentially quantified verification conditions (conjectures). We call this translation a Datalog hammer. The combination of its implementation in SPASS-SPL with the Datalog reasoner VLog establishes an effective way of deciding verification conditions in the Horn fragment. We verify supervisor code for two examples: a lane change assistant in a car and an electronic control unit of a supercharged combustion engine. In this paper, we improve our Datalog hammer in several ways: we generalize it to mixed real-integer arithmetic and finite first-order sorts; we extend the class of acceptable inequalities beyond variable bounds and positively grounded inequalities; and we significantly reduce the size of the hammer output by a soft typing discipline. We call the result the sorted Datalog hammer. It not only allows us to handle more complex supervisor code and to model already considered supervisor code more concisely, but it also improves our performance on real world benchmark examples. Finally, we replace the before file-based interface between SPASS-SPL and VLog by a close coupling resulting in a single executable binary",10.1007/978-3-030-99524-9_27,https://core.ac.uk/download/544384312.pdf,135778941,a sorted datalog hammer for supervisor verification conditions modulo simple linear arithmetic,2022-01-01T00:00:00,'Springer Science and Business Media LLC',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Question answering (QA) in the field of healthcare has received much
attention due to significant advancements in natural language processing.
However, existing healthcare QA datasets primarily focus on medical images,
clinical notes, or structured electronic health record tables. This leaves the
vast potential of combining electrocardiogram (ECG) data with these systems
largely untapped. To address this gap, we present ECG-QA, the first QA dataset
specifically designed for ECG analysis. The dataset comprises a total of 70
question templates that cover a wide range of clinically relevant ECG topics,
each validated by an ECG expert to ensure their clinical utility. As a result,
our dataset includes diverse ECG interpretation questions, including those that
require a comparative analysis of two different ECGs. In addition, we have
conducted numerous experiments to provide valuable insights for future research
directions. We believe that ECG-QA will serve as a valuable resource for the
development of intelligent QA systems capable of assisting clinicians in ECG
interpretations.Comment: 39 pages (9 pages for main text, 2 pages for references, 28 pages for
  supplementary materials",,http://arxiv.org/abs/2306.15681,143786840,"ecg-qa: a comprehensive question answering dataset combined with
  electrocardiogram",2023-06-21T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Student newspaper of the University of Montana, Missoula.https://scholarworks.umt.edu/studentnewspaper/11124/thumbnail.jp",,https://core.ac.uk/download/588596699.pdf,150549519,"montana kaimin, september 14, 2023",2023-09-14T08:00:00,ScholarWorks at University of Montana,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In the sub-arctic climate with its extremely short growing seasons and land cover that is dominated by forest with very little agricultural land, the built-up area offers an untapped capacity when thinking about sites for food production. This accounts both for the existing and, given the dynamics of Northern Sweden in terms of development and population growth, the forthcoming building stock. Designing Cycles at 64° takes a multi-scalar approach addressing individual building typologies - and exemplarily for climate adaptation of northern climate zones - in the city of Umeå, Sweden with its diverse urban fabric as a whole. Expanding on Bengt Warne’s Naturhus (1974) and following examples, we anticipate new multifunctional architectural models applicable in various contexts and scales (see fig. 2). It further builds on the hypothesis that low-tech, low-cost landscape-based solutions are applicable in different societal contexts and therefore potentially contribute to overcoming segregation (Redeker, Jüttner, 2020). At 64° latitude, interior landscapes and their water-energy-food nexus offer interesting possibilities to extend growing seasons and diversify crops, and to reduce energy consumption while providing hybrid living spaces between inside and outside. By exploring greenhouse extensions and building envelopes (GEEs) as local passive architectural solutions, DC64° sets out to build productive interfaces between the private and public sector, academia - involving the disciplines of architecture and urban planning - urban water management, plant physiology and vertical gardening, as well as the general public in a living lab format. In this text we want to reflect on phase 0 of a living lab set up, reflect on the idea of a new vernacular for local food production in the sub-arctic and the context that defines this adaptive process and elaborate the outline of the methodology to be applied",10.14198/uou.2022.4.10,https://core.ac.uk/download/552305464.pdf,137263987,from being consumers to becoming producers: designing cycles at 64°,2022-01-01T00:00:00,'Universidad de Alicante Servicio de Publicaciones',"[{'title': None, 'identifiers': ['issn:2697-1518', '2697-1518']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
The student newspaper of Humboldt State University.https://digitalcommons.humboldt.edu/studentnewspaper/1176/thumbnail.jp,,https://core.ac.uk/download/389065120.pdf,108425337,"the lumberjack, february 12, 2020",2020-02-12T08:00:00,Digital Commons @ Humboldt State University,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In this research-in-progress paper, the proposal for a research project is presented for discussion. The purpose of the project is to develop a set of scenarios that describes a range of possible future environments pertaining to information and communications technology (ICT) in academic libraries in sub-Saharan Africa over the next 6 years. The value of the study is that this set of scenarios can be used and adapted by libraries to inform strategic planning, decision-making and/or policymaking by various stakeholders when it comes to investing limited resources into ICT infrastructure and capacity building to support academic institutions’ teaching and research. The proposed research design comprises a Delphi study followed by scenario development",,https://core.ac.uk/download/301379706.pdf,17808703,scenarios for information and communication technology in sub-saharan african academic libraries: a research proposal,2019-05-21T08:00:00,AIS Electronic Library (AISeL),[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Value function is the central notion of Reinforcement Learning (RL). Value
estimation, especially with function approximation, can be challenging since it
involves the stochasticity of environmental dynamics and reward signals that
can be sparse and delayed in some cases. A typical model-free RL algorithm
usually estimates the values of a policy by Temporal Difference (TD) or Monte
Carlo (MC) algorithms directly from rewards, without explicitly taking dynamics
into consideration. In this paper, we propose Value Decomposition with Future
Prediction (VDFP), providing an explicit two-step understanding of the value
estimation process: 1) first foresee the latent future, 2) and then evaluate
it. We analytically decompose the value function into a latent future dynamics
part and a policy-independent trajectory return part, inducing a way to model
latent dynamics and returns separately in value estimation. Further, we derive
a practical deep RL algorithm, consisting of a convolutional model to learn
compact trajectory representation from past experiences, a conditional
variational auto-encoder to predict the latent future dynamics and a convex
return model that evaluates trajectory representation. In experiments, we
empirically demonstrate the effectiveness of our approach for both off-policy
and on-policy RL in several OpenAI Gym continuous control tasks as well as a
few challenging variants with delayed reward.Comment: Accepted paper on AAAI 2021. arXiv admin note: text overlap with
  arXiv:1905.1110",10.1609/aaai.v35i11.17182,http://arxiv.org/abs/2103.02225,108124715,"foresee then evaluate: decomposing value estimation with latent future
  prediction",2021-03-03T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The recent progress in large language models (LLMs), especially the invention
of chain-of-thoughts (CoT) prompting, makes it possible to solve reasoning
problems. However, even the strongest LLMs are still struggling with more
complicated problems that require non-linear thinking and multi-step reasoning.
In this work, we explore whether LLMs have the ability to recognize their own
errors, without resorting to external resources. In particular, we investigate
whether they can be used to identify individual errors within a step-by-step
reasoning. To this end, we propose a zero-shot verification scheme to recognize
such errors. We then use this verification scheme to improve question-answering
performance, by using it to perform weighted voting on different generated
answers. We test the method on three math datasets-GSM8K, MathQA, and MATH-and
find that it successfully recognizes errors and, in turn, increases final
predictive performance",,http://arxiv.org/abs/2308.00436,144971218,"selfcheck: using llms to zero-shot check their own step-by-step
  reasoning",2023-08-02T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"It is common to use past information about the system modeled in probabilistic statistics to make predictions about the future. Especially in the area of climate modeling and forecasting this is done. Here it is argued that doing this in a purely empirical way is full of perils and pitfalls. Without knowledge of the underlying physical laws it will go wrong sooner or later. Specifically, the distribution functions are analyzed, which are normally assumed to be well-behaved gaussian-like not because there is a reason for it, but only because they don’t cause mathematical problems. Real functions (like power laws) will prohibit any statistical analysis and thus prediction model. Furthermore, correlations and extrapolations are considered. The first show that correlations come in many types and not all of them have a direct causation link. The specific case of extreme events is used as an example to highlight the difficulty and the pitfalls of empirical forecasting in general. The conclusion is that empirical forecasting cannot be used for science",10.19044/esj.2017.v13n18p18,https://core.ac.uk/download/493000502.pdf,11579838,perils and pitfalls of empirical forecasting,2017-06-30T00:00:00,"'European Scientific Institute, ESI'",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Treball final de Grau en Disseny i Desenvolupament de Videojocs. Codi: VJ1241. Curs acadèmic: 2019/2020This document presents the technical report of the Final Degree Project of the Bachelor's Degree in Videogame Design and Development. The work developed consists of a three-dimensional computer role-playing videogame made with Unity3D, whose world will be easily expandable. The player has to choose among one of the characters offered by the game to start a story that will be told by the non-player characters through quests. These quests consist of defeating enemies, controlled by an artificial intelligence, that roam around the world and, fighting against them, our character will gain experience to level up and learn new combat skills. The player must defeat the enemies to make his character stronger, since each level will increase his statistics and his new skills will allow him to face more powerful enemies. In addition, the world will be able to expand with new quests and enemies in future updates",,https://core.ac.uk/download/373288528.pdf,45998239,design and development of a role-playing videogame with an expandable world,2020-06-09T01:00:00,'Universitat Jaume I',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Arcadian Theatre is a concept for performance practice that uses fictional scenarios to engage participants in autotelic play that facilitates intercultural (inter-epistemological) dialogue. In so doing, the performance models of Arcadian Theatre enable the cultivation of interaction and social coevolution. Drawing on theories of theatre and scenography, theory of models, philosophy (Speech Act Theory), anthropology, and social psychology, the article proposes the use of scenographic environments with its created and curated spaces and performance objects to create performative models and physical fictions capable of engendering novel ecologies with their autonomous epistemologies and ethics that build on the affordances of the spaces, objects and social behaviours within the fictional worlds",,https://core.ac.uk/download/553657175.pdf,138835171,performative models and physical fictions,2023-02-07T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Existing benchmarks for evaluating long video understanding falls short on
two critical aspects, either lacking in scale or quality of annotations. These
limitations arise from the difficulty in collecting dense annotations for long
videos, which often require manually labeling each frame. In this work, we
introduce an automated Annotation and Video Stream Alignment Pipeline
(abbreviated ASAP). We demonstrate the generality of ASAP by aligning unlabeled
videos of four different sports with corresponding freely available dense web
annotations (i.e. commentary). We then leverage ASAP scalability to create
LCric, a large-scale long video understanding benchmark, with over 1000 hours
of densely annotated long Cricket videos (with an average sample length of ~50
mins) collected at virtually zero annotation cost. We benchmark and analyze
state-of-the-art video understanding models on LCric through a large set of
compositional multi-choice and regression queries. We establish a human
baseline that indicates significant room for new research to explore. Our human
studies indicate that ASAP can align videos and annotations with high fidelity,
precision, and speed. The dataset along with the code for ASAP and baselines
can be accessed here: https://asap-benchmark.github.io/",,http://arxiv.org/abs/2301.06866,141819691,building scalable video understanding benchmarks through sports,2023-03-26T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
Peer reviewe,10.1093/bjps/axy053,https://core.ac.uk/download/328855523.pdf,37226059,defending a risk account of scientific objectivity,2018-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Smart contracts are self-executing digital transactions using decentralized cryptographic mechanisms for enforcement. They were theorized more than twenty years ago, but the recent development of Bitcoin and blockchain technologies has rekindled excitement about their potential among technologists and industry. Startup companies and major enterprises alike are now developing smart contract solutions for an array of markets, purporting to offer a digital bypass around traditional contract law. For legal scholars, smart contracts pose a significant question: Do smart contracts offer a superior solution to the problems that contract law addresses? In this article, we aim to understand both the potential and the limitations of smart contracts. We conclude that smart contracts offer novel possibilities, may significantly alter the commercial world, and will demand new legal responses. But smart contracts will not displace contract law. Understanding why not brings into focus the essential role of contract law as a remedial institution. In this way, smart contracts actually illuminate the role of contract law more than they obviate it",,https://core.ac.uk/download/232704911.pdf,69332801,contracts \u3cem\u3eex machina\u3c/em\u3e,2017-11-01T07:00:00,University of Michigan Law School Scholarship Repository,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The Howl is a magazine that is planned, researched, written, photographed and designed by Otterbein University’s ESL and international students. The magazine serves to give them a safe space in which to use their voice to share their cultures, experiences and lives. If you are interested in submitting to the Howl, please e-mail your writing or photography to gderosa@otterbein.edu. Enjoy Otterbein ESL’s contribution to the Otterbein community’s literary scene.https://digitalcommons.otterbein.edu/the_howl/1008/thumbnail.jp",,https://core.ac.uk/download/519865883.pdf,125803381,the howl - spring 2020,2020-04-01T08:00:00,Digital Commons @ Otterbein,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The Bernays-Sch\""onfinkel first-order logic fragment over simple linear real
arithmetic constraints BS(SLR) is known to be decidable. We prove that BS(SLR)
clause sets with both universally and existentially quantified verification
conditions (conjectures) can be translated into BS(SLR) clause sets over a
finite set of first-order constants. For the Horn case, we provide a Datalog
hammer preserving validity and satisfiability. A toolchain from the BS(LRA)
prover SPASS-SPL to the Datalog reasoner VLog establishes an effective way of
deciding verification conditions in the Horn fragment. This is exemplified by
the verification of supervisor code for a lane change assistant in a car and of
an electronic control unit for a supercharged combustion engine.Comment: 26 page",10.1007/978-3-030-86205-3_1,https://core.ac.uk/download/481113048.pdf,119510613,"a datalog hammer for supervisor verification conditions modulo simple
  linear arithmetic",2021-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
Inside This Issue    Corrections on Issue 2 Winter 2020 Pg. 2 On University\u27s population of female professors Pg. 4  One Last Dance  by University Dance Company Pg. 6&,,https://core.ac.uk/download/326318173.pdf,40001335,"february 19th, 2020",2020-02-19T08:00:00,CSUSB ScholarWorks,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We investigate the algebra and geometry of general interventions in discrete
DAG models. To this end, we develop the formalism to study these models as
subvarieties of multiprojective space and introduce a theory for modeling soft
interventions in the more general family of staged tree models. We then
consider the problem of finding their defining equations, and we derive a
combinatorial criterion for identifying interventional staged tree models for
which the defining ideal is toric. This criterion, when combined with a new
characterization of decomposable DAG models in terms of their associated staged
trees, specializes to a graphical criterion in the case of discrete
interventional DAG models.Comment: Comments welcom",,http://arxiv.org/abs/2012.03593,107766756,algebraic geometry of discrete interventional models,2020-12-07T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"There are a number of methods of investigating the function of recombinant proteins such as ion channels. However, after channel purification there are few methods to guarantee that the protein still functions. For ion channels, reconstituting back into planar lipid bilayers and demonstrating preserved function is a convenient and trusted method. It is cell free and even inaccessible, intracellular ion channels can be studied. We have used this method to study the function of recombinant channels of known subunit composition and have found it convenient for investigating the mode of action of ion channel modulators",10.1016/j.ymeth.2018.03.003,https://core.ac.uk/download/188257886.pdf,54816318,planar lipid bilayers in recombinant ion channel research,2018-03-09T00:00:00,'Elsevier BV',"[{'title': None, 'identifiers': ['1046-2023']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
publishedVersio,10.1016/j.lcsi.2020.100430,https://core.ac.uk/download/387218174.pdf,18468395,part 3: the study on the development of human mental activity: lecture 10. the development of mental actions and the orienting basis of actions,2020-01-01T00:00:00,'Elsevier BV',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Thema: Chinas Landesverteidigung am Beginn der 2020er Jahre - im Spiegel des Weißbuchs 2019  zur Militärstrategie Chinas.
• mit einem Kommentar.
• Chinas Weißbuch 2019, gekürzte und bearb. Übersetzung a. d. Engl.;
• Chinas Weißbuch 2019, Textoriginal (engl.);
• Chinas Weißbuch 2015, gekürzte und bearb. Übersetzung a. d. Engl.:Inhalt:
• Vorwort des Herausgebers
• Kommentar von Wilfried Schreiber:
  'Chinas Weißbuch 2019 zur Militärstrategie und die KP Chinas.'
• Übersetzung von Bernd Biedermann: 
Weißbuch 2019 zu Chinas Militärstrategie. 
'Chinas Landesverteidigung im neuen Zeitalter.'
• Anhang 1: Übersetzung von Bernd Biedermann: 
'Weißbuch 2015 zu Chinas Militärstrategie.'
• Anhang 2: Textoriginal (engl.): White paper 2019 -
 'China`s National Defense in the New Era (2019)",,https://core.ac.uk/download/287179214.pdf,77855269,chinas landesverteidigung am beginn der 2020er jahre: weißbuch zu chinas militärstrategie,2020-01-21T00:00:00,,"[{'title': None, 'identifiers': ['issn:2627-3470', '2627-3470']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Shelley's novel has been fertile ground for ecocritics over the last two decades. In Ecocriticism and the Idea of Culture (2014, 2016) I wrote about Frankenstein and culture's dialectical horror of nature. As a narrative of failed continuity, Frankenstein also exhibits our fear of culture, its machine determinism, of monstrous production in place of sustainable reproduction. Victor, the isolated, compulsive scientist is not unlike the figure of the lone programmer, coding for the ""enhanced"" human or cyborg of his uncritical posthuman dreams. Our world and its problems demonstrate that Frankenstein continues to be a prescient novel: before Darwin's theory of evolution, and long before genetic modification and what we call information technology, Shelley imagined the creation of a being as an assemblage of contingent ""natureculture"" in a bildungsroman that juxtaposes its creator's. While the novel invites us to consider the political promise of the monster (as I've argued elsewhere), it is also a commentary on the dangers of solitude, the dangers of failing to honour the social and ecological contingency, the entanglement, of all things in the pursuit of knowledge",,https://core.ac.uk/download/481505610.pdf,9053235,"transhumanism, frankenstein,  and extinction",2018-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The emergence of technological sophistication that they are proud of has resulted in the problem of decreasing attitudes and behavior experienced by millennial students. Attitudes caused include a lack of morals, cyberbullying, and gadget addiction. So, changes in behavior must be followed up by Arabic teachers, and the challenge for Arabic teachers in Indonesia is to meet the Era of Society 5.0. This study aims to show that Arabic language teachers and community components must be able to deal with complexities. And teachers must be able to build good and conducive communication with students, parents, and the community. The right step to deal with it is to think and act on a solution because it is part of creative thinking reform. Literature study is one approach in this research. Arabic teachers who think relatively must prepare themselves to face the challenges of society 5.0 using (1) always being optimistic, (2) having a solid work team, (3) being communicative teachers, (4) being hard workers, (5) commitment, (6) simplifying problems, not taking lightly. The author hopes that Arabic language teachers, communities, and stakeholders in Indonesia can together create students with innovative and solutive characters. <w:LsdException Locked=""false"" Priority=""39"" SemiHidden=""true"" Un",10.15575/jpba.v6i2.20236,https://core.ac.uk/download/551325605.pdf,135471049,indonesian arabic teachers must be solutive in the era of society 5.0,2022-12-01T00:00:00,'Sunan Gunung Djati State Islamic University of Bandung',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
N/,,https://core.ac.uk/download/478156528.pdf,120284126,fitting fractals into our toolbox for studying the human mind,2020-09-01T08:00:00,Digital Commons @ CIIS,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Large language models (LLMs) take advantage of step-by-step reasoning
instructions, e.g., chain-of-thought (CoT) prompting. Building on this, their
ability to perform CoT-style reasoning robustly is of interest from a probing
perspective. In this study, we inspect the step-by-step reasoning ability of
LLMs with a focus on negation, which is a core linguistic phenomenon that is
difficult to process. In particular, we introduce several controlled settings
(e.g., reasoning in case of fictional entities) to evaluate the logical
reasoning abilities of the models. We observed that dozens of modern LLMs were
not robust against lexical negation (e.g., plausible ->implausible) when
performing CoT-style reasoning, and the results highlight unique limitations in
each LLM family",,http://arxiv.org/abs/2310.14868,152814873,"assessing step-by-step reasoning against lexical negation: a case study
  on syllogism",2023-10-23T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Meeting notes, long form, from the Barcelona Funders Meeting in March 2018",,https://core.ac.uk/download/480180615.pdf,127301570,barcelona funders meeting notes,2018-04-04T01:00:00,Sigmawings Publishing Company,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Separation processes on an industrial scale account for well over half of the capital and operating costs in the chemical industry. Knowledge of these processes is key for every student of chemical or process engineering. This book is ideally suited to university teaching, thanks to its wealth of exercises and solutions. The second edition boasts an even greater number of applied examples and case studies as well as references for further reading. - An authoritative introduction to industrial separation technology. - Contains exercises at the end of each subject as well as solutions. - Now with extended and updated examples and case studies",10.1515/9783110654806,https://core.ac.uk/download/572222083.pdf,151081259,industrial separation processes:fundamentals,2020-01-01T00:00:00,Walter de Gruyter,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
การบริหารสถานศึกษาในยุคดิจิทัลนับเป็นความท้าทายอย่างมากของผู้บริหารสถานศึกษาในยุคดิจิทัล ท่ามกลางความเปลี่ยนแปลงและความเป็นพลวัตของโลกที่ไม่สามารถหยุดยั้งได้ ผู้บริหารสถานศึกษาต้องมีการปรับตัวให้สอดคล้องกับกระแสของการเปลี่ยนแปลงดังกล่าว ในบทความนี้นำเสนอประเด็นสำคัญของการบริหารสถานศึกษาในยุคดิจิทัล บทบาทและคุณลักษณะของผู้บริหารสถานศึกษา เทคโนโลยีในการบริหารสถานศึกษา รวมไปถึงทักษะของผู้บริหารสถานศึกษา หลักการสำคัญประการหนึ่งในการพัฒนาระบบการบริหารจัดการสถานศึกษาเพื่อยกระดับคุณภาพผู้เรียนโดยใช้เทคโนโลยีสารสนเทศและการสื่อสาร คือการส่งเสริมให้ครูและบุคลากรทางการศึกษา สามารถเข้าถึงเทคโนโลยี ข้อมูลข่าวสาร สื่อการเรียนรู้ และบริการต่างๆ ของสถานศึกษา โดยมีการวางแผนและพัฒนาระบบเทคโนโลยีดิจิทัลให้พร้อมต่อการให้บริการแก่ผู้ที่เกี่ยวข้อง ทั้งนี้เพื่อเป็นการเตรียมความพร้อมให้กับผู้เรียน และตอบสนองต่อการศึกษาในอนาคตรวมไปถึงการพัฒนาทรัพยากรมนุษย์ที่จะเติบโตขึ้นให้พร้อมที่จะเข้าสู่การทำงานหรือการศึกษาต่อในอนาคต เพื่อเป็นกำลังสำคัญของประเทศในการพัฒนาเศรษฐกิจและสังคม ,,https://core.ac.uk/download/599112700.pdf,153506335,การบริหารสถานศึกษาในยุคดิจิทัล: school adminisstration in digital era,2024-01-21T00:00:00,คณะศึกษาศาสตร์ มหาวิทยาลัยศรีนครินทรวิโรฒ,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In recent years, the partnership between Serbia and China has been elevated to a historically unprecedented level. This partnership manifests itself through Chinese economic statecraft, technological partnership, security partnership, with political ties reaching an unprecedented degree during the COVID-19 pandemic. However, as Vuk Vuksanovic examines, the future of this partnership will be dependent on the trajectory of China’s relationship with the West. As US-China relations are becoming adversarial, and as China’s relations with the EU are shaken, it will become increasingly difficult and risky for Belgrade to maintain its ties with Beijing. From ‘vaccine diplomacy’ to ‘debt-trap diplomacy’, this Strategic Update examines the Sino-Serbian partnership we are witnessing and what the future has in store for Serbian policymakers",,https://core.ac.uk/download/511316317.pdf,18689458,the dragon lands in belgrade: the drivers of sino-serbian partnership,2021-07-19T01:00:00,LSE Ideas,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Amateurs working on mini-films and short-form videos usually spend lots of
time and effort on the multi-round complicated process of setting and adjusting
scenes, plots, and cameras to deliver satisfying video shots. We present
Virtual Dynamic Storyboard (VDS) to allow users storyboarding shots in virtual
environments, where the filming staff can easily test the settings of shots
before the actual filming. VDS runs on a ""propose-simulate-discriminate"" mode:
Given a formatted story script and a camera script as input, it generates
several character animation and camera movement proposals following predefined
story and cinematic rules to allow an off-the-shelf simulation engine to render
videos. To pick up the top-quality dynamic storyboard from the candidates, we
equip it with a shot ranking discriminator based on shot quality criteria
learned from professional manual-created data. VDS is comprehensively validated
via extensive experiments and user studies, demonstrating its efficiency,
effectiveness, and great potential in assisting amateur video production.Comment: Project page: https://virtualfilmstudio.github.io",,http://arxiv.org/abs/2301.12688,144855826,"dynamic storyboard generation in an engine-based virtual environment for
  video production",2023-07-21T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Individual sports competitions provide a natural setting for examining the
relative importance of talent and luck/chance in achieving success. The belief
that success is primarily due to individual abilities and hard work rather than
external factors is particularly strong in this context. In this study, we test
this belief using tennis as a case study, due to its popularity and competition
structure in direct-elimination tournaments. Our dataset covers the decade
2010-2019 of main events in the ATP circuit and consists of tourney results and
annual rankings for professional male players. After a preliminary data
analysis, we introduce an agent-based model able to accurately simulate the
tennis players' dynamics along several seasons. We show that, once calibrated
on the dataset, the model is able to reproduce the main stylized facts observed
in real data, including the results of single tournaments and the development
of players' careers in the ATP community. The strength of our approach lies in
its simplicity: it requires only one free parameter a to determine the
importance of talent in scoring every single point: a = 1, if only talent
matters; a = 0, if the outcome of each point is entirely due to chance. We find
the best agreement between real data and simulation results when talent weights
substantially less than luck, i.e. when a is between 0.20 and 0.30. A further
comparison between data and simulations, based on the analysis of the direct
networks of all the matches, confirms the previous finding. A posteriori, we
notice that this surprisingly important role of chance in tennis tournaments is
not an exception. On the contrary, it can be explained by a more general
paradoxical effect that characterizes highly competitive environments,
particularly in individual sports. In other words, when the difference in
talent between top players is minimal, chance becomes determinant.Comment: 19 pages,17 figure",10.1016/j.chaos.2023.114088,http://arxiv.org/abs/2311.06268,153804644,the paradox of talent: how chance affects success in tennis tournaments,2023-10-05T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Linguistic steganography (LS) aims to embed secret information into a highly
encoded text for covert communication. It can be roughly divided to two main
categories, i.e., modification based LS (MLS) and generation based LS (GLS).
Unlike MLS that hides secret data by slightly modifying a given text without
impairing the meaning of the text, GLS uses a trained language model to
directly generate a text carrying secret data. A common disadvantage for MLS
methods is that the embedding payload is very low, whose return is well
preserving the semantic quality of the text. In contrast, GLS allows the data
hider to embed a high payload, which has to pay the high price of
uncontrollable semantics. In this paper, we propose a novel LS method to modify
a given text by pivoting it between two different languages and embed secret
data by applying a GLS-like information encoding strategy. Our purpose is to
alter the expression of the given text, enabling a high payload to be embedded
while keeping the semantic information unchanged. Experimental results have
shown that the proposed work not only achieves a high embedding payload, but
also shows superior performance in maintaining the semantic consistency and
resisting linguistic steganalysis",,http://arxiv.org/abs/2203.03795,140137467,"semantic-preserving linguistic steganography by pivot translation and
  semantic-aware bins coding",2022-03-07T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Calibration inductive logics are based on accepting estimates of relative frequencies, which are used to generate imprecise probabilities. In turn, these imprecise probabilities are intended to guide beliefs and decisions — a process called “calibration”. Two prominent examples are Henry E. Kyburg's system of Evidential Probability and Jon Williamson's version of Objective Bayesianism. There are many unexplored questions about these logics. How well do they perform in the short-run? Under what circumstances do they do better or worse? What is their performance relative to traditional Bayesianism?

In this article, we develop an agent-based model of a classic binomial decision problem, including players based on variations of Evidential Probability and Objective Bayesianism. We compare the performances of these players, including against a benchmark player who uses standard Bayesian inductive logic. We find that the calibrated players can match the performance of the Bayesian player, but only with particular acceptance thresholds and decision rules. Among other points, our discussion raises some challenges for characterising “cautious” reasoning using imprecise probabilities. Thus, we demonstrate a new way of systematically comparing imprecise probability systems, and we conclude that calibration inductive logics are surprisingly promising for making decisions",10.1016/j.ijar.2023.109030,https://core.ac.uk/download/590393609.pdf,151843415,making decisions with evidential probability and objective bayesian calibration inductive logics,2023-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Long counseling Text Generation for Mental health support (LTGM), an
innovative and challenging task, aims to provide help-seekers with mental
health support through a comprehensive and more acceptable response. The
combination of chain-of-thought (CoT) prompting and Large Language Models
(LLMs) is employed and get the SOTA performance on various NLP tasks,
especially on text generation tasks. Zero-shot CoT prompting is one of the most
common methods in CoT prompting. However, in the LTGM task, Zero-shot CoT
prompting can not simulate a counselor or provide personalized strategies
without effective mental health counseling strategy prompts. To tackle this
challenge, we propose a zero-shot Dynamic Strategy Chain (DSC) prompting
method. Firstly, we utilize GPT2 to learn the responses written by mental
health counselors and dynamically generate mental health counseling strategies
tailored to the help-seekers' needs. Secondly, the Zero-shot DSC prompting is
constructed according to mental health counseling strategies and the
help-seekers' post. Finally, the Zero-shot DSC prompting is employed to guide
LLMs in generating more human-like responses for the help-seekers. Both
automatic and manual evaluations demonstrate that Zero-shot DSC prompting can
deliver more human-like responses than CoT prompting methods on LTGM tasks",,http://arxiv.org/abs/2308.10444,145573460,"dynamic strategy chain: dynamic zero-shot cot for long mental health
  support generation",2023-08-20T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Physics-informed neural networks have emerged as a coherent framework for
building predictive models that combine statistical patterns with domain
knowledge. The underlying notion is to enrich the optimization loss function
with known relationships to constrain the space of possible solutions.
Hydrodynamic simulations are a core constituent of modern cosmology, while the
required computations are both expensive and time-consuming. At the same time,
the comparatively fast simulation of dark matter requires fewer resources,
which has led to the emergence of machine learning algorithms for baryon
inpainting as an active area of research; here, recreating the scatter found in
hydrodynamic simulations is an ongoing challenge. This paper presents the first
application of physics-informed neural networks to baryon inpainting by
combining advances in neural network architectures with physical constraints,
injecting theory on baryon conversion efficiency into the model loss function.
We also introduce a punitive prediction comparison based on the
Kullback-Leibler divergence, which enforces scatter reproduction. By
simultaneously extracting the complete set of baryonic properties for the Simba
suite of cosmological simulations, our results demonstrate improved accuracy of
baryonic predictions based on dark matter halo properties, successful recovery
of the fundamental metallicity relation, and retrieve scatter that traces the
target simulation's distribution",,http://arxiv.org/abs/2303.14090,152090010,"physics-informed neural networks in the recreation of hydrodynamic
  simulations from dark matter",2023-10-19T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The 43rd UID conference, held in Genova, takes up the theme of ‘Dialogues’ as practice and debate on many fundamental topics in our social life, especially in these complex and not yet resolved times. The city of Genova offers the opportunity to ponder on the value of comparison and on the possibilities for the community, naturally focused on the aspects that concern us, as professors, researchers, disseminators of knowledge, or on all the possibile meanings of the discipline of representation and its dialogue with ‘others’, which we have broadly catalogued in three macro areas: History, Semiotics, Science / Technology. Therefore, “dialogue” as a profitable exchange based on a common language, without which it is impossible to comprehend and understand one another; and the graphic sign that connotes the conference is the precise transcription of this concept: the title ‘translated’ into signs, derived from the visual alphabet designed for the visual identity of the UID since 2017. There are many topics which refer to three macro sessions: - Witnessing (signs and history) - Communicating (signs and semiotics) - Experimenting (signs and sciences) Thanks to the different points of view, an exceptional resource of our disciplinary area, we want to try to outline the prevailing theoretical-operational synergies, the collaborative lines of an instrumental nature, the recent updates of the repertoires of images that attest and nourish the relations among representation, history, semiotics, sciences",10.3280/oa-832-c95,https://core.ac.uk/download/552147416.pdf,136089541,chapter rappresentare il paesaggio urbano: segni per un’identità dinamica,2022-01-01T00:00:00,'Franco Angeli',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Along with the implementation of the independent curriculum, teacher readiness in implementing the independent curriculum is something that is absolutely realized so that the expected goals can be achieved. No matter how good a curriculum is, if the teacher does not have the readiness and skills, then the curriculum cannot be realized properly. This shows that the curriculum and teachers have a very close relationship. This study aims to determine the readiness of elementary school teachers in implementing the independent curriculum. This research uses descriptive research type. The object of this research is teacher readiness in implementing the independent curriculum at Muhammadiyah 1 Ketelan Elementary School, Surakarta. Meanwhile, the subjects of this study were school principals and teachers as actors in implementing the independent curriculum. Data collection techniques in this study include interviews, observation, and documentation. Test the validity of the data in this study using method triangulation and theory triangulation. Data analysis techniques in this study used data reduction (data reduction), data display (data presentation), and conclusion drawing/verification (drawing conclusions. The results of this study indicate that overall the teacher is ready to implement the independent curriculum. Outline of the six indicators of teacher readiness have fulfilled four indicators.With the other two indicators teachers still feel they do not understand and still need training regarding the preparation of teaching modules and learning assessment in the independent curriculu",10.30997/dt.v10i2.9761,https://core.ac.uk/download/599112148.pdf,153501378,analysis of teachers readiness in implementing the independent curriculum in elementary schools,2023-10-30T00:00:00,Universitas Djuanda,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Brazilian writer João Paulo Cuenca uses futuristic Tokyo as a venue for his antithetical love story that portrays a father ensnaring his adult son through a city-wide surveillance network. Foucault’s panopticism in Discipline and Punish (1975) reflects the wire taps and hidden cameras in Cuenca’s dystopic novel, revealing how technology intensifies the scale ranging from virtual invasion to physical brutality. Much as social media has changed the definition of “friend” and blurred the division between public and private life, the protagonist’s social web reveals that alliances are deceiving. Cuenca’s work exhibits the alarming reality in which concepts like identity and friendship are manipulated by society’s most powerful members. Cuenca’s dystopic society permits and encourages the multifaceted dehumanization of women’s bodies and analogizes media presence as a tool for personal freedom, illicit surveillance, and violence",10.34632/diffractions.2022.10218,https://core.ac.uk/download/525631712.pdf,123433363,inescapable prints: panoptic surveillance and violence in joão paulo cuenca’s o único final feliz para uma história de amor é um acidente,2022-05-16T01:00:00,Universidade Católica Portuguesa,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
https://egrove.olemiss.edu/thedmonline/2396/thumbnail.jp,,https://core.ac.uk/download/568301276.pdf,145420463,"february 2, 2023",2023-02-02T08:00:00,eGrove Press,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We analyze the performance of the best-response dynamic across all
normal-form games using a random games approach. The playing sequence -- the
order in which players update their actions -- is essentially irrelevant in
determining whether the dynamic converges to a Nash equilibrium in certain
classes of games (e.g. in potential games) but, when evaluated across all
possible games, convergence to equilibrium depends on the playing sequence in
an extreme way. Our main asymptotic result shows that the best-response dynamic
converges to a pure Nash equilibrium in a vanishingly small fraction of all
(large) games when players take turns according to a fixed cyclic order. By
contrast, when the playing sequence is random, the dynamic converges to a pure
Nash equilibrium if one exists in almost all (large) games.Comment: JEL codes: C62, C72, C73, D83 Keywords: Best-response dynamics,
  equilibrium convergence, random games, learning models in game",,https://core.ac.uk/download/534192510.pdf,128171297,"best-response dynamics, playing sequences, and convergence to equilibrium in random games",2021-01-01T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In the fall of 2020, amidst the COVID-19 pandemic, higher education institutions found themselves with more time to consider how to best use and refine educational technology that had been urgently implemented or expanded during the spring and summer. Despite taking this additional time, it often felt as though the desire to provide normalcy—amongst abnormal conditions—took precedence over privacy protections. Examples such as promoting classroom engagement by requiring students to have their cameras on during synchronous online instruction illustrate this attempt to bridge normality within remote services. Another example of this tendency is online proctoring, in which the need to ensure academic integrity is used to justify the implementation of software that leverages surveillance and harmful technology.
I am employed at an institution that supports online proctoring as a method of instruction and has a contract with an online proctoring service, ProctorU. When I first learned this information, I felt a call to action. Just as a sense of urgency helped guide the implementation of online proctoring services, my own urgency guided my attempts at dismantling its use. Through this article, I will explain online and remote proctoring, the harms it poses to students, and why librarians should care about it. Furthermore, I'll outline my own efforts to eliminate proctoring software on my campus, how they fell short, and how we can envision better methods of dismantling surveillance",,https://core.ac.uk/download/578223930.pdf,150080031,learning better for the next thing: online proctoring services and privacy advocacy outside the library,2022-03-22T00:00:00,Oregon Library Association,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"In establishing the Journal of Material Culture in 1996, the editors opened the first issue with an editorial that made the case that material culture studies is an undisciplined field of study. In framing it in this manner, they highlighted the intellectual freedom gained by drawing from multiple disciplinary insights and methodological approaches. In the 1990s, the research group was expanded, incorporating more of an archaeological influence from Cambridge, with the addition of Chris Tilley and Victor Buchli – both students of Ian Hodder. Within the anthropological attention to material culture, there has always been the critical issue of temporality as it is inscribed in the object. As Pinney reminds people, the Durkheimian tradition approaches objects as a historical record of society. Despite the many moves beyond representation, aesthetics, language, and semiotics, this chapter highlights a need to maintain these analytical registers in exploring material cultural phenomena",,https://core.ac.uk/download/323198495.pdf,147762770,introduction,2020-11-10T00:00:00,'Informa UK Limited',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"What does modern economics mean when it talks about the future and predicts the future? Where does it reach out to when it wants to secure the future for people or keep it open? How was the future experienced and thought of in Greek times, an epoch in which the possibility of theory formation first arose, and thus the foundation was laid for a knowledge of the future? This volume brings together the contributions to two colloquia held at the Free University of Bozen-Bolzano in 2013 and 2014 on the relationship between economics and the future and aims to point out the questionable nature of this relationship. With this intention, the terms ""economy"" and ""future"" lose their unambiguity and become questionable in their turn.; Was meint die moderne Wirtschaftswissenschaft, wenn sie von Zukunft redet und Künftiges vorhersagt? Wohin greift sie aus, wenn sie die Zukunft für den Menschen sichern oder offen halten will? Wie wurde Zukunft im Griechentum erfahren und gedacht, einer Epoche, in der zuerst die Möglichkeit einer Theoriebildung aufkam, und damit der Grundstein gelegt wurde für ein Wissen von Zukunft? Der vorliegende Band versammelt die Beiträge zu zwei in den Jahren 2013 und 2014 an der Freien Universität Bozen abgehaltenen Kolloquien zum Verhältnis von Ökonomie und Zukunft und möchte auf das Fragwürdige dieses Verhältnisses hinweisen. In dieser Absicht verlieren die Begriffe „Ökonomie“ und „Zukunft“ ihre Eindeutigkeit und werden ihrerseits fragwürdig",10.13124/9788860461223,https://core.ac.uk/download/487599698.pdf,120410263,ökonomie und zukunft,2021-12-07T16:15:08,"bu,press",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"“Latvian Grammar” was written to make information about the Latvian language and its grammatical system more easily available not only within Latvia, but also beyond its borders. A modern grammar of Latvian written in English is as important for native speakers of Latvian as for those who have learned Latvian as a second language and also is of great value for anyone interested in the culture and history of Latvia or the Latvian language itself. The need for a reference grammar of Latvian written in English is especially important right now due to the existence of a large Latvian diaspora community abroad, particularly in English-speaking countries where children and young people are educated in the language of their home countries rather than in Latvian. A Latvian grammar written in English will also be useful for those who are learning Latvian as a foreign language and wish to learn more about its grammatical system and unique features. Likewise, “Latvian grammar” will be a useful reference and source for examples for teachers of Latvian – both those who teach it to speakers as a school or university subject and those who teach it as a foreign language. There is also considerable demand among linguists abroad for a systematic and dependable description of Latvian written by native speakers of Latvian. Latvian is a rather unique combination of ancient as well as relatively new features, which are of interest to researchers abroad and are important for the typological, cognitive, pragmatic, functional, and contrastive analysis of language.University of Latvia
State research program “Letonika – the history, languages, culture, values of Latvia",10.22364/latgram.2021,https://core.ac.uk/download/421067331.pdf,40884743,latvian grammar,2021-04-20T01:00:00,'University of Latvia',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This article introduces a new method to support critical media literacy, learning and research in higher education. It acts as a response to an unprecedented profusion of visual information across digital media that contributes to the contemporary post-truth era, marked by fake news and uncritical consumption of the media. Whereas much has been written about the reasons behind and the character of the post-truth, less space has been dedicated to how educators could counteract the uncritical consumption of images from the perspective of semiotics. This article adopts a unique semiotic approach to address the stated gap. It discusses in depth the meaning making of pictures, digital photographs and material objects that photographs can embody. It does so by focusing on three aspects of a pictorial sign: 1) the materiality of its representation and representational elements, 2) its object (what the sign refers to), and 3) its descriptive interpretations. These three aspects inform the Signification analysis within the proposed Production-Signification-Consumption (PSC) method, exemplified with digital photographs. Understanding and analysing images via the PSC method draws attention to how humans create, interpret, (re)use, consume, and respond to online and offline communication signs. The method can contribute to the development of critical media literacy as an engagement with postdigital semiotics, much needed in an age of global ecological and social crises, uncertainty, and fast consumption of digital content",10.1007/s42438-019-00099-y,https://core.ac.uk/download/286353476.pdf,18621868,thinking with digital images in the post-truth era:a method in critical media literacy,2020-02-05T00:00:00,'Springer Science and Business Media LLC',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Hybrid tabular-textual question answering (QA) requires reasoning from
heterogeneous information, and the types of reasoning are mainly divided into
numerical reasoning and span extraction. Despite being the main challenge of
the task compared to extractive QA, current numerical reasoning method simply
uses LSTM to autoregressively decode program sequences, and each decoding step
produces either an operator or an operand. However, the step-by-step decoding
suffers from exposure bias, and the accuracy of program generation drops
sharply with progressive decoding. In this paper, we propose a
non-autoregressive program generation framework, which facilitates program
generation in parallel. Our framework, which independently generates complete
program tuples containing both operators and operands, can significantly boost
the speed of program generation while addressing the error accumulation issue.
Our experiments on the MultiHiertt dataset shows that our model can bring about
large improvements (+7.97 EM and +6.38 F1 points) over the strong baseline,
establishing the new state-of-the-art performance, while being much faster
(21x) in program generation. The performance drop of our method is also
significantly smaller than the baseline with increasing numbers of numerical
reasoning steps",,http://arxiv.org/abs/2211.03462,134913283,"napg: non-autoregressive program generation for hybrid tabular-textual
  question answering",2022-11-07T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Treating collections in cultural institutions as data encourages novel approaches to the use of historic collections. To reframe collections as data is to focus on how digitized collection material, collection metadata, and transcriptions can be used and reused for various types of computational analysis. Scholars active in the field of digital humanities have long taken advantage of computational data. This paper focuses on the work of cultural heritage institutions, which are increasingly offering collections as data. This paper outlines the collections as data project and examines specific examples of cultural institutions active in this space. The paper then details the practices of data brokers, and explores how the data broker model can frame the use of data in cultural heritage institutions. In closing a number of experiments are described that might help mitigate the harm that data in cultural institutions might cause. As we create and share data, can we be sure we are better than data brokers",,https://core.ac.uk/download/346612499.pdf,96742753,open data in cultural heritage institutions: can we be better than data brokers?,2020-01-01T08:00:00,LSU Digital Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"An idealized, though simplistic, view of the referring expression production
and grounding process in (situated) dialogue assumes that a speaker must merely
appropriately specify their expression so that the target referent may be
successfully identified by the addressee. However, referring in conversation is
a collaborative process that cannot be aptly characterized as an exchange of
minimally-specified referring expressions. Concerns have been raised regarding
assumptions made by prior work on visually-grounded dialogue that reveal an
oversimplified view of conversation and the referential process. We address
these concerns by introducing a collaborative image ranking task, a grounded
agreement game we call ""A Game Of Sorts"". In our game, players are tasked with
reaching agreement on how to rank a set of images given some sorting criterion
through a largely unrestricted, role-symmetric dialogue. By putting emphasis on
the argumentation in this mixed-initiative interaction, we collect discussions
that involve the collaborative referential process. We describe results of a
small-scale data collection experiment with the proposed task. All discussed
materials, which includes the collected data, the codebase, and a containerized
version of the application, are publicly available.Comment: Published at LREC 202",,http://arxiv.org/abs/2309.05162,149190569,collecting visually-grounded dialogue with a game of sorts,2023-09-10T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
,,https://core.ac.uk/download/483709216.pdf,150247219,emilia rensi and the italian counter-narrative on cristo-colombo (‘christ-columbus’) and otherness,2021-11-10T00:00:00,Literature & Aesthetics,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Permainan Puzzle merupakan permainan yang banyak diminati oleh kalangan banyak orang baik usia anak anak, remaja maupun orang dewasa. Permainan ini bisa juga dikatakan sebagai permainan yang mengasa otak dan menyenangkan. Permasalahan penelitian ini yaitu susah bagi user mencari solusi untuk menumukan goal antara algoritma Simple Hill Climbing dan Ascent hill Climbing. Manfaat permainan Puzzle yaitu&nbsp; mempelajari susunan huruf alfabert, Game puzzle memiliki banyak manfaat bagi perkembangan pola pikir&nbsp; seperti perkembangan kognitif, mengasah kemampuan dalam ingatan, Kemampuan metorik, melatih bentuk koordinasi mata dan tangan, mampu mencari solusi untuk memecahkan masalah dan yang lainnya. Tujuan penelitian ini yaitu mempermudah para pemain game puzzle untuk menyelesaikan permainan dengan cepat dan memperoleh solusi akhir untuk menyelesaikan permasalahan pada game puzzle. Untuk menyelesaikan solusi&nbsp; Menggunakan Algoritma Simple Hill Climbing dan Ascent hill Climbing, dari hasil kedua algoritma tersebut dibandingkan mana algoritma yang paling cepat menemukan solusi akhir Algoritma Ascent hill Climbing lebih cepat menemukan solusi karena proses pengerjaan nya langsung dan hasilnya terlihat lebih cepat dan jelas. 6 proses iterasi untuk menyelesaikan kasus game puzzle",,https://core.ac.uk/download/567873016.pdf,148295102,expert system  perbandingan algoritma simple hill climbing dan steepest ascent hill climbing,2023-06-02T01:00:00,LPPM UNIKA Santo Thomas,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The psychology of argumentation (PSA), has added new insight into argumentation theory and informal logic, fields that so far have been strongly influenced by the philosophy of argumentation (PHA). One assumption with regard to the PSA is that reasoning is argumentative and constructed to persuade. Thus, the successful outcome of reasoning is the ability to persuade for action to adapt to specific situations. Whereas biased beliefs – generated by mechanisms such as confirmation bias and motivated reasoning – might sway production and evaluation of arguments significantly. Arguers do not primarily activate reasoning for logical purposes; they do so rather to justify particular beliefs as well as actions. In contrast, from a critical PHA-perspective, reasoning is analyzed and corrected as fallacious and slippery communication in line with a normatively demanding perspective of the PHA. Insight from the PHA on smooth, manipulative, and outsmarting dialogue shifts might be decisive for understanding the outcome of a debate or group work. Another way in which the PSA and the PHA can complement each other concerns the fact that the PSA gathers data in the lab (cf. in vitro/”in glass”, referring to a lab) while the PHA does so by field studies (cf. in vivo).  In this paper I will indicate how knowledge from the PSA and the PHA might be complementary approaches",,https://core.ac.uk/download/323559038.pdf,71885359,broadening “in situ” for improving argument evaluation?,2020-06-05T19:00:00,Scholarship at UWindsor,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"English necessitates a linguistic distinction when coding for spatial relations that Spanish does not necessarily make: that of differentiating between CONTACT and CONTAINMENT. Image schemas of CONTACT and CONTAINMENT are evoked when using language to distinguish between these two spatial relations. The speech of Spanish-English simultaneous bilingual children, aged four and seven, was studied to find out to what degree they are linguistically able to evoke these two different image schemas and thus make this distinction when speaking in English. 32 situations of CONTACT and CONTAINMENT were focused on and the children were prompted to describe them using.  The four-year-old showed a much lower command at coding for CONTACT linguistically in English than the seven-year-old. The seven-year-old was able to produce all the kinds of spatial relations at a much higher rate of accuracy though his use of for lack of CONTAINMENT, presented his greatest challenge.Al contrario de lo que ocurre en español, en inglés es necesario
marcar lingüísticamente la diferencia entre las relaciones espaciales
RECIPIENTE y CONTACTO. Los esquemas de imagen de RECIPIENTE y
CONTACTO se pueden evocar cuando el lenguaje se utiliza para distinguir entre
estas dos relaciones espaciales. En el estudio que aquí presentamos, realizado
sobre niños bilingües simultáneos de español-inglés de 4 y 7 años, comprobamos
la capacidad y el grado para evocar estos dos esquemas, y por lo tanto, expresar
esta distinción cuando hablan en inglés. El estudio se centró en 32 situaciones
de RECIPIENTE y CONTACTO en las que se les pedía a los niños que las
describieran utilizando las preposiciones in, out, on y off. El niño informante de
7 años mostró mucho mayor dominio lingüístico en inglés en la codificación de
CONTACTO que el niño de 4 años. El niño de 7 años fue capaz de producir todo
tipo de relaciones espaciales en inglés con mayor ratio de precisión, aunque su
mayor reto lo encontramos en el uso de la preposición out",10.6035/clr.2020.23.2,https://core.ac.uk/download/344689282.pdf,45996516,"esquemas de imagen de contenido y contacto en discurso de niños
bilingües de español-inglés: un estudio de caso",2020-05-10T01:00:00,'Universitat Jaume I',"[{'title': 'Cultura Lenguaje y Representación', 'identifiers': ['issn:1697-7750', '1697-7750']}]",core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
This oral history conversation is an interview with David Bruemmer,,https://core.ac.uk/download/160256920.pdf,51950574,oral history conversation with david bruemmer,2018-04-01T08:00:00,Digital USD,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"There has been considerable divergence of opinion on the reasoning abilities
of Large Language Models (LLMs). While the initial optimism that reasoning
might emerge automatically with scale has been tempered thanks to a slew of
counterexamples, a wide spread belief in their iterative self-critique
capabilities persists. In this paper, we set out to systematically investigate
the effectiveness of iterative prompting of LLMs in the context of Graph
Coloring, a canonical NP-complete reasoning problem that is related to
propositional satisfiability as well as practical problems like scheduling and
allocation. We present a principled empirical study of the performance of GPT4
in solving graph coloring instances or verifying the correctness of candidate
colorings. In iterative modes, we experiment with the model critiquing its own
answers and an external correct reasoner verifying proposed solutions. In both
cases, we analyze whether the content of the criticisms actually affects bottom
line performance. The study seems to indicate that (i) LLMs are bad at solving
graph coloring instances (ii) they are no better at verifying a solution--and
thus are not effective in iterative modes with LLMs critiquing LLM-generated
solutions (iii) the correctness and content of the criticisms--whether by LLMs
or external solvers--seems largely irrelevant to the performance of iterative
prompting. We show that the observed increase in effectiveness is largely due
to the correct solution being fortuitously present in the top-k completions of
the prompt (and being recognized as such by an external verifier). Our results
thus call into question claims about the self-critiquing capabilities of state
of the art LLMs.Comment: 18 pages, 3 figure",,http://arxiv.org/abs/2310.12397,152091491,"gpt-4 doesn't know it's wrong: an analysis of iterative prompting for
  reasoning problems",2023-10-18T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Consciousness has an important role in ethics: when a being consciously experiences the frustration or satisfaction of its interests, those interests deserve higher moral priority than those of a behaviourally similar but non-conscious being. I consider the relationship between this ethical role and an a posteriori (or ‘type-B’) materialist solution to the mind-body problem. It is hard to avoid the conclusion that, if type-B materialism is correct, then the reference of the concept Phenomenal Consciousness is radically indeterminate between a neuronal-level property that is distinctive to mammals and a high-level functional property that is much more widely shared. This would leave many non-mammalian animals (such as birds, fish, insects and octopuses) with indeterminate moral status. There are ways to manage this radical moral indeterminacy, but all of these ways lead to profoundly troubling consequences",10.1093/pq/pqab072,https://core.ac.uk/download/511316308.pdf,18689604,materialism and the moral status of animals,2022-01-17T00:00:00,'Oxford University Press (OUP)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
https://digitalcommons.usu.edu/covid/1064/thumbnail.jp,,https://core.ac.uk/download/545810823.pdf,133451135,interview with garth mikesell,2022-12-01T08:00:00,DigitalCommons@USU,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Treball final de Grau en Disseny i Desenvolupament de Videojocs. Codi: VJ1241. Curs acadèmic: 2021/2022Fatum is an unconventional puzzle and adventure game in which
we will control a creature that wakes up in an unknown place in
ruins without knowing who it is and how it got there. It will have to
advance through short stages and solve the puzzles it finds to advance
and escape. This work consists of the implementation of the first level
of the game, which includes the tutorial and the design of a narrative
whose backbone is the major figures of the Tarot known as the Major
Arcana.[19] Academically, this document consists of the final degree
project report of the Video game Design and Development bachelor’s
degree at the Jaume I University",,https://core.ac.uk/download/570977565.pdf,150486226,final degree work report fatum a tarot based puzzle adventure,2022-05-25T01:00:00,'Universitat Jaume I',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We study the Densest Subgraph problem under the additional constraint of
differential privacy. In the LEDP (local edge differential privacy) model,
introduced recently by Dhulipala et al. [FOCS 2022], we give an $(\epsilon,
\delta)$-differentially private algorithm with no multiplicative loss: the loss
is purely additive. This is in contrast to every previous private algorithm for
densest subgraph (local or centralized), all of which incur some multiplicative
loss as well as some additive loss. Moreover, our additive loss matches the
best-known previous additive loss (in any version of differential privacy) when
$1/\delta$ is at least polynomial in $n$, and in the centralized setting we can
strengthen our result to provide better than the best-known additive loss.
Additionally, we give a different algorithm that is $\epsilon$-differentially
private in the LEDP model which achieves a multiplicative ratio arbitrarily
close to $2$, along with an additional additive factor. This improves over the
previous multiplicative $4$-approximation in the LEDP model. Finally, we
conclude with extensions of our techniques to both the node-weighted and the
directed versions of the problem.Comment: 41 page",,http://arxiv.org/abs/2308.10316,145572287,"improved differentially private densest subgraph: local and purely
  additive",2023-08-20T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The perspective of autonomous vehicles running on our roads has come closer and closer to reality over the last decades, and this technology might be implemented during the upcoming years. However, this will only be achievable through constant investigation and efforts in all the fields of science covered by the Connected and Automated Vehicles (CAV). The present study focuses on the behaviour of CAV platoons in highways, and more precisely experiments an algorithm to get rid of propagating perturbations, such as the bullwhip effect, that affects the proper functioning of the platoon. This algorithm manages to simulate a sequential acceleration where each vehicle is given an individual pattern to follow before it even performs its manoeuvre, thanks to the current and objective parameters that its disposes of. These individual patterns are coordinated and prevent therefore any bullwhip effect. Nevertheless, a misconception in the theoretical model elaborated prevents the vehicles to reach their objective Desired Space Gap (DSG), and modifications must still be made to obtain an operational algorithm in regular driving conditions. Some ideas are mentioned to improve the model in this sense, as well as an alternative method to look into, based on dynamic equations",,https://core.ac.uk/download/491491637.pdf,133440428,microsimulation of connected automated vehicles in platooning conditions in highways,2021-10-05T01:00:00,Universitat Politècnica de Catalunya,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Treball final de Grau en Disseny i Desenvolupament de Videojocs. Codi: VJ1241. Curs acadèmic: 2021/2022This document represents the technical report of the Final Degree Project of Fernando
Villanueva Padrones for the Bachelor’s Degree in Video Game Design and Development.
This work consists of a First Person Shooter (FPS) in Virtual Reality (VR) where the
player takes the role of a space agent that has been left alone in a space station. Sadly
for him, there is no escape from this base, so his only hope in order to survive is to
wait for a future rescue. However, he is surrounded by all types of enemies that will try
to kill him in order to establish their new life in this base. Obviously, the player will
have a weapon to defend himself, clearing all the rooms and overcoming the level. These
dungeons are generated in a procedural way within a range of rooms depending on the
current level in which the player is located. In addition, at each level, the player will
be able to choose an object located in a special room so his stats can be improved or
worsened",,https://core.ac.uk/download/570977573.pdf,150486124,development of a virtual reality first person shooter game with procedural map generation,2022-07-14T01:00:00,'Universitat Jaume I',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Most theoretical frameworks that focus on data errors and inconsistencies follow logic-based reasoning. Yet, practical data cleaning tools need to incorporate statistical reasoning to be effective in real-world data cleaning tasks. Motivated by empirical successes, we propose a formal framework for unclean databases, where two types of statistical knowledge are incorporated: The first represents a belief of how intended (clean) data is generated, and the second represents a belief of how noise is introduced in the actual observed database. To capture this noisy channel model, we introduce the concept of a Probabilistic Unclean Database (PUD), a triple that consists of a probabilistic database that we call the intention, a probabilistic data transformator that we call the realization and captures how noise is introduced, and an observed unclean database that we call the observation. We define three computational problems in the PUD framework: cleaning (infer the most probable intended database, given a PUD), probabilistic query answering (compute the probability of an answer tuple over the unclean observed database), and learning (estimate the most likely intention and realization models of a PUD, given examples as training data). We illustrate the PUD framework on concrete representations of the intention and realization, show that they generalize traditional concepts of repairs such as cardinality and value repairs, draw connections to consistent query answering, and prove tractability results. We further show that parameters can be learned in some practical instantiations, and in fact, prove that under certain conditions we can learn a PUD directly from a single dirty database without any need for clean examples",10.4230/lipics.icdt.2019.6,https://core.ac.uk/download/343692191.pdf,39974599,a formal framework for probabilistic unclean databases,2019-01-01T00:00:00,LIPIcs - Leibniz International Proceedings in Informatics. 22nd International Conference on Database Theory (ICDT 2019),[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Vision Transformers (ViTs) have achieved state-of-the-art performance on
various vision tasks. However, ViTs' self-attention module is still arguably a
major bottleneck, limiting their achievable hardware efficiency. Meanwhile,
existing accelerators dedicated to NLP Transformers are not optimal for ViTs.
This is because there is a large difference between ViTs and NLP Transformers:
ViTs have a relatively fixed number of input tokens, whose attention maps can
be pruned by up to 90% even with fixed sparse patterns; while NLP Transformers
need to handle input sequences of varying numbers of tokens and rely on
on-the-fly predictions of dynamic sparse attention patterns for each input to
achieve a decent sparsity (e.g., >=50%). To this end, we propose a dedicated
algorithm and accelerator co-design framework dubbed ViTCoD for accelerating
ViTs. Specifically, on the algorithm level, ViTCoD prunes and polarizes the
attention maps to have either denser or sparser fixed patterns for regularizing
two levels of workloads without hurting the accuracy, largely reducing the
attention computations while leaving room for alleviating the remaining
dominant data movements; on top of that, we further integrate a lightweight and
learnable auto-encoder module to enable trading the dominant high-cost data
movements for lower-cost computations. On the hardware level, we develop a
dedicated accelerator to simultaneously coordinate the enforced denser/sparser
workloads and encoder/decoder engines for boosted hardware utilization.
Extensive experiments and ablation studies validate that ViTCoD largely reduces
the dominant data movement costs, achieving speedups of up to 235.3x, 142.9x,
86.0x, 10.1x, and 6.8x over general computing platforms CPUs, EdgeGPUs, GPUs,
and prior-art Transformer accelerators SpAtten and Sanger under an attention
sparsity of 90%, respectively.Comment: Accepted to HPCA 202",,http://arxiv.org/abs/2210.09573,136809673,"vitcod: vision transformer acceleration via dedicated algorithm and
  accelerator co-design",2022-12-10T00:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Probabilistic programming and statistical computing are vibrant areas in the
development of the Julia programming language, but the underlying
infrastructure dramatically predates recent developments. The goal of
MeasureTheory.jl is to provide Julia with the right vocabulary and tools for
these tasks.
  In the package we introduce a well-chosen set of notions from the foundations
of probability together with powerful combinators and transforms, giving a
gentle introduction to the concepts in this article.
  The task is foremost achieved by recognizing measure as the central object.
This enables us to develop a proper concept of densities as objects relating
measures with each others. As densities provide local perspective on measures,
they are the key to efficient implementations.
  The need to preserve this computationally so important locality leads to the
new notion of locally-dominated measure solving the so-called base measure
problem and making work with densities and distributions in Julia easier and
more flexible",10.21105/jcon.00092,https://core.ac.uk/download/552894635.pdf,124064233,applied measure theory for probabilistic modeling,2022-01-01T00:00:00,'The Open Journal',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Page 1 Dean\u27s MessagePage 2 Awards and RecognitionPage 3-4  Nobel Recipient Visits CampusPage 4 Adopting the PantryPage 5 Growing a Recruitment MindsetPage 6 February Outreach EventsPage 7 Media Coverage of CNSPage 8 Open PRAIRIE DataPage 9 54th Geography Convention, and Tom Loveland EROS Geography ScholarshipPage 10 Photos of Dr. Carolyn Bertozzi\u27s Visithttps://openprairie.sdstate.edu/consci_pubs/1033/thumbnail.jp",,https://core.ac.uk/download/556248231.pdf,142379569,"college of natural sciences newsletter, february 2023",2023-03-01T08:00:00,Open PRAIRIE: Open Public Research Access Institutional Repository and Information Exchange,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"As the concept of a “practice-ready” attorney continues to grow in both law firms and law schools, law school libraries are meeting this need by offering programming related to legal technology. In this article, a law librarian from the United States discusses their successes and failures in creating and maintaining legal technology programming, a first step in a larger conversation on practice-ready law graduates. This article is based on a June 2021 presentation given at the annual conference of the British and Irish Association of Law Librarians",,https://core.ac.uk/download/519794776.pdf,83322415,making the case for law tech,2022-01-01T08:00:00,FLASH: The Fordham Law Archive of Scholarship and History,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The study guide contains educational material on the main topics of the course of theoretical phonetics of English: the sound structure of the language and the ways of its description and analysis; features of the modern pronunciation norm of English as a polyethnic formation and its national and regional variants; sounds of English as articulatory and functional units; syllable as a phonetic and phonological unit, word emphasis; prosodic arrangement of English language. Questions and practical tasks for each unit provide an opportunity for self-study of educational material.
Meant for students, graduate students, teachers, and all interested in learning English",,https://core.ac.uk/download/339163278.pdf,33391457,introduction to theoretical phonetics of english,2020-01-01T00:00:00,'Sumy State University',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Student sculpture vandalized – Two choirs dismissed – Taylor celebrates athletic inclusion – Alumnus hired to connect students, alumni – Campus group prompts discussion on sexuality – Life from Breu – foody fix – Drone racing world champion returns to alma mater – The Weekly Bachelor and Bachelorette – “Bible Characters” Weekly Crossword -- #TaylorU’s Top Tweets – Taylor says goodbye to professor of music an Chorale – ‘Metcalf Open’ shows student talent – ‘Avengers: Endgame’ brings 22-movie saga to a close – Taylor cheerleaders hope to level up – Conor and Kerri Angell hold a bake sale for future adoption – Taylor should stand in the middle – Our View – One church family – Scripture mandates community on campus – Letters to the Editor – Politics need moral people – Women’s golf prepares for national tournament – Baseball on brink of tournament play – Weekly Preview – Scoreboard – Athletes of the Weekhttps://pillars.taylor.edu/echo-2018-2019/1023/thumbnail.jp",,https://core.ac.uk/download/427076994.pdf,112546674,"the echo: may 3, 2019",2019-05-03T08:00:00,Pillars at Taylor University,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The VR work Turpin's Cave (2018) began as an account of the author's childhood memories of a chimeric cave in Bostall Woods, South East London. That part of London is subject to dramatic sink holes and subsidence, which in this work are a metaphor for unreliable memory, but also, as the project unfolded, became a potent symbol for the increasingly precarious nature of contemporary employment. In creating this project, the author found herself engaging with a gig economy of actors operating within a creative precariat, in which the ‘choice’ and ‘flexibility’ of deregulated work arguably creates a veneer of individual freedom. Through this project the author seeks to deconstruct some of the rhetoric of empathy, choice and immersivity that has grown around VR, evaluating whether the ontological instability of the form has non-trivial connections to the increasing precarity of global employment (Wall, Lesley, Matthew Revie, and Tim Bedford. 2018. Risk, Reliability and Safety: Innovating Theory and Practice. London: Taylor & Francis)",10.1080/14794713.2019.1633149,https://core.ac.uk/download/219589057.pdf,8807840,turpin’s cave: choice and deception in a virtual realm,2018-03-21T00:00:00,'Informa UK Limited',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Large-scale noisy web image-text datasets have been proven to be efficient
for learning robust vision-language models. However, when transferring them to
the task of video retrieval, models still need to be fine-tuned on hand-curated
paired text-video data to adapt to the diverse styles of video descriptions. To
address this problem without the need for hand-annotated pairs, we propose a
new setting, text-video retrieval with uncurated & unpaired data, that during
training utilizes only text queries together with uncurated web videos without
any paired text-video data. To this end, we propose an approach, In-Style, that
learns the style of the text queries and transfers it to uncurated web videos.
Moreover, to improve generalization, we show that one model can be trained with
multiple text styles. To this end, we introduce a multi-style contrastive
training procedure that improves the generalizability over several datasets
simultaneously. We evaluate our model on retrieval performance over multiple
datasets to demonstrate the advantages of our style transfer framework on the
new task of uncurated & unpaired text-video retrieval and improve
state-of-the-art performance on zero-shot text-video retrieval.Comment: Published at ICCV 2023, code: https://github.com/ninatu/in_styl",,http://arxiv.org/abs/2309.08928,148053046,"in-style: bridging text and uncurated videos with style transfer for
  text-video retrieval",2023-09-16T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"This is the ninth edition of the Global Terrorism Index (GTI). The report provides a comprehensive summary of the key global trends and patterns in terrorism over the last decade. The calculation of the GTI score takes into account not only deaths, but also incidents, hostages, and injuries from terrorism, weighted over a five-year period. The GTI report is produced by the Institute for Economics & Peace (IEP) using data from TerrorismTracker and other sources. TerrorismTracker provides event records on terrorist attacks since 1 January 2007. The dataset contains over 60,500 terrorist incidents for the period 2007 to 2021",,https://core.ac.uk/download/539980289.pdf,127369454,global terrorism index 2022: measuring the impact of terrorism,2022-03-03T00:00:00,Institute for Economics & Peace,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Prof. Klaus Krippendorff is Gregory Bateson Emeritus Professor of Communication at the Annenberg School for Communication, University of Pennsylvania. He received his PhD in communications from the University of Illinois (Urbana) in 1967. He has received numerous awards and honours over the years. To name just a few, he received a Doctor of Philosophy honoris causa from the Linneaus University in Kalmar/Växjö, Sweden in 2012. He is an elected Fellow of the International Communication Association (ICA) and was its president in 1984–85. He is an elected Fellow of the American Association for the Advancement of Science (AAAS) in 1982. His book Content Analysis: An Introduction to Its Methodology received the ICA Fellows Book Award in 2004. He has published extensively in many fields including communication, research methodology, semantics, information theory, design, cybernetics, etc. In this academic dialogue, he talks about how he first came to the U. S. from Germany and his early encounter with the method of content analysis. He elaborates on his unique approach to the methodology of content analysis, its changes in practice over the years, as well as his insights on communication scholarship. His organic involvement in and cross-pollination of many related fields listed above is also revealed",,https://core.ac.uk/download/219380856.pdf,19089618,the changing landscape of content analysis: reflections on social construction of reality and beyond,2019-01-01T08:00:00,ScholarlyCommons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Algoritmos tornaram-se vetores sociais e constituidores de sentidos, pois tensionam e são tensionados pelas dinâmicas sociais da web. O artigo discute consumo e recepção online, e apresenta o Mapa do Sistema de Mediações Algorítmicas, a partir das proposições de Jesús Martín-Barbero, como um instrumento de apoio à reflexão sobre pesquisas em plataformas. O mapa é uma tentativa de alinhar os estudos culturais à contemporaneidade, permeada por fluxos algorítmicos, em que as plataformas digitais ganham importância como categoria de análise das mediações institucionais na recepção. Investiga-se como os conteúdos são consumidos em um cotidiano atravessado pelas práticas sociais originadas de outras mediações do sujeito.Algorithms have become social vectors and constituents of meanings as they apply tension and are tensioned by the social dynamics of the web. This article discusses online consumption and reception and presents the Algorithmic Mediation System Map, based on the propositions by Jesús Martín-Barbero, as an instrument to support reflections on platform studies. The map attempts to align cultural studies with contemporaneity, permeated by algorithmic flows, in which digital platforms gain importance as a category of analysis of institutional mediations in reception. We investigate how the contents are consumed in a daily life that is overcome by social practices originated from other mediations of the subject",,https://core.ac.uk/download/542560654.pdf,135561370,"from media to (algorithmic) mediations: mediation, reception, and consumption on digital platforms",2022-09-02T01:00:00,"Universidade de São Paulo. Escola de Comunicações e Artes, Programa de Pós-Graduação em Ciências da Comunicação",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
Senior Project submitted to The Division of Social Studies of Bard Colleg,,https://core.ac.uk/download/232619330.pdf,86479248,the open boat,2019-01-01T08:00:00,Bard Digital Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Video games are increasingly becoming a part of people’s daily lives. More importantly,
digital games have been increasingly built as products that challenge the player morally
and ethically. Video games do not only demonstrate their moral and ethical influence,
they also influence people's behavior by their own social, economic and historical
context. The choices people make in video games start from a moral, social, economic
and historical contextualization and it is important to understand the relationship that
is developed between players, their contextualization, and video games, in order to
understand how digital games can constitute themselves as moral and educational
challenges. Thus, it is intended to highlight the educational potential of digital games
through the influence they can have on shaking, challenging and consolidating people's
moral systems. The aim of this dissertation is to create a game about depression in order
to build not only an educational object, but also a product of self-expression that can help
depression-affected patients cope with their illness. The developed game aims to explore
the power that digital games can reveal in creating moments of reflection, contemplation
and moral challenges in the player. Basically, the aim is to find out if digital games have
the power to educate through the challenges they present to players. The video game
described in this dissertation was developed using the Unity game engine.Os videojogos fazem, cada vez mais, parte do quotidiano das pessoas. Mais importante,
os jogos digitais têm-se construído, progressivamente, como produtos que desafiam o
jogador moral e eticamente. Os videojogos não demonstram a sua influência apenas a
nível moral e ético, influenciam também o comportamento das pessoas pelo próprio
contexto social, económico e histórico em que se inserem. As escolhas que as pessoas
realizam nos videojogos partem de uma contextualização moral, social, económica e
histórica e importa compreender a relação que se desenvolve entre os jogadores, as suas
contextualizações, e os videojogos, de forma a compreender de que forma os videojogos
podem constituir-se como desafios morais e educacionais. Os objetivos desta dissertação
são, portanto, destacar o potencial educacional que os jogos digitais evidenciam através
da influência que podem ter no abalar, desafiar e consolidar dos sistemas morais das
pessoas, e entender, adicionalmente, se os jogos digitais podem servir como ferramentas
para a expressão daqueles que os desenvolvem. Isto é, procura-se descobrir o jogo digital
enquanto objeto artístico que possibilita a expressão por parte do criador da obra. Esta
dissertação tem como alvo criar um jogo sobre a depressão, de forma a construir não só
um objeto de expressão educativo, como também um produto que possa ajudar doentes
afetados pela depressão a lidar com a sua doença. Desta forma, o jogo procura informar
as pessoas que o jogarem sobre a vida de uma pessoa que sofre de uma doença mental,
neste caso, de depressão, elucidando-as sobre os riscos e sinais da depressão, permitindo
que elas os reconheçam através desta aprendizagem. O jogo retrata a história de uma
jovem que tenta cometer suicídio porque sofre de depressão e não consegue melhorar a
sua condição. A jovem já tinha tentado melhorar a sua condição de várias formas, mas
nunca conseguiu ver resultados. No fim, o suicídio pareceu-lhe a melhor opção. Depois
de tentar acabar com a sua vida, a personagem acorda num mundo fantástico,
desconhecido, que representa o coma em que se encontra submetida. Sirah, a
personagem principal, terá de desvendar o mundo onde se encontra e tentar combater a
sua depressão, numa batalha épica contra a doença. Para fazer isto, o jogador deverá
controlar a personagem e desvendar a aventura sobre a sua vida, levando-a até à
conclusão da sua história. Depois de conseguir derrotar a sua doença, Sirah acorda,
percebe que estava adormecida num coma e compreende o momento de catarse que
viveu. Assim sendo, o jogo desenvolvido pretende explorar o poder que os jogos digitais
podem revelar na criação de momentos de reflexão, contemplação e desafio moral no
jogador. No fundo, pretende-se averiguar se os jogos digitais têm o poder de educar através do desafio que apresentam perante os jogadores. O videojogo descrito nesta
dissertação foi desenvolvido utilizando o motor de jogo Unity",,https://core.ac.uk/download/385856286.pdf,107181878,inside: a video game about depression,2020-10-22T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We study financial networks and reveal a new kind of systemic risk arising from what we call default ambiguity — that is, a situation where it is impossible to decide which banks are in default. Specifically, we study the clearing problem: given a network of banks interconnected by financial contracts, determine which banks are in default and what percentage of their liabilities they can pay. Prior work has shown that when banks can only enter into debt contracts with each other, this problem always has a unique maximal solution. We first prove that when banks can also enter into credit default swaps (CDSs), the clearing problem may have no solution or multiple conflicting solutions, thus leading to default ambiguity. We then derive sufficient conditions on the network structure to eliminate these issues. Finally, we discuss policy implications for the CDS market",10.1287/mnsc.2019.3304,https://core.ac.uk/download/289704983.pdf,10446374,default ambiguity: credit default swaps create new systemic risks in financial networks,2019-01-01T00:00:00,'Institute for Operations Research and the Management Sciences (INFORMS)',[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The diversity of gender, culture, ability is recognized as a value both at the level of common sense and in the context of national and European legislation. It is necessary to question the effectiveness of work placement strategies, as a human qualification device, of disabled people who complete their university studies. How to manage risks and opportunities in order to effectively guide the work placement of disabled people who reach the end of their university career? This contribution aims to offer an in-depth study on the subject, with a particular focus on the figure of the pedagogist as a pedagogical operator of mediation between the University and the world of work.La diversità di genere, cultura, abilità è riconosciuta in quanto valore sia a livello del senso comune sia nel contesto nella Legislazione europea. È necessario, pertanto, interrogarsi circa l’efficacia delle strategie di collocamento lavorativo in quanto dispositivo di qualificazione umana e professionale, delle persone con disabilità che abbiano completato il proprio percorso di studi universitari. Come gestire rischi e opportunità al fine di guidare di il percorso di collocamento lavorativo per soggetti con disabilità che abbiano concluso il proprio percorso universitario? Il presente contributo si propone di offrire uno studio dell’argomento, con una particolare attenzione alla figura del&nbsp; pedagogista in quanto mediatore tra Università e mondo del Lavoro",10.7346/-fei-xx-02-22_22,https://core.ac.uk/download/539344763.pdf,126780888,il pedagogista in quanto diversity manager e mediatore tra università e mondo del lavoro,2022-08-30T01:00:00,Pensa MultiMedia,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Artists\u27 Genres is a brief introduction to the history of post-medieval Western art organized by the major genres. The book is designed as a basic textbook for high school- or introductory college-level courses or for individuals simply looking for an interesting guidebook into the art of this period and geographical region.
This is the revised edition of Artists\u27 Genres: A Brief Introduction to Post-Medieval Western Art, which was released in 2018.https://uknowledge.uky.edu/art_book/1001/thumbnail.jp",,https://core.ac.uk/download/423733552.pdf,84315858,artists\u27 genres: a brief introduction to post-medieval western art,2021-04-16T08:00:00,UKnowledge,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"We built these lessons around diversity, equity, and inclusion to help parents and teachers feel equipped in supporting critical thinking, continuous learning, and difficult conversations with young children. Our themed lessons include curated diverse books, reflection and discussion questions, and accompanying activities that align with social justice standards for children.
The themed lessons are not intended to be sequential nor a comprehensive representation of all of the potential learning out there! Navigate the lessons in any order that you choose. We encourage you to create your own based on your interests, historical and contemporary throughlines, holidays, family events, and more.https://griffinshare.fontbonne.edu/westories-dei-lessons/1000/thumbnail.jp",,https://core.ac.uk/download/578701777.pdf,148455112,dei-themed lessons,2023-07-01T08:00:00,GriffinShare,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
https://ir.uiowa.edu/littlevillage/1228/thumbnail.jp,,https://core.ac.uk/download/213505528.pdf,61712980,"little village october 4 - october 17, 2017",2017-10-04T08:00:00,"Steele, Matthew",[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Detecting the presence of project management anti-patterns (AP) currently
requires experts on the matter and is an expensive endeavor. Worse, experts may
introduce their individual subjectivity or bias. Using the Fire Drill AP, we
first introduce a novel way to translate descriptions into detectable AP that
are comprised of arbitrary metrics and events such as logged time or
maintenance activities, which are mined from the underlying source code or
issue-tracking data, thus making the description objective as it becomes
data-based. Secondly, we demonstrate a novel method to quantify and score the
deviations of real-world projects to data-based AP descriptions. Using nine
real-world projects that exhibit a Fire Drill to some degree, we show how to
further enhance the translated AP. The ground truth in these projects was
extracted from two individual experts and consensus was found between them. Our
evaluation spans three kinds of pattern, where the first is purely derived from
description, the second type is enhanced by data, and the third kind is derived
from data only. The Fire Drill AP as translated from description only for
either, source code- or issue-tracking-based detection, shows weak potential of
confidently detecting the presence of the anti-pattern in a project. Enriching
the AP with data from real-world projects significantly improves detection.
Using patterns derived from data only leads to almost perfect correlations of
the scores with the ground truth. Some APs share symptoms with the Fire Drill
AP, and we conclude that the presence of similar patterns is most certainly
detectable. Furthermore, any pattern that can be characteristically modeled
using the proposed approach is potentially well detectable.Comment: 208 page",10.13140/rg.2.2.35805.33766/2,http://arxiv.org/abs/2104.15090,115647771,"technical reports compilation: detecting the fire drill anti-pattern
  using source code and issue-tracking data",2021-06-29T01:00:00,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Welcome Center .......................4
Spotlight on business ...............5
Hazard Pay ................................5
Community Food Center ........7
Poem by Nyamuon Nguany
Machar .......................................8
Fufu & Math ........................... 14
Legislative Update ..................15
Singer Clarisse Karasira ........37
DEI/Lewiston............................ 3
Translations French ......................9/13
Swahili ....................10/13
Somali ...............11/13/36
Kinyarwanda .........12/32
Portuguese .............30/32
Spanish ...................31/32
Health&Wellness. ..............20-27
Nutritious eating
In English & translation
Columns New Voices ................8/34/35
Professional Development ... 7
Ask the District Attorney....16
Bureau of Motor Vehicles ...16
Ask the Doctor ....................19
Finance ................................. 33
Community organizations. 28
Beautiful Blackbird .............18
Let’s Talk ...............................35
Maine Immigration .............36
Iraqi immigration freeze ....39https://digitalcommons.usm.maine.edu/samgen_amjambo/1046/thumbnail.jp",,https://core.ac.uk/download/555363415.pdf,140123270,amjambo africa! (march 2022),2022-03-01T08:00:00,USM Digital Commons,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Increasing the competence of vocational education teachers is an urgent need. This will ensure that vocational education can provide maximum benefits for students and align with the dynamics of the ever-evolving world of work. Data was collected using systematic literature method. The results of the study show that the urgency of the vocational competence of teachers in the era of society era 5.0 is very important and studies are needed to improve it. Overall, the urgency of improving teacher vocational competence in the current era is closely related to preparing students to contribute to the changing world of work and improving the quality of vocational education as a whole. By increasing the qualifications and knowledge of teachers in the vocational field, we can ensure that the education provided matches the demands of the labor market and produces students who are ready for the future. Some of the skills that teachers must have in this era include digital skills, adaptive skills, critical and creative thinking skills, multicultural skills, skills in implementing Teaching Factory in the learning process, collaboration and emotional social skills. Society Era 5.0 provides significant benefits for the realm of vocational education. In this era, digital technologies such as artificial intelligence (AI) and the Internet of Things (IoT) can be used in the vocational learning process. Technology-based learning systems enable more interactive and realistic practical experiences, through simulation and virtualization. This shows that more efforts are being made to develop vocational teacher competencies, especially for vocational education concept competencies",10.33487/edumaspul.v7i2.7588,https://core.ac.uk/download/599789021.pdf,154157273,the urgency of increasing teacher vocational competence in the era of society 5.0,2024-02-08T00:00:00,Universitas Muhammadiyah Enrekang,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"The purpose of this article is to investigate the complex link between theatre, as a practice involving a number of people, and the change in the use of dramatic texts occurred at the origins of the Italian printing industry, when dramatic texts were no longer only acted but also read as books. With the invention of printed books, theatre has been transformed from a performative action to a container of memory images fixed through the book illustration.
	On the one hand, the article investigates the printed tradition of sacre rappresentazioni (sacred plays) in connection with the other religious literary texts published between the end of the fifteenth and the beginning of sixteenth centuries, putting it in relation with the birth of devotional books widely used in Florence during the age of Savonarola. On the other hand, it will deal with the problem of illustrations by reconstructing the relationship between faithful people and sacred images before their diffusion was multiplied by the printing industry, and by looking at the real meaning of the link between written texts and woodcuts, in order to understand how the sacra rappresentazione, being a dramatic genre, was conceived when it was transformed into an object for readin",10.13128/jems-2279-7149-24883,https://core.ac.uk/download/195801803.pdf,57100492,acting and reading drama: notes on florentine \u2018sacre rappresentazioni\u2019 in print,2019-01-01T00:00:00,Firenze University Press,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Microbe Hunters by Paul de Kruif was first published in 1926 by Harcourt, Brace and Company, New York. It dramatically recounts the breakthrough discoveries of the fundamental elements of bacteriology. It features exciting profiles of Antony Leeuwenhoek, Lazzaro Spallanzani, Louis Pasteur, Robert Koch, Émile Roux, Emil Behring, Élie Metchnikoff, Theobald Smith, David Bruce, Ronald Ross, Battista Grassi, Walter Reed, and Paul Ehrlich. Their development of germ theory and its scientific proofs led to the first effective treatments for human diseases like anthrax, rabies, diptheria, malaria, sleeping sickness, syphilis, and yellow fever. They also made discoveries that saved the dairy, wine, beer, silk, and cattle industries. These determined experimenters proved time and again that tiny living beings only seen by microscope can have huge impacts on human life, and they emphatically demonstrated the value of science for modern civilization. A best seller in its time, the work is an enduring classic that has inspired many scientific careers.
Paul de Kruif (1890–1971) was an American microbiologist and World War I veteran who turned to writing after his dismissal from the Rockefeller Institute for Medical Research because of his controversial opinions on current medical practice published in a book of essays. Among his other works, he also assisted Sinclair Lewis with the background of science for the novel Arrowsmith (1925).
doi: 10.32873/unl.dc.zea.1503https://digitalcommons.unl.edu/zeabook/1147/thumbnail.jp",,https://core.ac.uk/download/573443493.pdf,146692648,microbe hunters,2023-07-12T08:00:00,DigitalCommons@University of Nebraska - Lincoln,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
ope,,https://core.ac.uk/download/570941312.pdf,150711461,rupi kaur's poetry: trauma and healing,2022-04-08T11:54:07,,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
"Detailed report on the efforts by the US government to manage Indian affairs, educate the Indians, and legislation regarding the Indians. In part, issues covered relate to employees, farming, health, schools, specific tribes, irrigation, forestry, minerals, supplies, finances, and statistics.https://digitalcommons.csumb.edu/hornbeck_usa_2_e/1037/thumbnail.jp",,https://core.ac.uk/download/229519794.pdf,67507796,1918 - report of the commissioner of indian affairs for 1918,2017-05-03T08:00:00,Digital Commons @ CSUMB,[],core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence')
