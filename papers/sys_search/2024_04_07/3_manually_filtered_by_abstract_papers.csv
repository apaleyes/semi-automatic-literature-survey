id,status,doi,publisher,database,query_name,query_value,url,publication_date,title,abstract,semantic_score
1,excluded,10.1145/3075564.3076259,Conf. Computing Frontiers,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/250f130fadcec134088be094b230489286dadf8e,2017-01-01 00:00:00,bonseyes: platform for open development of systems of artificial intelligence: invited paper,"The Bonseyes EU H2020 collaborative project aims to develop a platform consisting of a Data Marketplace, a Deep Learning Toolbox, and Developer Reference Platforms for organizations wanting to adopt Artificial Intelligence. The project will be focused on using artificial intelligence in low power Internet of Things (IoT) devices (""edge computing""), embedded computing systems, and data center servers (""cloud computing""). It will bring about orders of magnitude improvements in efficiency, performance, reliability, security, and productivity in the design and programming of systems of artificial intelligence that incorporate Smart Cyber-Physical Systems (CPS). In addition, it will solve a causality problem for organizations who lack access to Data and Models. Its open software architecture will facilitate adoption of the whole concept on a wider scale. To evaluate the effectiveness, technical feasibility, and to quantify the real-world improvements in efficiency, security, performance, effort and cost of adding AI to products and services using the Bonseyes platform, four complementary demonstrators will be built. Bonseyes platform capabilities are aimed at being aligned with the European FI-PPP activities and take advantage of its flagship project FIWARE. This paper provides a description of the project motivation, goals and preliminary work.",0.8214880228042603
2,excluded,http://arxiv.org/abs/1911.02912v1,arxiv,arxiv,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),http://arxiv.org/abs/1911.02912v1,2019-10-15 00:00:00,priority quality attributes for engineering ai-enabled systems,"Deploying successful software-reliant systems that address their mission
goals and user needs within cost, resource, and expected quality constraints
require design trade-offs. These trade-offs dictate how systems are structured
and how they behave and consequently can effectively be evolved and sustained.
Software engineering practices address this challenge by centering system
design and evolution around delivering key quality attributes, such as
security, privacy, data centricity, sustainability, and explainability. These
concerns are more urgent requirements for software-reliant systems that also
include AI components due to the uncertainty introduced by data elements.
Moreover, systems employed by the public sector exhibit unique design time and
runtime challenges due to the regulatory nature of the domains. We assert that
the quality attributes of security, privacy, data centricity, sustainability,
and explainability pose new challenges to AI engineering and will drive the
success of AI-enabled systems in the public sector. In this position paper, we
enumerate with examples from healthcare domain concerns related to these
requirements to mitigate barriers to architecting and fielding AI-enabled
systems in the public sector.",0.8663809895515442
3,excluded,10.1109/jas.2020.1003432,IEEE/CAA Journal of Automatica Sinica,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/7bb320e281f16a476255a5c654c48e4644a6c3ed,2021-01-01 00:00:00,towards a theoretical framework of autonomous systems underpinned by intelligence and systems sciences,"Autonomous systems are an emerging AI technology functioning without human intervention underpinned by the latest advances in intelligence, cognition, computer, and systems sciences. This paper explores the intelligent and mathematical foundations of autonomous systems. It focuses on structural and behavioral properties that constitute the intelligent power of autonomous systems. It explains how system intelligence aggregates from reflexive, imperative, adaptive intelligence to autonomous and cognitive intelligence. A hierarchical intelligence model ( HIM ) is introduced to elaborate the evolution of human and system intelligence as an inductive process. The properties of system autonomy are formally analyzed towards a wide range of applications in computational intelligence and systems engineering. Emerging paradigms of autonomous systems including brain-inspired systems, cognitive robots, and autonomous knowledge learning systems are described. Advances in autonomous systems will pave a way towards highly intelligent machines for augmenting human capabilities.",0.8254063129425049
4,excluded,10.1080/14606925.2019.1594979,core,core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://core.ac.uk/download/196591310.pdf,2019-04-01 01:00:00,"forget the singularity, its mundane artificial intelligence that should be our immediate concern","Fuelled by Science Fiction and the pronouncements of Silicon Valley gurus such as Elon Musk, the ‘Singularity’ is arguably the biggest geek myth of our time and is distracting us from addressing the numerous problems emerging with the increasing use of Artificial intelligence (AI). Artificial General Intelligence (AGI) is often perceived to mean super human like intelligence such as the ones depicted in movies like Her (2013) and Ex Machina (2014). These anthropomorphic representations of AI besiege our attention away from the very real threat of biases introduced through Machine Learning (ML). In this paper we will consider whether current practices within Human-Centred Design (HCD) permit designers to consider interactions and services in which non-human algorithms play a significant role and consider how approaches inspired by Object Oriented Ontology (OOO) may offer newperspectives for framing design activities concerning AI",0.8563174605369568
5,included,10.1515/auto-2022-0076,at - Automatisierungstechnik,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/f8492b9265e21f7db13c71214b68d640c6bf3903,2022-01-01 00:00:00,ki-engineering – ai systems engineering,Abstract KI-Engineering – translated as AI Systems Engineering – aims at the development of a new engineering practice in the intersection of Systems Engineering and Artificial Intelligence. Its goal is to professionalize the use of AI methods in a systems engineering context. The article defines KI-Engineering and compares it with historical examples of research disciplines that founded engineering disciplines. It furthermore discusses the long-term challenges where further development is needed and which results were already achieved in the context of the Competence Center for KI-Engineering (CC-KING).,0.8826118111610413
6,excluded,10.1109/cain58948.2023.00019,IEEE,ieeexplore,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://ieeexplore.ieee.org/document/10164777/,2023-05-16 00:00:00,conceptualising software development lifecycle for engineering ai planning systems,"Given the prominence of AI planning in research and industry, the development of AI planning software and its integration into production architectures are becoming important. However, building and managing planning software is a complex and expertise-dependent process without methodological support that would ensure AI planning applications have high quality and industrial strength. To that end, we propose a lifecycle for developing AI planning systems that consists of ten phases related to the design, development, and operation of planning systems.",0.8290835022926331
7,included,10.1109/sose55472.2022.9812672,International Symposium on Service Oriented Software Engineering,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/5a19c398c2b4738f5eb473a175807bb9b59e6d71,2022-01-01 00:00:00,engineering dependable ai systems,"If AI algorithms are now pervasive in our daily life, they essentially deliver non critical services, i.e., services which failures remain socially and economically acceptable. In order to introduce those algorithms in critical systems, new engineering practices must be defined to give a justified trust in the capability of the system to deliver the intended services. In this paper, we give an overview of the approach that we have put in place to reach this goal in the framework of the French Confiance.ai program. Based on the needs of the industrial partners of the program, we propose a model-based analysis framework capturing the two dimensions of the problem: the one related to the development and operation of the system and the one related to the trust in the system.",0.8794834017753601
8,excluded,10.1109/cesser-ip.2019.00008,IEEE,ieeexplore,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://ieeexplore.ieee.org/document/8836177/,2019-05-28 00:00:00,best practices for engineering ai-infused applications: lessons learned from microsoft teams,"Artificial intelligence and machine learning (AI/ML) are some of the newest trends to hit the software industry, compelling organizations to evolve their development processes to deliver novel products to their customers. In this talk, I describe a study in which we learned how Microsoft software teams develop AI/ML-based applications using a nine-stage AI workflow process informed by prior experiences developing early AI applications (e.g. search and NLP) and data science tools (e.g. application telemetry and bug reporting). Adapting this workflow into their pre-existing, well-evolved, Agile-like software engineering processes and job roles has resulted in a number of engineering challenges unique to the AI/ML domain, some universal to all teams, but others related to the amount of prior AI/ML experience and education the teams have. I tell you about some challenges and the solutions that teams have come up with. The lessons that Microsoft has learned can help other organizations embarking on their own path towards AI and ML.",0.8530495762825012
9,excluded,10.23919/istafrica.2017.8101981,IEEE,ieeexplore,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://ieeexplore.ieee.org/document/8101981/,2017-06-02 00:00:00,managing diseases thru' asclepios: an agile information exploitation framework,"This paper describes the development of an open-source information system, called Asclepios, which manages a plethora of information on communicable diseases in an agile manner. Asclepios exploits information from multiple databases from both open sources (Third Party) and Second party sources. A variety of tools are available in Asclepios to perform extensive processing of numeric and texts (along with some image and video processing) so that trend information can be gleaned on various communicable diseases. The Asclepios architecture draws together a confluence of technologies and industrial standards such as: cloud computing, metadata, ontology generation and management, artificial intelligence, pattern recognition, decision support system, data mining and systems engineering. Because of the use of Component Based Software Engineering (CBSE) methodology for its design, the architecture is scalable, its components replaceable dynamically and configured for the requirements of a given application. The underlying architecture of Asclepios is therefore horizontal, but it has an ability to support several verticals as epidemiology, pharmacology and other fields easily. The application of Asclepios is wide ranging - from military to Government through to medical and tourism and pharmaceuticals. Further, Asclepios-like applications are very much needed in most Third world countries, including all countries in Africa, as it can significantly enhance the health, safety and well-being of people.",0.8005644679069519
10,excluded,http://arxiv.org/abs/1707.09095v2,arxiv,arxiv,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),http://arxiv.org/abs/1707.09095v2,2017-07-28 00:00:00,toward the starting line: a systems engineering approach to strong ai,"Artificial General Intelligence (AGI) or Strong AI aims to create machines
with human-like or human-level intelligence, which is still a very ambitious
goal when compared to the existing computing and AI systems. After many hype
cycles and lessons from AI history, it is clear that a big conceptual leap is
needed for crossing the starting line to kick-start mainstream AGI research.
This position paper aims to make a small conceptual contribution toward
reaching that starting line. After a broad analysis of the AGI problem from
different perspectives, a system-theoretic and engineering-based research
approach is introduced, which builds upon the existing mainstream AI and
systems foundations. Several promising cross-fertilization opportunities
between systems disciplines and AI research are identified. Specific potential
research directions are discussed.",0.8995599150657654
11,excluded,10.1017/9781108616188.008,Next-Generation Ethics,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/b0c820f9d7fa4d8c56a7887548834b7ba65ddfa5,2017-01-01 00:00:00,guidelines for artificial intelligence containment,"With almost daily improvements in capabilities of artificial intelligence it is more important than ever to develop safety software for use by the AI research community. Building on our previous work on AI Containment Problem we propose a number of guidelines which should help AI safety researchers to develop reliable sandboxing software for intelligent programs of all levels. Such safety container software will make it possible to study and analyze intelligent artificial agent while maintaining certain level of safety against information leakage, social engineering attacks and cyberattacks from within the container.",0.8141870498657227
12,excluded,10.1109/ms.2020.2993662,IEEE Software,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/05086329135fdb15049a5ac8edd7f980762f2097,2020-01-01 00:00:00,what is really different in engineering ai-enabled systems?,"Advances in machine learning (ML) algorithms and increasing availability of computational power have resulted in huge investments in systems that aspire to exploit artificial intelligence (AI), in particular ML. AIenabled systems, software-reliant systems that include data and components that implement algorithms mimicking learning and problem solving, have inherently different characteristics than software systems alone.1 However, the development and sustainment of such systems also have many parallels with building, deploying, and sustaining software systems. A common observation is that although software systems are deterministic and you can build and test to a specification, AI-enabled systems, in particular those that include ML components, are generally probabilistic. Systems with ML components can have a high margin of error due to the uncertainty that often follows predictive algorithms. The margin of error can be related to the inability to predict the result in advance or the same result cannot be reproduced. This characteristic makes AI-enabled systems hard to test and verify.2 Consequently, it is easy to assume that what we know about designing and reasoning about software systems does not immediately apply in AI engineering. AI-enabled systems are software systems. The sneaky part about engineering AI systems is they are ""just like"" conventional software systems we can design and reason about until they?re not.",0.9178138971328736
13,excluded,http://arxiv.org/abs/2307.04495v1,arxiv,arxiv,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),http://arxiv.org/abs/2307.04495v1,2023-07-10 00:00:00,"model-driven engineering method to support the formalization of machine
  learning using sysml","Methods: This work introduces a method supporting the collaborative
definition of machine learning tasks by leveraging model-based engineering in
the formalization of the systems modeling language SysML. The method supports
the identification and integration of various data sources, the required
definition of semantic connections between data attributes, and the definition
of data processing steps within the machine learning support.
  Results: By consolidating the knowledge of domain and machine learning
experts, a powerful tool to describe machine learning tasks by formalizing
knowledge using the systems modeling language SysML is introduced. The method
is evaluated based on two use cases, i.e., a smart weather system that allows
to predict weather forecasts based on sensor data, and a waste prevention case
for 3D printer filament that cancels the printing if the intended result cannot
be achieved (image processing). Further, a user study is conducted to gather
insights of potential users regarding perceived workload and usability of the
elaborated method.
  Conclusion: Integrating machine learning-specific properties in systems
engineering techniques allows non-data scientists to understand formalized
knowledge and define specific aspects of a machine learning problem, document
knowledge on the data, and to further support data scientists to use the
formalized knowledge as input for an implementation using (semi-) automatic
code generation. In this respect, this work contributes by consolidating
knowledge from various domains and therefore, fosters the integration of
machine learning in industry by involving several stakeholders.",0.8103031516075134
14,excluded,10.15407/pp2022.03-04.099,PROBLEMS IN PROGRAMMING,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/17f80eaec2808e01a766be634fa5b77e9dfa57ef,2022-01-01 00:00:00,some aspects of software engineering for ai-based systems,"AI-based software systems are rapidly spreading in various business areas. In this context, the unavoidable convergence of the Software Engineering and Artificial Intelligence and Machine Learning (AI/ML) disciplines is considered an obvious and one of the following significant challenges within the engineering process. The life cycle, models, and technologies of AI/ML elements are pretty specific, and this should be considered in software engineering to ensure their performance and compliance with business needs. AI/ML applications have some distinct characteristics compared to traditional software applications. Thus, several challenges and risk factors regarding AI/ML applications appear to software developers. To study the common challenges in AI/ML application development, we used two different perspectives: software engineering and machine learning. AI/ML applications, like other software systems, need a well-defined software engineering process for their development and maintenance. We discussed challenges and recommendations for different phases of the software development life cycle for ML applications, particularly requirement engineering, design, implementation, integration, testing, and deployment. AI/ML application development has specific aspects to consider as a software development project. We discussed the characteristics and recommendations concerning problem formulation, data acquisition, preprocessing, feature extraction, model building, evaluation, model integration and deployment, model management, and ethics in AI/ML development. In the work, there were formulated recommendations for each analyzed challenge that should be useful for software developers. The next stage of this research is the compilation of detailed systematic guidelines for the software development process for AI/ML systems.",0.87928307056427
15,excluded,10.1089/cyber.2016.29060.csi,"Cyberpsychology, Behavior, and Social Networking",semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/9e1dff6f8cb4a2dab6fa8705f5fe17cd562928c9,2017-01-01 00:00:00,bringing more transparency to artificial intelligence,"The development of artificial intelligence (AI) has taken giant steps during the last decade to the point that for many experts, including the world-renowned atrophysics Stephen Hawking and hi-tech entrepreneur Elon Musk, AI could even destroy civilization by overtaking humans. However, on the other hand, AI may bring about huge benefits for humankind, some of which may be still beyond our imagination today. Thus, the scientific community is faced with the challenge of how we can develop powerful AI systems that support civilization while at the same time preventing the potential side effects of an uncontrolled AI evolution. To address these challenges, in late September 2016, tech giants Google, Facebook, Microsoft, Amazon, and IBM launched a ‘‘Partnership on Artificial Intelligence To Benefit People and Society.’’ The new alliance has been established ‘‘to study and formulate best practices on AI technologies, to advance the public’s understanding of AI, and to serve as an open platform for discussion and engagement about AI and its influences on people and society’’ (https://www .partnershiponai.org/). As claimed in the mission statement, a specific goal of the initiative is to help improving public awareness of what is happening in the AI field, where a number of players are shaping the future of intelligent services. Also, the Partnership aims to create more inclusive discussion by extending participation from AI specialists to activists and experts in other disciplines, such as psychology, philosophy, economics, finance, sociology, public policy, and law, to discuss and provide guidance on emerging issues related to the impact of AI on society. The Partnership has the potential to create a greater multidisciplinary understanding of the opportunities and challenges associated with potential breakthroughs in this field. Yet, some key players, such as Apple and Elon Musk’s OpenAI—a nonprofit AI research project (https://www .openai.com/blog/)—have not yet joined the club. While the goals of the Partnership have been set, the strategy that the alliance intends to put in place to attain these objectives is still unclear. Thus, it is too early to understand how the association will concretely address the challenges that need to be addressed with the public, such as how AI can be used safely to support military activities, or how to deal with the legal responsibilities for any damage caused by AI to humans.",0.8062982559204102
16,included,10.18293/seke2020-094,International Conference on Software Engineering and Knowledge Engineering,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/36e614624eca44d7854c982d089e033658b50431,2020-01-01 00:00:00,guidelines for quality assurance of machine learning-based artificial intelligence,"Significant effort is being put into developing industrial applications for artificial intelligence (AI), especially those using machine learning (ML) techniques. Despite the intensive support for building ML applications, there are still challenges when it comes to evaluating, assuring, and improving the quality or dependability. The difficulty stems from the unique nature of ML, namely, system behavior is derived from training data not from logical design by human engineers. This leads to black-box and intrinsically imperfect implementations that invalidate many principles and techniques in traditional software engineering. In light of this situation, the Japanese industry has jointly worked on a set of guidelines for the quality assurance of AI systems (in the Consortium of Quality Assurance for AI-based Products and Services) from the viewpoint of traditional quality-assurance engineers and test engineers. We report on the second version of these guidelines, which cover a list of quality evaluation aspects, catalogue of current state-of-the-art techniques, and domain-specific discussions in five representative domains. The guidelines provide significant insights for engineers in terms of methodologies and designs for tests driven by application-specific requirements.",0.8727734684944153
17,included,10.48550/arxiv.2208.02837,Artificial General Intelligence,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/21672a43ee8ea925173702fe034cbde18d9c773a,2022-01-01 00:00:00,core and periphery as closed-system precepts for engineering general intelligence,"Engineering methods are centered around traditional notions of decomposition and recomposition that rely on partitioning the inputs and outputs of components to allow for component-level properties to hold after their composition. In artificial intelligence (AI), however, systems are often expected to influence their environments, and, by way of their environments, to influence themselves. Thus, it is unclear if an AI system's inputs will be independent of its outputs, and, therefore, if AI systems can be treated as traditional components. This paper posits that engineering general intelligence requires new general systems precepts, termed the core and periphery, and explores their theoretical uses. The new precepts are elaborated using abstract systems theory and the Law of Requisite Variety. By using the presented material, engineers can better understand the general character of regulating the outcomes of AI to achieve stakeholder needs and how the general systems nature of embodiment challenges traditional engineering practice.",0.8783146739006042
18,excluded,10.54364/aaiml.2023.1156,Advances in Artificial Intelligence and Machine Learning,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/1e9c639bb2221483575b27cc99c3a448ba894270,2019-01-01 00:00:00,superintelligence safety: a requirements engineering perspective,"Under the headline “AI safety”, a wide-reaching issue is being discussed, whether in the future some “superhuman artificial intelligence” / “superintelligence” could pose a threat to humanity. In addition, the late Steven Hawking warned that the rise of robots may be disastrous for mankind. A major concern is that even benevolent superhuman artificial intelligence (AI) may become seriously harmful if its given goals are not exactly aligned with ours, or if we cannot specify precisely its objective function. Metaphorically, this is compared to king Midas in Greek mythology, who expressed the wish that everything he touched should turn to gold, but obviously this wish was not specified precisely enough. In our view, this sounds like requirements problems and the challenge of their precise formulation. (To our best knowledge, this has not been pointed out yet.) As usual in requirements engineering (RE), ambiguity or incompleteness may cause problems. In addition, the overall issue calls for a major RE endeavor, figuring out the wishes and the needs with regard to a superintelligence, which will in our opinion most likely be a very complex software-intensive system based on AI. This may even entail theoretically defining an extended requirements problem.",0.8132004737854004
19,excluded,10.1109/ms.2022.3193975,IEEE Software,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/8df4c04b25a24a8d941ed50401d92faf183ade63,2022-01-01 00:00:00,taming data quality in ai-enabled industrial internet of things,We address the problem of taming data quality in artificial intelligence (AI)-enabled Industrial Internet of Things systems by devising machine learning pipelines as part of a decentralized edge-to-cloud architecture. We present the design and deployment of our approach from an AI engineering perspective using two industrial case studies.,0.8093363046646118
20,included,10.1109/acsos55765.2022.00030,International Conference on Autonomic Computing and Self-Organizing Systems,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/d1e8e98848d6a4cad32c1fe9ad7eb051f37256bd,2022-01-01 00:00:00,a modular and composable approach to develop trusted artificial intelligence,"Trustworthy artificial intelligence (Trusted AI) is of utmost importance when learning-enabled components (LECs) are used in autonomous, safety-critical systems. When reliant on deep learning, these systems need to address the reliability, robustness, and interpretability of learning models. In addition to developing specific strategies to address each of these concerns, appropriate software architectures are needed to coordinate LECs and ensure they deliver acceptable behavior under uncertain conditions. This work proposes a model-driven framework of loosely-coupled modular services designed to monitor and control LECs with respect to Trusted AI assurance concerns. The proposed framework is composable, deploying independent services to improve the resilience and robustness of AI systems. The overarching objective of this framework is to support software engineering principles focusing on modularity, composability, and reusability in order to facilitate development and maintenance tasks, while also increasing stakeholder confidence in Trusted AI systems. To demonstrate this framework, it has been implemented to manage the operation of an autonomous rover’s vision-based LEC while exposed to uncertain environmental conditions.",0.8028196096420288
21,included,http://arxiv.org/abs/2302.07872v1,arxiv,arxiv,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),http://arxiv.org/abs/2302.07872v1,2023-02-14 00:00:00,data-centric governance,"Artificial intelligence (AI) governance is the body of standards and
practices used to ensure that AI systems are deployed responsibly. Current AI
governance approaches consist mainly of manual review and documentation
processes. While such reviews are necessary for many systems, they are not
sufficient to systematically address all potential harms, as they do not
operationalize governance requirements for system engineering, behavior, and
outcomes in a way that facilitates rigorous and reproducible evaluation. Modern
AI systems are data-centric: they act on data, produce data, and are built
through data engineering. The assurance of governance requirements must also be
carried out in terms of data. This work explores the systematization of
governance requirements via datasets and algorithmic evaluations. When applied
throughout the product lifecycle, data-centric governance decreases time to
deployment, increases solution quality, decreases deployment risks, and places
the system in a continuous state of assured compliance with governance
requirements.",0.8804633617401123
22,included,10.1109/syscon53536.2022.9773829,IEEE,ieeexplore,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://ieeexplore.ieee.org/document/9773829/,2022-04-28 00:00:00,closed systems paradigm for intelligent systems,"Intelligent systems ought to be distinguished as a special type of system. While some adopt this view informally, in practice, systems engineering methods for intelligent systems are still centered around traditional systems engineering notions of engineering by aggregation of components. We posit that this traditional approach follows from holding a notion of open systems as the fundamental precept, and that engineering intelligent systems, in contrast, requires an approach that holds notions of closed systems as fundamental precepts. We take a systems theoretic approach to defining closed system phenomena and their relation to engineering intelligence. We propose the concept of variety; particularly the law of requisite variety to enable closed view in engineering. We discuss how open and closed view approaches to engineering intelligent systems address variety differently, as well as the implications of this difference on engineering practice.",0.8415651321411133
23,excluded,10.1109/ase51524.2021.9678647,International Conference on Automated Software Engineering,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/87cc86ba7b42c45a0b924bffc1ad602dc688648f,2021-01-01 00:00:00,towards fluid software architectures: bidirectional human-ai interaction,"The research on engineering software applications that employ artificial intelligence (AI) and machine learning (ML) is at an all-time peak. However, most of the research in this area is focused on the interactions between humans and AI which, in turn, is predominantly concerned with either building immersive interfaces and user experiences that allow for increased telemetry or on handling AI and ML applications in production (MLOps). Nonetheless, the research on fundamental architectural differences between AI-powered applications and traditional ones did not receive its fair share of attention. To that end, we believe that a new take on the fundamental architecture of building software applications is needed. With the ever increasing prominence of content-driven AI-powered applications, it is our conviction that 1) content could be served by servers without clients requesting, 2) servers could (should) request data from clients without waiting for their requests, and 3) interfaces should dynamically adapt to updates that happen to the intelligence driving the application. Hence, in this paper, we propose the fluid architecture that facilitates the bidirectional interaction between clients and servers as well as accommodates the co-dependent evolution of interfaces and back-end intelligence in AI-powered systems.",0.8270476460456848
24,included,10.48550/arxiv.2203.00905,arXiv.org,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/da40fe10253e732460baff189e7c8cdac9e6033d,2022-01-01 00:00:00,responsible-ai-by-design: a pattern collection for designing responsible ai systems,"Although AI has significant potential to transform society, there are serious concerns about its ability to behave and make decisions responsibly. Many ethical regulations, principles, and guidelines for responsible AI have been issued recently. However, these principles are high-level and difficult to put into practice. In the meantime much effort has been put into responsible AI from the algorithm perspective, but they are limited to a small subset of ethical principles amenable to mathematical analysis. Responsible AI issues go beyond data and algorithms and are often at the system-level crosscutting many system components and the entire software engineering lifecycle. Based on the result of a systematic literature review, this paper identifies one missing element as the system-level guidance - how to design the architecture of responsible AI systems. We present a summary of design patterns that can be embedded into the AI systems as product features to contribute to responsible-AI-by-design.",0.8269172310829163
25,included,10.1145/3522664.3528598,2022 IEEE/ACM 1st International Conference on AI Engineering – Software Engineering for AI (CAIN),semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/bfa3cb3fae2d4fcc66b18dba752467f4f5861073,2022-01-01 00:00:00,ai governance in the system development life cycle: insights on responsible machine learning engineering,"In this study we explore the incorporation of artificial intelligence (AI) governance to system development life cycle (SDLC) models. We conducted expert interviews among AI and SDLC professionals and analyzed the interview data using qualitative coding and clustering to extract AI governance concepts. Subsequently, we mapped these concepts onto three stages in the machine learning (ML) system development process: (1) design, (2) development, and (3) operation. We discovered 20 governance concepts, some of which are relevant to more than one of the three stages. Our analysis highlights AI governance as a complex process that involves multiple activities and stakeholders. As development projects are unique, the governance requirements and processes also vary. This study is a step towards understanding how AI governance is conceptually connected to ML systems’ management processes through the project life cycle. CCS CONCEPTS • Software and its engineering $^{\rightarrow}$ Software creation and management.",0.8494580388069153
26,included,10.1007/978-3-030-60117-1_32,scopus,scopus,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85094144617&origin=inward,2020-01-01 00:00:00,safety analytics for ai systems,"
AbstractView references

Growing AI technologies are a threat to safety and security in systems due to its obscurity and uncertainty. This study introduces a prevailing Deep Learning model, Convolutional Neural Network (CNN) and it’s deep weaknesses through a simple case study of the CNN model based on Keras for handwriting recognition. It reveals that CNN algorithms don’t adapt well to changes. Adding new cases to the training data may improve accuracy, but not to the same level as before. Synthetic training data may improve the accuracy superficially because of the similarity of data distributions between generated data and original data. Prevailing ML models such as Generative Adversarial Networks (GAN) have their limitations such as similarity-addiction and modality collapse. They could be toxic to safety engineering without domain expertise. The study proposed four test strategies: 1) AI systems should be tested by the third parties, not the developers; 2) test datasets should be categorically different from training datasets; the test data should not be a part of the training data; the test data should be collected from independent sources to increase the “diversity” of data modality; 3) avoid fake data, or simulated data; and 4) don’t collect the data that are conveniently available, but actively collect disastrous event data, unexpected, or the worst scenarios that may destroy the model. The study also introduces a multidimensional checklist for AI safety analysis, including sensors, data and environments, default and recovery mode, system architectures, and human-system interaction. © 2020, Springer Nature Switzerland AG.
",0.8118554949760437
27,included,10.1177/15553434221097357,Journal of Cognitive Engineering and Decision Making,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/f47fe4e6a34083f5f9a48cf281acfdd1fe52c1ea,2022-01-01 00:00:00,a sociotechnical systems framework for the application of artificial intelligence in health care delivery,"In the coming years, artificial intelligence (AI) will pervade almost every aspect of the health care delivery system. AI has the potential to improve patient safety (e.g., diagnostic accuracy) as well as reduce the burden on clinicians (e.g., documentation-related workload); however, these benefits are yet to be realized. AI is only one element of a larger sociotechnical system that needs to be considered for effective AI application. In this paper, we describe the current challenges of integrating AI into clinical care and propose a sociotechnical systems (STS) approach for AI design and implementation. We demonstrate the importance of an STS approach through a case study on the design and implementation of a clinical decision support (CDS). In order for AI to reach its potential, the entire work system as well as clinical workflow must be systematically considered throughout the design of AI technology.",0.8117738962173462
28,included,10.1109/ictc55196.2022.9952989,Information and Communication Technology Convergence,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/f4b42bdd510b993177c578830e89e58776060aab,2022-01-01 00:00:00,trustops: a risk-based ai engineering process,"We live in an era of artificial intelligence (AI) technology, which enables traditional HW/SW systems to help humans make wise decisions and even operate in intelligent ways. However, due to its inductive behaviors, this data-driven technology creates problems differ from those of conventional deductive systems. Therefore, the more AI is used in a wider range of industries and societies, the more problems and issues unseen before arise in human society. That's why most international organizations and nations released principles, and are struggling to find a technical methodology for assuring trustworthiness of AI. In many studies and papers, technical requirements are being presented individually and risk management is raised as the one of those. This paper intends to present an integrated and systematic engineering process that implements technical requirements in aspect of risk management.",0.8350556492805481
29,included,http://arxiv.org/abs/2006.12497v3,arxiv,arxiv,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),http://arxiv.org/abs/2006.12497v3,2020-06-21 00:00:00,technology readiness levels for ai & ml,"The development and deployment of machine learning systems can be executed
easily with modern tools, but the process is typically rushed and
means-to-an-end. The lack of diligence can lead to technical debt, scope creep
and misaligned objectives, model misuse and failures, and expensive
consequences. Engineering systems, on the other hand, follow well-defined
processes and testing standards to streamline development for high-quality,
reliable results. The extreme is spacecraft systems, where mission critical
measures and robustness are ingrained in the development process. Drawing on
experience in both spacecraft engineering and AI/ML (from research through
product), we propose a proven systems engineering approach for machine learning
development and deployment. Our Technology Readiness Levels for ML (TRL4ML)
framework defines a principled process to ensure robust systems while being
streamlined for ML research and product, including key distinctions from
traditional software engineering. Even more, TRL4ML defines a common language
for people across the organization to work collaboratively on ML technologies.",0.804334282875061
30,included,10.1145/3375627.3375872,core,core,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),http://arxiv.org/abs/2002.05672,2020-11-09 00:00:00,steps towards value-aligned systems,"Algorithmic (including AI/ML) decision-making artifacts are an established
and growing part of our decision-making ecosystem. They are indispensable tools
for managing the flood of information needed to make effective decisions in a
complex world. The current literature is full of examples of how individual
artifacts violate societal norms and expectations (e.g. violations of fairness,
privacy, or safety norms). Against this backdrop, this discussion highlights an
under-emphasized perspective in the literature on assessing value misalignment
in AI-equipped sociotechnical systems. The research on value misalignment has a
strong focus on the behavior of individual tech artifacts. This discussion
argues for a more structured systems-level approach for assessing
value-alignment in sociotechnical systems. We rely primarily on the research on
fairness to make our arguments more concrete. And we use the opportunity to
highlight how adopting a system perspective improves our ability to explain and
address value misalignments better. Our discussion ends with an exploration of
priority questions that demand attention if we are to assure the value
alignment of whole systems, not just individual artifacts.Comment: Original version appeared in Proceedings of the 2020 AAAI ACM
  Conference on AI, Ethics, and Society (AIES '20), February 7-8, 2020, New
  York, NY, USA. 5 pages, 2 figures. Corrected some typos in this versio",0.8055118918418884
31,included,10.1115/1.4062597,scopus,scopus,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85173951276&origin=inward,2023-12-01 00:00:00,zero-trust for the system design lifecycle,"
AbstractView references

In an age of worsening global threat landscape and accelerating uncertainty, the design and manufacture of systems must increase resilience and robustness across both the system itself and the entire systems design process. We generally trust our colleagues after initial clearance/background checks; and systems to function as intended and within operating parameters after safety engineering review, verification, validation, and/ or system qualification testing. This approach has led to increased insider threat impacts; thus, we suggest moving to the ""trust, but verify""approach embodied by the Zero-Trust paradigm. Zero-Trust is increasingly adopted for network security but has not seen wide adoption in systems design and operation. Achieving the goal of Zero-Trust throughout the systems lifecycle will help to ensure that no single bad actor-whether human or machine learning/artificial intelligence (ML/AI)-can induce failure anywhere in a system's lifecycle. Additionally, while ML/AI and their associated risks are already entrenched within the operations phase of many systems' lifecycles, ML/AI is gaining traction during the design phase. For example, generative design algorithms are increasingly popular, but there is less understanding of potential risks. Adopting the Zero-Trust philosophy helps ensure robust and resilient design, manufacture, operations, maintenance, upgrade, and disposal of systems. We outline the rewards and challenges of implementing Zero-Trust and propose the framework for Zero-Trust for the system design lifecycle. This article highlights several areas of ongoing research with focus on high priority areas where the community should focus efforts. © 2023 by ASME.
",0.8407002687454224
32,excluded,10.1609/aimag.v38i3.2756,The AI Magazine,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/96ef2680eada97d2e7ff65e7a075513ecd449cdd,2017-01-01 00:00:00,steps toward robust artificial intelligence,"Recent advances in artificial intelligence are encouraging governments and corporations to deploy AI in high-stakes settings including driving cars autonomously, managing the power grid, trading on stock exchanges, and controlling autonomous weapons systems. Such applications require AI methods to be robust to both the known unknowns (those uncertain aspects of the world about which the computer can reason explicitly) and the unknown unknowns (those aspects of the world that are not captured by the system’s models). This article discusses recent progress in AI and then describes eight ideas related to robustness that are being pursued within the AI research community. While these ideas are a start, we need to devote more attention to the challenges of dealing with the known and unknown unknowns. These issues are fascinating, because they touch on the fundamental question of how finite systems can survive and thrive in a complex and dangerous world",0.8210446238517761
33,included,10.1145/3284869.3284875,International Conference on Smart Objects and Technologies for Social Good,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/0a33dfef5b2d1588b3a6796ad9b827054699c79d,2018-01-01 00:00:00,intelligent machines for good?: more focus on the context,"Machine learning and modern Artificial Intelligence (AI) systems are influencing several aspects of our human lives. Many of these algorithms, based on Artificial Neural Networks (ANNs), have been empowered to make decisions and take actions, based on the well-known notions of efficiency and speed. The aura of objectivity and infallibility of such algorithms, nonetheless, have been already put into question (e.g., refer to the debate about the recent tragic car crashes that have involved self-driving cars). In this setting, our intuition identifies a key issue around the problem of AI errors and bias into the insufficient or inaccurate (human) activity of comprehension and codification of the context where the ANNs will have to operate. We present here a simple cognification ANN-based case study, in an underwater scenario, where we recovered from a situation of partial failure, by including additional contextual factors that were initially disregarded. Our final reflection is that a nuanced consideration of a complex context, and subsequent technical actions, should be always kept in mind before an AI-based system takes its final shape. Because machines have still no context for what they are doing, it is a human duty and responsibility to codify it.",0.8012804985046387
34,excluded,10.5555/3463952.3464248,Adaptive Agents and Multi-Agent Systems,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/40a6c6adf5f8a0cffcf0c36e1963d6324add2705,2021-01-01 00:00:00,software engineering methods for responsible artificial intelligence,"In order to ensure responsible Artificial intelligence (AI) applications engineering, we need to make sure that the development of AI systems is mindful of the consequences for individuals and societies. By anticipating the consequences of the design choices, reflecting upon the problem being solved by engaging all stakeholders and taking appropriate actions to ensure openness and the system’s social, legal, and ethical acceptability. This research aims to develop an engineering process model by which ethical considerations can be addressed throughout the AI systems’ software development life-cycle. The design methodological framework engineered in this PhD research will support aligning system goals with key ethical values by providing explicit values analysis and interpretation mechanisms, formal representation of ethical values, mechanisms for stakeholders participation in handling ethical deliberation, and providing support for governance and compliance mechanisms.",0.8775680065155029
35,excluded,10.48550/arxiv.2207.00644,arXiv.org,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/266c331b1036cfddabdf86af799cd6bd6e5ac9ef,2022-01-01 00:00:00,using a cognitive architecture to consider antiblackness in design and development of ai systems,"How might we use cognitive modeling to consider the ways in which antiblackness, and racism more broadly, impact the design and development of AI systems? We provide a discussion and an example towards an answer to this question. We use the ACT-R/{\Phi} cognitive architecture and an existing knowledge graph system, ConceptNet, to consider this question not only from a cognitive and sociocultural perspective, but also from a physiological perspective. In addition to using a cognitive modeling as a means to explore how antiblackness may manifest in the design and development of AI systems (particularly from a software engineering perspective), we also introduce connections between antiblackness, the Human, and computational cognitive modeling. We argue that the typical eschewing of sociocultural processes and knowledge structures in cognitive architectures and cognitive modeling implicitly furthers a colorblind approach to cognitive modeling and hides sociocultural context that is always present in human behavior and affects cognitive processes.",0.8016064763069153
36,excluded,http://arxiv.org/abs/1911.07133v1,arxiv,arxiv,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),http://arxiv.org/abs/1911.07133v1,2019-11-17 00:00:00,"autonomics: in search of a foundation for next generation autonomous
  systems","The potential benefits of autonomous systems have been driving intensive
development of such systems, and of supporting tools and methodologies.
However, there are still major issues to be dealt with before such development
becomes commonplace engineering practice, with accepted and trustworthy
deliverables. We argue that a solid, evolving, publicly available,
community-controlled foundation for developing next generation autonomous
systems is a must. We discuss what is needed for such a foundation, identify a
central aspect thereof, namely, decision-making, and focus on three main
challenges: (i) how to specify autonomous system behavior and the associated
decisions in the face of unpredictability of future events and conditions and
the inadequacy of current languages for describing these; (ii) how to carry out
faithful simulation and analysis of system behavior with respect to rich
environments that include humans, physical artifacts, and other systems,; and
(iii) how to engineer systems that combine executable model-driven techniques
and data-driven machine learning techniques. We argue that autonomics, i.e.,
the study of unique challenges presented by next generation autonomous systems,
and research towards resolving them, can introduce substantial contributions
and innovations in system engineering and computer science.",0.829957902431488
37,included,10.1007/s43681-023-00289-2,Springer,springer,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),http://dx.doi.org/10.1007/s43681-023-00289-2,2023-05-30 00:00:00,auditing large language models: a three-layered approach,"Large language models (LLMs) represent a major advance in artificial intelligence (AI) research. However, the widespread use of LLMs is also coupled with significant ethical and social challenges. Previous research has pointed towards auditing as a promising governance mechanism to help ensure that AI systems are designed and deployed in ways that are ethical, legal, and technically robust. However, existing auditing procedures fail to address the governance challenges posed by LLMs, which display emergent capabilities and are adaptable to a wide range of downstream tasks. In this article, we address that gap by outlining a novel blueprint for how to audit LLMs. Specifically, we propose a three-layered approach, whereby governance audits (of technology providers that design and disseminate LLMs), model audits (of LLMs after pre-training but prior to their release), and application audits (of applications based on LLMs) complement and inform each other. We show how audits, when conducted in a structured and coordinated manner on all three levels, can be a feasible and effective mechanism for identifying and managing some of the ethical and social risks posed by LLMs. However, it is important to remain realistic about what auditing can reasonably be expected to achieve. Therefore, we discuss the limitations not only of our three-layered approach but also of the prospect of auditing LLMs at all. Ultimately, this article seeks to expand the methodological toolkit available to technology providers and policymakers who wish to analyse and evaluate LLMs from technical, ethical, and legal perspectives.",0.8081768155097961
38,included,10.1109/isse54508.2022.10005383,IEEE,ieeexplore,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://ieeexplore.ieee.org/document/10005383/,2022-10-26 00:00:00,patients’ perceptions of integrating ai into healthcare: systems thinking approach,"Artificial intelligence (AI) has become more integrated into healthcare with a promising future. The expansion and application of Artificial Intelligence depend on technologies, policymakers, healthcare providers, as well as patients. Nevertheless, how to systematically understand AI interventions from the patients' perspectives should be further explored. In this paper, we first outline patients' perceptions of integrating AI into healthcare systems through a brief survey-based case study. Next, we emphasized the challenges and concerns of applying AI to complex healthcare systems while considering the components' interactions. Then a three-layer structure was proposed to highlight the complexity of Human-AI-Technology interactions linked to the governance system. Moreover, a causal loop diagram (CLD) is established to analyze the dynamic and causality of the adoption of AI in healthcare inspired by the systems thinking approach to help understand the patients' attitudes and perceptions of the whole picture.",0.811959445476532
39,included,10.1109/raise.2019.00015,RAISE@ICSE,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/4167fbb4c9d3e4d0ab4982d4d102edc5c935ae1e,2019-01-01 00:00:00,towards concept based software engineering for intelligent agents,"The development of AI and machine learning applications at an industry mature level while maintaining quality and productivity goals is one of today's major challenges. Research in the field of intelligent agents has achieved many successes in recent years, especially due to various reinforcement learning techniques, and promises a high benefit in times of automation and autonomous systems. Bringing them into production, however, requires optimization against many other criteria than just accuracy. This leads to the emerging field of machine teaching. We already know many of the objectives used there from software engineering research, which has led to many well-established principles in recent decades. One of them is the component-based development whose idea finds an interesting counterpart in hierarchical reinforcement learning. We show that both areas can benefit from each other and introduce our approach of concept based software engineering, which is focused on supporting productivity and quality goals during the development of such systems.",0.8317070007324219
40,excluded,10.1184/r1/16560183.v1,IEEE pervasive computing,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/264b9b136889da3b4d7e50ef58c77678b35dc3e0,2021-01-01 00:00:00,human-centered ai,"We identify three specific areas of focus to advance human-centered AI:• Designers and systems must understand the context of use and sense changes over time: Successful AI Engineering depends on the team’s ability to identify and articulate the desired system outcome and understand human and contextual factors affecting the outcome. The system itself must be able to learn when shifts in context have occurred. What are the best ways to maintain clarity around operational intent and mechanisms for adapting and evolving systems based on dynamic contexts and user needs?• Development of tools, processes, and practices to scope and facilitate human-machine teaming: Implementation of AI systems entails high levels of interdependence between human and machine. Adoption of AI systems requires the primary users to interact with and understand systems, gaining appropriate levels of trust. Every AI system needs to be designed to recognize boundaries and unfamiliar scenarios, and to provide transparency regarding its limitations.• Methods, mechanisms, and mindsets to engage in critical oversight: AI systems learn through data and observations, rather than being explicitly programmed for a deterministic outcome. Critical and reflective oversight by organizations, teams, and individuals that create and use AI systems is needed to uphold ethical principles and proactively consider the risks of bias, misuse, abuse, and unintended consequences through design, development, and ongoing deployment.For each area, we identify ongoing work as well and challenges and opportunities in developing and deploying AI systems with confidence.",0.8841918706893921
41,included,10.48550/arxiv.2212.11854,Business &amp; Information Systems Engineering,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/70df7fec4224c0d98252a6c61ee5f835be6f9e0b,2022-01-01 00:00:00,data-centric artificial intelligence,"Data-centric artificial intelligence (data-centric AI) represents an emerging paradigm that emphasizes the importance of enhancing data systematically and at scale to  build effective and efficient AI-based systems. The novel paradigm complements recent model-centric AI, which focuses on improving the performance of AI-based systems based on changes in the model using a fixed set of data. The objective of this article is to introduce practitioners and researchers from the field of Business and Information Systems Engineering (BISE) to data-centric AI. The paper defines relevant terms, provides key characteristics to contrast the paradigm of data-centric AI with the model-centric one, and introduces a framework to illustrate the different dimensions of data-centric AI. In addition, an overview of available tools for data-centric AI is presented and this novel paradigm is differenciated from related concepts. Finally, the paper discusses the longer-term implications of data-centric AI for the BISE community.",0.8859785795211792
42,excluded,10.1109/compsac54236.2022.00140,Annual International Computer Software and Applications Conference,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/96dba71bb1a50b01c12b5d48cef5cc18384cd8c8,2021-01-01 00:00:00,supporting ai engineering on the iot edge through model-driven tinyml,"Software engineering of network-centric Artificial Intelligence (AI) and Internet of Things (IoT) enabled Cyber-Physical Systems (CPS) and services, involves complex design and validation challenges. In this paper, we propose a novel approach, based on the model-driven software engineering paradigm, in particular the domain-specific modeling methodology. We focus on a sub-discipline of AI, namely Machine Learning (ML) and propose the delegation of data analytics and ML to the IoT edge. This way, we may increase the service quality of ML, for example, its availability and performance, regardless of the network conditions, as well as maintaining the privacy, security and sustainability. We let practitioners assign ML tasks to heterogeneous edge devices, including highly resource-constrained embedded microcontrollers with main memories in the order of Kilobytes, and energy consumption in the order of milliwatts. This is known as Tiny ML. Furthermore, we show how software models with different levels of abstraction, namely platform-independent and platform-specific models can be used in the software development process. Finally, we validate the proposed approach using a case study addressing the predictive maintenance of a hydraulics system with various networked sensors and actuators.",0.8387377858161926
43,excluded,10.1109/dasc50938.2020.9256709,IEEE,ieeexplore,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://ieeexplore.ieee.org/document/9256709/,2020-10-15 00:00:00,the conception of a large-scale systems engineering environment,"With the rise of artificial intelligence, it is time to shape the systems engineering tooling environment for the future. In the last decade, we have seen several emerging technologies that will potentially have a great impact in complex systems. These new technologies are expected to cause a disruptive impact not only in the products but also in to the tools used across the whole product life cycle. For this reason, is imperative to perform a critical review of the current systems engineering tooling ecosystem. This assessment should also map the open research problems that could prevent the complete integration of the new technologies into the systems engineering framework. This paper proposes a new architecture for a system engineering environment to operate in large scale projects. The objective of this research is twofold: it will first identify the capabilities for the next generation platform, and secondly, it will evaluate how artificial intelligence applications can be integrated in compliance with DO-330. The concept developed by this research will drive tool design recommendations enabling the use of artificial intelligence driven applications in a systems engineering tooling ecosystem.",0.8759571313858032
44,excluded,http://arxiv.org/abs/2112.01226v1,arxiv,arxiv,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),http://arxiv.org/abs/2112.01226v1,2021-10-31 00:00:00,"role of artificial intelligence, clinicians & policymakers in clinical
  decision making: a systems viewpoint","What is a system? Is one of those questions that is yet not clear to most
individuals in this world. A system is an assemblage of interacting,
interrelated and interdependent components forming a complex and integrated
whole with an unambiguous and common goal. This paper emphasizes on the fact
that all components of a complex system are inter-related and interdependent in
some way and the behavior of that system depends on these independences. A
health care system as portrayed in this article is widespread and complex. This
encompasses not only hospitals but also governing bodies like the FDA,
technologies such as AI, biomedical devices, Cloud computing and many more. The
interactions between all these components govern the behavior and existence of
the overall healthcare system. In this paper, we focus on the interaction of
artificial intelligence, care providers and policymakers and analyze using
systems thinking approach, their impact on clinical decision making",0.8128914833068848
45,excluded,10.1109/icsc59802.2024.00047,IEEE,ieeexplore,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://ieeexplore.ieee.org/document/10475636/,2024-02-07 00:00:00,"designing social good semantic computing architectures for the long tail: case studies, evaluation, and challenges","Many real-world systems, especially systems characterized by high social activity (such as the Web), tend to obey power law distributions and thereby have a significant ‘long tail’. We argue that researching, developing and designing semantic computing systems for the long tail, especially dependent on inductive AI, constitutes an important class of problems, not least because the long tail is challenging both technically and socially. By its very nature, the long tail is irregular, testing the generalization capabilities of the state-of-the-art, especially in architectures and interfaces that are built on some form of machine learning or statistical inference (including large language models). As machine learning and generative AI continues to be integrated into more front facing systems, the issue of the long tail cannot be ignored by either the systems engineering or the AI communities. We present two case studies with important social consequences (fighting human trafficking online, and managing information effectively and in real-time during humanitarian crises) where semantic computing and AI platforms specifically designed to handle long-tail challenges find critical application, and sometimes with drastically different design choices compared to designing only for the short tail (with the main goal of maximizing average accuracy).",0.8320419192314148
46,excluded,10.1631/fitee.2300537,scopus,scopus,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85178939500&origin=inward,2023-11-01 00:00:00,software development in the age of intelligence: embracing large language models with the right approach,"
AbstractView references

Embracing LLMs is definitely a correct and even necessary direction for software enterprises to improve quality and efficiency. However, achieving systematic and comprehensive intelligent software development still requires careful consideration and there is much fundamental work to do. For enterprises, solidifying the digitization and knowledge accumulation of software development, as well as the fundamental capabilities of software engineering such as requirement analysis, design, and validation, remains crucial and is also a basic condition for achieving higher levels of intelligent development. For academic research, there is still much work to do in the direction of systematic and comprehensive intelligent software development. This also requires us have a deeper understanding of the complexity of software systems and software requirements and design, based on understanding the capabilities of LLMs. © 2023, Zhejiang University Press.
",0.8203039765357971
47,excluded,10.1109/aire51212.2020.00012,International Workshop on Artificial Intelligence for Requirements Engineering,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/60fd917a81fe79c94e2cda4599802269e412d5e6,2020-01-01 00:00:00,towards an extended requirements problem formulation for superintelligence safety,"Under the headline ""AI safety"", a wide-reaching issue is being discussed, whether in the future some ""superhuman artificial intelligence"" / ""superintelligence"" could pose a threat to humanity. In addition, the late Steven Hawking warned that the rise of robots may be disastrous for mankind. A major concern is that even benevolent superhuman artificial intelligence (AI) may become seriously harmful if its given goals are not exactly aligned with ours, or if we cannot specify precisely its objective function. Metaphorically, this is compared to king Midas in Greek mythology, who expressed the wish that everything he touched should turn to gold, but obviously this wish was not specified precisely enough. In our view, this sounds like requirements problems and the challenge of their precise formulation. Hence, we take a new perspective on the problem by exploring it using insights from requirements engineering (RE). In addition, the overall issue calls for a major RE endeavor, figuring out the wishes and the needs with regard to a superintelligence, which will in our opinion most likely be a very complex softwareintensive system based on AI. In this paper, we introduce the idea of developing a new theoretical formulation of an extended requirements problem applicable to it, since it involves goals of both stakeholders and of the AI-based system-to-be-built.",0.8247873783111572
48,excluded,10.1109/icess.2019.8782512,International Conference on Embedded Software and Systems,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/690eba7bcbadb3a93c3b8808d16d8a9a3bd7d2ce,2019-01-01 00:00:00,an open and modular architecture for autonomous and intelligent systems,"Over the past few decades, remarkable progress has been made in the the field of Artificial Intelligence (AI). For some tasks such as games, natural language processing, and image classification, AI powered applications can match or surpass human performance. Despite this progress, truly Autonomous and Intelligent Systems (AIS) serving the needs of, and sharing the environment with humans, are yet to become a commercial reality. AIS engineering requires considerable integration efforts that must be disciplined and guided by a reference model enabling reuse and concurrent design: an open and modular architecture. While several specialized architectures have been developed over the course of few decades, there is a need for a unified approach that supports multi-agency, learning, knowledge representation, reasoning, planning, and run-time verification. In this paper, we propose an open and modular architecture for autonomous and intelligent systems. We start by defining the three primary modules of the architecture, namely situational assessment, knowledge repository and management, and decision making. We then refine each module into functional units and we describe possible interaction patterns among them.",0.8660294413566589
49,included,10.18293/seke2019-094,International Conference on Software Engineering and Knowledge Engineering,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/876d346fb11be7636f30b11f597a525ce50dfd26,2019-01-01 00:00:00,safe-by-design development method for artificial intelligent based systems,"Albeit Artiﬁcial Intelligent (AI) based systems are nowa-days deployed in a variety of safety critical domains, current engineering methods and standards are barely applicable for their development and assurance. The lack of common criteria to assess safety levels as well as the dependency of certain development phases w.r.t. the chosen technology (e.g., machine learning modules) are among the identiﬁed drawbacks. In addition, the development of such engineering methods has been hampered by the emerging challenges in AI-based systems design mainly regarding autonomy, correctness and prevention of catastrophic risks. In this paper we propose an approach to conduct a safe-by-design development process for AI based systems. The approach relies upon a method which beneﬁts from a reference AI architecture and safety principles. This contribution helps to address safety concerns and to comprehend current AI architectures diversity and particularities.",0.8835116624832153
50,excluded,10.1109/fuzz-ieee55066.2022.9882675,IEEE International Conference on Fuzzy Systems,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/d42e04841c817a11eb6d8717d8d62b14c38fcff3,2022-01-01 00:00:00,security considerations for the procurement and acquisition of artificial intelligence (ai) systems,"Procurement is a critical step in the setup of systems, as reverting decisions made at this point is typically time-consuming and costly. Especially Artificial Intelligence (AI) based systems face many challenges, starting with unclear and unknown side parameters at design time of the systems, changing ecosystems and regulations, as well as problems of overselling capabilities of systems by vendors. Furthermore, the AI Act puts forth a great deal of additional requirements for operators of critical AI systems, like risk management and transparency measures, thus making procurement even more complex. In addition, the number of providers of AI systems is drastically increasing. In this paper we provide guidelines for the procurement of AI based systems that support the decision maker in identifying the key elements for the procurement of secure AI systems, depending on the respective technical and regulatory environment. Furthermore, we provide additional resources for utilizing these guidelines in practical procurement.",0.8225700259208679
51,included,http://arxiv.org/abs/2101.03989v2,arxiv,arxiv,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),http://arxiv.org/abs/2101.03989v2,2021-01-11 00:00:00,technology readiness levels for machine learning systems,"The development and deployment of machine learning (ML) systems can be
executed easily with modern tools, but the process is typically rushed and
means-to-an-end. The lack of diligence can lead to technical debt, scope creep
and misaligned objectives, model misuse and failures, and expensive
consequences. Engineering systems, on the other hand, follow well-defined
processes and testing standards to streamline development for high-quality,
reliable results. The extreme is spacecraft systems, where mission critical
measures and robustness are ingrained in the development process. Drawing on
experience in both spacecraft engineering and ML (from research through product
across domain areas), we have developed a proven systems engineering approach
for machine learning development and deployment. Our ""Machine Learning
Technology Readiness Levels"" (MLTRL) framework defines a principled process to
ensure robust, reliable, and responsible systems while being streamlined for ML
workflows, including key distinctions from traditional software engineering.
Even more, MLTRL defines a lingua franca for people across teams and
organizations to work collaboratively on artificial intelligence and machine
learning technologies. Here we describe the framework and elucidate it with
several real world use-cases of developing ML methods from basic research
through productization and deployment, in areas such as medical diagnostics,
consumer computer vision, satellite imagery, and particle physics.",0.8114748001098633
52,included,10.1109/iv47402.2020.9304740,IEEE,ieeexplore,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://ieeexplore.ieee.org/document/9304740/,2020-11-13 00:00:00,can ai-based components be part of dependable systems?,"Artificial Intelligence and especially Machine Learning have become main topics in the scientific community as well as in industry. These techniques seem to be a solution for complex problems and are suggested even for critical applications such as the medical diagnosis, predictive analytic in finance or autonomous driving. But will it be feasible to employ such techniques in critical systems in the avionics, train, or medical domain taking into account the current regulations in domain-specific standard relating to dependability? Validation, verification and certification in these domains strongly rely on explicit traceability and provability of functional and dependability requirements down to the code level. This seems to be impossible for components derived using e.g. learning approaches. Nonetheless, scientific community and industry do not want to lose the advantages related to AI-based techniques - new ways to ensure the required level of confidence just need to be found. This is a process that requires people with different professional background to work together - and it has started. This paper presents selected aspects relating to the current state of the art with regard to AI and dependable systems and describes ongoing activities and ideas for obstacle detection and routing for autonomous driving at HAW Hamburg.",0.8174083828926086
53,excluded,10.3233/aic-201523,AI Communications,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/a39e88db75509ae36ffa66249107b53a48c39f86,2021-01-01 00:00:00,an interdisciplinary conceptual study of artificial intelligence (ai) for helping benefit-risk assessment practices: towards a comprehensive qualification matrix of ai programs and devices (pre-print 2020),"This paper proposes a comprehensive analysis of existing concepts coming from different disciplines tackling the notion of intelligence, namely psychology and engineering, and from disciplines aiming to regulate AI innovations, namely AI ethics and law. The aim is to identify shared notions or discrepancies to consider for qualifying AI systems. Relevant concepts are integrated into a matrix intended to help defining more precisely when and how computing tools (programs or devices) may be qualified as AI while highlighting critical features to serve a specific technical, ethical and legal assessment of challenges in AI development. Some adaptations of existing notions of AI characteristics are proposed. The matrix is a risk-based conceptual model designed to allow an empirical, flexible and scalable qualification of AI technologies in the perspective of benefit-risk assessment practices, technological monitoring and regulatory compliance: it offers a structured reflection tool for stakeholders in AI development that are engaged in responsible research and innovation.Pre-print version (achieved on May 2020)",0.8538931012153625
54,excluded,10.1145/3137574.3137585,SIGAI,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/c5841f4e0f767a304e69e2a5dbfb4078bc8f1bc5,2017-01-01 00:00:00,how do we ensure that we remain in control of our autonomous weapons?,"'... our AI systems must do what we want them to do.''
 This quote is mentioned in the Open Letter: Research Priorities for Robust and Beneficial Artificial Intelligence (AI) (Future of Life Institute, 2016) signed by over 8.600 people including Elon Musk and Stephan Hawking. This open letter received a lot of media attention with news headlines as: 'Musk, Wozniak and Hawking urge ban on warfare AI and autonomous weapons' (Gibbs, 2015) and it fused the debate on this topic. Although this type of 'War of the Worlds' news coverage might seem exaggerated at first glance, the underlying question on how we ensure that our Autonomous Weapons remain under our control, is in my opinion one of the most pressing issues for AI technology at this moment in time.
 To remain in control of our Autonomous Weapons and AI in general, meaning that its actions are intentional and according to our plans (Cushman, 2015), we should design it in a responsible manner and to do so I believe we must find a way incorporate our moral and ethical values into their design. The ART principle, an acronym for Accountability, Responsibility and Transparency can support a responsible design of AI. The Value-Sensitive Design (VSD) approach can be used to cover the ART principle. In this essay, I show how Autonomous Weapons can be designed responsibly by applying the VSD approach which is an iterative process that considers human values throughout the design process of technology (Davis & Nathan, 2015; Friedman & Kahn Jr, 2003).",0.8030397295951843
55,excluded,10.1109/syscon53536.2022.9773890,IEEE,ieeexplore,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://ieeexplore.ieee.org/document/9773890/,2022-04-28 00:00:00,creating a digital twin of an insider threat detection enterprise using model-based systems engineering,"Inference Enterprise Modeling (IEM) is a methodology developed to address test and evaluation limitations that insider threat detection enterprises face due to a lack of ground truth and/or missing data. IEM uses a collection of statistical, data processing, analysis, and machine learning techniques to estimate and forecast the performance of these enterprises. As part of developing the IEM method, models satisfying various detection system evaluation requirements were created. In this work, we extend IEM as a digital twin generation technique by representing modeled processes as executable UML Activity Diagrams and tracing solution processes to problem requirements using ontologies. Using the proposed framework, we can rapidly prototype a digital twin of a detection system that can also be imported and executed in systems engineering simulation software tools such as Cameo Enterprise Architecture Simulation Toolkit. Cyber security and threat detection is a continuous process that requires regular maintenance and testing throughout its lifecycle, but there often exists access issues for sensitive and private data and proprietary detection model details to perform adequate test and evaluation activities in the live production environment. To solve this issue, organizations can use a digital twin technique to create a real-time virtual counterpart of the physical system. We describe a method for creating digital twins of live and/or hypothetical insider threat detection enterprises for the purpose of performing test and evaluation activities on continuous monitoring systems that are sensitive to disruptions. In this work, we use UML Activity Diagrams to leverage the integrated simulation capabilities of Model-Based Systems Engineering (MBSE).",0.8124027252197266
56,excluded,10.1109/iccicc53683.2021.9811311,IEEE International Conference on Cognitive Informatics and Cognitive Computing,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/1fc59c04ed32cad26ea0573cd9f811abc0b801a0,2021-01-01 00:00:00,autonomous software requirement specifications towards ai programming,"Autonomous software requirement specifications and code generation are not only an ultimate goal of AI Programming (AIP), but also a persistent challenge to theories and technologies of software engineering. A cognitive system is demanded to autonomously elicit and rigorously refine software requirements in order to generate a set of formal specifications as the front-end of AIP. This paper presents a novel methodology for the design of an Intelligent Tool for Autonomous Software Specifications (ITASS) based on latest advances in software science and intelligent mathematics. ITASS is implemented as an interactive system for capturing software requirements and generating mathematic-based specifications for code generation in the back-end of the AIP system. The ITASS methodology and experiments are demonstrated for solving real-world and complex software engineering problems enabled by the AIP theories underpinned by intelligent mathematics.",0.8142650127410889
57,included,10.1109/tem.2023.3268340,scopus,scopus,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85159803879&origin=inward,2023-01-01 00:00:00,ai in the context of complex intelligent systems: engineering management consequences,"
AbstractView references

As artificial intelligence (AI) is increasingly integrated into the context of complex products and systems (CoPS), making complex systems more intelligent, this article explores the consequences and implications for engineering management in emerging complex intelligent systems (CoIS). Based on five engineering management aspects, including design objectives, system boundaries, architecting and modeling, predictability and emergence, and learning and adaptation, a case study representing future CoIS illustrates how these five aspects, as well as their relationship to criticality and generativity, emerge as AI becomes an integrated part of the system. The findings imply that a future combined perspective on allowing generativity and maintaining or enhancing criticality is necessary, and notably, the results suggest that the understanding of system integrators and CoPS management partly fundamentally alters and partly is complemented with the emergence of CoIS. CoIS puts learning and adaptation characteristics in the foreground, i.e., CoIS are associated with increasingly generative design objectives, fluid system boundaries, new architecting and modeling approaches, and challenges predictability. The notion of bounded generativity is suggested to emphasize the combination of generativity and criticality as a direction for transforming engineering management in CoPS contexts and demands new approaches for designing future CoIS and safeguard its important societal functions. Author
",0.8543676137924194
58,excluded,10.1109/spicscon54707.2021.9885722,IEEE,ieeexplore,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://ieeexplore.ieee.org/document/9885722/,2021-12-04 00:00:00,a framework of metaverse for systems engineering,"Recently the Metaverse has received enormous attention around the world. The advanced metaverse will be a more realistic environment with greater specific and subtle interconnections, with less race, gender, and even physical impairment, all of which would be immensely helpful to society. However, metaverse is still in its infancy, with a lot of room for improvement. The industry has already begun to prepare for the metaverse’s enormous potential, supported by frenzied investment, yet there are few talks on metaverse in academia to scientifically lead its growth. In this paper, we present a metaverse design that adopts a global approach to technology, communication, and the environment. We propose an AI-driven metaverse model that might be deployed to realize the promise of model-based systems engineering in the near future. Finally, we offer research questions that should be taken up by academia to further the metaverse.",0.8510017395019531
59,included,10.1093/jamia/ocac006,J. Am. Medical Informatics Assoc.,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/a2736b7a0f7a0002e912c665b1dc99fd40b469c4,2021-01-01 00:00:00,defining amia's artificial intelligence principles,"Recent advances in the science and technology of artificial intelligence (AI) and growing numbers of deployed AI systems in healthcare and other services have called attention to the need for ethical principles and governance. We define and provide a rationale for principles that should guide the commission, creation, implementation, maintenance, and retirement of AI systems as a foundation for governance throughout the lifecycle. Some principles are derived from the familiar requirements of practice and research in medicine and healthcare: beneficence, nonmaleficence, autonomy, and justice come first. A set of principles follow from the creation and engineering of AI systems: explainability of the technology in plain terms; interpretability, that is, plausible reasoning for decisions; fairness and absence of bias; dependability, including ""safe failure""; provision of an audit trail for decisions; and active management of the knowledge base to remain up to date and sensitive to any changes in the environment. In organizational terms, the principles require benevolence-aiming to do good through the use of AI; transparency, ensuring that all assumptions and potential conflicts of interest are declared; and accountability, including active oversight of AI systems and management of any risks that may arise. Particular attention is drawn to the case of vulnerable populations, where extreme care must be exercised. Finally, the principles emphasize the need for user education at all levels of engagement with AI and for continuing research into AI and its biomedical and healthcare applications.",0.826555073261261
60,excluded,10.1613/jair.1.11345,arXiv.org,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/b2277775e67ad13a5ab22d86a055e1f49a4cc8f5,2017-01-01 00:00:00,human-in-the-loop artificial intelligence,"Little by little, newspapers are revealing the bright future that Artificial Intelligence (AI) is building. Intelligent machines will help everywhere. However, this bright future has a dark side: a dramatic job market contraction before its unpredictable transformation. Hence, in a near future, large numbers of job seekers will need financial support while catching up with these novel unpredictable jobs. This possible job market crisis has an antidote inside. In fact, the rise of AI is sustained by the biggest knowledge theft of the recent years. Learning AI machines are extracting knowledge from unaware skilled or unskilled workers by analyzing their interactions. By passionately doing their jobs, these workers are digging their own graves. 
In this paper, we propose Human-in-the-loop Artificial Intelligence (HIT-AI) as a fairer paradigm for Artificial Intelligence systems. HIT-AI will reward aware and unaware knowledge producers with a different scheme: decisions of AI systems generating revenues will repay the legitimate owners of the knowledge used for taking those decisions. As modern Robin Hoods, HIT-AI researchers should fight for a fairer Artificial Intelligence that gives back what it steals.",0.807987630367279
61,included,10.1109/transai60598.2023.00015,IEEE,ieeexplore,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://ieeexplore.ieee.org/document/10387654/,2023-09-27 00:00:00,ai engineering to deploy reliable ai in industry,"To bring competitive advantage to industry through a sound AI deployment, we need an end-to-end “AI systems engineering” process covering the overall lifecycle of an AI system, both at component level and at system level, regardless of whether the specifications come from regulation and reliability concerns.",0.8573559522628784
62,included,10.1109/wain52551.2021.00015,Workshop on AI Engineering - Software Engineering for AI,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/854aa07af911d493de2c465c5748b9453cee6a4d,2021-01-01 00:00:00,understanding and modeling ai-intensive system development,"Developers of AI-Intensive Systems—i.e., systems that involve both “traditional” software and Artificial Intelligence—are recognizing the need to organize development systematically and use engineered methods and tools. Since an AI-Intensive System (AIIS) relies heavily on software, it is expected that Software Engineering (SE) methods and tools can help. However, AIIS development differs from the development of “traditional” software systems in a few substantial aspects. Hence, traditional SE methods and tools are not suitable or sufficient by themselves and need to be adapted and extended.A quest for “SE for AI” methods and tools has started. We believe that, in this effort, we should learn from experience and avoid repeating some of the mistakes made in the quest for SE in past years. To this end, a fundamental instrument is a set of concepts and a notation to deal with AIIS and the problems that characterize their development processes.In this paper, we propose to describe AIIS via a notation that was proposed for SE and embeds a set of concepts that are suitable to represent AIIS as well. We demonstrate the usage of the notation by modeling some characteristics that are particularly relevant for AIIS.",0.8918479681015015
63,excluded,10.1145/3299819.3299843,Artificial Intelligence and Cloud Computing Conference,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/aff8681225be05b78df1ed663c65087c65334b7e,2018-01-01 00:00:00,ai based intelligent system on the edison platform,"In recent years, artificial intelligence (AI) has become a trend all over the world. This trend has led to the application and development of intelligent system that apply AI. In this paper, we describe a system architecture that uses AI, on a platform called EDISON, for computer science and engineering research. This architecture can be used to develop intelligent systems and can support applications in various fields by assisting in the development of algorithms and computer code. In this paper, we demonstrate the scalability of the proposed architecture on EDISON using different languages and application examples from various fields.",0.8619464039802551
64,excluded,10.1109/icse48619.2023.00012,IEEE,ieeexplore,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://ieeexplore.ieee.org/document/10172687/,2023-05-20 00:00:00,software engineering as the linchpin of responsible ai,"From humanity's existential risks to safety risks in critical systems to ethical risks, responsible AI, as the saviour, has become a major research challenge with significant real-world consequences. However, achieving responsible AI remains elusive despite the plethora of high-level ethical principles, risk frameworks and progress in algorithmic assurance. In the meantime, software engineering (SE) is being upended by AI, grappling with building system-level quality and alignment from inscrutable machine learning models and code generated from natural language prompts. The upending poses new challenges and opportunities for engineering AI systems responsibly. This talk will share our experiences in helping the industry achieve responsible AI systems by inventing new SE approaches. It will dive into industry challenges (such as risk silos and principle-algorithm gaps) and research challenges (such as lack of requirements, emerging properties and inscrutable systems) and make the point that SE is the linchpin of responsible AI. But SE also requires some fundamental rethinking - shifting from building functions into AI systems to discovering and managing emerging functions from AI systems. Only by doing so can SE take on critical new roles, from understanding human intelligence to building a thriving human-AI symbiosis.",0.8714330196380615
65,excluded,10.1109/iisr.2018.8535903,International Symposium on Robotics,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/a537f52e8febb263d320690cdf3eb99a4e03131d,2018-01-01 00:00:00,the risks of low level narrow artificial intelligence,"There is a great deal of concern expressed by many in the artificial intelligence (AI) community about the existential risk of this rapidly developing technology. This paper provides a discussion on some issues that need to be addressed to handle potential future risks and provides some new perspectives. The development of artificial intelligence is moving from relatively limited standalone to large-scale, complex distributed systems. However, potential risks such as malfunction, malicious attacks and mismatch of objective can occur from hardware and software failures or design errors. Moreover, a system controlled by high level AI can become unpredictable in its behaviours and thus ethical risks can emerge when such systems have to make a decision related to operational issues. Given that all new, disruptive, technologies have risks associated with them, what we need to do, as practitioners and users, is to find ways of mitigating those risks. We discuss applications of agent-based simulation to illustrate some of the risks and, potentially, how to mitigate them.",0.8822519183158875
66,excluded,10.1007/978-3-031-42622-3_23,Springer,springer,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),http://dx.doi.org/10.1007/978-3-031-42622-3_23,2023-01-01 00:00:00,a maturity model for collaborative agents in human-ai ecosystems,"AI entities lean on the aspects of their autonomy to carry out their tasks and perform intelligently. But when these entities collaborate in human-AI teams, their levels of autonomy and collaboration have to be balanced out. We present a maturity model for agents regarding this aspect of balancing. Whereas simple AI systems use pre-designed mechanisms, more advanced systems are able to learn this from experience. The maturity model is a two-dimensional matrix in which the degree of agency forms the horizontal axis, and the level of interaction the vertical axis. We validate the use of this maturity model with use-cases in the field of urban energy efficiency.",0.809422492980957
67,included,10.1109/sose52739.2021.9497496,IEEE,ieeexplore,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://ieeexplore.ieee.org/document/9497496/,2021-06-18 00:00:00,system of systems engineering approach for complex deterministic and nondeterministic systems (acdans),"As new commercial and military systems evolve, engineers face significant challenges that require solutions beyond traditional systems engineering. For example, military commanders recognize that in order to confront threats from high-tech adversaries, an advanced system of systems (SoS) is required to coordinate combat across multiple battlefield domains: land, sea, air, space, and cyberspace. System of Systems Engineering (SoSE), along with associated Modeling and Simulation (M&S) tools, can fill some of this need, especially for operational decision-support for complex multi-domain environments. This paper presents an M&S-based SoSE approach for complex SoS composed of deterministic and non-deterministic subsystems supported with reinforcement learning. The paper presents this new methodology, use cases, and preliminary results that address specific SoS challenges for a set of complex decision-support challenges.",0.8016894459724426
68,excluded,http://arxiv.org/abs/2401.03223v2,arxiv,arxiv,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),http://arxiv.org/abs/2401.03223v2,2024-01-06 00:00:00,"an intelligent sociotechnical systems (ists) framework: toward a
  sociotechnically-based hierarchical human-centered ai approach","Insights: - The human-centered AI (HCAI) approach and the sociotechnical
systems (STS) theory share the same goal: ensuring that new technologies such
as AI best serve humans in a sociotechnical environment. - HCAI practice needs
to fully embrace sociotechnical systems thinking, while traditional STS needs
to evolve to address the emerging characteristics of AI technology. - We
propose a conceptual framework for intelligent sociotechnical systems (iSTS) to
enhance traditional STS theory in the AI era. - Based on iSTS, we further
propose a sociotechnical-based hierarchical HCAI approach as a paradigmatic
extension to existing HCAI practice, further advancing HCAI practice.",0.844709575176239
69,excluded,10.1109/icse-seip55303.2022.9793864,2022 IEEE/ACM 44th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP),semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/6a03b02e61b447ce1456624853d7accfd24a2711,2021-01-01 00:00:00,software engineering for responsible ai: an empirical study and operationalised patterns,"AI ethics principles and guidelines are typically high-level and do not provide concrete guidance on how to develop responsible AI systems. To address this shortcoming, we perform an empirical study involving interviews with 21 scientists and engineers to understand the practitioners' views on AI ethics principles and their implementation. Our major findings are: (1) the current practice is often a done-once-and-forget type of ethical risk assessment at a particular development step, which is not sufficient for highly uncertain and continual learning AI systems; (2) ethical requirements are either omitted or mostly stated as high-level objectives, and not specified explicitly in verifiable way as system outputs or outcomes; (3) although ethical requirements have the characteristics of cross-cutting quality and non-functional requirements amenable to architecture and design analysis, system-level architecture and design are under-explored; (4) there is a strong desire for continuously monitoring and validating AI systems post deployment for ethical requirements but current operation practices provide limited guidance. To address these findings, we suggest a preliminary list of patterns to provide operationalised guidance for developing responsible AI systems.",0.8452555537223816
70,included,10.1109/rew56159.2022.00037,2022 IEEE 30th International Requirements Engineering Conference Workshops (REW),semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/1cc70f06afd34865deede7001925f35d250cc456,2022-01-01 00:00:00,ai ethics impact assessment based on requirement engineering,"This paper proposes a methodology for evaluating the ethical impact of artificial intelligence (AI) systems on people and society based on AI ethics guidelines. The ethical impact of AI has been recognized as a social issue, and countries and organizations have formulated principles and guidelines on AI ethics, and laws and regulations will be enforced in Europe. Because these principles and guidelines are written in terms of philosophy and law, AI service providers, developers, and business users have the challenge of how they should practice the principles and guidelines to their AI systems. To address this challenge, we first analyzed cases of ethical problems caused by AI in the past and assumed that ethical problems could be linked to interactions between components of AI systems and stakeholders related to such systems. On the basis of this assumption, we then developed a methodology to comprehensively extract the ethical risks that an AI system poses. This methodology consists of two approaches. The first approach is to develop an AI ethics model that embodies ethics guidelines as necessary requirements for ethical AI systems and correlates these requirements with interactions. The second approach is an impact assessment process that uses the AI ethics models to extract ethical risks for individual AI systems. In this paper, we discuss the details of this methodology and show the results of an initial validation to verify the above assumption and the ease of the impact assessment process.",0.8575771450996399
71,excluded,10.1109/rew56159.2022.00038,2022 IEEE 30th International Requirements Engineering Conference Workshops (REW),semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/a792faefc9230dc89aab3fac643a7d9ce0bf2077,2022-01-01 00:00:00,can requirements engineering support explainable artificial intelligence? towards a user-centric approach for explainability requirements,"With the recent proliferation of artificial intelligence systems, there has been a surge in the demand for explainability of these systems. Explanations help to reduce system opacity, support transparency, and increase stakeholder trust. In this position paper, we discuss synergies between requirements engineering (RE) and Explainable AI (XAI). We highlight challenges in the field of XAI, and propose a framework and research directions on how RE practices can help to mitigate these challenges.",0.8046533465385437
72,excluded,10.1109/isse54508.2022.10005441,IEEE,ieeexplore,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://ieeexplore.ieee.org/document/10005441/,2022-10-26 00:00:00,towards a data engineering process in data-driven systems engineering,"Highly Automated Driving (HAD) has become one of the leading trends in the automotive industry. Mandatory tasks like environment perception and scene understanding challenge existing rule-based methods. Thus, data-driven technologies and Artificial Intelligence (AI) have been introduced to automotive software development. Utilizing data in the development process has become essential as these systems are no longer developed with classical systems engineering methods, but rather by deriving requirements from and training the algorithms with recorded real-world data. This entails the introduction of data-driven workflows and data-management as new aspects of Automotive Systems Engineering (ASE). Tasks related to the development of Artificial Intelligence (AI) software differ from their classical engineering and programming counterparts. Thus, engineers require new tools and methods for developing safe and accurate AI-based software and handling data efficiently during ASE. Another important aspect of data-driven development is ensuring data quality throughout the systems engineering process. Hence, this paper aims to take a step towards the introduction of a data engineering process in data-driven automotive systems engineering. Putting a spotlight on developing well-designed data sets as the central element for training and validating AI-based software. Besides determining the quality of data sets, we present steps towards improving data and data set quality.",0.8017510771751404
73,excluded,10.1109/rew.2019.00051,2019 IEEE 27th International Requirements Engineering Conference Workshops (REW),semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/58090cdbb7526f4e22c09387814ee060dab1de54,2019-01-01 00:00:00,requirements engineering challenges in building ai-based complex systems,"This paper identifies and tackles the challenges of the requirements engineering discipline when applied to development of AI-based complex systems. Due to their complex behaviour, there is an immanent need for a tailored development process for such systems. However, there is still no widely used and specifically tailored process in place to effectively and efficiently deal with requirements suitable for specifying a software solution that uses machine learning. By analysing the related work from software engineering and artificial intelligence fields, potential contributions have been recognized from agent-based software engineering and goal-oriented requirements engineering research, as well as examples from large product development companies. The challenges have been discussed, with proposals given how and when to tackle them. RE4AI taxonomy has also been outlined, to inform the tailoring of development process.",0.8855636715888977
74,included,10.48550/arxiv.2204.04211,arXiv.org,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/40ed2b01f62baeb649ec5d30363bf392c25c246e,2022-01-01 00:00:00,measuring ai systems beyond accuracy,"Current test and evaluation (T&E) methods for assessing ma- chine learning (ML) system performance often rely on incomplete metrics. Testing is additionally often siloed from the other phases of the ML system lifecycle. Research inves- tigating cross-domain approaches to ML T&E is needed to drive the state of the art forward and to build an Artificial Intelligence (AI) engineering discipline. This paper advo- cates for a robust, integrated approach to testing by outlining six key questions for guiding a holistic T&E strategy.",0.8078747987747192
75,excluded,10.1109/sose52839.2021.00028,International Symposium on Service Oriented Software Engineering,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/bee60aa8343ae0057ce24cea34df4302e0f916f7,2021-01-01 00:00:00,model-based test modeling and automation tool for intelligent mobile apps,"Functionalities of AI-powered mobile Apps or systems heavily depend on the given training dataset. The challenge in this case is that a learning system will change its behavior due to a slight change of dataset. While current alternative approaches for evaluating these apps either focus on individual performance measurement such as accuracy etc. Inspired by principles of the decision tree test method in software engineering, we introduce a 3D decision tree testing model for AI testing, a combined AI feature input tree, context tree, and output tree methodology for testing AI-powered applications. We report a newly developed AI test automation tool (known as AITest), which is built and implemented based on an innovative 3D AI Test model for AI-powered functions in intelligent mobile apps to support model-based AI function testing, test data generation, and auto test scripting and execution, and adequate test coverage analysis. Furthermore, the tool infrastructure, components, sample applications, and case study results are presented.",0.8117448687553406
76,excluded,10.1145/3387939.3391595,International Symposium on Software Engineering for Adaptive and Self-Managing Systems,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/03454b3e323aca957b33f5644c0292935c27deba,2020-01-01 00:00:00,a hybrid approach combining control theory and ai for engineering self-adaptive systems,"Control theoretical techniques have been successfully adopted as methods for self-adaptive systems design to provide formal guarantees about the effectiveness and robustness of adaptation mechanisms. However, the computational effort to obtain guarantees poses severe constraints when it comes to dynamic adaptation. In order to solve these limitations, in this paper, we propose a hybrid approach combining software engineering, control theory, and AI to design for software self-adaptation. Our solution proposes a hierarchical and dynamic system manager with performance tuning. Due to the gap between high-level requirements specification and the internal knob behavior of the managed system, a hierarchically composed components architecture seek the separation of concerns towards a dynamic solution. Therefore, a two-layered adaptive manager was designed to satisfy the software requirements with parameters optimization through regression analysis and evolutionary meta-heuristic. The optimization relies on the collection and processing of performance, effectiveness, and robustness metrics w.r.t control theoretical metrics at the offline and online stages. We evaluate our work with a prototype of the Body Sensor Network (BSN) in the healthcare domain, which is largely used as a demonstrator by the community. The BSN was implemented under the Robot Operating System (ROS) architecture, and concerns about the system dependability are taken as adaptation goals. Our results reinforce the necessity of performing well on such a safety-critical domain and contribute with substantial evidence on how hybrid approaches that combine control and AI-based techniques for engineering self-adaptive systems can provide effective adaptation.",0.8395721912384033
77,excluded,10.1109/re51729.2021.00070,IEEE International Requirements Engineering Conference,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/60727256f6d41a2d5b5e20a45c3eb53a04fe2565,2021-01-01 00:00:00,human-centric requirements engineering for artificial intelligence software systems,"The surge in data availability and processing power has made it possible for Artificial Intelligence (AI) to advance at a faster rate. However, the different nature of AI systems has posed significant new challenges to Requirements Engineering (RE). Literature has shown that AI systems do not use current RE methods. It was also found that data scientists are taking the role of the requirements engineers resulting in software that does not focus on users needs. Building AI software with a human-centric approach has proven to produce more ethical, transparent, inclusive and non-bias outcomes. This research will look into adjusting current RE methodologies to fit into AI systems from a human-centric perspective. The project will aim to establish requirements specifications for human-centric AI and map them into a modeling language. A platform will be used to visually model and present requirements. Finally, I plan to conduct a case study to evaluate the modeling language. To date, I have conducted a Systematic Literature Review (SLR) to find current RE methodologies and challenges in AI and currently in the planning phase of a survey to find adopted practices in the industry.",0.8811267614364624
78,included,10.1109/syscon48628.2021.9447069,IEEE,ieeexplore,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://ieeexplore.ieee.org/document/9447069/,2021-05-15 00:00:00,design strategies for integrating artificial intelligence into systems engineering environment,"The use of artificial intelligence capabilities for developing airborne safety-critical systems has been troublesome to the aerospace industry. This technology inserts new sources of non-determinism on process execution, increasing difficulty to ensure safety requirements. In this work, we evaluate the artificial intelligence capabilities for improving systems engineering methodology. From this analysis, we present design strategies to support the tool qualification process. The design strategies are a sound basis for applying artificial intelligence into the tools employed during the whole airborne systems life cycle.",0.8561747670173645
79,excluded,http://arxiv.org/abs/2203.15628v1,arxiv,arxiv,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),http://arxiv.org/abs/2203.15628v1,2022-03-29 00:00:00,"exploring opportunities in usable hazard analysis processes for ai
  engineering","Embedding artificial intelligence into systems introduces significant
challenges to modern engineering practices. Hazard analysis tools and processes
have not yet been adequately adapted to the new paradigm. This paper describes
initial research and findings regarding current practices in AI-related hazard
analysis and on the tools used to conduct this work. Our goal with this initial
research is to better understand the needs of practitioners and the emerging
challenges of considering hazards and risks for AI-enabled products and
services. Our primary research question is: Can we develop new structured
thinking methods and systems engineering tools to support effective and
engaging ways for preemptively considering failure modes in AI systems? The
preliminary findings from our review of the literature and interviews with
practitioners highlight various challenges around integrating hazard analysis
into modern AI development processes and suggest opportunities for exploration
of usable, human-centered hazard analysis tools.",0.8534960746765137
80,excluded,10.4018/ijncr.310006,International Journal of Natural Computing Research,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/7ecae0b8c34e9d728517d616baf80c15d6d064b7,2022-01-01 00:00:00,insights into incorporating trustworthiness and ethics in ai systems with explainable ai,"Over the past seven decades since the advent of artificial intelligence (AI) technology, researchers have demonstrated and deployed systems incorporating AI in various domains. The absence of model explainability in critical systems such as medical AI and credit risk assessment among others has led to neglect of key ethical and professional principles which can cause considerable harm. With explainability methods, developers can check their models beyond mere performance and identify errors. This leads to increased efficiency in time and reduces development costs. The article summarizes that steering the traditional AI systems toward responsible AI engineering can address concerns raised in the deployment of AI systems and mitigate them by incorporating explainable AI methods. Finally, the article concludes with the societal benefits of the futuristic AI systems and the market shares for revenue generation possible through the deployment of trustworthy and ethical AI systems.",0.8033174872398376
81,excluded,10.1109/tiv.2023.3332877,IEEE,ieeexplore,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://ieeexplore.ieee.org/document/10319096/,2023-11-01 00:00:00,autonomous services: the evolution of services through intelligent vehicles,"The emergence of intelligent vehicles brings unique opportunities for the service industry. This study introduces the concept of autonomous services, a new service paradigm, and autonomous services systems, in which intelligent vehicles are vital enabling technology. Specifically, autonomous services aim to minimize unnecessary human participation and effort in the service process by leveraging intelligence for service delivery, rather than relying on simple stimulus-response or rule-based program behavior. This letter reports on the first Decentralized and Hybrid Workshop (DHW) on autonomous services, aiming to reduce the cost of human labor and improve the quality and efficiency of service while tackling the challenges posed by a shrinking workforce. The introduction of intelligent vehicles enhances the capability of the service systems, while also significantly increasing complexity. To address the challenges associated with complexity, the Systems Engineering (SE) approach is indispensable. The Requirements-Functional-Logical-Physical (RFLP) framework can implement Model-Based System Engineering (MBSE) and help researchers and managers to understand the autonomous services system more comprehensively, so as to better operate and manage it. We substitute “Implementation” for “Physical” in this research to define and elaborate on the autonomous services system. Finally, we outline the potential research opportunities within the autonomous services system.",0.8170905709266663
82,included,10.1515/auto-2022-0020,at - Automatisierungstechnik,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/20e4fac51b5a8ced6e66f9fe11cddad7d87c6d6e,2022-01-01 00:00:00,paise® – process model for ai systems engineering,"Abstract The application of artificial-intelligence-(AI)-based methods within the context of complex systems poses new challenges within the product life cycle. The process model for AI systems engineering, PAISE®, addresses these challenges by combining approaches from the disciplines of systems engineering, software development and data science. The general approach builds on a component-wise development of the overall system including an AI component. This allows domain specific development processes to be parallelized. At the same time, component dependencies are tested within interdisciplinary checkpoints, thus resulting in a refinement of component specifications.",0.9021071195602416
83,included,10.1109/smc.2019.8914324,IEEE,ieeexplore,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://ieeexplore.ieee.org/document/8914324/,2019-10-09 00:00:00,the digital (mission) twin: an integrating concept for future adaptive cyber-physical-human systems,"Top-down decomposition of a complex system of systems (SoS) requires representation of the behavior of multiple individuals and cyber-physical systems performing a wide variety of tasks, usually at different times and with different goals. In the future, as humans and machines learn and co-adapt in their mission context, systems engineering must develop approaches that support dynamic analysis and synthesis in both the design and operation of systems. The concept of a “digital (mission) twin” provides an integration framework for design and control of future complex cyber-physical-human SoS. The framework builds on mission function task (MFT) analysis, providing a basis for model-based systems engineering (MBSE) activities to identify and address needs for automation or other forms of advanced technology that improve overall system performance. However, human-driven adaptation and eventually machine adaptation of complex SoS poses organizational and methodological challenges. We discuss the need for and opportunities for convergence of three often segregated SE methodologies: product engineering, human systems integration, and mission/operations analysis by expanding the product or process engineering view of a digital twin to the mission level. In the present this gives us a framework to analyze and specify automation and adaptation opportunities at the mission level. In the future we envision this twin continuously operates with the real systems to manage both emergent mission conditions and lifecycle adaptation. We applied this framework to a complex military mission using a case where artificial intelligence can be incorporated widely across a set of mission tasks to significantly improve performance.",0.8081477880477905
84,excluded,10.1109/re51729.2021.00008,IEEE International Requirements Engineering Conference,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/0433639e31918b3f90d866eb61293b0e8760c3ff,2021-01-01 00:00:00,what’s up with requirements engineering for artificial intelligence systems?,"In traditional approaches to building software systems (that do not include an Artificial Intelligent (AI) or Machine Learning (ML) component), Requirements Engineering (RE) activities are well-established and researched. However, building software systems with one or more AI components may depend heavily on data with limited or no insight into the system’s workings. Therefore, engineering such systems poses significant new challenges to RE. Our search showed that literature has focused on using AI to manage RE activities, with limited research on RE for AI (RE4AI). Our study’s main objective was to investigate current approaches in writing requirements for AI/ML systems, identify available tools and techniques used to model requirements, and find existing challenges and limitations. We performed a Systematic Literature Review (SLR) of current RE4AI methods and identified 27 primary studies. Using these studies, we analysed the key tools and techniques used to specify and model requirements and found several challenges and limitations of existing RE4AI practices. We further provide recommendations for future research, based on our analysis of the primary studies and mapping to industry guidelines in Google PAIR). The SLR findings highlighted that present RE applications were not adaptive to manage most AI/ML systems and emphasised the need to provide new techniques and tools to support RE4AI.",0.852554202079773
85,excluded,10.1007/978-1-4842-9502-1_8,Springer,springer,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),http://dx.doi.org/10.1007/978-1-4842-9502-1_8,2023-01-01 00:00:00,building an ai platform,"As an AI startup, it is essential to have a clear strategy for designing, developing, and operating an AI platform that can meet market demands. In the previous chapters, we learned about validating AI products from various perspectives. This chapter will explore the details of building a successful AI platform that involves designing, developing, and operating the AI system. Building an AI platform is a complex process that requires careful consideration of many factors. We will explore the importance of the three pillars of AI platform design: system design, process design, and team design. We will provide a comprehensive framework that unifies these pillars into a single approach to building an effective AI platform. Measuring the maturity of an AI platform is also an essential aspect of the building process. We will discuss how to assess the platform at different stages, from initial development to optimized operation. This chapter will also discuss the challenges and best practices of building an AI platform. We will explore common issues and provide practical solutions to ensure success. To illustrate how the framework and best practices discussed in this chapter can be applied in practice, we will provide a case study of designing, developing, and operating an eKYC AI as a Service platform. This case study will provide real-world examples of the key considerations and decisions in building an effective AI platform. By the end of this chapter, you will have a comprehensive understanding of what it takes to build a successful AI platform and the steps involved in designing, developing, and operating such a system.",0.8540821075439453
86,included,10.1145/3489449.3490014,European Conference on Pattern Languages of Programs,semantic_scholar,systems engineering,'systems engineering' AND ('generative ai' OR 'artificial intelligence'),https://www.semanticscholar.org/paper/98cbc71f45d131de722c04bffb18cb59f4f75b44,2021-01-01 00:00:00,architectural patterns for integrating ai technology into safety-critical systems,"Artificial Intelligence (AI) is widely acknowledged as one of the most disruptive technologies driving the digital transformation of industries, enterprises, and societies in the 21st century. Advances in computing speed, algorithmic improvements, and access to a vast amount of data contributed to the adaption of AI in many different domains. Due to the outstanding performance, AI technology is increasingly integrated into safety-critical applications. However, the established safety engineering processes and practices have been only successfully applied in conventional model-based system development and no commonly agreed approaches for integrating AI technology are available yet. This work presents two architectural patterns that can support designers and engineers in the conception of safety-critical AI-enhanced cyber-physical system (CPS) applications. The first pattern addresses the problem of integrating AI capabilities into safety-critical functions. The second pattern deals with architectural approaches to integrate AI technologies for monitoring and learning system-specific behavior at runtime.",0.8690606355667114
