id,type,publication,publisher,publication_date,database,title,url,abstract,domain
10.1016/j.enconman.2022.115217,Journal,Energy Conversion and Management,scopus,2022-02-15,sciencedirect,RoboPV: An integrated software package for autonomous aerial monitoring of large scale PV plants,https://api.elsevier.com/content/abstract/scopus_id/85122793867,"In this paper, a novel software package, called RoboPV, is introduced for autonomous aerial monitoring of PV plants. RoboPV automatically performs aerial monitoring of PV plants, from optimal trajectory planning to image processing and pattern recognition for real-time fault detection and analysis. RoboPV consists of four integrated components: boundary area detection, path planning, dynamic processing, and fault detection. To design an optimal flight path, aerial images of PV plants, which have been collected from experimental flights, are given as inputs to a developed encoder-decoder deep learning architecture to extract boundary points of PV plants automatically. Then, a novel path planning algorithm is conducted by RoboPV to design an optimal flight path with full coverage of whole regions of the PV plant. Aerial images are analysed in real-time during the flight by a high precise neural network trained for automatic fault detection. In this study, several decision-making and maneuver algorithms were developed for various real-world flight conditions to improve the performance of RoboPV during an autonomous aerial inspection. RoboPV is a modular processing library that can be installed on any micro-computer processor with a low computational power. Moreover, supporting the MAVLink communication protocol enables RoboPV to connect with an intelligent Pixhawk flight autopilot and navigate a wide range of multi-rotors. To demonstrate the performance of RoboPV, a six degrees of freedom dynamic model of a multi-rotor is developed in a SIMULINK environment with a defined aerial monitoring mission on three different real megawatt-scale PV plants. The results prove that RoboPV can execute the autonomous aerial inspection with an overall accuracy of 93% for large-scale PV plants.",multimedia
10.1016/j.ymssp.2021.108284,Journal,Mechanical Systems and Signal Processing,scopus,2022-02-15,sciencedirect,Real-time model calibration with deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85112506465,"The real-time, and accurate inference of model parameters is of great importance in many scientific and engineering disciplines that use computational models (such as a digital twin) for the analysis and prediction of complex physical processes. However, fast and accurate inference for processes of complex systems cannot easily be achieved in real-time with state-of-the-art methods under noisy real-world conditions with the requirement of a real-time response. The primary reason is that the inference of model parameters with traditional techniques based on optimization or sampling often suffers from computational and statistical challenges, resulting in a trade-off between accuracy and deployment time. In this paper, we propose a novel framework for inference of model parameters based on reinforcement learning. The proposed methodology is demonstrated and evaluated on two different physics-based models of turbofan engines. The experimental results demonstrate that the proposed methodology outperforms all other tested methods in terms of speed and robustness, with high inference accuracy.",multimedia
10.1016/j.vrih.2022.01.004,Journal,Virtual Reality and Intelligent Hardware,scopus,2022-02-01,sciencedirect,Virtual-reality-based digital twin of office spaces with social distance measurement feature,https://api.elsevier.com/content/abstract/scopus_id/85124517698,"Background
                  Social distancing is an effective way to reduce the spread of the SARS-CoV-2 virus. Many students and researchers have already attempted to use computer vision technology to automatically detect human beings in the field of view of a camera and help enforce social distancing. However, because of the present lockdown measures in several countries, the validation of computer vision systems using large-scale datasets is a challenge.
               
                  Methods
                  In this paper, a new method is proposed for generating customized datasets and validating deep-learning-based computer vision models using virtual reality (VR) technology. Using VR, we modeled a digital twin (DT) of an existing office space and used it to create a dataset of individuals in different postures, dresses, and locations. To test the proposed solution, we implemented a convolutional neural network (CNN) model for detecting people in a limited-sized dataset of real humans and a simulated dataset of humanoid figures.
               
                  Results
                  We detected the number of persons in both the real and synthetic datasets with more than 90% accuracy, and the actual and measured distances were significantly correlated (r=0.99). Finally, we used intermittent-layer- and heatmap-based data visualization techniques to explain the failure modes of a CNN.
               
                  Conclusions
                  A new application of DTs is proposed to enhance workplace safety by measuring the social distance between individuals. The use of our proposed pipeline along with a DT of the shared space for visualizing both environmental and human behavior aspects preserves the privacy of individuals and improves the latency of such monitoring systems because only the extracted information is streamed.",multimedia
10.1016/j.pmcj.2022.101540,Journal,Pervasive and Mobile Computing,scopus,2022-02-01,sciencedirect,LwTool: A data processing toolkit for building a real-time pressure mapping smart textile software system,https://api.elsevier.com/content/abstract/scopus_id/85123030397,"Pressure mapping smart textile is a new type of sensing modality that transforms the pressure distribution over surfaces into digital ”image” and ”video”, that has rich application scenarios in Human Activity Recognition (HAR), because all human activities are linked with force change over certain surfaces. To speed up its application exploration, we propose a toolkit named LwTool for the data processing, including: (a) a feature library, including 1830 ready-to-use temporal and spatial features, (b) a hierarchical feature selection framework that automatically picks out the best features for a new application from the feature library. As real-time processing capability is important for instant user feedback, we emphasize not only on good recognition result but also on reducing time cost when selecting features. Our library and algorithms are validated on Smart-Toy and Smart-Bedsheet applications, an 89.7% accuracy for Smart-Toy and an 83.8% accuracy for Smart-Bedsheet can be achieved (10-fold cross-validation) using our feature library. Adopting the feature selection algorithm, the processing speed is increased by more than 3 times while maintaining high accuracy for both two applications. We believe our method could be a general and powerful toolkit in building real-time recognition software systems for pressure mapping smart textile.",multimedia
10.1016/j.cviu.2021.103339,Journal,Computer Vision and Image Understanding,scopus,2022-02-01,sciencedirect,SnapshotNet: Self-supervised feature learning for point cloud data segmentation using minimal labeled data,https://api.elsevier.com/content/abstract/scopus_id/85122523188,"Manually annotating complex scene point cloud datasets is both costly and error-prone. To reduce the reliance on labeled data, a new model called SnapshotNet is proposed as a self-supervised feature learning approach, which directly works on the unlabeled point cloud data of a complex 3D scene. The SnapshotNet pipeline includes three stages. In the snapshot capturing stage, snapshots, which are defined as local collections of points, are sampled from the point cloud scene. A snapshot could be a view of a local 3D scan directly captured from the real scene, or a virtual view of such from a large 3D point cloud dataset. Snapshots could also be sampled at different sampling rates or fields of view (FOVs), thus multi-FOV snapshots, to capture scale information from the scene. In the feature learning stage, a new pre-text task called multi-FOV contrasting is proposed to recognize whether two snapshots are from the same object or not, within the same FOV or across different FOVs. Snapshots go through two self-supervised learning steps: the contrastive learning step with both part contrasting and scale contrasting, followed by a snapshot clustering step to extract higher level semantic features. Then a weakly-supervised segmentation stage is implemented by first training a standard SVM classifier on the learned features with a small fraction of labeled snapshots. Then trained SVM is further used to predict labels for input snapshots and predicted labels are converted into point-wise label assignments for semantic segmentation of the entire scene using a voting procedure. The experiments are conducted on the Semantic3D dataset and the results have shown that the proposed method is capable of learning effective features from snapshots of complex scene data without any labels. Moreover, the proposed weakly-supervised method has shown advantages when comparing to the state of the art method on weakly-supervised point cloud semantic segmentation.",multimedia
10.1016/j.compag.2021.106644,Journal,Computers and Electronics in Agriculture,scopus,2022-02-01,sciencedirect,RIC-Net: A plant disease classification model based on the fusion of Inception and residual structure and embedded attention mechanism,https://api.elsevier.com/content/abstract/scopus_id/85121931762,"In this paper, we proposed a convolutional neural network based on Inception and residual structure with an embedded modified convolutional block attention module (CBAM), aiming to improve the classification of plant leaf diseases. Corn, potatoes and tomatoes are the most cultivated grains in southern China. The leaves of the three crops are very fragile and sensitive and are susceptible to leaf diseases, such as leaf blight of corn, late blight of potato and mosaic virus of tomato. These diseases cannot be identified at early stages. Therefore, an efficient solution is proposed by deep learning techniques to detect the disease categories of crops, which can effectively prevent the spread of diseases and ensure the normal growth of plants. In this experiment, our model achieved an overall accuracy of 99.55% for the identification of the three diseases of corn, potato and tomato. In addition, we tested the three plants individually. The classification accuracy of our model on corn, potato and tomato was 98.44%, 99.43% and 95.20%, respectively. We have also developed a web-based real-time plant disease classification system and deployed our model. The system had good performance in time and accuracy evaluation metrics. The results of this study showed that our model had fewer parameters, shorter training time, and higher recognition accuracy compared to existing image classification models.",multimedia
10.1016/j.cageo.2021.105010,Journal,Computers and Geosciences,scopus,2022-02-01,sciencedirect,GeospatialVR: A web-based virtual reality framework for collaborative environmental simulations,https://api.elsevier.com/content/abstract/scopus_id/85120435814,"This research introduces GeospatialVR, an open-source collaborative virtual reality framework to dynamically create 3D real-world environments that can be served on any web platform and accessed via desktop and mobile devices and virtual reality headsets. The framework can generate realistic simulations of desired locations entailing the terrain, elevation model, infrastructures, dynamic visualizations (e.g. water and fire simulation), and information layers (e.g. disaster damages and extent, sensor readings, occupancy, traffic, weather). These layers enable in-situ visualization of useful data to aid public, scientists, officials, and decision-makers in acquiring a bird's eye view of the current, historical, or forecasted condition of a community. The framework incorporates multiuser support to allow different stakeholders to remotely work on the same VR environment and observe other users' actions and 3D positions via avatars in real-time, and thus, presenting the potential to be utilized as a virtual incident command center or a meeting room. GeospatialVR's purpose is to enhance existing web-based cyberinfrastructure systems with the integration of immersive geospatial capabilities to assist the development of next-generation information and decision support systems powered by virtual reality. Finally, several case studies have been developed for flooding, wildfire, transportation, and public safety.",multimedia
10.1016/j.cose.2021.102539,Journal,Computers and Security,scopus,2022-02-01,sciencedirect,Deep face fuzzy vault: Implementation and performance,https://api.elsevier.com/content/abstract/scopus_id/85119176199,"Biometric technologies, especially face recognition, have become an essential part of identity management systems worldwide. In deployments of biometrics, secure storage of biometric information is necessary in order to protect the users’ privacy. In this context, biometric cryptosystems are designed to meet key requirements of biometric information protection enabling a privacy-preserving storage and comparison of biometric data, e.g. feature vectors extracted from facial images. Until now, biometric cryptosystems have hardly been applied to state-of-the-art biometric recognition systems utilizing deep convolutional neural networks.
                  This work investigates the application of a well-known biometric cryptosystem, i.e. the improved fuzzy vault scheme, to facial feature vectors extracted through deep convolutional neural networks. To this end, a feature transformation method is introduced which maps fixed-length real-valued deep feature vectors to integer-valued feature sets. As part of said feature transformation, a detailed analysis of different feature quantisation and binarisation techniques is conducted. At key binding, obtained feature sets are locked in an unlinkable improved fuzzy vault. For key retrieval, the efficiency of different polynomial reconstruction techniques is investigated. The proposed feature transformation method and template protection scheme are agnostic of the biometric characteristic and, thus, can be applied to virtually any biometric features computed by a deep neural network. In experiments, an unlinkable improved deep face fuzzy vault-based template protection scheme is constructed employing features extracted with a state-of-the-art deep convolutional neural network trained with the additive angular margin loss (ArcFace). For the best configuration, a false non-match rate below 1% at a false match rate of 0.01%, is achieved in cross-database experiments on the FERET and FRGCv2 face databases. On average, a security level of up to approximately 28 bits is obtained. This work presents an effective face-based fuzzy vault scheme providing privacy protection of facial reference data as well as digital key derivation from face.",multimedia
10.1016/j.aap.2021.106473,Journal,Accident Analysis and Prevention,scopus,2022-02-01,sciencedirect,Mining patterns of autonomous vehicle crashes involving vulnerable road users to understand the associated factors,https://api.elsevier.com/content/abstract/scopus_id/85118989110,"Autonomous or automated vehicles (AVs) have the potential to improve traffic safety by eliminating majority of human errors. As the interest in AV deployment increases, there is an increasing need to assess and understand the expected implications of AVs on traffic safety. Until recently, most of the literature has been based on either survey questionnaires, simulation analysis, virtual reality, or simulation to assess the safety benefits of AVs. Although few studies have used AV crash data, vulnerable road users (VRUs) have not been a topic of interest. Therefore, this study uses crash narratives from four-year (2017–2020) of AV crash data collected from California to explore the direct and indirect involvement of VRUs. The study applied text network and compared the text classification performance of four classifiers - Support Vector Machine (SVM), Naïve Bayes (NB), Random Forest (RF), and Neural Network (NN) and associated performance metrics to attain the objective. It was found that out of 252 crashes, VRUs were, directly and indirectly, involved in 23 and 12 crashes, respectively. Among VRUs, bicyclists and scooterists are more likely to be involved in the AV crashes directly, and bicyclists are likely to be at fault, while pedestrians appear more in the indirectly involvements. Further, crashes that involve VRUs indirectly are likely to occur when the AVs are in autonomous mode and are slightly involved minor damages on the rear bumper than the ones that directly involve VRUs. Additionally, feature importance from the best performing classifiers (RF and NN) revealed that crosswalks, intersections, traffic signals, movements of AVs (turning, slowing down, stopping) are the key predictors of the VRUs-AV related crashes. These findings can be helpful to AV operators and city planners.",multimedia
10.1016/j.eswa.2021.116073,Journal,Expert Systems with Applications,scopus,2022-02-01,sciencedirect,Efficient machine learning approach for volunteer eye-blink detection in real-time using webcam,https://api.elsevier.com/content/abstract/scopus_id/85117617175,"The progressive diminishment of motor capacities due to Amyotrophic Lateral Sclerosis (ALS) causes a severe communication deficit. The development of Alternative Communication software aids ALS patients in overcoming communication issues and the detection of communication signals plays a big role in this task. In this paper, volunteer eye-blinking is proposed as human–computer interaction signal and an intelligent Computer Vision detector was built for handling the captured data in real-time using a generic webcam. The eye-blink detection was treated as an extension of the eye-state classification, and the base pipeline used is delineated as follows: face detection, face alignment, region-of-interest (ROI) extraction, and eye-state classification. Furthermore, this pipeline was complemented with auxiliary models: a rotation compensator, a ROIs evaluator, and a moving average filter. Two new datasets were created: the Youtube Eye-state Classification (YEC) dataset, built from the AVSpeech dataset by extracting face images; and the Autonomus Blink Dataset (ABD), built completely as a result of the present work. The YEC allowed training the eye-classification task; ABD was specifically idealized taking into consideration volunteer eye-blinking detection. The proposed models, a Convolutional Neural Network (CNN) and a Support Vector Machine (SVM), were trained by the YEC dataset and performance evaluation experiments for both models were conducted across different databases: CeW, ZJU, Eyeblink, Talking Face (public datasets) and ABD. The impact of the proposed auxiliary models was evaluated and the CNN and SVM models were compared for the eye-state classification task. Promising results were obtained: 97.44% accuracy for the eye-state classification task on the CeW dataset and 92.63% F1-Score for the eye-blink detection task on the ABD dataset.",multimedia
10.1016/j.future.2021.08.030,Journal,Future Generation Computer Systems,scopus,2022-02-01,sciencedirect,A wearable-based posture recognition system with AI-assisted approach for healthcare IoT,https://api.elsevier.com/content/abstract/scopus_id/85115908462,"Human posture recognition is a challenging task in the medical healthcare industry, when pursuing intelligence, accuracy, security, privacy, and efficiency, etc. Currently, the main posture recognition methods are captured-behaviors-based visual image analysis and wearable devices-based signal analysis. However, these methods suffer from issues such as high misjudgment rate, high-cost and low-efficiency. To address these issues, we propose a collaborative AI-IoT-based solution (namely, WMHPR) that embeds with advanced AI-assisted approach. In WMHPR, we propose the multi-posture recognition (MPR), an offline algorithm is implemented on wearable hardware, to identify posture based on multi-dimensions data. Meanwhile, an AI-based algorithm running on the cloud server (online), named Cascade-AdaBoosting-CART (CACT), is proposed to further enhance the reliability and accuracy of MPR. We recruit 20 volunteers for real-life experiments to evaluate the effectiveness, and the results show our solution is significantly outstanding in terms of accuracy and reliability while comparing with other typical algorithms.",multimedia
10.1016/j.inffus.2021.09.004,Journal,Information Fusion,scopus,2022-02-01,sciencedirect,Multimodal Earth observation data fusion: Graph-based approach in shared latent space,https://api.elsevier.com/content/abstract/scopus_id/85115401406,"Multiple and heterogenous Earth observation (EO) platforms are broadly used for a wide array of applications, and the integration of these diverse modalities facilitates better extraction of information than using them individually. The detection capability of the multispectral unmanned aerial vehicle (UAV) and satellite imagery can be significantly improved by fusing with ground hyperspectral data. However, variability in spatial and spectral resolution can affect the efficiency of such dataset's fusion. In this study, to address the modality bias, the input data was projected to a shared latent space using cross-modal generative approaches or guided unsupervised transformation. The proposed adversarial networks and variational encoder-based strategies used bi-directional transformations to model the cross-domain correlation without using cross-domain correspondence. It may be noted that an interpolation-based convolution was adopted instead of the normal convolution for learning the features of the point spectral data (ground spectra). The proposed generative adversarial network-based approach employed dynamic time wrapping based layers along with a cyclic consistency constraint to use the minimal number of unlabeled samples, having cross-domain correlation, to compute a cross-modal generative latent space. The proposed variational encoder-based transformation also addressed the cross-modal resolution differences and limited availability of cross-domain samples by using a mixture of expert-based strategy, cross-domain constraints, and adversarial learning. In addition, the latent space was modelled to be composed of modality independent and modality dependent spaces, thereby further reducing the requirement of training samples and addressing the cross-modality biases. An unsupervised covariance guided transformation was also proposed to transform the labelled samples without using cross-domain correlation prior. The proposed latent space transformation approaches resolved the requirement of cross-domain samples which has been a critical issue with the fusion of multi-modal Earth observation data. This study also proposed a latent graph generation and graph convolutional approach to predict the labels resolving the domain discrepancy and cross-modality biases. Based on the experiments over different standard benchmark airborne datasets and real-world UAV datasets, the developed approaches outperformed the prominent hyperspectral panchromatic sharpening, image fusion, and domain adaptation approaches. By using specific constraints and regularizations, the network developed was less sensitive to network parameters, unlike in similar implementations. The proposed approach illustrated improved generalizability in comparison with the prominent existing approaches. In addition to the fusion-based classification of the multispectral and hyperspectral datasets, the proposed approach was extended to the classification of hyperspectral airborne datasets where the latent graph generation and convolution were employed to resolve the domain bias with a small number of training samples. Overall, the developed transformations and architectures will be useful for the semantic interpretation and analysis of multimodal data and are applicable to signal processing, manifold learning, video analysis, data mining, and time series analysis, to name a few.",multimedia
10.1016/j.aej.2021.06.024,Journal,Alexandria Engineering Journal,scopus,2022-02-01,sciencedirect,"Automatic diagnosis of COVID-19 disease using deep convolutional neural network with multi-feature channel from respiratory sound data: Cough, voice, and breath",https://api.elsevier.com/content/abstract/scopus_id/85109458695,"The problem of respiratory sound classification has received good attention from the clinical scientists and medical researcher’s community in the last year to the diagnosis of COVID-19 disease. The Artificial Intelligence (AI) based models deployed into the real-world to identify the COVID-19 disease from human-generated sounds such as voice/speech, dry cough, and breath. The CNN (Convolutional Neural Network) is used to solve many real-world problems with Artificial Intelligence (AI) based machines. We have proposed and implemented a multi-channeled Deep Convolutional Neural Network (DCNN) for automatic diagnosis of COVID-19 disease from human respiratory sounds like a voice, dry cough, and breath, and it will give better accuracy and performance than previous models. We have applied multi-feature channels such as the data De-noising Auto Encoder (DAE) technique, GFCC (Gamma-tone Frequency Cepstral Coefficients), and IMFCC (Improved Multi-frequency Cepstral Coefficients) methods on augmented data to extract the deep features for the input of the CNN. The proposed approach improves system performance to the diagnosis of COVID-19 disease and provides better results on the COVID-19 respiratory sound dataset.",multimedia
10.1016/j.apacoust.2021.108439,Journal,Applied Acoustics,scopus,2022-01-15,sciencedirect,"CAMNet: A controllable acoustic model for efficient, expressive, high-quality text-to-speech",https://api.elsevier.com/content/abstract/scopus_id/85116891718,"Spoken language is becoming one of the key components of human–machine interaction, both to send information to the machine – e.g. voice control – and to receive from it – e.g. virtual assistants. In this scenario, text-to-speech (TTS) models have become an essential artificial intelligence capacity. Even though this interaction can be based on neutral style speech, generating speech with different styles, pitches and speaking rates may improve user experience. With this in view, this paper presents CAMNet, a controllable acoustic model for efficient, expressive, high-quality TTS. CAMNet is based on deep convolutional TTS (DCTTS), a state-of-art acoustic model which is efficient and produces neutral speech. DCTTS was first adapted to generate Bark cepstrum acoustic features in order to integrate well with the LPCNet (linear prediction coefficient) neural vocoder and to remove the reduction factor which demanded the presence of an upsampling network before the vocoder – i.e. the CAMNet output can be directly fed into LPCNet. Next, style transfer functionality was added by means of a novel characterisation of the prosodic information from the Bark cepstrum acoustic features and a new approach to inject this information into the convolutional layers. Finally, controllability is provided via a variational auto-encoder module which creates a smoothed disentangled latent space which allows interpolation and extrapolation of reference styles as well as independent and simultaneous control of two generative factors: pitch and speaking rate. Moreover, this controllability is implemented using a simple offset-based approach. To sum up, CAMNet is an efficient acoustic model which provides a simple but consistent controllability on coarse-grained expression, pitch and speaking rate while still providing high-quality synthesised speech.",multimedia
10.1016/j.aca.2021.339411,Journal,Analytica Chimica Acta,scopus,2022-01-01,sciencedirect,A video processing and machine vision-based automatic analyzer to determine sequentially total suspended and settleable solids in wastewater,https://api.elsevier.com/content/abstract/scopus_id/85123884378,"The monitoring of total suspended (TSS) and settleable (SetS) solids in wastewater is essential to maintain the quality parameters for aquatic biota because they can transport pollutants and block light penetration. Determining them by their respective reference methods, however, is laborious, expensive, and time consuming. To overcome this, we developed a new analytical instrument called Solids in Wastewater's Machine Vision-based Automatic Analyzer (SWAMVA), which is equiped with an automatic sampler and a software for real-time digital movie capture to quantify sequentially the TSS and SetS contents in wastewater samples. The machine vision algorithm (MVA) coupled with the Red color plane (derived from color histograms in the Red-Green-Blue (RGB) system) showed the best prediction results with R2 of 0.988 and 0.964, and relative error of prediction (REP) of 6.133 and 9.115% for TSS and SetS, respectively. The constructed models were validated by Analysis of Variance (ANOVA), and the accuracy and precision of the predictions by the t- and F-tests, respectively, at a 0.05 significance level. The elliptical joint confidence region (EJCR) test confirmed the accuracy, while the coefficient of variation (CV) of 6.529 and 10.908% confirmed the good precisions, respectively. Compared with the reference method (Standard Methods For the Examination of Water and Wastewater), the proposed method reduced the analysis volume from 1.5 L to just 15 mL and the analysis time from 12 h to 24 s per sample. Therefore, SWAMVA can be considered an important alternative to the determination of TSS and SetS in wastewater as an automatic, fast, and low-cost analytical tool, following the principles of Green Chemistry and exploiting Industry 4.0 features such as intelligent processing, miniaturization, and machine vision.",multimedia
10.1016/j.jsr.2021.12.010,Journal,Journal of Safety Research,scopus,2022-01-01,sciencedirect,Learning to interpret novel eHMI: The effect of vehicle kinematics and eHMI familiarity on pedestrian’ crossing behavior,https://api.elsevier.com/content/abstract/scopus_id/85123375400,"Introduction: In current urban traffic, pedestrians attempting to cross the road at un-signalized locations are thought to mostly use implicit communication, such as deceleration cues, to interpret a vehicle’s intention to yield. There is less reliance on explicit driver- or vehicle-based messages, such as hand/head movements, or flashing lights/beeping horns. With the impending deployment of Automated Vehicles (AV), especially those at SAE Level 4 and 5, where the driver is no longer in control of the vehicle, there has been a surge in interest in the value of new forms of communication for AVs, for example, via different types of external Human Machine Interfaces (eHMIs). However, there is still much to be understood about how quickly a novel eHMI affects pedestrian crossing decisions, and whether it provides any additional aid, above and beyond implicit/kinematic information from the vehicle. The aim of this between-participant study, funded by the H2020 interACT project, was to investigate how the combination of kinematic information from a vehicle (e.g., Speed and Deceleration), and eHMI designs, play a role in assisting the crossing decision of pedestrians in a cave-based pedestrian simulator. Method: Using an existing, well-recognized, message for yielding (Flashing Headlights - FH) as a benchmark, this study also investigated how quickly a novel eHMI (Slow Pulsing Light Band – SPLB) was learned. To investigate the effect of eHMI visibility on crossing decisions, the distance at which each eHMI was perceivable was also measured. Results: Results showed that, compared to SPLB, the FH led to earlier crossings during vehicle deceleration, especially at lower approaching speeds, and smaller time gaps. However, although FH was visible earlier than SPLB, this visibility does not appear to be the only reason for earlier crossings, with message familiarity thought to play a role. Participants were found to learn the meaning conveyed by FH relatively quickly, crossing around 1 second earlier in its presence (compared to the no eHMI condition), across the three blocks of trials. On the other hand, it took participants at least one block of 12 trials for the new SPLB signal to affect crossing, which only accelerated crossing initiations by around 200 ms, compared to the no eHMI condition. The role of comprehension, long-term exposure, and familiarity of novel messages in this context is therefore important, if AVs are to provide safe, trustworthy communication messages, which will enhance traffic flow and efficiency.",multimedia
10.1016/j.buildenv.2021.108532,Journal,Building and Environment,scopus,2022-01-01,sciencedirect,Personal thermal comfort models using digital twins: Preference prediction with BIM-extracted spatial–temporal proximity data from Build2Vec,https://api.elsevier.com/content/abstract/scopus_id/85119963452,"Conventional thermal preference prediction in buildings has limitations due to the difficulty in capturing all environmental and personal factors. New model features can improve the ability of a machine learning model to classify a person’s thermal preference. The spatial context of a building can provide information to models about the windows, walls, heating and cooling sources, air diffusers, and other factors that create micro-environments that influence thermal comfort. Due to spatial heterogeneity, it is impractical to position sensors at a high enough resolution to capture all conditions. This research aims to build upon an existing vector-based spatial model, called Build2Vec, for predicting spatial–temporal occupants’ indoor environmental preferences. Build2Vec utilizes the spatial data from the Building Information Model (BIM) and indoor localization in a real-world setting. This framework uses longitudinal intensive thermal comfort subjective feedback from smart watch-based ecological momentary assessments (EMA). The aggregation of these data is combined into a graph network structure (i.e., objects and relations) and used as input for a classification model to predict occupant thermal preference. The results of a test implementation show 14%–28% accuracy improvement over a set of baselines that use conventional thermal preference prediction input variables.",multimedia
10.1016/j.jobe.2021.103571,Journal,Journal of Building Engineering,scopus,2022-01-01,sciencedirect,An integrated building energy performance evaluation method: From parametric modeling to GA-NN based energy consumption prediction modeling,https://api.elsevier.com/content/abstract/scopus_id/85119285403,"Building energy performance evaluation, as an important process in a sustainable building design, has important consequences for global energy conservation and environmental protection. The traditional methods to perform this evaluation are usually time-consuming and computationally complex, and have high requirements for designers’ professional knowledge on architectural physics and software operation skills. To solve these problems and provide rapid, user-friendly, and more accurate prediction results, this study presents an efficient building energy performance evaluation method which integrates building information modeling, energy simulation, and energy consumption prediction together. This method follows a three-stage research framework: Stage 1 proposes a rapid 3D building energy modeling process according to the parameterized setting, Stage 2 generates numerous simulation results automatically by EnergyPlus, and Stage 3 develops the user-friendly building energy consumption prediction model with the help of the Genetic Algorithm-Neural Network (GA-NN) and provides the energy performance level of the building design after the prediction. A case study is carried out to present the overall process and verify the accuracy of the proposed three-stage building energy performance evaluation method. This study contributes to the improvement of both the extensive dataset establishment and the operational efficiency of building energy consumption prediction. It can provide designers with a real-time, user-friendly, and reliable building energy consumption prediction tool and an energy performance assessment basis in the design phase of construction projects.",multimedia
10.1016/j.ijpe.2021.108339,Journal,International Journal of Production Economics,scopus,2022-01-01,sciencedirect,Age-based preventive maintenance with multiple printing options,https://api.elsevier.com/content/abstract/scopus_id/85118549755,"In today's economic context, production systems must be readily available and machinery downtime kept to a minimum. Maintenance and spare parts inventory management play a vital role in achieving these goals, and preventive maintenance has increasingly been considered in maintenance policies. Additive manufacturing (AM) has recently been combined with preventive maintenance, and thus represents an emerging research direction. However, few studies have as yet been conducted in this research stream, and we intend to fill this gap. Our study makes three main contributions. First, we address the main limitations of two current models (i.e., assuming that no failure occurs during the replenishment lead time of the spare parts). Second, we propose a new maintenance policy that considers two printing options with different levels of reliability and unitary purchase costs. Third, we develop a decision support system (DSS) to assist managers in deciding whether to implement a preventive maintenance policy that includes AM or conventional manufacturing (CM) parts. We take an interdisciplinary approach to conducting a parametrical analysis where we consider real data on the reliability of CM and AM parts, in addition to the impact of post-processing operations and optimization routines. We find that AM-based preventive maintenance policies are favored when the MTTF and the backorder costs are low and when the failure and maintenance costs are high. These findings have been incorporated into the DSS, which provides thresholds for every parameter to guide practitioners in choosing between AM and CM parts for preventive maintenance, without requiring time-expensive calculations.",multimedia
10.1016/j.compind.2021.103556,Journal,Computers in Industry,scopus,2022-01-01,sciencedirect,C-Ports: A proposal for a comprehensive standardization and implementation plan of digital services offered by the “Port of the Future”,https://api.elsevier.com/content/abstract/scopus_id/85118477493,"In this paper we address the topic of a possible path to standardize the ICT services expected to be delivered by the so-called “Port of the Future”. How the most relevant technologies and Information Systems are used by the Port Communities for their businesses is discussed together with a detailed analysis of the on-going actions carried on by Standard Setting Organizations. Considering the examples given by the C-ITS Platform and the C-Roads programme at EU level, a proposal of contents to be considered in a comprehensive standardization action is given. The innovation services are therefore grouped into four bundles: (i) Vessel & Marine Navigation, (ii) e-Freight & (Intermodal) Logistics, (iii) Passenger Transport, (iv) Environmental sustainability. The standardized version of these applications will be finally labeled as C-Port services. Alongside the standardization plan, a proposal for ranking the ports on the basis of a specially-defined C-Port vector is discussed with the purpose of addressing the well-known lack of consensus around the mathematical definition of the Smart Port Index. Considering the good practice and the background offered by the Port of Livorno in terms of innovation actions, the prospected final user applications are then labeled as Day 1, Day 1.5, and Day 2 services in consideration of the technical and commercial gaps to be filled. As a case study about the evolution in the C-Port vector experienced by the Port of Livorno in the last years will also be discussed.",multimedia
10.1016/j.scs.2021.103364,Journal,Sustainable Cities and Society,scopus,2022-01-01,sciencedirect,Blockchain-enabled Secure Framework for Energy-Efficient Smart Parking in Sustainable City Environment,https://api.elsevier.com/content/abstract/scopus_id/85117732239,"In the smart city environment, parking vehicle management is an essential requirement for citizens in the current situation because every city is rapidly growing as a crowded environment. Specific planning, operation, and thinking can address this problem with the Internet of things (IoT) and Information Communication Technologies (ICT). Existing research provides various solutions and methods for parking systems in the smart city. However, smart parking has many challenges, such as centralization, communication bandwidth, energy efficiency, integrity, security, and privacy. Inspired by Blockchain and AI technology, we propose a Blockchain-enabled Secure Framework for Energy-Efficient Smart Parking in Sustainable City Environment. The transport layer implements the ECC algorithm to encrypt and decrypt the parking zones data for secure communication. The RSU-based-Blockchain network offers authentication and verification of data at the security layer in a distributed manner. Virtualization technology is used for data storage and provides an energy-efficient environment using virtual machines. With Deep LSTM networks, we analyze the parking zone's data and offer the best parking space to the drivers with the best location and timing. We evaluate the proposed architecture using quantitative, qualitative analysis and provide the driver's best parking space.",multimedia
10.1016/j.eswa.2021.115973,Journal,Expert Systems with Applications,scopus,2022-01-01,sciencedirect,Deep correlation mining for multi-task image clustering,https://api.elsevier.com/content/abstract/scopus_id/85116928779,"Multi-task clustering (MTC) aims to enhance the performance of each individual task by leveraging the correlation information among them. Existing MTC algorithms usually first extract the feature representations of each task and then learn the relationships among multiple tasks for clustering. However, the multi-task correlations are not embedded into the feature learning in existing MTC. In addition, many real applications, such as image clustering, always perform visual feature extraction and clustering assignment separately, which often results in local optimal clustering resolutions. In this study, an end-to-end MTC framework, named Deep correlation mining for Multi-Task image Clustering (DMTC), is proposed to explore multi-task correlations and conduct image clustering simultaneously. Specifically, DMTC consists of two sub-networks: a between-task network (B-net) and a within-task network (W-net), which learn the correlations among multiple tasks and the relationships in each individual task, respectively, based on a deep convolutional network. To optimize B-net, an optimization procedure is proposed as follows: (1) DMTC builds a pseudo-graph to discover similar samples among tasks and obtain the positive pairs of possible related tasks. (2) A discriminator is designed to calculate the mutual information between the deep and shallow representations of related tasks, which can estimate the relatedness between each pair of related tasks. After that, the trained parameters in B-net are transferred to the within-task networks (W-net) as their initialized parameters, in which the above optimization procedure is performed again to obtain the final cluster partition by end-to-end training. Experimental results on NUS-Wide, Caltech-256, Cifar-100 and Pascal VOC demonstrate that our proposed DMTC method
                        1
                     
                     
                        1
                        The source code is available in https://github.com/Xiaoqiang-Yan/DMTC.
                     compares favorably to the state-of-the-art methods.",multimedia
10.1016/j.autcon.2021.103996,Journal,Automation in Construction,scopus,2022-01-01,sciencedirect,Implementation experiments on convolutional neural network training using synthetic images for 3D pose estimation of an excavator on real images,https://api.elsevier.com/content/abstract/scopus_id/85116888055,"Remote and descriptive visualization of spatio-temporal information of excavator activities may increase awareness about jobsite hazards and operational performance in earthwork operations. One of the emerging approaches to collect this information is to extract the 3D pose of an excavator from the video frames using a convolutional neural network (CNN). However, this method requires labeling the training datasets, which are difficult to prepare because of conditions unsuitable for installing the motion capture sensors. This study investigates the performance of a CNN for estimating the 3D pose when trained on a synthetic dataset. In particular, a kinematic constraint is proposed to update the model parameters efficiently during training. The results show that the proposed method estimated the 3D poses of a real excavator with an average pose error of 9.63°. Hence, the proposed data augmentation method could help address the training data issues and improves the learning of real data complexity.",multimedia
10.1016/j.sigpro.2021.108317,Journal,Signal Processing,scopus,2022-01-01,sciencedirect,Selective fixed-filter active noise control based on convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85114690529,"Active noise control (ANC) technology is increasingly ubiquitous in wearable audio devices, or hearables. Owing to its low computational complexity, high robustness, and exemplary performance in dealing with dynamic noise, the fixed-coefficient control filter strategy plays a central role in portable ANC implementation. Unlike its traditional adaptive counterpart, the fixed-filter strategy is unable to attain optimal noise reduction for different types of noise. Hence, we propose a selective fixed-filter ANC method based on a simplified two-dimensional convolution neural network (2D CNN), which is implemented on a co-processor (e.g., in a mobile phone), to derive the most suitable control filter for different noise types. To further reduce classification complexity, we designed a lightweight one-dimensional CNN (1D CNN), which can directly classify noise types in time domain. A numerical simulation based on measured paths in headphones demonstrates the proposed algorithm’s efficacy in attenuating real-world non-stationary noise over conventional adaptive algorithms.",multimedia
10.1016/j.csl.2021.101275,Journal,Computer Speech and Language,scopus,2022-01-01,sciencedirect,Feature learning for efficient ASR-free keyword spotting in low-resource languages,https://api.elsevier.com/content/abstract/scopus_id/85113158279,"We consider feature learning for a computationally efficient method of keyword spotting that can be applied in severely under-resourced settings. The objective is to support humanitarian relief programmes by the United Nations (UN) in parts of Africa in which almost no language resources are available. To allow a keyword spotting system to be rapidly developed in such a language, we rely on a small and easily-compiled set of isolated keywords. Using the isolated keywords as templates, we apply dynamic time warping (DTW) to a much larger corpus of in-domain but untranscribed speech. The resulting DTW alignment scores are used to train a convolutional neural network (CNN) which is orders of magnitude more computationally efficient than DTW and therefore suitable for real-time application. We optimise this ASR-free neural network keyword spotting procedure by identifying acoustic features that provide robust performance in this almost zero-resource setting. First, we consider the benefits of incorporating information from well-resourced but unrelated languages by incorporating a multilingual bottleneck feature (BNF) extractor. Next, we consider using features extracted from an autoencoder (AE) trained on in-domain but untranscribed data. Finally, we consider features obtained from a correspondence autoencoder (CAE) which is initialised with the AE and subsequently fine-tuned on the small set of in-domain labelled data. Experiments in South African English and Luganda, a low-resource language, demonstrate that, on their own, both the BNF and CAE features can achieve a 5% relative performance improvement over baseline MFCCs. However, by using BNFs as input to the CAE, even better performance is achieved, resulting in a more than 27% relative improvement over MFCCs in ROC area-under-the-curve (AUC) and more than twice as many top-10 retrievals. We also show that, using these features, the CNN-DTW keyword spotter performs almost as well as the DTW keyword spotter while comfortably outperforming a baseline CNN trained only on the keyword templates. We conclude that a CNN-DTW keyword spotter using BNF-derived CAE features represents a computationally efficient approach with very competitive performance that is suited to rapid deployment in a severely under-resourced scenario.",multimedia
10.1016/j.petrol.2021.109332,Journal,Journal of Petroleum Science and Engineering,scopus,2022-01-01,sciencedirect,End-to-end neural network approach to 3D reservoir simulation and adaptation,https://api.elsevier.com/content/abstract/scopus_id/85112357560,"Reservoir simulation and adaptation (also known as history matching) are typically considered as separate problems. While a set of models are aimed at the solution of the forward simulation problem assuming all initial geological parameters are known, the other set of models adjust geological parameters under the fixed forward simulation model to fit production data. This results in many difficulties for both reservoir engineers and developers of new efficient computation schemes. We present a unified approach to reservoir simulation and adaptation problems. A single neural network model allows a forward pass from initial geological parameters of the 3D reservoir model through dynamic state variables to well’s production rates and backward gradient propagation to any model inputs and variables. The model fitting and geological parameters adaptation both become the optimization problem over specific parts of the same neural network model. Standard gradient-based optimization schemes can be used to find the optimal solution. Using real-world oilfield model and historical production rates we demonstrate that the suggested approach allows reservoir simulation and history matching with a benefit of several orders of magnitude simulation speed-up. Finally, to propagate this research we open-source a Python-based framework DeepField that allows standard processing of reservoir models and reproducing the approach presented in this paper.",multimedia
10.1016/j.patcog.2021.108205,Journal,Pattern Recognition,scopus,2022-01-01,sciencedirect,Tracking more than 100 arbitrary objects at 25 FPS through deep learning,https://api.elsevier.com/content/abstract/scopus_id/85111593606,"Most video analytics applications rely on object detectors to localize objects in frames. However, when real-time is a requirement, running the detector at all the frames is usually not possible. This is somewhat circumvented by instantiating visual object trackers between detector calls, but this does not scale with the number of objects. To tackle this problem, we present SiamMT, a new deep learning multiple visual object tracking solution that applies single-object tracking principles to multiple arbitrary objects in real-time. To achieve this, SiamMT reuses feature computations, implements a novel crop-and-resize operator, and defines a new and efficient pairwise similarity operator. SiamMT naturally scales up to several dozens of targets, reaching 25 fps with 122 simultaneous objects for VGA videos, or up to 100 simultaneous objects in HD720 video. SiamMT has been validated on five large real-time benchmarks, achieving leading performance against current state-of-the-art trackers.",multimedia
