doi,title,publisher,content_type,abstract,html_url,publication_title,publication_date,database
10.1109/ICRA.2019.8793690,A Fog Robotics Approach to Deep Robot Learning: Application to Object Recognition and Grasp Planning in Surface Decluttering,IEEE,Conferences,"The growing demand of industrial, automotive and service robots presents a challenge to the centralized Cloud Robotics model in terms of privacy, security, latency, bandwidth, and reliability. In this paper, we present a `Fog Robotics' approach to deep robot learning that distributes compute, storage and networking resources between the Cloud and the Edge in a federated manner. Deep models are trained on non-private (public) synthetic images in the Cloud; the models are adapted to the private real images of the environment at the Edge within a trusted network and subsequently, deployed as a service for low-latency and secure inference/prediction for other robots in the network. We apply this approach to surface decluttering, where a mobile robot picks and sorts objects from a cluttered floor by learning a deep object recognition and a grasp planning model. Experiments suggest that Fog Robotics can improve performance by sim-to-real domain adaptation in comparison to exclusively using Cloud or Edge resources, while reducing the inference cycle time by 4× to successfully declutter 86% of objects over 213 attempts.",https://ieeexplore.ieee.org/document/8793690/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ROBIO.2009.4913063,A bio-inspired haptic interface for tele-robotics applications,IEEE,Conferences,"This paper presents the design concept for a bio-inspired exoskeleton intended for applications in tele-robotics and virtual reality. We based the development on an attentive analysis of the human arm anatomy with the intent to synthesize a system that will be able to interface with the human limb in a natural way. Our main goal is to develop a multi contact-point haptic interface that does not restrict the arm mobility and therefore increases the operational workspace. We propose a simplified kinematic model of the human arm using a notation coming from the robotics field. To figure out the best kinematic architecture we employed real movement data, measured from a human subject, and integrated them with the kinematic model of the exoskeleton. This allows us to test the system before its construction and to formalize specific requirements. We also implemented and tested a first passive version of the shoulder joint.",https://ieeexplore.ieee.org/document/4913063/,2008 IEEE International Conference on Robotics and Biomimetics,22-25 Feb. 2009,ieeexplore
10.1109/ROBIO.2014.7090308,A chaotic neural network as motor path generator for mobile robotics,IEEE,Conferences,This work aims at developing a motor path generator for applications in mobile robotics based on a chaotic neural network. The computational paradigm inspired by the neural structure of microcircuits located in the human prefrontal cortex is adapted to work in real-time and used to generate the joints trajectories of a lightweight quadruped robot. The recurrent neural network was implemented in Matlab and a software framework was developed to test the performances of the system with the robot dynamic model. Preliminary results demonstrate the capability of the neural controller to learn period signals in a short period of time allowing adaptation during the robot operation.,https://ieeexplore.ieee.org/document/7090308/,2014 IEEE International Conference on Robotics and Biomimetics (ROBIO 2014),5-10 Dec. 2014,ieeexplore
10.1109/IJCNN.2010.5596771,A cognitive developmental robotics architecture for lifelong learning by evolution in real robots,IEEE,Conferences,"This paper is devoted to a detailed presentation of the current state of the Multilevel Darwinist Brain (MDB) cognitive architecture for lifelong learning in real robots. This architecture follows the cognitive developmental robotics approach and it is based on concepts like embodiment, open-ended lifelong learning, autonomous knowledge acquisition or adaptive behaviors and motivations. In addition, this version of the MDB architecture incorporates several improvements related with more practical issues, which are the result of the experience gained through several experiments with real robots in the last few years. The MDB uses evolutionary algorithms in the knowledge acquisition process, which implies the need of paying attention to the efficiency of the computational implementation. Here, we first describe the cognitive model on which the basic operation of the architecture is based and, secondly, we detail the main aspects and working of the current version of the MDB. Finally, we have designed a very simple but illustrative real robot lifelong learning example, where we can show how to set up an experiment using the MDB. Hence, with this simple example we show the successful behavior of the MDB cognitive developmental robotics principles.",https://ieeexplore.ieee.org/document/5596771/,The 2010 International Joint Conference on Neural Networks (IJCNN),18-23 July 2010,ieeexplore
10.1109/ETFA.1999.815411,Advanced control techniques based in artificial intelligence for robotics manipulators,IEEE,Conferences,"The performance quality in nonlinear model based control of mechanical manipulators is conditioned to the reliability of the mathematical model and precision in the knowledge of all the involved parameters. Control methods based on artificial intelligence techniques (learning algorithms, system identification and neural networks) can be applied to improve its performance. A neural control scheme is proposed, consisting basically of a neural network for learning the robot inverse dynamics and online generating the control signal. Also an online supervision based on optimisation techniques is designed and implemented for such neural control. Simulation results are provided to evaluate the alternative variations to the proposed central scheme.",https://ieeexplore.ieee.org/document/815411/,1999 7th IEEE International Conference on Emerging Technologies and Factory Automation. Proceedings ETFA '99 (Cat. No.99TH8467),18-21 Oct. 1999,ieeexplore
10.1109/ICEKIM52309.2021.00040,Application of Teaching Innovation Based on robotics engineering,IEEE,Conferences,"As the core major of “Internet + Industrial Intelligence”, robotics engineering is an upgrade and reconstruction of traditional engineering major. The industrial robot course is the professional core course of the Robotics Engineering. It is also a comprehensive course of multi-discipline integration, which involved mechanical engineering, automatic control, computer, sensor, electronic technology, artificial intelligence and other multi-disciplinary content. Robotics Engineering is characterized by broad foundation, great difficulty, emphasis on practice, rapid development and application of new knowledge. In the process of implementation of the teaching innovation, the new concept of engineering education was applied to propose a new form of curriculum system. Taking the projects of engineering as the study objects, disassemble the knowledge points involved in industrial robots, break the course boundaries, reshape the knowledge system, draw knowledge maps and then design teaching activities. In teaching innovation, teachers extend classroom through formation of subject competition teams, promote teaching and promote learning by competition, realize the integration of “teaching, class and competition”, build a bridge between theory and practice, then complete the transformation from knowledge learning to ability training. Besides, they also keep contact with intelligent manufacturing enterprises in Zhuhai and the Bay Area to obtain real-time new developments in enterprises. Thus, the latest information was introduced into classroom. Therefore, the meaning of “production, teaching, research and application” has been deepened. According to the characteristics of the knowledge points of the course, experts were invited to make special lectures for students which can bring them with international perspective and frontier knowledge.",https://ieeexplore.ieee.org/document/9479656/,"2021 2nd International Conference on Education, Knowledge and Information Management (ICEKIM)",29-31 Jan. 2021,ieeexplore
10.1109/ROBOT.2000.844768,Application of automatic action planning for several work cells to the German ETS-VII space robotics experiments,IEEE,Conferences,"Experiences in space robotics show, that the user normally has to cope with a huge amount of data. So, only robot and mission specialists are able to control the robot arm directly in teleoperation mode. By means of an intelligent robot control in cooperation with virtual reality methods, it is possible for non-robot specialists to generate tasks for a robot or an automation component intuitively. Furthermore, the intelligent robot control improves the safety of the entire system. The on-ground robot control and command station for the robot arm ERA onboard the satellite ETS-VII builds on a new resource-based action planning approach to manage robot manipulators and other automation components. In the case of ERA, the action planning system also takes care of the ""real"" robot onboard the satellite and the ""virtual"" robot in the simulation system. By means of the simulation system, the user can plan tasks ahead as well as analyze and visualize different strategies. The paper describes the mechanism of resource-based action planning, its application to different work cells, the practical experiences gained from the implementation for the on-ground robot control and command station for the robot arm ERA developed in the GETEX project as well as the services it provides to support VR-based man machine interfaces.",https://ieeexplore.ieee.org/document/844768/,Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065),24-28 April 2000,ieeexplore
10.1109/ICACITE51222.2021.9404749,Artificial Intelligence and Robotics: Impact &amp; Open issues of automation in Workplace,IEEE,Conferences,"In engineering province robotics is one of the cognitive perspective to human communication or it concern with synod of perception of action. In Today's Tech World Artificial Intelligence is an essential tool which provides effective analytical business solutions &amp; plays significant role in the domain of robotics and have several similarities like human behavior which may drive the real world. This paper shows the significant blend of Artificial Intelligence and robotics which transform entire industries, technological improvement of robotics application &amp; utilization. It also focuses on different aspects of targets like marketing, home appliances, medical science, Smart agriculture and many more which includes open issues and technological challenges arises by this combination and conclude that robotics with AI can work in real world with real objects. Further AI based robotics are very important area in economics and organizational consequence, implementation of automation in any organizational design give impact on overall economy and infrastructure provide a wider direction for further research on Robotics and IoT are two terms each covering a myriad of technologies and concepts.",https://ieeexplore.ieee.org/document/9404749/,2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE),4-5 March 2021,ieeexplore
10.1109/ECMR.2019.8870908,Autonomous Robots as Actors in Robotics Theatre - Tribute to the Centenary of R.U.R.,IEEE,Conferences,"In the eyes of the roboticists, the play R.U.R. (Rossum's Universal Robots) of Czech writer Karel Čapek is seen as the messenger of the new robot age. R.U.R. is renown for the first mentioning of the word robot for a humanoid machine that looks, moves, feels, thinks and works like a human. Inspired by the 100th anniversary of R.U.R. in 2020, we have decided to make a performance with Pepper and NAO humanoid robots acting together with human actors. Performing in a theatrical performance is very demanding even for human actors, so we see the implementation of R.U.R. with robotic co-actors as a real challenge. For this purpose, we have analyzed human-robot and robot-robot interaction in the R.U.R. script to evaluate whether NAO and Pepper robots that we have are apt to act autonomously. Due to specific robot deficiencies that we found, we have made the robot casting first and then adapted the R.U.R. script to enable Pepper and NAO robots to perform their roles.",https://ieeexplore.ieee.org/document/8870908/,2019 European Conference on Mobile Robots (ECMR),4-6 Sept. 2019,ieeexplore
10.1109/CSCS52396.2021.00073,Bluetooth Communications in Educational Robotics,IEEE,Conferences,"In a world in a continuous and rapid change, it is absolutely necessary for our students to keep up with the rapid progress of new technologies: Internet of Things (IoT), Robotics, Artificial Intelligence (AI), Virtual Reality (VR), Augmented Reality (AR) etc. The rapid evolution and diversification of these emerging technologies has recently led to their introduction into the educational offer of the school curriculum for the gymnasium. The discipline of Information and Communication Technology (ICT) has already been implemented, a discipline that involves both the formation of skills to use new technologies and the formation of computational thinking necessary for the efficient and intelligent use of these technologies. In order to teach and learn Physics from a STEM (Science, Technology, Engineering and Mathematics) educational perspective, we initiated optional school courses of IoT, Robotics and AI (approached through Machine Learning). These courses stimulate, at the level of students, computational thinking, creativity and innovation and lead, from an interdisciplinary perspective, to the development of emerging specializations such as Mathematics-Physics-Automation, Mathematics-Physics-Electronics, Mathematics-Physics-Informatics-Robotics etc. In this paper we presented a method of approaching, in the school educational space, the study of wireless communication technologies between smart devices, through an Educational Robotics project. The project consisted of creating a wireless controlled mobile robotic platform (robot car) via a Bluetooth module connected to an Arduino Uno board.",https://ieeexplore.ieee.org/document/9481012/,2021 23rd International Conference on Control Systems and Computer Science (CSCS),26-28 May 2021,ieeexplore
10.1109/ICRA.2019.8793510,Bonnet: An Open-Source Training and Deployment Framework for Semantic Segmentation in Robotics using CNNs,IEEE,Conferences,"The ability to interpret a scene is an important capability for a robot that is supposed to interact with its environment. The knowledge of what is in front of the robot is, for example, relevant for navigation, manipulation, or planning. Semantic segmentation labels each pixel of an image with a class label and thus provides a detailed semantic annotation of the surroundings to the robot. Convolutional neural networks (CNNs) are popular methods for addressing this type of problem. The available software for training and the integration of CNNs for real robots, however, is quite fragmented and often difficult to use for non-experts, despite the availability of several high-quality open-source frameworks for neural network implementation and training. In this paper, we propose a tool called Bonnet, which addresses this fragmentation problem by building a higher abstraction that is specific for the semantic segmentation task. It provides a modular approach to simplify the training of a semantic segmentation CNN independently of the used dataset and the intended task. Furthermore, we also address the deployment on a real robotic platform. Thus, we do not propose a new CNN approach in this paper. Instead, we provide a stable and easy-to-use tool to make this technology more approachable in the context of autonomous systems. In this sense, we aim at closing a gap between computer vision research and its use in robotics research. We provide an open-source codebase for training and deployment. The training interface is implemented in Python using TensorFlow and the deployment interface provides C++ library that can be easily integrated in an existing robotics codebase, a ROS node, and two standalone applications for label prediction in images and videos.",https://ieeexplore.ieee.org/document/8793510/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/CASE49439.2021.9551562,Building Skill Learning Systems for Robotics,IEEE,Conferences,"Skill-generating policies have enabled robots to perform a wide range of applications as for example assembly tasks. However, the manual engineering effort for such policies is fairly high and the environment is frequently required to be rather deterministic. For expanding robot deployment to low-volume manufacturing two challenges need to be addressed. First, the robot should acquire the skill-generating policy not from a robot programmer but rather from an expert on the task and second, the robot needs to be able to operate in unstructured environments. In this paper we present a learning approach that combines imitation learning and reinforcement learning to provide a tool for intuitive task teaching followed by self-optimization of the system. The presented approach is applied to a dual-arm assembly task using a real robot and appropriate simulation models. Whereas pure imitation learning does not result in an acceptable success rate for the considered example, after 400 episodes of reinforcement learning the robot can successfully solve the assembly task.",https://ieeexplore.ieee.org/document/9551562/,2021 IEEE 17th International Conference on Automation Science and Engineering (CASE),23-27 Aug. 2021,ieeexplore
10.1109/ROBOT.1993.292250,Cellular robotics: simulation and HW implementation,IEEE,Conferences,"Aspects of self-organization are presented in this paper. Computer simulations as well as a real prototypical implementation are used to illustrate the proposed approach. Results of simulations are presented to compare different strategies of self-organization enabling a system of autonomous robots to form a chain between two landmarks in a completely unknown environment. This chain implicitly represents a path between any two points of the environment without an explicit representation of free space (no single robot has a global map of the environment). The experimental part, even if restricted to a few robots, demonstrates that the set of stimuli-action processes used in the simulations are indeed feasible on real systems.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/292250/,[1993] Proceedings IEEE International Conference on Robotics and Automation,2-6 May 1993,ieeexplore
10.1109/IROS.2001.977213,Computation principles for the development of visual skills in robotics,IEEE,Conferences,"Different working principles are often considered when different visual behaviors are implemented in an agent. This occurs basically because the physical interaction between the behavior and the environment is not studied in depth. The paper shows how apparently different visual behaviors share common theoretical principles for their working mechanism. In particular properties related to the navigation vector field they compute in the environment, provide a base to explain visual learning, guidance, topological navigation, sub goal placement, obstacle avoidance and navigation enhancement. To handle the mathematics of a vector field robust tools are needed. Techniques borrowed from computer vision literature provide the necessary mathematical tools. All behaviors described have been tested in real robots. On going research is still in progress for topological navigation and subgoal placement.",https://ieeexplore.ieee.org/document/977213/,Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180),29 Oct.-3 Nov. 2001,ieeexplore
10.1109/IJCNN48605.2020.9206931,Developmental Learning of Value Functions in a Motivational System for Cognitive Robotics,IEEE,Conferences,"Motivation is quite an important topic when addressing continual open-ended learning processes in autonomous robots. The three main issues that need to be considered are, firstly, how does a designer define what the robot strives for in a manner that is independent from any particular domain it may find itself in. Secondly, once that robot is in a domain, how does it go about finding and relating goals in that particular domain on its own. Finally, the third issue is, once a goal is found, how does a robot establish a representation, usually in the form of a Value Function, that will allow it to exploit that goal. This paper deals with the third issue in the framework of the motivational engine we have designed for cognitive architectures. It addresses the problem of efficiently and appropriately learning complex Value Functions starting from intrinsically motivated traces of valuated robot actions that are often ambiguous and multivalued. To this end, a developmental learning mechanism is proposed that relies on the concurrent application of a real time ANN learning procedure over the traces of the valuated robot actions, and a simpler sensor correlation-based approach to allow for the production of better configured data traces for the learning process. The mechanism is analyzed and discussed over an experiment considering a real Baxter robot.",https://ieeexplore.ieee.org/document/9206931/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/MWSCAS.2018.8624056,EMG-based hand gesture control system for robotics,IEEE,Conferences,"In this paper, a Electromyogram (EMG) based hand gesture control system is developed. A wearable human machine interface (HMI) device is designed for an in-home assistance service robot. An EMG-based control system utilizes MyoWave muscle sensor to acquire and amplify EMG signal. A microcontroller system is used to an artificial neural network (ANN) to classify the EMG signal. Based on different hand movements, commands are sent through WiFi to control the motor in a service robot. The on-board Camera system mounted the robot can capture video real-time. In addition, a web server is implemented to provide live video feedback for robot navigation and user instructions.",https://ieeexplore.ieee.org/document/8624056/,2018 IEEE 61st International Midwest Symposium on Circuits and Systems (MWSCAS),5-8 Aug. 2018,ieeexplore
10.1109/IJCNN.2019.8852425,Exploring Deep Models for Comprehension of Deictic Gesture-Word Combinations in Cognitive Robotics,IEEE,Conferences,"In the early stages of infant development, gestures and speech are integrated during language acquisition. Such a natural combination is therefore a desirable, yet challenging, goal for fluid human-robot interaction. To achieve this, we propose a multimodal deep learning architecture, for comprehension of complementary gesture-word combinations, implemented on an iCub humanoid robot. This enables human-assisted language learning, with interactions like pointing at a cup and labelling it with a vocal utterance. We evaluate various depths of the Mask Regional Convolutional Neural Network (for object and wrist detection) and the Residual Network (for gesture classification). Validation is carried out with two deictic gestures across ten real-world objects on frames recorded directly from the iCub's cameras. Results further strengthen the potential of gesture-word combinations for robot language acquisition.",https://ieeexplore.ieee.org/document/8852425/,2019 International Joint Conference on Neural Networks (IJCNN),14-19 July 2019,ieeexplore
10.1109/ICRA.2019.8793593,"Fast Instance and Semantic Segmentation Exploiting Local Connectivity, Metric Learning, and One-Shot Detection for Robotics",IEEE,Conferences,"Semantic scene understanding is important for autonomous robots that aim to navigate dynamic environments, manipulate objects, or interact with humans in a natural way. In this paper, we address the problem of jointly performing semantic segmentation as well as instance segmentation in an online fashion, so that autonomous robots can use this information on-the-go and without sacrificing accuracy. We achieve this by exploiting a local connectivity prior of objects in the real world and a multi-task convolutional neural network architecture. The network identifies the individual object instances and their classes without region proposals or pre-segmentation of the images into individual classes. We implemented and thoroughly evaluated our approach, and our experiments suggest that our method can be used to accurately segment instance masks of objects and identify their class in an online fashion.",https://ieeexplore.ieee.org/document/8793593/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ROBIO.2011.6181717,Human-like gradual multi-agent Q-learning using the concept of behavior-based robotics for autonomous exploration,IEEE,Conferences,"In the last few years, the field of mobile robotics has made lots of advancements. These advancements are due to the extensive application of mobile robots for autonomous exploration. Mobile robots are being popularly used for applications in space, underwater explorations, underground coal mines monitoring, inspection in chemical/toxic/ nuclear factories etc. But if these environments are unknown/unpredictable, conventional/ classical robotics may not serve the purpose. In such cases robot learning is the best option. Learning from the past experiences, is one such way for real time application of robots for completely unknown environments. Reinforcement learning is one of the best learning methods for robots using a constant system-environment interaction. Both single and multi-agent concepts are available for implementation of learning. The current research work describes a multi-agent based reinforcement learning using the concept of behaviour-based robotics for autonomous exploration of mobile robots. The concept has also been tested both in indoor and outdoor environments using real-time robots.",https://ieeexplore.ieee.org/document/6181717/,2011 IEEE International Conference on Robotics and Biomimetics,7-11 Dec. 2011,ieeexplore
10.1109/FIE.2006.322407,Incorporating an Affective Model to an Intelligent Tutor for Mobile Robotics,IEEE,Conferences,"Emotions have been identified as important players in motivation, and motivation is very important for learning. When a tutor recognizes the affective state of the student and responds accordingly, the tutor may be able to motivate students and improve the learning process. We propose a general affective behavior model which integrates information from the student's pedagogical state, affective state, and the tutorial situation, to decide the best tutorial action, considering the tutor preferences from a pedagogical and affective point of view. Our proposal is based on emotions models, personality theories and teachers' expertise. The affective model is implemented as a dynamic decision network, with utility measures on both learning and motivation, and is being incorporated to an intelligent tutor within a virtual laboratory for learning mobile robotics. This paper presents preliminary results in the construction of the affective behavior model",https://ieeexplore.ieee.org/document/4116913/,Proceedings. Frontiers in Education. 36th Annual Conference,27-31 Oct. 2006,ieeexplore
10.1109/IROS45743.2020.9341370,KOVIS: Keypoint-based Visual Servoing with Zero-Shot Sim-to-Real Transfer for Robotics Manipulation,IEEE,Conferences,"We present KOVIS, a novel learning-based, calibration-free visual servoing method for fine robotic manipulation tasks with eye-in-hand stereo camera system. We train the deep neural network only in the simulated environment; and the trained model could be directly used for real-world visual servoing tasks. KOVIS consists of two networks. The first keypoint network learns the keypoint representation from the image using with an autoencoder. Then the visual servoing network learns the motion based on keypoints extracted from the camera image. The two networks are trained end-to-end in the simulated environment by self-supervised learning without manual data labeling. After training with data augmentation, domain randomization, and adversarial examples, we are able to achieve zero-shot sim-to-real transfer to real-world robotic manipulation tasks. We demonstrate the effectiveness of the proposed method in both simulated environment and real-world experiment with different robotic manipulation tasks, including grasping, peg-in-hole insertion with 4mm clearance, and M13 screw insertion. The demo video is available at: http://youtube/gfBJBR2tDzA.",https://ieeexplore.ieee.org/document/9341370/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ISIE.2007.4374932,Learning Wall Following Behaviour in Robotics through Reinforcement and Image-based States,IEEE,Conferences,"In this work, a visual and reactive wall following behaviour is learned by reinforcement. With artificial vision the environment is perceived in 3D, and it is possible to avoid obstacles that are invisible to other sensors that are more common in mobile robotics. Reinforcement learning reduces the need for intervention in behaviour design, and simplifies its adjustment to the environment, the robot and the task. In order to facilitate its generalization to other behaviours and to reduce the role of the designer, we propose a regular image-based codification of states. Even though this is much more difficult, our implementation converges and is robust. Results are presented with a Pioneer 2 AT. Learning phase has been realized on the Gazebo 3D simulator and the test phase has been proved in simulated and real environments to demonstrate the correct design and robustness of our algorithms.",https://ieeexplore.ieee.org/document/4374932/,2007 IEEE International Symposium on Industrial Electronics,4-7 June 2007,ieeexplore
10.1109/ROBIO.2018.8665318,Manipulation Related EEG Brainwave Feature Extraction and Events Recognition for Robotics Learning Applications,IEEE,Conferences,"This research is directed to the application of pattern recognition techniques (PCA), for understanding waves patterns resulting from brain Electroencephalography (EEG). The EEG brainwaves are resulting from specific human hand fingers movements, for a defined task. The adopted technique involved four main computational stages. First, EEG dataset collection for a defined grasping task, Luciw et. al. [1]. Secondly, it was a filtration and multi-signals signals conditioning of such multi-dimensional EEG wave sets. Thirdly, dimensionality reduction of the EEG patterns, hence capturing main EEG waves features. Finally, last stage involved using of pattern recognition and classification algorithms for classification of diverse grasping events. Events classification was based on analysis of set of EEG related patterns, then to correlate such patterns with real word experiment fingers movements. The adopted technique is useful in terms of understanding EEG related and hidden patterns, that are useful for a number of robotics direct or indirect learning applications.",https://ieeexplore.ieee.org/document/8665318/,2018 IEEE International Conference on Robotics and Biomimetics (ROBIO),12-15 Dec. 2018,ieeexplore
10.1109/VRAIS.1995.512486,Model based vision as feedback for virtual reality robotics environments,IEEE,Conferences,"Task definition methods for robotic systems are often difficult to use. The ""on-line"" programming methods are often time expensive or risky for the human operator or the robot itself. On the other hand, ""off-line"" techniques are tedious and complex. In addition operator training is costly and time consuming. In a Virtual Reality Robotics Environment (VRRE), users are not asked to write down complicated functions, but can operate complex robotic systems in an intuitive and cost-effective way. However a VRRE is only effective if all the environment changes and object movements are fed-back to the virtual manipulating system. The paper describes the use of a VRRE for a semi-autonomous robot system comprising an industrial 5-axis robot, its virtual equivalent and a model based vision system used as feed-back. The user is immersed in a 3-D space built out of models of the robot's environment. He directly interacts with the virtual ""components"", defining tasks and dynamically optimizing them. A model based vision system locates objects in the real workspace to update the VRRE through a bi-directional communication link. In order to enhance the capabilities of the VRRE, a reflex-type behavior based on vision has been implemented. By locally (independently of the VRRE) controlling the real robot, the operator is discharged of small environmental changes due to transmission delays. Thus once the tasks have been optimized on the VRRE, they are sent to the real robot and a semi autonomous process ensures their correct execution thanks to a camera directly mounted on the robot's end effector. On the other hand if the environmental changes are too important, the robot stops, re-actualizes the VRRE with the new environmental configuration, and waits for task redesign. Because the operator interacts with the robotic system at a task oriented high level, VRRE systems are easily portable to other robotics environments (mobile robotics and micro assembly).",https://ieeexplore.ieee.org/document/512486/,Proceedings Virtual Reality Annual International Symposium '95,11-15 March 1995,ieeexplore
10.1109/SECON.2014.6950737,Modified reinforcement learning for sequential action behaviors and its application to robotics,IEEE,Conferences,"When developing a robot or other automaton, the efficacy of the agent is highly dependent on the performance of the behaviors which underpin the control system. Especially in the case of agents which must act in real world or disorganized environments, the design of robust behaviors can be both difficult and time consuming, and often requires the use of sensitive tuning. In response to this need, we present a behavioral, goal-oriented, reinforcement-based machine learning strategy which is flexible, simple to implement, and designed for application in real-world environments, but with the capability of software-based training. In this paper, we will explain our design paradigms, the formal implementation thereof, and the algorithm proper. We will show that the algorithm is able to emulate standard reinforcement learning within comparable training time, and to extend the capabilities thereof as well. We also demonstrate extension of learning beyond the scope of training examples, and present an example of a physical robot which learns a sequential action behavior by experimentation.",https://ieeexplore.ieee.org/document/6950737/,IEEE SOUTHEASTCON 2014,13-16 March 2014,ieeexplore
10.1109/ITNG.2011.116,Nerve: A Lightweight Middleware for Quality-of-service Networked Robotics,IEEE,Conferences,"Social robots must adapt to dynamic environments, human interaction partners and challenging new stringent tasks. Their inner software should be designed and deployed carefully because slight changes in the robot's requirements can have an important impact in the existing code. This paper focus on the design and implementation of a lightweight middleware for networked robotics called \textit{Nerve}, which guarantees the scalability and quality-of-service requirements for this kind of real-time software. Its benefits have been proved through its use in a Robot Learning by Imitation control architecture, but its design guidelines are general enough to be also applied with common distributed and real-time embedded applications.",https://ieeexplore.ieee.org/document/5945314/,2011 Eighth International Conference on Information Technology: New Generations,11-13 April 2011,ieeexplore
10.1109/CIRA.2005.1554245,Plenary talk June 29; The 3<sup>rd</sup>Generation of Robotics: Ubiquitous Robot,IEEE,Conferences,"This talk shows its possibility of implementation in real life through demonstrations using a Sobot, Rity: i) continuous interface between physical and virtual worlds ii) seamless transmission of Sobot between a PC and a Mobot, and iii) omnipresence of Sobot. Rity, developed at the Robot Intelligence Technology (RIT) Laboratory, KAIST, is a Sobot implemented as a 12 DOF artificial creature in the virtual 3D world created in a PC. It has virtual sensors to survive in the virtual world and physical sensors attached to the PC to interact with the real world. Based on sensor information it can express its emotion, and interact with human beings through a web camera in the real world. It can generate behaviors autonomously and has its own IP. This means that it can be accessed through a network at anywhere and anytime using any device. With this technique omnipresence of Sobot can be realized in a ubiquitous space. The eventual goal of this research is to integrate Sobot, Embot, and Mobot to build up a Ubibot so that ubiquitous services through it can be available in a ubiquitous era",https://ieeexplore.ieee.org/document/1554245/,2005 International Symposium on Computational Intelligence in Robotics and Automation,27-30 June 2005,ieeexplore
10.1109/ACIIW.2019.8925192,Real-time pain detection in facial expressions for health robotics,IEEE,Conferences,"Automatic pain detection is an important challenge in health computing. In this paper we report on our efforts to develop a real-time, real-world pain detection system from human facial expressions. Although many studies addressed this challenge, most of them use the same dataset for training and testing. There is no cross-check with other datasets or implementation in real-time to check performance on new data. This is problematic, as evidenced in this paper, because the classifiers overtrain on dataset-specific features. This limits realtime, real-world usage. In this paper, we investigate different methods of real-time pain detection. The training data uses a combination of pain and emotion datasets, unlike other papers. The best model shows an accuracy of 88.4% on a dataset including pain and 7 non-pain emotional expressions. Results suggest that convolutional neural networks (CNN) are not the best methods in some cases as they easily overtrain if the dataset is biased. Finally we implemented our pain detection method on a humanoid robot for physiotherapy. Our work highlights the importance of cross-corpus evaluation &amp; real-time testing, as well as the need for a well balanced and ecologically valid pain dataset.",https://ieeexplore.ieee.org/document/8925192/,2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW),3-6 Sept. 2019,ieeexplore
10.1109/ICIS.2017.7959982,Robotics data real-time management based on NoSQL solution,IEEE,Conferences,"In nowadays, robotics database management systems are increasing. These systems ensure good storage of data and with big data analytic, a new approach demands new structures and methods for collecting, recording, and analyzing enterprise data. This paper work deals with the NoSQL databases which are the secret of the continual progression data that new data management solutions have been emerged. They crossed several areas as personalization, profile management, big data in real-time, content management, catalogue, view of customers, mobile applications, internet of things, digital communication and fraud detection. Machine learning, for example, thrives on more data, so smart machines can learn more and faster, the Robotics are our use of case to focus on our Test. The implementation of NoSQL for Robotics wrestle all the data they acquire into usable form because with the ordinary type of Robotics we are facing very big limits to manage and find the exact information in real-time. Our original proposed approach was demonstrated by experimental studies and running example used as a use case.",https://ieeexplore.ieee.org/document/7959982/,2017 IEEE/ACIS 16th International Conference on Computer and Information Science (ICIS),24-26 May 2017,ieeexplore
10.1109/ICCVW.2017.84,SkiMap++: Real-Time Mapping and Object Recognition for Robotics,IEEE,Conferences,"We introduce SkiMap++, an extension to the recently proposed SkiMap mapping framework for robot navigation [1]. The extension deals with enriching the map with semantic information concerning the presence in the environment of certain objects that may be usefully recognized by the robot, e.g. for the sake of grasping them. More precisely, the map can accommodate information about the spatial locations of certain 3D object features, as determined by matching the visual features extracted from the incoming frames through a random forest learned off-line from a set of object models. Thereby, evidence about the presence of object features is gathered from multiple vantage points alongside with the standard geometric mapping task, so to enable recognizing the objects and estimating their 6 DOF poses. As a result, SkiMap++ can reconstruct the geometry of large scale environments as well as localize some relevant objects therein (Fig.1) in real-time on CPU. As an additional contribution, we present an RGB-D dataset featuring ground-truth camera and object poses, which may be deployed by researchers interested in pursuing SLAM alongside with object recognition, a topic often referred to as Semantic SLAM<sup>1</sup>.",https://ieeexplore.ieee.org/document/8265293/,2017 IEEE International Conference on Computer Vision Workshops (ICCVW),22-29 Oct. 2017,ieeexplore
10.1109/EMSOFT.2018.8537236,Special Session: Embedded Software for Robotics: Challenges and Future Directions,IEEE,Conferences,"This paper surveys recent challenges and solutions in the design, implementation, and verification of embedded software for robotics. Emphasis is placed on mobile robots, like self-driving cars. In design, it addresses programming support for robotic systems, secure state estimation, and ROS-based monitor generation. In the implementation phase, it describes the synthesis of control software using finite precision arithmetic, real-time platforms and architectures for safety-critical robotics, efficient implementation of neural network based-controllers, and standards for computer vision applications. The issues in verification include verification of neural network-based robotic controllers, and falsification of closed-loop control systems. The paper also describes notable open-source robotic platforms. Along the way, we highlight important research problems for developing the next generation of high-performance, low-resource-usage, correct embedded software.",https://ieeexplore.ieee.org/document/8537236/,2018 International Conference on Embedded Software (EMSOFT),30 Sept.-5 Oct. 2018,ieeexplore
10.1109/CSCI46756.2018.00293,"Timing and its Implementation in a Language, Communication, and Systems Integration SDK and Platform for Intelligent Entities and Robotics",IEEE,Conferences,"A framework to integrate different artificial intelligence and machine learning algorithms is combined with an execution framework to create a powerful cloud computing system development platform. By providing an execution framework and control software that is native to cloud architectures and supports interactivity and time synchronization, the true utility of cloud computing and Big Data systems can be increased. Many Big Data software systems are not interactive, automated, or able to run in real-time. An integration example is provided.",https://ieeexplore.ieee.org/document/8947742/,2018 International Conference on Computational Science and Computational Intelligence (CSCI),12-14 Dec. 2018,ieeexplore
10.1109/IROS.2018.8593799,Utility Model Re-description within a Motivational System for Cognitive Robotics,IEEE,Conferences,"This paper describes a re-descriptive approach to the efficient acquisition of ever higher level and more precise utility models within the motivational system (MotivEn) of a cognitive architecture. The approach is based on a two-step process whereby, as a first step, simple imprecise sensor correlation related utility models are obtained from the interaction traces of the robot. These utility models allow the robot to increase the frequency of achieving goals, and thus, provide lots of traces that can be used to try to train precise value functions implemented as artificial neural networks. The approach is tested experimentally on a real robotic setup that involves the coordination of two robots.",https://ieeexplore.ieee.org/document/8593799/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ACCESS.2020.3007064,Drive Through Robotics: Robotic Automation for Last Mile Distribution of Food and Essentials During Pandemics,IEEE,Journals,"The COVID-19 pandemic unraveled the weak points in the global supply chain for goods. Specifically, people all over the world, including those in the most advanced nations have had to go without medical supplies and personal protective equipment. Scarcity of essentials increases anxiety and uncertainty exacerbating unproductive behaviors like hoarding and price gouging. Left to market forces, such unfair practices are likely to aggravate hardships and increase the loss of lives. Thus, there is a critical need to ensure safe distribution of food and essential supplies to all citizens to sustain them through challenging times. To this end, we propose a simple, affordable and contact-less robotic system for preparing and dispensing food and survival-kits at community scale. The system has provisions to prevent hoarding and price gouging. Design, simulation, and, validation of the system has been completed to ensure readiness for real world implementation. This project is part of an open-source program and detailed designs are available upon request to entities interested in using it to serve their communities.",https://ieeexplore.ieee.org/document/9133423/,IEEE Access,2020,ieeexplore
10.1109/ACCESS.2019.2938366,Grasping Objects From the Floor in Assistive Robotics: Real World Implications and Lessons Learned,IEEE,Journals,"This paper presents a system enabling a mobile robot to autonomously pick-up objects a human is pointing at from the floor. The system does not require object models and is designed to grasp unknown objects. The robot decides by itself if an object is suitable for grasping by considering measures of size, position and the environment suitability. The implementation is built on the second prototype of the home care robot Hobbit, thereby verifying that complex robotic manipulation tasks can be performed with economical hardware. The presented system was already tested in real apartments with elderly people. We highlight this by discussing the additional complexity for complete autonomous behavior in apartments compared with tests in labs.",https://ieeexplore.ieee.org/document/8819885/,IEEE Access,2019,ieeexplore
10.1109/ACCESS.2018.2873597,Hierarchical Semantic Mapping Using Convolutional Neural Networks for Intelligent Service Robotics,IEEE,Journals,"The introduction of service robots in the public domain has introduced a paradigm shift in how robots are interacting with people, where robots must learn to autonomously interact with the untrained public instead of being directed by trained personnel. As an example, a hospital service robot is told to deliver medicine to Patient Two in Ward Three. Without awareness of what “Patient Two” or “Ward Three” is, a service robot must systematically explore the environment to perform this task, which requires a long time. The implementation of a Semantic Map allows for robots to perceive the environment similar to people by associating semantic information with spatial information found in geometric maps. Currently, many semantic mapping works provide insufficient or incorrect semantic-metric information to allow a service robot to function dynamically in human-centric environments. This paper proposes a semantic map with a hierarchical semantic organization structure based on a hybrid metric-topological map leveraging convolutional neural networks and spatial room segmentation methods. Our results are validated using multiple simulated and real environments on our lab's custom developed mobile service robot and demonstrate an application of semantic maps by providing only vocal commands. We show that this proposed method provides better capabilities in terms of semantic map labeling and retain multiple levels of semantic information.",https://ieeexplore.ieee.org/document/8490234/,IEEE Access,2018,ieeexplore
10.1109/JPROC.2018.2856739,Navigating the Landscape for Real-Time Localization and Mapping for Robotics and Virtual and Augmented Reality,IEEE,Journals,"Visual understanding of 3-D environments in real time, at low power, is a huge computational challenge. Often referred to as simultaneous localization and mapping (SLAM), it is central to applications spanning domestic and industrial robotics, autonomous vehicles, and virtual and augmented reality. This paper describes the results of a major research effort to assemble the algorithms, architectures, tools, and systems software needed to enable delivery of SLAM, by supporting applications specialists in selecting and configuring the appropriate algorithm and the appropriate hardware, and compilation pathway, to meet their performance, accuracy, and energy consumption goals. The major contributions we present are: 1) tools and methodology for systematic quantitative evaluation of SLAM algorithms; 2) automated, machine-learning-guided exploration of the algorithmic and implementation design space with respect to multiple objectives; 3) end-to-end simulation tools to enable optimization of heterogeneous, accelerated architectures for the specific algorithmic requirements of the various SLAM algorithmic approaches; and 4) tools for delivering, where appropriate, accelerated, adaptive SLAM solutions in a managed, JIT-compiled, adaptive runtime context.",https://ieeexplore.ieee.org/document/8436423/,Proceedings of the IEEE,Nov. 2018,ieeexplore
10.1109/TETC.2017.2769705,Robust Robot Tracking for Next-Generation Collaborative Robotics-Based Gaming Environments,IEEE,Journals,"The collaboration between humans and robots is one of the most disruptive and challenging research areas. Even considering advances in design and artificial intelligence, humans and robots could soon ally to perform together a number of different tasks. Robots could also became new playmates. In fact, an emerging trend is associated with the so-called phygital gaming, which builds upon the idea of merging the physical world with a virtual one in order to let physical and virtual entities, such as players, robots, animated characters and other game objects interact seamlessly as if they were all part of the same reality. This paper specifically focuses on mixed reality gaming environments that can be created by using floor projection, and tackles the issue of enabling accurate and robust tracking of off-the-shelf robots endowed with limited sensing capabilities. The proposed solution is implemented by fusing visual tracking data gathered via a fixed camera in a smart environment with odometry data obtained from robot's on-board sensors. The solution has been tested within a phygital gaming platform in a real usage scenario, by experimenting with a robotic game that exhibits many challenging situations which would be hard to manage using conventional tracking techniques.",https://ieeexplore.ieee.org/document/8094867/,IEEE Transactions on Emerging Topics in Computing,1 July-Sept. 2020,ieeexplore
10.1109/TE.2012.2224867,SyRoTek—Distance Teaching of Mobile Robotics,IEEE,Journals,"E-learning is a modern and effective approach for training in various areas and at different levels of education. This paper gives an overview of SyRoTek, an e-learning platform for mobile robotics, artificial intelligence, control engineering, and related domains. SyRoTek provides remote access to a set of fully autonomous mobile robots placed in a restricted area with dynamically reconfigurable obstacles, which enables solving a huge variety of problems. A user is able to control the robots in real time by their own developed algorithms as well as being able to analyze gathered data and observe activity of the robots by provided interfaces. The system is currently used for education at the Czech Technical University in Prague, Prague, Czech Republic, and at the University of Buenos Aires, Buenos, Aires, Argentina, and it is freely accessible to other institutions. In addition to the system overview, this paper presents the experience gained from the actual deployment of the system in teaching activities.",https://ieeexplore.ieee.org/document/6341862/,IEEE Transactions on Education,Feb. 2013,ieeexplore
10.1109/IROS.1992.601935,"""Arnie P."" - A Robot Golfing System Using Binocular And A Heuristic Feedback Mechanism",IEEE,Conferences,"This paper describes a robot vision golfing system. The Automated Robotic Navigational unit with Intelligent Eye and Putter (ARNIE P)<sup>τ</sup>project was initiated to investigate the problems and develop software solutions for robotic tasks that require good hand-eye coordination and an intelligent sensor feedback mechanism. This system has only one frame buffer and no specialized hardware, so quasi-real time 3D tracking is accomplished in software using the Unix Spline facility. The single frame buffer and digitizer, stores and retains the location of the ball from two separate cameras during the time interval between the golf ball initially crossing a trigger scan line and the ball coming to a complete stop. The most novel aspect of this study is that by attempting to build or model a difficult perceptory task such as golf, which requires integrating many complicated computational pieces (binocular stereo vision, robot arm motion, heuristic feedback, learning), it appears to be a good plarform to experiment with artificial intelligence techniques and robotics.",https://ieeexplore.ieee.org/document/601935/,Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems,7-10 July 1992,ieeexplore
10.1109/AIMS52415.2021.9466061,3D Control System of Arm Robot Prototype for Skin Cancer Detection,IEEE,Conferences,"Arm robot has a lack of control systems that depend on desired control for assistive medical. Our laboratory robotics &amp; artificial intelligent at Padjadjaran University created skin cancer detection of arm robot with dark flow framework to identify skin cancer in real-time. The implementation of the arm robot was for increasing the accuracy, precision, and stability. The main purpose of this paper was to control an arm robot for skin cancer detection that is capable to scan the whole body skin to localize the skin cancers by driving the manipulator in circular or elliptical skimming. To initiate the communication with the arm robot which used Dynamixel as the actuators, we applied USB2Dynamixel as the communicator. SMPS2Dynamixel was used to supply the power into servo motors. 3D Control system software has designed, and it had some features such as; forward kinematic movement, inverse kinematic movement, and 3D simulation to help user visualize the position of the arm robot. Control software was built in MATLAB GUI environment and 3D simulation adapted Peter Corke Robotics Toolbox.",https://ieeexplore.ieee.org/document/9466061/,2021 International Conference on Artificial Intelligence and Mechatronics Systems (AIMS),28-30 April 2021,ieeexplore
10.1109/3DV50981.2020.00038,3D-Aware Ellipse Prediction for Object-Based Camera Pose Estimation,IEEE,Conferences,"In this paper, we propose a method for coarse camera pose computation which is robust to viewing conditions and does not require a detailed model of the scene. This method meets the growing need of easy deployment of robotics or augmented reality applications in any environments, especially those for which no accurate 3D model nor huge amount of ground truth data are available. It exploits the ability of deep learning techniques to reliably detect objects regardless of viewing conditions. Previous works have also shown that abstracting the geometry of a scene of objects by an ellipsoid cloud allows to compute the camera pose accurately enough for various application needs. Though promising, these approaches use the ellipses fitted to the detection bounding boxes as an approximation of the imaged objects. In this paper, we go one step further and propose a learning-based method which detects improved elliptic approximations of objects which are coherent with the 3D ellipsoid in terms of perspective projection. Experiments prove that the accuracy of the computed pose significantly increases thanks to our method and is more robust to the variability of the boundaries of the detection boxes. This is achieved with very little effort in terms of training data acquisition - a few hundred calibrated images of which only three need manual object annotation.",https://ieeexplore.ieee.org/document/9320405/,2020 International Conference on 3D Vision (3DV),25-28 Nov. 2020,ieeexplore
10.1109/AIVR.2018.00028,A Benchmark of Four Methods for Generating 360° Saliency Maps from Eye Tracking Data,IEEE,Conferences,"Modeling and visualization of user attention in Virtual Reality is important for many applications, such as gaze prediction, robotics, retargeting, video compression, and rendering. Several methods have been proposed to model eye tracking data as saliency maps. We benchmark the performance of four such methods for 360° images. We provide a comprehensive analysis and implementations of these methods to assist researchers and practitioners. Finally, we make recommendations based on our benchmark analyses and the ease of implementation.",https://ieeexplore.ieee.org/document/8613647/,2018 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),10-12 Dec. 2018,ieeexplore
10.1109/ACCC51160.2020.9347897,A Comparative Analysis of Kinematics of Industrial Robot KUKA KR 60–3 Using Scientific Computing Languages,IEEE,Conferences,"In the field of robotics, there are kinematic analysis methods that are responsible for describing the positions and orientations of the end effectors, as well as the angles, velocities and trajectories of industrial robots; such techniques are: forward kinematics, inverse kinematics and velocity kinematics. For the solutions of these complex mathematical calculations, the use of scientific computing languages or programs is required; which more and more algorithms, libraries and complements are implemented, that achieve a reduction in programming hours and result in the creation of better solutions in areas of all kinds. For this reason, the kinematics of the Industrial Robot KUKA KR 60-3 was programmed in the languages and programs most used in scientific computing, with the aim of comparing the performance (real time) when carrying out symbolic and numerical analysis in said studies.",https://ieeexplore.ieee.org/document/9347897/,2020 Asia Conference on Computers and Communications (ACCC),18-20 Sept. 2020,ieeexplore
10.1109/KSE.2018.8573394,A Comparative Study on Detection and Estimation of a 3-D Object Model in a Complex Scene,IEEE,Conferences,"In this paper, we tackle the approaches to detect and estimate 3-D object model in a complex scene. Although it is fundamental research in the computer vision and robotics community, this task still has many challenges especially when the scene is complex with contaminated or occluded data. To do this, we compare three common approaches including two conventional ways (e.g., geometrical and appearance-based techniques) and the proposed scheme. While geometrical approaches tend to directly detect and estimate objects without any learning procedure, the appearance-based required a training process to model the interested object. We show that a combination of recent advantages of deep learning (e.g., RCNN, Yolo) could resolve the detection task, while the geometrical based approaches estimate full 3-D model. The evaluation utilizes two different dataset. One from a public available, second one is our self-prepared dataset. Difference scenarios are considered in the evaluation. The results confirmed that the proposed technique achieves the best performances. As a consequence, it suggests to deploy real application supporting visually impaired people in detecting and grasping common objects in their activities of daily living.",https://ieeexplore.ieee.org/document/8573394/,2018 10th International Conference on Knowledge and Systems Engineering (KSE),1-3 Nov. 2018,ieeexplore
10.1109/ICRA.2019.8793690,A Fog Robotics Approach to Deep Robot Learning: Application to Object Recognition and Grasp Planning in Surface Decluttering,IEEE,Conferences,"The growing demand of industrial, automotive and service robots presents a challenge to the centralized Cloud Robotics model in terms of privacy, security, latency, bandwidth, and reliability. In this paper, we present a `Fog Robotics' approach to deep robot learning that distributes compute, storage and networking resources between the Cloud and the Edge in a federated manner. Deep models are trained on non-private (public) synthetic images in the Cloud; the models are adapted to the private real images of the environment at the Edge within a trusted network and subsequently, deployed as a service for low-latency and secure inference/prediction for other robots in the network. We apply this approach to surface decluttering, where a mobile robot picks and sorts objects from a cluttered floor by learning a deep object recognition and a grasp planning model. Experiments suggest that Fog Robotics can improve performance by sim-to-real domain adaptation in comparison to exclusively using Cloud or Edge resources, while reducing the inference cycle time by 4× to successfully declutter 86% of objects over 213 attempts.",https://ieeexplore.ieee.org/document/8793690/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ICST46873.2019.9047714,A Fundamental Experiment on Contact Position Estimation on Vision based Dome-type Soft Tactile Sensor using Ready-made Medium,IEEE,Conferences,"Tactile sensors are critical components in robotics fields. Recently, soft tactile sensor utilizing vision is actively developed for safe human machine interaction. Some researches use novel custom-made medium in order to achieve tactile sensing. Deep learning can recognize pattern from any vision data when it has sufficient dataset, i.e., the system does not require specific pattern embedded hardware for the pattern recognition. To achieve soft tactile sensor's economical application for robot fingers, this paper presents a fundamental experiment on contract position estimation on vision based dome-type soft tactile sensor utilizing ready-made silicon as a medium and convolutional neural network. In order to estimate and classify the contact position, convolutional neural network (CNN) was applied. The modified VGGNet architecture was coded using Tensorflow and Keras. 1000 images were taken to train the modified VGG network; 200 images were taken for each neutral, left, right, lower, upper direction. For each direction, fingertip, pencil, ruler, and table corner were utilized to capture various situations. After checking the results of the test set, the trained model was applied to the embedded board and checked the contact position estimation in real-time. The experiment showed high accuracy on classifying the con-tact position of the vision based dome-type soft tactile sensor in real time. This contact position estimation system will be critical for the finger-typed robots since the system is reasonably small and it will reduce significant amount of manufacturing cost for the safe human machine interaction system. For the future work, we will acquire more image data and apply more advanced network architecture to improve accuracy.",https://ieeexplore.ieee.org/document/9047714/,2019 13th International Conference on Sensing Technology (ICST),2-4 Dec. 2019,ieeexplore
10.1109/IJCNN52387.2021.9534180,A Lightweight sequence-based Unsupervised Loop Closure Detection,IEEE,Conferences,"Stable, effective and lightweight loop closure detection is an always pursued goal in real-time SLAM systems, that can be ported on embedded processors and deployed on autonomous robotics. Deep learning methods have extended the expressive ability and adaptability of the descriptor, and sequence-based methods can greatly improve the matching accuracy. However, the increased computation complexity and storage bandwidth requirements of matching calculations for high-dimensional descriptor make it infeasible for real-time deployment, especially for robots that navigate in relatively big maps. To address this challenge, we propose a lightweight sequence-based unsupervised loop closure detection scheme. To be specific, Principal Component Analysis (PCA) is applied to squeeze the descriptor dimensions while maintaining sufficient expressive ability. Additionally, with the consideration of the image sequence and combining linear query with fast approximate nearest neighbor search to further reduce the execution time and improve the efficiency of sequence matching. We implement our method on CALC, a state-of-the-art unsupervised solution, and conduct experiments on NVIDIA TX2, results demonstrate that the accuracy has been improved by 5%, while the execution speed is 2× faster. Source code is available at https://github.com/Mingrui-Yu/Seq-CALC.",https://ieeexplore.ieee.org/document/9534180/,2021 International Joint Conference on Neural Networks (IJCNN),18-22 July 2021,ieeexplore
10.1109/UEMCON47517.2019.8993080,A Low-Cost Arm Robotic Platform based on Myoelectric Control for Rehabilitation Engineering,IEEE,Conferences,"Rehabilitation robotics is a recent kind of service robot that include devices such as robotic prosthesis and exoskeletons. These devices could help motor disabled people to rehabilitate their motor functions, and could provide functional compensation to accomplish motor activities. In order to control robotic prosthesis and exoskeletons it is required to identify human movement intention, to be converted into commands for the device. Motor impaired people may use surface electromyography (sEMG) signals to control these devices, taking into account that sEMG signals directly reflects the human motion intention. Myoelectric control is an advanced technique related with the detection, processing, classification, and application of sEMG signals to control human-assisting robots or rehabilitation devices. Despite recent advances with myoelectric control algorithms, currently there is still an important need to develop suitable methods involving usability, for controlling prosthesis and exoskeletons in a natural way. Traditionally, acquiring EMG signals and developing myoelectric control algorithms require expensive hardware. With the advent of low-cost technologies (i.e. sensors, actuators, controllers) and hardware support of simulation software packages as Matlab, affordable research tools could be used to develop novel myoelectric control algorithms. This work describes the implementation and validation of a Matlab-based robotic arm using low-cost technologies such as Arduino commanded using myoelectric control. The platform permits implementation of a variety of EMG-based algorithms. It was carried out a set of experiments aimed to evaluate the platform, through an application of pattern recognition based myoelectric control to identify and execute seven movements of the robotic upper limb: 1-forearm pronation; 2- forearm supination; 3-wrist flexion; 4-wrist extension; 5- elbow flexion; 6- elbow extension; 7-resting. The algorithm use a feature extraction stage based on a combination of time and frequency domain features (mean absolute value, waveform length, root mean square) and a widely used k-NN classifier. Obtained mean classification errors were 5.9%. As future work, additional features in the myoelectric control algorithm will be evaluated, for real-time applications.",https://ieeexplore.ieee.org/document/8993080/,"2019 IEEE 10th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)",10-12 Oct. 2019,ieeexplore
10.1109/ICRA48506.2021.9561941,A Robot Walks into a Bar: Automatic Robot Joke Success Assessment,IEEE,Conferences,"Effective social robots should leverage humor’s unique ability to improve relationship connections and dispel stress, but current robots possess limited (if any) humorous abilities. In this paper, we aim to supplement one aspect of autonomous robots by giving robotic systems the ability to ""read the room"" to assess how their humorous statements are received by nearby people in real time. Using a dataset of the audio of crowd responses to a robotic comedian over multiple performances (first presented in past work), we establish human-labeled joke success ground truths and compare individual human rater accuracy against the outputs of lightweight Machine Learning (ML) approaches that are easy to deploy in real-time joke assessment. Our results indicate that all three ML approaches (naïve Bayes, support vector machines, and single-hidden-layer feedforward neural networks) performed significantly better than the baseline approach used in our past work. In particular, support vector machines and neural network approaches are comparable to a human rater in the task of assessing if a joke failed or not in certain cases. The products of this work will inform self-assessment techniques for robots and help social robotics researchers test their own assessment methods on realistic data from human crowds.",https://ieeexplore.ieee.org/document/9561941/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/IROS.2018.8593714,A Software Framework for Planning Under Partial Observability,IEEE,Conferences,"Planning under partial observability is both challenging and critical for reliable robot operation. The past decade has seen substantial advances in this domain: The mathematically principled approach for addressing such problems, namely the Partially Observable Markov Decision Process (POMDP), has started to become practical for various robotics tasks. Good approximate solutions for problems framed as POMDPs can now be computed on-line, with a few classes of problems being solved in near real-time. However, applications of these more recent advances are often hindered by the lack of easy-to-use software tools. Implementation of state of the art algorithms exist, but most (if not all)require the POMDP model to be hard-coded inside the program, increasing the difficulty of applying them. To alleviate this problem, we propose a software toolkit, called On-line POMDP Planning Toolkit (OPPT)(downloadable from http://robotics.itee.uq.edu.au/~oppt). By providing a well-defined and general abstract solver API, OPPT enables the user to quickly implement new POMDP solvers. Furthermore, OPPT provides an easy-to-use plug-in architecture with interfaces to the high-fidelity simulator Gazebo that, in conjunction with user-friendly configuration files, allows users to specify POMDP models of a standard class of robot motion planning under partial observability problems with no additional coding effort.",https://ieeexplore.ieee.org/document/8593714/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ROBIO.2009.4913063,A bio-inspired haptic interface for tele-robotics applications,IEEE,Conferences,"This paper presents the design concept for a bio-inspired exoskeleton intended for applications in tele-robotics and virtual reality. We based the development on an attentive analysis of the human arm anatomy with the intent to synthesize a system that will be able to interface with the human limb in a natural way. Our main goal is to develop a multi contact-point haptic interface that does not restrict the arm mobility and therefore increases the operational workspace. We propose a simplified kinematic model of the human arm using a notation coming from the robotics field. To figure out the best kinematic architecture we employed real movement data, measured from a human subject, and integrated them with the kinematic model of the exoskeleton. This allows us to test the system before its construction and to formalize specific requirements. We also implemented and tested a first passive version of the shoulder joint.",https://ieeexplore.ieee.org/document/4913063/,2008 IEEE International Conference on Robotics and Biomimetics,22-25 Feb. 2009,ieeexplore
10.1109/ROBIO.2014.7090308,A chaotic neural network as motor path generator for mobile robotics,IEEE,Conferences,This work aims at developing a motor path generator for applications in mobile robotics based on a chaotic neural network. The computational paradigm inspired by the neural structure of microcircuits located in the human prefrontal cortex is adapted to work in real-time and used to generate the joints trajectories of a lightweight quadruped robot. The recurrent neural network was implemented in Matlab and a software framework was developed to test the performances of the system with the robot dynamic model. Preliminary results demonstrate the capability of the neural controller to learn period signals in a short period of time allowing adaptation during the robot operation.,https://ieeexplore.ieee.org/document/7090308/,2014 IEEE International Conference on Robotics and Biomimetics (ROBIO 2014),5-10 Dec. 2014,ieeexplore
10.1109/IJCNN.2010.5596771,A cognitive developmental robotics architecture for lifelong learning by evolution in real robots,IEEE,Conferences,"This paper is devoted to a detailed presentation of the current state of the Multilevel Darwinist Brain (MDB) cognitive architecture for lifelong learning in real robots. This architecture follows the cognitive developmental robotics approach and it is based on concepts like embodiment, open-ended lifelong learning, autonomous knowledge acquisition or adaptive behaviors and motivations. In addition, this version of the MDB architecture incorporates several improvements related with more practical issues, which are the result of the experience gained through several experiments with real robots in the last few years. The MDB uses evolutionary algorithms in the knowledge acquisition process, which implies the need of paying attention to the efficiency of the computational implementation. Here, we first describe the cognitive model on which the basic operation of the architecture is based and, secondly, we detail the main aspects and working of the current version of the MDB. Finally, we have designed a very simple but illustrative real robot lifelong learning example, where we can show how to set up an experiment using the MDB. Hence, with this simple example we show the successful behavior of the MDB cognitive developmental robotics principles.",https://ieeexplore.ieee.org/document/5596771/,The 2010 International Joint Conference on Neural Networks (IJCNN),18-23 July 2010,ieeexplore
10.1109/IROS.1998.727477,A constraint-based controller for soccer-playing robots,IEEE,Conferences,"Soccer meets the requirements of the situated agent approach and as a task domain is sufficiently rich to support research integrating many branches of robotics and AI. A robot is an integrated system, with a controller embedded in its plant. A robotic system is the coupling of a robot to its environment. Robotic systems are, in general, hybrid dynamic systems, consisting of continuous, discrete and event-driven components. Constraint nets provide a semantic model for modeling hybrid dynamic systems. Controllers are embedded constraint solvers that solve constraints in real-time. A controller for our new softbot soccer team, UBC Dynamo98, has been modeled in constraint nets, and implemented in Java, using the Java Beans architecture. The paper demonstrates that the formal constraint net approach is a practical tool for designing and implementing controllers for robots in multi-agent real-time environments.",https://ieeexplore.ieee.org/document/727477/,"Proceedings. 1998 IEEE/RSJ International Conference on Intelligent Robots and Systems. Innovations in Theory, Practice and Applications (Cat. No.98CH36190)",17-17 Oct. 1998,ieeexplore
10.1109/IJCNN.1989.118696,A general purpose analog neural computer,IEEE,Conferences,"The design of a programmable analog neural computer and simulator is described. The machine is intended for real-world real-time computations such as vision, acoustics, or robotics and the development of special-purpose neural nets. The computer is scalable and composed of interconnected switches. It runs entirely in analog mode but connection architecture, synaptic gains, and time constants as well as neuron parameters are set digitally. Each neuron has a limited number of inputs and can be connected to any but not all other neurons. For the implementation of learning algorithms the neuron outputs are multiplexed and converted to digital form. Even at the moderate size of 10/sup 3/ to 10/sup 5/ neurons the computational speed is expected to exceed that of any current digital computer.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/118696/,International 1989 Joint Conference on Neural Networks, 1989,ieeexplore
10.1109/IROS.2014.6942859,A machine learning approach for real-time reachability analysis,IEEE,Conferences,"Assessing reachability for a dynamical system, that is deciding whether a certain state is reachable from a given initial state within a given cost threshold, is a central concept in controls, robotics, and optimization. Direct approaches to assess reachability involve the solution to a two-point boundary value problem (2PBVP) between a pair of states. Alternative, indirect approaches involve the characterization of reachable sets as level sets of the value function of an appropriate optimal control problem. Both methods solve the problem accurately, but are computationally intensive and do no appear amenable to real-time implementation for all but the simplest cases. In this work, we leverage machine learning techniques to devise query-based algorithms for the approximate, yet real-time solution of the reachability problem. Specifically, we show that with a training set of pre-solved 2PBVP problems, one can accurately classify the cost-reachable sets of a differentially-constrained system using either (1) locally-weighted linear regression or (2) support vector machines. This novel, query-based approach is demonstrated on two systems: the Dubins car and a deep-space spacecraft. Classification errors on the order of 10% (and often significantly less) are achieved with average execution times on the order of milliseconds, representing 4 orders-of-magnitude improvement over exact methods. The proposed algorithms could find application in a variety of time-critical robotic applications, where the driving factor is computation time rather than optimality.",https://ieeexplore.ieee.org/document/6942859/,2014 IEEE/RSJ International Conference on Intelligent Robots and Systems,14-18 Sept. 2014,ieeexplore
10.1109/CISTI.2015.7170600,A mixed reality game using 3Pi robots — “PiTanks”,IEEE,Conferences,"In the growing field of Robotics, one of the many possible paths to explore is the social aspect that it can influence upon the present society. The combination of the goal-oriented development of robots with the interactivity used in games while employing mixed reality is a promising route to take in regard to designing user-friendly robots and improving problem solving featured in artificial intelligence software. In this paper, we present a competitive team-based game using Pololu's 3Pi robots moving in a projected map, capable of human interaction via game controllers. The game engine was developed utilizing the framework Qt Creator with C++ and OpenCV for the image processing tasks. The technical framework uses the ROS framework for communications that may be, in the future, used to connect different modules. Various parameters of the implementation are tested, such as position tracking errors.",https://ieeexplore.ieee.org/document/7170600/,2015 10th Iberian Conference on Information Systems and Technologies (CISTI),17-20 June 2015,ieeexplore
10.1109/CNE.2003.1196858,A neuro-controller for robotic manipulators based on biologically-inspired visuo-motor co-ordination neural models,IEEE,Conferences,"This paper presents a novel scheme for sensor-based control of robotics manipulators by means of artificial neural networks. The system is able to control simple reaching tasks by only fusing visual and proprioceptive sensory data, without computational kinematic modeling of the arm structure, Thanks to the generalization features typical of the neural approach, the same neurocontroller has been easily adapted and successfully validated for controlling different manipulators with different mechanical structures, i.e. number of degrees of freedom, link length and weight, etc. The proposed scheme is directly inspired to research results in the field of neuroscience, specifically on nervous structures and physiological mechanisms involved in sensory motor coordination. From a psychological point of view J. Piaget (1976) explained visuo-motor associations in his scheme of circular reaction. He observed how, by making endogenous movements and correlating the resulting arm and hand spatial locations, the brain allows an auto-association to be created between visual and proprioceptive sensing. The work presented in this paper is derived from the more recent DIRECT model proposed D. Bullock et al. (1993). Significant and original modifications of such model have been introduced by the authors to increase, at the same time, both system performance and the biological coherence. The proposed neurocontroller has been first simulated both in the 2-dimensional and the 3-dimensional case, and then implemented for experimental trials on two real robotic manipulators.",https://ieeexplore.ieee.org/document/1196858/,"First International IEEE EMBS Conference on Neural Engineering, 2003. Conference Proceedings.",20-22 March 2003,ieeexplore
10.1109/SACI.2013.6608963,A new NIR camera for gesture control of electronic devices,IEEE,Conferences,"Since the introduction Gesture Control technology in the electronic gaming technology a series of attempts have been made to deploy it also on other domains such as robotics, teaching, medical, automotive and many others. Human gesture used for Man-Machine Interaction became attractive as it offers a simpler way of controlling sophisticated devices, in a sci-fi-like scenario, in return of an increasingly computational power required by the artificial intelligence algorithms needed to detect, track and recognize them. There have been attempts to bring a solution to it by using 2D or 3D based image processing methods. There is a clear balance incline towards 3D methods in the consumer product as besides the almost insurmountable difficulties for producing robust and stable results, the price constraint added supplementary hurdles. As perfect illumination conditions are core factors in obtaining the above results, the infrared light was unanimously adopted by the domain technologies. In this paper, a novel real-time depth-mapping principle and a corresponding hardware solution for an IR depth-mapping camera is introduced. The new IR camera architecture comprises an illuminator module which is pulsed and modulated via a monotonic function using a phase-locked loop control for the laser intensity, while the reflected infrared light is captured during the increasing and decreasing monotonic function. A reconfigurable hardware architecture (RHA) unit calculates the depth and controls the IR waves in synchronism with the infrared sensor. The resolution of the depth map is variable depending on the resolution and gating possibilities of the image sensor. A sensor of 1 megapixel is used, providing a resolution of 1024×1024. Images of real objects are reconstructed in 3D based on the data obtained by the laser controlled by the RHA. A corresponding image processing algorithm builds the 3D map of the object in real-time. In this paper the camera is used to control consumer electronic products such as TV sets, laptops and others.",https://ieeexplore.ieee.org/document/6608963/,2013 IEEE 8th International Symposium on Applied Computational Intelligence and Informatics (SACI),23-25 May 2013,ieeexplore
10.1109/ISCAS.2000.856157,A new board for CNN stereo vision algorithm,IEEE,Conferences,Artificial vision for environment recognition is a very useful tool in autonomous robotics. Specifically the use of stereo vision algorithms implemented via a hardware neural architecture allows real time scene reconstruction. In this paper the follow-on of previous work on an analogue hardware Cellular Neural Network implementation of the algorithm is presented. In this paper a new CNN based PCI electronic board is presented.,https://ieeexplore.ieee.org/document/856157/,2000 IEEE International Symposium on Circuits and Systems (ISCAS),28-31 May 2000,ieeexplore
10.1109/FTC.2016.7821768,A non-biological AI approach towards natural language understanding,IEEE,Conferences,"The problem being addressed in this paper is that using brute force in Natural Language Processing and Machine Learning combined with advanced statistics will only approximate meaning and thus will not deliver in terms of real text understanding. Counting words and tracking word order or parsing by syntax will also result in probability and guesswork at best. Their vendors struggle in delivering accurate quality and this results in ill-functioning applications. The newer generation methodologies like Deep Learning and Cognitive Computing are breaking barriers in the (Big Data) fields of Internet of Things, Robotics and Image/Video Recognition but cannot be successfully deployed for text without huge amounts of training and sample data. In the short term, we believe non-biological Artificial Intelligence will produce the best results for text understanding. Miia applied advanced Linguistic and Semantic Technologies combined with ConceptNet modeling and Machine Learning to successfully cater deep intelligent and cross-language quality to several industries.",https://ieeexplore.ieee.org/document/7821768/,2016 Future Technologies Conference (FTC),6-7 Dec. 2016,ieeexplore
10.1109/FUZZY.1994.343709,A real time fuzzy dynamic image understanding system on general roads,IEEE,Conferences,"The purpose of this study is to realize a real time robotics vision system for, e.g. an ALV (autonomous land vehicle), in a cost effective way using fuzzy technology, that can be used in various circumstances (on general roads in Japan) such as from early morning till late evening and under the sunshine or in the rain. The presented system consists of an image processing part, knowledge base part, and a hardwired implementation part with VHDL. The image processing part is concerned with a dynamic image preprocessing based on mainly a conventional image processing technique. The knowledge base part employs a fuzzy frame knowledge base to express ambiguous information and natural language using fuzzy slot values. The hardwired implementation part designs hardware circuits using VHDL for high speed processing realization.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/343709/,Proceedings of 1994 IEEE 3rd International Fuzzy Systems Conference,26-29 June 1994,ieeexplore
10.1109/SICE.2002.1195611,A reinforcement learning using adaptive state space construction strategy for real autonomous mobile robots,IEEE,Conferences,"In the recent robotics, much attention has been focused on utilizing reinforcement learning for designing robot controllers. However, there still exists difficulties, one of them is well known as state space explosion problem. As the state space for a learning system becomes continuous and high dimensional, its combinational state space exponentially explodes and the learning process is time consuming. In this paper, we propose an adaptive state space recruitment strategy for reinforcement learning, which enables the system to divide state space gradually according to task complexity and progress of learning. Some simulation results and real robot implementation show the validity of the method.",https://ieeexplore.ieee.org/document/1195611/,Proceedings of the 41st SICE Annual Conference. SICE 2002.,5-7 Aug. 2002,ieeexplore
10.1109/IRDS.2002.1041504,A reinforcement learning with adaptive state space recruitment strategy for real autonomous mobile robots,IEEE,Conferences,"In the recent robotics, much attention has been focused on utilizing reinforcement learning for designing robot controllers. However, there still exists difficulties, one of them is well known as state space explosion problem. As the state space for learning system becomes continuous and high dimensional, the learning process results in time-consuming since its combinational states explodes exponentially. In order to adopt reinforcement learning for such complicated systems, it should be taken not only ""adaptability"" but ""computational efficiencies"" into account. In the paper, we propose an adaptive state space recruitment strategy for reinforcement learning, which enables the system to divide state space gradually according to task complexity and progress of learning. Some simulation results and real robot implementation show the validity of the method.",https://ieeexplore.ieee.org/document/1041504/,IEEE/RSJ International Conference on Intelligent Robots and Systems,30 Sept.-4 Oct. 2002,ieeexplore
10.1109/ICARCV.2012.6485305,A robust real-time tracking system based on an adaptive selection mechanism for mobile robots,IEEE,Conferences,"Extensive research has been conducted in the domain of object tracking. Among the existing tracking methods, most of them mainly focus on using various cues such as color, texture, contour, features, motion as well as depth information to achieve a robust tracking performance. The tracking methods themselves are highly emphasized while properties of the objects to be tracked are usually not exploited enough. In this paper, we first propose a novel adaptive tracking selection mechanism dependent on the properties of the objects. The system will automatically choose the optimal tracking algorithm after examining the textureness of the object. In addition, we propose a robust tracking algorithm for uniform objects based on color information which can cope with real world constraints. In the mean time, we deployed a textured object tracking algorithm which combines the Lucas-Kanade tracker and a model based tracker using the Random Forests classifier. The whole system was tested and the experimental results on a variety of objects show the effectiveness of the adaptive tracking selection mechanism. Moreover, the promising tracking performance shows the robustness of the proposed tracking algorithm. The computation cost of the algorithm is very low, which proves that it can be further used in various real-time robotics applications.",https://ieeexplore.ieee.org/document/6485305/,2012 12th International Conference on Control Automation Robotics & Vision (ICARCV),5-7 Dec. 2012,ieeexplore
10.1109/IJCNN.2017.7965912,A self-driving robot using deep convolutional neural networks on neuromorphic hardware,IEEE,Conferences,"Neuromorphic computing is a promising solution for reducing the size, weight and power of mobile embedded systems. In this paper, we introduce a realization of such a system by creating the first closed-loop battery-powered communication system between an IBM Neurosynaptic System (IBM TrueNorth chip) and an autonomous Android-Based Robotics platform. Using this system, we constructed a dataset of path following behavior by manually driving the Android-Based robot along steep mountain trails and recording video frames from the camera mounted on the robot along with the corresponding motor commands. We used this dataset to train a deep convolutional neural network implemented on the IBM NS1e board containing a TrueNorth chip of 4096 cores. The NS1e, which was mounted on the robot and powered by the robot's battery, resulted in a self-driving robot that could successfully traverse a steep mountain path in real time. To our knowledge, this represents the first time the IBM TrueNorth has been embedded on a mobile platform under closed-loop control.",https://ieeexplore.ieee.org/document/7965912/,2017 International Joint Conference on Neural Networks (IJCNN),14-19 May 2017,ieeexplore
10.1109/ROBOT.2010.5509238,A voice-commandable robotic forklift working alongside humans in minimally-prepared outdoor environments,IEEE,Conferences,"One long-standing challenge in robotics is the realization of mobile autonomous robots able to operate safely in existing human workplaces in a way that their presence is accepted by the human occupants. We describe the development of a multi-ton robotic forklift intended to operate alongside human personnel, handling palletized materials within existing, busy, semi-structured outdoor storage facilities. The system has three principal novel characteristics. The first is a multimodal tablet that enables human supervisors to use speech and pen-based gestures to assign tasks to the forklift, including manipulation, transport, and placement of palletized cargo. Second, the robot operates in minimally-prepared, semi-structured environments, in which the forklift handles variable palletized cargo using only local sensing (and no reliance on GPS), and transports it while interacting with other moving vehicles. Third, the robot operates in close proximity to people, including its human supervisor, other pedestrians who may cross or block its path, and forklift operators who may climb inside the robot and operate it manually. This is made possible by novel interaction mechanisms that facilitate safe, effective operation around people. We describe the architecture and implementation of the system, indicating how real-world operational requirements motivated the development of the key subsystems, and provide qualitative and quantitative descriptions of the robot operating in real settings.",https://ieeexplore.ieee.org/document/5509238/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/ICARCV.2018.8581349,Activity Recognition Based on RGB-D and Thermal Sensors for Socially Assistive Robots,IEEE,Conferences,"For socially assistive robots, being able to recognize basic human actions is an important capability. The sensors, which are frequently mounted on most recent robots, such as RGB-D and thermal cameras, as well as the advances in deep learning have enabled the research on activity recognition to grow. In this paper, we collected our own dataset of actions in a home-like scenario, which contains thermal imagery in addition to RGB-D data and we proposed a method based on Long-term Recurrent Convolutional Networks (LRCN). We showed that our method has an accuracy comparable with the state-of-the-art. We also proved that thermal information can improve the recognition accuracy. Furthermore, we tested the real-time capability of our system and conducted a real-time experiment with a robot (Pepper robot from Softbank Robotics) so as to investigate the effect of a robot enabled with action recognition capability in a human-robot interaction.",https://ieeexplore.ieee.org/document/8581349/,"2018 15th International Conference on Control, Automation, Robotics and Vision (ICARCV)",18-21 Nov. 2018,ieeexplore
10.1109/MESA.2016.7587103,Adaptive robust RBFNNs-based model estimator for a small quadrotor aircraft robot,IEEE,Conferences,"This paper presents an on-line estimator that incorporates adaptive MIMO radical basis function neural networks (RBFNNs) for model identification of quadrotor unmanned aerial vehicles (UAVs). The inputs and outputs of quadrotor aircrafts can be obtained from dynamic models or real attitude and position sensors. The adaptive learning rate is employed in the gradient descent method for the update of the weights of RBFNNs, and Lyapunov approach guarantees the stability of the global convergence of the modeling errors. The Welsch functions are also employed as the error functions to get rid of the influence from the noise due to disturbances like wind gusts. Simulation results using Robotics Toolbox for Matlab verify the effectiveness and robustness of the proposed estimator compared with results of traditional RBFNNs. Experiment results from real aircraft platform show that RBFNNs combining adaptive learning rate and Welsch error functions can approximate the overall system with high accuracy and robustness to disturbances.",https://ieeexplore.ieee.org/document/7587103/,2016 12th IEEE/ASME International Conference on Mechatronic and Embedded Systems and Applications (MESA),29-31 Aug. 2016,ieeexplore
10.1109/ICIRCA48905.2020.9182995,An Approach for Digital Farming using Mobile Robot,IEEE,Conferences,"Farming is the backbone of the Indian economy and it has been unchartered territory for a technological solution. As of late developments in Artificial Intelligence technology combined with Robotics has paved the way for an option of digital farming. As a matter of fact, Indian farming has been facing various challenges that include abrupt change in climatic conditions, spoiling of yields, soil nutrient requirement, pests/weed control and so forth. Robotics and Artificial Intelligence (AI) along with the integration of various sensors ensures the possibility of better outcome. In this work the simulation of Mobile robot for the purpose of seed sowing along with its movement has been presented. The implementation comprises of the Motor schema for the navigation of robot and Gale Shapley (GS) algorithm for stable match of seed and yield combination. Such a robotic system combined with AI in real time will form excellent means of farming in terms of yield.",https://ieeexplore.ieee.org/document/9182995/,2020 Second International Conference on Inventive Research in Computing Applications (ICIRCA),15-17 July 2020,ieeexplore
10.1109/ROBOT.2010.5509310,An Inertia-Based Surface Identification System,IEEE,Conferences,"In many robotics applications, knowing the material properties around a robot is often critical for the robot's successful performance. For example, in mobility, knowledge about the ground surface may determine the success of a robot's gait. In manipulation, the physical properties of an object may dictate the results of a grasping strategy. Thus, a reliable surface identification system would be invaluable for these applications. This paper presents an Inertia-Based Surface Identification System (ISIS) based on accelerometer sensor data. Using this system, a robot actively “knocks” on a surface with an accelerometer-equipped device (e.g., hand or leg), collects the accelerometer data in real-time, and then analyzes and extracts three critical physical properties, the hardness, the elasticity, and the stiffness, of the surface. A lookup table and k-nearest neighbors techniques are used to classify the surface material based on a database of previously known materials. This technique is low-cost and efficient in computation. It has been implemented on the modular and self-reconfigurable SuperBot and has achieved high accuracy (95% and 85%) in several identification experiments with real-world material.",https://ieeexplore.ieee.org/document/5509310/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/ISSE46696.2019.8984462,An IoT Reconfigurable SoC Platform for Computer Vision Applications,IEEE,Conferences,"The field of Internet of Things (IoT) and smart sensors has expanded rapidly in various fields of research and industrial applications. The area of IoT robotics has become a critical component in the evolution of Industry 4.0 standard. In this paper, we developed an IoT based reconfigurable System on Chip (SoC) robot that is fast and efficient for computer vision applications. It can be deployed in other IoT robotics applications and achieve its intended function. A Terasic Hexapod Spider Robot (TSR) was used with its DE0-Nano SoC board to implement our IoT robotics system. The TSR was designed to provide a competent computer vision application to recognize different shapes using a machine learning classifier. The data processing for image detection was divided into two parts, the first part involves hardware implementation on the SoC board and to provide real-time interaction of the robot with the surrounding environment. The second part of implementation is based on the cloud processing technique, where further data analysis was performed. The image detection algorithm for the computer vision component was tested and successfully implemented to recognize shapes. The TSR moves or reacts based on the detected image. The Field Programmable Gate Array (FPGA) part is programmed to handle the movement of the robot and the Hard Processor System (HPS) handles the shape recognition, Wi-Fi connectivity, and Bluetooth communication. This design is implemented, tested and can be used in real-time applications in harsh environments where movements of other robots are restricted.",https://ieeexplore.ieee.org/document/8984462/,2019 International Symposium on Systems Engineering (ISSE),1-3 Oct. 2019,ieeexplore
10.1109/DCOSS.2019.00111,An Open Source and Open Hardware Deep Learning-Powered Visual Navigation Engine for Autonomous Nano-UAVs,IEEE,Conferences,"Nano-size unmanned aerial vehicles (UAVs), with few centimeters of diameter and sub-10 Watts of total power budget, have so far been considered incapable of running sophisticated visual-based autonomous navigation software without external aid from base-stations, ad-hoc local positioning infrastructure, and powerful external computation servers. In this work, we present what is, to the best of our knowledge, the first 27g nano-UAV system able to run aboard an end-to-end, closed-loop visual pipeline for autonomous navigation based on a state-of-the-art deep-learning algorithm, built upon the open-source CrazyFlie 2.0 nano-quadrotor. Our visual navigation engine is enabled by the combination of an ultra-low power computing device (the GAP8 system-on-chip) with a novel methodology for the deployment of deep convolutional neural networks (CNNs). We enable onboard real-time execution of a state-of-the-art deep CNN at up to 18Hz. Field experiments demonstrate that the system's high responsiveness prevents collisions with unexpected dynamic obstacles up to a flight speed of 1.5m/s. In addition, we also demonstrate the capability of our visual navigation engine of fully autonomous indoor navigation on a 113m previously unseen path. To share our key findings with the embedded and robotics communities and foster further developments in autonomous nano-UAVs, we publicly release all our code, datasets, and trained networks.",https://ieeexplore.ieee.org/document/8804776/,2019 15th International Conference on Distributed Computing in Sensor Systems (DCOSS),29-31 May 2019,ieeexplore
10.1109/ICRAE.2017.8291426,An educational robot system of visual question answering for preschoolers,IEEE,Conferences,"The educational robotics is a novel technology for preschooler's companion and can be used for lower level education. This paper presents an AI-based robot system for achieving educational aims, such as metacognition tutoring and geometrical thinking training, with characteristics of contextual teaching by mining knowledge from the real world directly. For metacognition tutoring in our system, objects in real world are detected and a set of learning materials associated with the objects is presented for learners. For example, when a cat is detected, the robot will teach learners to pronounce the “Cat” in different languages, and more knowledge about cat will be pushed to the learners. For geometrical thinking training, an automatic questioning-and-answering section is employed to engage the learner to think, which is carried by a voice interaction between learners and robots. In our experiment, a set of specific object images are captured to validate the feasibility and efficiency of the proposed system. Our study indicated that the proposed system succeeded in captivating the children and parents in maximizing the children's desire to explore.",https://ieeexplore.ieee.org/document/8291426/,2017 2nd International Conference on Robotics and Automation Engineering (ICRAE),29-31 Dec. 2017,ieeexplore
10.1109/ROBOT.2010.5509935,An insect-based method for learning landmark reliability using expectation reinforcement in dynamic environments,IEEE,Conferences,"Navigation in unknown dynamic environments still remains a major challenge in robotics. Whereas insects like the desert ant with very limited computing and memory capacities solve this task with great efficiency. Thus, the understanding of the underlying neural mechanisms of insect navigation can inform us on how to build simpler yet robust autonomous robots. Based on recent developments in insect neuroethology and cognitive psychology, we propose a method for landmark navigation in dynamic environments. Our method enables the navigator to learn the reliability of landmarks using an expectation reinforcement method. For that end, we implemented a real-time neuronal model based on the Distributed Adaptive Control framework. The results demonstrate that our model is capable of learning the stability of landmarks by reinforcing its expectations. Also, the proposed mechanism allows the navigator to optimally restore its confidence when its expectations are violated. We also perform navigational experiments with real ants to compare with the results of our model. The behavior of the proposed autonomous navigator closely resembles real ant navigational behavior. Moreover, our model explains navigation in dynamic environments as a memory consolidation process, harnessing expectations and their violations.",https://ieeexplore.ieee.org/document/5509935/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/ICPR.1992.201634,An intelligent mobile robot golfing system using binocular stereo vision,IEEE,Conferences,"This paper describes a robot vision golfing system. The ARNIE P/sup tau / (Automated Robotic Navigational unit with Intelligent Eye and Putter) project was initiated to investigate the problems and develop software solutions for robotic tasks that require good hand-eye coordination and an intelligent feedback mechanism. This system has only one frame buffer and no specialized hardware, so quasi-real-time 3D tracking is accomplished in software using the unix spline facility. Golf is a difficult perceptory task which requires the integration of many complicated computational tasks. It is therefore a good platform to experiment with artificial intelligence techniques and robotics.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/201634/,[1992] Proceedings. 11th IAPR International Conference on Pattern Recognition,30 Aug.-3 Sept. 1992,ieeexplore
10.1109/SYSCON.2018.8369547,An interactive architecture for industrial scale prediction: Industry 4.0 adaptation of machine learning,IEEE,Conferences,"According to wiki definition, there are four design principles in Industry 4.0. These principles support companies in identifying and implementing Industry 4.0 scenarios, namely, Interoperability, Information transparency, Technical assistance, Decentralized decisions. In this paper we have discussed our work on an implementation of a machine learning based interactive architecture for industrial scale prediction for dynamic distribution of water resources across the continent, keeping the four corners of Industry 4.0 in place. We report the possibility of producing most probable high resolution estimation regarding the water balance in any region within Australia by implementation of an intelligent system that can integrate spatial-temporal data from various independent sensors and models, with the ground truth data produced by 250 practitioners from the irrigation industry across Australia. This architectural implementation on a cloud computing platform linked with a freely distributed mobile application, allowing interactive ground truthing of a machine learning model on a continental scale, shows accuracy of 90% with 85% sensitivity of correct surface soil moisture estimation with end users at its complete control. Along with high level of information transparency and interoperability, providing on-demand technical supports and motivating users by allowing them to customize and control their own local predictive models, show the successfulness of principles in Industry 4.0 in real environmental issues in the future adaptation in various industries starting from resource management to modern generation soft robotics.",https://ieeexplore.ieee.org/document/8369547/,2018 Annual IEEE International Systems Conference (SysCon),23-26 April 2018,ieeexplore
10.1109/ICSMC.2004.1398386,Ant colony optimization based swarms: implementation for the mine detection application,IEEE,Conferences,"Mine detection is a sensitive task confronting the battlefield strategists. There is an ever-increasing demand for proper and sophisticated resources for many issues involved in the task. Traditional practices still involve human force directly in executing the tasks in spite of the advances in technology for tools and implements for the operation [GAO, 2001]. The problem includes various facets inherently: two of the prominent issues are location of mines over a minefield and secondly removal of the mines once located [GAO, 2001]. These two issues are not totally independent as technology used for one can directly or indirectly affect the other. Developments in artificial intelligence, natural heuristics, computational optimization and robotics have endowed us with the ability to realize unmanned robots (or robot like vehicles) that work intelligently on a real time basis in attempting at the problem of mine detection. In this paper we focus on the algorithms developed using ant colony optimization based approaches to the mine detection application and its implementation on a real-time basis. We focus on certain optimization techniques that could be used for effective realization of the algorithm. Generic groundscout robots had been already built at the MABL, RIT [Sahin F. et al., 2003]. These robots have been used to demonstrate the implementation",https://ieeexplore.ieee.org/document/1398386/,"2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)",10-13 Oct. 2004,ieeexplore
10.1109/ACIT47987.2019.8991028,Application of Fuzzy Neural Networks in Robotic Path Planning,IEEE,Conferences,This paper essentially discusses different methodologies of Fuzzy Neural Networks which are implemented to robust the functionality of mobile robots in dynamic and static environment. Fusion of algorithms is important to increase the working of any system provided. Different kind of mobile robots along with various algorithms frameworks are taken as case studies for this paper. Due to the reason that typical mathematical models used to make robots mobile in real environment were not very useful as they were not catering for the limitation of robotic system memory. Thus new methodologies are being discussed and implemented by robotics research community.,https://ieeexplore.ieee.org/document/8991028/,2019 International Arab Conference on Information Technology (ACIT),3-5 Dec. 2019,ieeexplore
10.1109/ICEKIM52309.2021.00040,Application of Teaching Innovation Based on robotics engineering,IEEE,Conferences,"As the core major of “Internet + Industrial Intelligence”, robotics engineering is an upgrade and reconstruction of traditional engineering major. The industrial robot course is the professional core course of the Robotics Engineering. It is also a comprehensive course of multi-discipline integration, which involved mechanical engineering, automatic control, computer, sensor, electronic technology, artificial intelligence and other multi-disciplinary content. Robotics Engineering is characterized by broad foundation, great difficulty, emphasis on practice, rapid development and application of new knowledge. In the process of implementation of the teaching innovation, the new concept of engineering education was applied to propose a new form of curriculum system. Taking the projects of engineering as the study objects, disassemble the knowledge points involved in industrial robots, break the course boundaries, reshape the knowledge system, draw knowledge maps and then design teaching activities. In teaching innovation, teachers extend classroom through formation of subject competition teams, promote teaching and promote learning by competition, realize the integration of “teaching, class and competition”, build a bridge between theory and practice, then complete the transformation from knowledge learning to ability training. Besides, they also keep contact with intelligent manufacturing enterprises in Zhuhai and the Bay Area to obtain real-time new developments in enterprises. Thus, the latest information was introduced into classroom. Therefore, the meaning of “production, teaching, research and application” has been deepened. According to the characteristics of the knowledge points of the course, experts were invited to make special lectures for students which can bring them with international perspective and frontier knowledge.",https://ieeexplore.ieee.org/document/9479656/,"2021 2nd International Conference on Education, Knowledge and Information Management (ICEKIM)",29-31 Jan. 2021,ieeexplore
10.1109/ROBOT.2000.844768,Application of automatic action planning for several work cells to the German ETS-VII space robotics experiments,IEEE,Conferences,"Experiences in space robotics show, that the user normally has to cope with a huge amount of data. So, only robot and mission specialists are able to control the robot arm directly in teleoperation mode. By means of an intelligent robot control in cooperation with virtual reality methods, it is possible for non-robot specialists to generate tasks for a robot or an automation component intuitively. Furthermore, the intelligent robot control improves the safety of the entire system. The on-ground robot control and command station for the robot arm ERA onboard the satellite ETS-VII builds on a new resource-based action planning approach to manage robot manipulators and other automation components. In the case of ERA, the action planning system also takes care of the ""real"" robot onboard the satellite and the ""virtual"" robot in the simulation system. By means of the simulation system, the user can plan tasks ahead as well as analyze and visualize different strategies. The paper describes the mechanism of resource-based action planning, its application to different work cells, the practical experiences gained from the implementation for the on-ground robot control and command station for the robot arm ERA developed in the GETEX project as well as the services it provides to support VR-based man machine interfaces.",https://ieeexplore.ieee.org/document/844768/,Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065),24-28 April 2000,ieeexplore
10.1109/ICNN.1996.549172,Applying self-organizing networks to recognizing rooms with behavior sequences of a mobile robot,IEEE,Conferences,"We describe the application of a self-organizing network to the robot which learns to recognize rooms (enclosures) using behavior sequences. In robotics research, most studies on recognizing environments have tried to build the precise geometric map with highly sensitive sensors. However many natural agents like animals recognize the environments with low sensitivity sensors, and a geometric map may not be necessary. Thus we attempt to build a mobile robot using a self-organizing network to recognize the enclosures, in which it acts, with low sensitivity and local sensors. The mobile robot is behavior-based and does wall-following in an enclosure. Then the sequences of behaviors executed in each enclosure are obtained. The sequences are transformed into real-value vectors, and inputted to the Kohonen self-organizing network. Unsupervised learning is done and a mobile robot becomes able to distinguish and identify enclosures. We fully implemented the system using a real mobile robot and made experiments for evaluating the ability. Consequently we found out the recognition of enclosures was done well and our method was robust against small obstacles in an enclosure.",https://ieeexplore.ieee.org/document/549172/,Proceedings of International Conference on Neural Networks (ICNN'96),3-6 June 1996,ieeexplore
10.1109/ICACITE51222.2021.9404749,Artificial Intelligence and Robotics: Impact &amp; Open issues of automation in Workplace,IEEE,Conferences,"In engineering province robotics is one of the cognitive perspective to human communication or it concern with synod of perception of action. In Today's Tech World Artificial Intelligence is an essential tool which provides effective analytical business solutions &amp; plays significant role in the domain of robotics and have several similarities like human behavior which may drive the real world. This paper shows the significant blend of Artificial Intelligence and robotics which transform entire industries, technological improvement of robotics application &amp; utilization. It also focuses on different aspects of targets like marketing, home appliances, medical science, Smart agriculture and many more which includes open issues and technological challenges arises by this combination and conclude that robotics with AI can work in real world with real objects. Further AI based robotics are very important area in economics and organizational consequence, implementation of automation in any organizational design give impact on overall economy and infrastructure provide a wider direction for further research on Robotics and IoT are two terms each covering a myriad of technologies and concepts.",https://ieeexplore.ieee.org/document/9404749/,2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE),4-5 March 2021,ieeexplore
10.1109/ICMLC.2004.1378596,Artificial neural networks for mobile robot acquiring heading angle,IEEE,Conferences,The RBF network is designed for the mobile robot to acquire the accurate and real-time heading angle that is significant for the successful localization. Several designs related to the network architecture and training has been made to construct the RBF network using the OLS algorithm. The results of the experiment show that the designed neural network can greatly improve the accuracy of the localization. The proposed localization system with combined sensors based on the RBF neural network is reliable to ensure the intelligent behaviors of the robot. The technical presentations in this paper can facilitate the application of artificial neural networks in the environmental robotics.,https://ieeexplore.ieee.org/document/1378596/,Proceedings of 2004 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.04EX826),26-29 Aug. 2004,ieeexplore
10.1109/SIBCON50419.2021.9438884,Assessment of Map Construction in vSLAM,IEEE,Conferences,"Vision-based Simultaneous Localization and Mapping (vSLAM) is a challenging task in modern computer vision. vSLAM is particularly important as mobile robotics application. It allows to localize the robot and build the map of unknown environment in 3D in real-time. During research and development of new methods, it needs extensive evaluation on trajectory and map quality compared to known methods. In this work we focus on map quality estimation. We develop the simulated ground-truth data in photo-realistic environment and introduce new metrics in order to estimate map quality. We evaluate neural network based vSLAM methods with our framework in order to show that it fits map quality estimation more than standard approaches. Open-source implementation of our map metrics is available at https://github.com/CnnDepth/slam_comparison.",https://ieeexplore.ieee.org/document/9438884/,2021 International Siberian Conference on Control and Communications (SIBCON),13-15 May 2021,ieeexplore
10.1109/ROBOT.2005.1570581,Auto-supervised learning in the Bayesian Programming Framework,IEEE,Conferences,"Domestic and real world robotics requires continuous learning of new skills and behaviors to interact with humans. Auto-supervised learning, a compromise between supervised and completely unsupervised learning, consist in relying on previous knowledge to acquire new skills. We propose here to realize auto-supervised learning by exploiting statistical regularities in the sensorimotor space of a robot. In our context, it corresponds to achieve feature selection in a Bayesian programming framework. We compare several feature selection algorithms and validate them on a real robotic experiment.",https://ieeexplore.ieee.org/document/1570581/,Proceedings of the 2005 IEEE International Conference on Robotics and Automation,18-22 April 2005,ieeexplore
10.1109/SMC.2018.00655,Automated Training Plan Generation for Athletes,IEEE,Conferences,"In sports, athletes need detailed and individualised training plans for maintaining and improving their skills in order to achieve their best performance in competitions. This presents a considerable workload for coaches, who besides setting objectives have to formulate extremely detailed training plans. Automated Planning, which has already been successfully deployed in many real-world applications such as space exploration, robotics, and manufacturing processes, embodies a useful mechanism that can be exploited for generating training plans for athletes. In this paper, we propose the use of Automated Planning techniques for generating individual training plans, which consist of exercises the athlete has to perform during training, given the athlete's current performance, period of time, and target performance that should be achieved. Our experimental analysis, which considers general training of kickboxers, shows that apart of considerable less planning time, training plans automatically generated by the proposed approach are more detailed and individualised than plans prepared manually by an expert coach.",https://ieeexplore.ieee.org/document/8616652/,"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",7-10 Oct. 2018,ieeexplore
10.1109/ICAC.2004.1301379,Autonomic systems for mobile robots,IEEE,Conferences,"Mobile robots are an excellent testbed for autonomic computing research. The ultimate goal of robotics research is to develop a platform that can function autonomously in the face of hardware and software failures. This goal is becoming more important as robots are increasingly being deployed outside of controlled environments. In this paper, we discuss our work toward implementing an autonomic system for a mobile robot. This work is motivated by our experiences with existing mobile robot control software during real-world deployments.",https://ieeexplore.ieee.org/document/1301379/,"International Conference on Autonomic Computing, 2004. Proceedings.",17-18 May 2004,ieeexplore
10.1109/ICAMIMIA47173.2019.9223365,Autonomous Car Simulation Using Evolutionary Neural Network Algorithm,IEEE,Conferences,"Automation with artificial intelligence (AI) has widely implemented in robotics, transportation and manufacture. AI has become a powerful technology that change human life and help human more flexible doing something. In this paper, it will show a result of simulation from an autonomous car using the evolutionary neural network algorithm which combines genetic algorithm and neural network. The purpose of the simulation is to test the model that we develop to know the right direction based on the track, so the evolutionary neural network that implemented to the autonomous car be able to deliver the best solution before it implements in the real machine or car technology. Genetic algorithm combines with a neural network to reach an evolution condition. The evolution process is achieved through crossover, mutation and selection process, so the algorithm will give the best result from the iteration of the experiment. The result of our experiment shows that evolutionary neural network algorithm give the best result within 3 layer architecture, with iteration average is 14.5 reach finish point (check point) 3 in the track simulation. Based on the simulation, our car model can find out the right direction.",https://ieeexplore.ieee.org/document/9223365/,"2019 International Conference on Advanced Mechatronics, Intelligent Manufacture and Industrial Automation (ICAMIMIA)",9-10 Oct. 2019,ieeexplore
10.1109/ROBOT.2009.5152365,Autonomous driving in a multi-level parking structure,IEEE,Conferences,"Recently, the problem of autonomous navigation of automobiles has gained substantial interest in the robotics community. Especially during the two recent DARPA grand challenges, autonomous cars have been shown to robustly navigate over extended periods of time through complex desert courses or through dynamic urban traffic environments. In these tasks, the robots typically relied on GPS traces to follow pre-defined trajectories so that only local planners were required. In this paper, we present an approach for autonomous navigation of cars in indoor structures such as parking garages. Our approach utilizes multi-level surface maps of the corresponding environments to calculate the path of the vehicle and to localize it based on laser data in the absence of sufficiently accurate GPS information. It furthermore utilizes a local path planner for controlling the vehicle. In a practical experiment carried out with an autonomous car in a real parking garage we demonstrate that our approach allows the car to autonomously park itself in a large-scale multi-level structure.",https://ieeexplore.ieee.org/document/5152365/,2009 IEEE International Conference on Robotics and Automation,12-17 May 2009,ieeexplore
10.1109/ROBOT.2001.932842,Autonomous helicopter control using reinforcement learning policy search methods,IEEE,Conferences,"Many control problems in the robotics field can be cast as partially observed Markovian decision problems (POMDPs), an optimal control formalism. Finding optimal solutions to such problems in general, however is known to be intractable. It has often been observed that in practice, simple structured controllers suffice for good sub-optimal control, and recent research in the artificial intelligence community has focused on policy search methods as techniques for finding sub-optimal controllers when such structured controllers do exist. Traditional model-based reinforcement learning algorithms make a certainty equivalence assumption on their learned models and calculate optimal policies for a maximum-likelihood Markovian model. We consider algorithms that evaluate and synthesize controllers under distributions of Markovian models. Previous work has demonstrated that algorithms that maximize mean reward with respect to model uncertainty leads to safer and more robust controllers. We consider briefly other performance criterion that emphasize robustness and exploration in the search for controllers, and note the relation with experiment design and active learning. To validate the power of the approach on a robotic application we demonstrate the presented learning control algorithm by flying an autonomous helicopter. We show that the controller learned is robust and delivers good performance in this real-world domain.",https://ieeexplore.ieee.org/document/932842/,Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164),21-26 May 2001,ieeexplore
10.1109/IROS.2017.8202143,Autonomous skill-centric testing using deep learning,IEEE,Conferences,Software testing is an important tool to ensure software quality. This is a hard task in robotics due to dynamic environments and the expensive development and time-consuming execution of test cases. Most testing approaches use model-based and/or simulation-based testing to overcome these problems. We propose model-free skill-centric testing in which a robot autonomously executes skills in the real world and compares it to previous experiences. The skills are selected by maximising the expected information gain on the distribution of erroneous software functions. We use deep learning to model the sensor data observed during previous successful skill executions and to detect irregularities. Sensor data is connected to function call profiles such that certain misbehaviour can be related to specific functions. We evaluate our approach in simulation and in experiments with a KUKA LWR 4+ robot by purposefully introducing bugs to the software. We demonstrate that these bugs can be detected with high accuracy and without the need for the implementation of specific tests or task-specific models.,https://ieeexplore.ieee.org/document/8202143/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/BigComp48618.2020.00-21,Benchmarking Jetson Platform for 3D Point-Cloud and Hyper-Spectral Image Classification,IEEE,Conferences,"Modern innovations of embedded system platforms (hardware accelerations) play a vital role in revolutionizing deep learning into practical scenarios, transforming human efforts into an automated intelligent system such as autonomous driving, robotics, IoT (Internet-of-Things) and many other useful applications. NVIDIA Jetson platform provides promising performance in terms of energy efficiency, favorable accuracy, and throughput for running deep learning algorithms. In this paper, we present benchmarking of Jetson platforms (Nano, TX1, and Xavier) by evaluating its performance based on computationally expensive deep learning algorithms. Previously, most of the benchmark results were based on 2-D images with conventional deep learning models for image processing. However, the implementation of many other complex data types at Jetson platform has remained a challenge. We also showed the practical impact of optimizing the algorithm vs improving the hardware accelerations by deploying a diverse range of dense and intensive deep learning architectures at all three aforementioned Jetson platforms, to make a better comparison of performance. In this regard, we have used two entirely different data-types, namely (i) ModelNet-40(Princeton-3D point-cloud) data-set along with PointNet deep learning architecture for classification of 3D point-cloud, and (ii) hyperspectral images (HSI) datasets (KSC and Pavia) alongside stacked autoencoders(SAE) to classify HSI correspondingly. This will broaden the scope of edge-devices to handle 3-D and HSI data whilst real-time classification will be processed at edge-server under the umbrella of edge-computing. The selection of (i) was made to exploit GPU heavily as the code uses TensorFlowgpu whereas (ii) was chosen to challenge the CPU cores of each platform as the code is based on Theano and may suffer from under-utilizing the GPU cores. We have presented the detailed evaluation exclusively in term of performance indices as inference time, the maximum number of concurrent processes, resource utilization per process and efficiency",https://ieeexplore.ieee.org/document/9070378/,2020 IEEE International Conference on Big Data and Smart Computing (BigComp),19-22 Feb. 2020,ieeexplore
10.1109/IROS.2004.1389400,Biologically inspired optimal robot arm control with signal-dependent noise,IEEE,Conferences,"Progress in the field of humanoid robotics and the need to find simpler ways to program such robots has prompted research into computational models for robotic learning from human demonstration. To further investigate biologically inspired human-like robotic movement and imitation, we have constructed a framework based on three key features of human movement and planning: optimality, modularity and learning. In this paper we focus on the application of optimality principles to the production of human-like movement by a robot arm. Among computational theories of human movement, the signal-dependent noise, or minimum variance, model was chosen as a biologically realistic control scheme to produce human-like movement. A well known optimal control algorithm, the linear quadratic regulator, was adapted to implement this model. The scheme was applied both in simulation and on a real robot arm, which demonstrated human-like movement profiles in a point-to-point reaching experiment.",https://ieeexplore.ieee.org/document/1389400/,2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),28 Sept.-2 Oct. 2004,ieeexplore
10.1109/CSCS52396.2021.00073,Bluetooth Communications in Educational Robotics,IEEE,Conferences,"In a world in a continuous and rapid change, it is absolutely necessary for our students to keep up with the rapid progress of new technologies: Internet of Things (IoT), Robotics, Artificial Intelligence (AI), Virtual Reality (VR), Augmented Reality (AR) etc. The rapid evolution and diversification of these emerging technologies has recently led to their introduction into the educational offer of the school curriculum for the gymnasium. The discipline of Information and Communication Technology (ICT) has already been implemented, a discipline that involves both the formation of skills to use new technologies and the formation of computational thinking necessary for the efficient and intelligent use of these technologies. In order to teach and learn Physics from a STEM (Science, Technology, Engineering and Mathematics) educational perspective, we initiated optional school courses of IoT, Robotics and AI (approached through Machine Learning). These courses stimulate, at the level of students, computational thinking, creativity and innovation and lead, from an interdisciplinary perspective, to the development of emerging specializations such as Mathematics-Physics-Automation, Mathematics-Physics-Electronics, Mathematics-Physics-Informatics-Robotics etc. In this paper we presented a method of approaching, in the school educational space, the study of wireless communication technologies between smart devices, through an Educational Robotics project. The project consisted of creating a wireless controlled mobile robotic platform (robot car) via a Bluetooth module connected to an Arduino Uno board.",https://ieeexplore.ieee.org/document/9481012/,2021 23rd International Conference on Control Systems and Computer Science (CSCS),26-28 May 2021,ieeexplore
10.1109/ICRA.2019.8793510,Bonnet: An Open-Source Training and Deployment Framework for Semantic Segmentation in Robotics using CNNs,IEEE,Conferences,"The ability to interpret a scene is an important capability for a robot that is supposed to interact with its environment. The knowledge of what is in front of the robot is, for example, relevant for navigation, manipulation, or planning. Semantic segmentation labels each pixel of an image with a class label and thus provides a detailed semantic annotation of the surroundings to the robot. Convolutional neural networks (CNNs) are popular methods for addressing this type of problem. The available software for training and the integration of CNNs for real robots, however, is quite fragmented and often difficult to use for non-experts, despite the availability of several high-quality open-source frameworks for neural network implementation and training. In this paper, we propose a tool called Bonnet, which addresses this fragmentation problem by building a higher abstraction that is specific for the semantic segmentation task. It provides a modular approach to simplify the training of a semantic segmentation CNN independently of the used dataset and the intended task. Furthermore, we also address the deployment on a real robotic platform. Thus, we do not propose a new CNN approach in this paper. Instead, we provide a stable and easy-to-use tool to make this technology more approachable in the context of autonomous systems. In this sense, we aim at closing a gap between computer vision research and its use in robotics research. We provide an open-source codebase for training and deployment. The training interface is implemented in Python using TensorFlow and the deployment interface provides C++ library that can be easily integrated in an existing robotics codebase, a ROS node, and two standalone applications for label prediction in images and videos.",https://ieeexplore.ieee.org/document/8793510/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/IROS.2005.1545040,Broker: an interprocess communication solution for multi-robot systems,IEEE,Conferences,"We describe in this paper a novel implementation of the interprocess communication (IPC) technology, called Broker, in support of the development and the operation of a complex robot system. We view each robot system as a collection of processes that need to exchange information, e.g. motion commands and sensory data, in a flexible and convenient fashion, without affecting each other's operations in case of a process's scheduled termination or unexpected failure. We argue that the IPC technology provides an ideal framework for this purpose, and we carefully make our design decisions about its implementation based on the needs of robotics applications. Broker is programming language, operating system, and hardware platform independent and has served us well in a RoboCup project and collective robotics experiments, in both simulation and real-world environments.",https://ieeexplore.ieee.org/document/1545040/,2005 IEEE/RSJ International Conference on Intelligent Robots and Systems,2-6 Aug. 2005,ieeexplore
10.1109/UEMCON.2018.8796670,"Building Towards ""Invisible Cloak"": Robust Physical Adversarial Attack on YOLO Object Detector",IEEE,Conferences,"Deep learning based object detection algorithms like R-CNN, SSD, YOLO have been applied to many scenarios, including video surveillance, autonomous vehicle, intelligent robotics et al. With more and more application and autonomy left to deep learning based artificial intelligence, humans want to ensure that the machine does the best for them under their control. However, deep learning algorithms are known to be vulnerable to carefully crafted input known as adversarial examples which makes it possible for an attacker to fool an AI system. In this work, we explored the mechanism behind the YOLO object detector and proposed an optimization method to craft adversarial examples to attack the YOLO model. The experiment shows that this white box attack method is effective and has a success rate of 100% in crafting digital adversarial examples to fool the YOLO model. We also proposed a robust physical adversarial sticker generation method based on an extended Expectation Over Transformation (EOT) method(a method to craft adversarial example in the physical world). We conduct experiments to find the most effective approach to generate adversarial stickers. We tested the stickers both digitally as a watermark and physically showing it on an electronic screen on the front surface of a person. Our result shows that the sticker attack as a watermark has a success rate of 90% and 45% on photos taken indoors and on random 318 pictures from ImageNet. Our physical attack also has a success rate of 72% on photos taken indoors. We shared our project source code on the Github and our work is reproducible.",https://ieeexplore.ieee.org/document/8796670/,"2018 9th IEEE Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)",8-10 Nov. 2018,ieeexplore
10.1109/ISDA.2010.5687045,Bézier curve based dynamic obstacle avoidance and trajectory learning for autonomous mobile robots,IEEE,Conferences,"This paper addresses the problem of avoiding dynamic obstacles while following the learned trajectory through non-point based maps directly through laser data. The geometric representation of free configuration area changes while a moving obstacle enters into the safety region of autonomous mobile robot. We have applied the Bézier curve properties to the free configuration eigenspaces to satisfy the dynamic obstacle avoidance path constraints. The algorithm is designed to accurately represent the mobile robot's characteristics while avoiding obstacle such as minimum turning radius. Moreover, we also discuss the obstacle avoided path feasibility as a vectorial combination of free configuration eigen-vectors at discrete time scan-frames to manifest a trajectory, which once followed and mapped onto the two control signals of mobile robot will enable it to build an efficient and accurate online environment map. Preliminary results in Matlab have been shown to validate the idea, while the same has been implemented in Player/stage (robotics real-time software) to analyze the performance of the proposed system.",https://ieeexplore.ieee.org/document/5687045/,2010 10th International Conference on Intelligent Systems Design and Applications,29 Nov.-1 Dec. 2010,ieeexplore
10.1109/ICCE-Berlin.2018.8576251,CNN Inference: Dynamic and Predictive Quantization,IEEE,Conferences,"Deep Learning techniques like Convolutional Neural Networks (CNN) are the de-facto method for image classification with broad usage spanning across automotive, industrial, medicine, robotics etc. Efficient implementation of CNN inference on embedded device requires a quantization method, which minimizes the accuracy loss, ability to generalize across deployment scenarios as well as real-time processing. Existing literature doesn't address all these three requirements simultaneously. In this paper, we propose a novel quantization algorithm to overcome above mentioned challenges. The proposed solution dynamically selects the scale for quantizing activations and uses Kalman filter to predict quantization scale to reduce accuracy loss. The proposed solution exploits the range statistics from previous inference processes to estimate quantization scale, enabling real-time solution. The proposed solution is implemented on TI's TDA family of embedded automotive processors. The proposed solution is running real time semantic segmentation on TDA2x processor within 0.1% accuracy loss compared floating point algorithm. The solution performs well across multiple deployment scenarios (e.g. rain, snow, night etc) demonstrating generalization capability of the solution.",https://ieeexplore.ieee.org/document/8576251/,2018 IEEE 8th International Conference on Consumer Electronics - Berlin (ICCE-Berlin),2-5 Sept. 2018,ieeexplore
10.1109/MSM49833.2020.9202398,Collaborative Robot System for Playing Chess,IEEE,Conferences,"In recent years, number of collaborative robots industrial applications has made a significant increasment. Implementation of collaborative robots is a safe and effective way for designing robot-human cooperation systems. Combined with constantly developing artificial intelligence, collaborative systems are actually able to solve complex problems that require some sort of intelligence. For humans, board games are a good example of the visualization of robot intelligence. Such systems require estimation and detection of board and pieces in manipulator workspace, some kind of decision-making algorithms and robot control system to move pieces. The flagship of such systems are chess playing robots. The chess game has a defined and easy to understand set of rules which makes it interesting example of intelligent robotics systems application. In this paper, we present an implementation of collaborative robots for chess playing system which was designed to play against human or another robot. The system is able to track state of the game via camera, calculate the optimal move using implemented decision-making algorithm, detect illegal moves and execute pick-and-place task to physically move pieces. We test the developed system in a real-world setup and provide experimental results documenting the performance of proposed approach.",https://ieeexplore.ieee.org/document/9202398/,2020 International Conference Mechatronic Systems and Materials (MSM),1-3 July 2020,ieeexplore
10.1109/IVCNZ51579.2020.9290542,Comparison of Face Detection Algorithms on Mobile Devices,IEEE,Conferences,"Face detection is a fundamental task for many computer vision applications such as access control, security, advertisement, automatic payment, and healthcare. Due to technological advances mobile robots are becoming increasingly common in such applications (e.g. healthcare and security robots) and consequently there is a need for efficient and effective face detection methods on such platforms. Mobile robots have different hardware configurations and operating conditions from desktop applications, e.g. unreliable network connections and the need for lower power consumption. Hence results for face detection methods on desktop platforms cannot be directly translated to mobile platforms.We compare four common face detection algorithms, Viola-Jones, HOG, MTCNN and MobileNet-SSD, for use in mobile robotics using different face data bases. Our results show that for a typical mobile configuration (Nvidia Jetson TX2) Mobile-NetSSD performed best with 90% detection accuracy for the AFW data set and a frame rate of almost 10 fps with GPU acceleration. MTCNN had the highest precision and was superior for more difficult face data sets, but did not achieve real-time performance with the given implementation and hardware configuration.",https://ieeexplore.ieee.org/document/9290542/,2020 35th International Conference on Image and Vision Computing New Zealand (IVCNZ),25-27 Nov. 2020,ieeexplore
10.1109/MI-STA52233.2021.9464484,Comparison of PID and Artificial Neural Network Controller in on line of Real Time Industrial Temperature Process Control System,IEEE,Conferences,"Due to its simple structure and robustness, the traditional proportional-integral-derivative (PID) controller is commonly used in the field of industrial automation and process control, but it does not function well with nonlinear systems, time-delayed linear systems and time-varying systems. A new type of PID controller based on artificial neural networks and evolutionary algorithms is presented in this paper. An powerful instrument for a highly nonlinear system is the Artificial Neural Network. The interest in the study of the nonlinear system has increased through the implementation of a high-speed computer system,. In complex systems such as robotics and process control systems, the Neuro Control Algorithm is often applied. Systems of process management is also nonlinear and hard to control consistently.. This paper presents a comprehensive analysis in Which is offline trained by a multilayered feed forward back propagation neural network to act as a process control system controller, That is to say, a temperature control device without prior knowledge of its dynamics. Via the implementation of a range of input vectors to the neural network, the inverse dynamics model is developed. Based on these input vectors, the output of the neural network It is being studied by explicitly configuring it to monitor the operation. In this paper, based on set-point adjustment, impact of disturbances in load and variable dead time, compassion between the PID controller and ANN is conducted. The outcome shows that ANN outperforms the controller of the PID.",https://ieeexplore.ieee.org/document/9464484/,2021 IEEE 1st International Maghreb Meeting of the Conference on Sciences and Techniques of Automatic Control and Computer Engineering MI-STA,25-27 May 2021,ieeexplore
10.1109/ROBIO.2009.4913338,Complex robot training tasks through bootstrapping system identification,IEEE,Conferences,"Many sensor-motor competences in mobile robotics applications exhibit complex, non-linear characteristics. Previous research has shown that polynomial NARMAX models can learn such complex tasks. However as the complexity of the task under investigation increases, representing the whole relationship in one single model using only raw sensory inputs would lead to large models. Training such models is extremely difficult, and, furthermore, obtained models often exhibit poor performances. This paper presents a bootsrapping method of generating complex robot training tasks using simple NARMAX models. We model the desired task by combining predefined low level sensor motor controllers. The viability of the proposed method is demonstrated by teaching a Scitos GS autonomous robot to achieve complex route learning tasks in the real world robotics experiments.",https://ieeexplore.ieee.org/document/4913338/,2008 IEEE International Conference on Robotics and Biomimetics,22-25 Feb. 2009,ieeexplore
10.1109/ICIT.2002.1189341,Computer based robot training in a virtual environment,IEEE,Conferences,"As more market segments are welcoming automation, the robotic field continues to expand. With the accepted breadth of viable industrial robotic applications increasing, the need for flexible robotic training also grows. In the area of simulation and offline programming there have been innovative developments to Computer Aided Robotics (CAR) Systems. New and notable releases have been introduced to the public, especially among the small, affordable, and easy to use systems. These CAR-Systems are mainly aimed at system integrators in general industry business fields to whom the complex, powerful software tools used by the automotive industry (and its suppliers) are oversized. In general, CAR-Systems are used to design robot cells and to create the offline programs necessary to reduce start-up time and to achieve a considerable degree of planning reliability. Another potential yet to be fully considered, is the use of such CAR-Systems as an inexpensive and user-friendly tool for robotics training. This paper will show the educational potential and possibility inherent in simulation and introduce a successful example of this new method of training. Finally, this presentation should be seen as an attempt to outline novel methods for future education in an industrial environment characterized by the increased occurrence and implementation of the virtual factory.",https://ieeexplore.ieee.org/document/1189341/,"2002 IEEE International Conference on Industrial Technology, 2002. IEEE ICIT '02.",11-14 Dec. 2002,ieeexplore
,Corporate Social Responsibility Challenges and Risks of Industry 4.0 technologies: A review,VDE,Conferences,"The fourth industrial revolution arrived with many enabling technologies that would impact important sociological aspects in the industry. Some of the Industry 4.0 technologies are already running in different industrial application, and other are still as a paradigm state. The social, economic, and environmental acceptance of Industry 4.0 technologies is still under discussion, which open new opportunities to execute various analysis about the possible implications of the implementation of such technologies. This article refers to an exploratory analysis and identification of the different challenges and risks of this new Industry 4.0 paradigm and its related technologies. The technologies under review were Internet of Things, Artificial Intelligence, Cloud Computing, cybersecurity, bid data, blockchain, 5G, robotics, adding manufacturing, unmanned systems, autonomous vehicles, virtual reality, and augmented reality. As a result, different social challenges and risks were identified for each technology, starting from vulnerability, implementation cost, until social aspects such as education and unemployment caused by those new technologies. In conclusion, Industry 4.0 arrived with a lot of benefits to the industry business, but companies should not stop thinking about sustainable development.",https://ieeexplore.ieee.org/document/8835964/,"Smart SysTech 2019; European Conference on Smart Objects, Systems and Technologies",4-5 June 2019,ieeexplore
10.1109/ICECS46596.2019.8964645,Data-Driven Video Grasping Classification for Low-Power Embedded System,IEEE,Conferences,"Video-based hand grasp analysis can support both robotics and prosthetics. Indeed, computational aspects represent a major issue, as hand grasp analysis is expected to support grasping systems that are hosted on low-power embedded systems. This paper proposes a framework for video-based grasping classification that is designed for implementation on resource-constrained devices. The framework adopts a fully data-driven strategy and relies on deep learning to deal with advanced analysis of video signals. Nonetheless, the overall design takes advantage of CNN architectures that can cope with the constraints imposed by embedded systems. The experimental session involved a real-world dataset containing daily life activities collected using egocentric perspective. In addition, the complete inference system is implemented on a NVIDIA Jetson-TX2 obtaining real time performances. The results confirm that the proposed system can suitably balance the trade off between accuracy and computational costs.",https://ieeexplore.ieee.org/document/8964645/,"2019 26th IEEE International Conference on Electronics, Circuits and Systems (ICECS)",27-29 Nov. 2019,ieeexplore
10.1109/AERO.2018.8396547,Data-driven quality prognostics for automated riveting processes,IEEE,Conferences,"Technologies based in robotics and automatics are reshaping the aerospace industry. Aircraft manufacturers and top-tier suppliers now rely on robotics to perform most of its operational tasks. Over the years, a succession of implemented mobile robots has been developed with the mission of automating important industrial processes such as welding, material handling or assembly procedures. However, despite the progress achieved, a major limitation is that the process still requires human supervision and an extensive quality control process. An approach to address this limitation is to integrate machine learning methods within the quality control process. The idea is to develop algorithms that can direct manufacturing experts towards critical areas requiring human supervision and quality control. In this paper we present an application of machine learning to a concrete industrial problem involving the quality control of a riveting machine. The proposal consists of an intelligent predictive model that can be integrated within the existing real time sensing and pre-processing sub-systems at the equipment level. The framework makes use of several data-driven techniques for pre-processing and feature engineering, combined with the most accurate algorithms, validated through k-folds cross validation technique which also estimates prediction errors. The model is able to classify the manufacturing process of the machine as nominal or anomalous according to a real-world data set of design requirements and operational data. Several machine learning algorithms are compared such as linear regression, nearest neighbor, support vector machines, decision trees, random forests and extreme gradient boost. Results obtained from the case study suggest that the proposed model produces accurate predictions which meet industrial standards.",https://ieeexplore.ieee.org/document/8396547/,2018 IEEE Aerospace Conference,3-10 March 2018,ieeexplore
10.1109/MSM49833.2020.9201666,Deep Learning-based Algorithm for Mobile Robot Control in Textureless Environment,IEEE,Conferences,"For the implementation of stereo image-based visual servoing algorithm in the eye-in-hand robotics applications, one of the main concerns is the accurate point feature detection and matching algorithm. Since the visual servoing is carried out in the textureless environment, the feature detection process is even more challenging. To fulfill the requirement of a robust and reliable point feature detection process, in this paper we present the novel deep learning-based algorithm. The approach based on convolutional neural networks and algorithm for detection of manufacturing entities is proposed and detected regions of interest are utilized for the improvement of the point feature detection algorithm. The proposed algorithm is experimentally evaluated in real-world settings by using wheeled nonholonomic mobile robot RAICO equipped with stereo vision system. The experimental results show the improvement of 58% in the accuracy of matched point features in the images obtained during the visual servoing process. Moreover, with the implementation of the proposed deep learning-based approach, the number of successful experimental runs has increased by 80%.",https://ieeexplore.ieee.org/document/9201666/,2020 International Conference Mechatronic Systems and Materials (MSM),1-3 July 2020,ieeexplore
10.1109/ICRA48506.2021.9561145,Deep Reinforcement Learning Framework for Underwater Locomotion of Soft Robot,IEEE,Conferences,"Soft robotics is an emerging technology with excellent application prospects. However, due to the inherent compliance of the materials used to build soft robots, it is extremely complicated to control soft robots accurately. In this paper, we introduce a data-based control framework for solving the soft robot underwater locomotion problem using deep reinforcement learning (DRL). We first built a soft robot that can swim based on the dielectric elastomer actuator (DEA). We then modeled it in a simulation for the purpose of training the neural network and tested the performance of the control framework through real experiments on the robot. The framework includes the following: a simulation method for the soft robot that can be used to collect data for training the neural network, the neural network controller of the swimming robot trained in the simulation environment, and the computer vision method to collect the observation space from the real robot using a camera. We confirmed the effectiveness of the learning method for the soft swimming robot in the simulation environment by allowing the robot to learn how to move from a random initial state to a specific direction. After obtaining the trained neural network through the simulation, we deployed it on the real robot and tested the performance of the control framework. The soft robot successfully achieved the goal of moving in a straight line in disturbed water. The experimental results suggest the potential of using deep reinforcement learning to improve the locomotion ability of mobile soft robots.",https://ieeexplore.ieee.org/document/9561145/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICCSP.2017.8286790,Design framework for general purpose object recognition on a robotic platform,IEEE,Conferences,"The advancement in the broader field of Computer Vision is consequential, through past few decades. Therefore, a considerable improvement in object detection and tagging using convolutional neural networks has given way to accurate yet complex methods, which can identify objects in real-time. However, the growth in the area of implementing the algorithms on low powered portable devices has been relatively slow. This paper aims to converge the fields of computer vision and robotics, focusing on implementation of image description applications on an embedded system platform. We aim to integrate Neural Network powered object recognition system `YOLO v2' with a robotic platform to explore the potential applications in the advancing domain of service and personal robotics.",https://ieeexplore.ieee.org/document/8286790/,2017 International Conference on Communication and Signal Processing (ICCSP),6-8 April 2017,ieeexplore
10.1109/CNNA.2000.876849,Design of a dedicated CNN chip for autonomous robot navigation,IEEE,Conferences,"Obstacle avoidance is the main issue in autonomous robotics. It requires a three-dimensional effective environment sensing in real time. Among the others, the stereo vision approach to environmental information extraction seems to be very appealing, even if it leads an extremely high computational cost. However, a high performance implementation of this algorithm on a cellular neural network is able to overcome these difficulties. In the paper, the design of a CNN chip well suited for this algorithm is presented. This chip, performing a real time processing of the stereo vision data, will improve the cruising speed of a robotic platform.",https://ieeexplore.ieee.org/document/876849/,Proceedings of the 2000 6th IEEE International Workshop on Cellular Neural Networks and their Applications (CNNA 2000) (Cat. No.00TH8509),25-25 May 2000,ieeexplore
10.1109/SECON.2008.4494306,Design of an integrated environment for operation and control of robotic arms (non-reviewed),IEEE,Conferences,"As more advanced control algorithms are becoming available for the control of robotic arms, traditional fixed controller boards and associated code generators are becoming less convenient way to test such control algorithms in real-time. The process of using such boards is complex, time consuming, and inflexible. In this work, an integrated hardware-software environment was developed and presented where researchers can simply use any Matlab/Simulink basic function block and/or toolbox, such as fuzzy logic or neural network, to design, implement, and test different controller algorithms in realtime for robotic arm operations. The hardware includes a computer, the dSPACE-ds1103 digital processing board, an amplifier board, and the Zebra-ZERO robotics arm as a test-bed. Also, Matlab GUI, m-file, Matlab/Simulink blocks, and dSPACE interface functions are combined together to form the software environment. Control algorithms can be designed in the Matlab/Simulink then converted to c-code and download to the dSPACE processing board. The Matlab m-file are used to code the arm inverse kinematics model and the path planning to calculate the joint angles then send them to the dSPACE processing board using the dSPACE interface functions. Finally, the dSPACE processing board generates physical signal to control the robot arm in real-time. The proposed hardware-software components are developed and integrated together, and several control algorithms can be tested on it. The development steps and some of the realtime testing results conducted on the hardware are explained next in this extended abstract. Typically, controllers are designed to run on dedicated hardware and researchers need different hardware to test different control strategies. This can be costly and time consuming where one has to develop different control environment for every control strategy to be tested. In this work, an integrated hardware-software environment was developed for implementation and testing of different control algorithms in real-time. The integrated system is composed of a computer, a power supply, the DS1103 dSPACE controller board, an amplifier, and the Zebra- Zero force robotics arm. The computer is used to send commands to the DS1103 dSPACE controller board.Inside the DS1103 dSPACE controller board, a Texas instruments DSP micro-controller performs the necessary calculation to determine the PWM signal to be generated and sent to the amplifier. The amplifier then generates the control signals that are applied to dc-motors that drive the links. The motor encoders provide feedback position signals as output. To develop the software environment, the Matlab programming environment (m-file), Matlab's graphical user interface, Simulink, and the toolbox are all employed. A user graphical interface (GUI) was designed for user convenience. The robot can be moved to the ready position then, the forward or inverse kinematical model is chosen according to the type of input data. The links begin to move when the Move button is pressed. The user can also select different movement speed for each link. Finally, when link movement has ceased, the joint trajectories are displayed on the GUI. Trajectory planning files for position, velocity and acceleration references are also developed and implemented in the environment. Two types of trajectories are made available according to different requirements; second order polynomial and third-order polynomial trajectory. The second order polynomial trajectory is recommended for links with large angular position difference. For purpose of testing and verification, the Zebra-Zero robotics arm was used. The Lagrangian mechanics is used to develop the dynamic equations for the Zebra-Zero robotic arm. Some of the arm parameters are calculated while others are determined experimentally, e.g., the link inertias and masses. A Simulink model of the robotic arm dynamic was developed. To test the environment a control algorithm was also designed then automatically converted to C programming language and downloaded to the DS1103 dSPACE controller board. The user enters commands using the Matlab GUI. Based on input, positions or final location and orientation, the forward or inverse kinematical model is selected. In this work a PID control algorithm was designed and tested on the Zebra- Zero robotics arm. To verify the controller performance, Matlab toolbox was used to simulate the Zebra-Zero robotic arm dynamics model. The results were very comparable with the actual Zebra-Zero robotic arm hardware performance.",https://ieeexplore.ieee.org/document/4494306/,IEEE SoutheastCon 2008,3-6 April 2008,ieeexplore
10.1109/CONIELECOMP.2017.7891823,Detecting falling people by autonomous service robots: A ROS module integration approach,IEEE,Conferences,"In this paper is presented the integration of diverse modules for people fallen detection by a mobile service robot. This integration has been achieved in the middleware ROS (Robotics Operation System). The proposed implementation are arranged over an modular architecture of three layers: Hardware, Processing and Decision. The modules implemented are on the processing layer. The first module uses an RGB-D camera to detect and track a person in the environment. This module calculate features to detect the fallen pose. In the second module, a PID controller in a pan/tilt unit is used, in order to track the person with a minimum error and soft movement. For this purpose the centroid of the person is located at the center of the plane image. The main characteristics in our architecture are: 1) Segmentation in depth is used, because 3D information is required for detecting the fallen pose; 2) The parameters of PID control are tuned using a manual method and a genetic algorithm, to compare and improve the performance of the tracking person module. Once the PID controller was optimized, the architecture to follow the person and detect the fallen pose, is probed in real time.",https://ieeexplore.ieee.org/document/7891823/,"2017 International Conference on Electronics, Communications and Computers (CONIELECOMP)",22-24 Feb. 2017,ieeexplore
10.1109/ICCSPN46366.2019.9150190,Developing A Framework for A Tactile Internet Enabled Robot Assisted Real-Time Interactive Medical System,IEEE,Conferences,"In this paper we outline a high-level framework and architecture for a robotic assisted real time interactive medical system for use in developing countries to help cure the acute shortage of qualified skill medical personnel in the health sector in of an internet of skills domain. We explore the application of new and innovative advancements in technological areas such as AI, 5G mobile networks, the tactile internet networks, robotics and haptic technology to aid in the digital transfer of medical expertise over a wide geographical area. We describe and propose technical specifications of such systems and review existing literature and current technologies in these areas. We interrogate the potential benefits and challenges facing the deployment of these technologies.",https://ieeexplore.ieee.org/document/9150190/,"2019 International Conference on Communications, Signal Processing and Networks (ICCSPN)",29-31 May 2019,ieeexplore
10.1109/SII46433.2020.9025980,Development of a Web-Based Education System for Deep Reinforcement Learning-Based Autonomous Mobile Robot Navigation in Real World,IEEE,Conferences,"The technology that combined deep reinforcement learning and robotics is increasing interests in recent years. Although several online tools for studying this technology can be found, it is difficult for beginners to develop actual robot systems for autonomous navigation in the real world. In this study, we developed a web-based educational system that is able to help users to study mobile robot navigation based on deep reinforcement learning and develop actual robot systems. The proposed web system provides the following functions: setting the parameters of reinforcement learning for autonomous robot navigation, running learning scripts and monitoring status of the learning. The first experiment that a user develops an actual robot system was performed. In the experiment, the user tuned parameters on the web page started the training and obtained action policy models. The experimental results indicate the proposed system can be applied to develop an actual autonomous navigation system. Also, the user could decide better parameters through the trial and error process using the proposed system.",https://ieeexplore.ieee.org/document/9025980/,2020 IEEE/SICE International Symposium on System Integration (SII),12-15 Jan. 2020,ieeexplore
10.1109/INTERCON.2019.8853573,Development of a hand pose recognition system on an embedded computer using Artificial Intelligence,IEEE,Conferences,"The recognition of hand gestures is a very interesting research topic due to the growing demand in recent years in robotics, virtual reality, autonomous driving systems, human-machine interfaces and in other new technologies. Despite several approaches for a robust recognition system, gesture recognition based on visual perception has many advantages over devices such as sensors, or electronic gloves. This paper describes the implementation of a visual-based recognition system on a embedded computer for 10 hand poses recognition. Hand detection is achieved using a tracking algorithm and classification by a light convolutional neural network. Results show an accuracy of 94.50%, a low power consumption and a near real-time response. Thereby, the proposed system could be applied in a large range of applications, from robotics to entertainment.",https://ieeexplore.ieee.org/document/8853573/,"2019 IEEE XXVI International Conference on Electronics, Electrical Engineering and Computing (INTERCON)",12-14 Aug. 2019,ieeexplore
10.1109/ICVES.2009.5400189,Digital implementation of fuzzy logic controller for wide range speed control of brushless DC motor,IEEE,Conferences,"The brushless DC motors find wide applications such as in battery operated vehicles, wheel chairs, automotive fuel pumps, robotics, machine tools, aerospace and in many industrial applications due to their superior electrical and mechanical characteristics and its capability to operate in hazardous environment. Conventional controllers fail to yield desired performance in BLDC motor control systems due to the non-linearity arising out of variation in the system parameters and change in load. The main focus is now on the application of artificial intelligent techniques such as fuzzy logic to solve this problem. Another great challenge is to reduce the size and cost of the drive system without compromising the performance. In this paper, the design and digital implementation of fuzzy logic controller using a versatile ADUC812 microcontroller, and low-cost, compact, superior performance components are used in order to reduce the cost and size of the drive system. The experimental results are presented to prove the flexibility of the control scheme in real time.",https://ieeexplore.ieee.org/document/5400189/,2009 IEEE International Conference on Vehicular Electronics and Safety (ICVES),11-12 Nov. 2009,ieeexplore
10.1109/BIOROB.2014.6913811,EEG-based classification of upper-limb ADL using SNN for active robotic rehabilitation,IEEE,Conferences,"Repetitive activities of daily living (ADL) and robotic active training are commonly practised in the rehabilitation of paralyzed patients, both of which have been proven rather effective to recover the locomotor function of impaired limbs. ADL classification based on electroencephalogram (EEG) is of great significance to perform active robotic rehabilitation for patients with complete spinal cord injury (SCI) who lose locomotion of affected limbs absolutely, where surface electromyography (sEMG) or active force signal can hardly be detected. It is a challenge to achieve a satisfying result in neuro-rehabilitation robotics using EEG signals due to the high randomness of the EEG data. A classification method is proposed based on spiking neural networks (SNN) to identify the upper-limb ADL of three classes with 14-channel EEG data. The continuous real-number signals are firstly encoded into spike trains through Ben's Spike Algorithm (BSA). The generated spikes are then submitted into a 3-D brain-mapped SNN reservoir called NeuCube trained by Spike Timing Dependant Plasticity (STDP). Spike trains from all neurons of the trained reservoir are finally classified using one version of dynamic evolving spiking neuron networks (deSNN) - deSNNs. Classifications are presented with and without NeuCube respectively on the same EEG data set. Results indicate that using the reservoir improves identification accuracy which turns out pretty promising despite that EEG data is highly noisy, low frequently sampled, and only from 14 channels. The classification technique reveals a great potential for the further implementation of active robotic rehabilitation to the sufferers of complete SCI.",https://ieeexplore.ieee.org/document/6913811/,5th IEEE RAS/EMBS International Conference on Biomedical Robotics and Biomechatronics,12-15 Aug. 2014,ieeexplore
10.1109/FCCM51124.2021.00046,Edge Accelerator for Lifelong Deep Learning using Streaming Linear Discriminant Analysis,IEEE,Conferences,"Lifelong deep learning models are expected to continuously adapt and acquire new knowledge in dynamic environments. This capability is essential for numerous vision tasks in robotics and drones, and the models must be deployed on the edge to achieve real-time performance. We propose a FPGA accelerator of a streaming classifier for lifelong deep learning, which is based on streaming linear discriminant analysis (SLDA). When combined with a frozen Convolutional Neural Network (CNN) model, the proposed system is capable of class incremental lifelong learning for object classification.",https://ieeexplore.ieee.org/document/9444094/,2021 IEEE 29th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM),9-12 May 2021,ieeexplore
10.1109/WiSPNET51692.2021.9419475,Emotion based Media Playback System using PPG Signal,IEEE,Conferences,"The study involved identifying human emotions and integrates the identified emotion with the music system. The idea is to develop a complete product to utilize the detected emotion in a real-time application and also to achieve more accuracy and less memory. Human emotions are identified using physiological signals such as electrocardiography, electromyography, photoplethysmography, respiration, skin temperature, etc. Obtaining photoplethysmography (PPG) from the sensor is a simple, cost-effective, and non-invasive method. PPG sensors are capable of providing accurate heart-rate (HR) by detecting the variations in the blood flow. Signals are acquired using wearable technology from a personal whereas not compromising comfort and privacy. The attributes of Heart Rate Variability are analyzed to describe emotions, namely happy, calm, unhappy (sad), and fear using Machine learning technology. We deployed this recognized emotion to automate the music system associated with its emotion. To bring this, we built an Android app to communicate with the smart wearable utilized. Totally 150 members from both genders have participated. The accuracy of 91.81% is achieved. This emotion recognition system can be used in various fields like robotics, medicine, virtual reality, and gaming, advertising, education, automotive working conditions and safety, home appliances.",https://ieeexplore.ieee.org/document/9419475/,"2021 Sixth International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)",25-27 March 2021,ieeexplore
10.1109/ROMAN.2013.6628436,Emotional evaluation of bandit problems,IEEE,Conferences,"In this paper, we discuss an approach to evaluate decisions made during a multi-armed bandit learning experiment. Usually, the results of machine learning algorithms applied on multi-armed bandit scenarios are rated in terms of earned reward and optimal decisions taken. These criteria are valuable for objective comparison in finite experiments. But learning algorithms used in real scenarios, for example in robotics, need to have instantaneous criteria to evaluate their actual decisions taken. To overcome this problem, in our approach each decision updates the Zürich model which emulates the human sense of feeling secure and aroused. Combining these two feelings results in an emotional evaluation of decision policies and could be used to model the emotional state of an intelligent agent.",https://ieeexplore.ieee.org/document/6628436/,2013 IEEE RO-MAN,26-29 Aug. 2013,ieeexplore
10.1109/ICRA48506.2021.9561889,End-to-End Semi-supervised Learning for Differentiable Particle Filters,IEEE,Conferences,"Recent advances in incorporating neural networks into particle filters provide the desired flexibility to apply particle filters in large-scale real-world applications. The dynamic and measurement models in this framework are learnable through the differentiable implementation of particle filters. Past efforts in optimising such models often require the knowledge of true states which can be expensive to obtain or even unavailable in practice. In this paper, in order to reduce the demand for annotated data, we present an end-to-end learning objective based upon the maximisation of a pseudo-likelihood function which can improve the estimation of states when large portion of true states are unknown. We assess performance of the proposed method in state estimation tasks in robotics with simulated and real-world datasets.",https://ieeexplore.ieee.org/document/9561889/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/SIEDS49339.2020.9106581,"Explorer51 – Indoor Mapping, Discovery, and Navigation for an Autonomous Mobile Robot",IEEE,Conferences,"The nexus of robotics, autonomous systems, and artificial intelligence (AI) has the potential to change the nature of human guided exploration of indoor and outdoor spaces. Such autonomous mobile robots can be incorporated into a variety of applications, ranging from logistics and maintenance, to intelligence gathering, surveillance, and reconnaissance (ISR). One such example is that of a tele-operator using the robot to generate a map of the inside of a building while discovering and tagging the objects of interest. During this process, the tele-operator can also assign an area for the robot to navigate autonomously or return to a previously marked area/object of interest. Search and rescue and ISR abilities could be immensely improved with such capabilities. The goal of this research is to prototype and demonstrate the above autonomous capabilities in a mobile ground robot called Explorer51. Objectives include: (i) enabling an operator to drive the robot non-line of sight to explore a space by incorporating a first-person view (FPV) system to stream data from the robot to the base station; (ii) implementing automatic collision avoidance to prevent the operator from running the robot into obstacles; (iii) creating and saving 2D and 3D maps of the space in real time by using a 2D laser scanner, tracking, and depth/RGB cameras; (iv) locating and tagging objects of interest as waypoints within the map; (v) autonomously navigate within the map to reach a chosen waypoint. To accomplish these goals, we are using the AION Robotics R1 Unmanned Ground Vehicle (UGV) rover as the platform for Explorer51 to demonstrate the autonomous features. The rover runs the Robot Operating System (ROS) onboard an NVIDIA Jetson TX2 board, connected to a Pixhawk controller. Sensors include a 2D scanning LiDAR, depth camera, tracking camera, and an IMU. Using existing ROS packages such as Cartographer and TEB planner, we plan to implement ROS nodes for accomplishing these tasks. We plan to extend the mapping ability of the rover using Visual Inertial Odometry (VIO) using the cameras. In addition, we will explore the implementation of additional features such as autonomous target identification, waypoint marking, collision avoidance, and iterative trajectory optimization. The project will culminate in a series of demonstrations to showcase the autonomous navigation, and tele-operation abilities of the robot. Success will be evaluated based on ease of use by the tele-operator, collision avoidance ability, autonomous waypoint navigation accuracy, and robust map creation at high driving speeds.",https://ieeexplore.ieee.org/document/9106581/,2020 Systems and Information Engineering Design Symposium (SIEDS),24-24 April 2020,ieeexplore
10.1109/ICECS49266.2020.9294790,FPGA Implementation of Simplified Spiking Neural Network,IEEE,Conferences,"Spiking Neural Networks (SNN) are third generation Artificial Neural Networks (ANN), which are close to the biological neural system. In recent years SNN has become popular in the area of robotics and embedded applications, therefore, it has become imperative to explore its real-time and energy-efficient implementations. SNNs are more powerful than their predecessors because of their ability to encode temporal information and to use biologically plausible plasticity rules. In this paper, a simpler and computationally efficient SNN model is described. The proposed model is implemented and validated utilizing a Xilinx Virtex 6 FPGA. It is demonstrated that the proposed model analyzes a fully connected network consisting of 800 neurons and 12,544 synapses in real-time.",https://ieeexplore.ieee.org/document/9294790/,"2020 27th IEEE International Conference on Electronics, Circuits and Systems (ICECS)",23-25 Nov. 2020,ieeexplore
10.1109/SACI.2007.375494,FPGA Parallel Implementation of CMAC Type Neural Network with on Chip Learning,IEEE,Conferences,"The hardware implementation of neural networks is a new step in the evolution and use of neural networks in practical applications. The CMAC cerebellar model articulation controller is intended especially for hardware implementation, and this type of network is used successfully in the areas of robotics and control, where the real time capabilities of the network are of particular importance. The implementation of neural networks on FPGA's has several benefits, with emphasis on parallelism and the real time capabilities. This paper discusses the hardware implementation of the CMAC type neural network, the architecture and parameters and the functional modules of the hardware implemented neuro-processor.",https://ieeexplore.ieee.org/document/4262496/,2007 4th International Symposium on Applied Computational Intelligence and Informatics,17 Yearly-18 May 2007,ieeexplore
10.1109/SBR-LARS.2012.57,Fixed-Point Neural Network Ensembles for Visual Navigation,IEEE,Conferences,"Visual navigation is an important research field in robotics because of the low cost and the high performance that is usually achieved by visual navigation systems. Pixel classification as a road pixel or a non-road pixel is a task that can be well performed by Artificial Neural Networks. In the case of real-time instances of the image classification problem, as when applied to autonomous vehicles navigation, it is interesting to achieve the best possible execution time. Hardware implementations of these systems can achieve fast execution times but the floating-point implementation of Neural Networks are commonly complex and resource intensive. This work presents the implementation and analysis of a fixed-point Neural Network Ensemble for image classification. The system is composed by six fixed-point Neural Networks verified with cross-validation technique, using some proposed voting schemes and analyzed considering the execution time, precision, memory consumption and accuracy for hardware implementation. The results show that the fixed-point implementation is faster, consumes less memory and has an acceptable precision compared to the floating-point implementation. This fact suggests that the fixed point implementation should be used in systems that need a fast execution time. Some questions about ensembles and voting have to be reviewed for fixed-point Neural Network Ensembles.",https://ieeexplore.ieee.org/document/6363361/,2012 Brazilian Robotics Symposium and Latin American Robotics Symposium,16-19 Oct. 2012,ieeexplore
10.1109/INDIN.2009.5195905,GPS and sonar based area mapping and navigation by mobile robots,IEEE,Conferences,"In this paper, we have presented a GPS and sonar based area mapping and navigation scheme for a mobile robot. A mapping is achieved between the GPS space and the world coordinates of the mobile robot which enables us to generate direct motion commands for it. This mapping enables the robot to navigate among different GPS locations within the mapped area. The GPS data is extracted online to get the latitude and longitude information of a particular location. In the training phase, a 2-D axis transformation is used to relate local robot frame with the robot world coordinates and then the actual world coordinates are mapped from the GPS data using a RBFN (radial basis function network) based Neural Network. In the second phase, direct GPS data is used to get the mapping into the world coordinates of mobile robot using the trained network and the motion commands are generated accordingly. The physical placement of sonar devices, their ranging limits and beam opening angles are considered during navigation for possible collision detection and obstacle avoidance. This scheme is successfully implemented in real time with Pioneer mobile robot from ActivMedia Robotics and GPS receiver. The scheme is also tested in the simulation to justify its application in the real world.",https://ieeexplore.ieee.org/document/5195905/,2009 7th IEEE International Conference on Industrial Informatics,23-26 June 2009,ieeexplore
10.1109/ICCICC50026.2020.9450269,Human Capability Augmentation through Cognitive and Autonomous Systems,IEEE,Conferences,"The Covid-19 pandemic reminds us again about our limited knowledge and understanding in the nature including both micro and macro worlds. We have been developing a variety of tools such as automation, robotics, internet, and artificial intelligence (AI), etc. to augment human capability for improved safety, quality, and productivity in work and life, but human lives are still vulnerable over 100 years since the last Spanish Flu in 1918. We are even more vulnerable when the tools we developed (e.g., automation and AI) do not understand human intent or follow human instructions. Recent accidents to the Boeing 737 Max passengers ring the alarm again about the imperative needs of appropriate design concepts and scientific methodologies for developing safety critical cognitive and/or autonomous systems or AI functions and collaborative partnership of human and intelligent systems. With AI and its related technologies reach their bottleneck, it is even more vital to follow scientific and systematic methodology to understand well about capacity and limitation of both human intelligence and machine intelligence so that their strengths can be optimized for a collaborative partnership when dealing with safety critical situations. This talk discusses about the needs for the researchers, designers, developers, and all practitioners who are interested in building and using 21st century human-autonomy symbiosis technologies (Why). It touches the topics of proper analytical methodologies for functional requirements of the intelligent systems, design methodologies, implementation strategies, evaluation approaches, and trusted relationships (How). These aspects will be explained with real-world examples when considering contextual constraints of technology, human capability and limitations, and functionalities that AI and autonomous systems should achieve (When). Audience will gain insights of context-based and interaction-centered design approach for developing a safe, trusted, and collaborative partnership between human and technology by optimizing the interaction between human intelligence and AI. The challenges and potential issues will also be discussed for guiding future research and development activities when augmenting human capabilities with AI, and cognitive and/or autonomous systems.",https://ieeexplore.ieee.org/document/9450269/,2020 IEEE 19th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC),26-28 Sept. 2020,ieeexplore
10.1109/ROBIO.2011.6181717,Human-like gradual multi-agent Q-learning using the concept of behavior-based robotics for autonomous exploration,IEEE,Conferences,"In the last few years, the field of mobile robotics has made lots of advancements. These advancements are due to the extensive application of mobile robots for autonomous exploration. Mobile robots are being popularly used for applications in space, underwater explorations, underground coal mines monitoring, inspection in chemical/toxic/ nuclear factories etc. But if these environments are unknown/unpredictable, conventional/ classical robotics may not serve the purpose. In such cases robot learning is the best option. Learning from the past experiences, is one such way for real time application of robots for completely unknown environments. Reinforcement learning is one of the best learning methods for robots using a constant system-environment interaction. Both single and multi-agent concepts are available for implementation of learning. The current research work describes a multi-agent based reinforcement learning using the concept of behaviour-based robotics for autonomous exploration of mobile robots. The concept has also been tested both in indoor and outdoor environments using real-time robots.",https://ieeexplore.ieee.org/document/6181717/,2011 IEEE International Conference on Robotics and Biomimetics,7-11 Dec. 2011,ieeexplore
10.1109/HUMANOIDS.2017.8246941,Human-robot interaction assessment using dynamic engagement profiles,IEEE,Conferences,"This paper addresses the use of convolutional neural networks for image analysis resulting in an engagement metric that can be used to assess the quality of human robot interactions. We propose a method based on a pretrained convolutional network able to map emotions onto a continuous [0-1] interval, where 0 represents disengaged and 1 fully engaged. The network shows a good accuracy at recognizing the engagement state of humans given positive emotions. A time based analysis of interaction experiments between small humanoid robots and humans provides time series of engagement estimates, which are further used to understand the nature of the interaction as well as the overall mood and interest of the participant during the experiment. The method allows a real-time implementation and supports a quantitative and qualitative assessment of a human robot interaction with respect to a positive engagement and is applicable to humanoid robotics as well as other related contexts.",https://ieeexplore.ieee.org/document/8246941/,2017 IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids),15-17 Nov. 2017,ieeexplore
10.1109/ICECCME52200.2021.9590955,Impact of Real-World Market Conditions on Returns of Deep Learning based Trading Strategies,IEEE,Conferences,"Based on recent advancements in natural language processing, computer vision and robotics, a growing number of researchers and traders attempt to predict future asset prices using deep learning techniques. Typically, the goal is to find a profitable and at the same time low-risk trading strategy. However, it is not straightforward to evaluate a found trading strategy. Evaluating solely on historic price data neglects important factors arising in real markets. In this paper, we analyze the impact of real-world market conditions in terms of trading fees, borrow interests, slippage and spreads on trading returns. For that, we propose a deep learning trading bot based on Temporal Convolutional Networks, which is deployed to a real cryptocurrency exchange. We compare the results obtained in the real market with simulated returns and investigate the impact of the different real-world market conditions. Our results show that besides trading fees (which have the biggest impact on returns), factors like slippage and spread also affect the returns of the trading strategy.",https://ieeexplore.ieee.org/document/9590955/,"2021 International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME)",7-8 Oct. 2021,ieeexplore
10.1109/ACC.2014.6859431,"Implementation of an adaptive, model free, learning controller on the Atlas robot",IEEE,Conferences,"Recent events in natural and man-made disasters have highlighted the limitation in man's ability to confine and mitigate damage in such scenarios. Therefore, there is an urgent need for robotic technology that can function in all environments and serve as a substitute to humans in disaster scenarios. This paper presents research efforts to advance walking technology of humanoid robots with application to the Boston Dynamics Atlas robot. The Atlas was designed as part of the DARPA Robotics Challenge (DRC). The paper contribution is in a model free, walking trajectory tracking controller that is tested using GAZEBO robotics simulator. Artificial neural networks are used to learn the robot's nonlinear dynamics on the fly using a neuroadaptive control algorithm. The learned nonlinear dynamics are utilized along with a filtered error signal to generate input torques to control the system. Results show that the ability to approximate the robot nonlinear dynamics allows for full-body control without the need of modeling such a complex system. This ability is what makes the control scheme utilized appealing for complex, real-life, robotic applications that occur in a non-laboratory setting.",https://ieeexplore.ieee.org/document/6859431/,2014 American Control Conference,4-6 June 2014,ieeexplore
10.1109/FIE.2006.322407,Incorporating an Affective Model to an Intelligent Tutor for Mobile Robotics,IEEE,Conferences,"Emotions have been identified as important players in motivation, and motivation is very important for learning. When a tutor recognizes the affective state of the student and responds accordingly, the tutor may be able to motivate students and improve the learning process. We propose a general affective behavior model which integrates information from the student's pedagogical state, affective state, and the tutorial situation, to decide the best tutorial action, considering the tutor preferences from a pedagogical and affective point of view. Our proposal is based on emotions models, personality theories and teachers' expertise. The affective model is implemented as a dynamic decision network, with utility measures on both learning and motivation, and is being incorporated to an intelligent tutor within a virtual laboratory for learning mobile robotics. This paper presents preliminary results in the construction of the affective behavior model",https://ieeexplore.ieee.org/document/4116913/,Proceedings. Frontiers in Education. 36th Annual Conference,27-31 Oct. 2006,ieeexplore
10.1109/DEVLRN.2014.6983001,Incremental training of Restricted Boltzmann Machines using information driven saccades,IEEE,Conferences,"In the context of developmental robotics, a robot has to cope with complex sensorimotor spaces by reducing their dimensionality. In the case of sensor space reduction, classical approaches for pattern recognition use either hardcoded feature detection or supervised learning. We believe supervised learning and hard-coded feature extraction must be extended with unsupervised learning of feature representations. In this paper, we present an approach to learn representations using space-variant images and saccades. The saccades are driven by a measure of quantity of information in the visual scene, emerging from the activations of Restricted Boltzmann Machines (RBMs). The RBM, a generative model, is trained incrementally on locations where the system saccades. Our approach is implemented using real data captured by a NAO robot in indoor conditions.",https://ieeexplore.ieee.org/document/6983001/,4th International Conference on Development and Learning and on Epigenetic Robotics,13-16 Oct. 2014,ieeexplore
10.1109/CASE48305.2020.9216902,Industrial Robot Grasping with Deep Learning using a Programmable Logic Controller (PLC),IEEE,Conferences,"Universal grasping of a diverse range of previously unseen objects from heaps is a grand challenge in e-commerce order fulfillment, manufacturing, and home service robotics. Recently, deep learning based grasping approaches have demonstrated results that make them increasingly interesting for industrial deployments. This paper explores the problem from an automation systems point-of-view. We develop a robotics grasping system using Dex-Net, which is fully integrated at the controller level. Two neural networks are deployed on a novel industrial AI hardware acceleration module close to a PLC with a power footprint of less than 10 W for the overall system. The software is tightly integrated with the hardware allowing for fast and efficient data processing and real-time communication. The success rate of grasping an object form a bin is up to 95% with more than 350 picks per hour, if object and receptive bins are in close proximity. The system was presented at the Hannover Fair 2019 (world's largest industrial trade fair) and other events, where it performed over 5,000 grasps per event.",https://ieeexplore.ieee.org/document/9216902/,2020 IEEE 16th International Conference on Automation Science and Engineering (CASE),20-21 Aug. 2020,ieeexplore
10.1109/ICYCS.2008.34,Influence Graph based Task Decomposition and State Abstraction in Reinforcement Learning,IEEE,Conferences,"Task decomposition and state abstraction are crucial parts in reinforcement learning. It allows an agent to ignore aspects of its current states that are irrelevant to its current decision, and therefore speeds up dynamic programming and learning. This paper presents the SVI algorithm that uses a dynamic Bayesian network model to construct an influence graph that indicates relationships between state variables. SVI performs state abstraction for each subtask by ignoring irrelevant state variables and lower level subtasks. Experiment results show that the decomposition of tasks introduced by SVI can significantly accelerate constructing a near-optimal policy. This general framework can be applied to a broad spectrum of complex real world problems such as robotics, industrial manufacturing, games and others.",https://ieeexplore.ieee.org/document/4708962/,2008 The 9th International Conference for Young Computer Scientists,18-21 Nov. 2008,ieeexplore
10.1109/CADCG.2007.4407908,Intelligent Robotic Peg-in-Hole Insertion Learning Based on Haptic Virtual Environment,IEEE,Conferences,A new approach is explored to transfer human manipulation skills to a robotics system. A skill acquisition algorithm utilizes the position and contact force/torque data generated in the virtual environment combined with a priori knowledge about the task to generate the skills required to perform such a task. Such skills are translated into actual robotic trajectories for implementation in real time. The peg-in-hole insertion problem is used as a case study. The results are reported.,https://ieeexplore.ieee.org/document/4407908/,2007 10th IEEE International Conference on Computer-Aided Design and Computer Graphics,15-18 Oct. 2007,ieeexplore
10.1109/CIMCA.2006.133,International Conference on Computational Inteligence for Modelling Control and Automation and International Conference on Intelligent Agents Web Technologies and International Commerce - Title,IEEE,Conferences,"The following topics are dealt with: intelligent agents and ontologies; data mining, knowledge discovery and decision making; intelligent systems; Web technologies and Web services; virtual reality and games; image processing and image understanding techniques; adaptive control and automation; modelling, prediction and control; multi-agent systems and computational intelligence; agent systems, personal assistant agents and profiling; fuzzy systems for industrial automation; control strategies; neural network applications; clustering, classification, data mining and risk analysis; dynamics systems; innovative control systems, hardware design and implementation; robotics and automation; e-business, e-commerce, innovative Web applications; Web databases; diagnosis and medical applications; learning systems; optimization, hybrid systems, genetic algorithms and evolutionary computation control applications; online learning and ERP; knowledge acquisition and classification; nanomechatronics; simulation and control; mobile network applications; information retrieval; Bayesian networks; human computer interaction; cognitive science; mobile agents; knowledge management; intelligent control; e-search and navigation; security.",https://ieeexplore.ieee.org/document/4052645/,2006 International Conference on Computational Inteligence for Modelling Control and Automation and International Conference on Intelligent Agents Web Technologies and International Commerce (CIMCA'06),28 Nov.-1 Dec. 2006,ieeexplore
10.1109/IROS.2010.5649358,LCM: Lightweight Communications and Marshalling,IEEE,Conferences,"We describe the Lightweight Communications and Marshalling (LCM) library for message passing and data marshalling. The primary goal of LCM is to simplify the development of low-latency message passing systems, especially for real-time robotics research applications. Messages can be transmitted between different processes using LCM's publish/subscribe message-passing system. A platformand language-independent type specification language separates message description from implementation. Message specifications are automatically compiled into language-specific bindings, eliminating the need for users to implement marshalling code while guaranteeing run-time type safety. LCM is notable in providing a real-time deep traffic inspection tool that can decode and display message traffic with minimal user effort and no impact on overall system performance. This and other features emphasize LCM's focus on simplifying both the development and debugging of message passing systems. In this paper, we explain the design of LCM, evaluate its performance, and describe its application to a number of autonomous land, underwater, and aerial robots.",https://ieeexplore.ieee.org/document/5649358/,2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,18-22 Oct. 2010,ieeexplore
10.1109/OCEANS.2018.8604686,Learned Anticipation Strategy on Complex Behaviors and as an Approach to Generalization Behavior for the Coordination of an AUV Fleet,IEEE,Conferences,"Anticipation is natural behavior seen in certain organisms when they try to adapt their behavior to create an accurate reaction to an event that will happen in the future based on sequential information that extracted from the environment and other organisms. Anticipation has been studied from both the human and the animal perspectives and science has been taking some of these ideas to implement this behavior in machines. Research and studies of anticipation using Artificial Intelligence (AI) methods has been growing during the past years within different fields, including Robotics, Stock Market, Weather Forecast, Social Media, among others. At the University of Idaho, we have been focusing on studying Anticipation using Autonomous Underwater Vehicles (AUV). This paper analyzes the impact on coordination of including an anticipation module to adapt to complex behaviors and to make decisions based on generalization while running as part of a simulation of a fleet of AUVs following a magnetic signature assessment (MSA) task. During this task, a moving Target Ship (TS) shares information about its behavior with the fleet of AUVs while the fleet tries to maintain formation and reach a designated meeting point at the same time as the TS. The TS behaviors include sudden and/or complex changes in movement during the experiment. These changes in the TS's movement make it difficult for the AUVs to reach the meeting point at the same time as the TS without additional information. Progress messages from the TS are used by the AUVs to adjust their behavior, but the messages may be sparse. A portion of the data that represents the TS's behavior was used as training data for the anticipation module in the AUVs. The remaining data was used as brand new cases that the anticipation module would try to solve to encourage generalization. Generalization occurs when the robot can solve a task that it was not trained for, but there was sufficient training data to result in reasonable solutions. For these experiments, the messages that are sent by the TS to the AUVs report the TS's progress to the goal. The TS reports its progress using Fuzzy set membership values. This strategy is used to model real-world situations where progress cannot be defined with exact values. The membership values are represented by fuzzy sets including On Schedule, Behind Schedule, Ahead of Schedule, etc. This strategy gives a more human-like approach to the AUVs for decision making because humans often say things like “I'm a little behind schedule”. The anticipation module works as an aid for the communication between the TS and the fleet of AUVs. It tries to keep the fleet running on track and synchronized with the TS behavior by filling in missing messages with an anticipated message. In this research it is assumed that missing and corrupt messages occur because of a noisy or low-bandwidth communications. The experiments simulate this condition by sending messages more infrequently. The TS stops broadcasting messages for a specific time period that has been selected before starting the test. Versions of the anticipation module, using a Neural Network model and a Fuzzy Logic model were tested. To have comparable results, the position of the meeting point is constant during each experiment and is used as a point of reference. The effectiveness of the anticipation module was evaluated by measuring the distance between the actual meeting point of the fleet of AUVs and the TS and the desired meeting point. In general the anticipation module reduced the error significantly. This included the tests using the novel behaviors that were not part of the training set. These last results lead to the idea that, with the right training data, the AUVs are displaying generalization behavior. In general, the anticipation module helps the fleet of AUVs to infer the behavior of the TS and they synchronize to the TS even when there was a lack of information, caused by missing messages.",https://ieeexplore.ieee.org/document/8604686/,OCEANS 2018 MTS/IEEE Charleston,22-25 Oct. 2018,ieeexplore
10.1109/ISIE.2007.4374932,Learning Wall Following Behaviour in Robotics through Reinforcement and Image-based States,IEEE,Conferences,"In this work, a visual and reactive wall following behaviour is learned by reinforcement. With artificial vision the environment is perceived in 3D, and it is possible to avoid obstacles that are invisible to other sensors that are more common in mobile robotics. Reinforcement learning reduces the need for intervention in behaviour design, and simplifies its adjustment to the environment, the robot and the task. In order to facilitate its generalization to other behaviours and to reduce the role of the designer, we propose a regular image-based codification of states. Even though this is much more difficult, our implementation converges and is robust. Results are presented with a Pioneer 2 AT. Learning phase has been realized on the Gazebo 3D simulator and the test phase has been proved in simulated and real environments to demonstrate the correct design and robustness of our algorithms.",https://ieeexplore.ieee.org/document/4374932/,2007 IEEE International Symposium on Industrial Electronics,4-7 June 2007,ieeexplore
10.23919/ACC.1992.4792313,Learning for Skill Acquisition and Refinement: Toward Exploring Everyday Physics,IEEE,Conferences,"The present talk claims that ""robotics"" is not a test bed for AI but should involve a research frontier, which attempts to account for intelligibility of everyday physics underlying human activities such as perception, remembrance, planning, practices, and skill. In addition to traditional AI and neuro-network approaches, more of new domains that can account for any aspect of human intellectual behaviors must be exploited, and also more of new tools that actualize real implementation of intelligence in machines need to be devised. To aim at going on an expedition in this direction, this talk introduces one new domain and another new tool. The former is practice-based learning for skill refinement and the latter is a design tool of signal-based structured information base for skill acquirement.",https://ieeexplore.ieee.org/document/4792313/,1992 American Control Conference,24-26 June 1992,ieeexplore
10.1109/IROS.1991.174419,Learning for skill refinement,IEEE,Conferences,"It is claimed that 'robotics' is not a test bed for AI but should involve a research frontier relating to the physics underlying human activities such as perception, remembering, planning, practice, and skill. In addition to traditional AI and neural network approaches, other domains that can account for any aspect of human intellectual behavior must be exploited, and tools that actualize real implementation of intelligence in machines need to be devised. A practice-based learning domain for skill refinement and a design tool for a signal-based structured information base for skill acquisition are presented.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174419/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/ICIP.2019.8803544,Lightweight Monocular Depth Estimation Model by Joint End-to-End Filter Pruning,IEEE,Conferences,"Convolutional neural networks (CNNs) have emerged as the state-of-the-art in multiple vision tasks including depth estimation. However, memory and computing power requirements remain as challenges to be tackled in these models. Monocular depth estimation has significant use in robotics and virtual reality that requires deployment on low-end devices. Training a small model from scratch results in a significant drop in accuracy and it does not benefit from pre-trained large models. Motivated by the literature of model pruning, we propose a lightweight monocular depth model obtained from a large trained model. This is achieved by removing the least important features with a novel joint end-to-end filter pruning. We propose to learn a binary mask for each filter to decide whether to drop the filter or not. These masks are trained jointly to exploit relations between filters at different layers as well as redundancy within the same layer. We show that we can achieve around 5x compression rate with small drop in accuracy on the KITTI driving dataset. We also show that masking can improve accuracy over the baseline with fewer parameters, even without enforcing compression loss.",https://ieeexplore.ieee.org/document/8803544/,2019 IEEE International Conference on Image Processing (ICIP),22-25 Sept. 2019,ieeexplore
10.1109/CVPRW.2019.00218,Live Demonstration: Digit Recognition on Pixel Processor Arrays,IEEE,Conferences,"In this demo, we will showcase recent work on implementing convolutional neural networks directly on pixel processor arrays (PPA). As CNNs demonstrate enhanced performance across tasks from classification to image synthesis, it becomes essential to find the most adequate ways to realize them especially for embedded, real-time and reactive tasks in areas across Computer Vision and Robotics. The PPA concept is one architecture that pairs sensing and massively parallel processing at the focal plane level and allow mid to high level tasks to be run wholly embedded within them. They allow operation at high framerates and low energy consumption (≤ 2W), and without the need for external signal interpretation or processing. In this demo we will showcase our recent work on the implementation of CNNs on the SCAMP5 architecture [2] as a step towards true end-to-end operation on flexibly programmable PPA hardware. In particular, we will showcase live how our modifications to CNNs allow them to run tasks such as handwritten number classification from image capture to classification wholly embedded on the PPA.",https://ieeexplore.ieee.org/document/9025698/,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),16-17 June 2019,ieeexplore
10.1109/IROS.2004.1389735,Localization for robot mowers covering unmarked operational area,IEEE,Conferences,"The accurate localization is significant for both the accurate terrain acquisition and the successful area covering. Our research aims at the operational area without any manmade marks, the robot utilizes its localization system to establish the digital boundaries of the unmarked operational area. According to the specialties of outdoor environment and the practical mowing requirements, the localization system with combined sensors and the localization algorithm based on neural network are designed. The results of experiment show that the designed neural network can make the accuracy of the localization well improved. With the measurements of the ultrasonic sensors, an effective error-correction method based on the database of environmental features knowledge is proposed for the robot mower to correct its position errors in the real-time coverage operation. The localization information is reliable to ensure the intelligent behaviors of the robot mower. The technical presentations in this paper can facilitate the development of the environmental robotics.",https://ieeexplore.ieee.org/document/1389735/,2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),28 Sept.-2 Oct. 2004,ieeexplore
10.1109/ICM48031.2019.9021904,Low power CNN hardware FPGA implementation,IEEE,Conferences,"A convolution Neural Networks (CNN) goes under the wide umbrella of Deep Neural Networks (DNN) whose applications are widely used. For example, the later are used in robotics and different applications of recognition like speech recognition and facial recognition, also nowadays in autonomous cars. Therefore the aim of implementing the CNN is to be used in real time applications. As a result of that, Graphics processing units (GPUs) are used but their worst disadvantage is it's high power consumption which can't be used in daily used equipments. The target of this paper is to solve the power consumption problem by using Field Programmable Array (FPGA) which has low power consumption, and flexible architecture. The implementation architecture of Alex Network, which consists of three fully connected layers and five convolution layers, on FPGA will depend on two main techniques parallelism of resources, and pipelining inside of some layers.",https://ieeexplore.ieee.org/document/9021904/,2019 31st International Conference on Microelectronics (ICM),15-18 Dec. 2019,ieeexplore
10.1109/CCWC.2017.7868418,"Low-cost, real-time obstacle avoidance for mobile robots",IEEE,Conferences,"The goal of this project<sup>1</sup> is to advance the field of automation and robotics by utilizing recently-released, low-cost sensors and microprocessors to develop a mechanism that provides depth-perception and autonomous obstacle avoidance in a plug-and-play fashion. We describe the essential hardware components that can enable such a low-cost solution and an algorithm to avoid static obstacles present in the environment. The mechanism utilizes a novel single-point LIDAR module that affords more robustness and invariance than popular approaches, such as Neural Networks and Stereo. When this hardware is coupled with the proposed efficient obstacle avoidance algorithm, this mechanism is able to accurately represent environments through point clouds and construct obstacle-free paths to a destination, in a small timeframe. A prototype mechanism has been installed on a quadcopter for visualization on how actual implementation may take place<sup>2</sup>. We describe experimental results based on this prototype.",https://ieeexplore.ieee.org/document/7868418/,2017 IEEE 7th Annual Computing and Communication Workshop and Conference (CCWC),9-11 Jan. 2017,ieeexplore
10.1109/ROBIO.2018.8665318,Manipulation Related EEG Brainwave Feature Extraction and Events Recognition for Robotics Learning Applications,IEEE,Conferences,"This research is directed to the application of pattern recognition techniques (PCA), for understanding waves patterns resulting from brain Electroencephalography (EEG). The EEG brainwaves are resulting from specific human hand fingers movements, for a defined task. The adopted technique involved four main computational stages. First, EEG dataset collection for a defined grasping task, Luciw et. al. [1]. Secondly, it was a filtration and multi-signals signals conditioning of such multi-dimensional EEG wave sets. Thirdly, dimensionality reduction of the EEG patterns, hence capturing main EEG waves features. Finally, last stage involved using of pattern recognition and classification algorithms for classification of diverse grasping events. Events classification was based on analysis of set of EEG related patterns, then to correlate such patterns with real word experiment fingers movements. The adopted technique is useful in terms of understanding EEG related and hidden patterns, that are useful for a number of robotics direct or indirect learning applications.",https://ieeexplore.ieee.org/document/8665318/,2018 IEEE International Conference on Robotics and Biomimetics (ROBIO),12-15 Dec. 2018,ieeexplore
10.1109/CVPRW53098.2021.00141,MarkerPose: Robust Real-time Planar Target Tracking for Accurate Stereo Pose Estimation,IEEE,Conferences,"Despite the attention marker-less pose estimation has attracted in recent years, marker-based approaches still provide unbeatable accuracy under controlled environmental conditions. Thus, they are used in many fields such as robotics or biomedical applications but are primarily implemented through classical approaches, which require lots of heuristics and parameter tuning for reliable performance under different environments. In this work, we propose MarkerPose, a robust, real-time pose estimation system based on a planar target of three circles and a stereo vision system. MarkerPose is meant for high-accuracy pose estimation applications. Our method consists of two deep neural networks for marker point detection. A SuperPoint-like network for pixel-level accuracy keypoint localization and classification, and we introduce EllipSegNet, a lightweight ellipse segmentation network for sub-pixel-level accuracy keypoint detection. The marker’s pose is estimated through stereo triangulation. The target point detection is robust to low lighting and motion blur conditions. We compared MarkerPose with a detection method based on classical computer vision techniques using a robotic arm for validation. The results show our method provides better accuracy than the classical technique. Finally, we demonstrate the suitability of MarkerPose in a 3D freehand ultrasound system, which is an application where highly accurate pose estimation is required. Code is available in Python and C++ at https://github.com/jhacsonmeza/MarkerPose.",https://ieeexplore.ieee.org/document/9523117/,2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),19-25 June 2021,ieeexplore
10.1109/IECON.2012.6389520,Matlab/Simulink software implementation and interfacing of a strap-down inertial attitude method,IEEE,Conferences,"The paper presents a software tool used to calculate the angular attitude of a vehicle starting from the readings of a strap-down gyro triad. Firstly, the problem statement is presented and the implied mathematical equations are shown. The theoretical model is based on the discretized form of a matrix differential equation solution, and focuses on its first six truncation order. In order to have an easier communication between the user and the software, especially in the off-line data processing applications, a Graphical User Interface is developed. The obtained software is validated by using an integrated INS/GPS navigation system as reference system, the inputs of our software being the outputs of the gyro sensors in the strap-down INS. The tool can be used in all strap-down inertial systems application fields like aerospace, naval and automotive navigation, robotics, as well as in medicine surgery. Also, the developed software can be used in the real time applications or in the off-line processing of the navigation inertial sensors recorded data.",https://ieeexplore.ieee.org/document/6389520/,IECON 2012 - 38th Annual Conference on IEEE Industrial Electronics Society,25-28 Oct. 2012,ieeexplore
10.1109/PUNECON.2018.8745403,Military Surveillance Robot Implementation Using Robot Operating System,IEEE,Conferences,"Robots are becoming more and more prevalent in many real world scenarios. Housekeeping, medical aid, human assistance are a few common implementations of robots. Military and Security are also major areas where robotics is being researched and implemented. Robots with the purpose of surveillance in war zones and terrorist scenarios need specific functionalities to perform their tasks with precision and efficiency. In this paper, we present a model of Military Surveillance Robot developed using Robot Operating System. The map generation based on Kinect sensor is presented and some test case scenarios are discussed with results.",https://ieeexplore.ieee.org/document/8745403/,2018 IEEE Punecon,30 Nov.-2 Dec. 2018,ieeexplore
10.1109/VRAIS.1995.512486,Model based vision as feedback for virtual reality robotics environments,IEEE,Conferences,"Task definition methods for robotic systems are often difficult to use. The ""on-line"" programming methods are often time expensive or risky for the human operator or the robot itself. On the other hand, ""off-line"" techniques are tedious and complex. In addition operator training is costly and time consuming. In a Virtual Reality Robotics Environment (VRRE), users are not asked to write down complicated functions, but can operate complex robotic systems in an intuitive and cost-effective way. However a VRRE is only effective if all the environment changes and object movements are fed-back to the virtual manipulating system. The paper describes the use of a VRRE for a semi-autonomous robot system comprising an industrial 5-axis robot, its virtual equivalent and a model based vision system used as feed-back. The user is immersed in a 3-D space built out of models of the robot's environment. He directly interacts with the virtual ""components"", defining tasks and dynamically optimizing them. A model based vision system locates objects in the real workspace to update the VRRE through a bi-directional communication link. In order to enhance the capabilities of the VRRE, a reflex-type behavior based on vision has been implemented. By locally (independently of the VRRE) controlling the real robot, the operator is discharged of small environmental changes due to transmission delays. Thus once the tasks have been optimized on the VRRE, they are sent to the real robot and a semi autonomous process ensures their correct execution thanks to a camera directly mounted on the robot's end effector. On the other hand if the environmental changes are too important, the robot stops, re-actualizes the VRRE with the new environmental configuration, and waits for task redesign. Because the operator interacts with the robotic system at a task oriented high level, VRRE systems are easily portable to other robotics environments (mobile robotics and micro assembly).",https://ieeexplore.ieee.org/document/512486/,Proceedings Virtual Reality Annual International Symposium '95,11-15 March 1995,ieeexplore
10.1109/OCEANS.1998.724376,Model development of an underwater manipulator for coordinated arm-vehicle control,IEEE,Conferences,"This paper presents research on the hydrodynamic modeling of a manipulator for an autonomous underwater scientific vehicle. The focus is on improving the modeling accuracy of the in-line hydrodynamic coupling between a two-link manipulator and a small, free-floating vehicle in order to achieve better control for coordinated motion of the combined system. Loads predicted using existing models for underwater arms were determined to be off by as much as 25% when applied to a real, two-link arm in a test tank. In this new approach, an experimentally-determined model has been developed that takes into account the 3D flow effects that have previously not been included. The end result is a model that provides accurate predictions for the joint torques of a two-link arm in a form simple enough to be implemented in algorithms for precision planning and control. This project is part of a joint program between the Aerospace Robotics Laboratory at Stanford University and the Monterey Bay Aquarium Research Institute.",https://ieeexplore.ieee.org/document/724376/,IEEE Oceanic Engineering Society. OCEANS'98. Conference Proceedings (Cat. No.98CH36259),28 Sept.-1 Oct. 1998,ieeexplore
10.1109/AIKE48582.2020.00041,Multi-Agent Pathfinding with Hierarchical Evolutionary Hueristic A,IEEE,Conferences,"Multiagent pathfinding (MAPF) problem is an important topic to various domains including video games, robotics, logistics, and crowd simulation. The goal of a pathfinding algorithm for MAPF is to find the shortest possible path for each agent without collisions with other agents. Search is among the most fundamental techniques for problem solving, and A* is the best known heuristic search algorithm. While A* guarantees to find the shortest path using a heuristic function, it cannot handle the large scale and many uncertainties in MAPF. The main challenge of MAPF is the scalability. The problem complexity grows exponentially as both the size of environments and the number of autonomous agents increase, which becomes more difficult for A* to compute results in real time under the constraints of memory and computing resources. To overcome the challenges in MAPF, distributed approaches are introduced to reduce the computational time and complexity. Contrast to centralized approaches, which use a single controller to determine every move of all agents, distributed approaches allow each agent to search for its own solution. Distributed MAPF algorithms need to refine solutions for all agents that are collision-free. The algorithm should lead agents to take another path, or standby on the same node at the moment, to avoid conflicts between any two paths. Under the circumstances, an optimal solution is no longer simply finding the shortest path for each agent. Instead, it should contain a collision-free path for every agent, with the lowest makespan, which is the number of time steps required for all agents to reach their target. However, minimizing the makespan and the sum of cost for all agents is a NP-hard problem. Given MAPF problems often require to be solved in real time with limited resources, minimizing only the makespan is a more practical approach.To achieve accurate search and high scalability, a MAPF algorithm must fulfill the following requirements: 1) it is capable to compute collision-free paths for all agents; 2) it can provides an accurate priority decision mechanism to ensure solution optimality; and 3) it should maintain the successful rate to obtain a solution as the number of agents increases. In this paper, we proposed a novel hierarchical pathfinding technique named Multi-Agent Hierarchical Evolutionary Heuristics A* (MA-HEHA*). Our contributions in this paper are: 1) we propose MA-HEHA* that can identify bottleneck areas to reduce collisions in abstract search; 2) our algorithm evolves heuristic functions by itself to avoid potential conflicts during local search; 3) we prove that MA-HEHA* maintain high successful rate when the scalability is high; 4) we evaluate MA-HEHA* on different types of MAPF problems to show its effectiveness. Our experiment results show that our MA-HEHA* can efficiently solve large scale MAPF problems compared to traditional MAPF approaches.",https://ieeexplore.ieee.org/document/9355477/,2020 IEEE Third International Conference on Artificial Intelligence and Knowledge Engineering (AIKE),9-13 Dec. 2020,ieeexplore
10.1109/SSCI.2016.7850240,Multi-Channel Bayesian ART for robot fusion perception,IEEE,Conferences,"Multiple sensor data fusion is the technique of associate information from a number of different sensors to produce a robust and comprehensive description. Data fusion pose is using in various robotics application such as environment mapping, object recognition and robot localization. Their relation is generally hard coded and difficult to learn incrementally if new objects or events arise. In this paper, we propose a new learning architecture termed as Multi-Channel Bayesian ART which is very flexible can be adapted to new domains or different sensor configurations easily. The other advantages of the proposed method are: (1) it is capable of incremental on-line learning without forgetting previously-learned knowledge (2) It can process data real time and does not require any prior training to make it work in natural environment. The effectiveness of our proposed method is validated by real experimental results implemented on robot.",https://ieeexplore.ieee.org/document/7850240/,2016 IEEE Symposium Series on Computational Intelligence (SSCI),6-9 Dec. 2016,ieeexplore
10.1109/ICTAI50040.2020.00088,Multi-Robot Collision Avoidance with Map-based Deep Reinforcement Learning,IEEE,Conferences,"Multi-robot collision avoidance in a communication-free environment is one of the key issues for mobile robotics and autonomous driving. In this paper, we propose a map-based deep reinforcement learning (DRL) approach for collision avoidance of multiple robots, where robots do not communicate with each other and only sense other robots' positions and the obstacles around them. We use the egocentric grid map of a robot to represent the environmental information around it, which can be easily generated by using multiple sensors or sensor fusion. The learned policy generated from the DRL model directly maps 3 frames of egocentric grid maps and the robot's relative local goal positions into low-level robot control commands. We first train a convolutional neural network for the navigation policy in a simulator of multiple mobile robots using proximal policy optimization (PPO). Then we deploy the trained model to real robots to perform collision avoidance in their navigation. We evaluate the approach with various scenarios both in the simulator and on three differential-drive mobile robots in the real world. Both qualitative and quantitative experiments show that our approach is efficient with a high success rate. The demonstration video can be found at https://youtu.be/jcLKlEXuFuk.",https://ieeexplore.ieee.org/document/9288300/,2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI),9-11 Nov. 2020,ieeexplore
10.1109/IROS45743.2020.9341372,Multiplicative Controller Fusion: Leveraging Algorithmic Priors for Sample-efficient Reinforcement Learning and Safe Sim-To-Real Transfer,IEEE,Conferences,"Learning-based approaches often outperform hand-coded algorithmic solutions for many problems in robotics. However, learning long-horizon tasks on real robot hardware can be intractable, and transferring a learned policy from simulation to reality is still extremely challenging. We present a novel approach to model-free reinforcement learning that can leverage existing sub-optimal solutions as an algorithmic prior during training and deployment. During training, our gated fusion approach enables the prior to guide the initial stages of exploration, increasing sample-efficiency and enabling learning from sparse long-horizon reward signals. Importantly, the policy can learn to improve beyond the performance of the sub-optimal prior since the prior's influence is annealed gradually. During deployment, the policy's uncertainty provides a reliable strategy for transferring a simulation-trained policy to the real world by falling back to the prior controller in uncertain states. We show the efficacy of our Multiplicative Controller Fusion approach on the task of robot navigation and demonstrate safe transfer from simulation to the real world without any fine-tuning. The code for this project is made publicly available at https://sites.google.com/view/mcf-nav/home.",https://ieeexplore.ieee.org/document/9341372/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ICUAS.2016.7502665,Natural user interfaces for human-drone multi-modal interaction,IEEE,Conferences,"Personal drones are becoming part of every day life. To fully integrate them into society, it is crucial to design safe and intuitive ways to interact with these aerial systems. The recent advances on User-Centered Design (UCD) applied to Natural User Interfaces (NUIs) intend to make use of human innate features, such as speech, gestures and vision to interact with technology in the way humans would with one another. In this paper, a Graphical User Interface (GUI) and several NUI methods are studied and implemented, along with computer vision techniques, in a single software framework for aerial robotics called Aerostack which allows for intuitive and natural human-quadrotor interaction in indoor GPS-denied environments. These strategies include speech, body position, hand gesture and visual marker interactions used to directly command tasks to the drone. The NUIs presented are based on devices like the Leap Motion Controller, microphones and small size monocular on-board cameras which are unnoticeable to the user. Thanks to this UCD perspective, the users can choose the most intuitive and effective type of interaction for their application. Additionally, the strategies proposed allow for multi-modal interaction between multiple users and the drone by being able to integrate several of these interfaces in one single application as is shown in various real flight experiments performed with non-expert users.",https://ieeexplore.ieee.org/document/7502665/,2016 International Conference on Unmanned Aircraft Systems (ICUAS),7-10 June 2016,ieeexplore
10.1109/ITNG.2011.116,Nerve: A Lightweight Middleware for Quality-of-service Networked Robotics,IEEE,Conferences,"Social robots must adapt to dynamic environments, human interaction partners and challenging new stringent tasks. Their inner software should be designed and deployed carefully because slight changes in the robot's requirements can have an important impact in the existing code. This paper focus on the design and implementation of a lightweight middleware for networked robotics called \textit{Nerve}, which guarantees the scalability and quality-of-service requirements for this kind of real-time software. Its benefits have been proved through its use in a Robot Learning by Imitation control architecture, but its design guidelines are general enough to be also applied with common distributed and real-time embedded applications.",https://ieeexplore.ieee.org/document/5945314/,2011 Eighth International Conference on Information Technology: New Generations,11-13 April 2011,ieeexplore
10.1109/ICEE.2018.8472657,Neural Control of Mobile Robot Motion Based on Feedback Error Learning and Mimetic Structure,IEEE,Conferences,"Mobile robots motion control is a basic problem in robotics and there are still some control difficulties such as uncertainty in a real implementation which should be considered. This paper is concerned with the neural control of wheeled mobile robots trajectory tracking and posture stabilization. In the trajectory-tracking problem, the Feedback Error Learning (FEL) structure is used and for the posture stabilization problem, the Mimetic structure is employed. These neural based structures use a classic controller, Dynamic Feedback Linearization (DFL), and help to improve the adaptiveness of it. The effectiveness of the proposed controllers is verified by simulation in Webots robotic simulator and on the e-puck which is a differential wheeled mobile robot. The simulation results verify the ability of the proposed methods for controlling the robot and handling uncertainties.",https://ieeexplore.ieee.org/document/8472657/,"Electrical Engineering (ICEE), Iranian Conference on",8-10 May 2018,ieeexplore
10.1109/AIM.2009.5229901,Neural Q-Learning controller for mobile robot,IEEE,Conferences,"In recent years, increasing trend in application of autonomous mobile robot worldwide has highlighted the importance of path planning controller in robotics-related fields, especially where dynamic and unknown environment is involved. Writing a good robot controller program can be a very time consuming process. It is inevitably wasting of resources and efforts if we have to rewrite the controller over and over again whenever there is emergence of changes in the environment. Reinforcement Learning (RL) algorithms and Artificial Neural Network (ANN) are used to assist autonomous mobile robot to learn in an unrecognized environment. This research study is focused on exploring integration of multi-layer neural network and Q-Learning as an online learning controller. Learning process is divided into two stages. In the initial stage the agent will map the environment through collecting state-action information according to the Q-Learning procedure. Second training process involves neural network training which will utilize the state-action information gathered in earlier phase as training samples. During final application of the controller, Q-Learning would be used as the primary navigating tool whereas the trained neural network will be employed when approximation is needed. MATLAB simulation was developed to verify the validity of the algorithm before it is real-time implemented on the real world using Team AmigoBottrade robot. The results obtained from both simulation and actual application confirmed on-spot learning ability of the controller accompanied with certain degree of flexibility and robustness.",https://ieeexplore.ieee.org/document/5229901/,2009 IEEE/ASME International Conference on Advanced Intelligent Mechatronics,14-17 July 2009,ieeexplore
10.1109/OPTIM.2008.4602496,Neural control based on RBF network implemented on FPGA,IEEE,Conferences,"The RBF radial basis function network is intended especially for hardware implementation and this type of network is used successfully in the areas of robotics and control, where the real time capabilities of the network are of particular importance. The implementation of neural networks on FPGA has several benefits, with emphasis on parallelism and the real time capabilities. This paper discusses the hardware implementation of the RBF type neural network, the architecture and parameters and the functional modules of the hardware implemented neuro-processor.",https://ieeexplore.ieee.org/document/4602496/,2008 11th International Conference on Optimization of Electrical and Electronic Equipment,22-24 May 2008,ieeexplore
10.1109/ISCAS.1991.176692,Neural implementation of Karmarkar algorithm,IEEE,Conferences,"The Karmarkar algorithm performs a sequence of projective transformations each followed by optimization over an inscribed sphere and then inverse projective transformation. These steps are implemented on the authors' model with two neural-like circuits, one embedded inside the other. The inner circuit finds least square error solutions using the complementary slackness condition. The outer circuit finds a novel interior primal solution using the delta rule by making use of the error in the computation of dual solution. This circuit exhibits potential for applications where real-time optimization is required-as is the case in robotics, satellite guidance, etc.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/176692/,"1991., IEEE International Sympoisum on Circuits and Systems",11-14 June 1991,ieeexplore
10.1109/ISESD.2016.7886710,Neural network implementation for invers kinematic model of arm drawing robot,IEEE,Conferences,"Nowadays, the research in robotics field is growing. One of the studies in robotics is the control method of the robotic arm movement. In this research, a 3 DOF arm drawing robot was built. An inverse kinematic models of the robot arm is made using artificial neural network method. Artificial neural network model was implemented in a GUI application. The ANN model can work in real-time to control arm robot movement to reach certain coordinates. Based on test results, the inverse kinematic models of the arm drawing robot had an error rate under 2%. It is of 0.16% for X coordinate and 0.46% for Y coordinate.",https://ieeexplore.ieee.org/document/7886710/,2016 International Symposium on Electronics and Smart Devices (ISESD),29-30 Nov. 2016,ieeexplore
10.1109/SOFA.2009.5254883,Neurodynamic optimization with its application for model predictive control,IEEE,Conferences,"Summary form only given. Optimization problems arise in a wide variety of scientific and engineering applications. It is computationally challenging when optimization procedures have to be performed in real time to optimize the performance of dynamical systems. For such applications, classical optimization techniques may not be competent due to the problem dimensionality and stringent requirement on computational time. One very promising approach to dynamic optimization is to apply artificial neural networks. Because of the inherent nature of parallel and distributed information processing in neural networks, the convergence rate of the solution process is not decreasing as the size of the problem increases. Neural networks can be implemented physically in designated hardware such as ASICs where optimization is carried out in a truly parallel and distributed manner. This feature is particularly desirable for dynamic optimization in decentralized decision-making situations arising frequently in control and robotics. In this talk, the author presents the historic review and the state of the art of neurodynamic optimization models and selected applications in robotics and control. Specifically, starting from the motivation of neurodynamic optimization, we will review various recurrent neural network models for optimization. Theoretical results about the stability and optimality of the neurodynamic optimization models will be given along with illustrative examples and simulation results. It will be shown that many problems in control systems, such model predictive control, can be readily solved by using the neurodynamic optimization models. Specifically, linear and nonlinear model predictive control based on neurodynamic optimization will be delineated.",https://ieeexplore.ieee.org/document/5254883/,2009 3rd International Workshop on Soft Computing Applications,29 July-1 Aug. 2009,ieeexplore
10.1109/NGCT.2015.7375178,Neuronal Logic gates realization using Vedic mathematics,IEEE,Conferences,"Gates are the fundamental building block of all logic circuits. Artificial neural networks (ANN) have processing capabilities in a parallel architecture, and due to this they are useful in applications like pattern recognition, system identification, prediction problems, robotics, and control problems. Boolean logic realization using artificial neural network is known as Neuronal Logic. Simple and low precision computations are the basic requirements of ANN which can be performed faster. This can be implemented on cheap and low precision hardware. Neural network involves enormous number of multiplication and addition calculations. It has been already proved that multipliers based on Vedic mathematics are faster in speed than the standard multipliers. In this paper, the possibility of hardware realization of neuronal logic gates using Vedic multipliers herein referred to as Vedic neuron has been explored. This is achieved by performing the neural network computations using Vedic mathematics rather than the conventional multiplication process. Basic logic gates like AND, OR and AND-NOT have been studied and its hardware implementation using neural network has been simulated using VHDL. A comparative study was carried out on the computation speed of neuronal logic gates implemented using conventional multipliers as well as neuronal logic gates implemented using Vedic multipliers. The increase in processing speed with Vedic neuron implementation has been observed which can be of use in several real time operations where speed is critical.",https://ieeexplore.ieee.org/document/7375178/,2015 1st International Conference on Next Generation Computing Technologies (NGCT),4-5 Sept. 2015,ieeexplore
10.1109/CNN53494.2021.9580216,Neuropunk revolution and its implementation via real-time neurosimulations and their integrations,IEEE,Conferences,"In this paper I present the perspectives of the “neuropunk revolution” technologies. One could understand the “neuropunk revolution” as the integration of real-time neurosimulations into biological nervous/motor system via neurostimulation or artificial robotic systems via integration with actuators. I see the added value of the real-time neurosimulations as bridge technology for the set of developed technologies: BCI, neuroprosthetics, AI, robotics to provide bio-compatible integration into biological or artificial limbs. Here I present the three types of integration of the “neuropunk revolution” technologies as inbound, outbound and closed-loop in-outbound systems. I see the shift of the perspective how we see now the set of technologies including AI, BCI, neuroprosthetics and robotics due to the proposed concept for example the integration of external to a body simulated part of nervous system back into the biological nervous system or muscles.",https://ieeexplore.ieee.org/document/9580216/,2021 Third International Conference Neurotechnologies and Neurointerfaces (CNN),13-15 Sept. 2021,ieeexplore
10.1109/IRC.2019.00061,"ORC—A Lightweight, Lightning-Fast Middleware",IEEE,Conferences,"Robotic tasks are commonly solved by integrating numerous different software and hardware modules into one working application. The necessary integration work typically contributes a considerable share of the total work required for a project, which is why past research on robotics computing has pushed towards generating higher-level abstraction layers, like middlewares. However, the current state-of-the-art cannot provide reliable, low-latency communication performance as we will show in the experimental evaluation. In this paper we propose the Open Robot Communication framework (ORC). Compared to previous middlewares, ORC is lightweight and geared towards applications with high-performance requirements. We consider ORC especially useful for applications with Human Robot Interaction or collaborative tasks involving multiple robots. In the paper, we compare the runtime performance of ORC to the robot operating system (ROS). We can show that ORC enables message transfer with delays far below one millisecond and we demonstrate the real-time capabilities of ORC in a force-control task implemented in Python.",https://ieeexplore.ieee.org/document/8675625/,2019 Third IEEE International Conference on Robotic Computing (IRC),25-27 Feb. 2019,ieeexplore
10.1109/ICRA.2016.7487351,Object discovery and grasp detection with a shared convolutional neural network,IEEE,Conferences,"Grasp an object from a stack of objects in real-time is still a challenge in robotics. This requires the robot to have the ability of both fast object discovery and grasp detection: a target object should be picked out from the stack first and then a proper grasp configuration is applied to grasp the object. In this paper, we propose a shared convolutional neural network (CNN) which can simultaneously implement these two tasks in real-time. The processing speed of the model is about 100 frames per second on a GPU which largely satisfies the requirement. Meanwhile, we also establish a labeled RGBD dataset which contains scenes of stacked objects for robotic grasping. At last, we demonstrate the implementation of our shared CNN model on a real robotic platform and show that the robot can accurately discover a target object from the stack and successfully grasp it.",https://ieeexplore.ieee.org/document/7487351/,2016 IEEE International Conference on Robotics and Automation (ICRA),16-21 May 2016,ieeexplore
10.1109/IROS.2016.7759720,Object identification from few examples by improving the invariance of a Deep Convolutional Neural Network,IEEE,Conferences,"The development of reliable and robust visual recognition systems is a main challenge towards the deployment of autonomous robotic agents in unconstrained environments. Learning to recognize objects requires image representations that are discriminative to relevant information while being invariant to nuisances, such as scaling, rotations, light and background changes, and so forth. Deep Convolutional Neural Networks can learn such representations from large web-collected image datasets and a natural question is how these systems can be best adapted to the robotics context where little supervision is often available. In this work, we investigate different training strategies for deep architectures on a new dataset collected in a real-world robotic setting. In particular we show how deep networks can be tuned to improve invariance and discriminability properties and perform object identification tasks with minimal supervision.",https://ieeexplore.ieee.org/document/7759720/,2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),9-14 Oct. 2016,ieeexplore
10.1109/ROBIO.2009.4913200,Object orientation recognition based on SIFT and SVM by using stereo camera,IEEE,Conferences,"The goal of this research is to recognize an object and its orientation in space by using stereo camera. The principle of object orientation recognition in this paper was based on the scale invariant feature transform (SIFT) and support vector machine (SVM). SIFT has been successfully implemented on object recognition but it had a problem recognizing the object orientation. For many autonomous robotics applications, such as using a vision-guided industrial robot to grab a product, not only correct object recognition will be needed in this process but also object orientation recognition is required. In this paper we used SVM to recognize object orientation. SVM has been known as a promising method for classification accuracy and its generalization ability. The stereo camera system adopted in this research provided more useful information compared to single camera one. The object orientation recognition technique was implemented on an industrial robot in a real application. The proposed camera system and recognition algorithms were used to recognize a specific object and its orientation and then guide the industrial robot to perform some alignment operations on the object.",https://ieeexplore.ieee.org/document/4913200/,2008 IEEE International Conference on Robotics and Biomimetics,22-25 Feb. 2009,ieeexplore
10.1109/ICTAACS48474.2019.8988124,Online Adversarial Planning in μRTS : A Survey,IEEE,Conferences,"Online planning is an important research area focusing on the problem of real-time decision making, using information extracted from the environment. The aim is to compute, at each decision point, the best decision possible that contributes to the realization of a fixed objective. Relevant application domains include robotics, control engineering and computer games. Real-time strategy (RTS) games pose considerable challenges to artificial intelligence techniques, due to their dynamic, complex and adversarial aspects, where online planning plays a prominent role. They also constitute an ideal research platform and test-bed for online planning. μRTS is an open-source AI research platform that features a minimalistic, yet complete RTS implementation, used by AI researchers for developing and testing intelligent RTS game-playing agents. The unique characteristics of μRTS helped for the emergence of interesting online adversarial planning techniques, dealing with multiple levels of abstraction. This paper presents the major μRTS online planning approaches to date, categorized by the degree of abstraction, in fully and partially observable environments.",https://ieeexplore.ieee.org/document/8988124/,2019 International Conference on Theoretical and Applicative Aspects of Computer Science (ICTAACS),15-16 Dec. 2019,ieeexplore
10.1109/IROS.2016.7759410,Online joint learning of object concepts and language model using multimodal hierarchical Dirichlet process,IEEE,Conferences,"One of the biggest challenges in intelligent robotics is to build robots that can learn to use language. To this end, we think that the practical long-term on-line concept/word learning algorithm for robots is a key issue to be addressed. In this paper, we develop an unsupervised on-line learning algorithm that uses Bayesian nonparametrics for categorizing multimodal sensory signals such as audio, visual, and haptic information for robots. The robot uses its physical body to grasp and observe an object from various viewpoints as well as listen to the sound during the observation. The most important property of the proposed framework is to learn multimodal concepts and the language model simultaneously. This mutual learning framework of concepts and language significantly improves both speech recognition and multimodal categorization performances. We conducted a long-term experiment where a human subject interacted with a real robot over 100 hours using 499 objects. Some interesting results of the experiment are discussed in this paper.",https://ieeexplore.ieee.org/document/7759410/,2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),9-14 Oct. 2016,ieeexplore
10.1109/IROS.2017.8202247,Online learning for human classification in 3D LiDAR-based tracking,IEEE,Conferences,"Human detection and tracking are essential aspects to be considered in service robotics, as the robot often shares its workspace and interacts closely with humans. This paper presents an online learning framework for human classification in 3D LiDAR scans, taking advantage of robust multi-target tracking to avoid the need for data annotation by a human expert. The system learns iteratively by retraining a classifier online with the samples collected by the robot over time. A novel aspect of our approach is that errors in training data can be corrected using the information provided by the 3D LiDAR-based tracking. In order to do this, an efficient 3D cluster detector of potential human targets has been implemented. We evaluate the framework using a new 3D LiDAR dataset of people moving in a large indoor public space, which is made available to the research community. The experiments analyse the real-time performance of the cluster detector and show that our online learned human classifier matches and in some cases outperforms its offline version.",https://ieeexplore.ieee.org/document/8202247/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/IJCNN.2014.6889837,Optimising the overall power usage on the SpiNNaker neuromimetic platform,IEEE,Conferences,"Simulations of biological tissue have been extensively used to replicate phenomena observed by in-vivo and in-vitro experiments as an alternative methodology for explaining how computations could take place in a brain region. Additional benefits of simulated neural networks over in-vivo experiments include greater observability, experimental control and reproducibility. General-purpose supercomputers provide the computational power and parallelism required to implement highly complex neural models, but this comes at the expense of high power requirements and communication overheads. Moreover, there are certain cases where real-time simulation performance is a desirable feature, for example in the field of cognitive robotics where embodied agents need to interact with their environment through biologically inspired asynchronous sensors. The SpiNNaker neuromimetic platform is a scalable architecture that has been designed to enable energy-efficient, large-scale simulations of spiking neurons in biological realtime. This work is based on a recent study which revealed that while they are generally energy efficient, SpiNNaker chips dissipate significant amount of power whilst in the idle state. In this paper we perform a systematic investigation into the overall energy consumption of a SpiNNaker system and propose a number of optimised suspend modes in order to reduce this. The proposed implementation is 60% more energy efficient in the idle state, 50% in the uploading and 52% in the downloading phases, while the power dissipation of the whole simulation is reduced by 52%. For demonstration purposes, we run a neural network simulation comprising thousands of neurons and millions of complex synapses on a 48-chip SpiNNaker board, generating millions of synaptic events per second.",https://ieeexplore.ieee.org/document/6889837/,2014 International Joint Conference on Neural Networks (IJCNN),6-11 July 2014,ieeexplore
10.1109/FormaliSE.2019.00012,Parallelizable Reachability Analysis Algorithms for Feed-Forward Neural Networks,IEEE,Conferences,"Artificial neural networks (ANN) have displayed considerable utility in a wide range of applications such as image processing, character and pattern recognition, self-driving cars, evolutionary robotics, and non-linear system identification and control. While ANNs are able to carry out complicated tasks efficiently, they are susceptible to unpredictable and errant behavior due to irregularities that emanate from their complex non-linear structure. As a result, there have been reservations about incorporating them into safety-critical systems. In this paper, we present a reachability analysis method for feed-forward neural networks (FNN) that employ rectified linear units (ReLUs) as activation functions. The crux of our approach relies on three reachable-set computation algorithms, namely exact schemes, lazy-approximate schemes, and mixing schemes. The exact scheme computes an exact reachable set for FNN, while the lazy-approximate and mixing schemes generate an over-approximation of the exact reachable set. All schemes are designed efficiently to run on parallel platforms to reduce the computation time and enhance the scalability. Our methods are implemented in a toolbox called, NNV, and is evaluated using a set of benchmarks that consist of realistic neural networks with sizes that range from tens to a thousand neurons. Notably, NNV successfully computes and visualizes the exact reachable sets of the real world ACAS Xu deep neural networks (DNNs), which are a variant of a family of novel airborne collision detection systems known as the ACAS System X, using a representation of tens to hundreds of polyhedra.",https://ieeexplore.ieee.org/document/8807491/,2019 IEEE/ACM 7th International Conference on Formal Methods in Software Engineering (FormaliSE),27-27 May 2019,ieeexplore
10.1109/CRV52889.2021.00019,PathBench: A Benchmarking Platform for Classical and Learned Path Planning Algorithms,IEEE,Conferences,"Path planning is a key component in mobile robotics. A wide range of path planning algorithms exist, but few attempts have been made to benchmark the algorithms holistically or unify their interface. Moreover, with the recent advances in deep neural networks, there is an urgent need to facilitate the development and benchmarking of such learning-based planning algorithms. This paper presents PathBench, a platform for developing, visualizing, training, testing, and benchmarking of existing and future, classical and learned 2D and 3D path planning algorithms, while offering support for Robot Operating System (ROS). Many existing path planning algorithms are supported; e.g. A*, wavefront, rapidly-exploring random tree, value iteration networks, gated path planning networks; and integrating new algorithms is easy and clearly specified. We demonstrate the benchmarking capability of PathBench by comparing implemented classical and learned algorithms for metrics, such as path length, success rate, computational time and path deviation. These evaluations are done on built-in PathBench maps and external path planning environments from video games and real world databases. PathBench is open source <sup>1</sup>.",https://ieeexplore.ieee.org/document/9469507/,2021 18th Conference on Robots and Vision (CRV),26-28 May 2021,ieeexplore
10.1109/FPA.1994.636094,Perception systems implemented in analog VLSI for real-time applications,IEEE,Conferences,"We point out that analog VLSI can now be considered as the ideal medium to implement computational systems intended to carry out real time perceptive or even cognitive tasks that are not well handled by traditional computers. By exploiting the analog features of the transistors, only a few devices are needed to realise most of the elementary functions required to implement perceptive systems, resulting in very dense, sophisticated circuits and low power consumption. Elementary artificial retinas in silicon based on their biological counterparts have already been successfully used in industrial applications. Artificial cochleas and noses are also under development. This new enabling technology is of great interest over a wide range of industrial sectors, including robotics, automotive, surveillance and food industry.",https://ieeexplore.ieee.org/document/636094/,Proceedings of PerAc '94. From Perception to Action,7-9 Sept. 1994,ieeexplore
10.1109/ROBIO.2012.6491183,Primitive action learning using fuzzy neural networks,IEEE,Conferences,"The learning of primitive actions, or affordances as often called, has always been one of the top items in the research agenda of the robotics community. In this paper we propose fuzzy neural networks as a viable solution for their computational efficiency, their ability to approximate smooth non-linear functions and their transparency of the underlying mechanisms of the trained network. More specifically we benchmark the Takaki-Sugeno Fuzzy Neural Network (TSFNN) in an experimental scenario where the robot learns to control its arm velocity to push a rolling object in a requested position. The experimental scenario was kept simple and of linear nature in order to benchmark the TSFNN with a least squares linear model. The real time experiments using a PR2 robot have been conducted to verify the proposed method. The experimental results have shown that the TSFNN is able to reliably and robustly learn and demonstrate the pushing action.",https://ieeexplore.ieee.org/document/6491183/,2012 IEEE International Conference on Robotics and Biomimetics (ROBIO),11-14 Dec. 2012,ieeexplore
10.1109/RO-MAN46459.2019.8956461,Privacy First: Designing Responsible and Inclusive Social Robot Applications for in the Wild Studies,IEEE,Conferences,"Deploying social robots applications in public spaces for conducting in the wild studies is a significant challenge but critical to the advancement of social robotics. Real world environments are complex, dynamic, and uncertain. Human-Robot interactions can be unstructured and unanticipated. In addition, when the robot is intended to be a shared public resource, management issues such as user access and user privacy arise, leading to design choices that can impact on users' trust and the adoption of the designed system. In this paper we propose a user registration and login system for a social robot and report on people's preferences when registering their personal details with the robot to access services. This study is the first iteration of a larger body of work investigating potential use cases for the Pepper social robot at a government managed centre for startups and innovation. We prototyped and deployed a system for user registration with the robot, which gives users control over registering and accessing services with either face recognition technology or a QR code. The QR code played a critical role in increasing the number of users adopting the technology. We discuss the need to develop social robot applications that responsibly adhere to privacy principles, are inclusive, and cater for a broad spectrum of people.",https://ieeexplore.ieee.org/document/8956461/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/GloSIC.2018.8570124,Probabilistic Estimations of Increasing Expected Reliability and Safety for Intelligent Manufacturing,IEEE,Conferences,"In the near future the possibilities of the modern probabilistic models, artificial intelligence and machine learning methods can provide an intelligent support of making decisions by an operator in real time. An agile recovery of intelligent manufacturing integrity can be implemented owing to the development of industrial robotics. For intelligent manufacturing it means the expected reliability and safety may be in the near future at the expense of intelligent support of decision making and the agile recovery of integrity. To answer the question “How much essential may be this increasing?” here are proposed: general analytical approaches for a probabilistic estimation of the expected reliability and safety for every monitored element or the system of intelligent manufacturing on a level of probability distribution functions (PDF) of the time between the losses of system integrity; estimations of increasing the expected reliability and safety for intelligent manufacturing at the expense of the intelligent support of decision making and agile recovery of integrity; the comparisons of the estimations on a prognostic period up to 10 years using the identical model in applications to expected reliability and safety. The applications of the proposed approaches allow the customers, designers, developers, users and experts of Industry 4.0 intelligent manufacturing to be guided by the proposed probabilistic estimations for solving problems of reliability and safety in the system life cycle. The results are demonstrated by examples.",https://ieeexplore.ieee.org/document/8570124/,2018 Global Smart Industry Conference (GloSIC),13-15 Nov. 2018,ieeexplore
10.1109/ICRC.2016.7738697,Processor-in-memory support for artificial neural networks,IEEE,Conferences,"Hardware acceleration of artificial neural network (ANN) processing has potential for supporting applications benefiting from real time and low power operation, such as autonomous vehicles, robotics, recognition and data mining. Most interest in ANNs targets acceleration of deep multi-layered ANNs that can require days of offline training to converge on a desired network behavior. Interest has grown in ANNs capable of supporting unsupervised training, where networks can learn new information from unlabeled data dynamically without the need for offline training. These ANNs require large memories with bandwidths much higher than supported in modern GPGPUs. Custom hardware acceleration and memory co-design holds the potential to provide real-time performance in cases where the performance requirements cannot be met by modern GPGPUs. This work presents a custom processor solution to accelerate two hetero-associative memories (Sparsey and HTM) capable of unsupervised and one-hot learning. This custom processor is implemented as an expandable ASIP built upon a configurable SIMD engine for exploiting parallelism. Functional specialization is implemented utilizing processor-in-memory techniques, which results in up to a 20× speedup and a 2000× reduction in energy per frame compared to a software implementation operating on a dataset for recognition of human actions.",https://ieeexplore.ieee.org/document/7738697/,2016 IEEE International Conference on Rebooting Computing (ICRC),17-19 Oct. 2016,ieeexplore
10.1109/ICRA48506.2021.9562075,Reaching Pruning Locations in a Vine Using a Deep Reinforcement Learning Policy,IEEE,Conferences,"We outline a neural network-based pipeline for perception, control and planning of a 7 DoF robot for tasks that involve reaching into a dormant grapevine canopy. The proposed system consists of a 6 DoF industrial robot arm and a linear slider that can actuate on an entire grape vine. Our approach uses Convolutional Neural Networks to detect buds in dormant grape vines and a Reinforcement Learning based control strategy to reach desired cut-point locations for pruning tasks. Within this framework, three methodologies are developed and compared to reach the desired locations: the learned policy-based approach (RL), a hybrid method that uses the learned policy and an inverse kinematics solver (RL+IK), and lastly a classical approach commonly used in robotics. We first tested and validated the suitability of the proposed learning methodology in a simulated environment that resembled laboratory conditions. A reaching accuracy of up to 61.90% and 85.71% for the RL and RL+IK approaches respectively was obtained for a vine that the agent observed while learning. When testing in a new vine, the accuracy was up to 66.66% and 76.19% for RL and RL+IK, respectively. The same methods were then deployed on a real system in an end to end procedure: autonomously scan the vine using a vision system, create its model and finally use the learned policy to reach cutting points. The reaching accuracy obtained in these tests was 73.08%.",https://ieeexplore.ieee.org/document/9562075/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICCCE.2008.4580693,Real time implementation of NARMA L2 feedback linearization and smoothed NARMA L2 controls of a single link manipulator,IEEE,Conferences,"Robotics is a field of modern technology which requires knowledge in vast areas such as electrical engineering, mechanical engineering, computer science as well as finance. Nonlinearities and parametric uncertainties are unavoidable problems faced in controlling robots in industrial plants. Tracking control of a single link manipulator driven by a permanent magnet brushed DC motor is a nonlinear dynamics due to effects of gravitational force, mass of the payload, posture of the manipulator and viscous friction coefficient. Furthermore uncertainties arise because of changes of the rotor resistance with temperature and random variations of friction while operating. Due to this fact classical PID controller can not be used effectively since it is developed based on linear system theory. Neural network control schemes for manipulator control problem have been proposed by researchers; in which their competency is validated through simulation studies. On the other hand, actual real time applications are rarely established. Instead of simulation studies, this paper is aimed to implement neural network controller in real time for controlling a DC motor driven single link manipulator. The work presented in this paper is concentrating on neural NARMA L2 control and its improvement called to as Smoothed NARMA L2 control. As proposed by K. S Narendra and Mukhopadhyay, Narma L2 control is one of the popular neural network architectures for prediction and control. The real time experimentation showed that the Smoothed NARMA L2 is effective for controlling the single link manipulator for both point-to-point and continuous path motion control.",https://ieeexplore.ieee.org/document/4580693/,2008 International Conference on Computer and Communication Engineering,13-15 May 2008,ieeexplore
10.1109/ICRAI.2012.6413407,Real time localization of mobile robotic platform via fusion of Inertial and Visual Navigation System,IEEE,Conferences,"Inertial Navigation System (INS) is one of the most important component of a mobile robotic platform, be it ground or air based. It is used to localize the mobile robotic platform in the real world and identify its location in terms of latitudes and longitudes or other related coordinate systems. Highly accurate and precise INS is quite expensive and is therefore not suitable for more general purpose applications. It is, therefore, a standard approach in mobile robotics to use a low grade commercial INS coupled with another navigation device to provide a more accurate triangulation. Generally, INS and Global Positioning System (GPS) are integrated using Kalman Filters to provide accurate localization information about the mobile robots. Although, in certain scenarios, the mobile robot is not able to acquire a GPS fix for long durations of time especially when navigating in indoor environments or in areas with inadequate GPS satellite coverage. In such cases, an additional source of location fix is required. This paper describes an accurate and stable data fusion filter which integrates the position of a mobile robot from a Visual Navigation System (VNS) with the position from an INS to accurately localize the robot in absence of GPS data. This research proposes a seven error states model and uses it in Kalman Filter for data fusion. The filter is tuned and tested using dynamic and static data from INS and VNS. Simulation and experimentation results show that the seven error states model based Kalman Filter provides a good balance between accuracy, robustness and processing efficiency for a real time implementation. Experiments also show that in absence of GPS data only a couple of fixes from the VNS are sufficient to quickly correct the position of the mobile robotic platform and three fixes at different times are sufficient for velocity correction of INS.",https://ieeexplore.ieee.org/document/6413407/,2012 International Conference of Robotics and Artificial Intelligence,22-23 Oct. 2012,ieeexplore
10.1109/ICTAI.2008.143,Real-Time Classification of Streaming Sensor Data,IEEE,Conferences,"The last decade has seen a huge interest in classification of time series. Most of this work assumes that the data resides in main memory and is processed offline. However, recent advances in sensor technologies require resource-efficient algorithms that can be implemented directly on the sensors as real-time algorithms. We show how a recently introduced framework for time series classification, time series bitmaps, can be implemented as efficient classifiers which can be updated in constant time and space in the face of very high data arrival rates. We describe results from a case study of an important entomological problem, and further demonstrate the generality of our ideas with an example from robotics.",https://ieeexplore.ieee.org/document/4669683/,2008 20th IEEE International Conference on Tools with Artificial Intelligence,3-5 Nov. 2008,ieeexplore
10.1109/ICRA.2019.8794220,Real-Time Joint Semantic Segmentation and Depth Estimation Using Asymmetric Annotations,IEEE,Conferences,"Deployment of deep learning models in robotics as sensory information extractors can be a daunting task to handle, even using generic GPU cards. Here, we address three of its most prominent hurdles, namely, i) the adaptation of a single model to perform multiple tasks at once (in this work, we consider depth estimation and semantic segmentation crucial for acquiring geometric and semantic understanding of the scene), while ii) doing it in real-time, and iii) using asymmetric datasets with uneven numbers of annotations per each modality. To overcome the first two issues, we adapt a recently proposed real-time semantic segmentation network, making changes to further reduce the number of floating point operations. To approach the third issue, we embrace a simple solution based on hard knowledge distillation under the assumption of having access to a powerful `teacher' network. We showcase how our system can be easily extended to handle more tasks, and more datasets, all at once, performing depth estimation and segmentation both indoors and outdoors with a single model. Quantitatively, we achieve results equivalent to (or better than) current state-of-the-art approaches with one forward pass costing just 13ms and 6.5 GFLOPs on 640×480 inputs. This efficiency allows us to directly incorporate the raw predictions of our network into the SemanticFusion framework [1] for dense 3D semantic reconstruction of the scene.",https://ieeexplore.ieee.org/document/8794220/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ECMR.2019.8870936,Real-time Vision-based Depth Reconstruction with NVidia Jetson,IEEE,Conferences,"Vision-based depth reconstruction is a challenging problem extensively studied in computer vision but still lacking universal solution. Reconstructing depth from single image is particularly valuable to mobile robotics as it can be embedded to the modern vision-based simultaneous localization and mapping (vSLAM) methods providing them with the metric information needed to construct accurate maps in real scale. Typically, depth reconstruction is done nowadays via fully-convolutional neural networks (FCNNs). In this work we experiment with several FCNN architectures and introduce a few enhancements aimed at increasing both the effectiveness and the efficiency of the inference. We experimentally determine the solution that provides the best performance/accuracy tradeoff and is able to run on NVidia Jetson with the framerates exceeding 16FPS for 320 × 240 input. We also evaluate the suggested models by conducting monocular vSLAM of unknown indoor environment on NVidia Jetson TX2 in real-time. Open-source implementation of the models and the inference node for Robot Operating System (ROS) are available at https://github.com/CnnDepth/tx2_fcnn_node.",https://ieeexplore.ieee.org/document/8870936/,2019 European Conference on Mobile Robots (ECMR),4-6 Sept. 2019,ieeexplore
10.1109/RTOSS.1994.292553,Real-time platforms and environments for time constrained flexible manufacturing,IEEE,Conferences,"The Spring Kernel and associated algorithms, languages, and tools provide system support for static or dynamic real-time applications that require predictable operation. Spring currently consists of two major parts: (1) the development environment, where application and target systems are described, preprocessed and downloaded, and (2) the run-time environment, where the operating system, the Spring Kernel, creates and ensures predictable executions of application tasks. We have integrated our real-time systems technology with component technologies from robotics, computer vision, and real-time artificial intelligence, to develop a test platform for flexible manufacturing. The results being produced are generic so that they should be in many other real-time applications such as air traffic control and chemical plants. We describe this platform, identify new features developed, and comment on some lessons learned to date from this experiment.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/292553/,Proceedings of 11th IEEE Workshop on Real-Time Operating Systems and Software,18-19 May 1994,ieeexplore
10.1109/ICARM52023.2021.9536145,Reducing the Dimension of the Configuration Space with Self Organizing Neural Networks,IEEE,Conferences,"For robotics, especially industrial applications, it is crucial to reactively plan safe motions through efficient algorithms. Planning is more powerful in the configuration space than the task space. However, for robots with many degrees of freedom, this is challenging and computationally expensive. Sophisticated techniques for motion planning such as the Wavefront algorithm are limited by the high dimensionality of the configuration space, especially for robots with many degrees of freedom. For a neural implementation of the Wavefront algorithm in the configuration space, neurons represent discrete configurations and synapses are used for path planning. In order to decrease the complexity, we reduce the search space by pruning superfluous neurons and synapses. We present different models of self-organizing neural networks for this reduction. The approach takes real-life human motion data as input and creates a representation with reduced dimension. We compare six different neural network models and adapt the Wavefront algorithm to the different structures of the reduced output spaces. The method is backed up by an extensive evaluation of the reduced spaces, including their suitability for path planning by the Wavefront algorithm.",https://ieeexplore.ieee.org/document/9536145/,2021 6th IEEE International Conference on Advanced Robotics and Mechatronics (ICARM),3-5 July 2021,ieeexplore
10.1109/ROBOT.2010.5509336,Reinforcement learning of motor skills in high dimensions: A path integral approach,IEEE,Conferences,"Reinforcement learning (RL) is one of the most general approaches to learning control. Its applicability to complex motor systems, however, has been largely impossible so far due to the computational difficulties that reinforcement learning encounters in high dimensional continuous state-action spaces. In this paper, we derive a novel approach to RL for parameterized control policies based on the framework of stochastic optimal control with path integrals. While solidly grounded in optimal control theory and estimation theory, the update equations for learning are surprisingly simple and have no danger of numerical instabilities as neither matrix inversions nor gradient learning rates are required. Empirical evaluations demonstrate significant performance improvements over gradient-based policy learning and scalability to high-dimensional control problems. Finally, a learning experiment on a robot dog illustrates the functionality of our algorithm in a real-world scenario. We believe that our new algorithm, Policy Improvement with Path Integrals (PI<sup>2</sup>), offers currently one of the most efficient, numerically robust, and easy to implement algorithms for RL in robotics.",https://ieeexplore.ieee.org/document/5509336/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/DIS.2006.63,Remote Programming of Multirobot Systems within the UPC-UJI Telelaboratories: System Architecture and Agent-Based Multirobot Control,IEEE,Conferences,"One of the areas that needs more improvement within the e-learning environments via Internet (in fact they suppose a very big effort to be accomplished) is allowing students to access and practice real experiments is a real laboratory, instead of using simulations in Marin, R. et al. (2003). Real laboratories allow students to acquire methods, skills and experience related to real equipment, in a manner that is very close to the way they are being used in industry. The purpose of the project is the study, development and implementation of an e-learning environment to allow undergraduate students to practice subjects related to Robotics and Artificial Intelligence. The system, which is now at a preliminary stage, will allow the remote experimentation with real robotic devices (i.e. robots, cameras, etc.). It will enable the student to learn in a collaborative manner (remote participation with other students) where it will be possible to combine the on-site activities (performed ""in-situ"" within the real lab during the normal practical sessions), with the ""online"" one (performed remotely from home via the Internet). Moreover, the remote experiments within the e-laboratory to control the real robots can be performed by both, students and even scientist. This project is under development and it is carried out jointly by two Universities (UPC and UJI). In this article we present the system architecture and the way students and researchers have been able to perform a remote programming of multirobot systems via Web",https://ieeexplore.ieee.org/document/1633445/,IEEE Workshop on Distributed Intelligent Systems: Collective Intelligence and Its Applications (DIS'06),15-16 June 2006,ieeexplore
10.1109/IROS40897.2019.8968306,Robot Learning via Human Adversarial Games,IEEE,Conferences,"Much work in robotics has focused on “humanin-the-loop” learning techniques that improve the efficiency of the learning process. However, these algorithms have made the strong assumption of a cooperating human supervisor that assists the robot. In reality, human observers tend to also act in an adversarial manner towards deployed robotic systems. We show that this can in fact improve the robustness of the learned models by proposing a physical framework that leverages perturbations applied by a human adversary, guiding the robot towards more robust models. In a manipulation task, we show that grasping success improves significantly when the robot trains with a human adversary as compared to training in a self-supervised manner.",https://ieeexplore.ieee.org/document/8968306/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ROBOT.2001.933270,Robotic Antarctic meteorite search: outcomes,IEEE,Conferences,"Automation of the search for and classification of Antarctic meteorites offers a unique case for early demonstration of robotics in a scenario analogous to geological exploratory missions to other planets and to the Earth's extremes. Moreover, the discovery of new meteorite samples is of great value because meteorites are the only significant source of extraterrestrial material available to scientists. In this paper we focus on the primary outcomes and technical lessons learned from the first field demonstration of autonomous search and in situ classification of Antarctic meteorites by a robot. Using a novel autonomous control architecture, specialized science sensing, combined manipulation and visual servoing, and Bayesian classification, the Nomad robot classified five indigenous meteorites during an expedition to the remote site of Elephant Moraine in January 2000. Nomad's expedition proved the rudiments of science autonomy and exemplified the merits of machine learning techniques for autonomous geological classification in real-world settings. On the other hand, the expedition showcased the difficulty in executing reliable robotic deployment of science sensors and a limited performance in the speed and coverage of autonomous search.",https://ieeexplore.ieee.org/document/933270/,Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164),21-26 May 2001,ieeexplore
10.1109/ICIS.2017.7959982,Robotics data real-time management based on NoSQL solution,IEEE,Conferences,"In nowadays, robotics database management systems are increasing. These systems ensure good storage of data and with big data analytic, a new approach demands new structures and methods for collecting, recording, and analyzing enterprise data. This paper work deals with the NoSQL databases which are the secret of the continual progression data that new data management solutions have been emerged. They crossed several areas as personalization, profile management, big data in real-time, content management, catalogue, view of customers, mobile applications, internet of things, digital communication and fraud detection. Machine learning, for example, thrives on more data, so smart machines can learn more and faster, the Robotics are our use of case to focus on our Test. The implementation of NoSQL for Robotics wrestle all the data they acquire into usable form because with the ordinary type of Robotics we are facing very big limits to manage and find the exact information in real-time. Our original proposed approach was demonstrated by experimental studies and running example used as a use case.",https://ieeexplore.ieee.org/document/7959982/,2017 IEEE/ACIS 16th International Conference on Computer and Information Science (ICIS),24-26 May 2017,ieeexplore
10.1109/ICRA.2013.6631400,Robust real-time visual odometry for dense RGB-D mapping,IEEE,Conferences,"This paper describes extensions to the Kintinuous [1] algorithm for spatially extended KinectFusion, incorporating the following additions: (i) the integration of multiple 6DOF camera odometry estimation methods for robust tracking; (ii) a novel GPU-based implementation of an existing dense RGB-D visual odometry algorithm; (iii) advanced fused realtime surface coloring. These extensions are validated with extensive experimental results, both quantitative and qualitative, demonstrating the ability to build dense fully colored models of spatially extended environments for robotics and virtual reality applications while remaining robust against scenes with challenging sets of geometric and visual features.",https://ieeexplore.ieee.org/document/6631400/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/RTAS.2018.00028,S^3DNN: Supervised Streaming and Scheduling for GPU-Accelerated Real-Time DNN Workloads,IEEE,Conferences,"Deep Neural Networks (DNNs) are being widely applied in many advanced embedded systems that require autonomous decision making, e.g., autonomous driving and robotics. To handle resource-demanding DNN workloads, graphic processing units (GPUs) have been used as the main acceleration engine. Although much research has been conducted to algorithmically optimize the efficiency of applying DNN to applications such as object recognition, limited attention has been given to optimizing the execution of GPU-accelerated DNN workloads at the system level. In this paper, we propose S^3DNN, a system solution that optimizes the execution of DNN workloads on GPU in a real-time multi-tasking environment, which simultaneously optimizes the two (sometimes) conflicting goals of real-time correctness and throughput. S^3DNN contains a governor that selectively gathers system-wide DNN requests to perform smart data fusion, and a novel supervised streaming and scheduling framework that combines a deadline-aware scheduler with the concurrency-enabled CUDA stream technique. To simultaneously maximize concurrency-induced benefits and real-time performance, S^3DNN explores a rather interesting and unique characteristic of DNN workloads, where multiple layers of a DNN instance often exhibit a gradually decreased GPU resource utilization pattern. We have fully implemented S^3DNN in a GPU-accelerated system and have conducted extensive sets of experiments evaluating the efficacy of S^3DNN under a wide range of system and workload scenarios. The results show that S^3DNN significantly improves upon state-of-the-art GPU-accelerated DNN processing frameworks, e.g., up to 37% and over 40% improvements in real-time performance and throughput, respectively.",https://ieeexplore.ieee.org/document/8430082/,2018 IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS),11-13 April 2018,ieeexplore
10.1109/FCCM48280.2020.00067,Scalable Full Hardware Logic Architecture for Gradient Boosted Tree Training,IEEE,Conferences,"Gradient Boosted Tree is most effective and standard machine learning algorithm in many fields especially with various type of tabular dataset. Besides, recent industry field and robotics field require high-speed, power efficient and real-time training with enormous data. FPGA is effective device which enable custom domain specific approach to give acceleration as well as power efficiency. We introduce a scalable full hardware implementation of Gradient Boosted Tree training with high performance and flexibility of hyper parameterization. Experimental work shows that our hardware implementation achieved 11-33 times faster than state-of-art GPU acceleration even with small gates and low power FPGA device.",https://ieeexplore.ieee.org/document/9114741/,2020 IEEE 28th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM),3-6 May 2020,ieeexplore
10.1109/ICNNB.2005.1614810,Security Assurance Using Face Recognition &amp; Detection System Based On Neural Networks,IEEE,Conferences,"In this paper, we have proposed a new method of implementing an assurance system using the facial information of the people, this is a different approach to the conventional security system which uses biometric information or cryptography for assurance, here we use an efficient self-scaling face recognition system supported with a face detection system, the system is capable enough to extract the human faces from a real time video and to recognize the people using a face recognition system, we are designing the framework for face recognition system with a hybrid RBF neural network, the real advantage of the system lies in its capability to inculcate some basic features of the self organizing map (SOM) so that the system can scale on its own and it doesn't get outdated with time, for the face detection system we use a content based face detection algorithm, the facial feature so detected is inputted into the face recognition system, if the person's information is already present in the system, authentication can be accomplished, this system can be used in public places like airports and supermarkets, the information of criminals can be stored in the system and in case any of the criminals are detected by the system, the security personnel can be signaled, this system can also be implemented in robotics, the system can help the computer to identify individual users distinctly, our facial recognition system has been tested and found to be persistent in recognizing the individual even if the input facial image is of different gesture or holds some extra lineament like beard, moustache or spectacles so we can definitely state that the system is reliable and efficient",https://ieeexplore.ieee.org/document/1614810/,2005 International Conference on Neural Networks and Brain,13-15 Oct. 2005,ieeexplore
10.1109/ICRA.2019.8793744,Segmenting Unknown 3D Objects from Real Depth Images using Mask R-CNN Trained on Synthetic Data,IEEE,Conferences,"The ability to segment unknown objects in depth images has potential to enhance robot skills in grasping and object tracking. Recent computer vision research has demonstrated that Mask R-CNN can be trained to segment specific categories of objects in RGB images when massive hand-labeled datasets are available. As generating these datasets is time-consuming, we instead train with synthetic depth images. Many robots now use depth sensors, and recent results suggest training on synthetic depth data can transfer successfully to the real world. We present a method for automated dataset generation and rapidly generate a synthetic training dataset of 50,000 depth images and 320,000 object masks using simulated heaps of 3D CAD models. We train a variant of Mask R-CNN with domain randomization on the generated dataset to perform category-agnostic instance segmentation without any hand-labeled data and we evaluate the trained network, which we refer to as Synthetic Depth (SD) Mask R-CNN, on a set of real, high-resolution depth images of challenging, densely-cluttered bins containing objects with highly-varied geometry. SD Mask R-CNN outperforms point cloud clustering baselines by an absolute 15% in Average Precision and 20% in Average Recall on COCO benchmarks, and achieves performance levels similar to a Mask R-CNN trained on a massive, hand-labeled RGB dataset and fine-tuned on real images from the experimental setup. We deploy the model in an instance-specific grasping pipeline to demonstrate its usefulness in a robotics application. Code, the synthetic training dataset, and supplementary material are available at https://bit.ly/2letCuE.",https://ieeexplore.ieee.org/document/8793744/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/IJCNN.2016.7727359,Self-repairing mobile robotic car using astrocyte-neuron networks,IEEE,Conferences,"A self-repairing robot utilising a spiking astrocyte-neuron network is presented in this paper. It uses the output spike frequency of neurons to control the motor speed and robot activation. A software model of the astrocyte-neuron network previously demonstrated self-detection of faults and its self-repairing capability. In this paper the application demonstrator of mobile robotics is employed to evaluate the fault-tolerant capabilities of the astrocyte-neuron network when implemented in a hardware-based robotic car system. Results demonstrated that when 20% or less synapses associated with a neuron are faulty, the robot car can maintain system performance and complete the task of forward motion correctly. If 80% synapses are faulty, the system performance shows a marginal degradation, however this degradation is much smaller than that of conventional fault-tolerant techniques under the same levels of faults. This is the first time that astrocyte cells merged within spiking neurons demonstrates a self-repairing capabilities in the hardware system for a real application.",https://ieeexplore.ieee.org/document/7727359/,2016 International Joint Conference on Neural Networks (IJCNN),24-29 July 2016,ieeexplore
10.1109/ICRA.2019.8793595,Semi Supervised Deep Quick Instance Detection and Segmentation,IEEE,Conferences,"In this paper, we present a semi supervised deep quick learning framework for instance detection and pixelwise semantic segmentation of images in a dense clutter of items. The framework can quickly and incrementally learn novel items in an online manner by real-time data acquisition and generating corresponding ground truths on its own. To learn various combinations of items, it can synthesize cluttered scenes, in real time. The overall approach is based on the tutor-child analogy in which a deep network (tutor) is pretrained for class-agnostic object detection which generates labeled data for another deep network (child). The child utilizes a customized convolutional neural network head for the purpose of quick learning. There are broadly four key components of the proposed framework: semi supervised labeling, occlusion aware clutter synthesis, a customized convolutional neural network head, and instance detection. The initial version of this framework was implemented during our participation in Amazon Robotics Challenge (ARC), 2017. Our system was ranked 3rd rd, 4th and 5 th worldwide in pick, stow-pick and stow task respectively. The proposed framework is an improved version over ARC'17 where novel features such as instance detection and online learning has been added.",https://ieeexplore.ieee.org/document/8793595/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/RO-MAN50785.2021.9515358,Sequential Prediction with Logic Constraints for Surgical Robotic Activity Recognition,IEEE,Conferences,"Many real-world time-sensitive and high-stake applications (e.g., surgical, rescue, and recovery robotics) exhibit sequential nature; thus, applying Recurrent Neural Network (RNN)-based sequential models is an attractive approach to detect robotic activity. One limitation of such approaches is data scarcity. As a result, limited training samples may lead to over-fitting, producing incorrect predictions during deployment. Nevertheless, abundant domain knowledge may still be available, which may help formulate logic constraints. In this paper, we propose a novel way to integrate domain knowledge into RNN-based sequential prediction. We build a Markov Logic Network (MLN)-based classifier that automatically learns constraint weights from data. We propose two methods to incorporate this MLN-based prediction: (i) PriorLayer, in which the values of the hidden layer of the RNN are combined with weights learned from logic constraints in an additional neural network layer, and (ii) Conflation, in which class probabilities from RNN predictions and constraint weights are combined based on the conflation of class probabilities. We evaluate robotic activity classification methods on a simulated OpenAI Gym environment and a real-world DESK dataset for surgical robotics. We observe that our proposed MLN-based approaches boost the performance of LSTM-based networks. In particular, MLN boosts the accuracy of LSTM from 71% to 84% on the Gym dataset and from 68% to 72% on the Taurus robot dataset. Furthermore, MLN (i.e., PriorLayer) shows regularization capability where it improves accuracy in initial LSTM training while avoiding over-fitting early, thus improves the final classification accuracy on unseen data. The code is available at https://github.com/masud99r/prediction-with-logic-constraints.",https://ieeexplore.ieee.org/document/9515358/,2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN),8-12 Aug. 2021,ieeexplore
10.1109/ITSC.2018.8569569,ShadowCam: Real-Time Detection of Moving Obstacles Behind A Corner For Autonomous Vehicles,IEEE,Conferences,"Moving obstacles occluded by corners are a potential source for collisions in mobile robotics applications such as autonomous vehicles. In this paper, we address the problem of anticipating such collisions by proposing a vision-based detection algorithm for obstacles which are outside of a vehicle's direct line of sight. Our method detects shadows of obstacles hidden around corners and automatically classifies these unseen obstacles as “dynamic” or “static”. We evaluate our proposed detection algorithm on real-world corners and a large variety of simulated environments to assess generalizability in different challenging surface and lighting conditions. The mean classification accuracy on simulated data is around 80% and on real-world corners approximately 70%. Additionally, we integrate our detection system on a full-scale autonomous wheelchair and demonstrate its feasibility as an additional safety mechanism through real-world experiments. We release our real-time-capable implementation of the proposed ShadowCam algorithm and the dataset containing simulated and real-world data under an open-source license.",https://ieeexplore.ieee.org/document/8569569/,2018 21st International Conference on Intelligent Transportation Systems (ITSC),4-7 Nov. 2018,ieeexplore
10.1109/RO-MAN50785.2021.9515431,Simplifying the A.I. Planning modeling for Human-Robot Collaboration,IEEE,Conferences,"For an effective deployment in manufacturing, Collaborative Robots should be capable of adapting their behavior to the state of the environment and to keep the user safe and engaged during the interaction. Artificial Intelligence (AI) enables robots to autonomously operate understanding the environment, planning their tasks and acting to achieve some given goals. However, the effective deployment of AI technologies in real industrial environments is not straightforward. There is a need for engineering tools facilitating communication and interaction between AI engineers and Domain experts. This paper proposes a novel software tool, called TENANT (Tool fostEriNg Ai plaNning in roboTics) whose aim is to facilitate the use of AI planning technologies by providing domain experts like e.g., production engineers, with a graphical software framework to synthesize AI planning models abstracting from syntactic features of the underlying planning formalism.",https://ieeexplore.ieee.org/document/9515431/,2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN),8-12 Aug. 2021,ieeexplore
10.1109/DevLrn.2012.6400585,Simultaneous concept formation driven by predictability,IEEE,Conferences,"This study is conducted in the context of developmental learning in embodied agents who have multiple data sources (sensors) at their disposal. We describe an online learning method that simultaneously discovers “meaningful” concepts in the associated processing streams, extending methods such as PCA, SOM or sparse coding to the multimodal case. In addition to the avoidance of redundancies in the concepts derived from single modalities, we claim that “meaningful” concepts are those who have statistical relations across modalities. This is a reasonable claim because measurements by different sensors often have common cause in the external world and therefore carry correlated information. To capture such cross-modal relations while avoiding redundancy of concepts, we propose a set of interacting self-organization processes which are modulated by local predictability. To validate the fundamental applicability of the method, we conduct a plausible simulation experiment with synthetic data and find that those concepts which are predictable from other modalities successively “grow”, i.e., become over-represented, whereas concepts that are not predictable become systematically under-represented. We conclude the article by a discussion of applicability in real-world robotics scenarios.",https://ieeexplore.ieee.org/document/6400585/,2012 IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL),7-9 Nov. 2012,ieeexplore
10.1109/IROS.2018.8593856,"Skill-Oriented Designer of Conceptual Robotic Structures*This work was supported by CDTI under expedient IDI-20150289 (BOTBLOQ: Ecosistema integral para el diseño, fabricación y programación de robots DIY).",IEEE,Conferences,"This communication presents an application for the use of ontologies in the generation of robot structures. The ontology developed for this app relies on the IEEE Standard Ontologies for Robotics and Automation (ORA) and it incorporates a set of concepts, relations and axioms that link robotic skills with the structural parts needed for their realization. The user can select a base configuration and/or a set of desired skills that the robot should be able to perform. Then, the application evaluates the axioms and returns an abstract structure that can carry out the requested skills. The final implementation of the structure can be achieved with any modular robotic platform that could identify each structural part with a physical device.",https://ieeexplore.ieee.org/document/8593856/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ICCSE49874.2020.9201679,Small Agricultural Phenotype Robot and Its Navigation and Obstacle Avoidance in Parallel Walls,IEEE,Conferences,"With the development of robotics, computer vision and artificial intelligence, the study of Plant phenotyping has entered a stage of rapid growth. For robots can be used for a large-scale, automatic and sustainable phenotype collection and data processing, it has also been followed closely by more and more research institutions and international seed giants, but currently the more mature phenotype robots are huge in size and expensive in configuration. Although their accuracy are high, but the popularity are poor, so it is difficult to popularize on a large scale, which is not conducive to collect plant phenotype data in a wider space and for the more plant varieties. On the other side, the small phenotype robots have low cost, simple operation, and are more suitable for large-scale promotion. The current research on plant phenotype small robots is mainly based on small wheeled robots. The robot is equipped with visual and optical sensors for collecting plant information, and uses machine vision and various sensors to achieve the robot's movement, positioning and obstacle avoidance. This paper uses the small wheeled mobile robot to simulate the navigation and obstacle avoidance of the phenotype collecting robot in parallel walls, and its effectiveness is proved by simulation experiment and real machine test.",https://ieeexplore.ieee.org/document/9201679/,2020 15th International Conference on Computer Science & Education (ICCSE),18-22 Aug. 2020,ieeexplore
10.1109/ISC2.2016.7580798,SmartSEAL: A ROS based home automation framework for heterogeneous devices interconnection in smart buildings,IEEE,Conferences,"With this paper we present the SmartSEAL inter-connection system developed for the nationally founded SEAL project. SEAL is a research project aimed at developing Home Automation (HA) solutions for building energy management, user customization and improved safety of its inhabitants. One of the main problems of HA systems is the wide range of communication standards that commercial devices use. Usually this forces the designer to choose devices from a few brands, limiting the scope of the system and its capabilities. In this context, SmartSEAL is a framework that aims to integrate heterogeneous devices, such as sensors and actuators from different vendors, providing networking features, protocols and interfaces that are easy to implement and dynamically configurable. The core of our system is a Robotics middleware called Robot Operating System (ROS). We adapted the ROS features to the HA problem, designing the network and protocol architectures for this particular needs. These software infrastructure allows for complex HA functions that could be realized only levering the services provided by different devices. The system has been tested in our laboratory and installed in two real environments, Palazzo Fogazzaro in Schio and “Le Case” childhood school in Malo. Since one of the aim of the SEAL project is the personalization of the building environment according to the user needs, and the learning of their patterns of behaviour, in the final part of this work we also describe the ongoing design and experiments to provide a Machine Learning based re-identification module implemented with Convolutional Neural Networks (CNNs). The description of the adaptation module complements the description of the SmartSEAL system and helps in understanding how to develop complex HA services through it.",https://ieeexplore.ieee.org/document/7580798/,2016 IEEE International Smart Cities Conference (ISC2),12-15 Sept. 2016,ieeexplore
10.1109/ICRA40945.2020.9197523,SnapNav: Learning Mapless Visual Navigation with Sparse Directional Guidance and Visual Reference,IEEE,Conferences,"Learning-based visual navigation still remains a challenging problem in robotics, with two overarching issues: how to transfer the learnt policy to unseen scenarios, and how to deploy the system on real robots. In this paper, we propose a deep neural network based visual navigation system, SnapNav. Unlike map-based navigation or Visual-Teach-and-Repeat (VT&amp;R), SnapNav only receives a few snapshots of the environment combined with directional guidance to allow it to execute the navigation task. Additionally, SnapNav can be easily deployed on real robots due to a two-level hierarchy: a high level commander that provides directional commands and a low level controller that provides real-time control and obstacle avoidance. This also allows us to effectively use simulated and real data to train the different layers of the hierarchy, facilitating robust control. Extensive experimental results show that SnapNav achieves a highly autonomous navigation ability compared to baseline models, enabling sparse, map-less navigation in previously unseen environments.",https://ieeexplore.ieee.org/document/9197523/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ROMAN.2002.1045681,Socially interactive robots. Why our current beliefs about them still work,IEEE,Conferences,"Discussion about the application of scientific knowledge in robotics in order to build people helpers is widespread. The issue herein addressed is philosophically poignant, that of robots that are 'people'. It is currently popular to speak about robots and the image of Man. Behind this lurks the dialogical mind and the questions on its artificial existence. Without intending to defend or refute the discourse in favour of 'recreating' Man, a lesser familiar question is brought forth: 'Given that we are capable of creating a man (constructing a robot-person), what would the consequences of this be and would we be satisfied with such technology?' Thorny topic; it questions the entire knowledge foundation upon which strong AI/Robotics is positioned. The author argues for improved monitoring of technological progress and thus favours 'soft' (weak) implementation techniques.",https://ieeexplore.ieee.org/document/1045681/,Proceedings. 11th IEEE International Workshop on Robot and Human Interactive Communication,27-27 Sept. 2002,ieeexplore
10.1109/EMSOFT.2018.8537236,Special Session: Embedded Software for Robotics: Challenges and Future Directions,IEEE,Conferences,"This paper surveys recent challenges and solutions in the design, implementation, and verification of embedded software for robotics. Emphasis is placed on mobile robots, like self-driving cars. In design, it addresses programming support for robotic systems, secure state estimation, and ROS-based monitor generation. In the implementation phase, it describes the synthesis of control software using finite precision arithmetic, real-time platforms and architectures for safety-critical robotics, efficient implementation of neural network based-controllers, and standards for computer vision applications. The issues in verification include verification of neural network-based robotic controllers, and falsification of closed-loop control systems. The paper also describes notable open-source robotic platforms. Along the way, we highlight important research problems for developing the next generation of high-performance, low-resource-usage, correct embedded software.",https://ieeexplore.ieee.org/document/8537236/,2018 International Conference on Embedded Software (EMSOFT),30 Sept.-5 Oct. 2018,ieeexplore
10.1109/ICCRD.2011.5764067,Table of contents vol. 01,IEEE,Conferences,The following topics are dealt with: computer research and development; event driven programming; artificial intelligence; expert systems; algorithm analysis; high performance computing; automated software engineering; human computer interaction; bioinformatics; scientific computing; image processing; information retrieval; compilers; interpreters; computational intelligence; computer architecture; embedded systems; computer animation; Internet; Web applications; communication/networking; knowledge data engineering; computer system implementation; logics; VLSI; mathematical software; information systems; computer based education; mathematical logic; mobile computing; computer games; multimedia applications; computer graphics; virtual reality; natural language processing; neural networks; computer modeling; parallel computing; distributed computing; computer networks; pattern recognition; computer security; computer simulation; computer vision; probability; statistics; performance evaluation; computer aided design/manufacturing; computing ethics; programming languages; problem complexity; control systems; physical sciences; engineering; discrete mathematics; reconfigurable computing systems; data communications; robotics; automation; system security; cryptography; data compression; data encryption; data mining; database systems; document processing; text processing; educational technology; digital library; technology management; digital signal processing; theoretical computer science; digital systems; logic design; ubiquitous computing; and visualizations.,https://ieeexplore.ieee.org/document/5764067/,2011 3rd International Conference on Computer Research and Development,11-13 March 2011,ieeexplore
10.1109/FIE.2008.4720346,"Teaching concepts in fuzzy logic using low cost robots, PDAs, and custom software",IEEE,Conferences,"Fuzzy logic is a topic traditionally taught in artificial intelligence, machine learning, and robotics courses. Students receive the necessary mathematical and theoretical foundation in lecture format. The final learning experience may require that students create and code their own fuzzy logic application that solves a real world problem. This can be an issue when the target is a bioengineering course that introduces classical control theory, fuzzy logic, neural networks, genetic algorithms and genetic programming through the use of a low cost robot, personal digital assistant (PDA) handheld computer, and custom PDA software. In this course, the concepts and theories discussed in lecture are reinforced and extended in a corresponding laboratory through the use of wireless robots and PDAs. Fuzzy logic libraries and software modules for laptops and desktop computers are readily available, however, when it comes to handheld computers no such libraries exist. Students are able to spend more time experimenting with different fuzzy logic controllers when a custom fuzzy logic library and PDA graphical user interface are utilized. In this paper we introduce and discuss a unique low cost wireless robot, a custom fuzzy logic library, a custom fuzzy logic GUI for the PDA, and the implementation results for the fuzzy logic section in a newly created bioengineering course. Diagnostic and summative assessment in the form of a pre-test and post-test was administered for each section of the course, however, only the results for the fuzzy logic section will be provided.",https://ieeexplore.ieee.org/document/4720346/,2008 38th Annual Frontiers in Education Conference,22-25 Oct. 2008,ieeexplore
10.1109/ICARSC.2015.19,Testing a Fully Autonomous Robotic Salesman in Real Scenarios,IEEE,Conferences,"Over the past decades, the number of robots deployed in museums, trade shows and exhibitions have grown steadily. This new application domain has become a key research topic in the robotics community. Therefore, new robots are designed to interact with people in these domains, using natural and intuitive channels. Visual perception and speech processing have to be considered for these robots, as they should be able to detect people in their environment, recognize their degree of accessibility and engage them in social conversations. They also need to safely navigate around dynamic, uncontrolled environments. They must be equipped with planning and learning components, that allow them to adapt to different scenarios. Finally, they must attract the attention of the people, be kind and safe to interact with. In this paper, we describe our experience with Gualzru, a salesman robot endowed with the cognitive architecture RoboCog. This architecture synchronizes all previous processes in a social robot, using a common inner representation as the core of the system. The robot has been tested in crowded, public daily life environments, where it interacted with people that had never seen it before nor had a clue about its functionality. Experimental results presented in this paper demonstrate the capabilities of the robot and its limitations in these real scenarios, and define future improvement actions.",https://ieeexplore.ieee.org/document/7101621/,2015 IEEE International Conference on Autonomous Robot Systems and Competitions,8-10 April 2015,ieeexplore
10.1109/ICIA.2006.305788,The Design and Implementation of OpenGL-based Comprehensive Educational Robot System,IEEE,Conferences,"In this paper, the authors present the design and implementation of MountTai, a cost effective OpenGL based comprehensive educational robot system for China's primary and high school education. Firstly the system's goal and framework is introduced, then it is described the MountTai robot's functions and construction in hardware. The paper expatiates at length how VR technology is used to implement the system software as well as how the software's functions are designed to illustrate robotics in different perspectives relating to mechanics, electronics, communication, artificial intelligence, language programming. The Web-based teaching course dedicated to robot-DIY tutorials is also shown. Finally, concluding remarks for future works are given.",https://ieeexplore.ieee.org/document/4097992/,2006 IEEE International Conference on Information Acquisition,20-23 Aug. 2006,ieeexplore
10.1109/GHTC.2018.8601597,The EDNA Public Safety Drone: Bullet-Stopping Lifesaving,IEEE,Conferences,"Urban gun violence in cities across the world is a serious issue for public safety agencies and disaster management organizations. This led us to the development of the EDNA drone, an aerial robotics solution designed to equip first responders in high-risk settings with lifesaving-edge tools for situational awareness and non-lethal conflict resolution. The EDNA is an unmanned aerial vehicle (UAV) that delivers the patent-pending “Predictive Probable Cause” technology. The EDNA drone is designed to provide automated real-time analysis to assist teams entering high-risk situations where gun violence may occur. By leveraging machine learning, biometric sensors, and advanced materials in the field and routing feedback to an intuitive augmented-reality interface, the EDNA will provide autonomous threat detection and bullet-stopping capabilities wherever those features are needed--to groups such as Police and Sheriff's Departments, Fire Departments, and EMT and emergency rescue teams. Data from the EDNA drone's sensors is fed to machine learning algorithms running on the drone in real-time. Through a neural network trained on past data, the EDNA is able to detect the presence and location of firearms and explosives, even through walls or other obstacles. Through the use of advanced metal foams and composite materials, the armored drone can even stop bullets-functionality which has obvious benefits for humanitarian deployment.",https://ieeexplore.ieee.org/document/8601597/,2018 IEEE Global Humanitarian Technology Conference (GHTC),18-21 Oct. 2018,ieeexplore
10.1109/IEMC.1998.727776,The importance of artificial intelligence-expert systems in computer integrated manufacturing,IEEE,Conferences,"In order to maintain their competitiveness, companies feel compelled to adopt productivity increasing measures. Yet, they cannot relinquish the flexibility their production cycles need in order to improve their response, and thus, their positioning in the market. To achieve this, companies must combine these two seemingly opposed principles. Thanks to new technological advances, this combination is already a working reality in some companies. It is made possible today by the implementation of computer integrated manufacturing (CIM) and artificial intelligence (AI) techniques, fundamentally by means of expert systems (ES) and robotics. Depending on how these (AI/CIM) techniques contribute to automation, their immediate effects are an increase in productivity and cost reductions. Yet also, the system's flexibility allows for easier adaptation and, as a result, an increased ability to generate value, in other words, competitiveness is improved. The authors have analyzed three studies to identify the possible benefits or advantages, as well as the inconveniences, that this type of technique may bring to companies, specifically in the production field. Although the scope of the studies and their approach differ from one to the other, their joint contribution can be of unquestionable value in order to understand a little better the importance of ES within the production system.",https://ieeexplore.ieee.org/document/727776/,IEMC '98 Proceedings. International Conference on Engineering and Technology Management. Pioneering New Technologies: Management Issues and Challenges in the Third Millennium (Cat. No.98CH36266),11-13 Oct. 1998,ieeexplore
10.1109/ROBOT.2007.364220,Towards Mapping of Cities,IEEE,Conferences,"Map learning is a fundamental task in mobile robotics because maps are required for a series of high level applications. In this paper, we address the problem of building maps of large-scale areas like villages or small cities. We present our modified car-like robot which we use to acquire the data about the environment. We introduce our localization system which is based on an information filter and is able to merge the information obtained by different sensors. We furthermore describe out mapping technique that is able to compactly model three-dimensional scenes and allows us efficient and accurate incremental map learning. We additionally apply a global optimization techniques in order to accurately close loops in the environment. Our approach has been implemented and deeply tested on a real car equipped with a series of sensors. Experiments described in this paper illustrate the accuracy and efficiency of the presented techniques.",https://ieeexplore.ieee.org/document/4209838/,Proceedings 2007 IEEE International Conference on Robotics and Automation,10-14 April 2007,ieeexplore
10.1109/IROS.2015.7354134,Towards bridging the reality gap between tensegrity simulation and robotic hardware,IEEE,Conferences,"Using a new hardware implementation of our designs for tunably compliant spine-like tensegrity robots, we show that the NASA Tensegrity Robotics Toolkit can effectively generate and predict desirable locomotion strategies for these many degree of freedom systems. Tensegrity, which provides structural integrity through a tension network, shows promise as a design strategy for more compliant robots capable of interaction with rugged environments, such as a tensegrity interplanetary probe prototype surviving multi-story drops. Due to the complexity of tensegrity structures, modeling through physics simulation and machine learning improves our ability to design and evaluate new structures and their controllers in a dynamic environment. The kinematics of our simulator, the open source NASA Tensegrity Robotics Toolkit, have been previously validated within 1.3% error on position through motion capture of the six strut robot ReCTeR. This paper provides additional validation of the dynamics through the direct comparison of the simulator to forces experienced by the latest version of the Tetraspine robot. These results give us confidence in our strategy of using tensegrity to impart future robotic systems with properties similar to biological systems such as increased flexibility, power, and mobility in extreme terrains.",https://ieeexplore.ieee.org/document/7354134/,2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),28 Sept.-2 Oct. 2015,ieeexplore
10.1109/SECON.2017.7925321,Towards real-time segmentation of 3D point cloud data into local planar regions,IEEE,Conferences,"This article describes an algorithm for efficient segmentation of point cloud data into local planar surface regions. This is a problem of generic interest to researchers in the computer graphics, computer vision, artificial intelligence and robotics community where it plays an important role in applications such as object recognition, mapping, navigation and conversion from point clouds representations to 3D surface models. Prior work on the subject is either computationally burdensome, precluding real time applications such as robotic navigation and mapping, prone to error for noisy measurements commonly found at long range or requires availability of coregistered color imagery. The approach we describe consists of 3 steps: (1) detect a set of candidate planar surfaces, (2) cluster the planar surfaces merging redundant plane models, and (3) segment the point clouds by imposing a Markov Random Field (MRF) on the data and planar models and computing the Maximum A-Posteriori (MAP) of the segmentation labels using Bayesian Belief Propagation (BBP). In contrast to prior work which relies on color information for geometric segmentation, our implementation performs detection, clustering and estimation using only geometric data. Novelty is found in the fast clustering technique and new MRF clique potentials that are heretofore unexplored in the literature. The clustering procedure removes redundant detections of planes in the scene prior to segmentation using BBP optimization of the MRF to improve performance. The MRF clique potentials dynamically change to encourage distinct labels across depth discontinuities. These modifications provide improved segmentations for geometry-only depth images while simultaneously controlling the computational cost. Algorithm parameters are tunable to enable researchers to strike a compromise between segmentation detail and computational performance. Experimental results apply the algorithm to depth images from the NYU depth dataset which indicate that the algorithm can accurately extract large planar surfaces from depth sensor data.",https://ieeexplore.ieee.org/document/7925321/,SoutheastCon 2017,30 March-2 April 2017,ieeexplore
10.1109/ICAR46387.2019.8981600,Towards the Usage of Synthetic Data for Marker-Less Pose Estimation of Articulated Robots in RGB Images,IEEE,Conferences,"Pose estimation is a necessity for many applications in robotics incorporating interaction between the robot and external camera-equipped devices, e.g. mobile robots or Augmented Reality devices. In the practice of monocular cameras, one mostly takes advantage of pose estimation through fiducial marker detection. We propose a novel approach for marker-less robot pose estimation through monocular cameras utilizing 2D keypoint detection and 3D keypoint determination through readings from the encoders and forward kinematics. In particular, 2D-3D point correspondences enable the pose estimation through solving the Perspective-n-Point problem for calibrated cameras. The method does not rely on any depth data or initializations. The robust 2D keypoint detection is implemented by modern Convolutional Neural Networks trained on different dataset configurations of real and synthetic data in order to quantitatively evaluate robustness, precision and data efficiency. We demonstrate that the method provides robust pose estimation for random joint poses and benchmark the performance of different (synthetic) dataset configurations. Furthermore, we compare the accuracies to marker pose estimation and give an outlook towards enhancements and realtime capability.",https://ieeexplore.ieee.org/document/8981600/,2019 19th International Conference on Advanced Robotics (ICAR),2-6 Dec. 2019,ieeexplore
10.1109/VLSID.2018.20,Tutorial T2A: Safe Autonomous Systems: Real-Time Error Detection and Correction in Safety-Critical Signal Processing and Control Algorithms,IEEE,Conferences,"While the last two decades have seen revolutions in computing and communications systems, the next few decades will see a revolution in the use of every-day robotics and artificial intelligence in broad societal applications. Examples of such systems include sensor networks, the smart power grid, self-driven cars and autonomous drones. Such systems are driven by signal processing, control and learning algorithms that process sensor data, actuate control functions and learn about the environment in which these systems operate. The trustworthiness and safety of such systems is of paramount importance and has significant impact on the commercial viability of the underlying technology. As a consequence, anomalies in system operation due to computation errors in on-board processors, degradation and failure of embedded sensors, actuators and electro-mechanical subsystems and unforeseen changes in their operation environment need to detected with minimum latency. Such anomalies also need to be mitigated in ways that ensure the safety of such systems under all possible failure scenarios. Many future systems will be selflearning in the field. It is necessary to ensure that such learning does not compromise the safety of all human personnel involved in the operation of such systems. To enable safe operation of such systems, the underlying hardware needs to be tuned in the field to maximize performance, reliability and error-resilience while minimizing power consumption. To enable such dynamic adaptation, device operating conditions and the onset of soft errors are sensed using post-manufacture and real-time checking mechanisms. These mechanisms rely on the use of built-in sensors and/or low-overhead function encoding techniques to detect anomalies in system functions. A key capability is that of being able to deduce multiple performance parameters of the system-under-test using compact optimized stimulus using learning algorithms. The sensors and function encodings assess the loss in performance of the relevant systems due to workload uncertainties, manufacturing process imperfections, soft errors and hardware malfunction and failures induced by electromechanical degradation. These are then mitigated through the use of algorithm-through-circuit level compensation techniques based on pre-deployment simulation and post-deployment self-learning. These techniques continuously trade off performance vs. power of the individual software and hardware modules in such a way as to deliver the end-to-end desired application level Quality of Service (QoS), while minimizing energy/power consumption and maximizing reliability and safety. Applications to signal processing, and control algorithms for example autonomous systems will be discussed.",https://ieeexplore.ieee.org/document/8326883/,2018 31st International Conference on VLSI Design and 2018 17th International Conference on Embedded Systems (VLSID),6-10 Jan. 2018,ieeexplore
10.1109/ETFA.2016.7733537,UAV degradation identification for pilot notification using machine learning techniques,IEEE,Conferences,"Unmanned Aerial Vehicles are currently investigated as an important sub-domain of robotics, a fast growing and truly multidisciplinary research field. UAVs are increasingly deployed in real-world settings for missions in dangerous environments or in environments which are challenging to access. Combined with autonomous flying capabilities, many new possibilities, but also challenges, open up. To overcome the challenge of early identification of degradation, machine learning based on flight features is a promising direction. Existing approaches build classifiers that consider their features to be correlated. This prevents a fine-grained detection of degradation for the different hardware components. This work presents an approach where the data is considered uncorrelated and, using machine learning techniques, allows the precise identification of UAV's damages.",https://ieeexplore.ieee.org/document/7733537/,2016 IEEE 21st International Conference on Emerging Technologies and Factory Automation (ETFA),6-9 Sept. 2016,ieeexplore
10.1109/M2VIP.2018.8600864,Unsupervised Video Prediction Network with Spatio-temporal Deep Features,IEEE,Conferences,"Predicting the future states of things is an important performance form of intelligence and it is also of vital importance in real-time systems such as autonomous cars and robotics. This paper aims to tackle a video prediction task. Previous methods for future frame prediction are always subject to restrictions from environment, leading to poor accuracy and blurry prediction details. In this work, we present an unsupervised video prediction framework which iteratively anticipates the raw RGB pixel values in future video frames. Extensive experiments are implemented on advanced datasets - KTH and KITTI. The results demonstrate that our method achieves a good performance.",https://ieeexplore.ieee.org/document/8600864/,2018 25th International Conference on Mechatronics and Machine Vision in Practice (M2VIP),20-22 Nov. 2018,ieeexplore
10.1109/IDAACS-SWS50031.2020.9297062,Using a COTS Smartphone to Control an Autonomous Self-Driving Platform,IEEE,Conferences,"Recent interest in self-driving cars has boosted related fields like autonomous systems and robotics. This paper describes a simple and inexpensive small-scale self driving platform called ASV, which is based on a lowcost microcontroller and a COTS smartphone connected via WiFi. The camera of the phone, which is fixed to the platform, acquires images which are processed in a Convolutional Neural Network (CNN) inspired by the Nvidia's PilotNet. The network is trained in end-to-end learning to produce steering command to follow highway style lanes with markers on both sides. On the microcontroller, the steering commands are used for motor actuation and control of the physical movement of the platform. This paper presents the structure and implementation of ASV and evaluates its real-time performance and latency. For typical speeds encountered in small-scale systems, the performance is found more than sufficient for lane following with the CNN, leaving plenty of room for extensions. The platform's simplicity allows it to be used in research, education, and to spark interest in self-driving systems and neural networks. It can form the basis for general robot control.",https://ieeexplore.ieee.org/document/9297062/,2020 IEEE 5th International Symposium on Smart and Wireless Systems within the Conferences on Intelligent Data Acquisition and Advanced Computing Systems (IDAACS-SWS),17-18 Sept. 2020,ieeexplore
10.1109/IEEECONF51394.2020.9443272,VLSI Hardware Architecture for Gaussian Process,IEEE,Conferences,"Gaussian process (GP) is a popular machine learning technique that is widely used in many application domains, especially in robotics. However, GP is very computation intensive and time consuming during the inference phase, thereby bringing severe challenges for its large-scale deployment in real-time applications. In this paper, we propose two efficient hardware architecture for GP accelerator. One architecture targets for general GP inference, and the other architecture is specifically optimized for the scenario when the data point is gradually observed. Evaluation results show that the proposed hardware accelerator provides significant hardware performance improvement than the general-purpose computing platform.",https://ieeexplore.ieee.org/document/9443272/,"2020 54th Asilomar Conference on Signals, Systems, and Computers",1-4 Nov. 2020,ieeexplore
10.1109/ICRA.2019.8793556,VPE: Variational Policy Embedding for Transfer Reinforcement Learning,IEEE,Conferences,"Reinforcement Learning methods are capable of solving complex problems, but resulting policies might perform poorly in environments that are even slightly different. In robotics especially, training and deployment conditions often vary and data collection is expensive, making retraining undesirable. Simulation training allows for feasible training times, but on the other hand suffer from a reality-gap when applied in real-world settings. This raises the need of efficient adaptation of policies acting in new environments.We consider the problem of transferring knowledge within a family of similar Markov decision processes. We assume that Q-functions are generated by some low-dimensional latent variable. Given such a Q-function, we can find a master policy that can adapt given different values of this latent variable. Our method learns both the generative mapping and an approximate posterior of the latent variables, enabling identification of policies for new tasks by searching only in the latent space, rather than the space of all policies. The low-dimensional space, and master policy found by our method enables policies to quickly adapt to new environments. We demonstrate the method on both a pendulum swing-up task in simulation, and for simulation-to-real transfer on a pushing task.",https://ieeexplore.ieee.org/document/8793556/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/VR.2019.8798186,Virtual Reality and Photogrammetry for Improved Reproducibility of Human-Robot Interaction Studies,IEEE,Conferences,"Collecting data in robotics, especially human-robot interactions, traditionally requires a physical robot in a prepared environment, that presents substantial scalability challenges. First, robots provide many possible points of system failure, while the availability of human participants is limited. Second, for tasks such as language learning, it is important to create environments that provide interesting' varied use cases. Traditionally, this requires prepared physical spaces for each scenario being studied. Finally, the expense associated with acquiring robots and preparing spaces places serious limitations on the reproducible quality of experiments. We therefore propose a novel mechanism for using virtual reality to simulate robotic sensor data in a series of prepared scenarios. This allows for a reproducible dataset that other labs can recreate using commodity VR hardware. We demonstrate the effectiveness of this approach with an implementation that includes a simulated physical context, a reconstruction of a human actor, and a reconstruction of a robot. This evaluation shows that even a simple “sandbox” environment allows us to simulate robot sensor data, as well as the movement (e.g., view-port) and speech of humans interacting with the robot in a prescribed scenario.",https://ieeexplore.ieee.org/document/8798186/,2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),23-27 March 2019,ieeexplore
10.1109/JIOT.2019.2917066,A 64-mW DNN-Based Visual Navigation Engine for Autonomous Nano-Drones,IEEE,Journals,"Fully miniaturized robots (e.g., drones), with artificial intelligence (AI)-based visual navigation capabilities, are extremely challenging drivers of Internet-of-Things edge intelligence capabilities. Visual navigation based on AI approaches, such as deep neural networks (DNNs) are becoming pervasive for standard-size drones, but are considered out of reach for nano-drones with a size of a few cm<sup>2</sup>. In this paper, we present the first (to the best of our knowledge) demonstration of a navigation engine for autonomous nano-drones capable of closed-loop end-to-end DNN-based visual navigation. To achieve this goal we developed a complete methodology for parallel execution of complex DNNs directly on board resource-constrained milliwatt-scale nodes. Our system is based on GAP8, a novel parallel ultralow-power computing platform, and a 27-g commercial, open-source Crazyflie 2.0 nano-quadrotor. As part of our general methodology, we discuss the software mapping techniques that enable the DroNet state-of-the-art deep convolutional neural network to be fully executed aboard within a strict 6 frame-per-second real-time constraint with no compromise in terms of flight results, while all processing is done with only 64 mW on average. Our navigation engine is flexible and can be used to span a wide performance range: at its peak performance corner, it achieves 18 frames/s while still consuming on average just 3.5% of the power envelope of the deployed nano-aircraft. To share our key findings with the embedded and robotics communities and foster further developments in autonomous nano-unmanned aerial vehicles (UAVs), we publicly release all our code, datasets, and trained networks.",https://ieeexplore.ieee.org/document/8715489/,IEEE Internet of Things Journal,Oct. 2019,ieeexplore
10.1109/ACCESS.2018.2851841,A Brain-Inspired Multi-Modal Perceptual System for Social Robots: An Experimental Realization,IEEE,Journals,"We propose a multi-modal perceptual system that is inspired by the inner working of the human brain; in particular, the hierarchical structure of the sensory cortex and the spatial-temporal binding criteria. The system is context independent and can be applied to many on-going problems in social robotics, including but not limited to person recognition, emotion recognition, and multi-modal robot doctor to name a few. The system encapsulates the parallel distributed processing of real-world stimuli through different sensor modalities and encoding them into features vectors which in turn are processed via a number of dedicated processing units (DPUs) through hierarchical paths. DPUs are algorithmic realizations of the cell assemblies in neuroscience. A plausible and realistic perceptual system is presented via the integration of the outputs from these units by spiking neural networks. We will also discuss other components of the system including top-down influences and the integration of information through temporal binding with fading memory and suggest two alternatives to realize these criteria. Finally, we will demonstrate the implementation of this architecture on a hardware platform as a social robot and report experimental studies on the system.",https://ieeexplore.ieee.org/document/8400512/,IEEE Access,2018,ieeexplore
10.1109/ACCESS.2018.2835302,A Fast and Deterministic Algorithm for Consensus Set Maximization,IEEE,Journals,"With the current booming applications of virtual reality, augmented reality, and robotics, efficiently extracting the maximum consensus set among large-scale corrupted data has become a critical challenge. However, existing methods typically focus on optimization and are rarely concerned about the running time. In this paper, we propose a new fast and deterministic algorithm to address the consensus set maximization problem. First, we propose a novel formulation that transforms the original problem into a sequence of decision problems (DPs). Second, we propose an efficient algorithm to assess the feasibility of these DPs. Comprehensive experiments on linear hyper-plane regression and non-linear homography matrix estimation show that our approach is fully deterministic and can effectively process large-scale and highly corrupted data without any special initialization. Under a pure MATLAB implementation and a laptop CPU, our method can successfully determine the maximum consensus set from 1000 input data points (with 70% of them being outliers) at 30 Hz.",https://ieeexplore.ieee.org/document/8360018/,IEEE Access,2018,ieeexplore
10.1109/TCDS.2020.2968056,A Framework of Hybrid Force/Motion Skills Learning for Robots,IEEE,Journals,"Human factors and human-centered design philosophy are highly desired in today's robotics applications such as human-robot interaction (HRI). Several studies showed that endowing robots of human-like interaction skills can not only make them more likeable but also improve their performance. In particular, skill transfer by imitation learning can increase the usability and acceptability of robots by users without computer programming skills. In fact, besides positional information, muscle stiffness of the human arm and contact force with the environment also play important roles in understanding and generating human-like manipulation behaviors for robots, e.g., in physical HRI and teleoperation. To this end, we present a novel robot learning framework based on dynamic movement primitives (DMPs), taking into consideration both the positional and contact force profiles for human-robot skills transferring. Distinguished from the conventional method involving only the motion information, the proposed framework combines two sets of DMPs, which are built to model the motion trajectory and the force variation of the robot manipulator, respectively. Thus, a hybrid force/motion control approach is taken to ensure the accurate tracking and reproduction of the desired positional and force motor skills. Meanwhile, in order to simplify the control system, a momentum-based force observer is applied to estimate the contact force instead of employing force sensors. To deploy the learned motion-force robot manipulation skills to a broader variety of tasks, the generalization of these DMP models in actual situations is also considered. Comparative experiments have been conducted using a Baxter robot to verify the effectiveness of the proposed learning framework on real-world scenarios like cleaning a table.",https://ieeexplore.ieee.org/document/8964480/,IEEE Transactions on Cognitive and Developmental Systems,March 2021,ieeexplore
10.1109/TCSVT.2017.2726564,A Hardware Architecture for Cell-Based Feature-Extraction and Classification Using Dual-Feature Space,IEEE,Journals,"Many computer-vision and machine-learning applications in robotics, mobile, wearable devices, and automotive domains are constrained by their real-time performance requirements. This paper reports a dual-feature-based object recognition coprocessor that exploits both histogram of oriented gradient (HOG) and Haar-like descriptors with a cell-based parallel sliding-window recognition mechanism. The feature extraction circuitry for HOG and Haar-like descriptors is implemented by a pixel-based pipelined architecture, which synchronizes to the pixel frequency from the image sensor. After extracting each cell feature vector, a cell-based sliding window scheme enables parallelized recognition for all windows, which contain this cell. The nearest neighbor search classifier is, respectively, applied to the HOG and Haar-like feature space. The complementary aspects of the two feature domains enable a hardware-friendly implementation of the binary classification for pedestrian detection with improved accuracy. A proof-of-concept prototype chip fabricated in a 65-nm SOI CMOS, having thin gate oxide and buried oxide layers (SOTB CMOS), with 3.22-mm<sup>2</sup> core area achieves an energy efficiency of 1.52 nJ/pixel and a processing speed of 30 fps for 1024 × 1616-pixel image frames at 200-MHz recognition working frequency and 1-V supply voltage. Furthermore, multiple chips can implement image scaling, since the designed chip has image-size flexibility attributable to the pixel-based architecture.",https://ieeexplore.ieee.org/document/7979565/,IEEE Transactions on Circuits and Systems for Video Technology,Oct. 2018,ieeexplore
10.1109/TNSRE.2020.3044113,A Novel Point-in-Polygon-Based sEMG Classifier for Hand Exoskeleton Systems,IEEE,Journals,"In the early 2000s, data from the latest World Health Organization estimates paint a picture where one-seventh of the world population needs at least one assistive device. Fortunately, these years are also characterized by a marked technological drive which takes the name of the Fourth Industrial Revolution. In this terrain, robotics is making its way through more and more aspects of everyday life, and robotics-based assistance/rehabilitation is considered one of the most encouraging applications. Providing high-intensity rehabilitation sessions or home assistance through low-cost robotic devices can be indeed an effective solution to democratize services otherwise not accessible to everyone. However, the identification of an intuitive and reliable real-time control system does arise as one of the critical issues to unravel for this technology in order to land in homes or clinics. Intention recognition techniques from surface ElectroMyoGraphic (sEMG) signals are referred to as one of the main ways-to-go in literature. Nevertheless, even if widely studied, the implementation of such procedures to real-case scenarios is still rarely addressed. In a previous work, the development and implementation of a novel sEMG-based classification strategy to control a fully-wearable Hand Exoskeleton System (HES) have been qualitatively assessed by the authors. This paper aims to furtherly demonstrate the validity of such a classification strategy by giving quantitative evidence about the favourable comparison to some of the standard machine-learning-based methods. Real-time action, computational lightness, and suitability to embedded electronics will emerge as the major characteristics of all the investigated techniques.",https://ieeexplore.ieee.org/document/9291412/,IEEE Transactions on Neural Systems and Rehabilitation Engineering,Dec. 2020,ieeexplore
10.1109/TCYB.2019.2946090,A Robust Collision Perception Visual Neural Network With Specific Selectivity to Darker Objects,IEEE,Journals,"Building an efficient and reliable collision perception visual system is a challenging problem for future robots and autonomous vehicles. The biological visual neural networks, which have evolved over millions of years in nature and are working perfectly in the real world, could be ideal models for designing artificial vision systems. In the locust's visual pathways, a lobula giant movement detector (LGMD), that is, the LGMD2, has been identified as a looming perception neuron that responds most strongly to darker approaching objects relative to their backgrounds; similar situations which many ground vehicles and robots are often faced with. However, little has been done on modeling the LGMD2 and investigating its potential in robotics and vehicles. In this article, we build an LGMD2 visual neural network which possesses the similar collision selectivity of an LGMD2 neuron in locust via the modeling of biased-ON and -OFF pathways splitting visual signals into parallel ON/OFF channels. With stronger inhibition (bias) in the ON pathway, this model responds selectively to darker looming objects. The proposed model has been tested systematically with a range of stimuli including real-world scenarios. It has also been implemented in a micro-mobile robot and tested with real-time experiments. The experimental results have verified the effectiveness and robustness of the proposed model for detecting darker looming objects against various dynamic and cluttered backgrounds.",https://ieeexplore.ieee.org/document/8922628/,IEEE Transactions on Cybernetics,Dec. 2020,ieeexplore
10.1109/ACCESS.2020.3001277,"A Survey of Multi-Access Edge Computing in 5G and Beyond: Fundamentals, Technology Integration, and State-of-the-Art",IEEE,Journals,"Driven by the emergence of new compute-intensive applications and the vision of the Internet of Things (IoT), it is foreseen that the emerging 5G network will face an unprecedented increase in traffic volume and computation demands. However, end users mostly have limited storage capacities and finite processing capabilities, thus how to run compute-intensive applications on resource-constrained users has recently become a natural concern. Mobile edge computing (MEC), a key technology in the emerging fifth generation (5G) network, can optimize mobile resources by hosting compute-intensive applications, process large data before sending to the cloud, provide the cloud-computing capabilities within the radio access network (RAN) in close proximity to mobile users, and offer context-aware services with the help of RAN information. Therefore, MEC enables a wide variety of applications, where the real-time response is strictly required, e.g., driverless vehicles, augmented reality, robotics, and immerse media. Indeed, the paradigm shift from 4G to 5G could become a reality with the advent of new technological concepts. The successful realization of MEC in the 5G network is still in its infancy and demands for constant efforts from both academic and industry communities. In this survey, we first provide a holistic overview of MEC technology and its potential use cases and applications. Then, we outline up-to-date researches on the integration of MEC with the new technologies that will be deployed in 5G and beyond. We also summarize testbeds and experimental evaluations, and open source activities, for edge computing. We further summarize lessons learned from state-of-the-art research works as well as discuss challenges and potential future directions for MEC research.",https://ieeexplore.ieee.org/document/9113305/,IEEE Access,2020,ieeexplore
10.1109/TRO.2004.833801,A hybrid strategy to solve the forward kinematics problem in parallel manipulators,IEEE,Journals,"A parallel manipulator is a closed kinematic structure with the necessary rigidity to provide a high payload to self-weight ratio suitable for many applications in manufacturing, flight simulation systems, and medical robotics. Because of its closed structure, the kinematic control of such a mechanism is difficult. The inverse kinematics problem for such manipulators has a mathematical solution; however, the forward kinematics problem (FKP) is mathematically intractable. This work addresses the FKP and proposes a neural-network-based hybrid strategy that solves the problem to a desired level of accuracy, and can achieve the solution in real time. Two neural-network (NN) concepts using a modified form of multilayered perceptrons with backpropagation learning were implemented. The better performing concept was then combined with a standard Newton-Raphson numerical technique to yield a hybrid solution strategy. Simulation studies were carried out on a flight simulation syystem to check the validity o the approach. Accuracy of close to 0.01 mm and 0.01/spl deg/ in the position and orientation parameters was achieved in less than two iterations and 0.02 s of execution time for the proposed strategy.",https://ieeexplore.ieee.org/document/1391011/,IEEE Transactions on Robotics,Feb. 2005,ieeexplore
10.1109/TCDS.2018.2846778,Adaptive Behavior Acquisition of a Robot Based on Affective Feedback and Improvised Teleoperation,IEEE,Journals,"In socially assistive robotics, especially for children with autism spectrum disorder (ASD), adapting the behavior of the robot according to the personal characteristics of each individual is one of the important challenges. Machine learning techniques are promising approaches to endow a robot with the capability of adapting its behavior through the interaction. It is critical to prepare a rich data set such as a set of behaviors with teaching signals for each individual with ASD to allow application of the state-of-the-art machine learning techniques; however, this is typically difficult to prepare in advance owing to the diverseness of ASD and the complexity of the motion design of the robot. This paper proposes a framework to acquire the personalized behavior set of a robot by combining a robot teleoperation method and a wearable device for detecting the affective cue of a child with ASD while interacting with the robot. The developed system allows the human operator to improvise the robot's behavior flexibly in real-time to explore the preferred interaction manner and motion patterns of each child. The preferred motion patterns are extracted and evaluated based on the affective state of the child estimated by the wearable device, and stored in the personal database for each individual with ASD. We conducted a free-interaction experiment with ten participants with ASD and demonstrated that the proposed system successfully described the interaction between the robot and the participant for acquiring the appropriate behaviors of the robot.",https://ieeexplore.ieee.org/document/8383948/,IEEE Transactions on Cognitive and Developmental Systems,Sept. 2019,ieeexplore
10.1109/ACCESS.2020.2996576,An Embedded System for Collection and Real-Time Classification of a Tactile Dataset,IEEE,Journals,"Tactile perception of the material properties in real-time using tiny embedded systems is a challenging task and of grave importance for dexterous object manipulation such as robotics, prosthetics and augmented reality. As the psychophysical dimensions of the material properties cover a wide range of percepts, embedded tactile perception systems require efficient signal feature extraction and classification techniques to process signals collected by tactile sensors in real-time. For this purpose, we developed two embedded systems, one that served as a vibrotactile stimulator system and one that recorded and classified the vibrotactile signals collected by its sensors. The quality of the collected data was first verified offline using Fourier transform for feature extraction and then applying powerful machine learning classifiers such as support vector machines and neural networks. We implemented the proposed memory-less signal feature extraction method in order to achieve real-time processing as the data is being collected. The experimental results have shown that the proposed method significantly reduces the computational complexity of feature extraction and still has led to high classification accuracy even when fed to the less complex classifiers such as random forests that can be easily implemented on embedded systems. Finally, we have also shown that low-cost, highly accurate, and real-time tactile texture classification can be achieved using the proposed approach with an ensemble of sensors.",https://ieeexplore.ieee.org/document/9098886/,IEEE Access,2020,ieeexplore
10.1109/72.485630,Analog VLSI implementation for stereo correspondence between 2-D images,IEEE,Journals,"Many robotics and navigation systems utilizing stereopsis to determine depth have rigid size and power constraints and require direct physical implementation of the stereo algorithm. The main challenges lie in managing the communication between image sensor and image processor arrays, and in parallelizing the computation to determine stereo correspondence between image pixels in real-time. This paper describes the first comprehensive system level demonstration of a dedicated low-power analog VLSI (very large scale integration) architecture for stereo correspondence suitable for real-time implementation. The inputs to the implemented chip are the ordered pixels from a stereo image pair, and the output is a two-dimensional disparity map. The approach combines biologically inspired silicon modeling with the necessary interfacing options for a complete practical solution that can be built with currently available technology in a compact package. Furthermore, the strategy employed considers multiple factors that may degrade performance, including the spatial correlations in images and the inherent accuracy limitations of analog hardware, and augments the design with countermeasures.",https://ieeexplore.ieee.org/document/485630/,IEEE Transactions on Neural Networks,March 1996,ieeexplore
10.1109/ACCESS.2021.3093233,Assessment of a Robotic Assistant for Supporting Homework Activities of Children With ADHD,IEEE,Journals,"Robotics, Artificial Intelligence (AI), and the Internet of Things (IoT) support various processes in many scenarios of modern life such as e-health and psychological treatments. This article presents the design, development, implementation, and assessment of a Robotic Assistant (RA), named “Atent@”, as a support tool in the homework activities of children with Attention Deficit Hyperactivity Disorder (ADHD). Interacting with the children the RA helps them correct their bad habits and misbehavior caused by the disorder. Its features and functionalities were designed by therapists, implementing AI algorithms to process information and make decisions in real-time to help children to be focused on their homework. This RA interacts with smart objects deployed at home, which are associated with the activity under observation (desk and chair). This solution allows therapists to receive more accurate information about the homework sessions inside the home. At the same time, remote interaction with the child is made possible (through the RA) to provide new instructions and support him/her along with the sessions. This RA is a significant evolution of an earlier version. All the improvements brought to the project by the modifications in technical and qualitative features are explained. Furthermore, the experiment and its results are presented to illustrate the clinical potential. This project shows that the RA can not only make observations with a high degree of precision like an expert (teacher/therapist) but also positively influences the homework performance of children with and without ADHD.",https://ieeexplore.ieee.org/document/9466828/,IEEE Access,2021,ieeexplore
10.1109/ACCESS.2019.2925087,Automatic Gauge Detection via Geometric Fitting for Safety Inspection,IEEE,Journals,"For safety considerations in electrical substations, the inspection robots are recently deployed to monitor important devices and instruments with the presence of skilled technicians in the high-voltage environments. The captured images are transmitted to a data station and are usually analyzed manually. Toward automatic analysis, a common task is to detect gauges from captured images. This paper proposes a gauge detection algorithm based on the methodology of geometric fitting. We first use the Sobel filters to extract edges which usually contain the shapes of gauges. Then, we propose to use line fitting under the framework of random sample consensus (RANSAC) to remove straight lines that do not belong to gauges. Finally, the RANSAC ellipse fitting is proposed to find most fitted ellipse from the remaining edge points. The experimental results on a real-world dataset captured by the GuoZi Robotics demonstrate that our algorithm provides more accurate gauge detection results than several existing methods.",https://ieeexplore.ieee.org/document/8746263/,IEEE Access,2019,ieeexplore
10.1109/LRA.2017.2737046,Baxter's Homunculus: Virtual Reality Spaces for Teleoperation in Manufacturing,IEEE,Journals,"We demonstrate a low-cost telerobotic system that leverages commercial virtual reality (VR) technology and integrates it with existing robotics control infrastructure. The system runs on a commercial gaming engine using off-the-shelf VR hardware and can be deployed on multiple network architectures. The system is based on the homunculus model of mind wherein we embed the user in a VR control room. The control room allows for multiple sensor displays, and dynamic mapping between the user and robot. This dynamic mapping allows for selective engagement between the user and the robot. We compared our system with state-of-the-art automation algorithms and standard VR-based telepresence systems by performing a user study. The study showed that new users were faster and more accurate than the automation or a direct telepresence system. We also demonstrate that our system can be used for pick and place, assembly, and manufacturing tasks.",https://ieeexplore.ieee.org/document/8003431/,IEEE Robotics and Automation Letters,Jan. 2018,ieeexplore
10.1109/JOE.2012.2205638,COLA2: A Control Architecture for AUVs,IEEE,Journals,"This paper presents a control architecture for an autonomous underwater vehicle (AUV) named the Component Oriented Layer-based Architecture for Autonomy (COLA2). The proposal implements a component-oriented layer-based control architecture structured in three layers: the reactive layer, the execution layer, and the mission layer. Concerning the reactive layer, to improve the vehicle primitives' adaptability to unknown changing environments, reinforcement learning (RL) techniques have been programmed. Starting from a learned-in-simulation policy, the RL-based primitive cableTracking has been trained to follow an underwater cable in a real experiment inside a water tank using the Ictineu AUV. The execution layer implements a discrete event system (DES) based on Petri nets (PNs). PNs have been used to safely model the primitives' execution flow by means of Petri net building block (PNBBs) that have been designed according to some reachability properties showing that it is possible to compose them preserving these qualities. The mission layer describes the mission phases using a high-level mission control language (MCL), which is automatically compiled into a PN. The MCL presents agreeable properties of simplicity and structured programming. MCL can be used to describe offline imperative missions or to describe planning operators, in charge of solving a particular phase of a mission. If planning operators are defined, an onboard planner will be able to sequence them to achieve the proposed goals. The whole architecture has been validated in a cable tracking mission divided in two main phases. First, the cableTracking primitive of the reactive layer has been trained to follow a cable in a water tank with the Ictineu AUV, one of the research platforms available in the Computer Vision and Robotics Group (VICOROB), University of Girona, Girona, Spain. Second, the whole architecture has been proved in a realistic simulation of a whole cable tracking mission.",https://ieeexplore.ieee.org/document/6263248/,IEEE Journal of Oceanic Engineering,Oct. 2012,ieeexplore
10.1109/ACCESS.2021.3105136,Cocktail Glass Network: Fast Depth Estimation Using Channel to Space Unrolling,IEEE,Journals,"Depth-estimation from a single input image can be used in applications such as robotics and autonomous driving. Recently, depth-estimation networks with UNet encoder/decoder structures have been widely used. In these decoders, operations are repeated to gradually increase the image resolution, while decreasing the channel size. If the upsampling operation at a high magnification can be processed at once, the amount of computation in the decoder can be dramatically reduced. To achieve this, we propose a new network structure, i.e., a cocktail glass network. In this network, convolution layers in the decoder are reduced, and a novel fast upsampling method is used that is known as channel-to-space unrolling, which converts thick channel data into high-resolution data. The proposed method can be easily implemented using simple reshaping operations; therefore, it is suitable for reducing the depth-estimation network. Considering the experimental results based on the NYU V2 and KITTI datasets, we demonstrate that the proposed method reduces the amount of computation in the decoder by half, while maintaining the same level of accuracy; it can be used in both lightweight and large-model-capacity networks.",https://ieeexplore.ieee.org/document/9514839/,IEEE Access,2021,ieeexplore
10.1109/TIE.2015.2425359,Coordination of Multiple Robotic Fish With Applications to Underwater Robot Competition,IEEE,Journals,"This paper is concerned with the coordination control of multiple biomimetic robotic fish in highly dynamic aquatic environments by building a hybrid centralized system. With the aid of the results of biorobotics and control techniques, a radio-controlled multijoint robotic fish and its locomotion control are developed. To enable a closed control loop, a visual subsystem that is responsible for tracking of multiple moving objects is constructed and implemented in real time. Furthermore, a behavior-based hierarchical architecture in conjunction with fuzzy reinforcement learning is proposed to accomplish effective coordination among multiple swimming robots. Finally, experiments on 2vs2 water polo game are carried out to verify the proposed coordination control scheme. Over the past eight years, this multirobot platform has been successfully applied to international underwater robot competitions to promote innovative research and education in underwater robotics.",https://ieeexplore.ieee.org/document/7091905/,IEEE Transactions on Industrial Electronics,Feb. 2016,ieeexplore
10.1109/TSMC.2020.2967936,Deep Q-Learning With Q-Matrix Transfer Learning for Novel Fire Evacuation Environment,IEEE,Journals,"Deep reinforcement learning (RL) is achieving significant success in various applications like control, robotics, games, resource management, and scheduling. However, the important problem of emergency evacuation, which clearly could benefit from RL, has been largely unaddressed. Indeed, emergency evacuation is a complex task that is difficult to solve with RL. An emergency situation is highly dynamic, with a lot of changing variables and complex constraints that make it challenging to solve. Also, there is no standard benchmark environment available that can be used to train RL agents for evacuation. A realistic environment can be complex to design. In this article, we propose the first fire evacuation environment to train RL agents for evacuation planning. The environment is modeled as a graph capturing the building structure. It consists of realistic features like fire spread, uncertainty, and bottlenecks. The implementation of our environment is in the OpenAI gym format, to facilitate future research. We also propose a new RL approach that entails pretraining the network weights of a DQN-based agent [DQN/Double-DQN (DDQN)/Dueling-DQN] to incorporate information on the shortest path to the exit. We achieved this by using tabular <inline-formula> <tex-math notation=""LaTeX"">$Q$ </tex-math></inline-formula>-learning to learn the shortest path on the building model’s graph. This information is transferred to the network by deliberately overfitting it on the <inline-formula> <tex-math notation=""LaTeX"">$Q$ </tex-math></inline-formula>-matrix. Then, the pretrained DQN model is trained on the fire evacuation environment to generate the optimal evacuation path under time varying conditions due to fire spread, bottlenecks, and uncertainty. We perform comparisons of the proposed approach with state-of-the-art RL algorithms like DQN, DDQN, Dueling-DQN, PPO, VPG, state-action-reward-state-action (SARSA), actor–critic method, and ACKTR. The results show that our method is able to outperform state-of-the-art models by a huge margin including the original DQN-based models. Finally, our model is tested on a large and complex real building consisting of 91 rooms, with the possibility to move to any other room, hence giving 8281 actions. In order to reduce the action space, we propose a strategy that involves one step simulation. That is, an action importance vector is added to the final output of the pretrained DQN and acts like an attention mechanism. Using this strategy, the action space is reduced by 90.1%. In this manner, the model is able to deal with large action spaces. Hence, our model achieves near optimal performance on the real world emergency environment.",https://ieeexplore.ieee.org/document/8989970/,"IEEE Transactions on Systems, Man, and Cybernetics: Systems",Dec. 2021,ieeexplore
10.1109/TNSRE.2013.2294685,"Demonstration of a Semi-Autonomous Hybrid Brain–Machine Interface Using Human Intracranial EEG, Eye Tracking, and Computer Vision to Control a Robotic Upper Limb Prosthetic",IEEE,Journals,"To increase the ability of brain-machine interfaces (BMIs) to control advanced prostheses such as the modular prosthetic limb (MPL), we are developing a novel system: the Hybrid Augmented Reality Multimodal Operation Neural Integration Environment (HARMONIE). This system utilizes hybrid input, supervisory control, and intelligent robotics to allow users to identify an object (via eye tracking and computer vision) and initiate (via brain-control) a semi-autonomous reach-grasp-and-drop of the object by the MPL. Sequential iterations of HARMONIE were tested in two pilot subjects implanted with electrocortico-graphic (ECoG) and depth electrodes within motor areas. The subjects performed the complex task in 71.4% (20/28) and 67.7% (21/31) of trials after minimal training. Balanced accuracy for detecting movements was 91.1% and 92.9%, significantly greater than chance accuracies (p &lt;; 0.05). After BMI-based initiation, the MPL completed the entire task 100% (one object) and 70% (three objects) of the time. The MPL took approximately 12.2 s for task completion after system improvements implemented for the second subject. Our hybrid-BMI design prevented all but one baseline false positive from initiating the system. The novel approach demonstrated in this proof-of-principle study, using hybrid input, supervisory control, and intelligent robotics, addresses limitations of current BMIs.",https://ieeexplore.ieee.org/document/6683036/,IEEE Transactions on Neural Systems and Rehabilitation Engineering,July 2014,ieeexplore
10.1109/LRA.2021.3062323,Differentiable Simulation for Physical System Identification,IEEE,Journals,"Simulating frictional contacts remains a challenging research topic in robotics. Recently, differentiable physics emerged and has proven to be a key element in model-based Reinforcement Learning (RL) and optimal control fields. However, most of the current formulations deploy coarse approximations of the underlying physical principles. Indeed, the classic simulators loose precision by casting the Nonlinear Complementarity Problem (NCP) of frictional contact into a Linear Complementarity Problem (LCP) to simplify computations. Moreover, such methods deploy non-smooth operations and cannot be automatically differentiated. In this letter, we propose (i) an extension of the staggered projections algorithm for more accurate solutions of the problem of contacts with friction. Based on this formulation, we introduce (ii) a differentiable simulator and an efficient way to compute the analytical derivatives of the involved optimization problems. Finally, (iii) we validate the proposed framework with a set of experiments to present a possible application of our differentiable simulator. In particular, using our approach we demonstrate accurate estimation of friction coefficients and object masses both in synthetic and real experiments.",https://ieeexplore.ieee.org/document/9363565/,IEEE Robotics and Automation Letters,April 2021,ieeexplore
10.1109/TRO.2019.2929015,Fault Detection in a Swarm of Physical Robots Based on Behavioral Outlier Detection,IEEE,Journals,"The ability to reliably detect faults is essential in many real-world tasks that robot swarms have the potential to perform. Most studies on fault detection in swarm robotics have been conducted exclusively in simulation, and they have focused on a single type of fault or a specific task. In a series of previous studies, we have developed a robust fault-detection approach in which robots in a swarm learn to distinguish between normal and faulty behaviors online. In this paper, we assess the performance of our fault-detection approach on a swarm of seven physical mobile robots. We experiment with three classic swarm robotics tasks and consider several types of faults in both sensors and actuators. Experimental results show that the robots are able to reliably detect the presence of hardware faults in one another even when the swarm behavior is changed during operation. This paper is thus an important step toward making robot swarms sufficiently reliable and dependable for real-world applications.",https://ieeexplore.ieee.org/document/8787875/,IEEE Transactions on Robotics,Dec. 2019,ieeexplore
10.1109/TPDS.2020.3006238,GPU-Accelerated Real-Time Stereo Estimation With Binary Neural Network,IEEE,Journals,"Depth estimation from stereo images is essential to many applications such as robotics and autonomous vehicles, most of which ask for the real-time response, high energy and storage efficiency. Recent work has shown deep neural networks (DNN) perform extremely well for stereo estimation. However, these state-of-the-art DNN based algorithms are challenging to be deployed into real-world applications due to the high computational complexities of DNNs. Most of them are too slow for real-time inference and require several seconds of GPU computation to process image frames. In this article, we address the problem of fast stereo estimation and propose an efficient and light-weighted stereo matching system, called StereoBit, to produce a disparity map in a real-time manner while achieving close to state-of-the-art accuracy. To achieve this goal, we propose a binary neural network to generate weighted Hamming distance for an efficient similarity join in stereo estimation. In addition, we propose a novel approximation approach to derive StereoBit network directly from the well-trained network with the cosine similarity. Our approximation strategies enable a significant speedup while maintaining almost the same accuracy compared to the network with the cosine similarity. Furthermore, we present an optimization framework for fully exploiting the computing power of StereoBit. The framework provides a significant speedup of stereo estimation routines, and at the same time, reduces the memory usage for storing parameters. The effectiveness of StereoBit is evaluated by comprehensive experiments. StereoBit can achieve 60 frames per second on an NVIDIA TITAN Xp GPU on KITTI 2012 benchmark while achieving 3-pixel non-occluded stereo error 3.56 percent.",https://ieeexplore.ieee.org/document/9130887/,IEEE Transactions on Parallel and Distributed Systems,1 Dec. 2020,ieeexplore
10.1109/TLA.2019.9011550,Gate Detection for Micro Aerial Vehicles using a Single Shot Detector,IEEE,Journals,"Object detection has become an essential tool in aerial robotics thanks to the use of onboard cameras in drones that enables find objects using techniques of vision. However, vision algorithms may become unreliable presenting drawback by the illumination changes. Deep learning has been used to solve tasks of classification, segmentation and detection using traditional Convolutional Neural Network (CNN) like VGG16, YOLO and AlexNet. This paper presents a gates detector system in a real-time using CNN based on a Single Shot Detector Network (SSD) for drone racing circuits. For the latter, we have adopted the SSD7 architecture to modified and present an implementation with five layers, reducing the prediction time and improve detection velocity in comparison with other architectures. For evaluation purpose, we selected three environments: simulation, indoors and outdoors to compare the prediction time, average fps and the confidence obtained in the detections of the gates.",https://ieeexplore.ieee.org/document/9011550/,IEEE Latin America Transactions,December 2019,ieeexplore
10.1109/ACCESS.2021.3109733,Hardware-Aware Affordance Detection for Application in Portable Embedded Systems,IEEE,Journals,"Affordance detection in computer vision allows segmenting an object into parts according to functions that those parts afford. Most solutions for affordance detection are developed in robotics using deep learning architectures that require substantial computing power. Therefore, these approaches are not convenient for application in embedded systems with limited resources. For instance, computer vision is used in smart prosthetic limbs, and in this context, affordance detection could be employed to determine the graspable segments of an object, which is a critical information for selecting a grasping strategy. This work proposes an affordance detection strategy based on hardware-aware deep learning solutions. Experimental results confirmed that the proposed solution achieves comparable accuracy with respect to the state-of-the-art approaches. In addition, the model was implemented on real-time embedded devices obtaining a high FPS rate, with limited power consumption. Finally, the experimental assessment in realistic conditions demonstrated that the developed method is robust and reliable. As a major outcome, the paper proposes and characterizes the first complete embedded solution for affordance detection in embedded devices. Such a solution could be used to substantially improve computer vision based prosthesis control but it is also highly relevant for other applications (e.g., resource-constrained robotic systems).",https://ieeexplore.ieee.org/document/9527234/,IEEE Access,2021,ieeexplore
10.1109/ACCESS.2019.2895653,High-Quality 3D Reconstruction With Depth Super-Resolution and Completion,IEEE,Journals,"The 3D reconstruction is an important topic in computer vision with many applications, such as robotics and augmented reality. Since the raw depth images captured by consumer RGB-D cameras are often low resolution (LR), noisy, and incomplete. How to obtain high-quality 3D models with a consumer RGB-D camera is still a challenge for the existing systems. In this paper, we propose a new depth super-resolution and completion method implemented in a deep learning framework and build a high-quality 3D reconstruction system. We first improve the resolution of LR depth image with a depth super-resolution network and remove the outliers in high-resolution (HR) depth image based on gradient saliency. To further enhance the quality of HR depth image with the guide of HR color image, we learn surface normal and occlusion boundary images from the corresponding HR color image through two deep fully convolutional networks. In particular, the blurriness of HR color image is also detected and pixel-wise quantized. Finally, we obtain a completed HR depth image by optimizing the HR depth image with the surface normal, occlusion boundary, and color image blurriness. We have carried out qualitative and quantitative evaluations with baseline methods on public datasets. The experimental results demonstrate that our method has better performance both on single depth image enhancement and 3D reconstruction.",https://ieeexplore.ieee.org/document/8628990/,IEEE Access,2019,ieeexplore
10.1109/LRA.2021.3061336,Imitation Learning of Hierarchical Driving Model: From Continuous Intention to Continuous Trajectory,IEEE,Journals,"One of the challenges to reduce the gap between the machine and the human level driving is how to endow the system with the learning capacity to deal with the coupled complexity of environments, intentions, and dynamics. In this letter, we propose a hierarchical driving model with explicit models of continuous intention and continuous dynamics, which decouples the complexity in the observation-to-action reasoning in the human driving data. Specifically, the continuous intention module takes perception to generate a potential map encoded with obstacles and intentions. Then, the potential map is regarded as a condition, together with the current dynamics, to generate a continuous trajectory as output by a continuous function approximator network, whose derivatives can be used for supervision without additional parameters. Finally, our method is validated by both datasets and stimulation, demonstrating that our method has higher prediction accuracy of displacement and velocity and generates smoother trajectories. Our method is also deployed on the real vehicle with loop latency, validating its effectiveness. To the best of our knowledge, this is the first work to produce the driving trajectory using a continuous function approximator network. Our code is available at https://github.com/ZJU-Robotics-Lab/CICT.",https://ieeexplore.ieee.org/document/9361054/,IEEE Robotics and Automation Letters,April 2021,ieeexplore
10.1109/LRA.2020.3013937,Invariant Transform Experience Replay: Data Augmentation for Deep Reinforcement Learning,IEEE,Journals,"Deep Reinforcement Learning (RL) is a promising approach for adaptive robot control, but its current application to robotics is currently hindered by high sample requirements. To alleviate this issue, we propose to exploit the symmetries present in robotic tasks. Intuitively, symmetries from observed trajectories define transformations that leave the space of feasible RL trajectories invariant and can be used to generate new feasible trajectories, which could be used for training. Based on this data augmentation idea, we formulate a general framework, called Invariant Transform Experience Replay that we present with two techniques: (i) Kaleidoscope Experience Replay exploits reflectional symmetries and (ii) Goal-augmented Experience Replay which takes advantage of lax goal definitions. In the Fetch tasks from OpenAI Gym, our experimental results show significant increases in learning rates and success rates. Particularly, we attain a 13, 3, and 5 times speedup in the pushing, sliding, and pick-and-place tasks respectively in the multi-goal setting. Performance gains are also observed in similar tasks with obstacles and we successfully deployed a trained policy on a real Baxter robot. Our work demonstrates that invariant transformations on RL trajectories are a promising methodology to speed up learning in deep RL. Code, video, and supplementary materials are available at [1].",https://ieeexplore.ieee.org/document/9158366/,IEEE Robotics and Automation Letters,Oct. 2020,ieeexplore
10.1109/JETCAS.2020.3033135,<italic>Learning to Walk</italic>: Bio-Mimetic Hexapod Locomotion via Reinforcement-Based Spiking Central Pattern Generation,IEEE,Journals,"Online learning for the legged robot locomotion under performance and energy constraints remains to be a challenge. Methods such as stochastic gradient, deep reinforcement learning (RL) have been explored for bipeds, quadrupeds and hexapods. These techniques are computationally intensive and thus difficult to implement on edge computing platforms. These methods are also inefficient in energy consumption and throughput because of their reliance on complex sensors and pre-processing of data. On the other hand, neuromorphic computing paradigms, such as spiking neural networks (SNN), become increasingly favorable in low power computing on edge intelligence. SNN has exhibited the capability of performing reinforcement learning mechanisms with biomimetic spike time-dependent plasticity (STDP) of synapses. However, training a legged robot to walk in the synchronized gait patterns generated by a central pattern generator (CPG) in an SNN framework has not yet been explored. Such a method can combine the efficiency of SNNs with the synchronized locomotion of CPG based systems - providing breakthrough performance improvement of end-to-end learning in mobile robotics. In this paper, we propose a reinforcement based stochastic learning technique for training a spiking CPG for a hexapod robot which learns to walk using bio-inspired tripod gait without prior knowledge. The whole system is implemented on a lightweight raspberry pi platform with integrated sensors. Our method opens new opportunities for online learning with limited edge computing resources.",https://ieeexplore.ieee.org/document/9235477/,IEEE Journal on Emerging and Selected Topics in Circuits and Systems,Dec. 2020,ieeexplore
10.1109/TAMD.2015.2507439,Lifelong Augmentation of Multimodal Streaming Autobiographical Memories,IEEE,Journals,"Robot systems that interact with humans over extended periods of time will benefit from storing and recalling large amounts of accumulated sensorimotor and interaction data. We provide a principled framework for the cumulative organization of streaming autobiographical data so that data can be continuously processed and augmented as the processing and reasoning abilities of the agent develop and further interactions with humans take place. As an example, we show how a kinematic structure learning algorithm reasons a-posteriori about the skeleton of a human hand. A partner can be asked to provide feedback about the augmented memories, which can in turn be supplied to the reasoning processes in order to adapt their parameters. We employ active, multimodal remembering, so the robot as well as humans can gain insights of both the original and augmented memories. Our framework is capable of storing discrete and continuous data in real-time. The data can cover multiple modalities and several layers of abstraction (e.g., from raw sound signals over sentences to extracted meanings). We show a typical interaction with a human partner using an iCub humanoid robot. The framework is implemented in a platform-independent manner. In particular, we validate its multi platform capabilities using the iCub, Baxter and NAO robots. We also provide an interface to cloud based services, which allow automatic annotation of episodes. Our framework is geared towards the developmental robotics community, as it: 1) provides a variety of interfaces for other modules; 2) unifies previous works on autobiographical memory; and 3) is licensed as open source software.",https://ieeexplore.ieee.org/document/7350228/,IEEE Transactions on Cognitive and Developmental Systems,Sept. 2016,ieeexplore
10.1109/LRA.2020.2970679,Low to High Dimensional Modality Hallucination Using Aggregated Fields of View,IEEE,Journals,"Real-world robotics systems deal with data from a multitude of modalities, especially for tasks such as navigation and recognition. The performance of those systems can drastically degrade when one or more modalities become inaccessible, due to factors such as sensors' malfunctions or adverse environments. Here, we argue modality hallucination as one effective way to ensure consistent modality availability and thereby reduce unfavorable consequences. While hallucinating data from a modality with richer information, e.g., RGB to depth, has been researched extensively, we investigate the more challenging low-to-high modality hallucination with interesting use cases in robotics and autonomous systems. We present a novel hallucination architecture that aggregates information from multiple fields of view of the local neighborhood to recover the lost information from the extant modality. The process is implemented by capturing a non-linear mapping between the data modalities and the learned mapping is used to aid the extant modality to mitigate the risk posed to the system in the adverse scenarios which involve modality loss. We also conduct extensive classification and segmentation experiments on UWRGBD and NYUD datasets and demonstrate that hallucination allays the negative effects of the modality loss. Implementation and models: https://github.com/kausic94/Hallucination.",https://ieeexplore.ieee.org/document/8977350/,IEEE Robotics and Automation Letters,April 2020,ieeexplore
10.1109/TIM.2018.2884450,Low-order Nonlinear Finite-Impulse Response Soft Sensors for Ionic Electroactive Actuators Based on Deep Learning,IEEE,Journals,"This paper introduces a soft sensor (SS) for the estimation of the deflection of a polymeric mechanical actuator. The actuator is based on ionic polymer-metal composites (IPMCs). Applications of IPMCs have been proposed in fields such as robotics, surgery, and aerospace, to mention the most interesting ones. In such application fields, both the complexity and the size of the actuating system are of chief importance. An SS can be, therefore, preferred to hardware measuring the actuator output, for estimating the actuator motion. Also, low-order models are of interest to limit the computational load, which can be a constraint in real-time applications. To this aim, several data-driven nonlinear finite-impulse response (NFIR) models have been investigated. Data, used for the model identification, have been acquired, in controlled environmental conditions, by using swept signals as the input to the IPMC actuator. Linear and nonlinear models, based on principal component analysis, shallow, and deep neural networks (NNs), have been investigated, for different model orders. The best results have been obtained by an SS based on a fifth-order NFIR model, implemented by a deep belief NN.",https://ieeexplore.ieee.org/document/8584087/,IEEE Transactions on Instrumentation and Measurement,May 2019,ieeexplore
10.1109/JPROC.2018.2856739,Navigating the Landscape for Real-Time Localization and Mapping for Robotics and Virtual and Augmented Reality,IEEE,Journals,"Visual understanding of 3-D environments in real time, at low power, is a huge computational challenge. Often referred to as simultaneous localization and mapping (SLAM), it is central to applications spanning domestic and industrial robotics, autonomous vehicles, and virtual and augmented reality. This paper describes the results of a major research effort to assemble the algorithms, architectures, tools, and systems software needed to enable delivery of SLAM, by supporting applications specialists in selecting and configuring the appropriate algorithm and the appropriate hardware, and compilation pathway, to meet their performance, accuracy, and energy consumption goals. The major contributions we present are: 1) tools and methodology for systematic quantitative evaluation of SLAM algorithms; 2) automated, machine-learning-guided exploration of the algorithmic and implementation design space with respect to multiple objectives; 3) end-to-end simulation tools to enable optimization of heterogeneous, accelerated architectures for the specific algorithmic requirements of the various SLAM algorithmic approaches; and 4) tools for delivering, where appropriate, accelerated, adaptive SLAM solutions in a managed, JIT-compiled, adaptive runtime context.",https://ieeexplore.ieee.org/document/8436423/,Proceedings of the IEEE,Nov. 2018,ieeexplore
10.1162/089976602760407955,Real-Time Computing Without Stable States: A New Framework for Neural Computation Based on Perturbations,MIT Press,Journals,"A key challenge for neural modeling is to explain how a continuous stream of multimodal input from a rapidly changing environment can be processed by stereotypical recurrent circuits of integrate-and-fire neurons in real time. We propose a new computational model for real-time computing on time-varying input that provides an alternative to paradigms based on Turing machines or attractor neural networks. It does not require a task-dependent construction of neural circuits. Instead, it is based on principles of high-dimensional dynamical systems in combination with statistical learning theory and can be implemented on generic evolved or found recurrent circuitry. It is shown that the inherent transient dynamics of the high-dimensional dynamical system formed by a sufficiently large and heterogeneous neural circuit may serve as universal analog fading memory. Readout neurons can learn to extract in real time from the current state of such recurrent neural circuit information about current and past inputs that may be needed for diverse tasks. Stable internal states are not required for giving a stable output, since transient internal states can be transformed by readout neurons into stable target outputs due to the high dimensionality of the dynamical system. Our approach is based on a rigorous computational model, the liquid state machine, that, unlike Turing machines, does not require sequential transitions between well-defined discrete internal states. It is supported, as the Turing machine is, by rigorous mathematical results that predict universal computational power under idealized conditions, but for the biologically more realistic scenario of real-time processing of time-varying inputs. Our approach provides new perspectives for the interpretation of neural coding, the design of experiments and data analysis in neurophysiology, and the solution of problems in robotics and neurotechnology.",https://ieeexplore.ieee.org/document/6789852/,Neural Computation,1 Nov. 2002,ieeexplore
10.1109/TASE.2019.2940543,Robust Visual Localization in Dynamic Environments Based on Sparse Motion Removal,IEEE,Journals,"Visual localization has been well studied in recent decades and applied in many fields as a fundamental capability in robotics. However, the success of the state of the arts usually builds on the assumption that the environment is static. In dynamic scenarios where moving objects are present, the performance of the existing visual localization systems degrades a lot due to the disturbance of the dynamic factors. To address this problem, we propose a novel sparse motion removal (SMR) model that detects the dynamic and static regions for an input frame based on a Bayesian framework. The similarity between the consecutive frames and the difference between the current frame and the reference frame are both considered to reduce the detection uncertainty. After the detection process is finished, the dynamic regions are eliminated while the static ones are fed into a feature-based visual simultaneous localization and mapping (SLAM) system for further visual localization. To verify the proposed method, both qualitative and quantitative experiments are performed and the experimental results have demonstrated that the proposed model can significantly improve the accuracy and robustness for visual localization in dynamic environments.&lt;;/p&gt;&lt;;p&gt;&lt;;italic&gt;Note to Practitioners&lt;;/italic&gt;-This article was motivated by the visual localization problem in dynamic environments. Visual localization is well applied in many robotic fields such as path planning and exploration as the basic capability for a mobile robot. In the GPS-denied environments, one robot needs to localize itself through perceiving the unknown environment based on a visual sensor. In real-world scenes, the existence of the moving objects will significantly degrade the localization accuracy, which makes the robot implementation unreliable. In this article, an SMR model is designed to handle this problem. Once receiving a frame, the proposed model divides it into dynamic and static regions through a Bayesian framework. The dynamic regions are eliminated, while the static ones are maintained and fed into a feature-based visual SLAM system for further visual localization. The proposed method greatly improves the localization accuracy in dynamic environments and guarantees the robustness for robotic implementation.",https://ieeexplore.ieee.org/document/8855084/,IEEE Transactions on Automation Science and Engineering,April 2020,ieeexplore
10.1109/LRA.2017.2665694,Shakey 2016—How Much Does it Take to Redo Shakey the Robot?,IEEE,Journals,"Shakey the robot was one of the first autonomous robots that showed impressive capabilities of navigation and mobile manipulation. Since then, robotics research has made great progress, showing more and more capable robotic systems for a large variety of application domains and tasks. In this letter, we look back on decades of research by rebuilding Shakey with modern robotics technology in the open-source Shakey 2016 system. Hereby, we demonstrate the impact of research by showing that ideas from the original Shakey are still alive in state-of-the-art systems, while robotics in general has improved to deliver more robust and more capable software and hardware. Our Shakey 2016 system has been implemented on real robots and leverages mostly open-source software. We experimentally evaluate the system in real-world scenarios on a PR2 robot and a Turtlebot-based robot and particularly investigate the development effort. The experiments documented in this letter demonstrate that results from robotics research are readily available for building complex robots such as Shakey within a short amount of time and little effort.",https://ieeexplore.ieee.org/document/7847341/,IEEE Robotics and Automation Letters,April 2017,ieeexplore
10.1109/JSYST.2008.925270,Sonar-Based Rover Navigation for Single or Multiple Platforms: Forward Safe Path and Target Switching Approach,IEEE,Journals,"In this paper, we have proposed a sensor fusion scheme along with the geometrical modeling of mobile robot navigation path in an unknown environment. In this scheme, the physical placement of sonars, their ranging limits and beam opening angles are considered. A simple 2-D axis transformation is proposed to relate local robot frame with the actual navigation environment. forward safe path (FSP) and target switching approach (TSA) are proposed for efficient obstacle avoidance and target tracking of mobile robot. FSP greatly simplifies the environment conditions as sensed by the robot and also provides minimum turning path during avoidance of obstacles. This method also removes the ldquooscillationrdquo in the mobile robot navigation path. TSA technique gives highest priority on the target tracking during the obstacle avoidance and seeks minimum distance path towards the target. These methods remove unnecessary turning of mobile robot during navigation. A scheme for target directional motion is also proposed. So, mobile robot takes the minimum turning path required towards the target. These methods also ensure the avoidance of ldquodead cycle problemrdquo. These schemes are successfully implemented on a model of <i>PatrolBot</i> mobile robot from <i>ActivMedia</i> Robotics. The overview of current research work on multi-domain robotic system namely system-of-systems is also presented. This paper also describes the Global Positioning System-based navigation of rovers. Results of real-time experiments with Pioneer II P2AT-8 from <i>ActivMedia</i> are included in this paper to show the future aspect of this research work.",https://ieeexplore.ieee.org/document/4550588/,IEEE Systems Journal,June 2008,ieeexplore
10.1109/TE.2012.2224867,SyRoTek—Distance Teaching of Mobile Robotics,IEEE,Journals,"E-learning is a modern and effective approach for training in various areas and at different levels of education. This paper gives an overview of SyRoTek, an e-learning platform for mobile robotics, artificial intelligence, control engineering, and related domains. SyRoTek provides remote access to a set of fully autonomous mobile robots placed in a restricted area with dynamically reconfigurable obstacles, which enables solving a huge variety of problems. A user is able to control the robots in real time by their own developed algorithms as well as being able to analyze gathered data and observe activity of the robots by provided interfaces. The system is currently used for education at the Czech Technical University in Prague, Prague, Czech Republic, and at the University of Buenos Aires, Buenos, Aires, Argentina, and it is freely accessible to other institutions. In addition to the system overview, this paper presents the experience gained from the actual deployment of the system in teaching activities.",https://ieeexplore.ieee.org/document/6341862/,IEEE Transactions on Education,Feb. 2013,ieeexplore
10.1109/JIOT.2021.3068736,Terra: A Smart and Sensible Digital Twin Framework for Robust Robot Deployment in Challenging Environments,IEEE,Journals,"Digital twin (DT) systems that replicate the physical world digitally are powerful tools for monitoring physical systems and evaluating algorithms, but current DT systems are commonly not applicable for robotic deployment and investigation. Meanwhile, current 3-D simulation-based robotic platforms do not model the dynamics of the physical world on-the-fly as done in DT systems, limiting their potential for the development of robotics in challenging environments. To tackle this issue, we propose the first robot-centered smart DT framework, namely, Terra, to facilitate the deployment of robots in challenging environments. The proposed Terra framework introduces a comprehensive DT representation to encode the useful real-time dynamics of both the physical world and the robot agent deployed therein. A multiview multimodality perception module is further devised for Terra to obtain high-level semantics and deliver a precise description of the current status of the environment and the robot agent. By mapping the perceived results to the virtual replica of the physical environment, Terra actively updates the action policy and sends it back to the agent, forming an integral and real-time information feedback loop. In practice, to help demonstrate the effectiveness and feasibility of the proposed framework, we deliberately set up a challenging unordered physical environment with many obstacles and a very simple robot aiming to fulfill a navigation task. Empirical results show that the proposed Terra framework successfully facilitates the robot to accomplish the task without causing hazards.",https://ieeexplore.ieee.org/document/9386242/,IEEE Internet of Things Journal,"15 Sept.15, 2021",ieeexplore
10.1109/TPAMI.2004.1262308,The writer independent online handwriting recognition system frog on hand and cluster generative statistical dynamic time warping,IEEE,Journals,"In this paper, we give a comprehensive description of our writer-independent online handwriting recognition system frog on hand. The focus of this work concerns the presentation of the classification/training approach, which we call cluster generative statistical dynamic time warping (CSDTW). CSDTW is a general, scalable, HMM-based method for variable-sized, sequential data that holistically combines cluster analysis and statistical sequence modeling. It can handle general classification problems that rely on this sequential type of data, e.g., speech recognition, genome processing, robotics, etc. Contrary to previous attempts, clustering and statistical sequence modeling are embedded in a single feature space and use a closely related distance measure. We show character recognition experiments of frog on hand using CSDTW on the UNIPEN online handwriting database. The recognition accuracy is significantly higher than reported results of other handwriting recognition systems. Finally, we describe the real-time implementation of frog on hand on a Linux Compaq iPAQ embedded device.",https://ieeexplore.ieee.org/document/1262308/,IEEE Transactions on Pattern Analysis and Machine Intelligence,March 2004,ieeexplore
10.1109/LRA.2021.3123374,Uncertainty for Identifying Open-Set Errors in Visual Object Detection,IEEE,Journals,"Deployed into an open world, object detectors are prone to open-set errors, false positive detections of object classes not present in the training dataset.We propose GMM-Det, a real-time method for extracting epistemic uncertainty from object detectors to identify and reject open-set errors. GMM-Det trains the detector to produce a structured logit space that is modelled with class-specific Gaussian Mixture Models. At test time, open-set errors are identified by their low log-probability under all Gaussian Mixture Models. We test two common detector architectures, Faster R-CNN and RetinaNet, across three varied datasets spanning robotics and computer vision. Our results show that GMM-Det consistently outperforms existing uncertainty techniques for identifying and rejecting open-set detections, especially at the low-error-rate operating point required for safety-critical applications. GMM-Det maintains object detection performance, and introduces only minimal computational overhead. We also introduce a methodology for converting existing object detection datasets into specific <italic>open-set</italic> datasets to evaluate open-set performance in object detection.",https://ieeexplore.ieee.org/document/9591346/,IEEE Robotics and Automation Letters,Jan. 2022,ieeexplore
10.1109/TAMD.2010.2097260,Using the Rhythm of Nonverbal Human–Robot Interaction as a Signal for Learning,IEEE,Journals,"Human-robot interaction is a key issue in order to build robots for everyone. The difficulty for people to understand how robots work and how they must be controlled will be one of the mains limit for broad robotics. In this paper, we study a new way of interacting with robots without needing to understand how robots work or to give them explicit instructions. This work is based on psychological data showing that synchronization and rhythm are very important features for pleasant interaction. We propose a biologically inspired architecture using rhythm detection to build an internal reward for learning. After showing the results of keyboard interactions, we present and discuss the results of real human-robots (Aibo and Nao) interactions. We show that our minimalist control architecture allows the discovery and learning of arbitrary sensorimotor associations games with expert users. With nonexpert users, we show that using only the rhythm information is not sufficient for learning all the associations due to the different strategies used by the human. Nevertheless, this last experiment shows that the rhythm is still allowing the discovery of subsets of associations, being one of the promising signal of tomorrow social applications.",https://ieeexplore.ieee.org/document/5664771/,IEEE Transactions on Autonomous Mental Development,March 2011,ieeexplore
10.1109/LRA.2019.2894216,VR-Goggles for Robots: Real-to-Sim Domain Adaptation for Visual Control,IEEE,Journals,"In this letter, we deal with the reality gap from a novel perspective, targeting transferring deep reinforcement learning (DRL) policies learned in simulated environments to the real-world domain for visual control tasks. Instead of adopting the common solutions to the problem by increasing the visual fidelity of synthetic images output from simulators during the training phase, we seek to tackle the problem by translating the real-world image streams back to the synthetic domain during the deployment phase, to make the robot feel at home. We propose this as a lightweight, flexible, and efficient solution for visual control, as first, no extra transfer steps are required during the expensive training of DRL agents in simulation; second, the trained DRL agents will not be constrained to being deployable in only one specific real-world environment; and third, the policy training and the transfer operations are decoupled, and can be conducted in parallel. Besides this, we propose a simple yet effective shift loss that is agnostic to the downstream task, to constrain the consistency between subsequent frames which is important for consistent policy outputs. We validate the shift loss for artistic style transfer for videos and domain adaptation, and validate our visual control approach in indoor and outdoor robotics experiments.",https://ieeexplore.ieee.org/document/8620258/,IEEE Robotics and Automation Letters,April 2019,ieeexplore
10.1109/LRA.2021.3068106,Visual Navigation in Real-World Indoor Environments Using End-to-End Deep Reinforcement Learning,IEEE,Journals,"Visual navigation is essential for many applications in robotics, from manipulation, through mobile robotics to automated driving. Deep reinforcement learning (DRL) provides an elegant map-free approach integrating image processing, localization, and planning in one module, which can be trained and therefore optimized for a given environment. However, to date, DRL-based visual navigation was validated exclusively in simulation, where the simulator provides information that is not available in the real world, e.g., the robot's position or segmentation masks. This precludes the use of the learned policy on a real robot. Therefore, we present a novel approach that enables a direct deployment of the trained policy on real robots. We have designed a new powerful simulator capable of domain randomization. To facilitate the training, we propose visual auxiliary tasks and a tailored reward scheme. The policy is fine-tuned on images collected from real-world environments. We have evaluated the method on a mobile robot in a real office environment. The training took approximately 30 hours on a single GPU. In 30 navigation experiments, the robot reached a 0.3-meter neighbourhood of the goal in more than 86.7% of cases. This result makes the proposed method directly applicable to tasks like mobile manipulation.",https://ieeexplore.ieee.org/document/9384194/,IEEE Robotics and Automation Letters,July 2021,ieeexplore
10.1109/ACCESS.2020.3030963,Waypoint Mobile Robot Exploration Based on Biologically Inspired Algorithms,IEEE,Journals,"This article proposes stochastic exploration algorithms for mobile robot exploration problems. Navigation with uncertain conditions in the absence of initial parameters is a situation wherein precomputation and prediction are impossible for a robot. Therefore, stochastic optimization techniques were applied to find the optimal solution for the robot exploration problem. Driving to the unknown areas, the robot updates the frontier line of sensor visibility during the exploration mission. The points of the frontier line are assumed as the swarm population with their own positions and costs, which allows the computation of the next global waypoint. The calculation of global waypoints is carried out by a nature-inspired optimization algorithm that can place a waypoint in uncertainties. This study offers to apply three metaheuristic algorithms individually, such as Whale Optimization, Grey Wolf Optimizer, and Particle Swarm Optimization algorithms, for comparison and testing their performances in the mobile robotics. At first, the simulations based on the proposed exploration algorithms were implemented and evaluated in a created environment. The results were compared in a single and average cases. Then, the real-world experiments using Grey Wolf Optimizer exploration algorithm were conducted in the different types of environments using MATLAB-ROS integration tool. These results proved the effectiveness and applicability of the bio-inspired optimization algorithm in the mobile robotics.",https://ieeexplore.ieee.org/document/9223657/,IEEE Access,2020,ieeexplore
10.1109/UR49135.2020.9144789,A Markerless Deep Learning-based 6 Degrees of Freedom Pose Estimation for Mobile Robots using RGB Data,IEEE,Conferences,"Augmented Reality has been subject to various integration efforts within industries due to its ability to enhance human machine interaction and understanding. Neural networks have achieved remarkable results in areas of computer vision, which bear great potential to assist and facilitate an enhanced Augmented Reality experience. However, most neural networks are computationally intensive and demand huge processing power, thus are not suitable for deployment on Augmented Reality devices. In this work, we propose a method to deploy state of the art neural networks for real time 3D object localization on augmented reality devices. As a result, we provide a more automated method of calibrating the AR devices with mobile robotic systems. To accelerate the calibration process and enhance user experience, we focus on fast 2D detection approaches which are extracting the 3D pose of the object fast and accurately by using only 2D input. The results are implemented into an Augmented Reality application for intuitive robot control and sensor data visualization. For the 6D annotation of 2D images, we developed an annotation tool, which is, to our knowledge, the first open source tool to be available. We achieve feasible results which are generally applicable to any AR device, thus making this work promising for further research in combining high demanding neural networks with Internet of Things devices.",https://ieeexplore.ieee.org/document/9144789/,2020 17th International Conference on Ubiquitous Robots (UR),22-26 June 2020,ieeexplore
10.1109/IJCNN.2010.5596771,A cognitive developmental robotics architecture for lifelong learning by evolution in real robots,IEEE,Conferences,"This paper is devoted to a detailed presentation of the current state of the Multilevel Darwinist Brain (MDB) cognitive architecture for lifelong learning in real robots. This architecture follows the cognitive developmental robotics approach and it is based on concepts like embodiment, open-ended lifelong learning, autonomous knowledge acquisition or adaptive behaviors and motivations. In addition, this version of the MDB architecture incorporates several improvements related with more practical issues, which are the result of the experience gained through several experiments with real robots in the last few years. The MDB uses evolutionary algorithms in the knowledge acquisition process, which implies the need of paying attention to the efficiency of the computational implementation. Here, we first describe the cognitive model on which the basic operation of the architecture is based and, secondly, we detail the main aspects and working of the current version of the MDB. Finally, we have designed a very simple but illustrative real robot lifelong learning example, where we can show how to set up an experiment using the MDB. Hence, with this simple example we show the successful behavior of the MDB cognitive developmental robotics principles.",https://ieeexplore.ieee.org/document/5596771/,The 2010 International Joint Conference on Neural Networks (IJCNN),18-23 July 2010,ieeexplore
10.1109/iCREATE.2014.6828372,A comparison of various robotic control architectures for autonomous navigation of mobile robots,IEEE,Conferences,"For mobile robots, the most fundamental and pressing issue is that of autonomous navigation. Successful navigation of mobile robots is closely dependent on four vitals i.e. perception, localization, cognition and motion control. Implementation of each of these vital blocks requires consideration of at least one of the two well-known control architectures Deliberative Navigation Control and Reactive Navigation Control or a combination of the two, also known as a Hybrid Navigation Control. This paper compares each of these control architectures on the basis of their flexibility, ease of implementation, reactivity, robustness, efficiency and many other architecture specifications. The paper concludes with suggesting the schema that seems to be the best of each of these control schemes, on the basis of the analysis made, in order to cope with unknown and dynamic navigation problems encountered in real life scenarios.",https://ieeexplore.ieee.org/document/6828372/,2014 International Conference on Robotics and Emerging Allied Technologies in Engineering (iCREATE),22-24 April 2014,ieeexplore
10.1109/IROS.1998.727477,A constraint-based controller for soccer-playing robots,IEEE,Conferences,"Soccer meets the requirements of the situated agent approach and as a task domain is sufficiently rich to support research integrating many branches of robotics and AI. A robot is an integrated system, with a controller embedded in its plant. A robotic system is the coupling of a robot to its environment. Robotic systems are, in general, hybrid dynamic systems, consisting of continuous, discrete and event-driven components. Constraint nets provide a semantic model for modeling hybrid dynamic systems. Controllers are embedded constraint solvers that solve constraints in real-time. A controller for our new softbot soccer team, UBC Dynamo98, has been modeled in constraint nets, and implemented in Java, using the Java Beans architecture. The paper demonstrates that the formal constraint net approach is a practical tool for designing and implementing controllers for robots in multi-agent real-time environments.",https://ieeexplore.ieee.org/document/727477/,"Proceedings. 1998 IEEE/RSJ International Conference on Intelligent Robots and Systems. Innovations in Theory, Practice and Applications (Cat. No.98CH36190)",17-17 Oct. 1998,ieeexplore
10.1109/ICCS45141.2019.9065549,A low power Artificial Intelligence Processor for Autonomous Mobile Robots,IEEE,Conferences,"The robot which makes use of AI as a mode of processing is getting more popular day by day, starting from the autonomous room cleaning robot to Amazon Prime Air. This autonomous robot overtakes traditional robots in following aspects such as implementing effective decision making in order to reduce the computational overhead by reducing the overall power usage of the robot. In this report, we have designed a low power [1] AIP without compensating in performance. The AIP which we have designed is a 64 processing element that uses parallel processing architecture. A map with 8 different routes is created in Xilinx where it calculates the shortest path from the source to destination using conditional operators. A* algorithm is implemented in Matlab to calculate the shortest distance and Dijkstra's algorithm is converted to VHDL using Vivado HLS coder. A neural network is also created using Matlab to detect and avoid real time obstacle. The overall power report of the processor is implemented in Cadence.",https://ieeexplore.ieee.org/document/9065549/,2019 International Conference on Intelligent Computing and Control Systems (ICCS),15-17 May 2019,ieeexplore
10.1109/CISTI.2015.7170600,A mixed reality game using 3Pi robots — “PiTanks”,IEEE,Conferences,"In the growing field of Robotics, one of the many possible paths to explore is the social aspect that it can influence upon the present society. The combination of the goal-oriented development of robots with the interactivity used in games while employing mixed reality is a promising route to take in regard to designing user-friendly robots and improving problem solving featured in artificial intelligence software. In this paper, we present a competitive team-based game using Pololu's 3Pi robots moving in a projected map, capable of human interaction via game controllers. The game engine was developed utilizing the framework Qt Creator with C++ and OpenCV for the image processing tasks. The technical framework uses the ROS framework for communications that may be, in the future, used to connect different modules. Various parameters of the implementation are tested, such as position tracking errors.",https://ieeexplore.ieee.org/document/7170600/,2015 10th Iberian Conference on Information Systems and Technologies (CISTI),17-20 June 2015,ieeexplore
10.1049/cp:19940180,A novel neural adaptive controller for robots,IET,Conferences,"Existing industrial robotic manipulators have proven to be limited in many applications, e.g. both their payload capability and manipulation speeds are limited. This paper presents a novel neural adaptive controller-intelligent gain scheduling-(IGS) for robotic manipulators. It advances the idea of mapping the nonlinear relationship between robot working conditions (e.g. payload, speed, etc.) and its controller gains. This scheme is simple, inexpensive, and especially, attractive for its possible implementation in real-time. Simulation has shown promising results.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/327097/,1994 International Conference on Control - Control '94.,21-24 March 1994,ieeexplore
10.1109/AIM.2001.936513,A radial basis function networks approach for the tracking problem of mobile robots,IEEE,Conferences,Proposes a radial basis function network (RBFN) approach to the solution of the tracking problem for mobile robots. RBFN-based controllers are investigated in order to introduce some degree of robustness in the control system and to avoid the main disadvantage of multilayer neural networks (MNN) to be highly nonlinear in the parameters. The training of the nets and the control performances analysis have been done in a real experimental setup. The proposed solutions are implemented on a PC-based control architecture for the real-time control of the LabMate mobile base and are compared with MNN-based control schemes. The experimental results are satisfactory in terms of tracking errors and computational efforts.,https://ieeexplore.ieee.org/document/936513/,2001 IEEE/ASME International Conference on Advanced Intelligent Mechatronics. Proceedings (Cat. No.01TH8556),8-12 July 2001,ieeexplore
10.1109/SICE.2002.1195611,A reinforcement learning using adaptive state space construction strategy for real autonomous mobile robots,IEEE,Conferences,"In the recent robotics, much attention has been focused on utilizing reinforcement learning for designing robot controllers. However, there still exists difficulties, one of them is well known as state space explosion problem. As the state space for a learning system becomes continuous and high dimensional, its combinational state space exponentially explodes and the learning process is time consuming. In this paper, we propose an adaptive state space recruitment strategy for reinforcement learning, which enables the system to divide state space gradually according to task complexity and progress of learning. Some simulation results and real robot implementation show the validity of the method.",https://ieeexplore.ieee.org/document/1195611/,Proceedings of the 41st SICE Annual Conference. SICE 2002.,5-7 Aug. 2002,ieeexplore
10.1109/IRDS.2002.1041504,A reinforcement learning with adaptive state space recruitment strategy for real autonomous mobile robots,IEEE,Conferences,"In the recent robotics, much attention has been focused on utilizing reinforcement learning for designing robot controllers. However, there still exists difficulties, one of them is well known as state space explosion problem. As the state space for learning system becomes continuous and high dimensional, the learning process results in time-consuming since its combinational states explodes exponentially. In order to adopt reinforcement learning for such complicated systems, it should be taken not only ""adaptability"" but ""computational efficiencies"" into account. In the paper, we propose an adaptive state space recruitment strategy for reinforcement learning, which enables the system to divide state space gradually according to task complexity and progress of learning. Some simulation results and real robot implementation show the validity of the method.",https://ieeexplore.ieee.org/document/1041504/,IEEE/RSJ International Conference on Intelligent Robots and Systems,30 Sept.-4 Oct. 2002,ieeexplore
10.1109/ICARCV.2012.6485305,A robust real-time tracking system based on an adaptive selection mechanism for mobile robots,IEEE,Conferences,"Extensive research has been conducted in the domain of object tracking. Among the existing tracking methods, most of them mainly focus on using various cues such as color, texture, contour, features, motion as well as depth information to achieve a robust tracking performance. The tracking methods themselves are highly emphasized while properties of the objects to be tracked are usually not exploited enough. In this paper, we first propose a novel adaptive tracking selection mechanism dependent on the properties of the objects. The system will automatically choose the optimal tracking algorithm after examining the textureness of the object. In addition, we propose a robust tracking algorithm for uniform objects based on color information which can cope with real world constraints. In the mean time, we deployed a textured object tracking algorithm which combines the Lucas-Kanade tracker and a model based tracker using the Random Forests classifier. The whole system was tested and the experimental results on a variety of objects show the effectiveness of the adaptive tracking selection mechanism. Moreover, the promising tracking performance shows the robustness of the proposed tracking algorithm. The computation cost of the algorithm is very low, which proves that it can be further used in various real-time robotics applications.",https://ieeexplore.ieee.org/document/6485305/,2012 12th International Conference on Control Automation Robotics & Vision (ICARCV),5-7 Dec. 2012,ieeexplore
10.1109/ISIE.2010.5637497,A society of agents for service robots,IEEE,Conferences,"This article presents an agent based distributed software architecture for machine and robot control. The functionality of agents of this architecture has been inspired by Marvin Minsky's definition of the term in his book “The Society of Mind” (1986) [1]. Minsky, widely considered to be one of the fathers of artificial intelligence, tried to describe from an engineering point of view, in this book, how he thought the mind works: “I'll call “Society of Mind” this scheme in which each mind is made of many smaller processes. These we'll call agents. Each mental agent by itself can only do some simple thing that needs no mind or thought at all. Yet when we join these agents in societies-in certain very special ways-this leads to true intelligence.” Societies of simple behaving agents have been implemented in Fatronik, in real robots, and have been demonstrated to be able to perform complex tasks in industrial environments. This article explains the features of such societies of agents and presents their implementation in a real robot.",https://ieeexplore.ieee.org/document/5637497/,2010 IEEE International Symposium on Industrial Electronics,4-7 July 2010,ieeexplore
10.1109/CADCG.2009.5246869,A study on autonomous animated robots: Anibots,IEEE,Conferences,"In this paper, we demonstrate a design of autonomous virtual creatures (called animated robots: Anibots in this paper) and develop a design tool for animated robots. An animated robot can behave autonomously by using its own sensors and controllers on three-dimensional physically modeled environment. The developed tool can enable us to execute the simulation of Anibots on physical environment at any time during the modeling process. In order to simulate more realistic world, an approximate fluid environment model with low computational costs is presented. It is shown that a combinatorial use of neural network implementation for controllers and the genetic algorithm (GA) or the particle swarm optimization (PSO) is effective for emerging more realistic autonomous behaviours of animated robots.",https://ieeexplore.ieee.org/document/5246869/,2009 11th IEEE International Conference on Computer-Aided Design and Computer Graphics,19-21 Aug. 2009,ieeexplore
10.1109/IROS.1994.407376,A two-phase navigation system for mobile robots in dynamic environments,IEEE,Conferences,"This paper presents an implemented navigation system for mobile robots in dynamic environments. In order to take advantage of existing knowledge of the world and to deal with unknown obstacles in real time, our system divides motion planning into global path planning and local reactive navigation. The former uses genetic algorithm methods to find a collision-free path; the latter is implemented using neural network techniques to track the path generated by the global planner while avoiding unknown obstacles on the way. As a result, the system can adapt to dynamic environmental changes. Our experiments, both in simulation and on a real robot, showed that the system can find a reasonably good free path in a fraction of the time necessary to find an optimal free path, and it can effectively achieve its goal configurations without collision.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/407376/,Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS'94),12-16 Sept. 1994,ieeexplore
10.1109/ICSMC.2004.1400779,A user-oriented framework for the design and implementation of pet robots,IEEE,Conferences,"In recent years, application of intelligent autonomous robots for home amusement has become an important research criterion, and pet robots have been designed to become the electronic toys for the next generation. To develop pet robots that can act in real time in the real world, this work adopts the behavior-based control architecture. In our control framework, an imitation-based learning system is included to build robot behaviors. Moreover an emotional model is embedded to the control architecture. By giving the pet robot an emotional model it can explicitly express its internal conditions through its various external behaviors, as the real living creature does. To evaluate the proposed framework, we have developed an interactive environment and successfully used it to design a pet robot.",https://ieeexplore.ieee.org/document/1400779/,"2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)",10-13 Oct. 2004,ieeexplore
10.1109/ROBIO.2009.5420410,AMF: A novel reactive approach for motion planning of mobile robots in unknown dynamic environments,IEEE,Conferences,"This paper presents a new approach based on Artificial Potential Fields (APF) which provides real-time and very effective methodology for practical motion planners in unknown dynamic environments. The Maxwell's equations are exploited to define Artificial Magnetoquasistatic Fields (AMF) as an extension of APF, which provides a predictive, intelligent, and natural behavior in contrast with other approaches. The essential aim of the AMF is dealing with moving obstacles, as well as static ones. The main idea is to consider an electrical current in the direction of each moving obstacle which induces magnetic field around it. These moving obstacles could be arbitrary in shape, size, and number. Neither the motion-trajectory of the moving obstacles nor the model of their motion is known. The only available information is their instantaneous velocity at each time step. In this method, the magnetoquasistatic approximation is used to obtain the electric and magnetic fields around robot. Next, using Lorentz equation, the necessary force can be calculated which should be applied to robot to avoid the collision with obstacles. A path planner based on this approach has been implemented and tested by various scenarios containing both static and moving obstacles. Simulations and experimental results illustrate the efficacy of the proposed method.",https://ieeexplore.ieee.org/document/5420410/,2009 IEEE International Conference on Robotics and Biomimetics (ROBIO),19-23 Dec. 2009,ieeexplore
10.1109/DevLrn.2012.6400818,ASP+POMDP: Integrating non-monotonic logic programming and probabilistic planning on robots,IEEE,Conferences,"Mobile robots equipped with multiple sensors and deployed in real-world domains frequently find it difficult to process all sensor inputs, or to operate without any human input and domain knowledge. At the same time, robots cannot be equipped with all relevant domain knowledge in advance, and humans are unlikely to have the time and expertise to provide elaborate and accurate feedback. This paper presents a novel framework that addresses these challenges by integrating high-level logical inference with low-level probabilistic sequential decision-making. Specifically, Answer Set Programming (ASP), a non-monotonic logic programming paradigm, is used to represent, reason with and revise domain knowledge obtained from sensor inputs and high-level human feedback, while hierarchical partially observable Markov decision processes (POMDPs) are used to automatically adapt visual sensing and information processing to the task at hand. Furthermore, a psychophysics-inspired strategy is used to merge the output of logical inference with probabilistic beliefs. All algorithms are evaluated in simulation and on wheeled robots localizing target objects in indoor domains.",https://ieeexplore.ieee.org/document/6400818/,2012 IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL),7-9 Nov. 2012,ieeexplore
10.1109/ICARCV.2018.8581349,Activity Recognition Based on RGB-D and Thermal Sensors for Socially Assistive Robots,IEEE,Conferences,"For socially assistive robots, being able to recognize basic human actions is an important capability. The sensors, which are frequently mounted on most recent robots, such as RGB-D and thermal cameras, as well as the advances in deep learning have enabled the research on activity recognition to grow. In this paper, we collected our own dataset of actions in a home-like scenario, which contains thermal imagery in addition to RGB-D data and we proposed a method based on Long-term Recurrent Convolutional Networks (LRCN). We showed that our method has an accuracy comparable with the state-of-the-art. We also proved that thermal information can improve the recognition accuracy. Furthermore, we tested the real-time capability of our system and conducted a real-time experiment with a robot (Pepper robot from Softbank Robotics) so as to investigate the effect of a robot enabled with action recognition capability in a human-robot interaction.",https://ieeexplore.ieee.org/document/8581349/,"2018 15th International Conference on Control, Automation, Robotics and Vision (ICARCV)",18-21 Nov. 2018,ieeexplore
10.1109/ROMAN.2006.314387,Adaptive Social Skills for Robots Interacting with Virtual Characters in Real Worlds,IEEE,Conferences,"We propose the implementation of a new interaction type that allows the creation of adaptive social relationships between robots and virtual characters in a real world environment, using reinforcement learning. We present the implementation of a storytelling scenario, which results in an immersion experience for the robot. The robot is able to interact and learn dynamically from the virtual character",https://ieeexplore.ieee.org/document/4107778/,ROMAN 2006 - The 15th IEEE International Symposium on Robot and Human Interactive Communication,6-8 Sept. 2006,ieeexplore
10.1109/FUZZY.2008.4630629,Adaptive learning approach of integrating evolution fuzzy-neural networks and Q-learning for mobile robots,IEEE,Conferences,"In the paper, an adaptive learning approach of integrating evolution fuzzy-neural networks and Q-learning is developed so that a mobile robot can adapt itself to a real and complex environment. Specifically, based on Q-value and an evolution method that adjusts their parameter values of the fuzzy-neural networks, the mobile robot evolves better strategies to adapt to the environment. However, in most studies of evolution learning, the learning of mobile robots often requires a simulator and an enormous amount of evolution time so as to perform a task. Therefore, we are to integrate Q-learning into the evolution fuzzy-neural networks to avoid the requirement of the simulator. Experiment results of a mobile robot illustrate the performance of the proposed approach.",https://ieeexplore.ieee.org/document/4630629/,2008 IEEE International Conference on Fuzzy Systems (IEEE World Congress on Computational Intelligence),1-6 June 2008,ieeexplore
10.1109/SoutheastCon42311.2019.9020532,An IoT-based Common Platform Integrating Robots and Virtual Characters for High Performance and Cybersecurity,IEEE,Conferences,"Two humanoid robots are developed. Both robots are human-like in appearance though one is more human-like than the other. A virtual human with human-like appearance is also developed. Various similar functionalities and interaction modalities for the robots and the virtual human are developed. Various technologies are incorporated with them to make them intelligent and autonomous. A common platform in the form of an internet of things (IoT) is developed that can integrate the robots and the virtual human for their real-world collaboration. Then, the collaboration between each robot and the virtual human is separately implemented via the common platform based on some control algorithms for finding a hidden object in a homely environment. The collaboration between the robot and the virtual human is evaluated. The status of cybersecurity in the IoT is briefly analyzed. The results show that the collaboration is satisfactory in various terms, which justify their social integration in the form of an IoT. Two robots with different appearance are actually used to investigate the effects of anthropomorphism on the interaction. The results can help employ artificial intelligent agents of heterogeneous realities to perform real-world tasks through their cooperation in the form of IoT that can provide high performance and cybersecurity.",https://ieeexplore.ieee.org/document/9020532/,2019 SoutheastCon,11-14 April 2019,ieeexplore
10.1109/CCECE.1993.332425,An adaptive control scheme for robots with unknown dynamics,IEEE,Conferences,"In this paper, a stable adaptive control scheme for robot manipulators with unknown dynamics is proposed. It consists of an off-line least-mean-square (LMS) type identifier to identify structured system dynamics and an online dynamic compensator to compensating for dynamic uncertainties. Taking advantage of the unique structure of the robot regressor dynamics, the former uses an LMS type algorithm to identify, using a set of trial data, the structured dynamic parameters of the robot while the latter uses an online stable parameter updating mechanism determined using Lyapunov theory to compensate for both unknown and uncertain dynamics. The off-line identified parameters we used as initial values for the online dynamic parameter estimation. Since both identifier and compensator are implemented using the regressor dynamics, the recursive formula, for the computation of robot regressor dynamics previously proposed can be used to achieve high computational efficiency in real-time implementations. An illustrative simulation example is included to show the proposed adaptive control algorithm.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/332425/,Proceedings of Canadian Conference on Electrical and Computer Engineering,14-17 Sept. 1993,ieeexplore
10.1109/ROBOT.1993.291974,Application of neural network with real-time training to robust position/force control of multiple robots,IEEE,Conferences,A robust controller that compensates the uncertainties of the dynamic system of the multiple robotic system in order to obtain good tracking performance of position and force simultaneously while satisfying the constraint conditions is presented. A neural network architecture is proposed as one approach to its design and implementation. An online learning rule is provided for repeatedly assigned tasks so that the system is robust to the structured and unstructured uncertainties and the controller adjusts itself repeatedly to improve the performance progressively for each repeated task.&lt;<ETX>&gt;</ETX>,https://ieeexplore.ieee.org/document/291974/,[1993] Proceedings IEEE International Conference on Robotics and Automation,2-6 May 1993,ieeexplore
10.1109/IROS45743.2020.9341340,Applying Surface Normal Information in Drivable Area and Road Anomaly Detection for Ground Mobile Robots,IEEE,Conferences,"The joint detection of drivable areas and road anomalies is a crucial task for ground mobile robots. In recent years, many impressive semantic segmentation networks, which can be used for pixel-level drivable area and road anomaly detection, have been developed. However, the detection accuracy still needs improvement. Therefore, we develop a novel module named the Normal Inference Module (NIM), which can generate surface normal information from dense depth images with high accuracy and efficiency. Our NIM can be deployed in existing convolutional neural networks (CNNs) to refine the segmentation performance. To evaluate the effectiveness and robustness of our NIM, we embed it in twelve state-of-the-art CNNs. The experimental results illustrate that our NIM can greatly improve the performance of the CNNs for drivable area and road anomaly detection. Furthermore, our proposed NIM-RTFNet ranks 8th on the KITTI road benchmark and exhibits a real-time inference speed.",https://ieeexplore.ieee.org/document/9341340/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/AHS.2007.37,Automatic Synthesis of Fault Detection Modules for Mobile Robots,IEEE,Conferences,"In this paper, we present a new approach for automatic synthesis of fault detection modules for autonomous mobile robots. The method relies on the fact that hardware faults typically change the flow of sensory perceptions received by the robot and the subsequent behavior of the control program. We collect data from three experiments with real robots. In each experiment, we record all sensory inputs from the robots while they are operating normally and after software-simulated faults have been injected. We use back- propagation neural networks to synthesize task-dependent fault detection modules. The performance of the modules is evaluated in terms of false positives and latency.",https://ieeexplore.ieee.org/document/4291986/,Second NASA/ESA Conference on Adaptive Hardware and Systems (AHS 2007),5-8 Aug. 2007,ieeexplore
10.1109/ICIT.2018.8352157,Automatic parameter learning for easy instruction of industrial collaborative robots,IEEE,Conferences,"The manufacturing industry faces challenges in meeting requirements of flexibility, product variability and small batch sizes. Automation of high mix, low volume productions requires faster (re)configuration of manufacturing equipment. These demands are to some extend accommodated by collaborative robots. Certain actions can still be hard or impossible to manually adjust due to inherent process uncertainties. This paper proposes a generic iteratively learning approach based on Bayesian Optimisation to efficiently search for the optimal set of process parameters. The approach takes into account the process uncertainties by iteratively making a statistical founded choice on the next parameter-set to examine only based on the prior binomial outcomes. Moreover, our function estimator uses Wilson Score to make proper estimates on the success probability and the associated uncertain measure of sparsely sampled regions. The function estimator also generalises the experiment outcomes to the neighbour region through kernel smoothing by integrating Kernel Density Estimation. Our approach is applied to a real industrial task with significant process uncertainties, where sufficiently robust process parameters cannot intuitively be chosen. Using our approach, a collaborative robot automatically finds a reliable solution.",https://ieeexplore.ieee.org/document/8352157/,2018 IEEE International Conference on Industrial Technology (ICIT),20-22 Feb. 2018,ieeexplore
10.1109/ICAC.2004.1301379,Autonomic systems for mobile robots,IEEE,Conferences,"Mobile robots are an excellent testbed for autonomic computing research. The ultimate goal of robotics research is to develop a platform that can function autonomously in the face of hardware and software failures. This goal is becoming more important as robots are increasingly being deployed outside of controlled environments. In this paper, we discuss our work toward implementing an autonomic system for a mobile robot. This work is motivated by our experiences with existing mobile robot control software during real-world deployments.",https://ieeexplore.ieee.org/document/1301379/,"International Conference on Autonomic Computing, 2004. Proceedings.",17-18 May 2004,ieeexplore
10.1109/ECMR.2019.8870908,Autonomous Robots as Actors in Robotics Theatre - Tribute to the Centenary of R.U.R.,IEEE,Conferences,"In the eyes of the roboticists, the play R.U.R. (Rossum's Universal Robots) of Czech writer Karel Čapek is seen as the messenger of the new robot age. R.U.R. is renown for the first mentioning of the word robot for a humanoid machine that looks, moves, feels, thinks and works like a human. Inspired by the 100th anniversary of R.U.R. in 2020, we have decided to make a performance with Pepper and NAO humanoid robots acting together with human actors. Performing in a theatrical performance is very demanding even for human actors, so we see the implementation of R.U.R. with robotic co-actors as a real challenge. For this purpose, we have analyzed human-robot and robot-robot interaction in the R.U.R. script to evaluate whether NAO and Pepper robots that we have are apt to act autonomously. Due to specific robot deficiencies that we found, we have made the robot casting first and then adapted the R.U.R. script to enable Pepper and NAO robots to perform their roles.",https://ieeexplore.ieee.org/document/8870908/,2019 European Conference on Mobile Robots (ECMR),4-6 Sept. 2019,ieeexplore
10.1109/ICRA.2011.5980435,Autonomous learning of vision-based layered object models on mobile robots,IEEE,Conferences,"Although mobile robots are increasingly being used in real-world applications, the ability to robustly sense and interact with the environment is still missing. A key requirement for the widespread deployment of mobile robots is the ability to operate autonomously by learning desired environmental models and revising the learned models in response to environmental changes. This paper presents an approach that enables a mobile robot to autonomously learn layered models for environmental objects using temporal, local and global visual cues. A temporal assessment of image gradient features is used to detect candidate objects, which are then modeled using color distribution statistics and a spatial representation of gradient features. The robot incrementally revises the learned models and uses them for object recognition and tracking based on a matching scheme comprising a spatial similarity measure and second order distribution statistics. All algorithms are implemented and tested on a wheeled robot platform in dynamic indoor environments.",https://ieeexplore.ieee.org/document/5980435/,2011 IEEE International Conference on Robotics and Automation,9-13 May 2011,ieeexplore
10.1109/SSCI.2018.8628809,Bidirectional Fuzzy Brain Emotional Learning Control for Aerial Robots,IEEE,Conferences,This paper proposes a Bidirectional Fuzzy Brain Emotional Learning (BFBEL) control system to control Aerial Robots. The proposed controller is based on the emotional and logical processing of the brain. The proposed control system merges fuzzy inference and a bidirectional brain emotional learning algorithm. The Bidirectional Fuzzy Brain Emotional Learning (BFBEL) control can learn from scratch and adapt rapidly in real-time to control the system without much prior information. The proposed controller is tested against simulations of both a 1-Degree-Of-Freedom (DOF) flapping wing and a 6DOF flapping wing model and successfully implemented on a 1DOF flapping wing experiment which showcases the learning and adaptation capability in a real-time environment.,https://ieeexplore.ieee.org/document/8628809/,2018 IEEE Symposium Series on Computational Intelligence (SSCI),18-21 Nov. 2018,ieeexplore
10.1109/IECON.2007.4460382,Biomimetics Robots From Bio-inspiration to Implementation,IEEE,Conferences,"Biomimetics focuses on making nature as a model of inspiration that would immensely help conscious abstraction of new principles and ideas, foster innovative design collections, find out new techniques and functionalities, seek new paradigms and methods, develop new materials, and design new streams of intelligent machines, robots, systems, devices, algorithms, etc. Biomimetics incorporates materials, concepts and techniques drawn from naturally made substances, and resembles biological systems in structure, mechanism and/or function as necessary. Smart materials are the foundation supporting the development of new biomimetic based technology. Wide range of biologically inspired robots and intelligent systems has been developed. However, engineering such biomimetic intelligent creatures were hampered by physical and technological constraints, and it is still a challenge. Making robots and intelligent machines that are actuated by biologically inspired artificial muscles would create new reality with great potentials. This paper provides the concept and the importance of Biomimetic as an interdisciplinary field. In addition, the paper introduces and discusses scientific ideas and directions of research activities in the field. The paper presents key development in the field of Biomimetic robots, and finally it underlines the potential of the field and the challenges facing it.",https://ieeexplore.ieee.org/document/4460382/,IECON 2007 - 33rd Annual Conference of the IEEE Industrial Electronics Society,5-8 Nov. 2007,ieeexplore
10.1109/ISDA.2010.5687045,Bézier curve based dynamic obstacle avoidance and trajectory learning for autonomous mobile robots,IEEE,Conferences,"This paper addresses the problem of avoiding dynamic obstacles while following the learned trajectory through non-point based maps directly through laser data. The geometric representation of free configuration area changes while a moving obstacle enters into the safety region of autonomous mobile robot. We have applied the Bézier curve properties to the free configuration eigenspaces to satisfy the dynamic obstacle avoidance path constraints. The algorithm is designed to accurately represent the mobile robot's characteristics while avoiding obstacle such as minimum turning radius. Moreover, we also discuss the obstacle avoided path feasibility as a vectorial combination of free configuration eigen-vectors at discrete time scan-frames to manifest a trajectory, which once followed and mapped onto the two control signals of mobile robot will enable it to build an efficient and accurate online environment map. Preliminary results in Matlab have been shown to validate the idea, while the same has been implemented in Player/stage (robotics real-time software) to analyze the performance of the proposed system.",https://ieeexplore.ieee.org/document/5687045/,2010 10th International Conference on Intelligent Systems Design and Applications,29 Nov.-1 Dec. 2010,ieeexplore
10.1109/HUMANOIDS.2014.7041490,Can active impedance protect robots from landing impact?,IEEE,Conferences,"This paper studies the effect of passive and active impedance for protecting jumping robots from landing impacts. The theory of force transmissibility is used for selecting the passive impedance of the system to minimize the shock propagation. The active impedance is regulated online by a joint-level controller. On top of this controller, a reflex-based leg retraction scheme is implemented which is optimized using direct policy search reinforcement learning based on particle filtering. Experiments are conducted both in simulation and on a real-world hopping leg. We show that although the impact dynamics is fast, the addition of passive impedance provides enough time for the active impedance controller to react to the impact and protect the robot from damage.",https://ieeexplore.ieee.org/document/7041490/,2014 IEEE-RAS International Conference on Humanoid Robots,18-20 Nov. 2014,ieeexplore
10.1109/ICRA.2019.8793660,Chance Constrained Motion Planning for High-Dimensional Robots,IEEE,Conferences,"This paper introduces Probabilistic Chekov (p-Chekov), a chance-constrained motion planning system that can be applied to high degree-of-freedom (DOF) robots under motion uncertainty and imperfect state information. Given process and observation noise models, it can find feasible trajectories which satisfy a user-specified bound over the probability of collision. Leveraging our previous work in deterministic motion planning which integrated trajectory optimization into a sparse roadmap framework, p-Chekov shows superiority in its planning speed for high-dimensional tasks. P-Chekov incorporates a linear-quadratic Gaussian motion planning approach into the estimation of the robot state probability distribution, applies quadrature theories to waypoint collision risk estimation, and adapts risk allocation approaches to assign allowable probabilities of failure among waypoints. Unlike other existing risk-aware planners, p-Chekov can be applied to high-DOF robotic planning tasks without the convexification of the environment. The experiment results in this paper show that this p-Chekov system can effectively reduce collision risk and satisfy user-specified chance constraints in typical real-world planning scenarios for high-DOF robots.",https://ieeexplore.ieee.org/document/8793660/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ROBIO49542.2019.8961823,Collaborative Object Transportation by Multiple Robots with Onboard Object Localization Algorithm,IEEE,Conferences,"Collaborative object transportation has become a popular study trend with its remarkable application foreground. In previous relevant studies, localization of the transported object has always been accomplished by additional devices rather than robot onboard equipments. This paper presents a generalized multi-robot leader-follower system for collaborative object transportation and an onboard object localization algorithm for trajectory tracking of the target object. In this system, the mobile robots can directly push a cubic object without extra gripping devices, when tracking the reference trajectory. During the control process, the object is regarded as an virtual leader, whose localization information is utilized as the feedback, while the mobile robots are considered as the followers. In absence of external localization systems, the proposed onboard localization algorithm provides the real-time position information of the object using scan data from lidars equipped on the robots. A performed measurement accuracy test shows high precision of this algorithm. Finally, a lane-changing experiment of object transportation is conducted, and it verifies this multi-robot leader-follower system.",https://ieeexplore.ieee.org/document/8961823/,2019 IEEE International Conference on Robotics and Biomimetics (ROBIO),6-8 Dec. 2019,ieeexplore
10.1109/CIMCA.2005.1631373,Continuous Curvature Trajectory Generation with Obstacle Avoidance for Car-Like Robots,IEEE,Conferences,"This paper presents an extension of cubic curvature polynomial trajectory planning to include a mechanism for obstacle avoidance. Cubic polynomials have been used to describe curvature continuous trajectories for car like robots. From known start and end robot postures, (position, orientation and curvature) a continuous trajectory can be decided. We extend cubic polynomial trajectories to fourth order polynomials, and introduce a cost function, describing accumulated distance to obstacles along a trajectory, to the robot posture vector. Such trajectories, generated by a gradient descent method, satisfy continuity constraints and avoid obstacles. The method is implemented on a mobile robot system and experiments in real time trajectory planning and execution are conducted",https://ieeexplore.ieee.org/document/1631373/,"International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC'06)",28-30 Nov. 2005,ieeexplore
10.1109/ICCAS.2007.4407004,Cooperative behavior acquisition of multiple autonomous mobile robots by an objective-based reinforcement learning system,IEEE,Conferences,"The present paper proposes an objective-based reinforcement learning system for multiple autonomous mobile robots to acquire cooperative behavior. The proposed system employs profit sharing (PS) as a learning method. A major characteristic of the system is using two kinds of PS tables. One is to learn cooperative behavior using information on other agents' positions and the other is to learn how to control basic movements. Through computer simulation and real robot experiment using a garbage-collection problem, the performance of the proposed system is evaluated. As a result, it is verified that agents select the most available garbage for cooperative behavior using visual information in an unknown environment and move to the target avoiding obstacles.",https://ieeexplore.ieee.org/document/4407004/,"2007 International Conference on Control, Automation and Systems",17-20 Oct. 2007,ieeexplore
10.1109/ISIC.2000.882949,Cooperative learning and planning for multiple robots,IEEE,Conferences,"The paper deals with the the subject of learning and planning for real mobile robots, using Sutton's (1991) Dyna algorithm. The Dyna algorithm integrates reinforcement learning, planning and reactive execution. We present an extension of the Dyna algorithm which includes symmetric and cooperative learning with multiple robots. We applied the extended version of the algorithm to a population of two real robots. Practical problems associated with the implementation of the algorithm on a real setup are solved. Results obtained from simulations and real experiments are presented and discussed.",https://ieeexplore.ieee.org/document/882949/,Proceedings of the 2000 IEEE International Symposium on Intelligent Control. Held jointly with the 8th IEEE Mediterranean Conference on Control and Automation (Cat. No.00CH37147),19-19 July 2000,ieeexplore
10.1109/IROS.2012.6385982,Cooperative sensing and recognition by a swarm of mobile robots,IEEE,Conferences,"We present an approach for distributed real-time recognition tasks using a swarm of mobile robots. We focus on the visual recognition of hand gestures, but the solutions that we provide have general applicability and address a number of challenges common to many distributed sensing and classification problems. In our approach, robots acquire and process hand images from multiple points of view, most of which do not allow for a satisfactory classification. Each robot is equipped with a statistical classifier, which is used to generate an opinion for the sensed gesture. Using a low-bandwidth wireless channel, the robots locally exchange their opinions. They also exploit mobility to adapt their positions to maximize the mutual information collectively gathered by the swarm. A distributed consensus protocol is implemented, to allow to rapidly settle on a decision once enough evidence is available. The system is implemented and demonstrated on real robots. In addition, extensive quantitative results of emulation experiments, based on a real image dataset, are reported. We consider different scenarios and study the scalability and the robustness of the swarm performance for distributed recognition.",https://ieeexplore.ieee.org/document/6385982/,2012 IEEE/RSJ International Conference on Intelligent Robots and Systems,7-12 Oct. 2012,ieeexplore
10.1109/ICRA48506.2021.9562019,Decentralized Circle Formation Control for Fish-like Robots in the Real-world via Reinforcement Learning,IEEE,Conferences,"In this paper, the circle formation control problem is addressed for a group of cooperative underactuated fish-like robots involving unknown nonlinear dynamics and disturbances. Based on the reinforcement learning and cognitive consistency theory, we propose a decentralized controller without the knowledge of the dynamics of the fish-like robots. The proposed controller can be transferred from simulation to reality. It is only trained in our established simulation environment, and the trained controller can be deployed to real robots without any manual tuning. Simulation results confirm that the proposed model-free robust formation control method is scalable with respect to the group size of the robots and outperforms other representative RL algorithms. Several experiments in the real world verify the effectiveness of our RL-based approach for circle formation control.",https://ieeexplore.ieee.org/document/9562019/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/BioRob49111.2020.9224272,Deep Learning of Movement Intent and Reaction Time for EEG-informed Adaptation of Rehabilitation Robots,IEEE,Conferences,"Mounting evidence suggests that adaptation is a crucial mechanism for rehabilitation robots in promoting motor learning. Yet, it is commonly based on robot-derived movement kinematics, which is a rather subjective measurement of performance, especially in the presence of a sensorimotor impairment. Here, we propose a deep convolutional neural network (CNN) that uses electroencephalography (EEG) as an objective measurement of two kinematics components that are typically used to assess motor learning and thereby adaptation: i) the intent to initiate a goal-directed movement, and ii) the reaction time (RT) for that movement. We evaluated our CNN on data acquired from an in-house experiment where 12 healthy subjects moved a rehabilitation robotic arm in four directions on a plane, in response to visual stimuli. Our CNN achieved average test accuracies of 80.08% and 79.82% in a binary classification of the intent (intent vs. no intent) and RT (slow vs. fast), respectively. Our results demonstrate how individual movement components implicated in distinct types of motor learning can be predicted from synchronized EEG data acquired before the start of the movement. Our approach can, therefore, inform robotic adaptation in real-time and has the potential to further improve one's ability to perform the rehabilitation task.",https://ieeexplore.ieee.org/document/9224272/,2020 8th IEEE RAS/EMBS International Conference for Biomedical Robotics and Biomechatronics (BioRob),29 Nov.-1 Dec. 2020,ieeexplore
10.1109/ICRA48506.2021.9561729,Deep Neuromorphic Controller with Dynamic Topology for Aerial Robots,IEEE,Conferences,"Current aerial robots are increasingly adaptive; they can morph to enable operation in changing conditions to complete diverse missions. Each mission may require the robot to conduct a different task. A conventional learning approach can handle these variations when the system is trained for similar tasks in a representative environment. However, it may result in overfitting to the new data stream or the failure to adapt, leading to degradation or a potential crash. These problems can be mitigated with an excessive amount of data and embedded model, but the computational power and the memory of the aerial robots are limited. In order to address the variations in the model, environment as well as the tasks within onboard computation limitations, we propose a deep neuromorphic controller approach with variable topologies to handle each different condition and the data stream with a feasible computation and memory allocation. The proposed approach is based on a deep neuromorphic (multi and variable layered neural network) controller with dynamic depth and progressive layer adaptation for each new data stream. This adaptive structure is combined with a switching function to form a sliding mode controller. The network parameter update rule guarantees the stability of the closed loop system by the convergence of the error dynamics to the sliding surface. Being the first implementation on an aerial robot in this context, the results illustrate the adaptation capability, stability, computational efficiency as well as the real-time validation.",https://ieeexplore.ieee.org/document/9561729/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/SoutheastCon44009.2020.9249654,Deep Reinforcement Learning For Visual Navigation of Wheeled Mobile Robots,IEEE,Conferences,"A study is presented on applying deep reinforcement learning (DRL) for visual navigation of wheeled mobile robots (WMR) in dynamic and unknown environments. Two DRL algorithms, namely, value-learning deep Q-network (DQN) and policy gradient based asynchronous advantage actor critic ( A 3C), have been considered. RGB (red, green and blue) and depth images have been used as inputs in implementation of both DRL algorithms to generate control commands for autonomous navigation of WMR in simulation environments. The initial DRL networks were generated and trained progressively in OpenAI Gym Gazebo based simulation environments within robot operating system (ROS) framework for a popular target WMR, Kobuki TurtleBot2. A pre-trained deep neural network ResNet50 was used after further training with regrouped objects commonly found in laboratory setting for target-driven mapless visual navigation of Turlebot2 through DRL. The performance of A 3C with multiple computation threads (4, 6, and 8) was simulated on a desktop. The navigation performance of DQN and A 3C networks, in terms of reward statistics and completion time, was compared in three simulation environments. As expected, A 3C with multiple threads (4, 6, and 8) performed better than DQN and the performance of A 3C improved with number of threads. Details of the methodology, simulation results are presented and recommendations for future work towards real-time implementation through transfer learning of the DRL models are outlined.",https://ieeexplore.ieee.org/document/9249654/,2020 SoutheastCon,28-29 March 2020,ieeexplore
10.1109/WCNC45663.2020.9120611,Deep Reinforcement Learning based Indoor Air Quality Sensing by Cooperative Mobile Robots,IEEE,Conferences,"Confronted with the severe indoor air pollution nowadays, we propose the usage of multiple robots to detect the indoor air quality (IAQ) cooperatively for fewer sensors and larger sensing area. To acquire the complete real-time IAQ distribution map, we exploit the real statistical data to construct the IAQ data model and adopt Kalman Filter to obtain the estimation of the unmeasured area. Since the movement of the robots affects the estimation accuracy, a proper movement strategy should be planned to minimize the total estimation error. To solve this optimization problem, we design a deep Q-learning approach, which provides sub-optimal movement strategies for real-time robot sensing. By simulations, we verify the adopted IAQ data model and testify the effectiveness of the proposed solution. For application considerations, we have deployed this system in Peking University since Dec. 2018 and developed a website to visualize the IAQ distribution.",https://ieeexplore.ieee.org/document/9120611/,2020 IEEE Wireless Communications and Networking Conference (WCNC),25-28 May 2020,ieeexplore
10.1109/CONIELECOMP.2017.7891823,Detecting falling people by autonomous service robots: A ROS module integration approach,IEEE,Conferences,"In this paper is presented the integration of diverse modules for people fallen detection by a mobile service robot. This integration has been achieved in the middleware ROS (Robotics Operation System). The proposed implementation are arranged over an modular architecture of three layers: Hardware, Processing and Decision. The modules implemented are on the processing layer. The first module uses an RGB-D camera to detect and track a person in the environment. This module calculate features to detect the fallen pose. In the second module, a PID controller in a pan/tilt unit is used, in order to track the person with a minimum error and soft movement. For this purpose the centroid of the person is located at the center of the plane image. The main characteristics in our architecture are: 1) Segmentation in depth is used, because 3D information is required for detecting the fallen pose; 2) The parameters of PID control are tuned using a manual method and a genetic algorithm, to compare and improve the performance of the tracking person module. Once the PID controller was optimized, the architecture to follow the person and detect the fallen pose, is probed in real time.",https://ieeexplore.ieee.org/document/7891823/,"2017 International Conference on Electronics, Communications and Computers (CONIELECOMP)",22-24 Feb. 2017,ieeexplore
10.1109/IEEECONF49454.2021.9382646,Development and Testing of Garbage Detection for Autonomous Robots in Outdoor Environments,IEEE,Conferences,"In Japan, there is a growing concern about labor shortages due to the declining birthrate and aging population, and there are high expectations for robots to help solve such social problems and create industries. However, due to the prohibition of public road tests in Japan, there are few examples of actual applications of robots. Therefore, considerations and problems in the practical application of robots are still unclear. In this paper, by focusing on the implementation of garbage collection technology, we have developed an autonomous garbage collection robot using deep learning. In addition, we have verified the usefulness of our garbage detection technology in outdoor environments by conducting actual demonstrations at HANEDA INNOVATION CITY, which is a large-scale commercial and business complex belonged private property, Utsunomiya University, and Nakanoshima Challenge 2019, which is a field of demonstration experiment in the outdoor environment. Our garbage detector was designed to detect cans, plastic bottles, and lunch boxes automatically. Through experiments on test data and outdoor experiments in the real-world, we have confirmed that our detector has a 95.6% Precision and 96.8% Recall. Conparisons to other state-of-the-art detectors are also presented.",https://ieeexplore.ieee.org/document/9382646/,2021 IEEE/SICE International Symposium on System Integration (SII),11-14 Jan. 2021,ieeexplore
10.1109/EMS.2017.12,Development of Components of Multi-agent CASE-System for Describing the Logic of Behavior of Mobile Robots,IEEE,Conferences,"In the article there are substantiation of architectural and technical solutions, with the basis of the universal CASE-tool for describing (""programming"") the behavior of mobile robots. The development tool intended for carrying out experiments in the field of artificial intelligence and it is based on multi-agent technology. In addition, the toolkit will be the maximum possible reuse of elements (tasks, processes, etc.). The basis for the development is the idea of combining, within the framework of one tool, both the real execution of the algorithm by the robot, and its simulation. It allows talking about testing partially implemented hardware (sensors and actuators). Development is carried out based on open source technology; all texts of programs are available at web source: https://github.com/unclesal/tenguai.",https://ieeexplore.ieee.org/document/8356782/,2017 European Modelling Symposium (EMS),20-21 Nov. 2017,ieeexplore
10.1109/IROS.2016.7759250,Efficient learning of stand-up motion for humanoid robots with bilateral symmetry,IEEE,Conferences,"Standing up after falling is an essential ability for humanoid robots in order to resume their tasks without help from humans. Although many humanoid robots, especially small-size humanoid robots, have their own stand-up motions, there has not been a generalized method to automatically learn flexible stand-up motions for humanoid robots which can be applied to various fallen positions. In this research, we propose a method for learning stand-up motions for humanoid robots using Q-learning making use of their bilateral symmetry. We implemented this method on DarwIn-OP humanoid robots and learned an optimal policy in simulation. We compared the resulting stand-up motion with manually designed stand-up motions and with stand-up motions learned without considering bilateral symmetry. Both in simulation and on the real robot, the new stand-up motion was successful in most trials while other motions took longer or were not as robust.",https://ieeexplore.ieee.org/document/7759250/,2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),9-14 Oct. 2016,ieeexplore
10.1109/IROS.2001.976268,Embedding cooperation in robots to play soccer game,IEEE,Conferences,"Robotic soccer provides an opportunity to explore such a challenging research topic that multiple agents (physical robots or sofbots) work together in a realtime, noisy and adversarial environment to obtain specific objectives. It requires each agent can not only deal with infinite unpredictable situations, but also present cooperation with others. The previous researches about cooperation often put emphasis on task decomposition and conflict avoidance among team members. In this paper, we describe a robot architecture, which addresses ""scaling cooperation"" among robots, and meanwhile keeps each robot making decision independently. The architecture is based on ""ideal cooperation"" principle and implemented for Small Robot League in RoboCup Experimental results prove its effectiveness and reveal several primary characteristics of behaviors in robotic soccer. Finally, some important problems of future work are discussed.",https://ieeexplore.ieee.org/document/976268/,Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180),29 Oct.-3 Nov. 2001,ieeexplore
10.1109/ROBOT.2003.1241690,Extended QDSEGA for controlling real robots - acquisition of locomotion patterns for snake-like robot,IEEE,Conferences,"Reinforcement learning is very effective for robot learning. It is because it does not need prior knowledge and has higher capability of reactive and adaptive behaviors. In our previous works, we proposed new reinforce learning algorithm: ""Q-learning with dynamic structuring of exploration space based on genetic algorithm (QDSEGA)"". It is designed for complicated systems with large action-state space like a robot with many redundant degrees of freedom. However the application of QDSEGA is restricted to static systems. A snake-like robot has many redundant degrees of freedom and the dynamics of the system are very important to complete the locomotion task. So application of usual reinforcement learning is very difficult. In this paper, we extend layered structure of QDSEGA so that it becomes possible to apply it to real robots that have complexities and dynamics. We apply it to acquisition of locomotion pattern of the snake-like robot and demonstrate the effectiveness and the validity of QDSEGA with the extended layered structure by simulation and experiment.",https://ieeexplore.ieee.org/document/1241690/,2003 IEEE International Conference on Robotics and Automation (Cat. No.03CH37422),14-19 Sept. 2003,ieeexplore
10.1109/AMC.2019.8371065,"Extending the life of legacy robots: MDS-Ach, a real-time, process based, networked, secure middleware based on the x-Ach methodology",IEEE,Conferences,"This work shows how to add modern tools to legacy robots while retaining the original tools and original calibration procedures/utilities through the use of a lightweight middleware connected to the communications level of the robot. MDS-Ach is a middleware made for the Xitome Mobile Dexterous Social (MDS) Robot originally released in 2008. The robot is being actively used at multiple locations including the U.S. Naval Research Laboratory's Laboratory for Autonomous Systems Research (NRL-LASR). The MDS-Ach middleware gives the MDS Robot the software capabilities of modern robot systems using the x- Ach real-time processes based architecture. It controls the MDS Robot directly over the controller area network (CAN) bus via a dedicated real-time daemon. Each process communicates with the others over a network capable shared memory. The shared memory is a ""first-in-last-out"" (i.e. reads the newest data first) non-head-of-line blocking ring buffer which ensures readability of latest data first while retaining the ability to retrieve the older data. When running over a network, UDP or TCP protocol can be utilized depending on the timing and reliability requirements. SSH tunneling is used when secure connections between networked controllers are required. The MDS-Ach middleware is designed to allow for simple and easy development with modern robotic tools while adding accessibility and usability to our non-hardware-focused partners. Real-time collision avoidance and a robust inverse kinematics solution are implemented within the MDS-Ach system. Examples of collision avoidance, inverse kinematics implementation, and the software architecture are given.",https://ieeexplore.ieee.org/document/8371065/,2018 IEEE 15th International Workshop on Advanced Motion Control (AMC),9-11 March 2018,ieeexplore
10.1109/ICSyS47076.2019.8982469,FPGA-enabled Binarized Convolutional Neural Networks toward Real-time Embedded Object Recognition System for Service Robots,IEEE,Conferences,"In this presentation, we report the results of applying a binarized Convolutional Neural Network (CNN) and a Field Programmable Gate Array (FPGA) for image-based object recognition. While the demand rises for robots with robust object recognition implemented with Neural Networks, a tradeoff between data processing rate and power consumption persists. Some applications utilise Graphics Processing Units (GPU), which results in high power consumption, thus undesirable for embedded systems, while the others communicate with cloud computers to minimise computational resources at the clients' side, i.e. robots, raising another concern that the robots are unable to perform object recognition without the servers and network connections. To overcome these difficulties, we propose an embedded object recognition system implemented with a binarized CNN and an FPGA. FPGAs consist of a matrix of reconfigurable logic gates allowing parallel computing which befit most image processing algorithms such as the CNN. We train the binarized CNN on one of our datasets that contain images of several kinds of food and beverages. The results of the experiments show that the binarized CNN with an FPGA maintains high accuracy as well as real-time computation, suggesting that the proposed system is suitable for robots to perform their tasks in a real-world environment without needing to communicate with a server.",https://ieeexplore.ieee.org/document/8982469/,2019 IEEE International Circuits and Systems Symposium (ICSyS),18-19 Sept. 2019,ieeexplore
10.1109/COASE.2017.8256157,Full automatic path planning of cooperating robots in industrial applications,IEEE,Conferences,"Parts made of carbon fiber reinforced plastics (CFRP) for airplane components can be so huge that a single industrial robot is no longer able to handle them, and cooperating robots are required. Manual programming of cooperating robots is difficult, but with large numbers of different sized and shaped cut-pieces, it is almost impossible. This paper presents an automated production system consisting of a camera for the precise detection of the position of each cut-piece and a collision-free path planner which can dynamically react to different positions for the transfer motions. The path is planned for multiple robots adhering to motion constrains, such as the requirement that the textile cut-piece must form a catenary which can change during transport. Additionally a technique based on machine learning has been implemented which correctly resolves redundancy for a linear axis during planning. Finally, all components are tested on a real robot system in industrial scale.",https://ieeexplore.ieee.org/document/8256157/,2017 13th IEEE Conference on Automation Science and Engineering (CASE),20-23 Aug. 2017,ieeexplore
10.1109/INDIN.2009.5195905,GPS and sonar based area mapping and navigation by mobile robots,IEEE,Conferences,"In this paper, we have presented a GPS and sonar based area mapping and navigation scheme for a mobile robot. A mapping is achieved between the GPS space and the world coordinates of the mobile robot which enables us to generate direct motion commands for it. This mapping enables the robot to navigate among different GPS locations within the mapped area. The GPS data is extracted online to get the latitude and longitude information of a particular location. In the training phase, a 2-D axis transformation is used to relate local robot frame with the robot world coordinates and then the actual world coordinates are mapped from the GPS data using a RBFN (radial basis function network) based Neural Network. In the second phase, direct GPS data is used to get the mapping into the world coordinates of mobile robot using the trained network and the motion commands are generated accordingly. The physical placement of sonar devices, their ranging limits and beam opening angles are considered during navigation for possible collision detection and obstacle avoidance. This scheme is successfully implemented in real time with Pioneer mobile robot from ActivMedia Robotics and GPS receiver. The scheme is also tested in the simulation to justify its application in the real world.",https://ieeexplore.ieee.org/document/5195905/,2009 7th IEEE International Conference on Industrial Informatics,23-26 June 2009,ieeexplore
,Giving robots a flexible persona: The five factor model of artificial personality in action,IEEE,Conferences,"A computational framework for artificial personality in cognitive robots is introduced. While every robot has some form of personality, the framework reported here is flexible and enables the exploration of different behaviors on the same robotic platform. The framework described here maintains a probabilistic representation of an internal state that includes emotion, motivation, sensing, and previous action. The next action is computed by using a massive number of rules implemented using Bayes Rule. This flexible Bayesian representation of personality allows the robots personality to be designed by a personality generator algorithm. The authors present results in a real robot and compare the behavior of robots with differing personalities.",https://ieeexplore.ieee.org/document/6393419/,"2012 12th International Conference on Control, Automation and Systems",17-21 Oct. 2012,ieeexplore
10.1109/TAI.2000.889888,History checking of temporal fuzzy logic formulas for monitoring behavior-based mobile robots,IEEE,Conferences,"Behavior-based robot control systems have shown remarkable success for controlling robots evolving in real world environments. However, they can fail in different manners due to their distributed control and their local decision making. In this case, monitoring can be used to detect failures and help to recover from them. In this work, we present an approach for specifying monitoring knowledge and a method for using this knowledge to detect failures. In particular we show how temporal fuzzy logic can be used to represent monitoring knowledge and then utilized to effectively detect runtime failures. New semantics are introduced to take into consideration uncertainty and noisy information. There are numbers of advantages to our approach including a declarative semantics for the monitoring knowledge and an independence of this knowledge from the implementation details of the control system. Moreover we show how our system can deal effectively with noisy information and sensor readings. Experiments with two real world robots and the simulator are used to illustrate failure examples and the benefits of failure detection and noise elimination.",https://ieeexplore.ieee.org/document/889888/,Proceedings 12th IEEE Internationals Conference on Tools with Artificial Intelligence. ICTAI 2000,15-15 Nov. 2000,ieeexplore
10.1109/AIIoT52608.2021.9454183,Image Classification with Knowledge-Based Systems on the Edge for Real-Time Danger Avoidance in Robots,IEEE,Conferences,"Mobile robots are increasingly common in society and are increasingly being used for complex and high-stakes tasks such as search and rescue. The growing requirements for these robots demonstrate a need for systems which can review and react in real time to environmental hazards, which will allow robots to handle environments that are both dynamic and dangerous. We propose and test a system which allows mobile robots to reclassify environmental objects during operation in conjunction with an edge system. We train an image classification model with 99 percent accuracy and deploy it in conjunction with an edge server and JSON-based ruleset to allow robots to react to and avoid hazards.",https://ieeexplore.ieee.org/document/9454183/,2021 IEEE World AI IoT Congress (AIIoT),10-13 May 2021,ieeexplore
10.1109/ELECTR.1991.718282,Imaging And Controls For Mars Robots With Neural Networks,IEEE,Conferences,"Two aspects of the design of space robots is covered implemented by neural networks and by hybrid approach with artificial intelligence. One is a neurocontroller for a real-time autonomous system. An optical control system developed saves the time for the image processing that analyzes an image sensor through the environment and induces a transformation over the sensor array. A prototype of the neurocontroller is able to learn and control by itself. The second aspect deals with the design of a Servo Control System for a Robot with the capability of ""learning in Unanticipated Situations"" incorporated in the system. The robot is assumed to be employed to perform useful tasks in an alien evironment. The model developed is shown to provide the robot with the capability to recover from unanticipated situations that can lead to the disruption of its normal operation, and to learn to avoid such situations in the future. These two aspects will be integrated for a design of a very intelligent autonomous space robot.",https://ieeexplore.ieee.org/document/718282/,"Electro International, 1991",16-18 April 1991,ieeexplore
10.1109/ROBOT.1991.131908,Instinctive behaviors and personalities in societies of cellular robots,IEEE,Conferences,"A description is presented of the social organization of societies of cellular mobile units featuring instinctive behavior. Each robotic unit has its own personality and lives independently from the others. Useful tasks are carried out through collaboration rather than by individual effort. The behavior of each unit derives from a subsumption-like control structure, which emphasizes the roles of innate personality, external stimuli, and communication. A number of different robotic personalities are described and techniques of implementing them in real robot units are outlined. The implementation of instinctive behavior is described for the case of a robotic vehicle system (ROBBIE).&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/131908/,Proceedings. 1991 IEEE International Conference on Robotics and Automation,9-11 April 1991,ieeexplore
10.1109/IJCNN.2014.6889647,Intelligent Facial Action and emotion recognition for humanoid robots,IEEE,Conferences,"This research focuses on the development of a realtime intelligent facial emotion recognition system for a humanoid robot. In our system, Facial Action Coding System is used to guide the automatic analysis of emotional facial behaviours. The work includes both an upper and a lower facial Action Units (AU) analyser. The upper facial analyser is able to recognise six AUs including Inner and Outer Brow Raiser, Upper Lid Raiser etc, while the lower facial analyser is able to detect eleven AUs including Upper Lip Raiser, Lip Corner Puller, Chin Raiser, etc. Both of the upper and lower analysers are implemented using feedforward Neural Networks (NN). The work also further decodes six basic emotions from the recognised AUs. Two types of facial emotion recognisers are implemented, NN-based and multi-class Support Vector Machine (SVM) based. The NN-based facial emotion recogniser with the above recognised AUs as inputs performs robustly and efficiently. The Multi-class SVM with the radial basis function kernel enables the robot to outperform the NN-based emotion recogniser in real-time posed facial emotion detection tasks for diverse testing subjects.",https://ieeexplore.ieee.org/document/6889647/,2014 International Joint Conference on Neural Networks (IJCNN),6-11 July 2014,ieeexplore
10.1109/ICETIETR.2018.8529028,IoT Enabled Robots with QR Code Based Localization,IEEE,Conferences,"Robots are sophisticated form of IoT devices as they are smart devices that scrutinize sensor data from multiple sources and observe events to decide the best procedural actions to supervise and manoeuvre objects in the physical world. In this paper, localization of the robot is addressed by QR code Detection and path optimization is accomplished by Dijkstras algorithm. The robot can navigate automatically in its environment with sensors and shortest path is computed whenever heading measurements are updated with QR code landmark recognition. The proposed approach highly reduces computational burden and deployment complexity as it reflects the use of artificial intelligence to self-correct its course when required. An Encrypted communication channel is established over wireless local area network using SSHv2 protocol to transfer or receive sensor data(or commands) making it an IoT enabled Robot.",https://ieeexplore.ieee.org/document/8529028/,2018 International Conference on Emerging Trends and Innovations In Engineering And Technological Research (ICETIETR),11-13 July 2018,ieeexplore
10.1109/CCWC.2017.7868418,"Low-cost, real-time obstacle avoidance for mobile robots",IEEE,Conferences,"The goal of this project<sup>1</sup> is to advance the field of automation and robotics by utilizing recently-released, low-cost sensors and microprocessors to develop a mechanism that provides depth-perception and autonomous obstacle avoidance in a plug-and-play fashion. We describe the essential hardware components that can enable such a low-cost solution and an algorithm to avoid static obstacles present in the environment. The mechanism utilizes a novel single-point LIDAR module that affords more robustness and invariance than popular approaches, such as Neural Networks and Stereo. When this hardware is coupled with the proposed efficient obstacle avoidance algorithm, this mechanism is able to accurately represent environments through point clouds and construct obstacle-free paths to a destination, in a small timeframe. A prototype mechanism has been installed on a quadcopter for visualization on how actual implementation may take place<sup>2</sup>. We describe experimental results based on this prototype.",https://ieeexplore.ieee.org/document/7868418/,2017 IEEE 7th Annual Computing and Communication Workshop and Conference (CCWC),9-11 Jan. 2017,ieeexplore
10.1109/BioRob49111.2020.9224368,Machine Learning for Motor Learning: EEG-based Continuous Assessment of Cognitive Engagement for Adaptive Rehabilitation Robots,IEEE,Conferences,"Although cognitive engagement (CE) is crucial for motor learning, it remains underutilized in rehabilitation robots, partly because its assessment currently relies on subjective and gross measurements taken intermittently. Here, we propose an end-to-end computational framework that assesses CE in near real-time, using electroencephalography (EEG) signals as objective measurements. The framework consists of i) a deep convolutional neural network that extracts task-discriminative spatiotemporal EEG features to predict the level of CE for two classes- cognitively engaged vs. disengaged; and ii) a novel sliding window method that predicts continuous levels of CE in short time intervals. We evaluated our framework on 8 healthy subjects using an in-house Go/No-Go experiment that adapted its gameplay parameters to induce cognitive fatigue. The proposed CNN had an average leave-one-subject-out accuracy of 88.19%. The CE prediction correlated well with a commonly used behavioral metric based on self-reports taken every 5 minutes (ρ=0.93). Our results objectify CE measurement in near real-time and pave the way for using CE as a rehabilitation parameter for tailoring robotic therapy to each patient's needs and skills.",https://ieeexplore.ieee.org/document/9224368/,2020 8th IEEE RAS/EMBS International Conference for Biomedical Robotics and Biomechatronics (BioRob),29 Nov.-1 Dec. 2020,ieeexplore
10.1109/ROMAN.2010.5598692,Motion rendering system for emotion expression of human form robots based on Laban movement analysis,IEEE,Conferences,"A method for adding a target emotion to arbitrary body movements of a human form robot (HFR) is developed. The additional emotion is pleasure, anger, sadness or relaxation. This paper proposes a motion rendering system that modifies arbitrary basic movements of a certain real HFR to add the target emotion at intended strength. The system is developed on the assumption that movements can be emotive by processed on the basis of the correlations between movement features and expressed emotions. The movement features based on Laban movement analysis (LMA) are adopted. An experiment using a real HFR are conducted to test how well our system adds a target emotion to arbitrary movements at intended strength. The results of experiments suggest that our method succeeded in adding a target emotion to arbitrary movements.",https://ieeexplore.ieee.org/document/5598692/,19th International Symposium in Robot and Human Interactive Communication,13-15 Sept. 2010,ieeexplore
10.1109/ICRA48506.2021.9561586,Multimodal Anomaly Detection based on Deep Auto-Encoder for Object Slip Perception of Mobile Manipulation Robots,IEEE,Conferences,"Object slip perception is essential for mobile manipulation robots to perform manipulation tasks reliably in the dynamic real-world. Traditional approaches to robot arms’ slip perception use tactile or vision sensors. However, mobile robots still have to deal with noise in their sensor signals caused by the robot’s movement in a changing environment. To solve this problem, we present an anomaly detection method that utilizes multisensory data based on a deep autoencoder model. The proposed framework integrates heterogeneous data streams collected from various robot sensors, including RGB and depth cameras, a microphone, and a force-torque sensor. The integrated data is used to train a deep autoencoder to construct latent representations of the multisensory data that indicate the normal status. Anomalies can then be identified by error scores measured by the difference between the trained encoder’s latent values and the latent values of reconstructed input data. In order to evaluate the proposed framework, we conducted an experiment that mimics an object slip by a mobile service robot operating in a real-world environment with diverse household objects and different moving patterns. The experimental results verified that the proposed framework reliably detects anomalies in object slip situations despite various object types and robot behaviors, and visual and auditory noise in the environment.",https://ieeexplore.ieee.org/document/9561586/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/IJCNN.2001.938487,Neuro-controller for high performance induction motor drives in robots,IEEE,Conferences,"Presents an approach to the speed control of an induction motor (IM) as a robust high performance drive (HPD) using an online self-tuning adapted artificial neural network (ANN). Based on motor dynamics and nonlinear unknown load characteristics such as robot systems, a neuro speed controller is developed. The proposed controller is very simple and serves as an identifier and a controller at the same time. The combination of the adaptive learning rate with the epochs used through the online training offers a unique feature of system identification and adaptive control. The performance of the controller was evaluated under various operating conditions to track different speed trajectories. The results validate the efficacy of the ANN for the precise tracking control of IM. Furthermore the use of the ANN makes the drive system robust, accurate, and insensitive to parameter variations. Also the drive system is implemented in real-time using a digital signal processor (DSP) TMS320C31.",https://ieeexplore.ieee.org/document/938487/,IJCNN'01. International Joint Conference on Neural Networks. Proceedings (Cat. No.01CH37222),15-19 July 2001,ieeexplore
10.1109/CCMB.2014.7020689,Neuromodulation based control of autonomous robots in ROS environment,IEEE,Conferences,"The paper presents a control approach based on vertebrate neuromodulation and its implementation on autonomous robots in the open-source, open-access environment of robot operating system (ROS) within a cloud computing framework. A spiking neural network (SNN) is used to model the neuromodulatory function for generating context based behavioral responses of the robots to sensory input signals. The neural network incorporates three types of neurons- cholinergic and noradrenergic (ACh/NE) neurons for attention focusing and action selection, dopaminergic (DA) neurons for rewards- and curiosity-seeking, and serotonergic (5-HT) neurons for risk aversion behaviors. The model depicts description of neuron activity that is biologically realistic but computationally efficient to allow for large-scale simulation of thousands of neurons. The model is implemented using graphics processing units (GPUs) for parallel computing in real-time using the ROS environment. The model is implemented to study the risk-taking, risk-aversive, and distracted behaviors of the neuromodulated robots in single- and multi-robot configurations. The entire process is implemented in a distributed computing framework using ROS where the robots communicate wirelessly with the computing nodes through the on-board laptops. Results are presented for both single- and multi-robot configurations demonstrating interesting behaviors.",https://ieeexplore.ieee.org/document/7020689/,"2014 IEEE Symposium on Computational Intelligence, Cognitive Algorithms, Mind, and Brain (CCMB)",9-12 Dec. 2014,ieeexplore
10.1109/IConSCS.2012.6502471,Object recognition based on radial basis function neural networks: Experiments with RGB-D camera embedded on mobile robots,IEEE,Conferences,"An object recognition strategy based on artificial radial basis functions neural networks is presented in this paper. The general context of this work is to recognize object from captures made by a mobile robot. Unlike classical approaches which always select the closest object, our method outputs a set of potential candidates if the input information is not enough discriminant. There are three main steps in our approach: objects segmentation, signature extraction and classification. Segmentation is inspired from previous works and is shortly described. Signature extraction based on global geometric and color features is detailed. Classification based on artificial neural networks is also explained and architecture of the network is justified. Finally a real experiment made with a RGB-D camera mounted on a mobile robot is presented and classification results is criticized.",https://ieeexplore.ieee.org/document/6502471/,2012 1st International Conference on Systems and Computer Science (ICSCS),29-31 Aug. 2012,ieeexplore
10.1109/SSCI.2017.8280907,Obstacle avoidance of hexapod robots using fuzzy Q-learning,IEEE,Conferences,"Safe and autonomous obstacle avoidance plays an important role in the navigation control of hexapod robots. In this paper, we combine the method of reinforcement learning with fuzzy control to achieve the autonomous obstacle avoidance for a hexapod robot in complex environments. A fuzzy Q-learning algorithm is first presented and an obstacle avoidance approach is proposed using the Fuzzy Q-learning algorithm regarding the specific requirements of the hexapod robot. Then, the proposed approach is implemented for a real hexapod robot system that uses ultrasonic sensors to detect the obstacles in an unknown environment and learns an optimal policy to avoid the obstacles. Several groups of experiments are carried out to verify the performance of the proposed approach.",https://ieeexplore.ieee.org/document/8280907/,2017 IEEE Symposium Series on Computational Intelligence (SSCI),27 Nov.-1 Dec. 2017,ieeexplore
10.1109/ICRA40945.2020.9196769,Online LiDAR-SLAM for Legged Robots with Robust Registration and Deep-Learned Loop Closure,IEEE,Conferences,"In this paper, we present a 3D factor-graph LiDAR-SLAM system which incorporates a state-of-the-art deeply learned feature-based loop closure detector to enable a legged robot to localize and map in industrial environments. Point clouds are accumulated using an inertial-kinematic state estimator before being aligned using ICP registration. To close loops we use a loop proposal mechanism which matches individual segments between clouds. We trained a descriptor offline to match these segments. The efficiency of our method comes from carefully designing the network architecture to minimize the number of parameters such that this deep learning method can be deployed in real-time using only the CPU of a legged robot, a major contribution of this work. The set of odometry and loop closure factors are updated using pose graph optimization. Finally we present an efficient risk alignment prediction method which verifies the reliability of the registrations. Experimental results at an industrial facility demonstrated the robustness and flexibility of our system, including autonomous following paths derived from the SLAM map.",https://ieeexplore.ieee.org/document/9196769/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.23919/ACC45564.2020.9147898,Optimal Control of Wheeled Mobile Robots: From Simulation to Real World,IEEE,Conferences,"We study the problem of taking simulations to the real world (RW) for autonomous robotic systems with dynamic uncertainties and unknown disturbances while maintaining the optimal performance and stability of the designed controller designed in simulation. In general, an optimal and robust controller that is designed through simulation often does not perform similarly when deployed in the RW. We focus on using simulations to generate an optimal control policy utilizing the Memetic algorithm (MA) iteratively. The simulation-to-RW performance and stability are realized by using an adaptive fuzzy system to learn the uncertain part of the dynamic model, disturbance and noises. We demonstrate experimentally that this method permits the development of optimal control design in simulations and integrates adaptive learning rules to enable precise and repetitive trajectory tracking for the wheeled mobile robot (WMR) with disturbances and uncertainties.",https://ieeexplore.ieee.org/document/9147898/,2020 American Control Conference (ACC),1-3 July 2020,ieeexplore
10.1109/RCAR52367.2021.9517337,Pan-tilt Control Method Applied to Mobile Robots,IEEE,Conferences,"This paper presents a pan-tilt control method based on multi-sensor fusion, PSO and BP neural network. The traditional PID control algorithm has the disadvantage of difficult parameter tuning, and it is difficult to realize the effective control of complex nonlinear system. BP neural network is used to set the PID three parameters, but the initial neural network is easy to fall into local optimal and slow convergence. In this paper, PSO algorithm is further used to set the initial weight of BP neural network, which can effectively improve the global search ability and convergence speed of BP neural network. The pan-tilt is modeled and the experiment is designed to compared with the traditional digital PID control algorithm, BP neural network PID control algorithm and PSO-BP PID control algorithm, it is proved that the control effect of PSO-BP PID control algorithm is obviously better than the former two.",https://ieeexplore.ieee.org/document/9517337/,2021 IEEE International Conference on Real-time Computing and Robotics (RCAR),15-19 July 2021,ieeexplore
10.1109/ISIC.2002.1157740,Path planning for mobile robots using an improved reinforcement learning scheme,IEEE,Conferences,"The current method for establishing travel routes provides modeled environmental information. However, it is difficult to create an environment model for the environments in which mobile robots travel because the environment changes constantly due to the existence of moving objects, including pedestrians. In this study, we propose a path planning system for mobile robots using reinforcement-learning systems and Cerebellar Model Articulation Controllers (CMACs). We select the best travel route utilizing these reinforcement-learning systems. When a CMAC learns the value function of Q-Learning, it improves learning speed by utilizing generalizing action. CMACs enable us to reduce the time needed to select the best travel route. Using simulation and real robots, we perform a path-planning experiment. We report the results of simulation and experiment on traveling by on-line learning.",https://ieeexplore.ieee.org/document/1157740/,Proceedings of the IEEE Internatinal Symposium on Intelligent Control,30-30 Oct. 2002,ieeexplore
10.1109/SICE.2002.1195737,Path planning for mobile robots using an improved reinforcement learning scheme,IEEE,Conferences,"The current method for establishing travel routes provides modeled environmental information. However, it is difficult to create an environment model for the environments in which mobile robot travel because the environment changes constantly due to the existence of moving objects, Including pedestrians. In this study, we propose a path planning system for mobile robots using reinforcement-learning systems and cerebellar model articulation controllers (CMACs). We selected the best travel route utilizing these reinforcement-learning systems. When a CMAC learns the value function of Q-learning, it improves learning speed by utilizing the generalizing action. CMACs enable us to reduce the time needed to select the best travel route. Using simulation and real robots, we performed a path-planning experiment. We report the results of simulation and experiment on traveling by online learning.",https://ieeexplore.ieee.org/document/1195737/,Proceedings of the 41st SICE Annual Conference. SICE 2002.,5-7 Aug. 2002,ieeexplore
10.1109/ICECCT.2015.7226205,Performance analysis of path planning techniques for autonomous mobile robots,IEEE,Conferences,"This paper presents a comparative study on path planning techniques for autonomous mobile robots in a cluttered environment. It investigates four well known path planning algorithms and compares their performance with the proposed free configuration eigen-spaces (FCE) path planning method. In total, five path planning algorithms are considered towards the solution of the path planning problem under certain working parameters. These working parameters are the computation time needed to find a solution, the distance traveled and the amount of turning by the autonomous mobile robot. A comparison of results has been analyzed. This study will enable readers to identify, which of the proposed methods is most suitable for application under the working parameters the user wants to optimize. The findings have been summarized in the conclusion section. The techniques were implemented in the real-time robotic software Player/Stage. Further analysis were done using MATLAB mathematical computation software.",https://ieeexplore.ieee.org/document/7226205/,"2015 IEEE International Conference on Electrical, Computer and Communication Technologies (ICECCT)",5-7 March 2015,ieeexplore
10.1109/ICRA48506.2021.9561387,Pointing at Moving Robots: Detecting Events from Wrist IMU Data,IEEE,Conferences,"We propose a practical approach for detecting the event that a human wearing an IMU-equipped bracelet points at a moving robot; the approach uses a learned classifier to verify if the robot motion (as measured by its odometry) matches the wrist motion, and does not require that the relative pose of the operator and robot is known in advance. To train the model and validate the system, we collect datasets containing hundreds of real-world pointing events. Extensive experiments quantify the performance of the classifiers and relevant metrics of the resulting detectors; the approach is implemented in a real-world demonstrator that allows users to land quadrotors by pointing at them.",https://ieeexplore.ieee.org/document/9561387/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/SmartWorld.2018.00106,Real-Time Data Processing Architecture for Multi-Robots Based on Differential Federated Learning,IEEE,Conferences,"The emergency of ubiquitous intelligence in various things has become the ultimate cornerstone in building a smart interconnection of the physical world and the human world, which also caters to the idea of Internet of Things (IoT). Nowadays, robots as a new type of ubiquitous IoT devices have gained much attention. With the increasing number of distributed multi-robots, such smart environment generates unprecedented amounts of data. Robotic applications are faced with challenges of such big data: the serious real-time assurance and data privacy. Therefore, in order to obtain the big data values via knowledge sharing under the premise of ensuring the real-time data processing and data privacy, we propose a real-time data processing architecture for multi-robots based on the differential federated learning, called RT-robots architecture. A global shared model with differential privacy protection is trained on the cloud iteratively and distributed to multiple edge robots in each round, and the robotic tasks are processed locally in real time. Our implementation and experiments demonstrate that our architecture can be applied on multiple robotic recognition tasks, balance the trade-off between the performance and privacy.",https://ieeexplore.ieee.org/document/8560084/,"2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)",8-12 Oct. 2018,ieeexplore
10.1109/ICMLC.2005.1527001,Real-Time Path Planning for Mobile Robots,IEEE,Conferences,"A new on-line real-time approach with obstacle avoidance for mobile robots moving in an uncertain environment has been proposed and implemented. With the integration of global planning and local planning, this path planning approach is based on polar coordinates in which the desirable direction angle is taken into consideration as an optimization index. Detecting unknown obstacles with local feedback information by robot’s sensor system, this approach orients the desirable direction of mobile robot so as to generate local sub-goal in every planning window. As a result, the difference between real direction angle and desirable direction angle of robot motion steers the mobile robot to detour collisions and advance toward the target without stopping to re-plan a path when new sensor data become available. This approach is not only simple and flexible, but also overcomes flaws of global planning and local planning. The effectiveness, feasibility, real-time performance, optimization capability, high precision and perfect stability are demonstrated by means of simulation examples.",https://ieeexplore.ieee.org/document/1527001/,2005 International Conference on Machine Learning and Cybernetics,18-21 Aug. 2005,ieeexplore
10.1109/CEC.2003.1299618,Real-time adaptation technique to real robots: an experiment with a humanoid robot,IEEE,Conferences,"We introduce a technique that allows a real robot to execute a real-time learning, in which GP and RL are integrated. In our former research, we showed the result of an experiment with a real robot ""AIBO"" and proved the technique performed better than the traditional Q-learning method. Based on the proposed technique, we can acquire the common programs using a GP, applicable to various types of robots. We execute reinforcement learning with the acquired program in a real robot. In this way, the robot can adapt to its own operational characteristics and learn effective actions. In this paper, we show the experimental results in which a humanoid robot ""HOAP-1"" has been evolved to perform effectively to solve the box-moving task.",https://ieeexplore.ieee.org/document/1299618/,"The 2003 Congress on Evolutionary Computation, 2003. CEC '03.",8-12 Dec. 2003,ieeexplore
10.1109/ROMAN.2016.7745248,Real-time human detection for robots using CNN with a feature-based layered pre-filter,IEEE,Conferences,"Convolutional neural networks (CNNs), in combination with big data, are increasingly being used to engineer robustness into visual classification systems including human detection. One significant challenge to using a CNN on a mobile robot, however, is the associated computational cost and detection rate of running the network. In this work, we demonstrate how fusion with a feature-based layered classifier can help. Not only does score-level fusion of a CNN with the layered classifier improve precision/recall for detecting people on a mobile robot, but using the layered system as a pre-filter can substantially reduce the computational cost of running a CNN - reducing the number of objects that need to be classified while still improving precision. The combined real-time system is implemented and evaluated on a two robots with very different GPU capabilities.",https://ieeexplore.ieee.org/document/7745248/,2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),26-31 Aug. 2016,ieeexplore
10.1109/FUZZY.1998.687475,Reinforcement function design and bias for efficient learning in mobile robots,IEEE,Conferences,"The main paradigm in sub-symbolic learning robot domain is the reinforcement learning method. Various techniques have been developed to deal with the memorization/generalization problem, demonstrating the superior ability of artificial neural network implementations. In this paper, we address the issue of designing the reinforcement so as to optimize the exploration part of the learning. We also present and summarize works relative to the use of bias intended to achieve the effective synthesis of the desired behavior. Demonstrative experiments involving a self-organizing map implementation of the Q-learning and real mobile robots (Nomad 200 and Khepera) in a task of obstacle avoidance behavior synthesis are described.",https://ieeexplore.ieee.org/document/687475/,1998 IEEE International Conference on Fuzzy Systems Proceedings. IEEE World Congress on Computational Intelligence (Cat. No.98CH36228),4-9 May 1998,ieeexplore
10.1109/ICRA.2019.8793720,Robots Learn Social Skills: End-to-End Learning of Co-Speech Gesture Generation for Humanoid Robots,IEEE,Conferences,"Co-speech gestures enhance interaction experiences between humans as well as between humans and robots. Most existing robots use rule-based speech-gesture association, but this requires human labor and prior knowledge of experts to be implemented. We present a learning-based co-speech gesture generation that is learned from 52 h of TED talks. The proposed end-to-end neural network model consists of an encoder for speech text understanding and a decoder to generate a sequence of gestures. The model successfully produces various gestures including iconic, metaphoric, deictic, and beat gestures. In a subjective evaluation, participants reported that the gestures were human-like and matched the speech content. We also demonstrate a co-speech gesture with a NAO robot working in real time.",https://ieeexplore.ieee.org/document/8793720/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ICSMC.1997.635206,Robots as responsible agents,IEEE,Conferences,"The quest for real autonomous robots leads us to discuss the problem about the best possible control architecture enabling that important characteristic. It has been broadly accepted that a hybrid architecture, i.e. putting together both reactive and deliberative paradigms is needed to efficiently execute tasks in realistic dynamic environments. Our proposal, which is being implemented to control a Robuterll mobile platform, involves the use of a two-layers architecture. Using symbolic representation for knowledge and goals at the deliberative level and sub-symbolic neural networks for implementing the behaviors at the reactive level. One of the main problems we are now addressing is how to make these two levels to communicate, to interact without being completely dependent on each other. The multi-agent system framework gives a flexible strategy for single agents cooperation and enables a set of behaviours to have a certain degree of autonomy. This reactive layer works together with the cognitive control agent where goals and commitments are logically represented through simple modal logic.",https://ieeexplore.ieee.org/document/635206/,"1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation",12-15 Oct. 1997,ieeexplore
10.1109/ICRA.2018.8462969,Robust Human Following by Deep Bayesian Trajectory Prediction for Home Service Robots,IEEE,Conferences,"The capability of following a person is crucial in service-oriented robots for human assistance and cooperation. Though a vast variety of following systems exist, they lack robustness against dynamic changes of the environment and relocating to continue following a lost target. Here we present a robust human following system that has the extendability to commercial service robot platforms having a RGB-D camera. The proposed framework integrates deep learning methods for perception and variational Bayesian techniques for trajectory prediction. Deep learning modules enable robots to accompany a person by detecting the target, learning the target and following while avoiding collision within the dynamic home environment. The variational Bayesian techniques robustly predict the trajectory of the target by empowering the following ability of the robot when target is lost. We experimentally demonstrate the capability of the deep Bayesian trajectory prediction method on real-time usage, following abilities, collision avoidance and trajectory prediction of the system. The proposed system was deployed at the RoboCup@Home 2017 Social Standard Platform League and successfully demonstrated its robust functions and smooth person following capability resulting in winning the 1st place.",https://ieeexplore.ieee.org/document/8462969/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/IROS.2018.8594067,Robust Object Recognition Through Symbiotic Deep Learning In Mobile Robots,IEEE,Conferences,"Despite the recent success of state-of-the-art deep learning algorithms in object recognition, when these are deployed as-is on a mobile service robot, we observed that they failed to recognize many objects in real human environments. In this paper, we introduce a learning algorithm in which robots address this flaw by asking humans for help, also known as a symbiotic autonomy approach. In particular, we bootstrap YOLOv2, a state-of-the-art deep neural network and train a new neural network, that we call HHELP, using only data collected from human help. Using an RGB camera and an onboard tablet, the robot proactively seeks human input to assist it in labeling surrounding objects. Pepper, located at CMU, and Monarch Mbot, located at ISR-Lisbon, were the service robots that we used to validate the proposed approach. We conducted a study in a realistic domestic environment over the course of 20 days with 6 research participants. To improve object detection, we used the two neural networks, YOLOv2 + HHELP, in parallel. Following this methodology, the robot was able to detect twice the number of objects compared to the initial YOLOv2 neural network, and achieved a higher mAP (mean Average Precision) score. Using the learning algorithm the robot also collected data about where an object was located and to whom it belonged to by asking humans. This enabled us to explore a future use case where robots can search for a specific person's object. We view the contribution of this work to be relevant for service robots in general, in addition to Pepper, and Mbot.",https://ieeexplore.ieee.org/document/8594067/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ROBOT.2000.844830,Self-learning vision-guided robots for searching and grasping objects,IEEE,Conferences,"An approach to control vision-guided robots is introduced. It allows searching and grasping differently shaped objects that may be located anywhere in the robot's work space, even not visible in the initial fields of view of cameras. It eliminates the need for a calibration of the robot and of the vision system, it uses no world coordinates and no inverse perspective or kinematic transformations, and it comprises an automatic adaptation to changing parameters. The approach has been implemented on a calibration-free vision-guided manipulator with five degrees of freedom (DOF) and was evaluated in real-word experiments.",https://ieeexplore.ieee.org/document/844830/,Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065),24-28 April 2000,ieeexplore
10.1109/ROBOT.2002.1014331,Self-organized flocking with agent failure: Off-line optimization and demonstration with real robots,IEEE,Conferences,"This paper presents an investigation of flocking by teams of autonomous mobile robots using principles of Swarm Intelligence. First, we present a simple flocking task, and we describe a leaderless distributed flocking algorithm (LD) that is more conducive to implementation on embodied agents than the established algorithms used in computer animation. Next, we use an embodied simulator and reinforcement learning techniques to optimize LD performance under different conditions, showing that this method can be used not only to improve performance but also to gain insight into which algorithm components contribute most to system behavior. Finally, we demonstrate that a group of real robots executing LD with emulated sensors can successfully flock (even in the presence of individual agent failure) and that systematic characterization (and therefore optimization) of real robot flocking performance is achievable.",https://ieeexplore.ieee.org/document/1014331/,Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292),11-15 May 2002,ieeexplore
10.1109/KIMAS.2003.1245110,Sharing learning policies between multiple mobile robots,IEEE,Conferences,"Learning of a complex task usually requires a long learning period. In order to reduce the time of learning, the task is divided into several subtasks. Multiple agents can be used to serve a complex task by learning these subtasks concurrently. With a good knowledge sharing mechanism, the learning policy can be shared or exchanged among these agents and can enhance their learning efficiency. The learning policy is a mapping from system states to actions. The mechanism of sharing or exchanging learning knowledge among multiagent system is proposed. An index of expertise, which indicates the skill level of each learning agent, is presented. This index is used to select the best preferable advice among multiple advices, which can increase the probability of finding solution in the search space. The experiment in which the learning knowledge is exchanged between a mobile robot and a computer simulated agent is implemented in order to verify the validity of the proposed algorithm. The experimental results show that the learning efficiency of the advisor agent is increased and the advisee robot can use the given advice for avoiding collision with obstacle successfully in the real world implementation.",https://ieeexplore.ieee.org/document/1245110/,IEMC '03 Proceedings. Managing Technologically Driven Organizations: The Human Side of Innovation and Change (IEEE Cat. No.03CH37502),30 Sept.-4 Oct. 2003,ieeexplore
10.1109/IROS.2018.8593856,"Skill-Oriented Designer of Conceptual Robotic Structures*This work was supported by CDTI under expedient IDI-20150289 (BOTBLOQ: Ecosistema integral para el diseño, fabricación y programación de robots DIY).",IEEE,Conferences,"This communication presents an application for the use of ontologies in the generation of robot structures. The ontology developed for this app relies on the IEEE Standard Ontologies for Robotics and Automation (ORA) and it incorporates a set of concepts, relations and axioms that link robotic skills with the structural parts needed for their realization. The user can select a base configuration and/or a set of desired skills that the robot should be able to perform. Then, the application evaluates the axioms and returns an abstract structure that can carry out the requested skills. The final implementation of the structure can be achieved with any modular robotic platform that could identify each structural part with a physical device.",https://ieeexplore.ieee.org/document/8593856/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ROMAN.2002.1045681,Socially interactive robots. Why our current beliefs about them still work,IEEE,Conferences,"Discussion about the application of scientific knowledge in robotics in order to build people helpers is widespread. The issue herein addressed is philosophically poignant, that of robots that are 'people'. It is currently popular to speak about robots and the image of Man. Behind this lurks the dialogical mind and the questions on its artificial existence. Without intending to defend or refute the discourse in favour of 'recreating' Man, a lesser familiar question is brought forth: 'Given that we are capable of creating a man (constructing a robot-person), what would the consequences of this be and would we be satisfied with such technology?' Thorny topic; it questions the entire knowledge foundation upon which strong AI/Robotics is positioned. The author argues for improved monitoring of technological progress and thus favours 'soft' (weak) implementation techniques.",https://ieeexplore.ieee.org/document/1045681/,Proceedings. 11th IEEE International Workshop on Robot and Human Interactive Communication,27-27 Sept. 2002,ieeexplore
10.1109/IMCEC.2018.8469727,Study on Interactive Robots with Contingent Responses,IEEE,Conferences,"In the study of human-robot interaction, how to engage humans with robots and how to measure the engagement level are the important questions. Current study and technology achieved user habit adaptable intelligent system, whereas this technology relies heavily on the history of user behaviour and it always take a long time for the robots to make adjustments. However, this technology can hardly meet the demand from society anymore as people are expecting robots to adapt to user preferences in a shorter period. Due to the massive calculation for computer and complexity of system, research on robots with contingent response is still at early stage. Most relevant studies focus on one specific task that involves interacting with users and there is one project that focuses on finding elements that determine user behaviours. An experiment is designed to better investigate the factors that determine user engagement level.",https://ieeexplore.ieee.org/document/8469727/,"2018 2nd IEEE Advanced Information Management,Communicates,Electronic and Automation Control Conference (IMCEC)",25-27 May 2018,ieeexplore
10.1109/FIE.2008.4720346,"Teaching concepts in fuzzy logic using low cost robots, PDAs, and custom software",IEEE,Conferences,"Fuzzy logic is a topic traditionally taught in artificial intelligence, machine learning, and robotics courses. Students receive the necessary mathematical and theoretical foundation in lecture format. The final learning experience may require that students create and code their own fuzzy logic application that solves a real world problem. This can be an issue when the target is a bioengineering course that introduces classical control theory, fuzzy logic, neural networks, genetic algorithms and genetic programming through the use of a low cost robot, personal digital assistant (PDA) handheld computer, and custom PDA software. In this course, the concepts and theories discussed in lecture are reinforced and extended in a corresponding laboratory through the use of wireless robots and PDAs. Fuzzy logic libraries and software modules for laptops and desktop computers are readily available, however, when it comes to handheld computers no such libraries exist. Students are able to spend more time experimenting with different fuzzy logic controllers when a custom fuzzy logic library and PDA graphical user interface are utilized. In this paper we introduce and discuss a unique low cost wireless robot, a custom fuzzy logic library, a custom fuzzy logic GUI for the PDA, and the implementation results for the fuzzy logic section in a newly created bioengineering course. Diagnostic and summative assessment in the form of a pre-test and post-test was administered for each section of the course, however, only the results for the fuzzy logic section will be provided.",https://ieeexplore.ieee.org/document/4720346/,2008 38th Annual Frontiers in Education Conference,22-25 Oct. 2008,ieeexplore
10.1109/IROS.2013.6696802,Teaching mobile robots to cooperatively navigate in populated environments,IEEE,Conferences,"Mobile service robots are envisioned to operate in environments that are populated by humans and therefore ought to navigate in a socially compliant way. Since the desired behavior of the robots highly depends on the application, we need flexible means for teaching a robot a certain navigation policy. We present an approach that allows a mobile robot to learn how to navigate in the presence of humans while it is being teleoperated in its designated environment. Our method applies feature-based maximum entropy learning to derive a navigation policy from the interactions with the humans. The resulting policy maintains a probability distribution over the trajectories of all the agents that allows the robot to cooperatively avoid collisions with humans. In particular, our method reasons about multiple homotopy classes of the agents' trajectories, i. e., on which sides the agents pass each other. We implemented our approach on a real mobile robot and demonstrate that it is able to successfully navigate in an office environment in the presence of humans relying only on on-board sensors.",https://ieeexplore.ieee.org/document/6696802/,2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,3-7 Nov. 2013,ieeexplore
10.1109/ISIE.1998.711559,The sensor-control Jacobian as a basis for controlling calibration-free robots,IEEE,Conferences,"A method for controlling the motions of robots is presented. It is based on the newly introduced sensor-control Jacobian matrix and avoids all quantitative modeling of the robot and the sensor system. The sensor-control Jacobian contains the coefficients that relate those changes in sensor data which are caused by a motion of the robot to the robot control words that caused the robot to move and, thus, the sensor data to change. A wide variety of tasks of robots can be reduced to minimizing the differences between actual sensor data and a set of hypothetical sensor data corresponding to some desired state. All these tasks can be solved by this method. The method is especially useful for calibration-free robots, since neither quantitative models of the mechanical, kinematic and control characteristics of the robot, nor knowledge of the sensor characteristics are required. The sensor-control Jacobian may be determined automatically in real time while the robot is operating. This yields a high degree of adaptability and flexibility against unforeseen changes in the robot's parameters. Because the concept has an open structure it allows further extensions and improvements, e.g., in terms of the utilization of sensor data redundancy and machine learning. For the purpose of evaluation, the concept has been implemented on a calibration-free camera-manipulator system. Real-world grasping experiments have demonstrated the effectiveness of the method.",https://ieeexplore.ieee.org/document/711559/,IEEE International Symposium on Industrial Electronics. Proceedings. ISIE'98 (Cat. No.98TH8357),7-10 July 1998,ieeexplore
10.1109/ICRA.2011.5980333,To look or not to look: A hierarchical representation for visual planning on mobile robots,IEEE,Conferences,"Mobile robots are increasingly being used in real-world applications due to the ready availability of high fidelity sensors and the development of sophisticated information processing algorithms. However, one key challenge to the widespread deployment of mobile robots equipped with multiple sensors and processing algorithms is the ability to autonomously tailor sensing and information processing to the task at hand. This paper poses this challenge as the task of planning under uncertainty, and more specifically as an instance of probabilistic sequential decision-making. A novel hierarchy of partially observable Markov decision processes (POMDPs) is incorporated, which uses constrained-convolutional policies and automatic belief propagation to achieve efficient and reliable operation on mobile robots. All algorithms are implemented and evaluated on simulated and physical robot platforms for the task of searching for target objects in dynamic indoor environments.",https://ieeexplore.ieee.org/document/5980333/,2011 IEEE International Conference on Robotics and Automation,9-13 May 2011,ieeexplore
10.1109/IECON.2016.7793038,Tool compensation in walk-through programming for admittance-controlled robots,IEEE,Conferences,"This paper describes a walk-through programming technique, based on admittance control and tool dynamics compensation, to ease and simplify the process of trajectory learning in common industrial setups. In the walk-through programming, the human operator grabs the tool attached at the robot end-effector and “walks” the robot through the desired positions. During the teaching phase, the robot records the positions and then it will be able to interpolate them to reproduce the trajectory back. In the proposed control architecture, the admittance control allows to provide a compliant behavior during the interaction between the human operator and the robot end-effector, while the algorithm of compensation of the tool dynamics allows to directly use the real tool in the teaching phase. In this way, the setup used for the teaching can directly be the one used for performing the reproduction task. Experiments have been performed to validate the proposed control architecture and a pick and place example has been implemented to show a possible application in the industrial field.",https://ieeexplore.ieee.org/document/7793038/,IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society,23-26 Oct. 2016,ieeexplore
10.1109/CoASE.2014.6899348,Toward safe close-proximity human-robot interaction with standard industrial robots,IEEE,Conferences,"Allowing humans and robots to interact in close proximity to each other has great potential for increasing the effectiveness of human-robot teams across a large variety of domains. However, as we move toward enabling humans and robots to interact at ever-decreasing distances of separation, effective safety technologies must also be developed. While new, inherently human-safe robot designs have been established, millions of industrial robots are already deployed worldwide, which makes it attractive to develop technologies that can turn these standard industrial robots into human-safe platforms. In this work, we present a real-time safety system capable of allowing safe human-robot interaction at very low distances of separation, without the need for robot hardware modification or replacement. By leveraging known robot joint angle values and accurate measurements of human positioning in the workspace, we can achieve precise robot speed adjustment by utilizing real-time measurements of separation distance. This, in turn, allows for collision prevention in a manner comfortable for the human user.We demonstrate our system achieves latencies below 9.64 ms with 95% probability, 11.10 ms with 99% probability, and 14.08 ms with 99.99% probability, resulting in robust real-time performance.",https://ieeexplore.ieee.org/document/6899348/,2014 IEEE International Conference on Automation Science and Engineering (CASE),18-22 Aug. 2014,ieeexplore
10.1109/ROBOT.1990.126044,Towards a real-time architecture for obstacle avoidance and path planning in mobile robots,IEEE,Conferences,"The design and partial implementation of a real-time architecture for a mobile robot, aimed particularly towards a vehicle developed for factory automation, is described. The authors develop a layered design to equip the robot with a number of behavioral competences. They examine sensing and a potential field algorithm especially to achieve modification of behavior at a speed close to the robot's operational speed. It is shown how the layered architecture interfaces to the original onboard architecture, which provided sophisticated localization but no ability to deal with environmental exceptions.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/126044/,"Proceedings., IEEE International Conference on Robotics and Automation",13-18 May 1990,ieeexplore
10.1109/INDIN.2012.6301137,Towards hierarchical self-optimization in autonomous groups of mobile robots,IEEE,Conferences,"We present a real-world scenario for investigating and demonstrating hierarchical self-optimization in autonomous groups of mobile robots. The scenario is highly dynamic and easily expandable. It offers adequate starting points for the integration of hierarchical self-optimization. Reinforcement learning, e. g., can be introduced in order to improve the individual behavior of a single robot. Also swarm intelligence algorithms can improve the overall team behavior with respect to common goals. A reference behavior system incorporating a dynamic role assignment and hierarchical state machines was implemented and has been applied to the miniature robot BeBot. The system was evaluated by conducting several tests.",https://ieeexplore.ieee.org/document/6301137/,IEEE 10th International Conference on Industrial Informatics,25-27 July 2012,ieeexplore
10.1109/ICAR46387.2019.8981600,Towards the Usage of Synthetic Data for Marker-Less Pose Estimation of Articulated Robots in RGB Images,IEEE,Conferences,"Pose estimation is a necessity for many applications in robotics incorporating interaction between the robot and external camera-equipped devices, e.g. mobile robots or Augmented Reality devices. In the practice of monocular cameras, one mostly takes advantage of pose estimation through fiducial marker detection. We propose a novel approach for marker-less robot pose estimation through monocular cameras utilizing 2D keypoint detection and 3D keypoint determination through readings from the encoders and forward kinematics. In particular, 2D-3D point correspondences enable the pose estimation through solving the Perspective-n-Point problem for calibrated cameras. The method does not rely on any depth data or initializations. The robust 2D keypoint detection is implemented by modern Convolutional Neural Networks trained on different dataset configurations of real and synthetic data in order to quantitatively evaluate robustness, precision and data efficiency. We demonstrate that the method provides robust pose estimation for random joint poses and benchmark the performance of different (synthetic) dataset configurations. Furthermore, we compare the accuracies to marker pose estimation and give an outlook towards enhancements and realtime capability.",https://ieeexplore.ieee.org/document/8981600/,2019 19th International Conference on Advanced Robotics (ICAR),2-6 Dec. 2019,ieeexplore
10.1109/HRI.2019.8673298,Using Decision Support Systems for Juries in Court: Comparing the Use of Real and CG Robots,IEEE,Conferences,"In this report, we investigate the factor of social presence of a robot by using an actual robot and comparing it with a CG robot studied in our previous study. A laboratory experiment is conducted using a simple jury decision-making task, where participants play the role of a jury and make decisions regarding the length of the sentence for a particular crime. During the task, a robot with expert knowledge provides suggestions regarding the length of the sentence based on other similar cases. Results show that participants who engaged with an actual robot showed higher conformity with the suggested length of a sentence compared to the participants who engaged with a CG robot presented through a computer monitor. This study shows results that are consistent with those of previous studies in that interacting with physically aware robots is more engaging and also shows its effects on decision-making in a court.",https://ieeexplore.ieee.org/document/8673298/,2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI),11-14 March 2019,ieeexplore
10.1109/iFUZZY50310.2020.9297367,Using Interval Type-2 Recurrent Fuzzy Cerebellar Model Articulation Controller Based on Improved Differential Evolution for Cooperative Carrying Controller of Mobile Robots,IEEE,Conferences,"Mobile robot is widely utilized in various fields such as navigation control, obstacle avoidance and object carrying. For keeping away from obstacles to avoid collision and preventing object carrying from dropping down, we propose a state manager (SM) designed to assist the mobile robots so that they can switch operation between wall-following carrying (WFC) and toward goal carrying (TGC) by different external condition. In this controlling model, interval type-2 recurrent fuzzy cerebellar model articulation controller (IT2RFCMAC), embedded with a modified evolutionary optimization and dynamic grouping differential evolution (DGDE), is implemented for WFC and TGC. By adopting reinforcement learning strategy, mobile robots equip with adaptively wall-following control to make cooperative carrying control in real.",https://ieeexplore.ieee.org/document/9297367/,2020 International Conference on Fuzzy Theory and Its Applications (iFUZZY),4-7 Nov. 2020,ieeexplore
10.1109/IROS45743.2020.9341569,Velocity Regulation of 3D Bipedal Walking Robots with Uncertain Dynamics Through Adaptive Neural Network Controller,IEEE,Conferences,"This paper presents a neural-network based adaptive feedback control structure to regulate the velocity of 3D bipedal robots under dynamics uncertainties. Existing Hybrid Zero Dynamics (HZD)-based controllers regulate velocity through the implementation of heuristic regulators that do not consider model and environmental uncertainties, which may significantly affect the tracking performance of the controllers. In this paper, we address the uncertainties in the robot dynamics from the perspective of the reduced dimensional representation of virtual constraints and propose the integration of an adaptive neural network-based controller to regulate the robot velocity in the presence of model parameter uncertainties. The proposed approach yields improved tracking performance under dynamics uncertainties. The shallow adaptive neural network used in this paper does not require training a priori and has the potential to be implemented on the real-time robotic controller. A comparative simulation study of a 3D Cassie robot is presented to illustrate the performance of the proposed approach under various scenarios.",https://ieeexplore.ieee.org/document/9341569/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/IROS45743.2020.9341344,Virtual Reality for Robots,IEEE,Conferences,"This paper applies the principles of Virtual Reality (VR) to robots, rather than living organisms. A simulator, of either physical states or information states, renders outputs to custom displays that fool the robot's sensors. This enables a robot to experience a combination of real and virtual sensor inputs, combining the efficiency of simulation and the benefits of real world sensor inputs. Thus, the robot can be taken through targeted experiences that are more realistic than pure simulation, yet more feasible and controllable than pure real-world experiences. We define two distinctive methods for applying VR to robots, namely black box and white box; based on these methods we identify potential applications, such as testing and verification procedures that are better than simulation, the study of spoofing attacks and anti-spoofing techniques, and sample generation for machine learning. A general mathematical framework is presented, along with a simple experiment, detailed examples, and discussion of the implications.",https://ieeexplore.ieee.org/document/9341344/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/SMICND.2005.1558827,Virtual environment for robots interfaces design and testing,IEEE,Conferences,"This paper refers to the implementation of a virtual environment for the robot interfaces testing. This software environment is very useful because, comparing to the experiments with real robots, it allow the testing and evaluation of different types of interfaces and different working environments with diverse configurations. A very important facility of this interactive software environment is the fact that the designers of the robots sensors and interfaces are able to work in parallel to design test, optimize and realize different control devices for the robot",https://ieeexplore.ieee.org/document/1558827/,"CAS 2005 Proceedings. 2005 International Semiconductor Conference, 2005.",3-5 Oct. 2005,ieeexplore
10.1109/ICGEC.2012.151,Vision-Based Coordinate Transformation with Back Propagation Neural Networks on Mobile Robots,IEEE,Conferences,"Target tracking is important for vision-based robots to implement tasks of grasping, assembling and avoiding obstacles. the purpose of a target tracking system is to identify a target and then to estimate the position of the target. the targets' positions are usually described by various coordinate systems for different purposes. This study focuses on the problem of coordinate transformation on mobile robots and employs the techniques of Back-Propagation Neural Networks to discover the prediction models. with such prediction models, coordinate transformation can be done with less processing time. the techniques have been implemented and integrated with a four-wheeled vision-based security robot and has been verified in real environments. the experimental results show that the proposed method is able to produce simple and precise transformation models and improves the robot's performances.",https://ieeexplore.ieee.org/document/6456866/,2012 Sixth International Conference on Genetic and Evolutionary Computing,25-28 Aug. 2012,ieeexplore
10.1109/CDS49703.2020.00012,Welding Seam Recognition Robots Based on Edge Computing,IEEE,Conferences,"In order to meet the requirements of the accuracy and real-time performance during the working process of underwater welding robots, a scheme of welding seam recognition robots system based on the edge computing is proposed in this paper. A number of pre-processing methods for capturing welding seam image were designed, including Thresholding, Filtering and Edge Detect. A Convolutional Neural Network(CNN) model for welding seam recognition was also created. In the experiments, the image pre-processing and CNN algorithms were integrated in and deployed to the robots, and the learning and training algorithms of the CNN were deployed to the cloud servers. The image pre-processing methods filtered the interference in underwater operations and achieved the image compression and feature extraction. The cloud servers fulfilled the training and parameter optimization of the CNN, which improved the accuracy of welding seam image recognition.",https://ieeexplore.ieee.org/document/9275963/,2020 International Conference on Computing and Data Science (CDS),1-2 Aug. 2020,ieeexplore
10.1109/ACCESS.2018.2851841,A Brain-Inspired Multi-Modal Perceptual System for Social Robots: An Experimental Realization,IEEE,Journals,"We propose a multi-modal perceptual system that is inspired by the inner working of the human brain; in particular, the hierarchical structure of the sensory cortex and the spatial-temporal binding criteria. The system is context independent and can be applied to many on-going problems in social robotics, including but not limited to person recognition, emotion recognition, and multi-modal robot doctor to name a few. The system encapsulates the parallel distributed processing of real-world stimuli through different sensor modalities and encoding them into features vectors which in turn are processed via a number of dedicated processing units (DPUs) through hierarchical paths. DPUs are algorithmic realizations of the cell assemblies in neuroscience. A plausible and realistic perceptual system is presented via the integration of the outputs from these units by spiking neural networks. We will also discuss other components of the system including top-down influences and the integration of information through temporal binding with fading memory and suggest two alternatives to realize these criteria. Finally, we will demonstrate the implementation of this architecture on a hardware platform as a social robot and report experimental studies on the system.",https://ieeexplore.ieee.org/document/8400512/,IEEE Access,2018,ieeexplore
10.1109/TCDS.2020.2968056,A Framework of Hybrid Force/Motion Skills Learning for Robots,IEEE,Journals,"Human factors and human-centered design philosophy are highly desired in today's robotics applications such as human-robot interaction (HRI). Several studies showed that endowing robots of human-like interaction skills can not only make them more likeable but also improve their performance. In particular, skill transfer by imitation learning can increase the usability and acceptability of robots by users without computer programming skills. In fact, besides positional information, muscle stiffness of the human arm and contact force with the environment also play important roles in understanding and generating human-like manipulation behaviors for robots, e.g., in physical HRI and teleoperation. To this end, we present a novel robot learning framework based on dynamic movement primitives (DMPs), taking into consideration both the positional and contact force profiles for human-robot skills transferring. Distinguished from the conventional method involving only the motion information, the proposed framework combines two sets of DMPs, which are built to model the motion trajectory and the force variation of the robot manipulator, respectively. Thus, a hybrid force/motion control approach is taken to ensure the accurate tracking and reproduction of the desired positional and force motor skills. Meanwhile, in order to simplify the control system, a momentum-based force observer is applied to estimate the contact force instead of employing force sensors. To deploy the learned motion-force robot manipulation skills to a broader variety of tasks, the generalization of these DMP models in actual situations is also considered. Comparative experiments have been conducted using a Baxter robot to verify the effectiveness of the proposed learning framework on real-world scenarios like cleaning a table.",https://ieeexplore.ieee.org/document/8964480/,IEEE Transactions on Cognitive and Developmental Systems,March 2021,ieeexplore
10.1109/ACCESS.2020.3003991,A Software Architecture for Service Robots Manipulating Objects in Human Environments,IEEE,Journals,"This paper presents a software architecture for robots providing manipulation services autonomously in human environments. In an unstructured human environment, a service robot often needs to perform tasks even without human intervention and prior knowledge about tasks and environments. For autonomous execution of tasks, varied processes are necessary such as perceiving environments, representing knowledge, reasoning with the knowledge, and planning for task and motion. While developing each of the processes is important, integrating them into a working system for deployment is also important as a robotic system can bring tangible outcomes when it works in real world. However, such an architecture has been rarely realized in the literature owing to the difficulties of a full integration, deployment, understanding high-level goals without human interventions. In this work, we suggest a software architecture that integrates the components necessary to perform tasks by a real robot without human intervention. We show our architecture composed of deep learning based perception, symbolic reasoning, AI task planning, and geometric motion planning. We implement a deep neural network that produces information about the environment, which are then stored in a knowledge base. We implement a reasoner that processes the knowledge to use the result for task planning. We show our implementation of the symbolic task planner that generates a sequence of motion predicates. We implement an interface that computes geometric information necessary for motion planning to execute the symbolic task plans. We describe the deployment of the architecture through the result of lab tests and a public demonstration. The architecture is developed based on Robot Operating System (ROS) so compatible with any robot that is capable of object manipulation and mobile navigation running in ROS. We deploy the architecture to two different robot platforms to show the compatibility.",https://ieeexplore.ieee.org/document/9122008/,IEEE Access,2020,ieeexplore
10.1109/TSMC.2019.2912715,A Visual Leader-Following Approach With a T-D-R Framework for Quadruped Robots,IEEE,Journals,"The quadruped robot imitates the motions of four-legged animals with a superior flexibility and adaptability to complex terrains, compared with the wheeled and tracked robots. Its leader-following ability is unique to help a human to accomplish complex tasks in a more convenient way. However, long-term following is severely obstructed due to the high-frequency vibration of the quadruped robot and the unevenness of terrains. To solve this problem, a visual approach under a novel T-D-R framework is proposed. The proposed T-D-R framework is composed of a visual tracker based on correlation filter, a person detector with deep learning, and a person re-identification (re-ID) module. The result of the tracker is verified by the detector to improve tracking performance. Especially, the re-ID module is introduced to handle distractions and occlusion caused by other persons, where the convolutional correlation filter (CCF) is employed to discriminate the leader among multiple persons through recording the appearance information in the long run. By comparing the results of the tracker and the detector as well as their similarity scores with the leader identified by the re-ID module, a stable and real-time tracking of the leader can be guaranteed. Experiments reveal that our approach is effective in handling distractions, appearance changes, and illumination variations. A long-distance experiment on a quadruped robot indicates the validity of the proposed approach.",https://ieeexplore.ieee.org/document/8709995/,"IEEE Transactions on Systems, Man, and Cybernetics: Systems",April 2021,ieeexplore
10.1109/JIOT.2020.3004339,AirScope: Mobile Robots-Assisted Cooperative Indoor Air Quality Sensing by Distributed Deep Reinforcement Learning,IEEE,Journals,"Indoor air pollution has become a growing health risk, but it is challenging to provide low-cost air quality monitoring for the indoor environment. In this article, we present “AirScope,” a mobile sensing system that employs cooperative robots to monitor the indoor air quality. Since the wireless coverage can be incomplete in some indoor areas, AirScope allows the robots to defer uploading the data to the central server by utilizing their own data buffers. In order to guarantee the timeliness of the data in the server, AirScope aims to minimize the average data latency by properly planning the routes of the robots. Such a route planning strategy has to be implemented in a distributed way since the robots that are out of wireless coverage can only make plans on their own. In addition, the cooperation of the robots is also necessary because the aggregation of the robots in a small area increases the average data latency of the other unattended areas. To solve this distributed and cooperative routing planning problem, we propose a solution based on distributed deep Q-learning (DDQL). We evaluate the system performance by simulations and real-world experiments. The results show that AirScope is effective to reduce data latency, where the proposed DDQL is 8% better than the greedy algorithm and 24% better than the random strategy.",https://ieeexplore.ieee.org/document/9123492/,IEEE Internet of Things Journal,Sept. 2020,ieeexplore
10.1109/TFUZZ.2004.832532,Automatic design of fuzzy controllers for car-like autonomous robots,IEEE,Journals,"This paper describes the design and implementation of a fuzzy control system for a car-like autonomous vehicle. The problem addressed is the diagonal parking in a constrained space, a typical problem in motion control of nonholonomic robots. The architecture proposed for the fuzzy controller is a hierarchical scheme which combines seven modules working in series and in parallel. The rules of each module employ the adequate fuzzy operators for its task (making a decision or generating a smoothly varying control output), and they have been obtained from heuristic knowledge and numerical data (with geometric information) depending on the module requirements (some of them are constrained to provide paths of near-minimal lengths). The computer-aided design tools of the environment Xfuzzy 3.0 (developed by some of the authors) have been employed to automate the different design stages: 1) translation of heuristic knowledge into fuzzy rules; 2) extraction of fuzzy rules from numerical data and their tuning to give paths of near-minimal lengths; 3) offline verification of the control system behavior; and 4) its synthesis to be implemented in a true robot and be verified on line. Real experiments with the autonomous vehicle ROMEO 4R (designed and built at the Escuela Superior de Ingenieros, University of Seville, Seville, Spain) demonstrate the efficiency of the described controller and of the methodology followed in its design.",https://ieeexplore.ieee.org/document/1321074/,IEEE Transactions on Fuzzy Systems,Aug. 2004,ieeexplore
10.1109/TSMCB.2004.843270,Autonomous stair-climbing with miniature jumping robots,IEEE,Journals,"The problem of vision-guided control of miniature mobile robots is investigated. Untethered mobile robots with small physical dimensions of around 10 cm or less do not permit powerful onboard computers because of size and power constraints. These challenges have, in the past, reduced the functionality of such devices to that of a complex remote control vehicle with fancy sensors. With the help of a computationally more powerful entity such as a larger companion robot, the control loop can be closed. Using the miniature robot's video transmission or that of an observer to localize it in the world, control commands can be computed and relayed to the inept robot. The result is a system that exhibits autonomous capabilities. The framework presented here solves the problem of climbing stairs with the miniature Scout robot. The robot's unique locomotion mode, the jump, is employed to hop one step at a time. Methods for externally tracking the Scout are developed. A large number of real-world experiments are conducted and the results discussed.",https://ieeexplore.ieee.org/document/1408060/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",April 2005,ieeexplore
10.1109/ACCESS.2020.3016893,Coping With Multiple Visual Motion Cues Under Extremely Constrained Computation Power of Micro Autonomous Robots,IEEE,Journals,"The perception of different visual motion cues is crucial for autonomous mobile robots to react to or interact with the dynamic visual world. It is still a great challenge for a micro mobile robot to cope with dynamic environments due to the restricted computational resources and the limited functionalities of its visual systems. In this study, we propose a compound visual neural system to automatically extract and fuse different visual motion cues in real-time using the extremely constrained computation power of micro mobile robots. The proposed visual system contains multiple bio-inspired visual motion perceptive neurons each with a unique role, for example to extract collision visual cues, darker collision cue and directional motion cues. In the embedded system, these multiple visual neurons share a similar presynaptic network to minimise the consumption of computation resources. In the postsynaptic part of the system, visual cues pass results to corresponding action neurons using lateral inhibition mechanism. The translational motion cues, which are identified by comparing pairs of directional cues, are given the highest priority, followed by the darker colliding cues and approaching cues. Systematic experiments with both virtual visual stimuli and real-world scenarios have been carried out to validate the system's functionality and reliability. The proposed methods have demonstrated that (1) with extremely limited computation power, it is still possible for a micro mobile robot to extract multiple visual motion cues robustly in a complex dynamic environment; (2) the cues extracted can be fused with a lateral inhibited postsynaptic network, thus enabling the micro robots to respond effectively with different actions, accordingly to different states, in real-time. The proposed embedded visual system has been modularised and can be easily implemented in other autonomous mobile platforms for real-time applications. The system could also be used by neurophysiologists to test new hypotheses pertaining to biological visual neural systems.",https://ieeexplore.ieee.org/document/9167216/,IEEE Access,2020,ieeexplore
10.1109/56.802,Dynamic multi-sensor data fusion system for intelligent robots,IEEE,Journals,"The objective of the authors is to develop an intelligent robot workstation capable of integrating data from multiple sensors. The investigation is based on a Unimation PUMA 560 robot and various external sensors. These include overhead vision, eye-in-hand vision, proximity, tactile array, position, force/torque, cross-fire, overload, and slip-sensing devices. The efficient fusion of data from different sources will enable the machine to respond promptly in dealing with the 'real world'. Towards this goal, the general paradigm of a sensor data fusion system has been developed, and some simulation results, as well as results from the actual implementation of certain concepts of sensor data fusion, have been demonstrated.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/802/,IEEE Journal on Robotics and Automation,Aug. 1988,ieeexplore
10.1109/TRO.2019.2929015,Fault Detection in a Swarm of Physical Robots Based on Behavioral Outlier Detection,IEEE,Journals,"The ability to reliably detect faults is essential in many real-world tasks that robot swarms have the potential to perform. Most studies on fault detection in swarm robotics have been conducted exclusively in simulation, and they have focused on a single type of fault or a specific task. In a series of previous studies, we have developed a robust fault-detection approach in which robots in a swarm learn to distinguish between normal and faulty behaviors online. In this paper, we assess the performance of our fault-detection approach on a swarm of seven physical mobile robots. We experiment with three classic swarm robotics tasks and consider several types of faults in both sensors and actuators. Experimental results show that the robots are able to reliably detect the presence of hardware faults in one another even when the swarm behavior is changed during operation. This paper is thus an important step toward making robot swarms sufficiently reliable and dependable for real-world applications.",https://ieeexplore.ieee.org/document/8787875/,IEEE Transactions on Robotics,Dec. 2019,ieeexplore
10.1109/TCST.2017.2756962,Full-State Tracking Control for Flexible Joint Robots With Singular Perturbation Techniques,IEEE,Journals,"This paper proposes a practical method to realize multivariable full-state tracking control for industrial robots with elastic joints. Unlike existing methods, the proposed method does not require high-order derivatives of the link states such as acceleration and jerk. Therefore, the proposed method does not suffer from chatter related to inaccurate estimation of high-order derivatives. The method is derived by adopting a singular perturbation technique. A decoupled error dynamics is achieved by two decoupling control loops: a fast loop that controls the deflection error and a slow loop for tracking control on the link side. Our stability analysis based on a linear system shows that the proposed control system is stable as long as the fast system is at least twice as fast as the slow system. A practical method to select the gain is also presented such that the closed-loop poles are placed at the desired locations. In simulation, we compare the proposed method with feedback linearization. The results indicate that in an ideal scenario the proposed method can obtain a similar performance as feedback linearization. However, the proposed method obtains a superior performance in a realistic scenario. A real-world experiment with a six degree-of-freedom commercial industrial robot is carried out to further validate our approach.",https://ieeexplore.ieee.org/document/8065027/,IEEE Transactions on Control Systems Technology,Jan. 2019,ieeexplore
10.1109/ACCESS.2019.2949835,Hybrid Path Planning Algorithm Based on Membrane Pseudo-Bacterial Potential Field for Autonomous Mobile Robots,IEEE,Journals,"A hybrid path planning algorithm based on membrane pseudo-bacterial potential field (MemPBPF) is proposed. Membrane-inspired algorithms can reach an evolutionary behavior based on biochemical processes to find the best parameters for generating a feasible and safe path. The proposed MemPBPF algorithm uses a combination of the structure and rules of membrane computing. In that sense, the proposed MemPBPF algorithm contains dynamic membranes that include a pseudo-bacterial genetic algorithm for evolving the required parameters in the artificial potential field method. This hybridization between membrane computing, the pseudo-bacterial genetic algorithm, and the artificial potential field method provides an outperforming path planning algorithm for autonomous mobile robots. Computer simulation results demonstrate the effectiveness of the proposed MemPBPF algorithm in terms of path length considering collision avoidance and smoothness. Comparisons with two different versions employing a different number of elementary membranes and with other artificial potential field based algorithms are presented. The proposed MemPBPF algorithm yields improved performance in terms of time execution by using a parallel implementation on a multi-core computer. Therefore, the MemPBPF algorithm achieves high performance yielding competitive results for autonomous mobile robot navigation in complex and real scenarios.",https://ieeexplore.ieee.org/document/8884165/,IEEE Access,2019,ieeexplore
10.1109/TSMCC.2007.897491,Integration of Coordination Architecture and Behavior Fuzzy Learning in Quadruped Walking Robots,IEEE,Journals,"This paper presents the design and implementation of a coordination architecture for quadruped walking robots to learn and execute soccer-playing behaviors. A typical hybrid architecture combing reactive behaviors with deliberative reasoning is developed. The reactive behaviors directly map spatial information extracted from sensors into actions. The deliberative reasoning represents temporal constraints of a robot's strategy in terms of finite state machines. In order to achieve real-time and robust control performance in reactive behaviors, fuzzy logic controllers (FLCs) are used to encode the behaviors, and a two-stage learning scheme is adopted to make these FLCs adaptive to complex situations. The experimental results are provided to show the suitability of the architecture and effectiveness of the proposed learning scheme.",https://ieeexplore.ieee.org/document/4252246/,"IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)",July 2007,ieeexplore
10.1109/TSMCA.2009.2033029,Interactive Teaching for Vision-Based Mobile Robots: A Sensory-Motor Approach,IEEE,Journals,"For the last decade, we have been developing a vision-based architecture for mobile robot navigation. Using our bio-inspired model of navigation, robots can perform sensory-motor tasks in real time in unknown indoor as well as outdoor environments. We address here the problem of autonomous incremental learning of a sensory-motor task, demonstrated by an operator guiding a robot. The proposed system allows for semisupervision of task learning and is able to adapt the environmental partitioning to the complexity of the desired behavior. A real dialogue based on actions emerges from the interactive teaching. The interaction leads the robot to autonomously build a precise sensory-motor dynamics that approximates the behavior of the teacher. The usability of the system is highlighted by experiments on real robots, in both indoor and outdoor environments. Accuracy measures are also proposed in order to evaluate the learned behavior as compared to the expected behavioral attractor. These measures, used first in a real experiment and then in a simulated experiment, demonstrate how a real interaction between the teacher and the robot influences the learning process.",https://ieeexplore.ieee.org/document/5345874/,"IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans",Jan. 2010,ieeexplore
10.1109/LRA.2020.3010739,Learning Force Control for Contact-Rich Manipulation Tasks With Rigid Position-Controlled Robots,IEEE,Journals,"Reinforcement Learning (RL) methods have been proven successful in solving manipulation tasks autonomously. However, RL is still not widely adopted on real robotic systems because working with real hardware entails additional challenges, especially when using rigid position-controlled manipulators. These challenges include the need for a robust controller to avoid undesired behavior, that risk damaging the robot and its environment, and constant supervision from a human operator. The main contributions of this work are, first, we proposed a learning-based force control framework combining RL techniques with traditional force control. Within said control scheme, we implemented two different conventional approaches to achieve force control with position-controlled robots; one is a modified parallel position/force control, and the other is an admittance control. Secondly, we empirically study both control schemes when used as the action space of the RL agent. Thirdly, we developed a fail-safe mechanism for safely training an RL agent on manipulation tasks using a real rigid robot manipulator. The proposed methods are validated both on simulation and a real robot with an UR3 e-series robotic arm.",https://ieeexplore.ieee.org/document/9145608/,IEEE Robotics and Automation Letters,Oct. 2020,ieeexplore
10.1109/41.704895,Modeling of ultrasonic range sensors for localization of autonomous mobile robots,IEEE,Journals,"This paper presents a probabilistic model of ultrasonic range sensors using backpropagation neural networks trained on experimental data. The sensor model provides the probability of detecting mapped obstacles in the environment, given their position and orientation relative to the transducer. The detection probability can be used to compute the location of an autonomous vehicle from those obstacles that are more likely to be detected. The neural network model is more accurate than other existing approaches, since it captures the typical multilobal detection pattern of ultrasonic transducers. Since the network size is kept small, implementation of the model on a mobile robot can be efficient for real-time navigation. An example that demonstrates how the credence could be incorporated into the extended Kalman filter (EKF) and the numerical values of the final neural network weights are provided in the appendices.",https://ieeexplore.ieee.org/document/704895/,IEEE Transactions on Industrial Electronics,Aug. 1998,ieeexplore
10.1109/TAMD.2010.2086453,Multilevel Darwinist Brain (MDB): Artificial Evolution in a Cognitive Architecture for Real Robots,IEEE,Journals,"The multilevel Darwinist brain (MDB) is a cognitive architecture that follows an evolutionary approach to provide autonomous robots with lifelong adaptation. It has been tested in real robot on-line learning scenarios obtaining successful results that reinforce the evolutionary principles that constitute the main original contribution of the MDB. This preliminary work has lead to a series of improvements in the computational implementation of the architecture so as to achieve realistic operation in real time, which was the biggest problem of the approach due to the high computational cost induced by the evolutionary algorithms that make up the MDB core. The current implementation of the architecture is able to provide an autonomous robot with real time learning capabilities and the capability for continuously adapting to changing circumstances in its world, both internal and external, with minimal intervention of the designer. This paper aims at providing an overview or the architecture and its operation and defining what is required in the path towards a real cognitive robot following a developmental strategy. The design, implementation and basic operation of the MDB cognitive architecture are presented through some successful real robot learning examples to illustrate the validity of this evolutionary approach.",https://ieeexplore.ieee.org/document/5599851/,IEEE Transactions on Autonomous Mental Development,Dec. 2010,ieeexplore
10.1109/JPROC.2019.2898267,"On Proactive, Transparent, and Verifiable Ethical Reasoning for Robots",IEEE,Journals,"Previous work on ethical machine reasoning has largely been theoretical, and where such systems have been implemented, it has, in general, been only initial proofs of principle. Here, we address the question of desirable attributes for such systems to improve their real world utility, and how controllers with these attributes might be implemented. We propose that ethically critical machine reasoning should be proactive, transparent, and verifiable. We describe an architecture where the ethical reasoning is handled by a separate layer, augmenting a typical layered control architecture, ethically moderating the robot actions. It makes use of a simulation-based internal model and supports proactive, transparent, and verifiable ethical reasoning. To do so, the reasoning component of the ethical layer uses our Python-based belief-desire-intention (BDI) implementation. The declarative logic structure of BDI facilitates both transparency, through logging of the reasoning cycle, and formal verification methods. To prove the principles of our approach, we use a case study implementation to experimentally demonstrate its operation. Importantly, it is the first such robot controller where the ethical machine reasoning has been formally verified.",https://ieeexplore.ieee.org/document/8648363/,Proceedings of the IEEE,March 2019,ieeexplore
10.1109/TSMCB.2012.2192107,Robust Multiperson Detection and Tracking for Mobile Service and Social Robots,IEEE,Journals,"This paper proposes an efficient system which integrates multiple vision models for robust multiperson detection and tracking for mobile service and social robots in public environments. The core technique is a novel maximum likelihood (ML)-based algorithm which combines the multimodel detections in mean-shift tracking. First, a likelihood probability which integrates detections and similarity to local appearance is defined. Then, an expectation-maximization (EM)-like mean-shift algorithm is derived under the ML framework. In each iteration, the E-step estimates the associations to the detections, and the M-step locates the new position according to the ML criterion. To be robust to the complex crowded scenarios for multiperson tracking, an improved sequential strategy to perform the mean-shift tracking is proposed. Under this strategy, human objects are tracked sequentially according to their priority order. To balance the efficiency and robustness for real-time performance, at each stage, the first two objects from the list of the priority order are tested, and the one with the higher score is selected. The proposed method has been successfully implemented on real-world service and social robots. The vision system integrates stereo-based and histograms-of-oriented-gradients-based human detections, occlusion reasoning, and sequential mean-shift tracking. Various examples to show the advantages and robustness of the proposed system for multiperson tracking from mobile robots are presented. Quantitative evaluations on the performance of multiperson tracking are also performed. Experimental results indicate that significant improvements have been achieved by using the proposed method.",https://ieeexplore.ieee.org/document/6187748/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",Oct. 2012,ieeexplore
10.1109/TCST.2019.2914634,Robust Regressor-Free Control of Rigid Robots Using Function Approximations,IEEE,Journals,"This paper develops a novel regressor-free robust controller for rigid robots whose dynamics can be described using the Euler-Lagrange equations of motion. The function approximation technique (FAT) is used to represent the robot's inertia matrix, the Coriolis matrix, and the gravity vector as finite linear combinations of orthonormal basis functions. The proposed controller establishes a robust FAT control framework that uses a fixed control structure. The control objectives are to track reference trajectories in worst case scenarios where the robot dynamics are too costly to develop or otherwise unavailable. Detailed stability analysis via Lyapunov functions, the passivity property, and continuous switching laws shows uniform ultimate boundedness of the closed-loop dynamics. The simulation results of a three-degree-of-freedom (DOF) robot when the robot parameters are perturbed from their nominal values show good robustness of the proposed controller when compared with some well-established control methods. We also demonstrate success in the real-time experimental implementation of the proposed controller, which validates practicality for real-world robotic applications.",https://ieeexplore.ieee.org/document/8718993/,IEEE Transactions on Control Systems Technology,July 2020,ieeexplore
10.1109/70.88137,The vector field histogram-fast obstacle avoidance for mobile robots,IEEE,Journals,"A real-time obstacle avoidance method for mobile robots which has been developed and implemented is described. This method, named the vector field histogram (VFH), permits the detection of unknown obstacles and avoids collisions while simultaneously steering the mobile robot toward the target. The VFH method uses a two-dimensional Cartesian histogram grid as a world model. This world model is updated continuously with range data sampled by onboard range sensors. The VFH method subsequently uses a two-stage data-reduction process to compute the desired control commands for the vehicle. Experimental results from a mobile robot traversing densely cluttered obstacle courses in smooth and continuous motion and at an average speed of 0.6-0.7 m/s are shown. A comparison of the VFN method to earlier methods is given.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/88137/,IEEE Transactions on Robotics and Automation,June 1991,ieeexplore
10.1109/LRA.2019.2894216,VR-Goggles for Robots: Real-to-Sim Domain Adaptation for Visual Control,IEEE,Journals,"In this letter, we deal with the reality gap from a novel perspective, targeting transferring deep reinforcement learning (DRL) policies learned in simulated environments to the real-world domain for visual control tasks. Instead of adopting the common solutions to the problem by increasing the visual fidelity of synthetic images output from simulators during the training phase, we seek to tackle the problem by translating the real-world image streams back to the synthetic domain during the deployment phase, to make the robot feel at home. We propose this as a lightweight, flexible, and efficient solution for visual control, as first, no extra transfer steps are required during the expensive training of DRL agents in simulation; second, the trained DRL agents will not be constrained to being deployable in only one specific real-world environment; and third, the policy training and the transfer operations are decoupled, and can be conducted in parallel. Besides this, we propose a simple yet effective shift loss that is agnostic to the downstream task, to constrain the consistency between subsequent frames which is important for consistent policy outputs. We validate the shift loss for artistic style transfer for videos and domain adaptation, and validate our visual control approach in indoor and outdoor robotics experiments.",https://ieeexplore.ieee.org/document/8620258/,IEEE Robotics and Automation Letters,April 2019,ieeexplore
10.1109/LRA.2018.2851148,Visual Navigation for Biped Humanoid Robots Using Deep Reinforcement Learning,IEEE,Journals,"In this letter, we propose a map-less visual navigation system for biped humanoid robots, which extracts information from color images to derive motion commands using deep reinforcement learning (DRL). The map-less visual navigation policy is trained using the Deep Deterministic Policy Gradients (DDPG) algorithm, which corresponds to an actor-critic DRL algorithm. The algorithm is implemented using two separate networks, one for the actor and one for the critic, but with similar structures. In addition to convolutional and fully connected layers, Long Short-Term Memory (LSTM) layers are included to address the limited observability present in the problem. As a proof of concept, we consider the case of robotic soccer using humanoid NAO V5 robots, which have reduced computational capabilities, and low-cost Red - Green - Blue (RGB) cameras as main sensors. The use of DRL allowed to obtain a complex and high performant policy from scratch, without any prior knowledge of the domain, or the dynamics involved. The visual navigation policy is trained in a robotic simulator and then successfully transferred to a physical robot, where it is able to run in 20 ms, allowing its use in real-time applications.",https://ieeexplore.ieee.org/document/8398461/,IEEE Robotics and Automation Letters,Oct. 2018,ieeexplore
10.1109/IJCNN48605.2020.9207496,"""I’m Sorry Dave, I’m Afraid I Can’t Do That"" Deep Q-Learning from Forbidden Actions",IEEE,Conferences,"The use of Reinforcement Learning (RL) is still restricted to simulation or to enhance human-operated systems through recommendations. Real-world environments (e.g. industrial robots or power grids) are generally designed with safety constraints in mind implemented in the shape of valid actions masks or contingency controllers. For example, the range of motion and the angles of the motors of a robot can be limited to physical boundaries. Violating constraints thus results in rejected actions or entering in a safe mode driven by an external controller, making RL agents incapable of learning from their mistakes. In this paper, we propose a simple modification of a state-of-the-art deep RL algorithm (DQN), enabling learning from forbidden actions. To do so, the standard Q-learning update is enhanced with an extra safety loss inspired by structured classification. We empirically show that it reduces the number of hit constraints during the learning phase and accelerates convergence to near-optimal policies compared to using standard DQN. Experiments are done on a Visual Grid World Environment and the TextWorld domain.",https://ieeexplore.ieee.org/document/9207496/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/WCICA.2016.7578819,3D vision based fast badminton localization with prediction and error elimination for badminton robot,IEEE,Conferences,"In this paper, the problem of fast badminton localization problem is investigated for a class of badminton robots. More precisely, a manifold-learning based localization method is implemented for the improvement of hitting accuracy and effectiveness. Based on the localization results, a novel badminton trajectory prediction algorithm is designed based on 3D Vision in the real world. Furthermore, clock-synchronization combined with motion compensation methods are also proposed to better localization error elimination. In the end, the validity and usefulness of our proposed algorithm is demonstrated by numerical experiments.",https://ieeexplore.ieee.org/document/7578819/,2016 12th World Congress on Intelligent Control and Automation (WCICA),12-15 June 2016,ieeexplore
10.1109/ICRA.2018.8461228,3DOF Pedestrian Trajectory Prediction Learned from Long-Term Autonomous Mobile Robot Deployment Data,IEEE,Conferences,"This paper presents a novel 3DOF pedestrian trajectory prediction approach for autonomous mobile service robots. While most previously reported methods are based on learning of 2D positions in monocular camera images, our approach uses range-finder sensors to learn and predict 3DOF pose trajectories (i.e. 2D position plus 1D rotation within the world coordinate system). Our approach, T-Pose-LSTM (Temporal 3DOF-Pose Long-Short-Term Memory), is trained using long-term data from real-world robot deployments and aims to learn context-dependent (environment- and time-specific) human activities. Our approach incorporates long-term temporal information (i.e. date and time) with short-term pose observations as input. A sequence-to-sequence LSTM encoder-decoder is trained, which encodes observations into LSTM and then decodes the resulting predictions. On deployment, the approach can perform on-the-fly prediction in real-time. Instead of using manually annotated data, we rely on a robust human detection, tracking and SLAM system, providing us with examples in a global coordinate system. We validate the approach using more than 15 km of pedestrian trajectories recorded in a care home environment over a period of three months. The experiments show that the proposed T-Pose-LSTM model outperforms the state-of-the-art 2D-based method for human trajectory prediction in long-term mobile robot deployments.",https://ieeexplore.ieee.org/document/8461228/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/ISSCC.2009.4977352,A 201.4GOPS 496mW real-time multi-object recognition processor with bio-inspired neural perception engine,IEEE,Conferences,"The visual attention mechanism, which is the way humans perform object recognition, was applied to the implementation of a high performance object recognition chip. Even though the previous chip achieved 50% gain of computational cost, it could recognize only one object in a frame so that it is not suitable for advanced multi-object recognition applications such as video surveillance, intelligent robots, and autonomous vehicle",https://ieeexplore.ieee.org/document/4977352/,2009 IEEE International Solid-State Circuits Conference - Digest of Technical Papers,8-12 Feb. 2009,ieeexplore
10.1109/ISCAS.2003.1205068,A CNN-based chip for robot locomotion control,IEEE,Conferences,"In this paper a VLSI chip for real-time locomotion control in legged robots is introduced. The control is based on the biological paradigm of Central Pattern Generator (CPG) and is implemented by a Cellular Neural Network (CNN). The gait generation is accomplished by the CNN and is fully analog, while a digital controller modulates the behavior of the CNN-based CPG to allow the locomotion system to adapt to sensory feedback. The chip is designed with a switched-capacitor technique, fundamental to address the speed control issue. Experimental results on the first prototype are illustrated. These results confirm the suitability of the approach and open the way to the design of a fully autonomous bio-inspired micro-robot.",https://ieeexplore.ieee.org/document/1205068/,"Proceedings of the 2003 International Symposium on Circuits and Systems, 2003. ISCAS '03.",25-28 May 2003,ieeexplore
10.1109/RTCSA.2018.00012,A Case Study of Cyber-Physical System Design: Autonomous Pick-and-Place Robot,IEEE,Conferences,"Although modern robots in warehousing systems can perform adequately in a goods-to-person model using hand-designed algorithms that are specialized to a particular environment, developing a robotic system that is capable of handling new products at an inexpensive cost remains a challenge. A conspicuous example of this challenge is seen in Amazon's use of autonomous robots to fetch customers' orders in their massive warehouses. To encourage advance in this technology, Amazon organized the competition, Amazon Picking Challenge that asked participants to develop their own hardware and software for the general task of picking a designated set of products from inventory shelves and then placing them at a target location (called a pick-and-place task). Current technology for pick-and-place tasks is still insufficient to meet the demand for low-cost automation. Handling awkward or oddly shaped object must still depend on hand-programming or specialized robotic systems, making manufacturing automation less flexible and expensive. In this paper, we shall present the design and implementation of a software system that is a step in advancing the technology toward full automation at reasonable costs. Our system integrates a set of state-of-the-art techniques in computer vision, deep-learning, trajectory optimization, visual servoing to create a library of skills that can be composed to perform a variety of robotic tasks. We demonstrate the capability of our system for performing autonomous pick-and-place tasks with an implementation using Hoppy, an industrial robotic arm in an environment similar to the Amazon Picking Challenge.",https://ieeexplore.ieee.org/document/8607230/,2018 IEEE 24th International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA),28-31 Aug. 2018,ieeexplore
10.1109/ACCC51160.2020.9347897,A Comparative Analysis of Kinematics of Industrial Robot KUKA KR 60–3 Using Scientific Computing Languages,IEEE,Conferences,"In the field of robotics, there are kinematic analysis methods that are responsible for describing the positions and orientations of the end effectors, as well as the angles, velocities and trajectories of industrial robots; such techniques are: forward kinematics, inverse kinematics and velocity kinematics. For the solutions of these complex mathematical calculations, the use of scientific computing languages or programs is required; which more and more algorithms, libraries and complements are implemented, that achieve a reduction in programming hours and result in the creation of better solutions in areas of all kinds. For this reason, the kinematics of the Industrial Robot KUKA KR 60-3 was programmed in the languages and programs most used in scientific computing, with the aim of comparing the performance (real time) when carrying out symbolic and numerical analysis in said studies.",https://ieeexplore.ieee.org/document/9347897/,2020 Asia Conference on Computers and Communications (ACCC),18-20 Sept. 2020,ieeexplore
10.1109/ICRITO51393.2021.9596550,A Comparative Study on Shortest Path Visualization using Artificial Intelligence,IEEE,Conferences,"In the modern computation system, that rely on various aspects to obtain the optimal results in easy manner appears more deterministic. There are several algorithms available that can distinguish a probable shortest path between two points, which helps students actively study algorithms with visualization. Therefore, in this study, we developed the GUI based shortest path finding tool consists of Dijkstra and A* algorithm. Further, in this study, the obtained shortest path results were graphically visualised and tabular output are stored in the database. The implementation of the algorithm and visualization was developed using Java AWT API and SWING package of Java. The Dijkstra and A* algorithm comparative analysis showed that the checks value and path length in terms of the A* algorithm is comparatively less than Dijkstra. Thus, it is affirmative that A * approach produces faster results and appeared as more efficient in terms of destination path finding than Dijkstra algorithm. Path finding is a fundamental feature of many significant applications and can be applied in static, interactive, and real-time situations. Such information shed light on the efficient application for computer gaming, robots, logistics, and crowd simulation.",https://ieeexplore.ieee.org/document/9596550/,"2021 9th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)",3-4 Sept. 2021,ieeexplore
10.1109/FDL53530.2021.9568376,A Container-based Design Methodology for Robotic Applications on Kubernetes Edge-Cloud architectures,IEEE,Conferences,"Programming modern Robots' missions and behavior has become a very challenging task. The always increasing level of autonomy of such platforms requires the integration of multi-domain software applications to implement artificial intelligence, cognition, and human-robot/robot-robot interaction applications. In addition, to satisfy both functional and nonfunctional requirements such as reliability and energy efficiency, robotic SW applications have to be properly developed to take advantage of heterogeneous (Edge-Fog-Cloud) architectures. In this context, containerization and orchestration are becoming a standard practice as they allow for better information flow among different network levels as well as increased modularity in the use of software components. Nevertheless, the adoption of such a practice along the design flow, from simulation to the deployment of complex robotic applications by addressing the de-facto development standards (i.e., robotic operating system - ROS - compliancy for robotic applications) is still an open problem. We present a design methodology based on Docker and Kubernetes that enables containerization and orchestration of ROS-based robotic SW applications for heterogeneous and hierarchical HW architectures. The design methodology allows for (i) integration and verification of multi-domain components since early in the design flow, (ii) task-to-container mapping techniques to guarantee minimum overhead in terms of performance and memory footprint, and (iii) multi-domain verification of functional and non-functional constraints before deployment. We present the results obtained in a real case of study, in which the design methodology has been applied to program the mission of a Robotnik RB-Kairos mobile robot in an industrial agile production chain. The source code of the mobile robot is publicly available on GitHub.",https://ieeexplore.ieee.org/document/9568376/,2021 Forum on specification & Design Languages (FDL),8-10 Sept. 2021,ieeexplore
10.1109/RCAR52367.2021.9517387,A Depthwise Separable Convolution Based 6D Pose Estimation Network by Efficient 2D-3D Feature Fusion,IEEE,Conferences,"Precise 6D pose estimation of the target object is an essential prerequisite for robots to understand the real world. Previous 6D pose estimation methods based on 3D data usually have problems such as long model training time, imperfect feature extraction, redundant network model parameters, and complicated follow-up processing steps. This paper proposes a 2D-3D feature fusion module that could enhance feature extraction for the 6D pose estimation network. Furthermore, we compress the size of model parameters by adopting depthwise separable convolution to accelerate training speed and to reduce memory consumption. The experiment results on LineMOD dataset show the effectiveness of our method. Our method achieves on par or better performance than the state-of-art methods for 6D pose estimation and reduces model training time and the number of model parameters simultaneously.",https://ieeexplore.ieee.org/document/9517387/,2021 IEEE International Conference on Real-time Computing and Robotics (RCAR),15-19 July 2021,ieeexplore
10.1109/CACRE50138.2020.9230347,A Distributed Reward Algorithm for Inverse Kinematics of Arm Robot,IEEE,Conferences,"Traditional methods of inverse kinematics of robots always adopt analytical approach and numerical approach to solve the continuous state and action problems with experience and experiment mostly, which require much time and work in reality work scene, especially for robots with complex structure. This paper proposes a method based on reinforcement learning TD3 network, which is constructed by PyTorch to find the inverse solution from another point of view. A set of improved distributed multiple rewards which choose the position difference between adjacent joints as the reward standard are designed to optimize the solution, avoid solving unreachable points and prevent the mechanical structure from being damaged also in the environment of five-degree-of-freedom arm robot. The validity of above method is verified by simulation experiment results.",https://ieeexplore.ieee.org/document/9230347/,"2020 5th International Conference on Automation, Control and Robotics Engineering (CACRE)",19-20 Sept. 2020,ieeexplore
10.1109/IJCNN48605.2020.9207308,A Few-shot Dynamic Obstacle Avoidance Strategy in Unknown Environments,IEEE,Conferences,"Obstacle avoidance is one of the basic capabilities of intelligent mobile robots. With the diversification of the application environment, mobile robots are required to avoid obstacles with higher generality. Benefit from the development of mobile platform and deep learning algorithm in recent years, we conceive a few-shot dynamic obstacle avoidance strategy to meet this higher generality demand. Under this metric-based meta-learning method, mobile robots can quickly adapt to unknown environments by learning from several samples. In order to verify its effectiveness, we use this strategy to train a model and deploy it to the mobile robot and run multiple obstacle avoidance recognition tests in the real-world environment. The results of experiments performed on the mobile robot platform illustrates a good performance and verifies our proposed strategy. In addition to analyzing the experimental results, the advantages, disadvantages as well as application potential of the proposed strategy as a decision aid are also discussed.",https://ieeexplore.ieee.org/document/9207308/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/ICRA.2019.8793690,A Fog Robotics Approach to Deep Robot Learning: Application to Object Recognition and Grasp Planning in Surface Decluttering,IEEE,Conferences,"The growing demand of industrial, automotive and service robots presents a challenge to the centralized Cloud Robotics model in terms of privacy, security, latency, bandwidth, and reliability. In this paper, we present a `Fog Robotics' approach to deep robot learning that distributes compute, storage and networking resources between the Cloud and the Edge in a federated manner. Deep models are trained on non-private (public) synthetic images in the Cloud; the models are adapted to the private real images of the environment at the Edge within a trusted network and subsequently, deployed as a service for low-latency and secure inference/prediction for other robots in the network. We apply this approach to surface decluttering, where a mobile robot picks and sorts objects from a cluttered floor by learning a deep object recognition and a grasp planning model. Experiments suggest that Fog Robotics can improve performance by sim-to-real domain adaptation in comparison to exclusively using Cloud or Edge resources, while reducing the inference cycle time by 4× to successfully declutter 86% of objects over 213 attempts.",https://ieeexplore.ieee.org/document/8793690/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ICST46873.2019.9047714,A Fundamental Experiment on Contact Position Estimation on Vision based Dome-type Soft Tactile Sensor using Ready-made Medium,IEEE,Conferences,"Tactile sensors are critical components in robotics fields. Recently, soft tactile sensor utilizing vision is actively developed for safe human machine interaction. Some researches use novel custom-made medium in order to achieve tactile sensing. Deep learning can recognize pattern from any vision data when it has sufficient dataset, i.e., the system does not require specific pattern embedded hardware for the pattern recognition. To achieve soft tactile sensor's economical application for robot fingers, this paper presents a fundamental experiment on contract position estimation on vision based dome-type soft tactile sensor utilizing ready-made silicon as a medium and convolutional neural network. In order to estimate and classify the contact position, convolutional neural network (CNN) was applied. The modified VGGNet architecture was coded using Tensorflow and Keras. 1000 images were taken to train the modified VGG network; 200 images were taken for each neutral, left, right, lower, upper direction. For each direction, fingertip, pencil, ruler, and table corner were utilized to capture various situations. After checking the results of the test set, the trained model was applied to the embedded board and checked the contact position estimation in real-time. The experiment showed high accuracy on classifying the con-tact position of the vision based dome-type soft tactile sensor in real time. This contact position estimation system will be critical for the finger-typed robots since the system is reasonably small and it will reduce significant amount of manufacturing cost for the safe human machine interaction system. For the future work, we will acquire more image data and apply more advanced network architecture to improve accuracy.",https://ieeexplore.ieee.org/document/9047714/,2019 13th International Conference on Sensing Technology (ICST),2-4 Dec. 2019,ieeexplore
10.1109/ICMSS.2011.5999339,A Human-Machine Interaction System: A Voice Command Learning System Using PL-G-SOM,IEEE,Conferences,"This paper proposes a voice command learning system for partner robots acquiring communication ability with instructors. Parameter-less Growing Self-Organizing Map (PL-G-SOM), an intelligent pattern recognition model given by our previous work, is used and computational feeling of robots is also adopted to improve the human-machine interaction system. AIBO robot was used in the experiment and the results of real environment showed the effectiveness of the proposed methods.",https://ieeexplore.ieee.org/document/5999339/,2011 International Conference on Management and Service Science,12-14 Aug. 2011,ieeexplore
10.1109/IJCNN48605.2020.9206637,A Lightweight Neural-Net with Assistive Mobile Robot for Human Fall Detection System,IEEE,Conferences,"Falls are a major health issue, particularly among the elderly. Increasing fall events require high service quality and dedicated medical treatment which is an economic burden. In the lack of appropriate care and support, serious injuries caused by fall will cost lives. Therefore, tracking systems with fall detection capabilities are required. Static-view sensors with machine learning techniques for human fall detection have been widely studied and achieved significant results. However, these systems unable to monitor a person if he or she is out of viewing angle which greatly impedes its performance. Mobile robots are an alternative for keeping the person in sight. However, existing mobile robots are unable to operate for a long time due to battery issues and movement constraints in complex environments. In this paper, we proposed a lightweight deep learning vision-based model for human fall detection with an assistive robot to provide assistance when a fall happens. The proposed detection system requires less computational power which can be implemented in a low-cost 2D camera and GPU board for real-time monitoring. The assistive robot equipped with various sensors that can perform SLAM, obstacle avoidance and navigation autonomously. Our proposed system integrates these two sub-systems to compensate for the weakness of each other to constitute a system that robust, adaptable, and high performance. The proposed method has been validated through a series of experiments.",https://ieeexplore.ieee.org/document/9206637/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/IJCNN52387.2021.9534180,A Lightweight sequence-based Unsupervised Loop Closure Detection,IEEE,Conferences,"Stable, effective and lightweight loop closure detection is an always pursued goal in real-time SLAM systems, that can be ported on embedded processors and deployed on autonomous robotics. Deep learning methods have extended the expressive ability and adaptability of the descriptor, and sequence-based methods can greatly improve the matching accuracy. However, the increased computation complexity and storage bandwidth requirements of matching calculations for high-dimensional descriptor make it infeasible for real-time deployment, especially for robots that navigate in relatively big maps. To address this challenge, we propose a lightweight sequence-based unsupervised loop closure detection scheme. To be specific, Principal Component Analysis (PCA) is applied to squeeze the descriptor dimensions while maintaining sufficient expressive ability. Additionally, with the consideration of the image sequence and combining linear query with fast approximate nearest neighbor search to further reduce the execution time and improve the efficiency of sequence matching. We implement our method on CALC, a state-of-the-art unsupervised solution, and conduct experiments on NVIDIA TX2, results demonstrate that the accuracy has been improved by 5%, while the execution speed is 2× faster. Source code is available at https://github.com/Mingrui-Yu/Seq-CALC.",https://ieeexplore.ieee.org/document/9534180/,2021 International Joint Conference on Neural Networks (IJCNN),18-22 July 2021,ieeexplore
10.1109/UEMCON47517.2019.8993080,A Low-Cost Arm Robotic Platform based on Myoelectric Control for Rehabilitation Engineering,IEEE,Conferences,"Rehabilitation robotics is a recent kind of service robot that include devices such as robotic prosthesis and exoskeletons. These devices could help motor disabled people to rehabilitate their motor functions, and could provide functional compensation to accomplish motor activities. In order to control robotic prosthesis and exoskeletons it is required to identify human movement intention, to be converted into commands for the device. Motor impaired people may use surface electromyography (sEMG) signals to control these devices, taking into account that sEMG signals directly reflects the human motion intention. Myoelectric control is an advanced technique related with the detection, processing, classification, and application of sEMG signals to control human-assisting robots or rehabilitation devices. Despite recent advances with myoelectric control algorithms, currently there is still an important need to develop suitable methods involving usability, for controlling prosthesis and exoskeletons in a natural way. Traditionally, acquiring EMG signals and developing myoelectric control algorithms require expensive hardware. With the advent of low-cost technologies (i.e. sensors, actuators, controllers) and hardware support of simulation software packages as Matlab, affordable research tools could be used to develop novel myoelectric control algorithms. This work describes the implementation and validation of a Matlab-based robotic arm using low-cost technologies such as Arduino commanded using myoelectric control. The platform permits implementation of a variety of EMG-based algorithms. It was carried out a set of experiments aimed to evaluate the platform, through an application of pattern recognition based myoelectric control to identify and execute seven movements of the robotic upper limb: 1-forearm pronation; 2- forearm supination; 3-wrist flexion; 4-wrist extension; 5- elbow flexion; 6- elbow extension; 7-resting. The algorithm use a feature extraction stage based on a combination of time and frequency domain features (mean absolute value, waveform length, root mean square) and a widely used k-NN classifier. Obtained mean classification errors were 5.9%. As future work, additional features in the myoelectric control algorithm will be evaluated, for real-time applications.",https://ieeexplore.ieee.org/document/8993080/,"2019 IEEE 10th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)",10-12 Oct. 2019,ieeexplore
10.1109/RoSE52553.2021.00011,A Modeling Tool for Reconfigurable Skills in ROS,IEEE,Conferences,"Known attempts to build autonomous robots rely on complex control architectures, often implemented with the Robot Operating System platform (ROS). The implementation of adaptable architectures is very often ad hoc, quickly gets cumbersome and expensive. Reusable solutions that support complex, runtime reasoning for robot adaptation have been seen in the adoption of ontologies. While the usage of ontologies significantly increases system reuse and maintainability, it requires additional effort from the application developers to translate requirements into formal rules that can be used by an ontological reasoner. In this paper, we present a design tool that facilitates the specification of reconfigurable robot skills. Based on the specified skills, we generate corresponding runtime models for self-adaptation that can be directly deployed to a running robot that uses a reasoning approach based on ontologies. We demonstrate the applicability of the tool in a real robot performing a patrolling mission at a university campus.",https://ieeexplore.ieee.org/document/9474550/,2021 IEEE/ACM 3rd International Workshop on Robotics Software Engineering (RoSE),2-2 June 2021,ieeexplore
10.1109/ISMR48331.2020.9312950,A Multi-Modal Learning System for On-Line Surgical Action Segmentation,IEEE,Conferences,"Surgical action recognition and temporal segmentation is a building block needed to provide some degrees of autonomy to surgical robots. In this paper, we present a deep learning model that relies on videos and kinematic data to output in real-time the current action in a surgical procedure. The proposed neural network architecture is composed of two sub-networks: a Spatial-Kinematic Network, which produces high-level features by processing images and kinematic data, and a Temporal Convolutional Network, which filters such features temporally over a sliding window to stabilize their changes over time. Since we are interested in applications to real-time supervisory control of robots, we focus on an efficient and causal implementation, i.e. the prediction at sample k only depends on previous observations. We tested our causal architecture on the publicly available JIGSAWS dataset, outperforming comparable state-of-the-art non-causal algorithms up to 8.6% in the edit score.",https://ieeexplore.ieee.org/document/9312950/,2020 International Symposium on Medical Robotics (ISMR),18-20 Nov. 2020,ieeexplore
10.1109/GCIS.2012.60,A Natural Hand Gesture System for Intelligent Human-Computer Interaction and Medical Assistance,IEEE,Conferences,"This paper presents a novel hand gesture system for intelligent human-computer interaction (HCI) and its applications in medical assistance, e.g. intelligent wheelchair control. The hand gesture vocabulary in the system consists of five key hand postures and three compound states, and its design strategy covers the minimal hand motions, distraction detection and user-friendly design. The experiment results show that the designed lexicon is intuitive, ergonomic, and easy to be remembered and performed. The system is tested in both of the indoor and outdoor environments and shows the robustness to lighting change and users' errors. The proposed intelligent HCI system can run in real-time and offers a natural and efficient interface for people with disability in their limbs to communicate with robots.",https://ieeexplore.ieee.org/document/6449559/,2012 Third Global Congress on Intelligent Systems,6-8 Nov. 2012,ieeexplore
10.1109/IROS.2018.8594036,A Neurorobotic Experiment for Crossmodal Conflict Resolution in Complex Environments *,IEEE,Conferences,"Crossmodal conflict resolution is crucial for robot sensorimotor coupling through the interaction with the environment, yielding swift and robust behaviour also in noisy conditions. In this paper, we propose a neurorobotic experiment in which an iCub robot exhibits human-like responses in a complex crossmodal environment. To better understand how humans deal with multisensory conflicts, we conducted a behavioural study exposing 33 subjects to congruent and incongruent dynamic audio-visual cues. In contrast to previous studies using simplified stimuli, we designed a scenario with four animated avatars and observed that the magnitude and extension of the visual bias are related to the semantics embedded in the scene, i.e., visual cues that are congruent with environmental statistics (moving lips and vocalization) induce the strongest bias. We implement a deep learning model that processes stereophonic sound, facial features, and body motion to trigger a discrete behavioural response. After training the model, we exposed the iCub to the same experimental conditions as the human subjects, showing that the robot can replicate similar responses in real time. Our interdisciplinary work provides important insights into how crossmodal conflict resolution can be modelled in robots and introduces future research directions for the efficient combination of sensory observations with internally generated knowledge and expectations.",https://ieeexplore.ieee.org/document/8594036/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ECICE47484.2019.8942691,A Novel Dynamic Hand Gesture and Movement Trajectory Recognition model for Non-Touch HRI Interface,IEEE,Conferences,"Efficient Human Robot Interaction (HRI) interface is very much demandable for controlling the semi-autonomous robots. Hand gesture recognition is an effective form of non-touch instruction. Thus, human hand gesture recognition is mostly used technique for HRI. However, in most research, some sensor devices or marker are incorporate with the hand or a large number of hand image and hand gesture sequence is stored and process for gesture recognition in machine learning techniques, which are costly and demand complex computation. From this point of view, an efficient dynamic hand gesture and movement trajectory recognition system is proposed in this paper, which can be used in real-time fashion for effective HRI interface. In the proposed dynamic gesture recognition system, hand images and skeleton information are extracted for Kinect sensor. Hands are segmented from the video frame using a skin color segmentation model from the region of interest (ROI) around the palm position of both hands. The hand open and close states are identified by calculating the position of palm and extreme position of Figure for activating the instruction recognition. The trajectory of segmented hands and the hands open state are considered for formulating the model of gesture with respect to the selected index points of body skeleton. Finally, several gesture models are derived to recognize the instruction during temporal gesture movement. For validating the proposed model, an experimental environment is setup in experimental lab. Ten volunteers are considered and tested the proposed system for six gesture instructions. According to the experiment, the proposed system shows 94.5% average recognition accuracy for dynamic motion instruction identification.",https://ieeexplore.ieee.org/document/8942691/,"2019 IEEE Eurasia Conference on IOT, Communication and Engineering (ECICE)",3-6 Oct. 2019,ieeexplore
10.1109/FUZZ48607.2020.9177557,A Novel Self-Organizing PID Approach for Controlling Mobile Robot Locomotion,IEEE,Conferences,"A novel self-organizing fuzzy proportional-integral-derivative (SOF-PID) control system is proposed in this paper. The proposed system consists of a pair of control and reference models, both of which are implemented by a first-order autonomous learning multiple model (ALMMo) neuro-fuzzy system. The SOF-PID controller self-organizes and self-updates the structures and meta-parameters of both the control and reference models during the control process ""on the fly"". This gives the SOF-PID control system the capability of quickly adapting to entirely new operating environments without a full re-training. Moreover, the SOF-PID control system is free from user- and problem-specific parameters and is entirely data-driven. Simulations and real-world experiments with mobile robots demonstrate the effectiveness and validity of the proposed SOF-PID control system.",https://ieeexplore.ieee.org/document/9177557/,2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),19-24 July 2020,ieeexplore
10.1109/RO-MAN46459.2019.8956259,A Reinforcement-Learning Approach for Adaptive and Comfortable Assistive Robot Monitoring Behavior,IEEE,Conferences,"Companion robots used in the field of elderly assistive care can be of great value in monitoring their everyday activities and well-being. However, in order to be accepted by the user, their behavior, while monitoring them, should not provide discomfort: robots must take into account the activity the user is performing and not be a distraction for them. In this paper, we propose a Reinforcement Learning approach to adaptively decide a monitoring distance and an approaching direction starting from an estimation of the current activity obtained by the use of a wearable device. Our goal is to improve user activity recognition performance without making the robot's presence uncomfortable for the monitored person. Results show that the proposed approach is promising for real scenario deployment, succeeding in accomplishing the task in more than 80%of episodes run.",https://ieeexplore.ieee.org/document/8956259/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/ICRA48506.2021.9561941,A Robot Walks into a Bar: Automatic Robot Joke Success Assessment,IEEE,Conferences,"Effective social robots should leverage humor’s unique ability to improve relationship connections and dispel stress, but current robots possess limited (if any) humorous abilities. In this paper, we aim to supplement one aspect of autonomous robots by giving robotic systems the ability to ""read the room"" to assess how their humorous statements are received by nearby people in real time. Using a dataset of the audio of crowd responses to a robotic comedian over multiple performances (first presented in past work), we establish human-labeled joke success ground truths and compare individual human rater accuracy against the outputs of lightweight Machine Learning (ML) approaches that are easy to deploy in real-time joke assessment. Our results indicate that all three ML approaches (naïve Bayes, support vector machines, and single-hidden-layer feedforward neural networks) performed significantly better than the baseline approach used in our past work. In particular, support vector machines and neural network approaches are comparable to a human rater in the task of assessing if a joke failed or not in certain cases. The products of this work will inform self-assessment techniques for robots and help social robotics researchers test their own assessment methods on realistic data from human crowds.",https://ieeexplore.ieee.org/document/9561941/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ITAIC.2019.8785467,A Weights and Improved Adaptive Artificial Fish Swarm Algorithm for Path Planning,IEEE,Conferences,"A weight and improved adaptive artificial fish swarm algorithm(WIA-AFSA) is proposed to deal with the problem of mobile robots path planning have low optimization accuracy and premature convergence under real environment. Firstly, introduced an improved aggregation degree factor to obtain an adaptive step and visual strategy, which can reflect the actual changes in the optimal state of the artificial fish swarm search, and better balance the global and local search capabilities. At the same time, the weight evaluation factor is introduced in the pray, swarm and follow behavior of the artificial fish, which effectively avoids the algorithm falling into the local optimum and premature. The benchmark function is used to test the performance of the algorithm. The results show that the algorithm has good searching ability and convergence. Simulation experiments of path planning based on raster model were carried out to verify the superiority of wia-afsa algorithm in robot navigation. Finally, the path planning experiment of the robot in real environment proves the effectiveness and practicability of the proposed algorithm.",https://ieeexplore.ieee.org/document/8785467/,2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC),24-26 May 2019,ieeexplore
10.1109/IJCNN.2010.5596771,A cognitive developmental robotics architecture for lifelong learning by evolution in real robots,IEEE,Conferences,"This paper is devoted to a detailed presentation of the current state of the Multilevel Darwinist Brain (MDB) cognitive architecture for lifelong learning in real robots. This architecture follows the cognitive developmental robotics approach and it is based on concepts like embodiment, open-ended lifelong learning, autonomous knowledge acquisition or adaptive behaviors and motivations. In addition, this version of the MDB architecture incorporates several improvements related with more practical issues, which are the result of the experience gained through several experiments with real robots in the last few years. The MDB uses evolutionary algorithms in the knowledge acquisition process, which implies the need of paying attention to the efficiency of the computational implementation. Here, we first describe the cognitive model on which the basic operation of the architecture is based and, secondly, we detail the main aspects and working of the current version of the MDB. Finally, we have designed a very simple but illustrative real robot lifelong learning example, where we can show how to set up an experiment using the MDB. Hence, with this simple example we show the successful behavior of the MDB cognitive developmental robotics principles.",https://ieeexplore.ieee.org/document/5596771/,The 2010 International Joint Conference on Neural Networks (IJCNN),18-23 July 2010,ieeexplore
10.1109/iCREATE.2014.6828372,A comparison of various robotic control architectures for autonomous navigation of mobile robots,IEEE,Conferences,"For mobile robots, the most fundamental and pressing issue is that of autonomous navigation. Successful navigation of mobile robots is closely dependent on four vitals i.e. perception, localization, cognition and motion control. Implementation of each of these vital blocks requires consideration of at least one of the two well-known control architectures Deliberative Navigation Control and Reactive Navigation Control or a combination of the two, also known as a Hybrid Navigation Control. This paper compares each of these control architectures on the basis of their flexibility, ease of implementation, reactivity, robustness, efficiency and many other architecture specifications. The paper concludes with suggesting the schema that seems to be the best of each of these control schemes, on the basis of the analysis made, in order to cope with unknown and dynamic navigation problems encountered in real life scenarios.",https://ieeexplore.ieee.org/document/6828372/,2014 International Conference on Robotics and Emerging Allied Technologies in Engineering (iCREATE),22-24 April 2014,ieeexplore
10.1109/IROS.1998.727477,A constraint-based controller for soccer-playing robots,IEEE,Conferences,"Soccer meets the requirements of the situated agent approach and as a task domain is sufficiently rich to support research integrating many branches of robotics and AI. A robot is an integrated system, with a controller embedded in its plant. A robotic system is the coupling of a robot to its environment. Robotic systems are, in general, hybrid dynamic systems, consisting of continuous, discrete and event-driven components. Constraint nets provide a semantic model for modeling hybrid dynamic systems. Controllers are embedded constraint solvers that solve constraints in real-time. A controller for our new softbot soccer team, UBC Dynamo98, has been modeled in constraint nets, and implemented in Java, using the Java Beans architecture. The paper demonstrates that the formal constraint net approach is a practical tool for designing and implementing controllers for robots in multi-agent real-time environments.",https://ieeexplore.ieee.org/document/727477/,"Proceedings. 1998 IEEE/RSJ International Conference on Intelligent Robots and Systems. Innovations in Theory, Practice and Applications (Cat. No.98CH36190)",17-17 Oct. 1998,ieeexplore
10.1109/ROBOT.1998.676374,A control architecture to achieve manipulation task goals for a humanoid robot,IEEE,Conferences,"Focusing on the manipulation tasks to be executed by humanoid robots, principal requirements which are to be satisfied by hardware/software of the control system are considered. In order to meet the requirements, a novel type of hardware structure and software architecture is proposed. Since the target humanoid robot consists of multiple subsystems such as a central controller for brain, a vision controller for eye, and five motion sub-controllers for two arms, two hands, one spine, the on-board hardware control system is designed to have a distributed control structure connected by pseudo real-time Ethernet interfaces. A goal-achieving software architecture is also proposed which meets the requirements of semi-autonomy, reactivity, expandability, and object-orientedness. Specifically, in order to achieve reactivity, a coordination method is proposed to configure three kinds of executive modules, primitive module, flow-control module, and goal module, which have multiple exit states. The control architecture proposed has been implemented for performing toy-block assembly tasks on a humanoid robot as well as on the graphic simulator.",https://ieeexplore.ieee.org/document/676374/,Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),20-20 May 1998,ieeexplore
10.1109/IJCNN.2014.6889900,A developmental perspective on humanoid skill learning using a hierarchical SOM-based encoding,IEEE,Conferences,"Hand-coding is an impractical approach to developing motion repertoires for humanoid robots, requiring both task and programming expertise. Physical demonstration of skills, on the other hand, is an approach with which humans are both competent and familiar. When following a programming-by-demonstration approach, the adaptiveness of a robot can be further increased by giving it the ability to compose novel skills from skills already acquired from demonstration. We have previously presented [1] an extension to the Piaget-inspired Constructivist Learning Architecture [2], featuring a hierarchical SOM-based algorithm that encodes skills as a hierarchy of fixed-length subsequences. At the core of the extended algorithm lies a novel principle for comparing long-term memory and short-term memory, represented as connection weights and decaying node activation values, respectively. In this article, we present an in-depth analysis of how this comparison, can provide a robot control algorithm that is both state-sensitive and goal oriented. We present results from experiments using an abstract chain walk problem that includes hidden states, to demonstrate how the algorithm disambiguates states and selects actions yielding higher rewards. Furthermore, we present results from an experiment where we use programming-by-demonstration to encode and reproduce a figure-8 gesture with a Nao humanoid robot. The results show that our algorithm is capable of identifying hidden states in both real and abstract problem domains.",https://ieeexplore.ieee.org/document/6889900/,2014 International Joint Conference on Neural Networks (IJCNN),6-11 July 2014,ieeexplore
10.1109/IROS.2013.6696771,A learning-based approach to robust binaural sound localization,IEEE,Conferences,"Sound source localization is an important feature designed and implemented on robots and intelligent systems. Like other artificial audition tasks, it is constrained to multiple problems, notably sound reflections and noises. This paper presents a sound source azimuth estimation approach in reverberant environments. It exploits binaural signals in a humanoid robotic context. Interaural Time and Level Differences (ITD and ILD) are extracted on multiple frequency bands and combined with a neural network-based learning scheme. A cue filtering process is used to reduce the reverberations effects. The system has been evaluated with simulation and real data, in multiple aspects covering realistic robot operating conditions, and was proven satisfying and effective as will be shown and discussed in the paper.",https://ieeexplore.ieee.org/document/6696771/,2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,3-7 Nov. 2013,ieeexplore
10.1109/ICCS45141.2019.9065549,A low power Artificial Intelligence Processor for Autonomous Mobile Robots,IEEE,Conferences,"The robot which makes use of AI as a mode of processing is getting more popular day by day, starting from the autonomous room cleaning robot to Amazon Prime Air. This autonomous robot overtakes traditional robots in following aspects such as implementing effective decision making in order to reduce the computational overhead by reducing the overall power usage of the robot. In this report, we have designed a low power [1] AIP without compensating in performance. The AIP which we have designed is a 64 processing element that uses parallel processing architecture. A map with 8 different routes is created in Xilinx where it calculates the shortest path from the source to destination using conditional operators. A* algorithm is implemented in Matlab to calculate the shortest distance and Dijkstra's algorithm is converted to VHDL using Vivado HLS coder. A neural network is also created using Matlab to detect and avoid real time obstacle. The overall power report of the processor is implemented in Cadence.",https://ieeexplore.ieee.org/document/9065549/,2019 International Conference on Intelligent Computing and Control Systems (ICCS),15-17 May 2019,ieeexplore
10.1109/CISTI.2015.7170600,A mixed reality game using 3Pi robots — “PiTanks”,IEEE,Conferences,"In the growing field of Robotics, one of the many possible paths to explore is the social aspect that it can influence upon the present society. The combination of the goal-oriented development of robots with the interactivity used in games while employing mixed reality is a promising route to take in regard to designing user-friendly robots and improving problem solving featured in artificial intelligence software. In this paper, we present a competitive team-based game using Pololu's 3Pi robots moving in a projected map, capable of human interaction via game controllers. The game engine was developed utilizing the framework Qt Creator with C++ and OpenCV for the image processing tasks. The technical framework uses the ROS framework for communications that may be, in the future, used to connect different modules. Various parameters of the implementation are tested, such as position tracking errors.",https://ieeexplore.ieee.org/document/7170600/,2015 10th Iberian Conference on Information Systems and Technologies (CISTI),17-20 June 2015,ieeexplore
10.1109/CIG.2011.6032027,A neuronal global workspace for human-like control of a computer game character,IEEE,Conferences,"This paper describes a system that uses a global workspace architecture implemented in spiking neurons to control an avatar within the Unreal Tournament 2004 (UT2004) computer game. This system is designed to display human-like behaviour within UT2004, which provides a good environment for comparing human and embodied AI behaviour without the cost and difficulty of full humanoid robots. Using a biologically-inspired approach, the architecture is loosely based on theories about the high level control circuits in the brain, and it is the first neural implementation of a global workspace that is embodied in a dynamic real time environment. At its current stage of development the system can navigate through UT2004 and shoot opponents. We are currently completing the implementation and testing in preparation for the human-like bot competition at CIG 2011 in September.",https://ieeexplore.ieee.org/document/6032027/,2011 IEEE Conference on Computational Intelligence and Games (CIG'11),31 Aug.-3 Sept. 2011,ieeexplore
10.1109/ICVES.2016.7548165,A new hopfield-type neural network approach to multi-goal vehicle navigation in unknown environments,IEEE,Conferences,"A Hopfield-type neural networks (HNN) algorithm associated with histogram navigation method is proposed in this paper for real-time map building and path planning for multiple goals applications. In real world applications such as rescue robots, service robots, mining mobile robots, and mine searching robots, etc., an autonomous vehicle needs to reach multiple goals with a shortest path that, in this paper, is capable of being implemented by a HNN method with minimized overall distance. Once a global trajectory is planned, a foraging-enabled trail is created to guide the vehicle to the multiple goals. A histogram-based local navigation algorithm is employed to plan a collision-free path along the trail planned by the global path planner. A re-planning-based algorithm aims to generate trajectory while an autonomous vehicle explores through a terrain with map building in unknown environments. In this paper, simulation and experimental results demonstrate that the real-time concurrent mapping and multi-goal navigation of an autonomous vehicle is successfully performed under unknown environments.",https://ieeexplore.ieee.org/document/7548165/,2016 IEEE International Conference on Vehicular Electronics and Safety (ICVES),10-12 July 2016,ieeexplore
10.1109/WINCOM50532.2020.9272477,A new middleware for managing heterogeneous robot in ubiquitous environments,IEEE,Conferences,"Heterogeneity is one of the main issues for the deployment of the Industry 4.0. This is due to the diversity in the available robots and the IIoT devices. These equipments use different programming languages and communication protocols. To make the integration of such equipments easy, we propose TalkRoBots, a middleware that allows heterogeneous robots and IIoT devices to communicate together and exchange data in a transparent way. The middleware was experimented in a real scenario with different robots that demonstrate its efficiency.",https://ieeexplore.ieee.org/document/9272477/,2020 8th International Conference on Wireless Networks and Mobile Communications (WINCOM),27-29 Oct. 2020,ieeexplore
10.1109/SNPD.2016.7515880,A novel fuzzy omni-directional gait planning algorithm for biped robot,IEEE,Conferences,"Aiming at the problems in gait planning of the biped robots, including the complex model, low stability, etc., a novel fuzzy omni-directional gait planning algorithm (FOGPA) is proposed. At first, this method puts forward a new separated omni-directional gait planning model, which combines the straight walking planning algorithm based on the improved Hermite interpolation and the rotation motion together. And then, a fuzzy gait parameter adjustment algorithm is put forward to control the gait parameters including the step size and rotation speed dynamically. At last, the fuzzy control results are used to get the gait data of robot real-timely. The experiment results show that the FOGPA improves the stability and robustness of gait in a certain degree and also improves the adaptability to the complex environment of the robot.",https://ieeexplore.ieee.org/document/7515880/,"2016 17th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",30 May-1 June 2016,ieeexplore
10.1109/HAPTICS.2014.6775492,A novel haptic interface and control algorithm for robotic rehabilitation of stoke patients,IEEE,Conferences,"Rehabilitation robots are gradually becoming popular for stroke rehabilitation to improve motor recovery. By using a robot, the patient may perform the training more frequently on their own, but they must be motivated to do so. Therefore, this project develops a set of rehabilitation training programs with different haptic modalities on Compact Rehabilitation Robot (CR2) - a robot used to train upper and lower limbs reaching movement. The paper present the developed haptic interface, Haptic Sense with five configurable haptic modalities that include sensations of weight, wall, spring, sponge and visual amplification. A combination of several haptic modalities was implemented into virtual reality games, Water Drop - a progressive training game with up to nine levels of difficulties that requires user to move the cup to collect the water drops.",https://ieeexplore.ieee.org/document/6775492/,2014 IEEE Haptics Symposium (HAPTICS),23-26 Feb. 2014,ieeexplore
10.1109/IECON.1993.339087,A planning architecture for intelligent robot: fuzzy memory-based reasoning for real-time planning/control,IEEE,Conferences,"Our research's main objective is to design an architecture prototype to govern an intelligent robot which can work quickly and efficiently in a vague dynamical environment, typically where various robots and human cooperate each other to accomplish a common global goal. To realize such kind of system, a new planning and control architecture with abilities of real-time control and easy implementation of control knowledge is required. The architecture proposed here is based on the idea of memory-based reasoning systems and behavior-based control systems. Then, to confirm its performance, a simple simulation example of two mobile robots that cooperate to capture a target is showed.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/339087/,Proceedings of IECON '93 - 19th Annual Conference of IEEE Industrial Electronics,15-19 Nov. 1993,ieeexplore
10.1109/AIM.2001.936513,A radial basis function networks approach for the tracking problem of mobile robots,IEEE,Conferences,Proposes a radial basis function network (RBFN) approach to the solution of the tracking problem for mobile robots. RBFN-based controllers are investigated in order to introduce some degree of robustness in the control system and to avoid the main disadvantage of multilayer neural networks (MNN) to be highly nonlinear in the parameters. The training of the nets and the control performances analysis have been done in a real experimental setup. The proposed solutions are implemented on a PC-based control architecture for the real-time control of the LabMate mobile base and are compared with MNN-based control schemes. The experimental results are satisfactory in terms of tracking errors and computational efforts.,https://ieeexplore.ieee.org/document/936513/,2001 IEEE/ASME International Conference on Advanced Intelligent Mechatronics. Proceedings (Cat. No.01TH8556),8-12 July 2001,ieeexplore
10.1109/IROS.2003.1250667,A robot that reinforcement-learns to identify and memorize important previous observations,IEEE,Conferences,"It is difficult to apply traditional reinforcement learning algorithms to robots, due to problems with large and continuous domains, partial observability, and limited numbers of learning experiences. This paper deals with these problems by combining: (1) reinforcement learning with memory, implemented using an LSTM recurrent neural network whose inputs are discrete events extracted from raw inputs; (2) online exploration and offline policy learning. An experiment with a real robot demonstrates the methodology's feasibility.",https://ieeexplore.ieee.org/document/1250667/,Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453),27-31 Oct. 2003,ieeexplore
10.1109/ISIE.2010.5637497,A society of agents for service robots,IEEE,Conferences,"This article presents an agent based distributed software architecture for machine and robot control. The functionality of agents of this architecture has been inspired by Marvin Minsky's definition of the term in his book “The Society of Mind” (1986) [1]. Minsky, widely considered to be one of the fathers of artificial intelligence, tried to describe from an engineering point of view, in this book, how he thought the mind works: “I'll call “Society of Mind” this scheme in which each mind is made of many smaller processes. These we'll call agents. Each mental agent by itself can only do some simple thing that needs no mind or thought at all. Yet when we join these agents in societies-in certain very special ways-this leads to true intelligence.” Societies of simple behaving agents have been implemented in Fatronik, in real robots, and have been demonstrated to be able to perform complex tasks in industrial environments. This article explains the features of such societies of agents and presents their implementation in a real robot.",https://ieeexplore.ieee.org/document/5637497/,2010 IEEE International Symposium on Industrial Electronics,4-7 July 2010,ieeexplore
10.1109/CADCG.2009.5246869,A study on autonomous animated robots: Anibots,IEEE,Conferences,"In this paper, we demonstrate a design of autonomous virtual creatures (called animated robots: Anibots in this paper) and develop a design tool for animated robots. An animated robot can behave autonomously by using its own sensors and controllers on three-dimensional physically modeled environment. The developed tool can enable us to execute the simulation of Anibots on physical environment at any time during the modeling process. In order to simulate more realistic world, an approximate fluid environment model with low computational costs is presented. It is shown that a combinatorial use of neural network implementation for controllers and the genetic algorithm (GA) or the particle swarm optimization (PSO) is effective for emerging more realistic autonomous behaviours of animated robots.",https://ieeexplore.ieee.org/document/5246869/,2009 11th IEEE International Conference on Computer-Aided Design and Computer Graphics,19-21 Aug. 2009,ieeexplore
10.1109/ICCITECHN.2016.7860248,A support vector machine approach for real time vision based human robot interaction,IEEE,Conferences,"Today humanoid robots are being exhibited to redact various task as a personal assistant of a human. To be an assistant, a robot needs to interact with human as a human. For this reason robot needs to understand the human gender, facial expression, facial gesture in real time. Ribo - A humanoid robot build in RoboSUST lab which has the ability to communicate in Bangla with the people speaking in Bengali. In this article the authors show the implementation of theoretical knowledge of the recognition of real time facial expression, detection of human gender and yes / no from facial gesture in Ribo. Real time facial expression and gender detection can be performed using Support Vector Machine (SVM). A prepared dataset containing the facial landmarks leveled as five different expression: sad, angry, smile, surprise and normal, is given to SVM to construct a classifier. For the prediction of any expression, facial images are taken in real time and provided the facial landmarks data to SVM. Local Binary Pattern(LBP) algorithm is used for extracting features from face images. These features leveled as male and female are responsible to build the classifier. The face gesture for detecting `yes/no' is performed by tracking the movement of face in a certain time. After those implementations the principal results will make a framework that will be used in Ribo to recognize human facial expression, facial gesture movement and detect human gender.",https://ieeexplore.ieee.org/document/7860248/,2016 19th International Conference on Computer and Information Technology (ICCIT),18-20 Dec. 2016,ieeexplore
10.1109/ICAT.2013.6728900,A teleoperating interface for ground vehicles using autonomous flying cameras,IEEE,Conferences,"Navigating remote robots and providing awareness of the remote environment is essential in many teleoperated tasks. An external view on the remote robot, a bird's eye view, is thought to improve operator performance. In this paper we explore a novel design for providing such a third-person view for a ground vehicle using a dynamic, external camera mounted on a quadcopter. Compared to earlier methods that use 3D reconstruction to create third-person views, our approach comprises a true third-person view through a video feed. We so provide visually rich, live information to the operator. In an experiment simulating a search and rescue mission in a simplified environment, we compared our proposed design to a pole-mounted camera and to a traditional front-mounted camera. The third-person perspective provided by our flying camera and pole-mounted camera resulted in fewer collisions and more victims being located, compared to the front-mounted camera.",https://ieeexplore.ieee.org/document/6728900/,2013 23rd International Conference on Artificial Reality and Telexistence (ICAT),11-13 Dec. 2013,ieeexplore
10.1109/IROS.1994.407376,A two-phase navigation system for mobile robots in dynamic environments,IEEE,Conferences,"This paper presents an implemented navigation system for mobile robots in dynamic environments. In order to take advantage of existing knowledge of the world and to deal with unknown obstacles in real time, our system divides motion planning into global path planning and local reactive navigation. The former uses genetic algorithm methods to find a collision-free path; the latter is implemented using neural network techniques to track the path generated by the global planner while avoiding unknown obstacles on the way. As a result, the system can adapt to dynamic environmental changes. Our experiments, both in simulation and on a real robot, showed that the system can find a reasonably good free path in a fraction of the time necessary to find an optimal free path, and it can effectively achieve its goal configurations without collision.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/407376/,Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS'94),12-16 Sept. 1994,ieeexplore
10.1109/ICSMC.2004.1400779,A user-oriented framework for the design and implementation of pet robots,IEEE,Conferences,"In recent years, application of intelligent autonomous robots for home amusement has become an important research criterion, and pet robots have been designed to become the electronic toys for the next generation. To develop pet robots that can act in real time in the real world, this work adopts the behavior-based control architecture. In our control framework, an imitation-based learning system is included to build robot behaviors. Moreover an emotional model is embedded to the control architecture. By giving the pet robot an emotional model it can explicitly express its internal conditions through its various external behaviors, as the real living creature does. To evaluate the proposed framework, we have developed an interactive environment and successfully used it to design a pet robot.",https://ieeexplore.ieee.org/document/1400779/,"2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)",10-13 Oct. 2004,ieeexplore
10.1109/ROBOT.2010.5509238,A voice-commandable robotic forklift working alongside humans in minimally-prepared outdoor environments,IEEE,Conferences,"One long-standing challenge in robotics is the realization of mobile autonomous robots able to operate safely in existing human workplaces in a way that their presence is accepted by the human occupants. We describe the development of a multi-ton robotic forklift intended to operate alongside human personnel, handling palletized materials within existing, busy, semi-structured outdoor storage facilities. The system has three principal novel characteristics. The first is a multimodal tablet that enables human supervisors to use speech and pen-based gestures to assign tasks to the forklift, including manipulation, transport, and placement of palletized cargo. Second, the robot operates in minimally-prepared, semi-structured environments, in which the forklift handles variable palletized cargo using only local sensing (and no reliance on GPS), and transports it while interacting with other moving vehicles. Third, the robot operates in close proximity to people, including its human supervisor, other pedestrians who may cross or block its path, and forklift operators who may climb inside the robot and operate it manually. This is made possible by novel interaction mechanisms that facilitate safe, effective operation around people. We describe the architecture and implementation of the system, indicating how real-world operational requirements motivated the development of the key subsystems, and provide qualitative and quantitative descriptions of the robot operating in real settings.",https://ieeexplore.ieee.org/document/5509238/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/FUZZ48607.2020.9177654,AI-FML Agent for Robotic Game of Go and AIoT Real-World Co-Learning Applications,IEEE,Conferences,"In this paper, we propose an AI-FML agent for robotic game of Go and AIoT real-world co-learning applications. The fuzzy machine learning mechanisms are adopted in the proposed model, including fuzzy markup language (FML)-based genetic learning (GFML), eXtreme Gradient Boost (XGBoost), and a seven-layered deep fuzzy neural network (DFNN) with backpropagation learning, to predict the win rate of the game of Go as Black or White. This paper uses Google AlphaGo Master sixty games as the dataset to evaluate the performance of the fuzzy machine learning, and the desired output dataset were predicted by Facebook AI Research (FAIR) ELF Open Go AI bot. In addition, we use IEEE 1855 standard for FML to describe the knowledge base and rule base of the Open Go Darkforest (OGD) prediction platform in order to infer the win rate of the game. Next, the proposed AI-FML agent publishes the inferred result to communicate with the robot Kebbi Air based on MQTT protocol to achieve the goal of human and smart machine co-learning. From Sept. 2019 to Jan. 2020, we introduced the AI-FML agent into the teaching and learning fields in Taiwan. The experimental results show the robots and students can co-learn AI tools and FML applications effectively. In addition, XGBoost outperforms the other machine learning methods but DFNN has the most obvious progress after learning. In the future, we hope to deploy the AI-FML agent to more available robot and human co-learning platforms through the established AI-FML International Academy in the world.",https://ieeexplore.ieee.org/document/9177654/,2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),19-24 July 2020,ieeexplore
10.1109/DevLrn.2012.6400818,ASP+POMDP: Integrating non-monotonic logic programming and probabilistic planning on robots,IEEE,Conferences,"Mobile robots equipped with multiple sensors and deployed in real-world domains frequently find it difficult to process all sensor inputs, or to operate without any human input and domain knowledge. At the same time, robots cannot be equipped with all relevant domain knowledge in advance, and humans are unlikely to have the time and expertise to provide elaborate and accurate feedback. This paper presents a novel framework that addresses these challenges by integrating high-level logical inference with low-level probabilistic sequential decision-making. Specifically, Answer Set Programming (ASP), a non-monotonic logic programming paradigm, is used to represent, reason with and revise domain knowledge obtained from sensor inputs and high-level human feedback, while hierarchical partially observable Markov decision processes (POMDPs) are used to automatically adapt visual sensing and information processing to the task at hand. Furthermore, a psychophysics-inspired strategy is used to merge the output of logical inference with probabilistic beliefs. All algorithms are evaluated in simulation and on wheeled robots localizing target objects in indoor domains.",https://ieeexplore.ieee.org/document/6400818/,2012 IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL),7-9 Nov. 2012,ieeexplore
10.1109/IEEECONF49454.2021.9382693,Accelerated Sim-to-Real Deep Reinforcement Learning: Learning Collision Avoidance from Human Player,IEEE,Conferences,"This paper presents a sensor-level mapless collision avoidance algorithm for use in mobile robots that map raw sensor data to linear and angular velocities and navigate in an unknown environment without a map. An efficient training strategy is proposed to allow a robot to learn from both human experience data and self-exploratory data. A game format simulation framework is designed to allow the human player to tele-operate the mobile robot to a goal and human action is also scored using the reward function. Both human player data and self-playing data are sampled using prioritized experience replay algorithm. The proposed algorithm and training strategy have been evaluated in two different experimental configurations: Environment 1, a simulated cluttered environment, and Environment 2, a simulated corridor environment, to investigate the performance. It was demonstrated that the proposed method achieved the same level of reward using only 16% of the training steps required by the standard Deep Deterministic Policy Gradient (DDPG) method in Environment 1 and 20% of that in Environment 2. In the evaluation of 20 random missions, the proposed method achieved no collision in less than 2 h and 2.5 h of training time in the two Gazebo environments respectively. The method also generated smoother trajectories than DDPG. The proposed method has also been implemented on a real robot in the real-world environment for performance evaluation. We can confirm that the trained model with the simulation software can be directly applied into the real-world scenario without further fine-tuning, further demonstrating its higher robustness than DDPG. The video and code are available: https://youtu.be/BmwxevgsdGc https://github.com/hanlinniu/turtlebot3_ddpg_collision_avoidance.",https://ieeexplore.ieee.org/document/9382693/,2021 IEEE/SICE International Symposium on System Integration (SII),11-14 Jan. 2021,ieeexplore
10.1109/IROS45743.2020.9341187,Active Improvement of Control Policies with Bayesian Gaussian Mixture Model,IEEE,Conferences,"Learning from demonstration (LfD) is an intuitive framework allowing non-expert users to easily (re-)program robots. However, the quality and quantity of demonstrations have a great influence on the generalization performances of LfD approaches. In this paper, we introduce a novel active learning framework in order to improve the generalization capabilities of control policies. The proposed approach is based on the epistemic uncertainties of Bayesian Gaussian mixture models (BGMMs). We determine the new query point location by optimizing a closed-form information-density cost based on the quadratic Rényi entropy. Furthermore, to better represent uncertain regions and to avoid local optima problem, we propose to approximate the active learning cost with a Gaussian mixture model (GMM). We demonstrate our active learning framework in the context of a reaching task in a cluttered environment with an illustrative toy example and a real experiment with a Panda robot.",https://ieeexplore.ieee.org/document/9341187/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/FPA.1994.636089,"Active perception, navigation, homing, and grasping: an autonomous perspective",IEEE,Conferences,"Perception is needed for action, not for the pure sake of the construction of abstract representations, although it does not exclude the role of internal representations for mediating complex behaviours. We think that, for the purpose of building autonomous robots, active perception requires specific recipes for three related aspects: the design of the physical sensory system, the modality and type of information extracted, and the structure and functioning of the control system. We outline a set of solutions for these three aspects and describe their implementation on a real mobile robot through a set of three different experiments using a combination of neural networks and genetic algorithms. The results show that active perception is a useful feature that is exploited by autonomous agents. The experiments shout that the combination of genetic algorithms and neural networks is a feasible and fruitful technique for the development of active perception in autonomous agents.",https://ieeexplore.ieee.org/document/636089/,Proceedings of PerAc '94. From Perception to Action,7-9 Sept. 1994,ieeexplore
10.1109/ICARCV.2018.8581349,Activity Recognition Based on RGB-D and Thermal Sensors for Socially Assistive Robots,IEEE,Conferences,"For socially assistive robots, being able to recognize basic human actions is an important capability. The sensors, which are frequently mounted on most recent robots, such as RGB-D and thermal cameras, as well as the advances in deep learning have enabled the research on activity recognition to grow. In this paper, we collected our own dataset of actions in a home-like scenario, which contains thermal imagery in addition to RGB-D data and we proposed a method based on Long-term Recurrent Convolutional Networks (LRCN). We showed that our method has an accuracy comparable with the state-of-the-art. We also proved that thermal information can improve the recognition accuracy. Furthermore, we tested the real-time capability of our system and conducted a real-time experiment with a robot (Pepper robot from Softbank Robotics) so as to investigate the effect of a robot enabled with action recognition capability in a human-robot interaction.",https://ieeexplore.ieee.org/document/8581349/,"2018 15th International Conference on Control, Automation, Robotics and Vision (ICARCV)",18-21 Nov. 2018,ieeexplore
10.1109/RCAR47638.2019.9043958,Actor-Critic Method-Based Search Strategy for High Precision Peg-in-Hole Tasks,IEEE,Conferences,"In the field of 3C(Computer/Communication/Consumer Electronic) product assembly, Peg-in-hole task, such as fiber assembly, is widely used. However, it remains as a big challenge for robots to automatically execute peg-in-hole tasks. Building a contact model is the traditional idea, which requires lots of time and effort. However, the model suffers low accuracy in the situation with tighter clearance. Currently, the most learning-based methods do not take into account the particularity of such assembly tasks, which lead to slow convergence. In this paper, we propose a new search strategy based on reinforcement learning for high precision peg-in-hole assembly tasks. The assembly task is divided into two steps: search and insert. Afterwards, a Markov Decision Process (MDP) is designed for the two steps according to different assembly features and solved by an Actor-Critic method. The robot can learn how to choose the optimal action and accomplish peg-in-hole task with less training and execute steps, high success rate and smaller contact force. Moreover, the proposed method can be applied to the multi-hole task without retraining. The results of simulation and experiment demonstrate its fast and stable performance.",https://ieeexplore.ieee.org/document/9043958/,2019 IEEE International Conference on Real-time Computing and Robotics (RCAR),4-9 Aug. 2019,ieeexplore
10.1109/ICCAR52225.2021.9463494,Adaptive Self-Localization System for Low-Cost Autonomous Robot,IEEE,Conferences,"Due to the massive growth in autonomous vehicles, mobile robots applications are more prevalent today. To implement intelligent behaviors, the robot must have the ability to locate itself and adapt to different environments. Despite the recent developments in self-localization, long-term navigation with low-cost robot is still an active area of research. This paper develops a new self-localization system based on Neural Network (NN) method that is fused into a fuzzy logic navigation system using low-cost encoders. The proposed system allows the autonomous mobile robot to adapt itself to different environments and improve its localization based on the trained model. In the experiment, the system is tested with PowerBot robot in different real environments, and compared with one of the most well-known self-localization method (i.e., dead-reckoning). The test is conducted in different set-up to confirm that the proposed system significantly improved the accuracy without the need for additional sensors other than the encoders. It was able to adapt to different environment and accumulatively improved the results.",https://ieeexplore.ieee.org/document/9463494/,"2021 7th International Conference on Control, Automation and Robotics (ICCAR)",23-26 April 2021,ieeexplore
10.1109/ROMAN.2006.314387,Adaptive Social Skills for Robots Interacting with Virtual Characters in Real Worlds,IEEE,Conferences,"We propose the implementation of a new interaction type that allows the creation of adaptive social relationships between robots and virtual characters in a real world environment, using reinforcement learning. We present the implementation of a storytelling scenario, which results in an immersion experience for the robot. The robot is able to interact and learn dynamically from the virtual character",https://ieeexplore.ieee.org/document/4107778/,ROMAN 2006 - The 15th IEEE International Symposium on Robot and Human Interactive Communication,6-8 Sept. 2006,ieeexplore
10.1109/FUZZY.2008.4630629,Adaptive learning approach of integrating evolution fuzzy-neural networks and Q-learning for mobile robots,IEEE,Conferences,"In the paper, an adaptive learning approach of integrating evolution fuzzy-neural networks and Q-learning is developed so that a mobile robot can adapt itself to a real and complex environment. Specifically, based on Q-value and an evolution method that adjusts their parameter values of the fuzzy-neural networks, the mobile robot evolves better strategies to adapt to the environment. However, in most studies of evolution learning, the learning of mobile robots often requires a simulator and an enormous amount of evolution time so as to perform a task. Therefore, we are to integrate Q-learning into the evolution fuzzy-neural networks to avoid the requirement of the simulator. Experiment results of a mobile robot illustrate the performance of the proposed approach.",https://ieeexplore.ieee.org/document/4630629/,2008 IEEE International Conference on Fuzzy Systems (IEEE World Congress on Computational Intelligence),1-6 June 2008,ieeexplore
10.1109/IROS.2010.5650226,Adaptive motion control with visual feedback for a humanoid robot,IEEE,Conferences,"The performance of a soccer robot is highly dependent on its motion ability. The kicking motion is one of the most important motions in a soccer game. However, automatic, full body motion generation for humanoid robots presents a formidable computational challenge. At the current state the most common approaches of implementing this motion are based on key frame technique. Such solutions are inflexible, i.e., in order to adjust the aimed direction of the kick the robot has to walk around the ball. The adjustment costs a lot of time especially if some precise adjustments have to be done, e.g., for a penalty kick. In this paper we present an approach for adaptive control of the motions. We implemented our approach in order to solve the task of kicking the ball on a humanoid robot Nao. The approach was tested both in simulation and on a real robot.",https://ieeexplore.ieee.org/document/5650226/,2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,18-22 Oct. 2010,ieeexplore
10.1109/RAAD.2010.5524575,Adaptive sliding mode controller design for mobile robot fault tolerant control. introducing ARTEMIC.,IEEE,Conferences,"Current real-time applications should timely deliver synchronized data-sets, minimize latency in their response and meet their performance specifications in the presence of disturbances and faults. The adaptive features of the designed controller are present at the lower control level using specific artificial intelligence techniques. Fuzzy inference system design is the fundamental element to generate an adaptive nonlinear controller for the robot operation in the presence of disturbances and modeling inaccuracies. This paper introduces an adaptive real-time distributed control application with fault tolerance capabilities for differential wheeled mobile robots, named ARTEMIC. Specific design, development and implementation details will be provided in this paper.",https://ieeexplore.ieee.org/document/5524575/,19th International Workshop on Robotics in Alpe-Adria-Danube Region (RAAD 2010),24-26 June 2010,ieeexplore
10.1109/COINS51742.2021.9524186,An Edge AI based Robot System for Search and Rescue Applications,IEEE,Conferences,"In this work, we propose an edge AI based robot system that contains drones and multi-legged robots for search and rescue applications. To accurately search for survivors in real-time, we integrate Tiny-YOLO into the drone design. Instead of adopting a microprocessor usually used in a robot, the FPGA device is adopted as the main hardware computing architecture of the multi-legged robot. A resource-efficient quantized neural network is implemented as a hardware module and integrated into the multi-legged robot for real-time detection. When a survivor is detected from robots, the corresponding information about GPS and the triangulation localization is thus delivered to the edge server. Then, rescuers can receive the notification message from the edge server by using their mobile devices. For survivor detection, experiments show the drone and the multi-legged robot can achieve 2.164 fps and 2.404 fps, respectively.",https://ieeexplore.ieee.org/document/9524186/,2021 IEEE International Conference on Omni-Layer Intelligent Systems (COINS),23-25 Aug. 2021,ieeexplore
10.1109/IJCNN.2018.8489157,An Embedded Tracking System with Neural Network Accelerator,IEEE,Conferences,"With robots and unmanned aerial vehicles (UAVs) being more and more employed in real-life scenarios for monitoring and surveillance, there is a increasing demand for deploying various video processing applications in mobile systems. However, with limited on-board computational resources and power consumption, the application in this domain requires that the tracking platforms equipped should have outstanding computing power to handle the tasks in real-time with high-accuracy, while at the same time, fit the highly constrained environment of small size, light weight, and low power consumption (SWaP) for the purpose of long-term surveillance. In this paper, we proposed a new autonomous object tracking system based on an embedded platform, leveraging the emerging neural network hardware which is capable of massive parallel pattern recognition processing and demands only a low level power consumption. Further, a prototype of the tracking system that combines a low-power neural network chip, CogniMem, and an embedded development board, BeagleBone, is developed. Our experimental results show that the power consumption for the entire system is only about 2. 25W, which signifies a promising future of applying ultra-low-power neuromorphic hardware as a accelerator in recognition tasks.",https://ieeexplore.ieee.org/document/8489157/,2018 International Joint Conference on Neural Networks (IJCNN),8-13 July 2018,ieeexplore
10.1109/RCAR.2018.8621725,An Image Recognition Approach for Coal and Gangue Used in Pick-Up Robot,IEEE,Conferences,"Picking gangue from raw coal is a crucial step of coal production. Due to the potential for replacing manual workers, the study of pick-up robot is attracting much interest. Pick-up robots usually work in fixed working areas where the types of coals and gangues are unitary. Based on this fact, this paper proposes a simple, fast, and easily implemented approach for coal and gangue classification which is LS-SVM (Least Square Support Vector Machine) based using gray scale and texture as features. We firstly sampled the image dataset from Han City, Shaanxi province and Jizhong, Hebei province which are two main mining areas in China. The data of Han City consists of the images of lean coal and shale, and the data of Jizhong is coking coal and sandstone. By analyzing the gray scale and the texture of the sampled data, we discover that coal and gangue vary in the parameters including the mean and peak of gray scale, contrast ratio, and entropy. Therefore, these four parameters are chosen as features. We utilize LS-SVM as the machine learning model, and the model is trained with three groups of parameters separately. The first are the mean and peak of gray scale, the second are the contrast ratio and entropy which represents texture features, and the third are the peak of gray scale and the contrast ratio which integrates gray scale and texture features. After evaluation by using our sampled dataset, the model trained by the third group outperforms others. The classification results were 98.7% correct of coal and 96.6% correct of gangue for the data of Han city, and 98.6% correct of coal and 96.6% correct of gangue for the data of Jizhong.",https://ieeexplore.ieee.org/document/8621725/,2018 IEEE International Conference on Real-time Computing and Robotics (RCAR),1-5 Aug. 2018,ieeexplore
10.1109/ISSE46696.2019.8984462,An IoT Reconfigurable SoC Platform for Computer Vision Applications,IEEE,Conferences,"The field of Internet of Things (IoT) and smart sensors has expanded rapidly in various fields of research and industrial applications. The area of IoT robotics has become a critical component in the evolution of Industry 4.0 standard. In this paper, we developed an IoT based reconfigurable System on Chip (SoC) robot that is fast and efficient for computer vision applications. It can be deployed in other IoT robotics applications and achieve its intended function. A Terasic Hexapod Spider Robot (TSR) was used with its DE0-Nano SoC board to implement our IoT robotics system. The TSR was designed to provide a competent computer vision application to recognize different shapes using a machine learning classifier. The data processing for image detection was divided into two parts, the first part involves hardware implementation on the SoC board and to provide real-time interaction of the robot with the surrounding environment. The second part of implementation is based on the cloud processing technique, where further data analysis was performed. The image detection algorithm for the computer vision component was tested and successfully implemented to recognize shapes. The TSR moves or reacts based on the detected image. The Field Programmable Gate Array (FPGA) part is programmed to handle the movement of the robot and the Hard Processor System (HPS) handles the shape recognition, Wi-Fi connectivity, and Bluetooth communication. This design is implemented, tested and can be used in real-time applications in harsh environments where movements of other robots are restricted.",https://ieeexplore.ieee.org/document/8984462/,2019 International Symposium on Systems Engineering (ISSE),1-3 Oct. 2019,ieeexplore
10.1109/SoutheastCon42311.2019.9020532,An IoT-based Common Platform Integrating Robots and Virtual Characters for High Performance and Cybersecurity,IEEE,Conferences,"Two humanoid robots are developed. Both robots are human-like in appearance though one is more human-like than the other. A virtual human with human-like appearance is also developed. Various similar functionalities and interaction modalities for the robots and the virtual human are developed. Various technologies are incorporated with them to make them intelligent and autonomous. A common platform in the form of an internet of things (IoT) is developed that can integrate the robots and the virtual human for their real-world collaboration. Then, the collaboration between each robot and the virtual human is separately implemented via the common platform based on some control algorithms for finding a hidden object in a homely environment. The collaboration between the robot and the virtual human is evaluated. The status of cybersecurity in the IoT is briefly analyzed. The results show that the collaboration is satisfactory in various terms, which justify their social integration in the form of an IoT. Two robots with different appearance are actually used to investigate the effects of anthropomorphism on the interaction. The results can help employ artificial intelligent agents of heterogeneous realities to perform real-world tasks through their cooperation in the form of IoT that can provide high performance and cybersecurity.",https://ieeexplore.ieee.org/document/9020532/,2019 SoutheastCon,11-14 April 2019,ieeexplore
10.1109/ICIEV.2012.6317522,An adaptive Neuro-Fuzzy control approach for motion control of a robot arm,IEEE,Conferences,"This paper proposes an adaptive Neuro-Fuzzy control approach for controlling the link variables of a 4 degree-of-freedom Selective Compliant Assembly Robot Arm (SCARA) type robot arm / manipulator. In the real world environment, the mathematical models of many robots are often not accurate, due to the presence of continuous disturbances that effect their dynamic equations, in addition to errors in parameter knowledge. Consequently, method that rely less on precise mathematical models are often preferred. One such Adaptive Machine Learning Technique is proposed to be applied here, for motion control of the robot arm. The controller uses an inverse learning Adaptive Neuro-Fuzzy Inference System (ANFIS) model only to train itself from certain given robot trajectories. Ideally, these trajectories should be obtained by directly measuring the robot arm responses for given inputs to capture the actual dynamics in the presence of all uncertainties. However, for algorithm validation, trajectories generated through simulations based on mathematical models assumed to be reasonably accurate, can also be used for the training purpose. This approach is used for design and implementation of an ANFIS controller which is shown to act work satisfactorily. Further possible developments of this method are also outlined.",https://ieeexplore.ieee.org/document/6317522/,"2012 International Conference on Informatics, Electronics & Vision (ICIEV)",18-19 May 2012,ieeexplore
10.1109/IROS.1991.174539,An approach to on-line obstacle avoidance for robot arms,IEEE,Conferences,"Presents an approach to on-line obstacle avoidance for fixed-base robot manipulators. It guarantees a collision-free path for the robot during real-time operations. This approach is based on analytic geometry and is suitable for continuous path control. Considering the potential collision with obstacles, the next trajectory point to move to is corrected. This strategy is direct formulated in the operational space in which the tasks are described and applicable for two-dimensional as well as for three-dimensional space. Because this algorithm requires no access to joint control, it can be also used for commercial robots given the desired path. One can assign it for various robots, here the implementation for the PUMA 560 is presented as an example.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174539/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/FWC.2017.8368522,An auction based smart service robot implemented on a Fog Computing node,IEEE,Conferences,"Adopting AR/VR technology on smart retail services is gaining more momentum with the progress in indoor map scanning technology and the research on AI deep learning algorithms. In this paper we propose the use of a Fog computing node to generate an AR/VR view of the real store on a web page. The customers can then use the service robot to view the merchandise in the real store via the web and make purchases. Since the service robot is a precious resource on the AR/VR business model, we develop an auction method to optimize the customer satisfaction and the owner satisfaction in terms of customer waiting time and the average number of transactions that are assisted by the service robot respectively. We demonstrate that the auction method is a critical part in the AR/VR smart business services when the number of service robots is much less than the number of active customers from the web and that it performs better than the standard preemptive method.",https://ieeexplore.ieee.org/document/8368522/,2017 IEEE Fog World Congress (FWC),30 Oct.-1 Nov. 2017,ieeexplore
10.1109/ICRAE.2017.8291426,An educational robot system of visual question answering for preschoolers,IEEE,Conferences,"The educational robotics is a novel technology for preschooler's companion and can be used for lower level education. This paper presents an AI-based robot system for achieving educational aims, such as metacognition tutoring and geometrical thinking training, with characteristics of contextual teaching by mining knowledge from the real world directly. For metacognition tutoring in our system, objects in real world are detected and a set of learning materials associated with the objects is presented for learners. For example, when a cat is detected, the robot will teach learners to pronounce the “Cat” in different languages, and more knowledge about cat will be pushed to the learners. For geometrical thinking training, an automatic questioning-and-answering section is employed to engage the learner to think, which is carried by a voice interaction between learners and robots. In our experiment, a set of specific object images are captured to validate the feasibility and efficiency of the proposed system. Our study indicated that the proposed system succeeded in captivating the children and parents in maximizing the children's desire to explore.",https://ieeexplore.ieee.org/document/8291426/,2017 2nd International Conference on Robotics and Automation Engineering (ICRAE),29-31 Dec. 2017,ieeexplore
10.1109/MWSCAS.2014.6908370,An efficient implementation of deep convolutional neural networks on a mobile coprocessor,IEEE,Conferences,"In this paper we present a hardware accelerated real-time implementation of deep convolutional neural networks (DCNNs). DCNNs are becoming popular because of advances in the processing capabilities of general purpose processors. However, DCNNs produce hundreds of intermediate results whose constant memory accesses result in inefficient use of general purpose processor hardware. By using an efficient routing strategy, we are able to maximize utilization of available hardware resources but also obtain high performance in real world applications. Our system, consisting of an ARM Cortex-A9 processor and a coprocessor, is capable of a peak performance of 40 G-ops/s while consuming less than 4W of power. The entire platform is in a small form factor which, combined with its high performance at low power consumption makes it feasible to use this hardware in applications like micro-UAVs, surveillance systems and autonomous robots.",https://ieeexplore.ieee.org/document/6908370/,2014 IEEE 57th International Midwest Symposium on Circuits and Systems (MWSCAS),3-6 Aug. 2014,ieeexplore
10.1109/IROS.2007.4399219,An extended policy gradient algorithm for robot task learning,IEEE,Conferences,"In real-world robotic applications, many factors, both at low-level (e.g., vision and motion control parameters) and at high-level (e.g., the behaviors) determine the quality of the robot performance. Thus, for many tasks, robots require fine tuning of the parameters, in the implementation of behaviors and basic control actions, as well as in strategic decisional processes. In recent years, machine learning techniques have been used to find optimal parameter sets for different behaviors. However, a drawback of learning techniques is time consumption: in practical applications, methods designed for physical robots must be effective with small amounts of data. In this paper, we present a method for concurrent learning of best strategy and optimal parameters, by extending the policy gradient reinforcement learning algorithm. The results of our experimental work in a simulated environment and on a real robot show a very high convergence rate.",https://ieeexplore.ieee.org/document/4399219/,2007 IEEE/RSJ International Conference on Intelligent Robots and Systems,29 Oct.-2 Nov. 2007,ieeexplore
,An incremental behavior learning based on reinforcement learning with schema extraction mechanism for autonomous mobile robot,IEEE,Conferences,"Recently, a number of skillful robots have been developed. However it can so far only demonstrate preprogrammed motions according to external stimuli. In contrast, humans can learn new motions such as catching a ball, in spite of his/her high dimensional sensorimotor DOF. In this learning process, it can be hypothesized that the learner actively constrains the DOF by him/her-self using learning skills, in this paper referred to as schema. In this study, a learning method for autonomous mobile robots operating in unknown environments is proposed, where not only a learning mechanism for sensorimotor mappings but also an extraction/re-use mechanism of the schemata (i.e. constraint rules for learning) is implemented. Through the results of simulations and real experiments of mobile robot navigation, the validity of the proposed method is clarified.",https://ieeexplore.ieee.org/document/1324279/,SICE 2003 Annual Conference (IEEE Cat. No.03TH8734),4-6 Aug. 2003,ieeexplore
10.1109/CIRA.2003.1222155,An incremental learning using schema extraction mechanism for autonomous mobile robot,IEEE,Conferences,"Recently, a number of skillful robots have been developed. One of them can walk and move upstairs just like human beings. However it can so far only demonstrate preprogrammed motions according to the external commands/situations. Therefore autonomous adaptation ability has been highly anticipated. Meanwhile, humans can learn new motions such as catching/kicking a ball, in spite of his/her high dimensional sensorimotor DOF (degree of freedom). In this learning process, it can be hypothesized that the learner actively constrains the DOF by him/her-self using learning skills, in this paper referred to as schema. In this study, a learning method for autonomous mobile robots operating in unknown environments is proposed, where not only a learning mechanism for sensorimotor mappings but also an extraction/re-use mechanism of the schema (i.e. constraint rules for learning) is implemented. Through the results of simulations and real experiments of mobile robot navigation, the validity of the proposed method is clarified.",https://ieeexplore.ieee.org/document/1222155/,Proceedings 2003 IEEE International Symposium on Computational Intelligence in Robotics and Automation. Computational Intelligence in Robotics and Automation for the New Millennium (Cat. No.03EX694),16-20 July 2003,ieeexplore
10.1109/ROBOT.2010.5509935,An insect-based method for learning landmark reliability using expectation reinforcement in dynamic environments,IEEE,Conferences,"Navigation in unknown dynamic environments still remains a major challenge in robotics. Whereas insects like the desert ant with very limited computing and memory capacities solve this task with great efficiency. Thus, the understanding of the underlying neural mechanisms of insect navigation can inform us on how to build simpler yet robust autonomous robots. Based on recent developments in insect neuroethology and cognitive psychology, we propose a method for landmark navigation in dynamic environments. Our method enables the navigator to learn the reliability of landmarks using an expectation reinforcement method. For that end, we implemented a real-time neuronal model based on the Distributed Adaptive Control framework. The results demonstrate that our model is capable of learning the stability of landmarks by reinforcing its expectations. Also, the proposed mechanism allows the navigator to optimally restore its confidence when its expectations are violated. We also perform navigational experiments with real ants to compare with the results of our model. The behavior of the proposed autonomous navigator closely resembles real ant navigational behavior. Moreover, our model explains navigation in dynamic environments as a memory consolidation process, harnessing expectations and their violations.",https://ieeexplore.ieee.org/document/5509935/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/ISESD.2017.8253306,Analysis of artificial intelligence application using back propagation neural network and fuzzy logic controller on wall-following autonomous mobile robot,IEEE,Conferences,"This paper presents a comparison of two methods of artificial intelligence which applied in Wall following Autonomous Mobile Robot; both of them are Neural Network Back propagation and Fuzzy Logic. The robot has three input variables and two output variables. The inputs are distance between the robot and the wall which is sensed by HC-SR04 ultrasonic sensors. The output variables are the speed of the two wheels which is driving by 12 Volt DC motor. In this case mobile robot is designed to avoid the collision with any obstacles like wall or other mobile robots. In this implementation mobile robot is designed with a numbers of ultrasonic sensors and placed on certain position like center front, left front and left back. The sensor will send the data in real time. After being processed, the input produces output in form of speed value governing motor rotation mounted on both wheels of the robot to find the optimum point. In this comparison, both methods Backpropagation Neural Network and Fuzzy Logic are treated the same. Wall following Autonomous Mobile Robot is using Atmega2560 microcontroller. The logic is uploaded to the microcontroller. The result of the comparison of these two methods when applied in Wall-following Autonomous Mobile Robot is the movement of the robot using Neural Network Back propagation is faster than using Fuzzy Logic Controller.",https://ieeexplore.ieee.org/document/8253306/,2017 International Symposium on Electronics and Smart Devices (ISESD),17-19 Oct. 2017,ieeexplore
10.1109/ICRA48506.2021.9561373,Analyzing Neural Jacobian Methods in Applications of Visual Servoing and Kinematic Control,IEEE,Conferences,"Designing adaptable control laws that can transfer between different robots is a challenge because of kinematic and dynamic differences, as well as in scenarios where external sensors are used. In this work, we empirically investigate a neural networks ability to approximate the Jacobian matrix for an application in Cartesian control schemes. Specifically, we are interested in approximating the kinematic Jacobian, which arises from kinematic equations mapping a manipulator’s joint angles to the end-effector’s location. We propose two different approaches to learn the kinematic Jacobian. The first method arises from visual servoing where we learn the kinematic Jacobian as an approximate linear system of equations from the k-nearest neighbors for a desired joint configuration. The second, motivated by forward models in machine learning, learns the kinematic behavior directly and calculates the Jacobian by differentiating the learned neural kinematics model. Simulation experimental results show that both methods achieve better performance than alternative data-driven methods for control, provide closer approximations to the proper kinematics Jacobian matrix, and on average produce better-conditioned Jacobian matrices. Real-world experiments were conducted on a Kinova Gen-3 lightweight robotic manipulator, which includes an uncalibrated visual servoing experiment, a practical application of our methods, as well as a 7-DOF point-to-point task highlighting that our methods are applicable on real robotic manipulators.",https://ieeexplore.ieee.org/document/9561373/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICSMC.2004.1398386,Ant colony optimization based swarms: implementation for the mine detection application,IEEE,Conferences,"Mine detection is a sensitive task confronting the battlefield strategists. There is an ever-increasing demand for proper and sophisticated resources for many issues involved in the task. Traditional practices still involve human force directly in executing the tasks in spite of the advances in technology for tools and implements for the operation [GAO, 2001]. The problem includes various facets inherently: two of the prominent issues are location of mines over a minefield and secondly removal of the mines once located [GAO, 2001]. These two issues are not totally independent as technology used for one can directly or indirectly affect the other. Developments in artificial intelligence, natural heuristics, computational optimization and robotics have endowed us with the ability to realize unmanned robots (or robot like vehicles) that work intelligently on a real time basis in attempting at the problem of mine detection. In this paper we focus on the algorithms developed using ant colony optimization based approaches to the mine detection application and its implementation on a real-time basis. We focus on certain optimization techniques that could be used for effective realization of the algorithm. Generic groundscout robots had been already built at the MABL, RIT [Sahin F. et al., 2003]. These robots have been used to demonstrate the implementation",https://ieeexplore.ieee.org/document/1398386/,"2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)",10-13 Oct. 2004,ieeexplore
10.1109/ICC.2018.8422231,Anticipatory Mobility Management by Big Data Analytics for Ultra-Low Latency Mobile Networking,IEEE,Conferences,"Massive deployment of autonomous vehicles, un- manned aerial vehicles, and robots, brings in a new technology challenge to establish ultra-low end-to-end latency mobile networking to enable holistic computing mechanisms. With the aid of open-loop wireless communication and proactive network association in vehicle-centric heterogeneous network architecture, anticipatory mobility management relying on inference and learning from big vehicular data plays a key role to facilitate such a new technological paradigm. Anticipatory mobility management aims to predict APs to be connected in the next time instant and in a real-time manner, such that ultra-low latency downlink open-loop communication can be realized with proactive network association. In this paper, we successfully respond this technology challenge using big data analytics with location-based learning and inference tech- niques, to achieve satisfactory performance of predicting APs. Real vehicular movement data have been used to verify that the proposed prediction methods are effective for the purpose of anticipatory mobility management and thus ultra-low latency mobile networking.",https://ieeexplore.ieee.org/document/8422231/,2018 IEEE International Conference on Communications (ICC),20-24 May 2018,ieeexplore
10.1109/ICACTE.2010.5579484,Applicability of feature selection on multivariate time series data for robotic discovery,IEEE,Conferences,"Open ended robotic discovery aims at enabling robots to autonomously design and execute sophisticated experiments for gaining conceptual insight about real world. Such experiments are planned activities rather than innate motor commands and thus each single experiment results in a multivariate time series. In such a scenario, reducing the number of features in order to allow a symbolic learner to build a correct conceptual model of underlying phenomena is a fundamental task. Only few feature selection approaches deal with finding relevant features in multivariate time series, which is just what the robot receives through its sensors. In this paper, we present results of applicability of a range of feature selection and time series analysis approaches on a novel real world scenario for autonomous robotic discovery. We found that even sophisticated representations and state of the art techniques, which perform very well on other benchmarks, do not show significant results in context of open ended discovery.",https://ieeexplore.ieee.org/document/5579484/,2010 3rd International Conference on Advanced Computer Theory and Engineering(ICACTE),20-22 Aug. 2010,ieeexplore
10.1109/ACIT47987.2019.8991028,Application of Fuzzy Neural Networks in Robotic Path Planning,IEEE,Conferences,This paper essentially discusses different methodologies of Fuzzy Neural Networks which are implemented to robust the functionality of mobile robots in dynamic and static environment. Fusion of algorithms is important to increase the working of any system provided. Different kind of mobile robots along with various algorithms frameworks are taken as case studies for this paper. Due to the reason that typical mathematical models used to make robots mobile in real environment were not very useful as they were not catering for the limitation of robotic system memory. Thus new methodologies are being discussed and implemented by robotics research community.,https://ieeexplore.ieee.org/document/8991028/,2019 International Arab Conference on Information Technology (ACIT),3-5 Dec. 2019,ieeexplore
10.1109/ICEKIM52309.2021.00040,Application of Teaching Innovation Based on robotics engineering,IEEE,Conferences,"As the core major of “Internet + Industrial Intelligence”, robotics engineering is an upgrade and reconstruction of traditional engineering major. The industrial robot course is the professional core course of the Robotics Engineering. It is also a comprehensive course of multi-discipline integration, which involved mechanical engineering, automatic control, computer, sensor, electronic technology, artificial intelligence and other multi-disciplinary content. Robotics Engineering is characterized by broad foundation, great difficulty, emphasis on practice, rapid development and application of new knowledge. In the process of implementation of the teaching innovation, the new concept of engineering education was applied to propose a new form of curriculum system. Taking the projects of engineering as the study objects, disassemble the knowledge points involved in industrial robots, break the course boundaries, reshape the knowledge system, draw knowledge maps and then design teaching activities. In teaching innovation, teachers extend classroom through formation of subject competition teams, promote teaching and promote learning by competition, realize the integration of “teaching, class and competition”, build a bridge between theory and practice, then complete the transformation from knowledge learning to ability training. Besides, they also keep contact with intelligent manufacturing enterprises in Zhuhai and the Bay Area to obtain real-time new developments in enterprises. Thus, the latest information was introduced into classroom. Therefore, the meaning of “production, teaching, research and application” has been deepened. According to the characteristics of the knowledge points of the course, experts were invited to make special lectures for students which can bring them with international perspective and frontier knowledge.",https://ieeexplore.ieee.org/document/9479656/,"2021 2nd International Conference on Education, Knowledge and Information Management (ICEKIM)",29-31 Jan. 2021,ieeexplore
10.1109/CYBER53097.2021.9588269,Application of YOLO Object Detection Network In Weld Surface Defect Detection,IEEE,Conferences,"As industrial production becomes more modern and intelligent today, the inspection of product quality of the workshop is becoming more and more accustomed to replacing the old manual visual inspection methods with automated inspection systems. In the welding field, automated welding robots are not only used in traditional large-scale automobile assembly lines. In more general welding work, welding robots also plays an important role. The inspection of the welding quality of the welding robot is mainly to detect the four main types of weld defects. Compared to traditional defect classification based on support vector machines and defect detection based on template matching, this paper uses a welding surface defect detection system designed based on deep learning methods. By working with workshop welding experts, a large-scale image of nearly 5000 pictures is built. Large-scale weld defect datasets, while using the real-time and accuracy of the YOLO series of deep learning object detection frameworks, the weld defects detection model reaches 75.5% mean average precision(mAP) in constructed weld defect data set. In addition, the construction cost of the detection model and the deployment time of the detection system are greatly reduced. During the field test of the system in the workshop, among a batch of welding workpieces provided by the factory, the detection accuracy of weld defects reached 71%, which initially met the requirements of the workshop for an automated defect detection system.",https://ieeexplore.ieee.org/document/9588269/,"2021 IEEE 11th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)",27-31 July 2021,ieeexplore
10.1109/IROS45743.2020.9341340,Applying Surface Normal Information in Drivable Area and Road Anomaly Detection for Ground Mobile Robots,IEEE,Conferences,"The joint detection of drivable areas and road anomalies is a crucial task for ground mobile robots. In recent years, many impressive semantic segmentation networks, which can be used for pixel-level drivable area and road anomaly detection, have been developed. However, the detection accuracy still needs improvement. Therefore, we develop a novel module named the Normal Inference Module (NIM), which can generate surface normal information from dense depth images with high accuracy and efficiency. Our NIM can be deployed in existing convolutional neural networks (CNNs) to refine the segmentation performance. To evaluate the effectiveness and robustness of our NIM, we embed it in twelve state-of-the-art CNNs. The experimental results illustrate that our NIM can greatly improve the performance of the CNNs for drivable area and road anomaly detection. Furthermore, our proposed NIM-RTFNet ranks 8th on the KITTI road benchmark and exhibits a real-time inference speed.",https://ieeexplore.ieee.org/document/9341340/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/IJCNN.2015.7280807,Applying the canonical distributed Embodied Evolution algorithm in a collective indoor navigation task,IEEE,Conferences,"The automatic design of control systems for multi-robot teams that operate in real time is not affordable with traditional evolutionary algorithms mainly due to the huge computational requirements they imply. Embodied Evolution (EE) is an evolutionary paradigm that aims to address this problem through the embodiment of the individuals that make up the population in the physical robots. The interest for this type of evolutionary approach has been increasing steadily, leading to different algorithms and variations adapted to solve very specific practical cases. In a previous work, the authors started the implementation of a standard canonical EE algorithm that captures the more general principles of this paradigm and that can be applied to any distributed optimization problem. This canonical algorithm has been characterized already over a set of theoretical fitness landscapes corresponding to representative examples of the basic casuistry found in collective tasks. The current paper goes one step ahead in this research line, and the canonical algorithm is applied here in a collective navigation task in which a fleet of Micro Aerial Vehicles (MAVs) has to gather red rocks in an indoor scenario. The objective is to confirm that the characterization conclusions are generalizable to a practical case and to show that the canonical algorithm can be configured to operate as a specific algorithm easily.",https://ieeexplore.ieee.org/document/7280807/,2015 International Joint Conference on Neural Networks (IJCNN),12-17 July 2015,ieeexplore
10.1109/SAHCN.2014.6990347,Area coverage under low sensor density,IEEE,Conferences,"This paper presents a solution to the problem of monitoring a region of interest (RoI) using a set of nodes that is not sufficient to achieve the required degree of monitoring coverage. In particular, sensing coverage of wireless sensor networks (WSNs) is a crucial issue in projects due to failure of sensors. This scenario of limited funding hinders the traditional method of using mobile robots to move around the RoI to collect readings. Instead, our solution employs supervised neural networks to produce the values of the uncovered locations by extracting the non-linear relation among randomly deployed sensor nodes throughout the area. Moreover, we apply a hybrid backpropagation method to accelerate the learning convergence speed to a local minimum solution. We use a real-world data set from meteorological deployment for experimental validation and analysis.",https://ieeexplore.ieee.org/document/6990347/,"2014 Eleventh Annual IEEE International Conference on Sensing, Communication, and Networking (SECON)",30 June-3 July 2014,ieeexplore
10.1109/ICMLA.2019.00099,Asynchronous Multitask Reinforcement Learning with Dropout for Continuous Control,IEEE,Conferences,"Deep reinforcement learning is sample inefficient for solving complex tasks. Recently, multitask reinforcement learning has received increased attention because of its ability to learn general policies with improved sample efficiency. In multitask reinforcement learning, a single agent must learn multiple related tasks, either sequentially or simultaneously. Based on the DDPG algorithm, this paper presents Asyn-DDPG, which asynchronously learns a multitask policy for continuous control with simultaneous worker agents. We empirically found that sparse policy gradients can significantly reduce interference among conflicting tasks and make multitask learning more stable and sample efficient. To ensure the sparsity of gradients evaluated for each task, Asyn-DDPG represents both actor and critic functions as deep neural networks and regularizes them using Dropout. During training, worker agents share the actor and the critic functions, and asynchronously optimize them using task-specific gradients. For evaluating Asyn-DDPG, we proposed robotic navigation tasks based on realistically simulated robots and physics-enabled maze-like environments. Although the number of tasks used in our experiment is small, each task is conducted based on a real-world setting and posts a challenging environment. Through extensive evaluation, we demonstrate that Dropout regularization can effectively stabilize asynchronous learning and enable Asyn-DDPG to outperform DDPG significantly. Also, Asyn-DDPG was able to learn a multitask policy that can be well generalized for handling environments unseen during training.",https://ieeexplore.ieee.org/document/8999228/,2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA),16-19 Dec. 2019,ieeexplore
10.1109/ICRA.2018.8462967,Auctioning over Probabilistic Options for Temporal Logic-Based Multi-Robot Cooperation Under Uncertainty,IEEE,Conferences,"Coordinating a team of robots to fulfill a common task is still a demanding problem. This is even more the case when considering uncertainty in the environment, as well as temporal dependencies within the task specification. A multi-robot cooperation from a single goal specification requires mechanisms for decomposing the goal as well as an efficient planning for the team. However, planning action sequences offline is insufficient in real world applications. Rather, due to uncertainties, the robots also need to closely coordinate during execution and adjust their policies when additional observations are made. The framework presented in this paper enables the robot team to cooperatively fulfill tasks given as temporal logic specifications while explicitly considering uncertainty and incorporating observations during execution. We present the effectiveness of our ROS implementation of this approach in a case study scenario.",https://ieeexplore.ieee.org/document/8462967/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/AIVR46125.2019.00061,Augmented Reality for Human-Robot Cooperation in Aircraft Assembly,IEEE,Conferences,"Augmented Reality (AR) is often discussed as one of the enabling technologies in Industrie 4.0. In this paper, we describe a practical application, where Augmented Reality glasses are used not only for assembly assistance, but also as a means of communication to enable the orchestration of a hybrid team consisting of a human worker and two mobile robotic systems. The task of the hybrid team is to rivet so-called stringers onto an aircraft hull. While the two robots do the physically demanding, unergonomic and possibly hazardous tasks (squeezing and sealing rivets), the human takes over those responsibilities that need experience, multi-sensory sensitiveness and specialist knowledge. We describe the working scenario, the overall architecture and give design and implementation details on the AR application.",https://ieeexplore.ieee.org/document/8942239/,2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),9-11 Dec. 2019,ieeexplore
10.23919/MIPRO52101.2021.9597142,Automated Robot Control for a Game of Chess in Unity Game Engine through Artificial Intelligence,IEEE,Conferences,"The topic of this paper is to study the possibility of using Unity game development engine for robot control. The aim of the work is to create a virtual environment in which the game of chess is simulated, through a duel of two robots controlled by artificial intelligence. As part of the work, real robot models were implemented in the Unity game engine. The simulated robots were ABB's IRB-120 arms with two joints. The movement of the robot is fully simulated within the physics simulation in the Unity system. The Forward and Backward Reaching Inverse Kinematics (FABRIK) algorithm was used for the inverse kinematics algorithm. For calculating the next move, external artificial intelligence library Stockfish was used and integrated with the Unity game engine. The final application has automated moves between the robots, has the option of a simple change of the viewpoint through camera movement, and is intended to be used in future work for the control of a real robot.",https://ieeexplore.ieee.org/document/9597142/,"2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO)",27 Sept.-1 Oct. 2021,ieeexplore
10.1109/ICICIC.2009.121,Automatic Path Search for Roving Robot Using Reinforcement Learning,IEEE,Conferences,"Rapid advances in robot technology have been made in recent years. In connection with these advances, robots are expected to be utilized in a variety of places and environments. This study describes, (1) a method which allows a robot to measure the location of its destination in the real world based on an image obtained from a single camera, and (2) a method of navigating a robot to a destination which is selected by a user on a display showing the forward robot view. Consideration is also given to cases in which there are obstacles between the robot and the destination. Through the use of reinforcement learning, which is considered a promising candidate among autonomous control techniques, the roving robot tries to find the shortest way to the destination based on information concerning the locations of obstacles and the destination. This study also describes an image-based method of measuring a selected location, the results from a simulation of path finding using reinforcement learning, and the results from an experiment of navigation in a real environment. Finally, a summary of the main conclusions is provided.",https://ieeexplore.ieee.org/document/5412489/,"2009 Fourth International Conference on Innovative Computing, Information and Control (ICICIC)",7-9 Dec. 2009,ieeexplore
10.1109/AHS.2007.37,Automatic Synthesis of Fault Detection Modules for Mobile Robots,IEEE,Conferences,"In this paper, we present a new approach for automatic synthesis of fault detection modules for autonomous mobile robots. The method relies on the fact that hardware faults typically change the flow of sensory perceptions received by the robot and the subsequent behavior of the control program. We collect data from three experiments with real robots. In each experiment, we record all sensory inputs from the robots while they are operating normally and after software-simulated faults have been injected. We use back- propagation neural networks to synthesize task-dependent fault detection modules. The performance of the modules is evaluated in terms of false positives and latency.",https://ieeexplore.ieee.org/document/4291986/,Second NASA/ESA Conference on Adaptive Hardware and Systems (AHS 2007),5-8 Aug. 2007,ieeexplore
10.1109/IEEECONF38699.2020.9389377,Automatic in-situ instance and semantic segmentation of planktonic organisms using Mask R-CNN,IEEE,Conferences,"Planktonic organisms form the principal source for consumers on higher trophic levels in the food chain. Studying their community dispersion is vital to our understanding of the planet's ecological systems. With the recent technological advancements in imaging systems, capturing images of planktons in-situ is made possible by embedding mobile underwater robots with sophisticated camera systems and computing power that implement deep machine learning approaches. Efforts of applying deep learning methods to plankton imaging systems have been limited to classification, while detection and segmentation has been left to traditional methods in this context. There is a variety of publicly available datasets made suited for planktonic species classification. These datasets consist of images of individual species. Thus, they do not represent the actual environment, which is usually given by a scene representation more suited for object localization, detection and semantic segmentation. In this paper we propose a novel custom dataset [1] from planktonic images captured in-situ in a lab environment suited for supervised learning of object detection and instance segmentation. The data is tested in experiments using the state-of-the-art deep learning visual recognition method of Mask R-CNN. The experiment results show the potential of this method and create a baseline analysis module for real-time in-situ image processing. We provide a comparison of how the method is performing when trained on automatically processed and annotated images from existing segmentation frameworks using traditional methods. This comparison illustrates the importance of utilizing proper data and the potential for success if provided<sup>11</sup>All results, code and metrics used for the experiments are provided in: https://github.com/AILARON/Segmentation",https://ieeexplore.ieee.org/document/9389377/,Global Oceans 2020: Singapore – U.S. Gulf Coast,5-30 Oct. 2020,ieeexplore
10.1109/ICIT.2018.8352157,Automatic parameter learning for easy instruction of industrial collaborative robots,IEEE,Conferences,"The manufacturing industry faces challenges in meeting requirements of flexibility, product variability and small batch sizes. Automation of high mix, low volume productions requires faster (re)configuration of manufacturing equipment. These demands are to some extend accommodated by collaborative robots. Certain actions can still be hard or impossible to manually adjust due to inherent process uncertainties. This paper proposes a generic iteratively learning approach based on Bayesian Optimisation to efficiently search for the optimal set of process parameters. The approach takes into account the process uncertainties by iteratively making a statistical founded choice on the next parameter-set to examine only based on the prior binomial outcomes. Moreover, our function estimator uses Wilson Score to make proper estimates on the success probability and the associated uncertain measure of sparsely sampled regions. The function estimator also generalises the experiment outcomes to the neighbour region through kernel smoothing by integrating Kernel Density Estimation. Our approach is applied to a real industrial task with significant process uncertainties, where sufficiently robust process parameters cannot intuitively be chosen. Using our approach, a collaborative robot automatically finds a reliable solution.",https://ieeexplore.ieee.org/document/8352157/,2018 IEEE International Conference on Industrial Technology (ICIT),20-22 Feb. 2018,ieeexplore
10.1109/ICAC.2004.1301379,Autonomic systems for mobile robots,IEEE,Conferences,"Mobile robots are an excellent testbed for autonomic computing research. The ultimate goal of robotics research is to develop a platform that can function autonomously in the face of hardware and software failures. This goal is becoming more important as robots are increasingly being deployed outside of controlled environments. In this paper, we discuss our work toward implementing an autonomic system for a mobile robot. This work is motivated by our experiences with existing mobile robot control software during real-world deployments.",https://ieeexplore.ieee.org/document/1301379/,"International Conference on Autonomic Computing, 2004. Proceedings.",17-18 May 2004,ieeexplore
10.1109/ECMR.2019.8870908,Autonomous Robots as Actors in Robotics Theatre - Tribute to the Centenary of R.U.R.,IEEE,Conferences,"In the eyes of the roboticists, the play R.U.R. (Rossum's Universal Robots) of Czech writer Karel Čapek is seen as the messenger of the new robot age. R.U.R. is renown for the first mentioning of the word robot for a humanoid machine that looks, moves, feels, thinks and works like a human. Inspired by the 100th anniversary of R.U.R. in 2020, we have decided to make a performance with Pepper and NAO humanoid robots acting together with human actors. Performing in a theatrical performance is very demanding even for human actors, so we see the implementation of R.U.R. with robotic co-actors as a real challenge. For this purpose, we have analyzed human-robot and robot-robot interaction in the R.U.R. script to evaluate whether NAO and Pepper robots that we have are apt to act autonomously. Due to specific robot deficiencies that we found, we have made the robot casting first and then adapted the R.U.R. script to enable Pepper and NAO robots to perform their roles.",https://ieeexplore.ieee.org/document/8870908/,2019 European Conference on Mobile Robots (ECMR),4-6 Sept. 2019,ieeexplore
10.1109/AMS.2017.22,Autonomous Rover Navigation Using GPS Based Path Planning,IEEE,Conferences,"Nowadays, with the constant evolution of Artificial Intelligence and Machine Learning, robots are getting more perceptive than ever. For this quality they are being used in varying circumstances which humans cannot control. Rovers are special robots, capable of traversing through areas that are too difficult for humans. Even though it is a robust bot, lack of proper intelligence and automation are its basic shortcomings. As the main purpose of a rover is to traverse through areas of extreme difficulties, therefore an intelligent path generation and following system is highly required. Our research work aimed at developing an algorithm for autonomous path generation using GPS (Global Positioning System) based coordinate system and implementation of this algorithm in real life terrain, which in our case is MDRS, Utah, USA. Our prime focus was the development of a robust but easy to implement system. After developing such system, we have been able to successfully traverse our rover through that difficult terrain. It uses GPS coordinates of target points that will be fed into the rover from a control station. The rover capturing its own GPS signal generates a path between the current location and the destination location on its own. It then finds the deviation in its current course of direction and position. And eventually it uses Proportional Integral Derivative control loop feedback mechanism (PID control algorithm) for compensating the error or deviation and thus following that path and reach destination. A low cost on board computer (Raspberry Pi in our case) handles all the calculations during the process and drives the rover fulfilling its task using an microcontroller (Arduino).",https://ieeexplore.ieee.org/document/8424312/,2017 Asia Modelling Symposium (AMS),4-6 Dec. 2017,ieeexplore
10.1109/ROBOT.2009.5152365,Autonomous driving in a multi-level parking structure,IEEE,Conferences,"Recently, the problem of autonomous navigation of automobiles has gained substantial interest in the robotics community. Especially during the two recent DARPA grand challenges, autonomous cars have been shown to robustly navigate over extended periods of time through complex desert courses or through dynamic urban traffic environments. In these tasks, the robots typically relied on GPS traces to follow pre-defined trajectories so that only local planners were required. In this paper, we present an approach for autonomous navigation of cars in indoor structures such as parking garages. Our approach utilizes multi-level surface maps of the corresponding environments to calculate the path of the vehicle and to localize it based on laser data in the absence of sufficiently accurate GPS information. It furthermore utilizes a local path planner for controlling the vehicle. In a practical experiment carried out with an autonomous car in a real parking garage we demonstrate that our approach allows the car to autonomously park itself in a large-scale multi-level structure.",https://ieeexplore.ieee.org/document/5152365/,2009 IEEE International Conference on Robotics and Automation,12-17 May 2009,ieeexplore
10.1109/ICRA.2011.5980435,Autonomous learning of vision-based layered object models on mobile robots,IEEE,Conferences,"Although mobile robots are increasingly being used in real-world applications, the ability to robustly sense and interact with the environment is still missing. A key requirement for the widespread deployment of mobile robots is the ability to operate autonomously by learning desired environmental models and revising the learned models in response to environmental changes. This paper presents an approach that enables a mobile robot to autonomously learn layered models for environmental objects using temporal, local and global visual cues. A temporal assessment of image gradient features is used to detect candidate objects, which are then modeled using color distribution statistics and a spatial representation of gradient features. The robot incrementally revises the learned models and uses them for object recognition and tracking based on a matching scheme comprising a spatial similarity measure and second order distribution statistics. All algorithms are implemented and tested on a wheeled robot platform in dynamic indoor environments.",https://ieeexplore.ieee.org/document/5980435/,2011 IEEE International Conference on Robotics and Automation,9-13 May 2011,ieeexplore
10.1109/IES53407.2021.9594013,Ball Position Transformation with Artificial Intelligence Based on Tensorflow Libraries,IEEE,Conferences,Research on wheeled soccer robots has been carried out by several researchers. This is due to the existence of national and international competitions. Previous research was to create a ball position transformation system with a modified method of neural network architecture. This research was developed by building an intelligent transformation system with the Tensorflow library. This transformation system aims to be able to directly measure the distance of objects in real terms without first changing the environmental image from an omni field to a flat plane with conventional camera calibration techniques. This process can replace manual calibration with a variety of field size changes The system can transform with mean error 0.0000026 on epoch 10000 using “conda-tensorflowneural network” libraries. It can transform the position of the ball from the omni space to the cartesian space. This system was implemented on wheeled soccer robot as keeper.,https://ieeexplore.ieee.org/document/9594013/,2021 International Electronics Symposium (IES),29-30 Sept. 2021,ieeexplore
10.1109/IJCNN.2016.7727848,Bayesian perception of touch for control of robot emotion,IEEE,Conferences,"In this paper, we present a Bayesian approach for perception of touch and control of robot emotion. Touch is an important sensing modality for the development of social robots, and it is used in this work as stimulus through a human-robot interaction. A Bayesian framework is proposed for perception of various types of touch. This method together with a sequential analysis approach allow the robot to accumulate evidence from the interaction with humans to achieve accurate touch perception for adaptable control of robot emotions. Facial expressions are used to represent the emotions of the iCub humanoid. Emotions in the robotic platform, based on facial expressions, are handled by a control architecture that works with the output from the touch perception process. We validate the accuracy of our system with simulated and real robot touch experiments. Results from this work show that our method is suitable and accurate for perception of touch to control robot emotions, which is essential for the development of sociable robots.",https://ieeexplore.ieee.org/document/7727848/,2016 International Joint Conference on Neural Networks (IJCNN),24-29 July 2016,ieeexplore
10.1109/ROMOCO.2001.973435,"Behavior learning to predict using neural networks (NN): Ttowards a fast, cooperative and adversarial robot team (RoboCup)",IEEE,Conferences,"To build a fast, cooperative and adversarial robot team (RoboCup), prediction behaviors became necessary. In the paper, a behavior learning method using neural networks (NN) is developed to enhance the behavior of GMD mobile robots. In fact, the suggested NN called NN-Prediction learns to predict successfulness of the elementary behavior ""Kick"" the ball towards the goal in order to act as consequence. The training is carried out by the supervised gradient back-propagation learning paradigm. This NN-Prediction has been specified on the Dual Dynamics Designer, to be thereafter implemented and tested on both the Dual Dynamics Simulator and GMD mobile robots, and analyzed on the Real-Time Trace Tool. NN-prediction demonstrated, during the 4/sup th/ World Championships RoboCup 2000, cooperative and adversarial behaviors especially face to situations where the successfulness of ""Kick"" is not guaranteed. Then, a discussion is given dealing with the suggested prediction behavior and how it relates to some other works.",https://ieeexplore.ieee.org/document/973435/,Proceedings of the Second International Workshop on Robot Motion and Control. RoMoCo'01 (IEEE Cat. No.01EX535),20-20 Oct. 2001,ieeexplore
10.1109/SSCI.2018.8628809,Bidirectional Fuzzy Brain Emotional Learning Control for Aerial Robots,IEEE,Conferences,This paper proposes a Bidirectional Fuzzy Brain Emotional Learning (BFBEL) control system to control Aerial Robots. The proposed controller is based on the emotional and logical processing of the brain. The proposed control system merges fuzzy inference and a bidirectional brain emotional learning algorithm. The Bidirectional Fuzzy Brain Emotional Learning (BFBEL) control can learn from scratch and adapt rapidly in real-time to control the system without much prior information. The proposed controller is tested against simulations of both a 1-Degree-Of-Freedom (DOF) flapping wing and a 6DOF flapping wing model and successfully implemented on a 1DOF flapping wing experiment which showcases the learning and adaptation capability in a real-time environment.,https://ieeexplore.ieee.org/document/8628809/,2018 IEEE Symposium Series on Computational Intelligence (SSCI),18-21 Nov. 2018,ieeexplore
10.1109/IJCNN.2008.4633875,Bio-inspired stochastic chance-constrained multi-robot task allocation using WSN,IEEE,Conferences,"The multi-robot task allocation (MRTA) especially in unknown complex environment is one of the fundamental problems, a mostly important object in research of multi-robot. The MRTA problem is initially formulated as a chance-constrained optimization problem. Monte Carlo simulation is used to verify the accuracy of the solution provided by the algorithm. Ant colony optimization (ACO) algorithm based on bionic swarm intelligence was used. A hybrid intelligent algorithm combined Monte Carlo simulation and neural network is used for solving stochastic chance constrained models of MRTA. A practical implementation with real WSN and real mobile robots were carried out. In environment the successful implementation of tasks without collision validates the efficiency, stability and accuracy of the proposed algorithm. The convergence curve shows that as iterative generation grows, the utility increases and finally reaches a stable and optimal value. Results show that using sensor information fusion can greatly improve the efficiency. The algorithm is proved better than tradition algorithms without WSN for MRTA in real time.",https://ieeexplore.ieee.org/document/4633875/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/IROS.2004.1389400,Biologically inspired optimal robot arm control with signal-dependent noise,IEEE,Conferences,"Progress in the field of humanoid robotics and the need to find simpler ways to program such robots has prompted research into computational models for robotic learning from human demonstration. To further investigate biologically inspired human-like robotic movement and imitation, we have constructed a framework based on three key features of human movement and planning: optimality, modularity and learning. In this paper we focus on the application of optimality principles to the production of human-like movement by a robot arm. Among computational theories of human movement, the signal-dependent noise, or minimum variance, model was chosen as a biologically realistic control scheme to produce human-like movement. A well known optimal control algorithm, the linear quadratic regulator, was adapted to implement this model. The scheme was applied both in simulation and on a real robot arm, which demonstrated human-like movement profiles in a point-to-point reaching experiment.",https://ieeexplore.ieee.org/document/1389400/,2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),28 Sept.-2 Oct. 2004,ieeexplore
10.1109/IECON.2007.4460382,Biomimetics Robots From Bio-inspiration to Implementation,IEEE,Conferences,"Biomimetics focuses on making nature as a model of inspiration that would immensely help conscious abstraction of new principles and ideas, foster innovative design collections, find out new techniques and functionalities, seek new paradigms and methods, develop new materials, and design new streams of intelligent machines, robots, systems, devices, algorithms, etc. Biomimetics incorporates materials, concepts and techniques drawn from naturally made substances, and resembles biological systems in structure, mechanism and/or function as necessary. Smart materials are the foundation supporting the development of new biomimetic based technology. Wide range of biologically inspired robots and intelligent systems has been developed. However, engineering such biomimetic intelligent creatures were hampered by physical and technological constraints, and it is still a challenge. Making robots and intelligent machines that are actuated by biologically inspired artificial muscles would create new reality with great potentials. This paper provides the concept and the importance of Biomimetic as an interdisciplinary field. In addition, the paper introduces and discusses scientific ideas and directions of research activities in the field. The paper presents key development in the field of Biomimetic robots, and finally it underlines the potential of the field and the challenges facing it.",https://ieeexplore.ieee.org/document/4460382/,IECON 2007 - 33rd Annual Conference of the IEEE Industrial Electronics Society,5-8 Nov. 2007,ieeexplore
10.1109/ROMAN.2017.8172296,Blame my telepresence robot joint effect of proxemics and attribution on interpersonal attraction,IEEE,Conferences,"When remote users share autonomy with a telepresence robot, questions arise as to how the behaviour of the robot is interpreted by local users. We investigated how a robot's violations of social norms under shared autonomy influence the local user's evaluation of the robot's remote users. Specifically, we examined how attribution of such violations to either the robot or the remote user influences social perception of the remote user. Using personal space invasion as a salient social norm violation, we conducted a within-subject experiment (n=20) to investigate these questions. Participants saw several people introducing themselves through a telepresence robot, personal space invasion and attribution were manipulated. We found a significant (p=0.007) joint effect of the manipulations on interpersonal attraction. After these first 20 participants our robot broke down, and we had to continue with another robot (n=20). We found a difference between the two robots, causing us to discard this data from our main analysis. Subsequent video annotation and comparison of the two robots suggests that accuracy of the followed trajectory modifies attribution. Our results offer insights into the mechanisms of attribution in interactions with a telepresence robot as a mediator.",https://ieeexplore.ieee.org/document/8172296/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/ICRA.2019.8793510,Bonnet: An Open-Source Training and Deployment Framework for Semantic Segmentation in Robotics using CNNs,IEEE,Conferences,"The ability to interpret a scene is an important capability for a robot that is supposed to interact with its environment. The knowledge of what is in front of the robot is, for example, relevant for navigation, manipulation, or planning. Semantic segmentation labels each pixel of an image with a class label and thus provides a detailed semantic annotation of the surroundings to the robot. Convolutional neural networks (CNNs) are popular methods for addressing this type of problem. The available software for training and the integration of CNNs for real robots, however, is quite fragmented and often difficult to use for non-experts, despite the availability of several high-quality open-source frameworks for neural network implementation and training. In this paper, we propose a tool called Bonnet, which addresses this fragmentation problem by building a higher abstraction that is specific for the semantic segmentation task. It provides a modular approach to simplify the training of a semantic segmentation CNN independently of the used dataset and the intended task. Furthermore, we also address the deployment on a real robotic platform. Thus, we do not propose a new CNN approach in this paper. Instead, we provide a stable and easy-to-use tool to make this technology more approachable in the context of autonomous systems. In this sense, we aim at closing a gap between computer vision research and its use in robotics research. We provide an open-source codebase for training and deployment. The training interface is implemented in Python using TensorFlow and the deployment interface provides C++ library that can be easily integrated in an existing robotics codebase, a ROS node, and two standalone applications for label prediction in images and videos.",https://ieeexplore.ieee.org/document/8793510/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/AIM.2019.8868855,Brain-robot Shared Control Based on Motor Imagery and Improved Bayes Filter<sup>*</sup>,IEEE,Conferences,"Brain-controlled robots are an innovative means of interacting and can also provide new solutions for disabled and stroke patients to communicate with the outside world. Since the poor real-time performance and poor accuracy of brain-computer interface (BCI) is not precise to control the robot directly, in order to avoid damage to the robot and humans in the process, this paper designs a brain-robot shared control system based on brain-computer interface. The motion direction of the robot controlled via four types of motor imagery (MI) signals. Feature extraction of MI signals is performed using common space pattern (CSP) combined with local characteristic-scale decomposition (LCD). The classification results are obtained with the appropriate features processed by the spectral regression discriminant analysis (SRDA) classifier. The Bayes filter algorithm is used to implement the robot shared control method, the belief of the robot's motion direction is calculated, and then the control ratio of the robot's autonomous motion and the BCI are assigned automatically. Considering that each control instruction given by BCI cost at least 1.5 seconds. To achieve better control effect at the interval between two instructions, the relationship with two steps of Bayes filter is redesigned, even if a new control data is not received, the robot will continuously update the measurement according to the previous control data, assign a new control ratio and execute the corresponding instruction, so that the robot can continuously adjust the movement intention and proportion during the instruction interval of BCI. The control effect was verified by online experiments. Using the improved Bayes filter algorithm, the success rate of the experiment is greatly improved, and the number of instructions used in single trial is reduced by 50%.",https://ieeexplore.ieee.org/document/8868855/,2019 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM),8-12 July 2019,ieeexplore
10.1109/CASE49439.2021.9551562,Building Skill Learning Systems for Robotics,IEEE,Conferences,"Skill-generating policies have enabled robots to perform a wide range of applications as for example assembly tasks. However, the manual engineering effort for such policies is fairly high and the environment is frequently required to be rather deterministic. For expanding robot deployment to low-volume manufacturing two challenges need to be addressed. First, the robot should acquire the skill-generating policy not from a robot programmer but rather from an expert on the task and second, the robot needs to be able to operate in unstructured environments. In this paper we present a learning approach that combines imitation learning and reinforcement learning to provide a tool for intuitive task teaching followed by self-optimization of the system. The presented approach is applied to a dual-arm assembly task using a real robot and appropriate simulation models. Whereas pure imitation learning does not result in an acceptable success rate for the considered example, after 400 episodes of reinforcement learning the robot can successfully solve the assembly task.",https://ieeexplore.ieee.org/document/9551562/,2021 IEEE 17th International Conference on Automation Science and Engineering (CASE),23-27 Aug. 2021,ieeexplore
10.1109/HUMANOIDS.2014.7041490,Can active impedance protect robots from landing impact?,IEEE,Conferences,"This paper studies the effect of passive and active impedance for protecting jumping robots from landing impacts. The theory of force transmissibility is used for selecting the passive impedance of the system to minimize the shock propagation. The active impedance is regulated online by a joint-level controller. On top of this controller, a reflex-based leg retraction scheme is implemented which is optimized using direct policy search reinforcement learning based on particle filtering. Experiments are conducted both in simulation and on a real-world hopping leg. We show that although the impact dynamics is fast, the addition of passive impedance provides enough time for the active impedance controller to react to the impact and protect the robot from damage.",https://ieeexplore.ieee.org/document/7041490/,2014 IEEE-RAS International Conference on Humanoid Robots,18-20 Nov. 2014,ieeexplore
10.1109/IJCNN52387.2021.9533738,CarSNN: An Efficient Spiking Neural Network for Event-Based Autonomous Cars on the Loihi Neuromorphic Research Processor,IEEE,Conferences,"Autonomous Driving (AD) related features provide new forms of mobility that are also beneficial for other kind of intelligent and autonomous systems like robots, smart transportation, and smart industries. For these applications, the decisions need to be made fast and in real-time. Moreover, in the quest for electric mobility, this task must follow low power policy, without affecting much the autonomy of the mean of transport or the robot. These two challenges can be tackled using the emerging Spiking Neural Networks (SNNs). When deployed on a specialized neuromorphic hardware, SNNs can achieve high performance with low latency and low power consumption. In this paper, we use an SNN connected to an event-based camera for facing one of the key problems for AD, i.e., the classification between cars and other objects. To consume less power than traditional frame-based cameras, we use a Dynamic Vision Sensor (DVS) [1]. The experiments are made following an offline supervised learning rule, followed by mapping the learnt SNN model on the Intel Loihi Neuromorphic Research Chip [2]. Our best experiment achieves an accuracy on offline implementation of 86%, that drops to 83% when it is ported onto the Loihi Chip. The Neuromorphic Hardware implementation has maximum 0.72 ms of latency for every sample, and consumes only 310 mW. To the best of our knowledge, this work is the first implementation of an event-based car classifier on a Neuromorphic Chip.",https://ieeexplore.ieee.org/document/9533738/,2021 International Joint Conference on Neural Networks (IJCNN),18-22 July 2021,ieeexplore
10.1109/ROBOT.1993.292250,Cellular robotics: simulation and HW implementation,IEEE,Conferences,"Aspects of self-organization are presented in this paper. Computer simulations as well as a real prototypical implementation are used to illustrate the proposed approach. Results of simulations are presented to compare different strategies of self-organization enabling a system of autonomous robots to form a chain between two landmarks in a completely unknown environment. This chain implicitly represents a path between any two points of the environment without an explicit representation of free space (no single robot has a global map of the environment). The experimental part, even if restricted to a few robots, demonstrates that the set of stimuli-action processes used in the simulations are indeed feasible on real systems.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/292250/,[1993] Proceedings IEEE International Conference on Robotics and Automation,2-6 May 1993,ieeexplore
10.1109/ICRA.2019.8793660,Chance Constrained Motion Planning for High-Dimensional Robots,IEEE,Conferences,"This paper introduces Probabilistic Chekov (p-Chekov), a chance-constrained motion planning system that can be applied to high degree-of-freedom (DOF) robots under motion uncertainty and imperfect state information. Given process and observation noise models, it can find feasible trajectories which satisfy a user-specified bound over the probability of collision. Leveraging our previous work in deterministic motion planning which integrated trajectory optimization into a sparse roadmap framework, p-Chekov shows superiority in its planning speed for high-dimensional tasks. P-Chekov incorporates a linear-quadratic Gaussian motion planning approach into the estimation of the robot state probability distribution, applies quadrature theories to waypoint collision risk estimation, and adapts risk allocation approaches to assign allowable probabilities of failure among waypoints. Unlike other existing risk-aware planners, p-Chekov can be applied to high-DOF robotic planning tasks without the convexification of the environment. The experiment results in this paper show that this p-Chekov system can effectively reduce collision risk and satisfy user-specified chance constraints in typical real-world planning scenarios for high-DOF robots.",https://ieeexplore.ieee.org/document/8793660/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ICRA48506.2021.9561926,Circus ANYmal: A Quadruped Learning Dexterous Manipulation with Its Limbs,IEEE,Conferences,"Quadrupedal robots are skillful at locomotion tasks while lacking manipulation skills, not to mention dexterous manipulation abilities. Inspired by the animal behavior and the duality between multi-legged locomotion and multi-fingered manipulation, we showcase a circus ball challenge on a quadrupedal robot, ANYmal. We employ a model-free reinforcement learning approach to train a deep policy that enables the robot to balance and manipulate a light-weight ball robustly using its limbs without any contact measurement sensor. The policy is trained in the simulation, in which we randomize many physical properties with additive noise and inject random disturbance force during manipulation, and achieves zero-shot deployment on the real robot without any adjustment. In the hardware experiments, dynamic performance is achieved with a maximum rotation speed of 15 °/s, and robust recovery is showcased under external poking. To our best knowledge, it is the first work that demonstrates the dexterous dynamic manipulation on a real quadrupedal robot.",https://ieeexplore.ieee.org/document/9561926/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICRA40945.2020.9197336,CityLearn: Diverse Real-World Environments for Sample-Efficient Navigation Policy Learning,IEEE,Conferences,"Visual navigation tasks in real-world environments often require both self-motion and place recognition feedback. While deep reinforcement learning has shown success in solving these perception and decision-making problems in an end-to-end manner, these algorithms require large amounts of experience to learn navigation policies from high-dimensional data, which is generally impractical for real robots due to sample complexity. In this paper, we address these problems with two main contributions. We first leverage place recognition and deep learning techniques combined with goal destination feedback to generate compact, bimodal image representations that can then be used to effectively learn control policies from a small amount of experience. Second, we present an interactive framework, CityLearn, that enables for the first time training and deployment of navigation algorithms across city-sized, realistic environments with extreme visual appearance changes. CityLearn features more than 10 benchmark datasets, often used in visual place recognition and autonomous driving research, including over 100 recorded traversals across 60 cities around the world. We evaluate our approach on two CityLearn environments, training our navigation policy on a single traversal per dataset. Results show our method can be over 2 orders of magnitude faster than when using raw images, and can also generalize across extreme visual changes including day to night and summer to winter transitions.",https://ieeexplore.ieee.org/document/9197336/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ICIP42928.2021.9506200,Classification of RIGID and Non-Rigid Transformations with Autoencoder Representations,IEEE,Conferences,"Feature matching in transformed images is critical to many fields of computer science, from autonomous robots to video analysis. However, most widely used feature matching algorithms vary in their ability to track features depending on whether rigid or non-rigid image transformations occur. This makes it critical, especially in real-time calculations, to be able to identify what kind of transformation is taking place quickly in order to deploy the best feature matching algorithm for that type of transformation. The proposed research uses a combined autoencoder and neural network classification model to classify rigid or non-rigid transformations in order to improve feature matching on the image pairs. This system is the first to perform this kind of analysis with representation learning and opens new ways to improving feature matching performance. We show that using this method improves the amount of feature matches found between correctly identified image pairs.",https://ieeexplore.ieee.org/document/9506200/,2021 IEEE International Conference on Image Processing (ICIP),19-22 Sept. 2021,ieeexplore
10.1109/IROS.2018.8594311,Cognition-enabled Framework for Mixed Human-Robot Rescue Teams,IEEE,Conferences,"With the advancements in robotic technology and the progress in human-robot interaction research, the interest in deploying mixed human-robot teams in rescue missions is increasing. Due to their complementary capabilities in terms of locomotion, visibility and reachability of areas, human-robot teams are considerably deployed in real-world settings, albeit the robotic agents in such scenarios are normally fully teleoperated. A major barrier to successful and efficient mission execution in those teams is the lack of cognitive skills in robotic systems. In this paper, we present a cognition-enabled framework and an implemented system where robotic agents are equipped with cognitive capabilities to naturally communicate with humans and autonomously perform tasks. The framework allows for natural tasking of robots, reasoning about robot behavior, capabilities and actions, and a common belief state representation for shared mission awareness of robots and human operators.",https://ieeexplore.ieee.org/document/8594311/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ROBIO49542.2019.8961823,Collaborative Object Transportation by Multiple Robots with Onboard Object Localization Algorithm,IEEE,Conferences,"Collaborative object transportation has become a popular study trend with its remarkable application foreground. In previous relevant studies, localization of the transported object has always been accomplished by additional devices rather than robot onboard equipments. This paper presents a generalized multi-robot leader-follower system for collaborative object transportation and an onboard object localization algorithm for trajectory tracking of the target object. In this system, the mobile robots can directly push a cubic object without extra gripping devices, when tracking the reference trajectory. During the control process, the object is regarded as an virtual leader, whose localization information is utilized as the feedback, while the mobile robots are considered as the followers. In absence of external localization systems, the proposed onboard localization algorithm provides the real-time position information of the object using scan data from lidars equipped on the robots. A performed measurement accuracy test shows high precision of this algorithm. Finally, a lane-changing experiment of object transportation is conducted, and it verifies this multi-robot leader-follower system.",https://ieeexplore.ieee.org/document/8961823/,2019 IEEE International Conference on Robotics and Biomimetics (ROBIO),6-8 Dec. 2019,ieeexplore
10.1109/MSM49833.2020.9202398,Collaborative Robot System for Playing Chess,IEEE,Conferences,"In recent years, number of collaborative robots industrial applications has made a significant increasment. Implementation of collaborative robots is a safe and effective way for designing robot-human cooperation systems. Combined with constantly developing artificial intelligence, collaborative systems are actually able to solve complex problems that require some sort of intelligence. For humans, board games are a good example of the visualization of robot intelligence. Such systems require estimation and detection of board and pieces in manipulator workspace, some kind of decision-making algorithms and robot control system to move pieces. The flagship of such systems are chess playing robots. The chess game has a defined and easy to understand set of rules which makes it interesting example of intelligent robotics systems application. In this paper, we present an implementation of collaborative robots for chess playing system which was designed to play against human or another robot. The system is able to track state of the game via camera, calculate the optimal move using implemented decision-making algorithm, detect illegal moves and execute pick-and-place task to physically move pieces. We test the developed system in a real-world setup and provide experimental results documenting the performance of proposed approach.",https://ieeexplore.ieee.org/document/9202398/,2020 International Conference Mechatronic Systems and Materials (MSM),1-3 July 2020,ieeexplore
10.1109/IVCNZ51579.2020.9290542,Comparison of Face Detection Algorithms on Mobile Devices,IEEE,Conferences,"Face detection is a fundamental task for many computer vision applications such as access control, security, advertisement, automatic payment, and healthcare. Due to technological advances mobile robots are becoming increasingly common in such applications (e.g. healthcare and security robots) and consequently there is a need for efficient and effective face detection methods on such platforms. Mobile robots have different hardware configurations and operating conditions from desktop applications, e.g. unreliable network connections and the need for lower power consumption. Hence results for face detection methods on desktop platforms cannot be directly translated to mobile platforms.We compare four common face detection algorithms, Viola-Jones, HOG, MTCNN and MobileNet-SSD, for use in mobile robotics using different face data bases. Our results show that for a typical mobile configuration (Nvidia Jetson TX2) Mobile-NetSSD performed best with 90% detection accuracy for the AFW data set and a frame rate of almost 10 fps with GPU acceleration. MTCNN had the highest precision and was superior for more difficult face data sets, but did not achieve real-time performance with the given implementation and hardware configuration.",https://ieeexplore.ieee.org/document/9290542/,2020 35th International Conference on Image and Vision Computing New Zealand (IVCNZ),25-27 Nov. 2020,ieeexplore
10.1109/IROS.2001.977213,Computation principles for the development of visual skills in robotics,IEEE,Conferences,"Different working principles are often considered when different visual behaviors are implemented in an agent. This occurs basically because the physical interaction between the behavior and the environment is not studied in depth. The paper shows how apparently different visual behaviors share common theoretical principles for their working mechanism. In particular properties related to the navigation vector field they compute in the environment, provide a base to explain visual learning, guidance, topological navigation, sub goal placement, obstacle avoidance and navigation enhancement. To handle the mathematics of a vector field robust tools are needed. Techniques borrowed from computer vision literature provide the necessary mathematical tools. All behaviors described have been tested in real robots. On going research is still in progress for topological navigation and subgoal placement.",https://ieeexplore.ieee.org/document/977213/,Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180),29 Oct.-3 Nov. 2001,ieeexplore
10.1109/AITest.2019.00015,Constraint-Based Testing of An Industrial Multi-Robot Navigation System,IEEE,Conferences,"Intelligent multi-robot systems get more and more deployed in industrial settings to solve complex and repetitive tasks. Due to safety and economic reasons they need to operate dependably. To ensure a high degree of dependability, testing the deployed system has to be done in a rigorous way. Advanced multi-robot systems show a rich set of complex behaviors. Thus, these systems are difficult to test manually. Moreover, the space of potential environments and tasks for such systems is enormous. Therefore, methods that are able to explore this space in a structured way are needed. One way to address these issues is through model-based testing. In this paper we present an approach for testing the navigation system of a fleet of industrial transport robots. We show how all potential environments and navigation behaviors as well as requirements and restrictions can be represented in a formal constraint-based model. Moreover, we present the concept of coverage criteria in order to handle the potentially infinite space of test cases. Finally, we show how test cases can be derived from this model in an efficient way. In order to show the feasibility of the proposed approach we present an empirical evaluation of a prototype implementation using a real industrial use case.",https://ieeexplore.ieee.org/document/8718216/,2019 IEEE International Conference On Artificial Intelligence Testing (AITest),4-9 April 2019,ieeexplore
10.1109/IROS40897.2019.8967523,Contact Skill Imitation Learning for Robot-Independent Assembly Programming,IEEE,Conferences,"Robotic automation is a key driver for the advancement of technology. The skills of human workers, however, are difficult to program and seem currently unmatched by technical systems. In this work we present a data-driven approach to extract and learn robot-independent contact skills from human demonstrations in simulation environments, using a Long Short Term Memory (LSTM) network. Our model learns to generate error-correcting sequences of forces and torques in task space from object-relative motion, which industrial robots carry out through a Cartesian force control scheme on the real setup. This scheme uses forward dynamics computation of a virtually conditioned twin of the manipulator to solve the inverse kinematics problem. We evaluate our methods with an assembly experiment, in which our algorithm handles part tilting and jamming in order to succeed. The results show that the skill is robust towards localization uncertainty in task space and across different joint configurations of the robot. With our approach, non-experts can easily program force-sensitive assembly tasks in a robot-independent way.",https://ieeexplore.ieee.org/document/8967523/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/RO-MAN47096.2020.9223341,Context Dependent Trajectory Generation using Sequence-to-Sequence Models for Robotic Toilet Cleaning,IEEE,Conferences,"A robust, easy-to-deploy robot for service tasks in a real environment is difficult to construct. Record-and-playback (R&amp;P) is a method used to teach motor-skills to robots for performing service tasks. However, R&amp;P methods do not scale to challenging tasks where even slight changes in the environment, such as localization errors, would either require trajectory modification or a new demonstration. In this paper, we propose a Sequence-to-Sequence (Seq2Seq) based neural network model to generate robot trajectories in configuration space given a context variable based on real-world measurements in Cartesian space. We use the offset between a target pose and the actual pose after localization as the context variable. The model is trained using a few expert demonstrations collected using teleoperation. We apply our proposed method to the task of toilet cleaning where the robot has to clean the surface of a toilet bowl using a compliant end-effector in a constrained toilet setting. In the experiments, the model is given a novel offset context and it generates a modified robot trajectory for that context. We demonstrate that our proposed model is able to generate trajectories for unseen setups and the executed trajectory results in cleaning of the toilet bowl.",https://ieeexplore.ieee.org/document/9223341/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore
10.1109/CIMCA.2005.1631373,Continuous Curvature Trajectory Generation with Obstacle Avoidance for Car-Like Robots,IEEE,Conferences,"This paper presents an extension of cubic curvature polynomial trajectory planning to include a mechanism for obstacle avoidance. Cubic polynomials have been used to describe curvature continuous trajectories for car like robots. From known start and end robot postures, (position, orientation and curvature) a continuous trajectory can be decided. We extend cubic polynomial trajectories to fourth order polynomials, and introduce a cost function, describing accumulated distance to obstacles along a trajectory, to the robot posture vector. Such trajectories, generated by a gradient descent method, satisfy continuity constraints and avoid obstacles. The method is implemented on a mobile robot system and experiments in real time trajectory planning and execution are conducted",https://ieeexplore.ieee.org/document/1631373/,"International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC'06)",28-30 Nov. 2005,ieeexplore
10.1109/WHC.2011.5945522,Control of a desktop mobile haptic interface,IEEE,Conferences,"Most haptic devices share two main limits: they are grounded and they have limited workspace. A possible solution is to create haptic interfaces by combining mobile robots and standard grounded force-feedback devices, the so called Mobile Haptic Interfaces (MHIs). However, MHIs are characterized by dynamical limitations due to performance of the employed devices. This paper focuses on basic design issues and presents a novel (prototype) Mobile Haptics Platform that employs the coordination of numerically controlled wheel torques to render forces to a user handle placed on the top of the device. The interface, consisting in a small omni-directional robot, is link-less, fully portable and it has been designed to support home-rehabilitation exercises. In the present paper we shall review relevant choices concerning the functional aspects and the control design. In particular a specific embedded sensor fusion was implemented to allow the device to move on a desk without drifting. The sensor fusion algorithm has been optimized to provide users with a quality force feedback while ensuring accurate position tracking. The two requirements are in contrast each other and a specific variant of the Extended Kalman Filter (EKF) was required to allow the device working.",https://ieeexplore.ieee.org/document/5945522/,2011 IEEE World Haptics Conference,21-24 June 2011,ieeexplore
10.1109/IROS.2012.6385803,Control of contact forces: The role of tactile feedback for contact localization,IEEE,Conferences,"This paper investigates the role of precise estimation of contact points in force control. This analysis is motivated by scenarios in which robots make contacts, either voluntarily or accidentally, with different parts of their body. Control paradigms that are usually implemented in robots with no tactile system, make the hypothesis that contacts occur at the end-effectors only. In this paper we try to investigate what happens when this assumption is not verified. First we consider a simple feedforward force control law, and then we extend it by introducing a proportional feedback term. For both controllers we find the error in the resulting contact force, that is induced by a hypothetic error in the estimation of the contact point. We show that, depending on the geometry of the contact, incorrect estimation of contact points can induce undesired joint accelerations. We validate the presented analysis with tests on a simulated robot arm. Moreover we consider a complex real world scenario, where most of the assumptions that we make in our analytical derivation do not hold. Through tests on the iCub humanoid robot we see how errors in contact localization affect the performance of a parallel force/position controller. In order to estimate contact points and contact forces on the forearm of the iCub we do not use any model of the environment, but we exploit its 6-axis force/torque sensor and its sensorized skin.",https://ieeexplore.ieee.org/document/6385803/,2012 IEEE/RSJ International Conference on Intelligent Robots and Systems,7-12 Oct. 2012,ieeexplore
10.1109/ICRA40945.2020.9197209,Cooperative Multi-Robot Navigation in Dynamic Environment with Deep Reinforcement Learning,IEEE,Conferences,"The challenges of multi-robot navigation in dynamic environments lie in uncertainties in obstacle complexities, partially observation of robots, and policy implementation from simulations to the real world. This paper presents a cooperative approach to address the multi-robot navigation problem (MRNP) under dynamic environments using a deep reinforcement learning (DRL) framework, which can help multiple robots jointly achieve optimal paths despite a certain degree of obstacle complexities. The novelty of this work includes threefold: (1) developing a cooperative architecture that robots can exchange information with each other to select the optimal target locations; (2) developing a DRL based framework which can learn a navigation policy to generate the optimal paths for multiple robots; (3) developing a training mechanism based on dynamics randomization which can make the policy generalized and achieve the maximum performance in the real world. The method is tested with Gazebo simulations and 4 differential drive robots. Both simulation and experiment results validate the superior performance of the proposed method in terms of success rate and travel time when compared with the other state-of-art technologies.",https://ieeexplore.ieee.org/document/9197209/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ICCAS.2007.4407004,Cooperative behavior acquisition of multiple autonomous mobile robots by an objective-based reinforcement learning system,IEEE,Conferences,"The present paper proposes an objective-based reinforcement learning system for multiple autonomous mobile robots to acquire cooperative behavior. The proposed system employs profit sharing (PS) as a learning method. A major characteristic of the system is using two kinds of PS tables. One is to learn cooperative behavior using information on other agents' positions and the other is to learn how to control basic movements. Through computer simulation and real robot experiment using a garbage-collection problem, the performance of the proposed system is evaluated. As a result, it is verified that agents select the most available garbage for cooperative behavior using visual information in an unknown environment and move to the target avoiding obstacles.",https://ieeexplore.ieee.org/document/4407004/,"2007 International Conference on Control, Automation and Systems",17-20 Oct. 2007,ieeexplore
10.1109/ISIC.2000.882949,Cooperative learning and planning for multiple robots,IEEE,Conferences,"The paper deals with the the subject of learning and planning for real mobile robots, using Sutton's (1991) Dyna algorithm. The Dyna algorithm integrates reinforcement learning, planning and reactive execution. We present an extension of the Dyna algorithm which includes symmetric and cooperative learning with multiple robots. We applied the extended version of the algorithm to a population of two real robots. Practical problems associated with the implementation of the algorithm on a real setup are solved. Results obtained from simulations and real experiments are presented and discussed.",https://ieeexplore.ieee.org/document/882949/,Proceedings of the 2000 IEEE International Symposium on Intelligent Control. Held jointly with the 8th IEEE Mediterranean Conference on Control and Automation (Cat. No.00CH37147),19-19 July 2000,ieeexplore
10.1109/IROS.2012.6385982,Cooperative sensing and recognition by a swarm of mobile robots,IEEE,Conferences,"We present an approach for distributed real-time recognition tasks using a swarm of mobile robots. We focus on the visual recognition of hand gestures, but the solutions that we provide have general applicability and address a number of challenges common to many distributed sensing and classification problems. In our approach, robots acquire and process hand images from multiple points of view, most of which do not allow for a satisfactory classification. Each robot is equipped with a statistical classifier, which is used to generate an opinion for the sensed gesture. Using a low-bandwidth wireless channel, the robots locally exchange their opinions. They also exploit mobility to adapt their positions to maximize the mutual information collectively gathered by the swarm. A distributed consensus protocol is implemented, to allow to rapidly settle on a decision once enough evidence is available. The system is implemented and demonstrated on real robots. In addition, extensive quantitative results of emulation experiments, based on a real image dataset, are reported. We consider different scenarios and study the scalability and the robustness of the swarm performance for distributed recognition.",https://ieeexplore.ieee.org/document/6385982/,2012 IEEE/RSJ International Conference on Intelligent Robots and Systems,7-12 Oct. 2012,ieeexplore
10.1109/IROS.2014.6942970,Coordination in human-robot teams using mental modeling and plan recognition,IEEE,Conferences,"Beliefs play an important role in human-robot teaming scenarios, where the robots must reason about other agents' intentions and beliefs in order to inform their own plan generation process, and to successfully coordinate plans with the other agents. In this paper, we cast the evolving and complex structure of beliefs, and inference over them, as a planning and plan recognition problem. We use agent beliefs and intentions modeled in terms of predicates in order to create an automated planning problem instance, which is then used along with a known and complete domain model in order to predict the plan of the agent whose beliefs are being modeled. Information extracted from this predicted plan is used to inform the planning process of the modeling agent, to enable coordination. We also look at an extension of this problem to a plan recognition problem. We conclude by presenting an evaluation of our technique through a case study implemented on a real robot.",https://ieeexplore.ieee.org/document/6942970/,2014 IEEE/RSJ International Conference on Intelligent Robots and Systems,14-18 Sept. 2014,ieeexplore
10.1109/LARC.2011.6086817,Coordination mechanisms for a multi-agent robotic system applied to search and target location,IEEE,Conferences,"In this paper we consider the problem of searching an unknown number of targets in static environment by a team of robots. As the targets positions and distribution are uncertain; the goal is to minimize the overall exploration time. Using cell maps, the key problem can be solved choosing the suitable cell for the individual robots so that they simultaneously explore different regions of the environment. We present an intelligent approach for the coordination of multiple robots, in which contrast to previous approaches, able to perform task allocations taking into account the trade-off between the costs of reaching the cell and its utility. This utility function has been modeled using neural networks and optimized with genetic algorithms. Besides, if the task produces some conflict between robots, a negotiation algorithm is used to collision avoidance. The proposed approach has been implemented in real-world experiments and its performance tested in simulation runs. The results given in this paper demonstrate that our coordination mechanism significantly reduces the exploration time and increase the effectiveness compared to previous approaches.",https://ieeexplore.ieee.org/document/6086817/,"IX Latin American Robotics Symposium and IEEE Colombian Conference on Automatic Control, 2011 IEEE",1-4 Oct. 2011,ieeexplore
10.1109/DICTA.2018.8615819,Crack-pot: Autonomous Road Crack and Pothole Detection,IEEE,Conferences,"With the advent of self-driving cars and autonomous robots, it is imperative to detect road impairments like cracks and potholes and to perform necessary evading maneuvers to ensure fluid journey for on-board passengers or equipment. We propose a fully autonomous robust real-time road crack and pothole detection algorithm which can be deployed on any GPU based conventional processing boards with an associated camera. The approach is based on a deep neural net architecture which detects cracks and potholes using texture and spatial features. We also propose pre-processing methods which ensure real-time performance. The novelty of the approach lies in using texture-based features to differentiate between crack surfaces and sound roads. The approach performs well in large viewpoint changes, background noise, shadows, and occlusion. The efficacy of the system is shown on standard road crack datasets.",https://ieeexplore.ieee.org/document/8615819/,2018 Digital Image Computing: Techniques and Applications (DICTA),10-13 Dec. 2018,ieeexplore
10.1109/IROS.2003.1248914,Creation and analysis of a scenario based universal sensory driver layer with real-time fault tolerant properties,IEEE,Conferences,"Sensor fusion and sensor integration is becoming an increasingly popular approach in dealing with complex sensor systems in autonomous mobile robots (AMR). However, the procedure for the sensor integration and sensor fusion is a non-trivial process. This paper presents a scenario based approach to sensor fusion based on the autonomous evolution of sensory and actuator driver layers through environmental constraints (AEDEC) [T.A Choi, 2002]. Using the scenario based approach, the programmer's work of creating a sensory driver will be eliminated by having the AMR learn the driver on its own. In the process of creating each scenario, sensor fusion is automatically implemented. If sensors change or even if the sensor configuration changes, the driver can be updated by having the AMR relearn the driver over again. Due to the tabular structure of the scenario based sensory drivers, malfunctioning sensors can not only be detected, but the driver can automatically adapt to the malfunctioning sensor in real-time. Furthermore, different AMR's trained using AEDEC architecture will have similar interpretations of its environment. This is guaranteed by having the AMR learn the driver in the same highly structured training environment. The behavioral coding is simplified by eliminating any reference to hardware dependent parameters. Finally, the level of abstraction and the consistency of the highly structured environment allows for coding portability.",https://ieeexplore.ieee.org/document/1248914/,Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453),27-31 Oct. 2003,ieeexplore
10.1109/IROS.2014.6942768,Crowdsourcing as a methodology to obtain large and varied robotic data sets,IEEE,Conferences,"For autonomous robots to operate successfully in unknown environments, their computer vision algorithms need to generalize over many different environments. However, due to practical considerations robotic vision experiments are typically limited to a single robot and a few (laboratory) environments. We propose crowdsourcing as a methodology for gathering large and varied robotic data sets. We evaluate the methodology by performing the first crowdsourcing experiment involving actual robots. In particular, we have made a space-game called `Astro Drone' for a toy quad rotor, the Parrot AR drone. Nine months after the game's release, there are 14,628 downloads and 840 contributions, consisting of visual features and drone state estimates. Data mining shows the methodology's potential, providing insights such as the relation between the number of visual features and obstacle distances.",https://ieeexplore.ieee.org/document/6942768/,2014 IEEE/RSJ International Conference on Intelligent Robots and Systems,14-18 Sept. 2014,ieeexplore
10.1109/AERO.2018.8396547,Data-driven quality prognostics for automated riveting processes,IEEE,Conferences,"Technologies based in robotics and automatics are reshaping the aerospace industry. Aircraft manufacturers and top-tier suppliers now rely on robotics to perform most of its operational tasks. Over the years, a succession of implemented mobile robots has been developed with the mission of automating important industrial processes such as welding, material handling or assembly procedures. However, despite the progress achieved, a major limitation is that the process still requires human supervision and an extensive quality control process. An approach to address this limitation is to integrate machine learning methods within the quality control process. The idea is to develop algorithms that can direct manufacturing experts towards critical areas requiring human supervision and quality control. In this paper we present an application of machine learning to a concrete industrial problem involving the quality control of a riveting machine. The proposal consists of an intelligent predictive model that can be integrated within the existing real time sensing and pre-processing sub-systems at the equipment level. The framework makes use of several data-driven techniques for pre-processing and feature engineering, combined with the most accurate algorithms, validated through k-folds cross validation technique which also estimates prediction errors. The model is able to classify the manufacturing process of the machine as nominal or anomalous according to a real-world data set of design requirements and operational data. Several machine learning algorithms are compared such as linear regression, nearest neighbor, support vector machines, decision trees, random forests and extreme gradient boost. Results obtained from the case study suggest that the proposed model produces accurate predictions which meet industrial standards.",https://ieeexplore.ieee.org/document/8396547/,2018 IEEE Aerospace Conference,3-10 March 2018,ieeexplore
10.1109/ICRA48506.2021.9562019,Decentralized Circle Formation Control for Fish-like Robots in the Real-world via Reinforcement Learning,IEEE,Conferences,"In this paper, the circle formation control problem is addressed for a group of cooperative underactuated fish-like robots involving unknown nonlinear dynamics and disturbances. Based on the reinforcement learning and cognitive consistency theory, we propose a decentralized controller without the knowledge of the dynamics of the fish-like robots. The proposed controller can be transferred from simulation to reality. It is only trained in our established simulation environment, and the trained controller can be deployed to real robots without any manual tuning. Simulation results confirm that the proposed model-free robust formation control method is scalable with respect to the group size of the robots and outperforms other representative RL algorithms. Several experiments in the real world verify the effectiveness of our RL-based approach for circle formation control.",https://ieeexplore.ieee.org/document/9562019/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICRA48506.2021.9561066,Decentralized Connectivity Maintenance with Time Delays using Control Barrier Functions,IEEE,Conferences,"Connectivity maintenance is crucial for the real world deployment of multi-robot systems, as it ultimately allows the robots to communicate, coordinate and perform tasks in a collaborative way. A connectivity maintenance controller must keep the multi-robot system connected independently from the system’s mission and in the presence of undesired real world effects such as communication delays, model errors, and computational time delays, among others. In this paper we present the implementation, on a real robotic setup, of a connectivity maintenance control strategy based on Control Barrier Functions. During experimentation, we found that the presence of communication delays has a significant impact on the performance of the controlled system, with respect to the ideal case. We propose a heuristic to counteract the effects of communication delays, and we verify its efficacy both in simulation and with physical robot experiments.",https://ieeexplore.ieee.org/document/9561066/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICRA.2016.7487617,Decentralized multi-agent exploration with online-learning of Gaussian processes,IEEE,Conferences,"Exploration is a crucial problem in safety of life applications, such as search and rescue missions. Gaussian processes constitute an interesting underlying data model that leverages the spatial correlations of the process to be explored to reduce the required sampling of data. Furthermore, multi-agent approaches offer well known advantages for exploration. Previous decentralized multi-agent exploration algorithms that use Gaussian processes as underlying data model, have only been validated through simulations. However, the implementation of an exploration algorithm brings difficulties that were not tackle yet. In this work, we propose an exploration algorithm that deals with the following challenges: (i) which information to transmit to achieve multi-agent coordination; (ii) how to implement a light-weight collision avoidance; (iii) how to learn the data's model without prior information. We validate our algorithm with two experiments employing real robots. First, we explore the magnetic field intensity with a ground-based robot. Second, two quadcopters equipped with an ultrasound sensor explore a terrain profile. We show that our algorithm outperforms a meander and a random trajectory, as well as we are able to learn the data's model online while exploring.",https://ieeexplore.ieee.org/document/7487617/,2016 IEEE International Conference on Robotics and Automation (ICRA),16-21 May 2016,ieeexplore
10.1109/IROS40897.2019.8967874,Deep Dive into Faces: Pose &amp; Illumination Invariant Multi-Face Emotion Recognition System,IEEE,Conferences,"One of the advancements in humanization of robots is its ability to recognize human emotions. Facial expression plays a key role in identifying human emotions relative to other cues. In this research, an intelligent network capable of real-time emotion recognition from multiple faces using deep learning technique is presented. The proposed network is based on Convolution Neural Network (CNN) in which three blocks of Convolution layers for feature extraction and two blocks of Dense layers for classification are used. The novelty of this method lies in recognizing emotions from multiple faces simultaneously in real time and its invariance to head pose, illumination and age factor. Most of reported work in literature for multiple faces is for frontal face without illumination variation. The proposed emotion recognition system is deployed on Raspberry Pi3 B+ for human robot interaction applications and achieved an average accuracy of 95.8% in real time.",https://ieeexplore.ieee.org/document/8967874/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/BioRob49111.2020.9224272,Deep Learning of Movement Intent and Reaction Time for EEG-informed Adaptation of Rehabilitation Robots,IEEE,Conferences,"Mounting evidence suggests that adaptation is a crucial mechanism for rehabilitation robots in promoting motor learning. Yet, it is commonly based on robot-derived movement kinematics, which is a rather subjective measurement of performance, especially in the presence of a sensorimotor impairment. Here, we propose a deep convolutional neural network (CNN) that uses electroencephalography (EEG) as an objective measurement of two kinematics components that are typically used to assess motor learning and thereby adaptation: i) the intent to initiate a goal-directed movement, and ii) the reaction time (RT) for that movement. We evaluated our CNN on data acquired from an in-house experiment where 12 healthy subjects moved a rehabilitation robotic arm in four directions on a plane, in response to visual stimuli. Our CNN achieved average test accuracies of 80.08% and 79.82% in a binary classification of the intent (intent vs. no intent) and RT (slow vs. fast), respectively. Our results demonstrate how individual movement components implicated in distinct types of motor learning can be predicted from synchronized EEG data acquired before the start of the movement. Our approach can, therefore, inform robotic adaptation in real-time and has the potential to further improve one's ability to perform the rehabilitation task.",https://ieeexplore.ieee.org/document/9224272/,2020 8th IEEE RAS/EMBS International Conference for Biomedical Robotics and Biomechatronics (BioRob),29 Nov.-1 Dec. 2020,ieeexplore
10.1109/ICRA48506.2021.9561729,Deep Neuromorphic Controller with Dynamic Topology for Aerial Robots,IEEE,Conferences,"Current aerial robots are increasingly adaptive; they can morph to enable operation in changing conditions to complete diverse missions. Each mission may require the robot to conduct a different task. A conventional learning approach can handle these variations when the system is trained for similar tasks in a representative environment. However, it may result in overfitting to the new data stream or the failure to adapt, leading to degradation or a potential crash. These problems can be mitigated with an excessive amount of data and embedded model, but the computational power and the memory of the aerial robots are limited. In order to address the variations in the model, environment as well as the tasks within onboard computation limitations, we propose a deep neuromorphic controller approach with variable topologies to handle each different condition and the data stream with a feasible computation and memory allocation. The proposed approach is based on a deep neuromorphic (multi and variable layered neural network) controller with dynamic depth and progressive layer adaptation for each new data stream. This adaptive structure is combined with a switching function to form a sliding mode controller. The network parameter update rule guarantees the stability of the closed loop system by the convergence of the error dynamics to the sliding surface. Being the first implementation on an aerial robot in this context, the results illustrate the adaptation capability, stability, computational efficiency as well as the real-time validation.",https://ieeexplore.ieee.org/document/9561729/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ROBIO.2018.8665274,Deep Reinforcement Learning Based Brachiation Control for Two-Link Bio-Primate Robot,IEEE,Conferences,"Manually designing an effective and efficient controller for complex mechanics, such as bio-inspired robots or underactuated mechanical system, typically are very difficult. It requires precise motion planning and dynamic control. Reinforcement learning or genetic algorithm based learning methods suffers from representing the high dimensional models. The combination of deep learning and reinforcement learning provide a feasible way to handle such difficulties. However, priori-less searching sometimes tends to be low efficient and usually finds the “mechanic” solution instead of the “natural” one. In this paper, the traditional nonlinear control concept is integrated into the deep reinforcement learning (DRL) framework. The whole process is implemented on the brachiation control problem of a two link bio-primate robot. Deep Deterministic Policy Gradient (DDPG) is used to search for the optimal control policy. The searching process is realized by interacting with the dynamic model instead of real robot. The energy based planning and control concept is adopted, which utilize the fact that when the shoulder joint angle is fixed, energy of the whole system keeps constant. By regulating the angle and energy, the robot can be restricted on a particular trajectory. The energy concept is encoded within the reward function and trained in the Gym environment. For varying targets point-to-point control, the network structure is also modified to accept the target coordinates. Effectiveness of the proposed methods are verified by simulation and experimental results.",https://ieeexplore.ieee.org/document/8665274/,2018 IEEE International Conference on Robotics and Biomimetics (ROBIO),12-15 Dec. 2018,ieeexplore
10.1109/SoutheastCon44009.2020.9249654,Deep Reinforcement Learning For Visual Navigation of Wheeled Mobile Robots,IEEE,Conferences,"A study is presented on applying deep reinforcement learning (DRL) for visual navigation of wheeled mobile robots (WMR) in dynamic and unknown environments. Two DRL algorithms, namely, value-learning deep Q-network (DQN) and policy gradient based asynchronous advantage actor critic ( A 3C), have been considered. RGB (red, green and blue) and depth images have been used as inputs in implementation of both DRL algorithms to generate control commands for autonomous navigation of WMR in simulation environments. The initial DRL networks were generated and trained progressively in OpenAI Gym Gazebo based simulation environments within robot operating system (ROS) framework for a popular target WMR, Kobuki TurtleBot2. A pre-trained deep neural network ResNet50 was used after further training with regrouped objects commonly found in laboratory setting for target-driven mapless visual navigation of Turlebot2 through DRL. The performance of A 3C with multiple computation threads (4, 6, and 8) was simulated on a desktop. The navigation performance of DQN and A 3C networks, in terms of reward statistics and completion time, was compared in three simulation environments. As expected, A 3C with multiple threads (4, 6, and 8) performed better than DQN and the performance of A 3C improved with number of threads. Details of the methodology, simulation results are presented and recommendations for future work towards real-time implementation through transfer learning of the DRL models are outlined.",https://ieeexplore.ieee.org/document/9249654/,2020 SoutheastCon,28-29 March 2020,ieeexplore
10.1109/ICRA48506.2021.9561145,Deep Reinforcement Learning Framework for Underwater Locomotion of Soft Robot,IEEE,Conferences,"Soft robotics is an emerging technology with excellent application prospects. However, due to the inherent compliance of the materials used to build soft robots, it is extremely complicated to control soft robots accurately. In this paper, we introduce a data-based control framework for solving the soft robot underwater locomotion problem using deep reinforcement learning (DRL). We first built a soft robot that can swim based on the dielectric elastomer actuator (DEA). We then modeled it in a simulation for the purpose of training the neural network and tested the performance of the control framework through real experiments on the robot. The framework includes the following: a simulation method for the soft robot that can be used to collect data for training the neural network, the neural network controller of the swimming robot trained in the simulation environment, and the computer vision method to collect the observation space from the real robot using a camera. We confirmed the effectiveness of the learning method for the soft swimming robot in the simulation environment by allowing the robot to learn how to move from a random initial state to a specific direction. After obtaining the trained neural network through the simulation, we deployed it on the real robot and tested the performance of the control framework. The soft robot successfully achieved the goal of moving in a straight line in disturbed water. The experimental results suggest the potential of using deep reinforcement learning to improve the locomotion ability of mobile soft robots.",https://ieeexplore.ieee.org/document/9561145/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/WCNC45663.2020.9120611,Deep Reinforcement Learning based Indoor Air Quality Sensing by Cooperative Mobile Robots,IEEE,Conferences,"Confronted with the severe indoor air pollution nowadays, we propose the usage of multiple robots to detect the indoor air quality (IAQ) cooperatively for fewer sensors and larger sensing area. To acquire the complete real-time IAQ distribution map, we exploit the real statistical data to construct the IAQ data model and adopt Kalman Filter to obtain the estimation of the unmeasured area. Since the movement of the robots affects the estimation accuracy, a proper movement strategy should be planned to minimize the total estimation error. To solve this optimization problem, we design a deep Q-learning approach, which provides sub-optimal movement strategies for real-time robot sensing. By simulations, we verify the adopted IAQ data model and testify the effectiveness of the proposed solution. For application considerations, we have deployed this system in Peking University since Dec. 2018 and developed a website to visualize the IAQ distribution.",https://ieeexplore.ieee.org/document/9120611/,2020 IEEE Wireless Communications and Networking Conference (WCNC),25-28 May 2020,ieeexplore
10.1109/ROMAN.2017.8172429,Deep recurrent Q-learning of behavioral intervention delivery by a robot from demonstration data,IEEE,Conferences,"We present a learning from demonstration (LfD) framework that uses a deep recurrent Q-network (DRQN) to learn how to deliver a behavioral intervention (BI) from demonstrations performed by a human. The trained DRQN enables a robot to deliver a similar BI in an autonomous manner. BIs are highly structured procedures wherein children with developmental delays/disorders (e.g. autism, ADHD, etc.) are trained to perform new behaviors and life-skills. Mounting anecdotal evidence from human-robot interaction (HRI) research has shown that BI benefits from the use of robots as a delivery tool. Most of the HRI research on robot-based intervention relies on tele-operated robots. However, the need for autonomy has become increasingly evident, especially when it comes to the real-world deployment of these systems. The few studies that have used autonomy in robot-based BI relied on hand-picked features of the environment in order to trigger correct robot actions. Additionally, none of these automated architectures attempted to learn the BI from human demonstrations, though this appears to be the most natural way of learning. This paper represents the first attempt to design a robot that uses LfD to learn BI. We generate a model then correctly predict appropriate actions with greater than 80% accuracy. To the best of our knowledge, this is the first attempt to employ DRQN within an LfD framework to learn high level reasoning embedded in human actions and behaviors simply from observations.",https://ieeexplore.ieee.org/document/8172429/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/ICMLA51294.2020.00201,Defending Against Localized Adversarial Attacks on Edge-Deployed Monocular Depth Estimators,IEEE,Conferences,"Estimation of depth from a single image is an important scene understanding task in computer vision. With the advent of Deep Learning and Convolutional Neural Networks, staggeringly high accuracies have been achieved in this task. With advancements in model optimization, it has been possible to deploy these models on edge devices, allowing for efficient depth estimation in safety-critical applications in robots, rovers, drones and even self-driving vehicles. However, these models are susceptible to attacks from malicious adversaries, which aim to distort the output of the model for a seemingly clean image by adding minute perturbations. In the real-world scenario, the most plausible attack is the adversarial patch, which can be printed and used as a physical adversarial attack against Deep Learning models. In the case of Monocular Depth Estimation, we show that small adversarial patches, which range from 0.7% to 5% of the image size, greatly worsen model performance. It is thus essential that these models are made robust using defense mechanisms, to defend against malicious inputs while also not reducing performance on clean images. Moreover, it is essential that the defense mechanism be computationally efficient, for real-time inference on edge devices. In this work, we propose the first defense mechanism against adversarial patches for a regression network, in the context of Monocular Depth Estimation on an edge device. The defense mechanism adds very little overhead time of 38 milliseconds on a Raspberry Pi 3 Model B, maintaining performance on clean images while also achieving near clean image levels of performance on adversarial inputs.",https://ieeexplore.ieee.org/document/9356303/,2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA),14-17 Dec. 2020,ieeexplore
10.1109/ETFA.2015.7301549,Design and implementation for multiple-robot deployment in intelligent space,IEEE,Conferences,"This paper presents the problem of robot deployment for a number of scattered tasks. We aim to minimize the duration it takes for all robots to reach their assigned task locations. In previous work, we have proposed a team composed of one carrier robot (CR) and several servant robots to accomplish the mission. Then we have suggested an algorithm that determines a path of the CR for an efficient deployment under a few constraints, which is verified by simulations. Assuming that the servant robots are unmanned aerial vehicles (UAVs), the present paper extends the discussion to a real robot experiment. We design and implement a deployment system in intelligent space. The feasibility of the study is demonstrated through an experiment.",https://ieeexplore.ieee.org/document/7301549/,2015 IEEE 20th Conference on Emerging Technologies & Factory Automation (ETFA),8-11 Sept. 2015,ieeexplore
10.1109/IROS.2018.8594335,Detection- Tracking for Efficient Person Analysis: The DetTA Pipeline,IEEE,Conferences,"In the past decade many robots were deployed in the wild, and people detection and tracking is an important component of such deployments. On top of that, one often needs to run modules which analyze persons and extract higher level attributes such as age and gender, or dynamic information like gaze and pose. The latter ones are especially necessary for building a reactive, social robot-person interaction. In this paper, we combine those components in a fully modular detection-tracking-analysis pipeline, called DetTA. We investigate the benefits of such an integration on the example of head and skeleton pose, by using the consistent track ID for a temporal filtering of the analysis modules' observations, showing a slight improvement in a challenging real-world scenario. We also study the potential of a so-called “free-flight” mode, where the analysis of a person attribute only relies on the filter's predictions for certain frames. Here, our study shows that this boosts the runtime dramatically, while the prediction quality remains stable. This insight is especially important for reducing power consumption and sharing precious (GPU-)memory when running many analysis components on a mobile platform, especially so in the era of expensive deep learning methods.",https://ieeexplore.ieee.org/document/8594335/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/RO-MAN50785.2021.9515353,Developing an Engagement-Aware System for the Detection of Unfocused Interaction,IEEE,Conferences,"We introduce a perception system for social robots that is able to detect a person’s engagement in an interaction from nonverbal cues independently of principal user activity. This was achieved by the introduction of a set of proxemics, body posture and attention features relevant for human-human interaction. The features were extracted from RGB-D image data of a single Kinect and utilized to train two separate machine learning models. Multiple system configurations and feature combinations were tested, and their impact on the detection of user engagement evaluated. Combining all features, our perception system reaches an F1-score of 81% when estimating an observed person’s interaction intent through binary classification. Regression of a user’s level of availability deviates from the given ground truth values by 13.27% on average. Finally, a prototype was implemented which is able to simultaneously run both previous estimates in real-time using a shared feature vector. In the following, the proposed system shall be used to design robots whose behavior shows their awareness of user engagement.",https://ieeexplore.ieee.org/document/9515353/,2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN),8-12 Aug. 2021,ieeexplore
10.1109/IJCNN.2003.1223996,"Developing early senses about the world: ""Object Permanence"" and visuoauditory real-time learning",IEEE,Conferences,"What ""constraints"" are exactly wired into the human developmental program? What ""constraints"" are minimally necessary for a developmental robot? These are open questions. In this paper, we propose a mechanism of developing experience-based priming - predicting the future contexts including sensation and action based on the previous experience - as a powerful ""constraint"" for developmental robots. We present an architecture that develops this priming capability through realtime online interactions with the environment. We report how our SAIL robot developed a sense of novelty in a well-known ""drawbridge"" experiment which sheds light on the controversial issue of ""object permanence"" in psychology. We further show how the proposed priming mechanism enabled SAIL to deal with a very challenging online learning setting: learning the name and property (e.g., size) of dynamically rotating objects through verbal dialogues.",https://ieeexplore.ieee.org/document/1223996/,"Proceedings of the International Joint Conference on Neural Networks, 2003.",20-24 July 2003,ieeexplore
10.1109/IEEECONF49454.2021.9382646,Development and Testing of Garbage Detection for Autonomous Robots in Outdoor Environments,IEEE,Conferences,"In Japan, there is a growing concern about labor shortages due to the declining birthrate and aging population, and there are high expectations for robots to help solve such social problems and create industries. However, due to the prohibition of public road tests in Japan, there are few examples of actual applications of robots. Therefore, considerations and problems in the practical application of robots are still unclear. In this paper, by focusing on the implementation of garbage collection technology, we have developed an autonomous garbage collection robot using deep learning. In addition, we have verified the usefulness of our garbage detection technology in outdoor environments by conducting actual demonstrations at HANEDA INNOVATION CITY, which is a large-scale commercial and business complex belonged private property, Utsunomiya University, and Nakanoshima Challenge 2019, which is a field of demonstration experiment in the outdoor environment. Our garbage detector was designed to detect cans, plastic bottles, and lunch boxes automatically. Through experiments on test data and outdoor experiments in the real-world, we have confirmed that our detector has a 95.6% Precision and 96.8% Recall. Conparisons to other state-of-the-art detectors are also presented.",https://ieeexplore.ieee.org/document/9382646/,2021 IEEE/SICE International Symposium on System Integration (SII),11-14 Jan. 2021,ieeexplore
10.1109/ROBOT.2004.1307521,Development and deployment of a line of sight virtual sensor for heterogeneous teams,IEEE,Conferences,"For a team of cooperating robots, geometry plays a vital role in operation. Knowledge of line of sight to local obstacles and adjacent teammates is critical in both the movement and planning stages to avoid collisions, maintain formation and localize the team. However, determining if other robots are within the line of sight of one another is difficult with existing sensor platforms - especially as the scale of the robot is reduced. We describe a method of exploiting collective team information to generate a virtual sensor that provides line of sight determination, greater range and resolution and the ability to generalize local sensing. We develop this sensor and apply it to the control of a tightly coupled, resource-limited robot team called Millibots.",https://ieeexplore.ieee.org/document/1307521/,"IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004",26 April-1 May 2004,ieeexplore
10.1109/IECON48115.2021.9589075,Development of Agricultural Robot Platform with Virtual Laboratory Capabilities,IEEE,Conferences,"Agricultural robots are called to help in many tasks in emerging clean and sustainable agriculture. These complex electro-mechanical systems can actually integrate artificial intelligence (AI), the Internet of Things (IoT), sensors, actuators, and advanced control methods to accomplish functions in autonomous or in collaborative ways. Before the deployment of such techniques in the field, it is convenient to carry out laboratory validations. These last could be at the sub-system, e.g., sensors or servos operation, or the whole system level. This paper proposes the development of the hardware and software parts of a platform of agricultural robot. The proposed system, highly motivated by the restrictions imposed by COVID-19 context, enables laboratory tests virtualization while keeping real-time functionalities",https://ieeexplore.ieee.org/document/9589075/,IECON 2021 – 47th Annual Conference of the IEEE Industrial Electronics Society,13-16 Oct. 2021,ieeexplore
10.1109/EMS.2017.12,Development of Components of Multi-agent CASE-System for Describing the Logic of Behavior of Mobile Robots,IEEE,Conferences,"In the article there are substantiation of architectural and technical solutions, with the basis of the universal CASE-tool for describing (""programming"") the behavior of mobile robots. The development tool intended for carrying out experiments in the field of artificial intelligence and it is based on multi-agent technology. In addition, the toolkit will be the maximum possible reuse of elements (tasks, processes, etc.). The basis for the development is the idea of combining, within the framework of one tool, both the real execution of the algorithm by the robot, and its simulation. It allows talking about testing partially implemented hardware (sensors and actuators). Development is carried out based on open source technology; all texts of programs are available at web source: https://github.com/unclesal/tenguai.",https://ieeexplore.ieee.org/document/8356782/,2017 European Modelling Symposium (EMS),20-21 Nov. 2017,ieeexplore
10.1109/ICIS.2018.8466473,Development of a GPU-Based Human Emotion Recognition Robot Eye for Service Robot by Using Convolutional Neural Network,IEEE,Conferences,"Service robots can be used widely to assist elderly and disable population due to the lack of caregivers in future. Real-time human tracking, detection, focusing and implementing various algorithms are a wide range of application in emotion recognition service robots. Therefore service robots must have a properly designed robot eye model to be human-friendly with accurate human-robot interaction. Developed robot eye can be recognized the human emotional states by using well trained deep convolutional neural networks (ConvNet). This paper describes graphics processing units (GPUs) based human emotion recognition robot eye by using ConvNet. Mainly, the robot eye performs two processes in the intelligent systems. They are the robot eye focus to the human face and head by using pre-trained haar cascade classifier and recognizes the human emotional states probability with percentages as happy, sad or relaxes by using pre-trained ConvNet. The developed robot eye was implemented and tested by using different people successfully and the results of them are presented. According to the results, the emotions are detected more than 85% of overall accuracy for each person.",https://ieeexplore.ieee.org/document/8466473/,2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS),6-8 June 2018,ieeexplore
10.1109/ICRAIE51050.2020.9358310,Development of a Neural Network Library for Resource Constrained Speech Synthesis,IEEE,Conferences,"Machine learning frameworks, like Tensorflow and PyTorch, use GPU hardware acceleration to deliver the needed performance. Since GPUs require a lot of power (and space) to operate, typical use cases involve high-performance servers, with the final deployment available as a cloud service. To address limitations of this approach, AI Accelerators have been proposed. In this context, we have designed and implemented a library of neural network algorithms, to efficiently run on “edge devices”, with AI Accelerators. Moreover, a unified interface has been provided, to allow easy experimentation with various neural networks applied to the same dataset. Here, let us stress that we do not propose new algorithms, but port known ones to, resource restricted, edge devices. The context is provided by a speech synthesis application for edge devices that is deployed on an NVIDIA Jetson Nano. This application is to be used by social robots for real-time off-cloud text-to-speech processing.",https://ieeexplore.ieee.org/document/9358310/,2020 5th IEEE International Conference on Recent Advances and Innovations in Engineering (ICRAIE),1-3 Dec. 2020,ieeexplore
10.1109/IJCNN48605.2020.9206931,Developmental Learning of Value Functions in a Motivational System for Cognitive Robotics,IEEE,Conferences,"Motivation is quite an important topic when addressing continual open-ended learning processes in autonomous robots. The three main issues that need to be considered are, firstly, how does a designer define what the robot strives for in a manner that is independent from any particular domain it may find itself in. Secondly, once that robot is in a domain, how does it go about finding and relating goals in that particular domain on its own. Finally, the third issue is, once a goal is found, how does a robot establish a representation, usually in the form of a Value Function, that will allow it to exploit that goal. This paper deals with the third issue in the framework of the motivational engine we have designed for cognitive architectures. It addresses the problem of efficiently and appropriately learning complex Value Functions starting from intrinsically motivated traces of valuated robot actions that are often ambiguous and multivalued. To this end, a developmental learning mechanism is proposed that relies on the concurrent application of a real time ANN learning procedure over the traces of the valuated robot actions, and a simpler sensor correlation-based approach to allow for the production of better configured data traces for the learning process. The mechanism is analyzed and discussed over an experiment considering a real Baxter robot.",https://ieeexplore.ieee.org/document/9206931/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/CCDC.2019.8832952,Digital Implementation of the Spiking Neural Network and Its Digit Recognition,IEEE,Conferences,"Motivated by biological principles of neural systems, spiking neural network (SNN) shows a tremendous potential in solving pattern recognition and cognitive tasks in recent years. In this study, a biologically inspired SNN composed of three layers is implemented on a reconfigurable FPGA with high computational efficiency and low hardware cost. The proposed SNN is consists of spiking neurons simulated by leaky-integrate-and-fire neuron model. In addition, spiking-time-dependent-plasticity based on event-driven is utilized to train the constructed network. The real-time hardware realization of the proposed SNN demonstrates powerful and efficient learning scheme. Results on different datasets shows that the proposed SNN implementation has the merit of capability of coping with pattern recognition tasks. Furthermore, the proposed implementation with remarkable performance could be applied and embed in bio-inspired neuromorphic platform such as robots for recognition tasks and on-line applications.",https://ieeexplore.ieee.org/document/8832952/,2019 Chinese Control And Decision Conference (CCDC),3-5 June 2019,ieeexplore
10.1109/NCA.2013.21,Distributed and Dynamic Map-less Self-reconfiguration for Microrobot Networks,IEEE,Conferences,"MEMS micro robots are low-power and low memory capacity devices that can sense and act. One of the most challenges in MEMS micro robot applications is the self-reconfiguration, especially when the efficiency and the scalability of the algorithm are required. In the literature, if we want a self-reconfiguration of micro robots to a target shape consisting of P positions, each micro robot should have a memory capacity of P positions. Therefore, if P equals to millions, each node should have a memory capacity of millions of positions. Therefore, this is not scalable. In this paper, nodes do not record any position, we present a self-reconfiguration method where a set of micro robots are unaware of their current position and do not have the map of the target shape. In other words, nodes do not store the positions that build the target shape. Consequently, memory usage for each node is reduced to O(1). An algorithm of self-reconfiguration to optimize the communication is deeply studied showing how to manage the dynamicity (wake up and sleep of micro robots) of the network to save energy. Our algorithm is implemented in Meld, a declarative language, and executed in a real environment simulator called DPRSim.",https://ieeexplore.ieee.org/document/6623641/,2013 IEEE 12th International Symposium on Network Computing and Applications,22-24 Aug. 2013,ieeexplore
10.1109/VDAT50263.2020.9190415,DynRP- Non-Intrusive Profiler for Dynamic Reconfigurability,IEEE,Conferences,"Emerging technological areas such as machine learning, speech recognition, computer vision, autonomous robots, AI, bioinformatics involving big data, require implementation in complex heterogeneous accelerator platforms, to be able to handle data explosion with higher efficiency, lower power, and better performance. Dynamic reconfiguration in such platforms can help in run-time optimization to meet the design goals. The required optimal platform configuration can be achieved by a flexible design space exploration and appropriate task partitioning obtained through profiling computation and communication of processes in application code. This paper focuses on profiling, it being the key to the success of obtaining optimal platform configurations. It points to existing profiling techniques, their pros and cons vis-à-vis dynamic reconfigurable architectures, and the challenges in their design for obtaining optimal profiling performance. It further outlines desirable specifications for a profiler to allow dynamic real-time profiling for effective use of dynamic reconfiguration. DynRP, a non-intrusive hardware profiler for dynamic reconfiguration is proposed based on the desirable specifications, followed by its design and implementation details.",https://ieeexplore.ieee.org/document/9190415/,2020 24th International Symposium on VLSI Design and Test (VDAT),23-25 July 2020,ieeexplore
10.1109/ICRA48506.2021.9560730,Dynamic Object Aware LiDAR SLAM based on Automatic Generation of Training Data,IEEE,Conferences,"Highly dynamic environments, with moving objects such as cars or humans, can pose a performance challenge for LiDAR SLAM systems that assume largely static scenes. To overcome this challenge and support the deployment of robots in real world scenarios, we propose a complete solution for a dynamic object aware LiDAR SLAM algorithm. This is achieved by leveraging a real-time capable neural network that can detect dynamic objects, thus allowing our system to deal with them explicitly. To efficiently generate the necessary training data which is key to our approach, we present a novel end-to-end occupancy grid based pipeline that can automatically label a wide variety of arbitrary dynamic objects. Our solution can thus generalize to different environments without the need for expensive manual labeling and at the same time avoids assumptions about the presence of a predefined set of known objects in the scene. Using this technique, we automatically label over 12000 LiDAR scans collected in an urban environment with a large amount of pedestrians and use this data to train a neural network, achieving an average segmentation IoU of 0.82. We show that explicitly dealing with dynamic objects can improve the LiDAR SLAM odometry performance by 39.6% while yielding maps which better represent the environments. A supplementary video<sup>1</sup> as well as our test data<sup>2</sup> are available online.",https://ieeexplore.ieee.org/document/9560730/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICPR.1992.201790,Dynamic neural estimation for autonomous vehicles driving,IEEE,Conferences,"Mobile robots and vehicles may be driven by dynamical neural networks which utilize image data of real-world scenes collected through a TV camera for learning and performance. An innovative system for road direction detection is proposed which is comprised of three specialized blocks performing edge extraction, image-segments detection, and road direction estimation. The road direction estimation block is implemented as a feedback neural network.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/201790/,"Proceedings., 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems",30 Aug.-3 Sept. 1992,ieeexplore
10.1109/UIC-ATC.2013.107,Dynamicity to Save Energy in Microrobots Reconfiguration,IEEE,Conferences,"In this paper we present a dynamic self reconfiguration protocol for MEMS micro robots. The protocol presented in this paper is without map of the target shape which makes it efficient and scalable. In other words, nodes do not store the positions that build the target shape. Consequently, memory usage for each node is reduced to a constant complexity. An algorithm of self-reconfiguration is deeply studied showing how to manage the dynamicity (wake up and sleep of micro robots)of the network to save energy. Our algorithm is implemented in Meld, a declarative language, and executed in a real environment simulator called DPRSim.",https://ieeexplore.ieee.org/document/6726216/,2013 IEEE 10th International Conference on Ubiquitous Intelligence and Computing and 2013 IEEE 10th International Conference on Autonomic and Trusted Computing,18-21 Dec. 2013,ieeexplore
10.1109/IROS.2004.1389805,Dynamics from patterns: creating neural controllers with SENMP,IEEE,Conferences,"In this paper we show how simple laterally interacting computational entities, i.e. neurons, can be guided by a selectionist process into spatial patterns that show interesting and purposeful dynamics with regard to a particular utility measure. In other words, if a suitable population of laterally interacting mobile entities exist, it is possible to gradually arrange the entities into a spatial pattern that exhibits the desired dynamics. In this paper, the selectionist process is implemented with the stochastic evolutionary neuron migration process (SENMP) and approach is used to evolve dynamic recurrent neural networks (DRNNs) for controlling complex dynamic systems such as autonomous mobile robots, for example. The feasibility and advantages of the approach are demonstrated by evolving neural controllers for solving a non-Markovian double pole balancing problem. In addition, we have earlier used SENMP to evolve navigation behaviors for mobile robots in complex simulated and real environments.",https://ieeexplore.ieee.org/document/1389805/,2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),28 Sept.-2 Oct. 2004,ieeexplore
10.1109/EMBC.2015.7318719,EEG error potentials detection and classification using time-frequency features for robot reinforcement learning,IEEE,Conferences,"In thought-based steering of robots, error potentials (ErrP) can appear when the action resulting from the brain-machine interface (BMI) classifier/controller does not correspond to the user's thought. Using the Steady State Visual Evoked Potentials (SSVEP) techniques, ErrP, which appear when a classification error occurs, are not easily recognizable by only examining the temporal or frequency characteristics of EEG signals. A supplementary classification process is therefore needed to identify them in order to stop the course of the action and back up to a recovery state. This paper presents a set of time-frequency (t-f) features for the detection and classification of EEG ErrP in extra-brain activities due to misclassification observed by a user exploiting non-invasive BMI and robot control in the task space. The proposed features are able to characterize and detect ErrP activities in the t-f domain. These features are derived from the information embedded in the t-f representation of EEG signals, and include the Instantaneous Frequency (IF), t-f information complexity, SVD information, energy concentration and sub-bands' energies. The experiment results on real EEG data show that the use of the proposed t-f features for detecting and classifying EEG ErrP achieved an overall classification accuracy up to 97% for 50 EEG segments using 2-class SVM classifier.",https://ieeexplore.ieee.org/document/7318719/,2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),25-29 Aug. 2015,ieeexplore
10.1109/CSCloud-EdgeCom49738.2020.00050,Edge Computing-based 3D Pose Estimation and Calibration for Robot Arms,IEEE,Conferences,"Industrial robots are widely used in current production lines, and complex pipeline processes, especially those with different assembly requirements, are designed for intelligent manufacturing in the era of industry 4.0. During the new crown epidemic, a large number of car companies used the production line to transform production of medical materials such as masks and protective clothing, which provided a strong guarantee for fighting the epidemic. In this scenario, a pipeline is often assembled from robotic arms from multiple suppliers. The traditional methods is complex and takes a lot of time. In this paper, we propose a novel deep learning based robot arm 3D pose estimation and calibration model with simple Kinect stereo cameras which can be deployed on light-weight edge computing systems. The light-weight deep CNN model can detection 5 predefined key points based on RGB-D data. In this way, when the assembly line composed of different robot arms needs to be reassembled, our model can quickly provide the robot's pose information without additional tuning processes. Testing in Webots with Rokae xb4 robot arm model shows that our model can quickly estimate the key point of the robot arm.",https://ieeexplore.ieee.org/document/9170983/,2020 7th IEEE International Conference on Cyber Security and Cloud Computing (CSCloud)/2020 6th IEEE International Conference on Edge Computing and Scalable Cloud (EdgeCom),1-3 Aug. 2020,ieeexplore
10.1109/RCAR.2018.8621810,Efficient and Low-Cost Deep-Learning Based Gaze Estimator for Surgical Robot Control,IEEE,Conferences,"Surgical robots are playing more and more important role in modern operating room. However, operations by using surgical robot are not easy to handle by doctors. Vision based human-computer interaction (HCI) is a way to ease the difficulty to control surgical robots. While the problem of this method is that eyes tracking devices are expensive. In this paper, a low cost and robust deep-learning based on gaze estimator is proposed to control surgical robots. By this method, doctors can easily control the robot by specifying the starting point and ending point of the surgical robot using eye gazing. Surgical robots can also be controlled to move in 9 directions using controllers' eyes gazing information. A Densely Connected convolutional Neural Networks (Dense CNN) model for 9-direction/36-direction gaze estimation is built. The Dense CNN architecture has much more less trainable parameters compared to traditional CNN network architecture (AlexNet like/VGG like) which is more feasible to deploy on the Field-Programmable Gate Array (FPGA) and other hardware with limited memories.",https://ieeexplore.ieee.org/document/8621810/,2018 IEEE International Conference on Real-time Computing and Robotics (RCAR),1-5 Aug. 2018,ieeexplore
10.1109/IROS.2016.7759250,Efficient learning of stand-up motion for humanoid robots with bilateral symmetry,IEEE,Conferences,"Standing up after falling is an essential ability for humanoid robots in order to resume their tasks without help from humans. Although many humanoid robots, especially small-size humanoid robots, have their own stand-up motions, there has not been a generalized method to automatically learn flexible stand-up motions for humanoid robots which can be applied to various fallen positions. In this research, we propose a method for learning stand-up motions for humanoid robots using Q-learning making use of their bilateral symmetry. We implemented this method on DarwIn-OP humanoid robots and learned an optimal policy in simulation. We compared the resulting stand-up motion with manually designed stand-up motions and with stand-up motions learned without considering bilateral symmetry. Both in simulation and on the real robot, the new stand-up motion was successful in most trials while other motions took longer or were not as robust.",https://ieeexplore.ieee.org/document/7759250/,2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),9-14 Oct. 2016,ieeexplore
10.1109/IROS.2012.6385832,Elastic strips: Implementation on a physical humanoid robot,IEEE,Conferences,"For robots to operate in human environments, they are required to react safely to unexpected changes in the work area. However, existing manipulation task planning methods take more than several seconds or minutes to update their solutions when environmental changes are recognized. Furthermore, the computation time exponentially increases in case of highly complex structures such as humanoid robots. Therefore, we propose a reactive system for high d.o.f. robots to perform interactive manipulation tasks under real-time conditions. The paper describes the implementation of the Elastic Strip Framework, a plan modification approach to update initial motion plans. To improve its real-time performance and reliability, the previous geometric approximation is replaced by an implicit method that constructs an elastic tunnel for collision checking. Additionally, in order to maintain a robust system even in exceptional situations, such as undetected obstacles, the force transformer module executes compliant motions, and the current elastic strip adapts the path tracking motion by monitoring tracking errors of the actual motion. The proposed system is applied to a Honda humanoid robot. Real-time performance is successfully demonstrated in real-world experiments.",https://ieeexplore.ieee.org/document/6385832/,2012 IEEE/RSJ International Conference on Intelligent Robots and Systems,7-12 Oct. 2012,ieeexplore
10.1109/IROS.2001.976268,Embedding cooperation in robots to play soccer game,IEEE,Conferences,"Robotic soccer provides an opportunity to explore such a challenging research topic that multiple agents (physical robots or sofbots) work together in a realtime, noisy and adversarial environment to obtain specific objectives. It requires each agent can not only deal with infinite unpredictable situations, but also present cooperation with others. The previous researches about cooperation often put emphasis on task decomposition and conflict avoidance among team members. In this paper, we describe a robot architecture, which addresses ""scaling cooperation"" among robots, and meanwhile keeps each robot making decision independently. The architecture is based on ""ideal cooperation"" principle and implemented for Small Robot League in RoboCup Experimental results prove its effectiveness and reveal several primary characteristics of behaviors in robotic soccer. Finally, some important problems of future work are discussed.",https://ieeexplore.ieee.org/document/976268/,Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180),29 Oct.-3 Nov. 2001,ieeexplore
10.1109/RO-MAN46459.2019.8956327,End-User Programming of Low-and High-Level Actions for Robotic Task Planning,IEEE,Conferences,"Programming robots for general purpose applications is extremely challenging due to the great diversity of end-user tasks ranging from manufacturing environments to personal homes. Recent work has focused on enabling end-users to program robots using Programming by Demonstration. However, teaching robots new actions from scratch that can be reused for unseen tasks remains a difficult challenge and is generally left up to robotic experts. We propose iRoPro, an interactive Robot Programming framework that allows end-users to teach robots new actions from scratch and reuse them with a task planner. In this work we provide a system implementation on a two-armed Baxter robot that (i) allows simultaneous teaching of low-and high-level actions by demonstration, (ii) includes a user interface for action creation with condition inference and modification, and (iii) allows creating and solving previously unseen problems using a task planner for the robot to execute in real-time. We evaluate the generalisation power of the system on six benchmark tasks and show how taught actions can be easily reused for complex tasks. We further demonstrate its usability with a user study (N=21), where users completed eight tasks to teach the robot new actions that are reused with a task planner. The study demonstrates that users with any programming level and educational background can easily learn and use the system.",https://ieeexplore.ieee.org/document/8956327/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/ICCE.2018.8326229,End-to-end deep learning for autonomous navigation of mobile robot,IEEE,Conferences,"This paper proposes an end-to-end method for training convolutional neural networks for autonomous navigation of a mobile robot. Traditional approach for robot navigation consists of three steps. The first step is extracting visual features from the scene using the camera input. The second step is to figure out the current position by using a classifier on the extracted visual features. The last step is making a rule for moving the direction manually or training a model to handle the direction. In contrast to the traditional multi-step method, the proposed visuo-motor navigation system can directly output the linear and angular velocities of the robot from an input image in a single step. The trained model gives wheel velocities for navigation as outputs in real-time making it possible to be implanted on mobile robots such as robotic vacuum cleaner. The experimental results show an average linear velocity error of 2.2 cm/s and average angular velocity error of 3.03 degree/s. The robot deployed with the proposed model can navigate in a real-world environment by only using the camera without relying on any other sensors such as LiDAR, Radar, IR, GPS, IMU.",https://ieeexplore.ieee.org/document/8326229/,2018 IEEE International Conference on Consumer Electronics (ICCE),12-14 Jan. 2018,ieeexplore
10.1109/CAIA.1989.49141,Experiences with the subsumption architecture,IEEE,Conferences,"A subsumption architecture has been proposed as an effective approach for the construction of robust, real-time control systems for mobile robots. To investigate its strengths and weaknesses, a simulation of the architecture was developed called the Subsumption Architecture Tool (SAT). This simulation allows various models of system behavior to be quickly built and tested. During the building and testing of the SAT, issues related to some architectural features became evident: level of commitment of each layer; code redundancy; problem decomposition and programming style; complexity of large system; and abstract reasoning capabilities. The effects of these issues are presented with respect to the design and implementation choices of two sample layers of behavior. These layers are used to illustrate considerations that need to be taken into account when a project team is considering the use of the subsumption architecture or when a subsumption-architecture-based system is being designed and implemented.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/49141/,[1989] Proceedings. The Fifth Conference on Artificial Intelligence Applications,6-10 March 1989,ieeexplore
10.1109/ICRA.2019.8793829,Exploiting Trademark Databases for Robotic Object Fetching,IEEE,Conferences,"Service robots require the ability to recognize various household objects in order to carry out certain tasks, such as fetching an object for a person. Manually collecting information on all the objects a robot may encounter in a household is tedious and time-consuming; therefore this paper proposes the use of large-scale data from existing trademark databases. These databases contain logo images and a description of the goods and services the logo was registered under. For example, Pepsi is registered under soft drinks. We extend domain randomization in order to generate synthetic data to train a convolutional neural network logo detector, which outperformed previous logo detectors trained on synthetic data. We also provide a practical implementation for object fetching on a robot, which uses a Kinect and the logo detector to identify the object the human user requested. Tests on this robot indicate promising results, despite not using any real world photos for training.",https://ieeexplore.ieee.org/document/8793829/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/AIM.2019.8868536,Exploiting the ACCuracy-ACCeleration tradeoff: VINS-assisted real-time object detection on moving systems,IEEE,Conferences,"In recent years, Convolutional Neural Networks (CNNs) have repeatedly shown state-of-the-art performance for their accuracy in the task of object detection, but their heavy computational costs impede their ability for real-time detection when the supporting system is moving, particularly when it is accelerating. At the same time, recent progress on visual inertial systems takes great advantage of movement information to robustly estimate the robot state and its surrounding. This paper proposes to exploit the advantages of inertial odometry research for the purpose of real-time object detection system on mobile robots. We combine a CNN detector with VINS-Mono, a moving visual odometry system, and show reliable improvement in the detection process, especially when the robot accelerates or decelerates. Our system is ready-to-use in that it has very low deployment cost and requires no calibration. The resulting system allows for simultaneous robot state estimation and object detection, as well as object tracking. Lastly, this architecture proves to be flexible because not restrained to a specific object type or detector.",https://ieeexplore.ieee.org/document/8868536/,2019 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM),8-12 July 2019,ieeexplore
10.1109/SIEDS49339.2020.9106581,"Explorer51 – Indoor Mapping, Discovery, and Navigation for an Autonomous Mobile Robot",IEEE,Conferences,"The nexus of robotics, autonomous systems, and artificial intelligence (AI) has the potential to change the nature of human guided exploration of indoor and outdoor spaces. Such autonomous mobile robots can be incorporated into a variety of applications, ranging from logistics and maintenance, to intelligence gathering, surveillance, and reconnaissance (ISR). One such example is that of a tele-operator using the robot to generate a map of the inside of a building while discovering and tagging the objects of interest. During this process, the tele-operator can also assign an area for the robot to navigate autonomously or return to a previously marked area/object of interest. Search and rescue and ISR abilities could be immensely improved with such capabilities. The goal of this research is to prototype and demonstrate the above autonomous capabilities in a mobile ground robot called Explorer51. Objectives include: (i) enabling an operator to drive the robot non-line of sight to explore a space by incorporating a first-person view (FPV) system to stream data from the robot to the base station; (ii) implementing automatic collision avoidance to prevent the operator from running the robot into obstacles; (iii) creating and saving 2D and 3D maps of the space in real time by using a 2D laser scanner, tracking, and depth/RGB cameras; (iv) locating and tagging objects of interest as waypoints within the map; (v) autonomously navigate within the map to reach a chosen waypoint. To accomplish these goals, we are using the AION Robotics R1 Unmanned Ground Vehicle (UGV) rover as the platform for Explorer51 to demonstrate the autonomous features. The rover runs the Robot Operating System (ROS) onboard an NVIDIA Jetson TX2 board, connected to a Pixhawk controller. Sensors include a 2D scanning LiDAR, depth camera, tracking camera, and an IMU. Using existing ROS packages such as Cartographer and TEB planner, we plan to implement ROS nodes for accomplishing these tasks. We plan to extend the mapping ability of the rover using Visual Inertial Odometry (VIO) using the cameras. In addition, we will explore the implementation of additional features such as autonomous target identification, waypoint marking, collision avoidance, and iterative trajectory optimization. The project will culminate in a series of demonstrations to showcase the autonomous navigation, and tele-operation abilities of the robot. Success will be evaluated based on ease of use by the tele-operator, collision avoidance ability, autonomous waypoint navigation accuracy, and robust map creation at high driving speeds.",https://ieeexplore.ieee.org/document/9106581/,2020 Systems and Information Engineering Design Symposium (SIEDS),24-24 April 2020,ieeexplore
10.1109/ROMAN.2017.8172449,Exploring data augmentation methods in reverberant human-robot voice communication,IEEE,Conferences,"Collecting training data is not an easy task especially in situation involving robots that require tremendous physical effort. The ability to augment data through synthetic means is a convenient tool to solve this problem. Therefore it is important to evaluate the extent of the usefulness of augmented data. In this paper, we will explore data augmentation schemes in reverberant environment and investigate a method to effectively select data. We experiment in a real reverberant environment condition and investigate both the traditional automatic speech recognition (ASR) system based on gaussian mixture model-hidden markov model (GMM-HMM) and the most current system based on Deep Neural Networks (i.e, HMM-DNN). Our results show that the combination of data augmentation and data selection, further improves system performance. In our experiments, we used real test data in a reverberant hands-free human-robot communication scenario.",https://ieeexplore.ieee.org/document/8172449/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/ROBOT.2003.1241690,Extended QDSEGA for controlling real robots - acquisition of locomotion patterns for snake-like robot,IEEE,Conferences,"Reinforcement learning is very effective for robot learning. It is because it does not need prior knowledge and has higher capability of reactive and adaptive behaviors. In our previous works, we proposed new reinforce learning algorithm: ""Q-learning with dynamic structuring of exploration space based on genetic algorithm (QDSEGA)"". It is designed for complicated systems with large action-state space like a robot with many redundant degrees of freedom. However the application of QDSEGA is restricted to static systems. A snake-like robot has many redundant degrees of freedom and the dynamics of the system are very important to complete the locomotion task. So application of usual reinforcement learning is very difficult. In this paper, we extend layered structure of QDSEGA so that it becomes possible to apply it to real robots that have complexities and dynamics. We apply it to acquisition of locomotion pattern of the snake-like robot and demonstrate the effectiveness and the validity of QDSEGA with the extended layered structure by simulation and experiment.",https://ieeexplore.ieee.org/document/1241690/,2003 IEEE International Conference on Robotics and Automation (Cat. No.03CH37422),14-19 Sept. 2003,ieeexplore
10.1109/AMC.2019.8371065,"Extending the life of legacy robots: MDS-Ach, a real-time, process based, networked, secure middleware based on the x-Ach methodology",IEEE,Conferences,"This work shows how to add modern tools to legacy robots while retaining the original tools and original calibration procedures/utilities through the use of a lightweight middleware connected to the communications level of the robot. MDS-Ach is a middleware made for the Xitome Mobile Dexterous Social (MDS) Robot originally released in 2008. The robot is being actively used at multiple locations including the U.S. Naval Research Laboratory's Laboratory for Autonomous Systems Research (NRL-LASR). The MDS-Ach middleware gives the MDS Robot the software capabilities of modern robot systems using the x- Ach real-time processes based architecture. It controls the MDS Robot directly over the controller area network (CAN) bus via a dedicated real-time daemon. Each process communicates with the others over a network capable shared memory. The shared memory is a ""first-in-last-out"" (i.e. reads the newest data first) non-head-of-line blocking ring buffer which ensures readability of latest data first while retaining the ability to retrieve the older data. When running over a network, UDP or TCP protocol can be utilized depending on the timing and reliability requirements. SSH tunneling is used when secure connections between networked controllers are required. The MDS-Ach middleware is designed to allow for simple and easy development with modern robotic tools while adding accessibility and usability to our non-hardware-focused partners. Real-time collision avoidance and a robust inverse kinematics solution are implemented within the MDS-Ach system. Examples of collision avoidance, inverse kinematics implementation, and the software architecture are given.",https://ieeexplore.ieee.org/document/8371065/,2018 IEEE 15th International Workshop on Advanced Motion Control (AMC),9-11 March 2018,ieeexplore
10.1109/ICSyS47076.2019.8982469,FPGA-enabled Binarized Convolutional Neural Networks toward Real-time Embedded Object Recognition System for Service Robots,IEEE,Conferences,"In this presentation, we report the results of applying a binarized Convolutional Neural Network (CNN) and a Field Programmable Gate Array (FPGA) for image-based object recognition. While the demand rises for robots with robust object recognition implemented with Neural Networks, a tradeoff between data processing rate and power consumption persists. Some applications utilise Graphics Processing Units (GPU), which results in high power consumption, thus undesirable for embedded systems, while the others communicate with cloud computers to minimise computational resources at the clients' side, i.e. robots, raising another concern that the robots are unable to perform object recognition without the servers and network connections. To overcome these difficulties, we propose an embedded object recognition system implemented with a binarized CNN and an FPGA. FPGAs consist of a matrix of reconfigurable logic gates allowing parallel computing which befit most image processing algorithms such as the CNN. We train the binarized CNN on one of our datasets that contain images of several kinds of food and beverages. The results of the experiments show that the binarized CNN with an FPGA maintains high accuracy as well as real-time computation, suggesting that the proposed system is suitable for robots to perform their tasks in a real-world environment without needing to communicate with a server.",https://ieeexplore.ieee.org/document/8982469/,2019 IEEE International Circuits and Systems Symposium (ICSyS),18-19 Sept. 2019,ieeexplore
10.1109/ICRA.2019.8793593,"Fast Instance and Semantic Segmentation Exploiting Local Connectivity, Metric Learning, and One-Shot Detection for Robotics",IEEE,Conferences,"Semantic scene understanding is important for autonomous robots that aim to navigate dynamic environments, manipulate objects, or interact with humans in a natural way. In this paper, we address the problem of jointly performing semantic segmentation as well as instance segmentation in an online fashion, so that autonomous robots can use this information on-the-go and without sacrificing accuracy. We achieve this by exploiting a local connectivity prior of objects in the real world and a multi-task convolutional neural network architecture. The network identifies the individual object instances and their classes without region proposals or pre-segmentation of the images into individual classes. We implemented and thoroughly evaluated our approach, and our experiments suggest that our method can be used to accurately segment instance masks of objects and identify their class in an online fashion.",https://ieeexplore.ieee.org/document/8793593/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/IROS.2004.1389583,"Fast, reliable, adaptive, bimodal people tracking for indoor environments",IEEE,Conferences,"We present a real-time system for a mobile robot that can reliably detect and track people in uncontrolled indoor environments. The system uses a combination of leg detection based on distance information from a laser range sensor and visual face detection based on an analogical algorithm implemented on specialized hardware (the CNN universal machine). Results from tests in a variety of environments with different lighting conditions, a different number of appearing and disappearing people, and different obstacles are reported to demonstrate that the system can find and subsequently track several, possibly people simultaneously in indoor environments. Applications of the system include in particular service robots for social events.",https://ieeexplore.ieee.org/document/1389583/,2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),28 Sept.-2 Oct. 2004,ieeexplore
10.1109/ICMLC.2004.1380629,Fault tolerance for communication-based multirobot formation,IEEE,Conferences,"This paper investigates the ability of fault tolerance for multirobot formation, which is important for practical formation in complex environment. Our model enables mobile robots group to continue to complete given tasks by reorganizing their formation, when some members are in failure. First, to build such model, a multi-agent architecture is presented, which is implemented through communication. Second, we introduce the hierarchy graph of multirobot formation to be the theoretical foundation of the fault tolerance system. The graph analysis is suitable for general leader-follower formation format. And then, the failure detection mechanism for formation is discussed. Finally, integrated fault tolerance algorithm is investigated, including supplement for faulty robots and formation reconfiguration. The improved agent architecture adding the fault tolerance module is also presented. The experiments on real multiple mobile robots demonstrate our design is feasible.",https://ieeexplore.ieee.org/document/1380629/,Proceedings of 2004 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.04EX826),26-29 Aug. 2004,ieeexplore
10.1109/CYBER53097.2021.9588329,Fault-Aware Robust Control via Adversarial Reinforcement Learning,IEEE,Conferences,"Robots have limited adaptation ability compared to humans and animals in the case of damage. However, robot damages are prevalent in realworld applications, especially for robots deployed in extreme environments. The fragility of robots greatly limits their widespread application. We propose an adversarial reinforcement learning framework, which significantly increases robot robustness over joint damage cases in both manipulation tasks and locomotion tasks. The agent is trained iteratively under the joint damage cases where it has poor performance. We validate our algorithm on a three-fingered robot hand and a quadruped robot. Our algorithm can be trained only in simulation and directly deployed on a real robot without any fine-tuning. It also demonstrates exceeding success rates over arbitrary joint damage cases.",https://ieeexplore.ieee.org/document/9588329/,"2021 IEEE 11th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)",27-31 July 2021,ieeexplore
10.1109/RIOS.2013.6595317,Flexible snake robot: Design and implementation,IEEE,Conferences,"This paper presents a snake robot able to pass different and difficult paths because of special physical form and movement joints mechanism. These snake robots have no passive wheels. The robot moves by friction between the robot body and the surface on which it is. The joints have been designed and fabricated in a way that each joint has two freedom grades and it may move 228 degrees in every direction. Each joint has two DC servo motors and the power is transferred from the motors output to the joint shaft through bevel gear. The flexibility of the robot makes possible to move forward, back and laterally by imitating real snake's moves. In this paper different measures have been presented in order to design and assemble the joints, motors driver, different ways to guide the robot and its vision.",https://ieeexplore.ieee.org/document/6595317/,2013 3rd Joint Conference of AI & Robotics and 5th RoboCup Iran Open International Symposium,8-8 April 2013,ieeexplore
10.1109/VR.2015.7223421,Flying robot manipulation system using a virtual plane,IEEE,Conferences,"The flexible movements of flying robots make it difficult for novices to manipulate them precisely with controllers such as a joystick and a proportional radio system. Moreover, the mapping of instructions between a robot and its reactions is not necessarily intuitive for users. We propose manipulation methods for flying robots using augmented reality technologies. In the proposed system, a virtual plane is superimposed on a flying robot and users control the robot by manipulating the virtual plane and drawing a moving path on it. We present the design and implementation of our system and describe experiments conducted to evaluate our methods.",https://ieeexplore.ieee.org/document/7223421/,2015 IEEE Virtual Reality (VR),23-27 March 2015,ieeexplore
10.1109/IROS.2016.7759701,From indoor GIS maps to path planning for autonomous wheelchairs,IEEE,Conferences,"This work focuses on how to compute trajectories for an autonomous wheelchair based on indoor GIS maps, in particular on IndoorGML maps, which set the standard in this context. Good wheelchair trajectories are safe and comfortable for the user and the people sharing the space with him, turn gently, are high legible, and smooth (at least G<sup>2</sup> continuos). We derive a navigation graph from a given IndoorGML map. We define and solve an optimization problem to find the desired path: given a succession of cells to traverse, the path corresponds to the best composite Bézier trajectory for the wheelchair. We discuss a related multi-objective path planning problem. Experimental results and an implementation on real robots show the planner performance.",https://ieeexplore.ieee.org/document/7759701/,2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),9-14 Oct. 2016,ieeexplore
10.1109/CDC40024.2019.9029916,From self-tuning regulators to reinforcement learning and back again,IEEE,Conferences,"Machine and reinforcement learning (RL) are increasingly being applied to plan and control the behavior of autonomous systems interacting with the physical world. Examples include self-driving vehicles, distributed sensor networks, and agile robots. However, when machine learning is to be applied in these new settings, the algorithms had better come with the same type of reliability, robustness, and safety bounds that are hallmarks of control theory, or failures could be catastrophic. Thus, as learning algorithms are increasingly and more aggressively deployed in safety critical settings, it is imperative that control theorists join the conversation. The goal of this tutorial paper is to provide a starting point for control theorists wishing to work on learning related problems, by covering recent advances bridging learning and control theory, and by placing these results within an appropriate historical context of system identification and adaptive control.",https://ieeexplore.ieee.org/document/9029916/,2019 IEEE 58th Conference on Decision and Control (CDC),11-13 Dec. 2019,ieeexplore
10.1109/COASE.2017.8256157,Full automatic path planning of cooperating robots in industrial applications,IEEE,Conferences,"Parts made of carbon fiber reinforced plastics (CFRP) for airplane components can be so huge that a single industrial robot is no longer able to handle them, and cooperating robots are required. Manual programming of cooperating robots is difficult, but with large numbers of different sized and shaped cut-pieces, it is almost impossible. This paper presents an automated production system consisting of a camera for the precise detection of the position of each cut-piece and a collision-free path planner which can dynamically react to different positions for the transfer motions. The path is planned for multiple robots adhering to motion constrains, such as the requirement that the textile cut-piece must form a catenary which can change during transport. Additionally a technique based on machine learning has been implemented which correctly resolves redundancy for a linear axis during planning. Finally, all components are tested on a real robot system in industrial scale.",https://ieeexplore.ieee.org/document/8256157/,2017 13th IEEE Conference on Automation Science and Engineering (CASE),20-23 Aug. 2017,ieeexplore
10.1109/FUZZY.2006.1681996,Fuzzy Logic based Active Map Learning for Autonomous Robot,IEEE,Conferences,"The paper proposes a fast map learning approach for real-time map building and active exploration in unknown indoor environments. This approach includes a map model, a map update method, an exploration method, and a map postprocessing method. The map adopts a grid-based representation and uses frequency value to measure the confidence that a cell is occupied by an obstacle. The exploration method is implemented by coordinating two novel behaviors: path-exploring behavior and environment-detection behavior. Fuzzy logic is used to implement the behavior design and coordination. The fast map update and path planning (i.e. the exploration method) make our approach a candidate for real-time implementation on mobile robots. The results are demonstrated by simulated experiments based on a Pioneer robot with eight forward sonar sensors.",https://ieeexplore.ieee.org/document/1681996/,2006 IEEE International Conference on Fuzzy Systems,16-21 July 2006,ieeexplore
10.1109/FUZZY.1996.551714,Fuzzy logic control of an obstacle avoidance robot,IEEE,Conferences,"A fuzzy controller is used to control an obstacle avoidance mobile robot. In this classical problem, the aim is to guide a mobile robot along its path to avoid any static obstacles in front of it. Obstacle avoidance in real-time is a mandatory feature for mobile robots in a dynamically unknown environment. The controller presented here uses three sub-controllers. The outputs are summed to produce a concerted effort to control the motors steering the robot away from obstacles. This fuzzy controller was implemented on a miniature robot. This robot is able to overcome its limitation on range accuracy to follow a left wall, maintaining a short distance from it, to avoid obstacles in front of it, and to decide whether a gap is wide enough for a ""side-step"" manoeuvre.",https://ieeexplore.ieee.org/document/551714/,Proceedings of IEEE 5th International Fuzzy Systems,11-11 Sept. 1996,ieeexplore
10.1109/ROMAN.2004.1374845,Fuzzy reinforcement learning for an evolving virtual servant robot,IEEE,Conferences,"This work presents our research in the application of reinforcement learning algorithms for the generation of autonomous intelligent virtual robots, that can learn and enhance their task performance in assisting humans in housekeeping. For the control system architecture of the virtual agents, two algorithms, based on Watkins' Q(/spl lambda/) learning and the zeroth-level classifier system (ZLCS), are incorporated with fuzzy inference systems(FlS). Performance of these algorithms is evaluated and compared. A 3D application of a virtual robot whose task is to interact with virtual humans and offer optimal services on everyday in-house needs is designed and implemented. The learning systems are incorporated in the decision-making process of the virtual robot servant to allow itself to understand and evaluate the fuzzy value requirements and enhance its performance.",https://ieeexplore.ieee.org/document/1374845/,RO-MAN 2004. 13th IEEE International Workshop on Robot and Human Interactive Communication (IEEE Catalog No.04TH8759),22-22 Sept. 2004,ieeexplore
10.1109/IROS40897.2019.8967785,GQ-STN: Optimizing One-Shot Grasp Detection based on Robustness Classifier,IEEE,Conferences,"Grasping is a fundamental robotic task needed for the deployment of household robots or furthering warehouse automation. However, few approaches are able to perform grasp detection in real time (frame rate). To this effect, we present Grasp Quality Spatial Transformer Network (GQ-STN), a one-shot grasp detection network. Being based on the Spatial Transformer Network (STN), it produces not only a grasp configuration, but also directly outputs a depth image centered at this configuration. By connecting our architecture to an externally-trained grasp robustness evaluation network, we can train efficiently to satisfy a robustness metric via the backpropagation of the gradient emanating from the evaluation network. This removes the difficulty of training detection networks on sparsely annotated databases, a common issue in grasping. We further propose to use this robustness classifier to compare approaches, being more reliable than the traditional rectangle metric. Our GQ-STN is able to detect robust grasps on the depth images of the Dex-Net 2.0 dataset with 92.4 % accuracy in a single pass of the network. We finally demonstrate in a physical benchmark that our method can propose robust grasps more often than previous sampling-based methods, while being more than 60 times faster.",https://ieeexplore.ieee.org/document/8967785/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/IJCNN.2015.7280540,Gesture based human multi-robot interaction,IEEE,Conferences,"The emergence of robot applications for non-technical users implies designing new ways of interaction between robotic platforms and users. The main goal of this work is the development of a gestural interface to interact with robots in a similar way as humans do, allowing the user to provide information of the task with non-verbal communication. The gesture recognition application has been implemented using the Microsoft's Kinect<sup>™</sup> v2 sensor. Hence, a real-time algorithm based on skeletal features is described to deal with both, static gestures and dynamic ones, being the latter recognized using a weighted Dynamic Time Warping method. The gesture recognition application has been implemented in a multi-robot case. A NAO humanoid robot is in charge of interacting with the users and respond to the visual signals they produce. Moreover, a wheeled Wifibot robot carries both the sensor and the NAO robot, easing navigation when necessary. A broad set of user tests have been carried out demonstrating that the system is, indeed, a natural approach to human robot interaction, with a fast response and easy to use, showing high gesture recognition rates.",https://ieeexplore.ieee.org/document/7280540/,2015 International Joint Conference on Neural Networks (IJCNN),12-17 July 2015,ieeexplore
10.1109/CACRE52464.2021.9501291,Give Me a Wrench!: Finding Tools for Human Partners in Human-Robot Collaborative Manufacturing Contexts,IEEE,Conferences,"Manufacturing processes can be optimized by enabling human-robot collaboration. A relevant goal in this area is to create a collaborative solution in which robots can provide assisting actions to humans, thereby, reducing menial labor as well as increasing productivity. The solution is based on implementing efficient hand-over of mechanical tools from robots to humans. Hand-over tasks are inevitable in human-robot collaborative manufacturing contexts. These tasks need three-step mechanism: object identification, object grasping, and the actual hand-over. This paper presents an approach for robots to find tools for human partners in human-robot collaboration via deep learning. This is achieved using the object detection system YOLOv3 for identification of commonly used mechanical tools. By training on a custom dataset of 800 images of mechanical tools created for the study, the tool recognition is implemented in realworld human-robot hand-over tasks. Experimental results show that the proposed approach achieves a high accuracy for identification of tools in real-world human-robot collaboration. Future work of this study is also discussed.",https://ieeexplore.ieee.org/document/9501291/,"2021 6th International Conference on Automation, Control and Robotics Engineering (CACRE)",15-17 July 2021,ieeexplore
10.1109/ICRA.2019.8793810,Goal-Driven Navigation for Non-holonomic Multi-Robot System by Learning Collision,IEEE,Conferences,"In this paper, we propose the reinforcement learning based multi-robot collision avoidance approach by learning collision. Dynamical path re-planning, which is massively used in classical collision avoidance methods, needs overall information of the environment. Also, training agent robots to avoid the collision and pursue a goal point simultaneously is inefficient since the agent should learn two tasks. As the number of tasks that the agent should learn increases, it is difficult to make the performance of an algorithm consistent, which is known as reproducibility issue. To overcome these limitations, Collision Avoidance by Learning Collision (CALC), which learns collision instead of avoiding an obstacle robot is suggested. To solve the collision avoidance problem efficiently, the proposed method divides the problem into training and planning. In the training algorithm, an agent robot learns how to collide with a single obstacle robot and then generates a trained policy. With the trained policy, the agent can pursue a goal point since the policy leads the agent to `collide' with the goal. Furthermore, by taking action in a reverse way from the trained policy, the agent can avoid multiple obstacle robots in the planning algorithm at once. The proposed method is validated both in the robot simulation and real robot experiment, and compared with the existing collision avoidance method.",https://ieeexplore.ieee.org/document/8793810/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/RO-MAN47096.2020.9223558,HATSUKI : An anime character like robot figure platform with anime-style expressions and imitation learning based action generation,IEEE,Conferences,"Japanese character figurines are popular and have a pivot position in Otaku culture. Although numerous robots have been developed, few have focused on otaku-culture or on embodying anime character figurines. Therefore, we take the first steps to bridge this gap by developing Hatsuki, which is a humanoid robot platform with anime based design. Hatsuki's novelty lies in its aesthetic design, 2D facial expressions, and anime-style behaviors that allows Hatsuki to deliver rich interaction experiences resembling anime-characters. We explain our design implementation process of Hatsuki, followed by our evaluations. In order to explore user impressions and opinions towards Hatsuki, we conducted a questionnaire in the world's largest anime-figurine event. The results indicate that participants were generally very satisfied with Hatsuki's design, and proposed various use case scenarios and deployment contexts for Hatsuki. The second evaluation focused on imitation learning, as such a method can provide better interaction ability in the real world and generate rich, context-adaptive behaviors in different situations. We made Hatsuki learn 11 actions, combining voice, facial expressions and motions, through the neural network based policy model with our proposed interface. Results show our approach was successfully able to generate the actions through self-organized contexts, which shows the potential for generalizing our approach in further actions under different contexts. Lastly, we present our future research direction for Hatsuki and provide our conclusion.",https://ieeexplore.ieee.org/document/9223558/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore
10.1109/SIBGRAPI51738.2020.00016,HTR-Flor: A Deep Learning System for Offline Handwritten Text Recognition,IEEE,Conferences,"In recent years, Handwritten Text Recognition (HTR) has captured a lot of attention among the researchers of the computer vision community. Current state-of-the-art approaches for offline HTR are based on Convolutional Recurrent Neural Networks (CRNNs) excel at scene text recognition. Unfortunately, deep models such as CRNNs, Recur-rent Neural Networks (RNNs) are likely to suffer from vanishing/exploding gradient problems when processing long text images, which are commonly found in scanned documents. Besides, they usually have millions of parameters which require huge amount of data, and computational resource. Recently, a new class of neural net-work architecture, called Gated Convolutional Neural Networks (Gated-CNN), has demonstrated potentials to complement CRNN methods in modeling. Therefore, in this paper, we present a new architecture for HTR, based on Gated-CNN, with fewer parameters and fewer layers, which is able to outperform the current state-of-the-art architectures for HTR. The experiment validates that the proposed model has statistically significant recognition results, surpassing previous HTR systems by an average of 33% over five important handwritten benchmark datasets. Moreover, the proposed model is able to achieve satisfactory recognition rates even in case of few training data. Finally, its compact architecture requires less computational resources, which can be applied for real-world applications that have hardware limitations, such as robots and smartphones.",https://ieeexplore.ieee.org/document/9266005/,"2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)",7-10 Nov. 2020,ieeexplore
10.1109/ICIEA.2006.257252,Hand Posture Recognition in Gesture-Based Human-Robot Interaction,IEEE,Conferences,"Natural and friendly interface is critical for the development of service robots. Gesture-based interface offers a way to enable untrained users to interact with robots more easily and efficiently. In this paper, we present a posture recognition system implemented on a real humanoid service robot. The system applies the RCE neural network based color segmentation algorithm to separate hand images from complex backgrounds. The topological features of the hand are then extracted from the silhouette of the segmented hand region. Based on the analysis of these simple but distinctive features, hand postures are identified accurately. Experimental results on gesture-based robot programming demonstrated the effectiveness and robustness of the system",https://ieeexplore.ieee.org/document/4025853/,2006 1ST IEEE Conference on Industrial Electronics and Applications,24-26 May 2006,ieeexplore
10.1109/ROBOT.1995.525442,Hierarchical control architecture for Cellular Robotic System-simulations and experiments,IEEE,Conferences,"Describes the hierarchical control architecture of real mobile robots for Cellular Robotic System Mark-V (CEBOT Mark-V). A parallel processing control system has been adopted, and by adjusting the role of parallel processes standing for the states of independent primitive behaviors, the change of system organization is realized to adapt the redefinition of plural tasks and the variation of environments. The authors propose a method for decision making of a mobile robot's behavior through integrating multiple behavioral processes. The authors define two relation matrices denoting the relationship among the processes: the priority matrix and the interest relation matrix. The matrices are used to adjust the outputs of behavioral processes and optimize the behavior of mobile robots. To obtain the most suitable priority matrix, the authors introduce a learning-adapting algorithm. The results of simulation and experiment with a real CEBOT Mark-V showed the effectiveness of the proposed matrices and learning-adapting algorithm. On the other hand, instead of simply selecting processes for decision making of the robot's behavior, the integration of multiple processes based on the proposed matrices enhanced the control robustness of robot system.",https://ieeexplore.ieee.org/document/525442/,Proceedings of 1995 IEEE International Conference on Robotics and Automation,21-27 May 1995,ieeexplore
10.1109/IROS.2008.4651150,High-dimensional underactuated motion planning via task space control,IEEE,Conferences,"Kinodynamic planning algorithms have the potential to find feasible control trajectories which accomplish a task even in very nonlinear or constrained dynamical systems. Underactuation represents a particular form of a dynamic constraint, inherently present in many machines of interest (e.g., walking robots), and necessitates planning for long-term control solutions. A major limitation in motion planning techniques, especially for real-time implementation, is that they are only practical for relatively low degree-of-freedom problems. Here we present a model-based dimensionality reduction technique based on an extension of partial feedback linearization control into a task-space framework. This allows one to plan motions for a complex underactuated robot directly in a low-dimensional task-space, and to resolve redundancy with lower-priority tasks. We illustrate the potential of this approach with an extremely simple motion planning system which solves the swing-up problem for multi-link underactuated pendula, and discuss extensions to the control of walking.",https://ieeexplore.ieee.org/document/4651150/,2008 IEEE/RSJ International Conference on Intelligent Robots and Systems,22-26 Sept. 2008,ieeexplore
10.1109/TAI.2000.889888,History checking of temporal fuzzy logic formulas for monitoring behavior-based mobile robots,IEEE,Conferences,"Behavior-based robot control systems have shown remarkable success for controlling robots evolving in real world environments. However, they can fail in different manners due to their distributed control and their local decision making. In this case, monitoring can be used to detect failures and help to recover from them. In this work, we present an approach for specifying monitoring knowledge and a method for using this knowledge to detect failures. In particular we show how temporal fuzzy logic can be used to represent monitoring knowledge and then utilized to effectively detect runtime failures. New semantics are introduced to take into consideration uncertainty and noisy information. There are numbers of advantages to our approach including a declarative semantics for the monitoring knowledge and an independence of this knowledge from the implementation details of the control system. Moreover we show how our system can deal effectively with noisy information and sensor readings. Experiments with two real world robots and the simulator are used to illustrate failure examples and the benefits of failure detection and noise elimination.",https://ieeexplore.ieee.org/document/889888/,Proceedings 12th IEEE Internationals Conference on Tools with Artificial Intelligence. ICTAI 2000,15-15 Nov. 2000,ieeexplore
10.1109/ACSOS49614.2020.00036,How far should I watch? Quantifying the effect of various observational capabilities on long-range situational awareness in multi-robot teams,IEEE,Conferences,"In our previous work, we showed that individual robots within a multi-robot team can gain long-distance situational awareness from passive observations of a single nearby neighbor without any explicit robot-to-robot communication. However, that prior work was developed only in simulation, and performance was not measured for real robot teams in physical space with realistic hardware limitations. Toward this end, we studied the performance of these methods in real robot scenarios with methods using more sophisticated techniques in machine learning to mitigate practical implementation problems. In this study, we further extend that work by characterizing the effects of changing history length and sensor range. Rather than finding that increasing history length and sensor range always yield better estimation performance, we find that the optimal history length and sensor range varies depending on the distance between the estimating robot and the robot being estimated. For estimation problems where the estimation target is nearby, longer histories actually degrade performance, and so sensor ranges could be increased instead. Conversely, for farther targets, history length is as valuable or more valuable than sensor range. Thus, just as optimal shutter speed varies with light availability and speed of the subject, passive situational awareness in multi-robot teams is best achieved with different strategies depending on proximity to locations of interest. All studies use the teams of Thymio II physical, two-wheeled robots in laboratory environments <sup>1</sup>.<sup>1</sup>Data and models used are available at https://github.com/PavlicLab/ACSOS2020_ReTLo_Extension.git.",https://ieeexplore.ieee.org/document/9196255/,2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS),17-21 Aug. 2020,ieeexplore
10.1109/SCISISIS50064.2020.9322719,Human-Robot Interaction Based on Facial Expression Recognition Using Deep Learning,IEEE,Conferences,"In recent years, many robots for the purpose of communicating with people have been developed. Such a robot is required to have human interaction and communication ability. In order to perform the interaction naturally, the nonverbal communication such as human facial expression and body movement is important. In this research, we propose a method to classify emotions from human face images by deep learning and generate a robot emotional reaction by Markovian emotional model. Here, we perform to learn human facial images with various emotions using CNN (Convolutional Neural Network) which is a kind of deep learning, and recognize human emotions from facial images in the human interaction. Based on the human emotion obtained by deep learning, the robot returns its emotional behavior to the human. In this research, we executed the interaction experiment using an real communication robot and this result is also reported in this paper.",https://ieeexplore.ieee.org/document/9322719/,2020 Joint 11th International Conference on Soft Computing and Intelligent Systems and 21st International Symposium on Advanced Intelligent Systems (SCIS-ISIS),5-8 Dec. 2020,ieeexplore
10.1109/ICRA.2013.6630610,Human-friendly robot navigation in dynamic environments,IEEE,Conferences,"The vision-based mechanisms that pedestrians in social groups use to navigate in dynamic environments, avoiding obstacles and each others, have been subject to a large amount of research in social anthropology and biological sciences. We build on recent results in these fields to develop a novel fully-distributed algorithm for robot local navigation, which implements the same heuristics for mutual avoidance adopted by humans. The resulting trajectories are human-friendly, because they can intuitively be predicted and interpreted by humans, making the algorithm suitable for the use on robots sharing navigation spaces with humans. The algorithm is computationally light and simple to implement. We study its efficiency and safety in presence of sensing uncertainty, and demonstrate its implementation on real robots. Through extensive quantitative simulations we explore various parameters of the system and demonstrate its good properties in scenarios of different complexity. When the algorithm is implemented on robot swarms, we could observe emergent collective behaviors similar to those observed in human crowds.",https://ieeexplore.ieee.org/document/6630610/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/ROBIO.2011.6181717,Human-like gradual multi-agent Q-learning using the concept of behavior-based robotics for autonomous exploration,IEEE,Conferences,"In the last few years, the field of mobile robotics has made lots of advancements. These advancements are due to the extensive application of mobile robots for autonomous exploration. Mobile robots are being popularly used for applications in space, underwater explorations, underground coal mines monitoring, inspection in chemical/toxic/ nuclear factories etc. But if these environments are unknown/unpredictable, conventional/ classical robotics may not serve the purpose. In such cases robot learning is the best option. Learning from the past experiences, is one such way for real time application of robots for completely unknown environments. Reinforcement learning is one of the best learning methods for robots using a constant system-environment interaction. Both single and multi-agent concepts are available for implementation of learning. The current research work describes a multi-agent based reinforcement learning using the concept of behaviour-based robotics for autonomous exploration of mobile robots. The concept has also been tested both in indoor and outdoor environments using real-time robots.",https://ieeexplore.ieee.org/document/6181717/,2011 IEEE International Conference on Robotics and Biomimetics,7-11 Dec. 2011,ieeexplore
10.1109/HUMANOIDS.2017.8246941,Human-robot interaction assessment using dynamic engagement profiles,IEEE,Conferences,"This paper addresses the use of convolutional neural networks for image analysis resulting in an engagement metric that can be used to assess the quality of human robot interactions. We propose a method based on a pretrained convolutional network able to map emotions onto a continuous [0-1] interval, where 0 represents disengaged and 1 fully engaged. The network shows a good accuracy at recognizing the engagement state of humans given positive emotions. A time based analysis of interaction experiments between small humanoid robots and humans provides time series of engagement estimates, which are further used to understand the nature of the interaction as well as the overall mood and interest of the participant during the experiment. The method allows a real-time implementation and supports a quantitative and qualitative assessment of a human robot interaction with respect to a positive engagement and is applicable to humanoid robotics as well as other related contexts.",https://ieeexplore.ieee.org/document/8246941/,2017 IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids),15-17 Nov. 2017,ieeexplore
10.1109/CSPA.2014.6805724,Humanoid localisation in a robot soccer competition using a single camera,IEEE,Conferences,"One of the main challenges in a humanoid robot soccer competition is registering robots on the field so that they can estimate their best possible positions. This paper proposes an initial self-localisation algorithm to estimate the distance between a robot and a goal post, which is used as a landmark. By manipulating a single camera, we can apply analytic geometry to determine the real world coordinates of a robot from the transformation image plane. An experiment was conducted from the perspective of a robot in a soccer competition. The robot was able to locate itself with a minimum mean square error rate. This technology has great potential for boosting attacking and defensive performance.",https://ieeexplore.ieee.org/document/6805724/,2014 IEEE 10th International Colloquium on Signal Processing and its Applications,7-9 March 2014,ieeexplore
10.1109/ICRA.2013.6631340,Humanoid robot posture-control learning in real-time based on human sensorimotor learning ability,IEEE,Conferences,"In this paper we propose a system capable of teaching humanoid robots new skills in real-time. The system aims to simplify the robot control and to provide a natural and intuitive interaction between the human and the robot. The key element of the system is exploitation of the human sensorimotor learning ability where a human demonstrator learns how to operate a robot in the same fashion as humans adapt to various everyday tasks. Another key aspect of the proposed system is that the robot learns the task simultaneously while the human is operating the robot. This enables the control of the robot to be gradually transferred from the human to the robot during the demonstration. The control is transferred based on the accuracy of the imitated task. We demonstrated our approach using an experiment where a human demonstrator taught a humanoid robot how to maintain the postural stability in the presence of the perturbations. To provide the appropriate feedback information of the robot's postural stability to the human sensorimotor system, we utilized a custom-built haptic interface. To absorb the demonstrated skill by the robot, we used Locally Weighted Projection Regression machine learning method. A novel approach was implemented to gradually transfer the control responsibility from the human to the incrementally built autonomous robot controller.",https://ieeexplore.ieee.org/document/6631340/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/MHS.1995.494218,Hybrid system of mechanical parts and living organisms for microrobots,IEEE,Conferences,"Summary form only given. Fundamental attempts to make hybrid robots, in which some artificial sensors and actuators are replaced with natural antennas and muscles, are discussed. First, it is shown that signals from an antenna are easily obtained with electrodes connected to both ends of the antenna. In our experiment, antennas of silkworm moth (Bombyx mori) are used as sensors which can detect a few molecules of pheromone. As for actuators, electrical stimulation can generate the desired smooth movement of muscles. Finally, intelligence of microrobots is considered. Currently, it is impossible to use a real nervous system for hybrid robots because a nervous system cannot be taken out from the body without damage. In addition, a nervous system cannot be connected with artificial sensors and actuators. Instead, recurrent artificial neural networks are applied. The connections of the neural networks are obtained by genetic algorithms. As a result, a mobile robot with antennas follows a stream of pheromone.",https://ieeexplore.ieee.org/document/494218/,MHS'95. Proceedings of the Sixth International Symposium on Micro Machine and Human Science,4-6 Oct. 1995,ieeexplore
10.1109/AIIoT52608.2021.9454183,Image Classification with Knowledge-Based Systems on the Edge for Real-Time Danger Avoidance in Robots,IEEE,Conferences,"Mobile robots are increasingly common in society and are increasingly being used for complex and high-stakes tasks such as search and rescue. The growing requirements for these robots demonstrate a need for systems which can review and react in real time to environmental hazards, which will allow robots to handle environments that are both dynamic and dangerous. We propose and test a system which allows mobile robots to reclassify environmental objects during operation in conjunction with an edge system. We train an image classification model with 99 percent accuracy and deploy it in conjunction with an edge server and JSON-based ruleset to allow robots to react to and avoid hazards.",https://ieeexplore.ieee.org/document/9454183/,2021 IEEE World AI IoT Congress (AIIoT),10-13 May 2021,ieeexplore
10.1109/ELECTR.1991.718282,Imaging And Controls For Mars Robots With Neural Networks,IEEE,Conferences,"Two aspects of the design of space robots is covered implemented by neural networks and by hybrid approach with artificial intelligence. One is a neurocontroller for a real-time autonomous system. An optical control system developed saves the time for the image processing that analyzes an image sensor through the environment and induces a transformation over the sensor array. A prototype of the neurocontroller is able to learn and control by itself. The second aspect deals with the design of a Servo Control System for a Robot with the capability of ""learning in Unanticipated Situations"" incorporated in the system. The robot is assumed to be employed to perform useful tasks in an alien evironment. The model developed is shown to provide the robot with the capability to recover from unanticipated situations that can lead to the disruption of its normal operation, and to learn to avoid such situations in the future. These two aspects will be integrated for a design of a very intelligent autonomous space robot.",https://ieeexplore.ieee.org/document/718282/,"Electro International, 1991",16-18 April 1991,ieeexplore
10.1109/ICCSP.2018.8524377,Implementation of Robotic Vision to Perform Threaded Assembly,IEEE,Conferences,"In manufacturing of mechanical parts and assemblies, proper thread-engagement between a bolt and a nut is vital for the performance and reliability of the product. Typically, this is a precision work, requiring repetitive manual operations. In this paper, we explain how such assembly operations can be carried out by collaborative robots (co-bots) by monitoring the position and orientation of the nut and bolt using an image-sensor (camera). The focus of our discussion is the assembly-operation of bolting of a nut by the grippers of a co-bot. Slips and misalignment, leading to wrong positioning of the nut and the bolt, are identified by capturing the images of the two components in real time using Microsoft Kinect camera-sensor. 3D Reconstruction of the image captured by the camera-sensor is carried out using the Kinect Fusion application. The reconstructed image is in the form of a polygonal mesh which is further converted to 3D Point Cloud data which is less sensitive to noise. Thereafter, the Point Cloud is segmented by dividing the entire scene into many clusters in order to distinguish the objects of the scene as grippers and nut and bolt. These clusters can be used for the training of the co-bot for the proposed operation. This method of extracting object-boundaries leading to recognition of objects is a vital operation in the field of robotic vision. We provide baseline description of various machine learning techniques that can be applied to realize proper assembly of a nut and a bolt.",https://ieeexplore.ieee.org/document/8524377/,2018 International Conference on Communication and Signal Processing (ICCSP),3-5 April 2018,ieeexplore
10.1109/CIBDA50819.2020.00024,Implementation of Water Quality Management Platform for Aquaculture Based on Big Data,IEEE,Conferences,"In order to ensure the quality and quantity of aquaculture, aquaculture farmers need to grasp the water quality in time. However, most farmers have to collect water quality data manually at present, and cannot store and reuse that information rapidly. This paper aims to use SpringBoot framework and JPA framework to build a big data platform of acquisition automation and visualization, which realizes the data analysis and display of heterogeneous water quality and breeding information. The platform can make the water quality prediction and real-time warning. Meanwhile, it realizes the management of robots, users and breeding experts. The application of this platform will bring better social benefits to aquaculture farmers.",https://ieeexplore.ieee.org/document/9148352/,2020 International Conference on Computer Information and Big Data Applications (CIBDA),17-19 April 2020,ieeexplore
10.1109/CNNA.2010.5430286,Implementation of a drosophila-inspired orientation model on the Eye-Ris platform,IEEE,Conferences,"A behavioral model, recently derived from experiments on fruit-flies, was implemented, with successful comparative experiments on orientation control in real robots. This model has been firstly implemented in a standard CNN structure, using an algorithm based on classical, space-invariant templates. Subsequently, the Eye-Ris platform was utilised for the implementation of the whole strategy, at the aim to constitute a stand alone smart sensor for orientation control in bio-inspired robotic platforms. The Eye-Ris vl.2 is a visual system, made by Anafocus, that employs a fully-parallel mixed-signal array sensor-processor chip. Some experiments are reported using a commercial roving platform, the Pioneer P3-AT, showing the reliability of the proposed implementation and usefulness in higher level perceptual tasks.",https://ieeexplore.ieee.org/document/5430286/,2010 12th International Workshop on Cellular Nanoscale Networks and their Applications (CNNA 2010),3-5 Feb. 2010,ieeexplore
10.1109/IROS.1991.174485,Implementation of an active optical range sensor using laser slit for in-door intelligent mobile robot,IEEE,Conferences,"The sensor with real-time environment recognition ability is one of the key technologies for autonomous robots. The authors have designed and implemented a small size optical range sensor for their experimental mobile robot. The sensor consists of a laser slit generator, a CCD image sensor and a processing unit. Using this sensor, the real-time obstacle avoiding function is realized and added to the autonomous navigation aspect of the robot.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174485/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/ACC.2014.6859431,"Implementation of an adaptive, model free, learning controller on the Atlas robot",IEEE,Conferences,"Recent events in natural and man-made disasters have highlighted the limitation in man's ability to confine and mitigate damage in such scenarios. Therefore, there is an urgent need for robotic technology that can function in all environments and serve as a substitute to humans in disaster scenarios. This paper presents research efforts to advance walking technology of humanoid robots with application to the Boston Dynamics Atlas robot. The Atlas was designed as part of the DARPA Robotics Challenge (DRC). The paper contribution is in a model free, walking trajectory tracking controller that is tested using GAZEBO robotics simulator. Artificial neural networks are used to learn the robot's nonlinear dynamics on the fly using a neuroadaptive control algorithm. The learned nonlinear dynamics are utilized along with a filtered error signal to generate input torques to control the system. Results show that the ability to approximate the robot nonlinear dynamics allows for full-body control without the need of modeling such a complex system. This ability is what makes the control scheme utilized appealing for complex, real-life, robotic applications that occur in a non-laboratory setting.",https://ieeexplore.ieee.org/document/6859431/,2014 American Control Conference,4-6 June 2014,ieeexplore
10.1109/CONIELECOMP.2014.6808580,Implementation of an embedded system on a TS7800 board for robot control,IEEE,Conferences,"Growing Functional Modules (GFM) learning based controllers need to be experimented on real robots. In 2009, looking to develop a flexible and generic embedded interface for such robots, we decided to use a TS-7800 single board computer (SBC) with a Debian Linux operating system. Despite the many advantages of this board, implementing the embedded system has been a complex task. This paper describes the implementation of protocols through the TS-7800 different ports (RS232, TCP/IP, USB, analog and digital pins) as well as the connection of external boards (TS-ADC24, TS-DIO64, SSC-32 and LCD display). This implementation was required to connect a large range of actuators, sensors and other peripherals. Furthermore, the architecture of the embedded system is exposed in detail, including topics such as the XML configuration file that specifies the peripherals connected to the SBC, the concept of virtual sensors, the implementation of parallelism and the embedded system interface launcher. Technical aspects such as the optimization of video capture and processing are detailed because their execution required specific compilers versions, EABI emulation and extra libraries (openCV libjpg and libpngand libv4l). The final embedded system was implemented in a humanoid robot and connected to the GFM controller in charge of developing its equilibrium subsystem.",https://ieeexplore.ieee.org/document/6808580/,"2014 International Conference on Electronics, Communications and Computers (CONIELECOMP)",26-28 Feb. 2014,ieeexplore
10.1109/CEC.2003.1299606,Implementation of an immuno-genetic network on a real Khepera II robot,IEEE,Conferences,"The design of autonomous navigation systems for mobile robots, with simultaneous objectives to be satisfied such as garbage collection with integrity maintenance, requires refined coordination mechanisms to deal with modules of elementary behaviour. This paper shows the implementation on a real Khepera II robot of an immuno-genetic network for autonomous navigation that combines an evolutionary algorithm with a continuous immune network model. The proposed immuno-genetic system has the immune network implementing a dynamic process of decision-making, and the evolutionary algorithm defining the network structure. To be able to evaluate the controllers (immune networks) on the evolutionary process, a virtual environment was used for computer simulation, based on the characteristics of the navigation problem. The immune networks obtained by evolution were then analyzed and tested on new situations, presenting coordination capability in simple and more complex tasks. Some preliminary experiments on a real Khepera II robot demonstrate the feasibility of the evolved immune networks.",https://ieeexplore.ieee.org/document/1299606/,"The 2003 Congress on Evolutionary Computation, 2003. CEC '03.",8-12 Dec. 2003,ieeexplore
10.1109/SMC.2017.8122654,Implementation of human-robot VQA interaction system with dynamic memory networks,IEEE,Conferences,"One of the major functions of intelligent robots such as social or home service robots is to interact with users in natural language. Moving on from simple conversation or retrieval of data stored in computer memory, we present a new Human-Robot Interaction (HRI) system which can understand and reason over environment around the user and provide information about it in a natural language. For its intelligent interaction, we integrated Dynamic Memory Networks (DMN), a deep learning network for Visual Question Answering (VQA). For its hardware, we built a robotic head platform with a tablet PC and a 3 DOF neck. Through an experiment where the user and the robot had question answering interaction in our customized environment and in real time, the feasibility our proposed system was validated, and the effectiveness of deep learning application in real world as well as a new insight on human robot interaction was demonstrated.",https://ieeexplore.ieee.org/document/8122654/,"2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",5-8 Oct. 2017,ieeexplore
10.1109/IROS45743.2020.9341029,Improving Unimodal Object Recognition with Multimodal Contrastive Learning,IEEE,Conferences,"Robots perceive their environment using various sensor modalities, e.g., vision, depth, sound or touch. Each modality provides complementary information for perception. However, while it can be assumed that all modalities are available for training, when deploying the robot in real-world scenarios the sensor setup often varies. In order to gain flexibility with respect to the deployed sensor setup we propose a new multimodal approach within the framework of contrastive learning. In particular, we consider the case of learning from RGB-D images while testing with one modality available, i.e., exclusively RGB or depth. We leverage contrastive learning to capture high-level information between different modalities in a compact feature embedding. We extensively evaluate our multimodal contrastive learning method on the Falling Things dataset and learn representations that outperform prior methods for RGB-D object recognition on the NYU-D dataset. Our code and details on the used datasets are available at: https://github.com/meyerjo/MultiModalContrastiveLearning.",https://ieeexplore.ieee.org/document/9341029/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ICSPCC50002.2020.9259462,Indoor Object Identification based on Spectral Subtraction of Acoustic Room Impulse Response,IEEE,Conferences,"Object identification in the room environment is a key technique in many advanced engineering applications such as the unidentified object recognition in security surveillance, human identification and barrier recognition for AI robots. The identification technique based on the sound field perturbation analysis is capable of giving immersive identification which avoids the occlusion problem in the traditional vision-based method. In this paper, a new insight into the relation between the object and the variation of the sound field is presented. The sound field difference before and after the object locates in the environment is analyzed using the spectral subtraction based on the room impulse response. The spectral subtraction shows that the energy loss caused by the sound absorption is the essential factor which perturbs the sound field. By using the energy loss with high uniqueness as the extracted feature, an object identification technique is constructed under the classical supervised pattern recognition framework. The experiment in a real room validates that the system has high identification accuracy. In addition, based on the feature property of position insensitivity, this technique can achieve high identifying accuracy with a quite small training data set, which demonstrates that the technique has potential to be used in real engineering applications.",https://ieeexplore.ieee.org/document/9259462/,"2020 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)",21-24 Aug. 2020,ieeexplore
10.1109/ICEE50131.2020.9260698,"Indoor and Outdoor Face Recognition for Social Robot, Sanbot Robot as Case Study",IEEE,Conferences,"The interaction between human and robots is of paramount importance in comforting robot and human in the context of social demand. For the purpose of human-robot interaction, the robot should have the ability to perform a variety of actions including face recognition, path planning, etc. In this paper, face recognition has been implemented on the Sanbot robot. Since the Sanbot robot is intended to work in real environment, therefore indoor and outdoor environment is taken into account in proposing the corresponding face recognition algorithm. For each case a robust pre-processing algorithm should be designed and which can circumvent a challenging problem in face recognition, namely, different lighting conditions (light intensity, angle of radiation, etc.). In case of indoor environment, faces in an captured image by the robot HD camera are found using a Haar-cascade algorithm. Afterwards, a histogram equalization is applied to face images in order to standardize them. Then commonly practiced Deep convolutional neural network structures such as Inception and ResNet are used to design a model and trained end-to-end on a customized dataset with strong augmentation. Finally, by using a voting method, proper prediction is carried out on each face. In what concerns the outdoor environment, which has more challenges, upon applying histogram Equalization on the captured image, faces are found using a MultiTask Cascaded Convolutional Neural Network. Then face images are aligned as head orientation are corrected. Finally, cropped face image is fed to Siamese Network in order to extract face features and verifying individuals. From several practical results it has been inferred that the accuracy of the indoor method is nearly 93% without voting and with voting 97%, and the outdoor method is about 95%.",https://ieeexplore.ieee.org/document/9260698/,2020 28th Iranian Conference on Electrical Engineering (ICEE),4-6 Aug. 2020,ieeexplore
10.1109/IROS.2013.6696336,Inferring categories to accelerate the learning of new classes,IEEE,Conferences,"On-the-fly learning systems are necessary for the deployment of general purpose robots. New training examples for such systems are often supplied by mentor interactions. Due to the cost of acquiring such examples, it is desirable to reduce the number of necessary interactions. Transfer learning has been shown to improve classification results for classes with small numbers of training examples by pooling knowledge from related classes. Standard practice in these works is to assume that the relationship between the transfer target and related classes is already known. In this work, we explore how previously learned categories, or related groupings of classes, can be used to transfer knowledge to novel classes without explicitly known relationships to them. We demonstrate an algorithm for determining the category membership of a novel class, focusing on the difficult case when few training examples are available. We show that classifiers trained via this method outperform classifiers optimized to learn the novel class individually when evaluated on both synthetic and real-world datasets.",https://ieeexplore.ieee.org/document/6696336/,2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,3-7 Nov. 2013,ieeexplore
10.1109/ICIT.2010.5472498,Intelligent control and evolutionary strategies applied to multirobotic systems,IEEE,Conferences,"This paper describes the modeling, implementation, and evaluation of RoBombeiros multirobotic system. The robotic task in this paper is performed over a natural disaster, simulated as a forest fire. The simulator supports several features to allow realistic simulation, like irregular terrains, natural processes (e.g. fire, wind) and physical constraint in the creation and application of mobile robots. The proposed system relies on two steps: (i) group formation planning and (ii) intelligent techniques to perform robots navigation for fire fighting. For planning, we used genetic algorithms to evolve positioning strategies for firefighting robots performance. For robots operation, physically simulated fire-fighting robots were built, and the sensory information of each robot (e.g. GPS, compass, sonar) was used in the input of an artificial neural network (ANN). The ANN controls the vehicle (robot) actuators and allows navigation with obstacle avoidance. Simulation results show that the ANN satisfactorily controls the mobile robots; the genetic algorithm adequately configures the fire fighting strategy and the proposed multi-robotic system can have an essential hole in the planning and execution of fire fighting in real forests.",https://ieeexplore.ieee.org/document/5472498/,2010 IEEE International Conference on Industrial Technology,14-17 March 2010,ieeexplore
10.1109/ICCCYB.2004.1437660,Intelligent control application on sample identification,IEEE,Conferences,"An intelligent control implementation is proposed for sample differentiation with Raman spectroscopy, which can be used to characterize various samples for decision-making and medical diagnosis. Raman spectra are weak signals whose features are inevitably affected by numerous noises during the calibration process. These noises must be eliminated to an acceptable level. Fuzzy control has been widely used to solve uncertainty, imprecision and vague phenomena, so fuzzy logic can be used for noise filtering. The resulting intrinsic Raman spectrum has been trained using artificial neural networks. Both unsupervised learning and supervised learning are to be conducted in this preliminary research on sample identification. For unsupervised training, principal component analysis (PCA) is exploited, which is based on Hebbian rule and single value decomposition (SVD) approach, respectively. For supervised training, radial basis function (RBF) is presented. A complete procedure for sample identification consists of Raman spectra calibration, noise filtering, unsupervised classification and supervised neural network training. A systematic intelligent control approach is formulated in consequence for sample identification. The long-term objective is to create a real-time approach for sample analysis using a Raman spectrometer directly mounted at the end-effector of the medical robots to enhance robotic remote surgery",https://ieeexplore.ieee.org/document/1437660/,"Second IEEE International Conference on Computational Cybernetics, 2004. ICCC 2004.",30 Aug.-1 Sept. 2004,ieeexplore
10.1109/ICRA.2018.8463211,Intent-Aware Multi-Agent Reinforcement Learning,IEEE,Conferences,"This paper proposes an intent-aware multi-agent planning framework as well as a learning algorithm. Under this framework, an agent plans in the goal space to maximize the expected utility. The planning process takes the belief of other agents' intents into consideration. Instead of formulating the learning problem as a partially observable Markov decision process (POMDP), we propose a simple but effective linear function approximation of the utility function. It is based on the observation that for humans, other people's intents will pose an influence on our utility for a goal. The proposed framework has several major advantages: i) it is computationally feasible and guaranteed to converge. ii) It can easily integrate existing intent prediction and low-level planning algorithms. iii) It does not suffer from sparse feedbacks in the action space. We experiment our algorithm in a real-world problem that is non-episodic, and the number of agents and goals can vary over time. Our algorithm is trained in a scene in which aerial robots and humans interact, and tested in a novel scene with a different environment. Experimental results show that our algorithm achieves the best performance and human-like behaviors emerge during the dynamic process.",https://ieeexplore.ieee.org/document/8463211/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/WPNC.2016.7822857,Introducing a novel marker-based geometry model in monocular vision,IEEE,Conferences,"A spherical marker-based distance capture concept using monocular vision is presented in this paper. A novel method is explored, within the concept of a virtual sphere, which shows how to improve the reading measurements of the distance of a moving object from low resolution digital images, and from a single viewpoint. The aim here is to be able to track accurately the object at a furthest possible position. A conclusion with experimental simulations carried out using 3D modeling of markers and representing the real world showing the potency of the marker's geometry on improving the accuracy of the measurements. A potential application field of the proposed method is the implementation of tracking object in mobile robots, marker-based localization, and field of topography.",https://ieeexplore.ieee.org/document/7822857/,"2016 13th Workshop on Positioning, Navigation and Communications (WPNC)",19-20 Oct. 2016,ieeexplore
10.1109/ICETIETR.2018.8529028,IoT Enabled Robots with QR Code Based Localization,IEEE,Conferences,"Robots are sophisticated form of IoT devices as they are smart devices that scrutinize sensor data from multiple sources and observe events to decide the best procedural actions to supervise and manoeuvre objects in the physical world. In this paper, localization of the robot is addressed by QR code Detection and path optimization is accomplished by Dijkstras algorithm. The robot can navigate automatically in its environment with sensors and shortest path is computed whenever heading measurements are updated with QR code landmark recognition. The proposed approach highly reduces computational burden and deployment complexity as it reflects the use of artificial intelligence to self-correct its course when required. An Encrypted communication channel is established over wireless local area network using SSHv2 protocol to transfer or receive sensor data(or commands) making it an IoT enabled Robot.",https://ieeexplore.ieee.org/document/8529028/,2018 International Conference on Emerging Trends and Innovations In Engineering And Technological Research (ICETIETR),11-13 July 2018,ieeexplore
10.1109/ROBIO.2018.8665255,Knowledge-Driven Deep Deterministic Policy Gradient for Robotic Multiple Peg-in-Hole Assembly Tasks,IEEE,Conferences,"It remains a formidable challenge for traditional control strategies to perform automatic multiple peg-in-hole assembly tasks due to the complicated and dynamic contact states. Inspired by that human could generalize the learned skills to perform the different assembly tasks well, a general learning-based algorithm based on deep deterministic policy gradient (DDPG) is proposed. To make robots learn the multiple peg-in-hole assembly skills from experience efficiently and stably, the learning process is driven by the basic knowledge like PD force control strategy. To achieve a fast learning process in the real-world assembly tasks, a hybrid exploration strategy is applied to drive a efficient exploration during policy search phase. A dual peg-in-hole assembly simulation and real-world experiments are implemented to verify the effectiveness of the proposed algorithm. The performance measured by the assembly time and the maximum contact forces demonstrates that the multiple peg-in-hole assembly skills could be improved only after 150 training episodes in dual peg-in-hole assembly task.",https://ieeexplore.ieee.org/document/8665255/,2018 IEEE International Conference on Robotics and Biomimetics (ROBIO),12-15 Dec. 2018,ieeexplore
10.1109/INDIN.2015.7281881,Knowledge-driven finite-state machines. Study case in monitoring industrial equipment,IEEE,Conferences,Traditionally state machines are implemented by coding the desired behavior of a given system. This work proposes the use of ontological models to describe and perform computations on state machines by using SPARQL queries. This approach represents a paradigm shift relating to the customary manner in which state machines are stored and computed. The main contribution of the work is an ontological model to represent state machines and a set of generic queries that can be used in any knowledge-driven state machine to compute valuable information. The approach was tested in a study case were the state machines of industrial robots in a manufacturing line were modeled as ontological models and used for monitoring the behavior of these devices on real time.,https://ieeexplore.ieee.org/document/7281881/,2015 IEEE 13th International Conference on Industrial Informatics (INDIN),22-24 July 2015,ieeexplore
10.1109/IROS.2010.5649358,LCM: Lightweight Communications and Marshalling,IEEE,Conferences,"We describe the Lightweight Communications and Marshalling (LCM) library for message passing and data marshalling. The primary goal of LCM is to simplify the development of low-latency message passing systems, especially for real-time robotics research applications. Messages can be transmitted between different processes using LCM's publish/subscribe message-passing system. A platformand language-independent type specification language separates message description from implementation. Message specifications are automatically compiled into language-specific bindings, eliminating the need for users to implement marshalling code while guaranteeing run-time type safety. LCM is notable in providing a real-time deep traffic inspection tool that can decode and display message traffic with minimal user effort and no impact on overall system performance. This and other features emphasize LCM's focus on simplifying both the development and debugging of message passing systems. In this paper, we explain the design of LCM, evaluate its performance, and describe its application to a number of autonomous land, underwater, and aerial robots.",https://ieeexplore.ieee.org/document/5649358/,2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,18-22 Oct. 2010,ieeexplore
10.1109/ROBIO.2006.340332,Landmark Design Using Projective Invariant for Mobile Robot Localization,IEEE,Conferences,"For the fast and accurate self-localization of mobile robots in navigation, artificial landmarks can be used very efficiently in the complex workspace. In this paper, in order to provide feedback and verification mechanisms in navigation technique, we design two types of artificial landmarks with symmetric rectangles and seven-part numbers, which show cross- ratio invariant under projective transformation. The fast landmark detection-recognition algorithm and self-localization are proposed and their feasibility and robustness are demonstrated by practical experiments in cluttered indoor environments and simulation experiment. Experimental results show that proposed landmark patterns are enough to be used in cluttered environment and landmark detection-recognition in cluttered scene is real-time robustly under various viewing angles, self-localization accuracy is high enough in the presence of additive random noise.",https://ieeexplore.ieee.org/document/4141977/,2006 IEEE International Conference on Robotics and Biomimetics,17-20 Dec. 2006,ieeexplore
10.1109/GCIS.2009.206,Layered Task Allocation in Multi-robot Systems,IEEE,Conferences,"A layered task allocation method is presented for multi-robot systems in a collaboration and adversarial, dynamic, real-time environment with unreliable communication in this paper. The process of task allocation is divided into three layers: task decomposition layer, task evaluation layer and task selection layer. In task decomposition layer, robots categorize their environments into corresponding modes, and fix subtasks in every mode as experts do, in order to reduce candidate tasks and decrease the complexity of task allocation. Q-Learning based on Adaptive Neuro Fuzzy Inference System (ANFIS) is adopted to compute utilities of candidate tasks in task evaluation layer. This can not only avoid the complicated opponent modeling but also make the learning more efficient. In task selection layer, task with the maximum utility is selected in application, but in learning, task is selected according to randomized Boltzmann exploration tactics in order to get more information for optimization. Simulation experiments implemented on simulated robotic soccer show that this approach improves performances of multi-robot systems greatly.",https://ieeexplore.ieee.org/document/5209028/,2009 WRI Global Congress on Intelligent Systems,19-21 May 2009,ieeexplore
10.1109/IROS45743.2020.9340865,Learning Human-Aware Robot Navigation from Physical Interaction via Inverse Reinforcement Learning,IEEE,Conferences,"Autonomous systems, such as delivery robots, are increasingly employed in indoor spaces to carry out activities alongside humans. This development poses the question of how robots can carry out their tasks while, at the same time, behaving in a socially compliant manner. Further, humans need to be able to communicate their preferences in a simple and intuitive way, and robots should adapt their behavior accordingly. This paper investigates force control as a natural means to interact with a mobile robot by pushing it along the desired trajectory. We employ inverse reinforcement learning (IRL) to learn from human interaction and adapt the robot behavior to its users' preferences, thereby eliminating the need to program the desired behavior manually. We evaluate our approach in a real-world experiment where test subjects interact with an autonomously navigating robot in close proximity. The results suggest that force control presents an intuitive means to interact with a mobile robot and show that our robot can quickly adapt to the test subjects' personal preferences.",https://ieeexplore.ieee.org/document/9340865/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/SMC.2019.8914406,Learning Locomotion Skills via Model-based Proximal Meta-Reinforcement Learning,IEEE,Conferences,"Model-based reinforcement learning methods provide a promising direction for a range of automated applications, such as autonomous vehicles and legged robots, due to their sample-efficiency. However, their asymptotic performance is usually inferior compared to the state-of-the-art model-free reinforcement learning methods in locomotion control domains. One main challenge of model-based reinforcement learning is learning a dynamics model that is accurate enough for planning. This paper mitigates this issue by meta-reinforcement learning from an ensemble of dynamics models. A policy learns from dynamics models that hold different beliefs of a real environment. This procedure improves its adaptability and inaccuracy-tolerance ability. A proximal meta-reinforcement learning algorithm is introduced to improve computational efficiency and reduces variance of higher-order gradient estimation. A heteroscedastic noise is added to the training dataset, thus leading to a robust and efficient model learning. Subsequently, proximal meta-reinforcement learning maximizes the expected returns by sampling “imaginary” trajectories from the learned dynamics, which does not require real environment data and can be deployed on many servers in parallel to speed up the whole learning process. The aim of this work is to reduce the sample-complexity and computational cost of reinforcement learning in robot locomotion tasks. Simulation experiments show that the proposed algorithm achieves an asymptotic performance compared with the state-of-the-art model-free reinforcement learning methods with significantly fewer samples, which confirm our theoretical results.",https://ieeexplore.ieee.org/document/8914406/,"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)",6-9 Oct. 2019,ieeexplore
10.1109/IROS45743.2020.9341458,Learning Motion Parameterizations of Mobile Pick and Place Actions from Observing Humans in Virtual Environments,IEEE,Conferences,"In this paper, we present an approach and an implemented pipeline for transferring data acquired from observing humans in virtual environments onto robots acting in the real world, and adapting the data accordingly to achieve successful task execution. We demonstrate our pipeline by inferring seven different symbolic and subsymbolic motion parameters of mobile pick and place actions, which allows the robot to set a simple breakfast table. We propose an approach to learn general motion parameter models and discuss, which parameters can be learned at which abstraction level.",https://ieeexplore.ieee.org/document/9341458/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/SII.2013.6776750,Learning and association of synaesthesia phenomenon using deep neural networks,IEEE,Conferences,"Robots are required to process multimodal information because the information in the real world comes from various modal inputs. However, there exist only a few robots integrating multimodal information. Humans can recognize the environment effectively by cross-modal processing. We focus on modeling synaesthesia phenomenon known to be a cross-modal perception of humans. Recently, deep neural networks (DNNs) have gained more attention and successfully applied to process high-dimensional data composed not only of single modality but also of multimodal information. We introduced DNNs to construct multimodal association model which can reconstruct one modality from the other modality. Our model is composed of two DNNs: one for image compression and the other for audio-visual sequential learning. We tried to reproduce synaesthesia phenomenon by training our model with the multimodal data acquired from psychological experiment. Cross-modal association experiment showed that our model can reconstruct the same or similar images from sound as synaesthetes, those who experience synaesthesia. The analysis of middle layers of DNNs representing multimodal features implied that DNNs self-organized the difference of perception between individual synaesthetes.",https://ieeexplore.ieee.org/document/6776750/,Proceedings of the 2013 IEEE/SICE International Symposium on System Integration,15-17 Dec. 2013,ieeexplore
10.1109/IECON.1993.339280,Learning behavioral control by reinforcement for an autonomous mobile robot,IEEE,Conferences,"We present an implementation of a reinforcement learning algorithm through the use of a special neural network topology, the AHC (adaptive heuristic critic). The AHC constitutes a fusion supervisor of primitive behaviours in order to execute more complex robot behaviours as for example go to goal. This fusion supervisor is part of an architecture for the execution of mobile robot tasks which are composed of several primitive behaviours which act in a simultaneous or concurrent fashion. The architecture allows for learning to take place at the execution level, it incorporates the experience gained in executing primitive behaviours as well as the overall task. The implementation of the autonomous learning approach has been tested within OPMOR, a simulation environment for mobile robots and with our mobile platform UPM Robuter. Both simulated and real results are presented. The performance of the AHC neural network is adequate. Portions of this work have been implemented in the EEC ESPRIT 2483 PANORAMA Project.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/339280/,Proceedings of IECON '93 - 19th Annual Conference of IEEE Industrial Electronics,15-19 Nov. 1993,ieeexplore
10.1109/ROMAN.2010.5598659,Learning grasp stability based on tactile data and HMMs,IEEE,Conferences,"In this paper, the problem of learning grasp stability in robotic object grasping based on tactile measurements is studied. Although grasp stability modeling and estimation has been studied for a long time, there are few robots today able of demonstrating extensive grasping skills. The main contribution of the work presented here is an investigation of probabilistic modeling for inferring grasp stability based on learning from examples. The main objective is classification of a grasp as stable or unstable before applying further actions on it, e.g. lifting. The problem cannot be solved by visual sensing which is typically used to execute an initial robot hand positioning with respect to the object. The output of the classification system can trigger a regrasping step if an unstable grasp is identified. An off-line learning process is implemented and used for reasoning about grasp stability for a three-fingered robotic hand using Hidden Markov models. To evaluate the proposed method, experiments are performed both in simulation and on a real robot system.",https://ieeexplore.ieee.org/document/5598659/,19th International Symposium in Robot and Human Interactive Communication,13-15 Sept. 2010,ieeexplore
10.1109/DEVLRN.2002.1011867,Learning movement sequences from demonstration,IEEE,Conferences,"Presents a control and learning architecture for humanoid robots designed for acquiring movement skills in the context of imitation learning. Multiple levels of movement abstraction occur across the hierarchical structure of the architecture, finally leading to the representation of movement sequences within a probabilistic framework. As its substrate, the framework uses the notion of visuo-motor primitives, modules capable of recognizing as well as executing similar movements. This notion is heavily motivated by the neuroscience evidence for motor primitives and mirror neurons. Experimental results from an implementation of the architecture are presented involving learning and representation of demonstrated movement sequences from synthetic as well as real human movement data.",https://ieeexplore.ieee.org/document/1011867/,Proceedings 2nd International Conference on Development and Learning. ICDL 2002,12-15 June 2002,ieeexplore
10.1109/IROS.2014.6943031,Learning robot tactile sensing for object manipulation,IEEE,Conferences,"Tactile sensing is a fundamental component of object manipulation and tool handling skills. With robots entering unstructured environments, tactile feedback also becomes an important ability for robot manipulation. In this work, we explore how a robot can learn to use tactile sensing in object manipulation tasks. We first address the problem of in-hand object localization and adapt three pose estimation algorithms from computer vision. Second, we employ dynamic motor primitives to learn robot movements from human demonstrations and record desired tactile signal trajectories. Then, we add tactile feedback to the control loop and apply relative entropy policy search to learn the parameters of the tactile coupling. Additionally, we show how the learning of tactile feedback can be performed more efficiently by reducing the dimensionality of the tactile information through spectral clustering and principal component analysis. Our approach is implemented on a real robot, which learns to perform a scraping task with a spatula in an altered environment.",https://ieeexplore.ieee.org/document/6943031/,2014 IEEE/RSJ International Conference on Intelligent Robots and Systems,14-18 Sept. 2014,ieeexplore
10.1109/ICCVW.2019.00309,Learning to Navigate Robotic Wheelchairs from Demonstration: Is Training in Simulation Viable?,IEEE,Conferences,"Learning from demonstration (LfD) enables robots to learn complex relationships between their state, perception and actions that are hard to express in an optimization framework. While people intuitively know what they would like to do in a given situation, they often have difficulty representing their decision process precisely enough to enable an implementation. Here, we are interested in robots that carry passengers, such as robotic wheelchairs, where user preferences, comfort and the feeling of safety are important for autonomous navigation. Balancing these requirements is not straightforward. While robots can be trained in an LfD framework in which users drive the robot according to their preferences, performing these demonstrations can be time-consuming, expensive, and possibly dangerous. Inspired by recent efforts for generating synthetic data for training autonomous driving systems, we investigate whether it is possible to train a robot based on simulations to reduce the time requirements, cost and potential risk. A key characteristic of our approach is that the input is not images, but the locations of people and obstacles relative to the robot. We argue that this allows us to transfer the classifier from the simulator to the physical world and to previously unseen environments that do not match the appearance of the training set. Experiments with 14 subjects providing physical and simulated demonstrations validate our claim.",https://ieeexplore.ieee.org/document/9022271/,2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW),27-28 Oct. 2019,ieeexplore
10.1109/ICEC.1995.487489,Learning to achieve co-operation by temporal-spatial fitness sharing,IEEE,Conferences,"We propose a co-operative GA-based learning system that would make real-world heterogeneous agents feasible with the minimum amount of communication hardware. The problem is identical to a distributed GA implemented on processors connected by local and very slow communication lines. We have developed an extension of the fitness sharing method that incorporates sharing over temporally-spatially distributed populations. Restricting an agent's task to the inter-agent conflict avoidance, this sharing is realised by exchanging estimated fitness values over all agents. The mechanism of finding conflict avoidance actions is similar to that of a self-organisation mechanism of a Kohonen-type network. Our results from simulations of a bump-avoidance task for multiple mobile robots show that it elicits a notable performance improvement compared to normal classifier systems.",https://ieeexplore.ieee.org/document/487489/,Proceedings of 1995 IEEE International Conference on Evolutionary Computation,29 Nov.-1 Dec. 1995,ieeexplore
10.1109/ICSMC.1993.390770,Learning to coordinate behaviors for real-time path planning of autonomous systems,IEEE,Conferences,"We present a neural network (NN) system which learns the appropriate simultaneous activation of primitive behaviors in order to execute more complex robot behaviors. The NN implementation is part of an architecture for the execution of mobile robot tasks which are composed of several primitive behaviors in a simultaneous or concurrent fashion. We use a supervised learning technique with a human trainer generating appropriate training for the simultaneous activation of behavior in a simulated environment. The NN implementation has been tested within OPMOR, a simulation environment for mobile robots and several results are presented. The performance of the neural network is adequate. Portions of this work has been implemented in the EEC ESPRIT 2483 PANORAMA Project.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/390770/,Proceedings of IEEE Systems Man and Cybernetics Conference - SMC,17-20 Oct. 1993,ieeexplore
10.1109/ITSC45102.2020.9294425,Learning-to-Fly: Learning-based Collision Avoidance for Scalable Urban Air Mobility,IEEE,Conferences,"With increasing urban population, there is global interest in Urban Air Mobility (UAM), where hundreds of autonomous Unmanned Aircraft Systems (UAS) execute missions in the airspace above cities. Unlike traditional human-inthe-loop air traffic management, UAM requires decentralized autonomous approaches that scale for an order of magnitude higher aircraft densities and are applicable to urban settings. We present Learning-to-Fly (L2F), a decentralized on-demand airborne collision avoidance framework for multiple UAS that allows them to independently plan and safely execute missions with spatial, temporal and reactive objectives expressed using Signal Temporal Logic. We formulate the problem of predictively avoiding collisions between two UAS without violating mission objectives as a Mixed Integer Linear Program (MILP). This however is intractable to solve online. Instead, we develop L2F, a two-stage collision avoidance method that consists of: 1) a learning-based decision-making scheme and 2) a distributed, linear programming-based UAS control algorithm. Through extensive simulations, we show the real-time applicability of our method which is ≈6000× faster than the MILP approach and can resolve 100% of collisions when there is ample room to maneuver, and shows graceful degradation in performance otherwise. We also compare L2F to two other methods and demonstrate an implementation on quad-rotor robots.",https://ieeexplore.ieee.org/document/9294425/,2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC),20-23 Sept. 2020,ieeexplore
10.1109/HRI.2019.8673212,Lifespan Design of Conversational Agent with Growth and Regression Metaphor for the Natural Supervision on Robot Intelligence,IEEE,Conferences,"Human's direct supervision on robot's erroneous behavior is crucial to enhance a robot intelligence for a `flawless' human-robot interaction. Motivating humans to engage more actively for this purpose is however difficult. To alleviate such strain, this research proposes a novel approach, a growth and regression metaphoric interaction design inspired from human's communicative, intellectual, social competence aspect of developmental stages. We implemented the interaction design principle unto a conversational agent combined with a set of synthetic sensors. Within this context, we aim to show that the agent successfully encourages the online labeling activity in response to the faulty behavior of robots as a supervision process. The field study is going to be conducted to evaluate the efficacy of our proposal by measuring the annotation performance of real-time activity events in the wild. We expect to provide a more effective and practical means to supervise robot by real-time data labeling process for long-term usage in the human-robot interaction.",https://ieeexplore.ieee.org/document/8673212/,2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI),11-14 March 2019,ieeexplore
10.1109/HSI49210.2020.9142636,Lightweight Convolutional Neural Network for Real-Time Face Detector on CPU Supporting Interaction of Service Robot,IEEE,Conferences,"Face detection plays an essential role in the success of the interaction between service robots and consumers. This method is the initial stage for face-related applications. Practical applications require face detection to work in real-time and can be implemented on low-cost devices such as CPU. Traditional methods have problems when the face is not frontal, blocked, and partially covered, but real-time speed is not an obstacle. On the other hand, deep learning has succeeded in accurately distinguishing facial features and backgrounds. Face sizes that tend to be medium and large when robot interaction with consumers so it can employ Convolutional Neural Networks (CNN) with light weights. In this paper, a real-time face detector is built that can work on the CPU. This detector will be implemented explicitly in service robots to support interactions with consumers. It can overcome the occlusion and not-frontal face. Detector architecture consists of the backbone as rapidly features extractor, transition module as a transformer of prediction map, and the dual-detection layer is head of a network prediction based on scale assignment. As a result, the detector can work at speeds of 301 frames per second on CPU without ignoring the accuracy.",https://ieeexplore.ieee.org/document/9142636/,2020 13th International Conference on Human System Interaction (HSI),6-8 June 2020,ieeexplore
10.1109/AIM43001.2020.9158805,MISO Model Free Adaptive Control of Single Joint Rehabilitation Robot Driven by Pneumatic Artificial Muscles,IEEE,Conferences,"Pneumatic artificial muscles (PAMs) are widely used as actuators in the field of rehabilitation robots, but their intrinsic compliance properties make it difficult to control precisely. In this paper, an improved multiple input single output model free adaptive control (MISO-IMFAC) method is proposed for the modeling the uncertainty, high nonlinearity and time-variability of the single joint rehabilitation robot driven by antagonistic PAMs, so as to realize the high-precision control of the joint angle. Considering the influence of the error change of adjacent time on the actual control effect, a new control law is formed by adding a term representing error change to the original control input criterion function. The experiment is carried out on a real rehabilitation robot and four types of errors are used to evaluate the effectiveness of the control system. The results show that the control algorithm can improve the accuracy of angle trajectory tracking at different amplitudes. Compared with original algorithm, the experiment errors of MISO-IMFAC were significantly reduced. In addition, the MISO-IMFAC still maintains stable performance in the process of load variation and external disturbance.",https://ieeexplore.ieee.org/document/9158805/,2020 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM),6-9 July 2020,ieeexplore
10.1109/INFOCOM.2018.8485910,MV-Sports: A Motion and Vision Sensor Integration-Based Sports Analysis System,IEEE,Conferences,"Recently, intelligent sports analytics is becoming a hot area in both industry and academia for coaching, practicing tactic and technical analysis. With the growing trend of bringing sports analytics to live broadcasting, sports robots and common playfield, a low cost system that is easy to deploy and performs real-time and accurate sports analytics is very desirable. However, existing systems, such as Hawk-Eye, cannot satisfy these requirements due to various factors. In this paper, we present MV-Sports, a cost-effective system for real-time sports analysis based on motion and vision sensor integration. Taking tennis as a case study, we aim to recognize player shot types and measure ball states. For fine-grained player action recognition, we leverage motion signal for fast action highlighting and propose a long short term memory (LSTM)-based framework to integrate MV data for training and classification. For ball state measurement, we compute the initial ball state via motion sensing and devise an extended kalman filter (EKF)-based approach to combine ball motion physics-based tracking and vision positioning-based tracking to get more accurate ball state. We implement MV-Sports on commercial off-the-shelf (COTS) devices and conduct real-world experiments to evaluate the performance of our system. The results show our approach can achieve accurate player action recognition and ball state measurement with sub-second latency.",https://ieeexplore.ieee.org/document/8485910/,IEEE INFOCOM 2018 - IEEE Conference on Computer Communications,16-19 April 2018,ieeexplore
10.1109/HPCC/SmartCity/DSS.2019.00339,Machine Learning Based CloudBot Detection Using Multi-Layer Traffic Statistics,IEEE,Conferences,"With the rapid development of e-commerce services and online transactions, an increasing number of advanced web robots are utilized by speculators and hackers in underground economy to perform click fraud, register fake accounts and commit other kinds of frauds, seriously harming the profit of businesses and the fairness of online activities. There is solid evidence that the vast majority of such malicious bot traffic comes from data centers. The malicious bot deployed on the hosts of data centers is referred to as a CloudBot. How to detect and block CloudBots effectively has become an urgent problem in practice, while the research on it can be seldom seen in public. To this end, we propose a traffic-based quasi-real-time method for CloudBot detection using machine learning, which exploits a new sample partitioning approach, as well as innovative multi-layer features that reveal the essential difference between CloudBots and human traffic. Our method achieves 93.4% precision in the experiment and performs well on the real-world dataset, which proves to be effective to detect unknown CloudBots and combat the concept drift caused by varying time. Besides, the approach is also privacy-preserving without using any specific application layer information. We believe our work can benefit network economy security and fairness in practice.",https://ieeexplore.ieee.org/document/8855536/,2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS),10-12 Aug. 2019,ieeexplore
10.1109/BioRob49111.2020.9224368,Machine Learning for Motor Learning: EEG-based Continuous Assessment of Cognitive Engagement for Adaptive Rehabilitation Robots,IEEE,Conferences,"Although cognitive engagement (CE) is crucial for motor learning, it remains underutilized in rehabilitation robots, partly because its assessment currently relies on subjective and gross measurements taken intermittently. Here, we propose an end-to-end computational framework that assesses CE in near real-time, using electroencephalography (EEG) signals as objective measurements. The framework consists of i) a deep convolutional neural network that extracts task-discriminative spatiotemporal EEG features to predict the level of CE for two classes- cognitively engaged vs. disengaged; and ii) a novel sliding window method that predicts continuous levels of CE in short time intervals. We evaluated our framework on 8 healthy subjects using an in-house Go/No-Go experiment that adapted its gameplay parameters to induce cognitive fatigue. The proposed CNN had an average leave-one-subject-out accuracy of 88.19%. The CE prediction correlated well with a commonly used behavioral metric based on self-reports taken every 5 minutes (ρ=0.93). Our results objectify CE measurement in near real-time and pave the way for using CE as a rehabilitation parameter for tailoring robotic therapy to each patient's needs and skills.",https://ieeexplore.ieee.org/document/9224368/,2020 8th IEEE RAS/EMBS International Conference for Biomedical Robotics and Biomechatronics (BioRob),29 Nov.-1 Dec. 2020,ieeexplore
10.1109/ICRA.2019.8793485,Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks,IEEE,Conferences,"Contact-rich manipulation tasks in unstructured environments often require both haptic and visual feedback. However, it is non-trivial to manually design a robot controller that combines modalities with very different characteristics. While deep reinforcement learning has shown success in learning control policies for high-dimensional inputs, these algorithms are generally intractable to deploy on real robots due to sample complexity. We use self-supervision to learn a compact and multimodal representation of our sensory inputs, which can then be used to improve the sample efficiency of our policy learning. We evaluate our method on a peg insertion task, generalizing over different geometry, configurations, and clearances, while being robust to external perturbations. We present results in simulation and on a real robot.",https://ieeexplore.ieee.org/document/8793485/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/DDCLS52934.2021.9455635,Mask-based Object Pose Estimation with Domain Transfer,IEEE,Conferences,"Object pose estimation is important for robots to understand and interact with the real world. This problem is challenging because the various objects, clutter and occlusions between objects in the scene. Deep learning methods show better performances than traditional problems in this problem but training a convolutional neural network needs lots of annotated data which is expensive to obtain. This paper proposes a general method by using domain transfer technology to efficiently solve object pose estimation problem. Besides, the proposed method obtains mask to achieve high quality performance by combing an instance segmentation framework, Mask R-CNN. We present the results of our experiments with the LineMOD dataset. We also deploy our method to robotic grasp object based on the estimated pose.",https://ieeexplore.ieee.org/document/9455635/,2021 IEEE 10th Data Driven Control and Learning Systems Conference (DDCLS),14-16 May 2021,ieeexplore
10.1109/PUNECON.2018.8745403,Military Surveillance Robot Implementation Using Robot Operating System,IEEE,Conferences,"Robots are becoming more and more prevalent in many real world scenarios. Housekeeping, medical aid, human assistance are a few common implementations of robots. Military and Security are also major areas where robotics is being researched and implemented. Robots with the purpose of surveillance in war zones and terrorist scenarios need specific functionalities to perform their tasks with precision and efficiency. In this paper, we present a model of Military Surveillance Robot developed using Robot Operating System. The map generation based on Kinect sensor is presented and some test case scenarios are discussed with results.",https://ieeexplore.ieee.org/document/8745403/,2018 IEEE Punecon,30 Nov.-2 Dec. 2018,ieeexplore
10.1109/ROBOT.1998.681416,Mobile robot exploration and map-building with continuous localization,IEEE,Conferences,"Our research addresses how to integrate exploration and localization for mobile robots. A robot exploring and mapping an unknown environment needs to know its own location, but it may need a map in order to determine that location. In order to solve this problem, we have developed ARIEL, a mobile robot system that combines frontier based exploration with continuous localization. ARIEL explores by navigating to frontiers, regions on the boundary between unexplored space and space that is known to be open. ARIEL finds these regions in the occupancy grid map that it builds as it explores the world. ARIEL localizes by matching its recent perceptions with the information stored in the occupancy grid. We have implemented ARIEL on a real mobile robot and tested ARIEL in a real-world office environment. We present quantitative results that demonstrate that ARIEL can localize accurately while exploring, and thereby build accurate maps of its environment.",https://ieeexplore.ieee.org/document/681416/,Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),20-20 May 1998,ieeexplore
10.1109/ICSAI.2018.8599478,Mobile robot multi-resolution full coverage path planning algorithm,IEEE,Conferences,"The mobile robot can independently run the core as SLAM and path planning [1]. In the grid method drawing, high-precision positioning requires a high-resolution grid. When a mobile robot covers a certain working area, since the coverage width is constant each time, when high-efficiency coverage is required, a low-resolution grid is required for path planning, and a multi-resolution raster problem occurs. For the full coverage path planning problem of multi-resolution mobile robots, this paper proposes the use of high-precision grid positioning, low-resolution raster path planning coverage. In the normal grid traversal process, this paper adopts a mobile robot full coverage path planning algorithm based on bio-excitation network, which can be autonomous exploration traversal. This paper actually models its algorithm, and increases direction guidance and robot into dead zone. When escaping from the dead zone as soon as possible according to greedy thoughts, the algorithm has good real-time performance, can automatically avoid obstacles and escape from the dead zone, and there will be no large-scale folding back. Especially in the field of cleaning, the follow-on mobile robot can effectively clean the narrow area. It can make the cleaning car recycle garbage and has high cleaning efficiency. In the process of high resolution to low resolution, there are both moving obstacles and movable motion grids. This paper uses quadtree segmentation and Hilbert curve to traverse the motion grid to improve coverage and efficiency. The edge of the rule explores the purpose of reciprocating the entire region by reciprocating the unknown environment. In the experiment, it is proved that the algorithm of this paper has higher coverage efficiency by comparing with the original biological excitation network algorithm.",https://ieeexplore.ieee.org/document/8599478/,2018 5th International Conference on Systems and Informatics (ICSAI),10-12 Nov. 2018,ieeexplore
10.1109/ICRoM.2017.8466169,Mobile robot navigation based on Fuzzy Cognitive Map optimized with Grey Wolf Optimization Algorithm used in Augmented Reality,IEEE,Conferences,"This work presents a control technique for Mobile Robot Navigation using augmented reality (AR). This navigation technique is based on optimized Fuzzy Cognitive Map (FCM) and AR's Glyphs. AR's symbols are provided by the overhead camera. The patterns are made up of glyphs and a clear path. Six practical test are manipulated to examine the strength of optimizing FCM by a mobile robot for navigation with AR's symbols. The experiment examined the effectiveness of a Grey Wolf Optimization Algorithm (GWOA) in optimizing the FCM. Two practical experiments confirm that AR's Glyphs are an effective symbol for a robot to navigation in an unknown environment. A practical experiment reveals that a robot can use AR to manage its intended movement. Augmented reality, such as the Glyphs and a simplified map, are an effective tool for mobile robots to use in navigation in unknown environments. A prototype system is made to navigate the mobile robot by using AR and FCM.",https://ieeexplore.ieee.org/document/8466169/,2017 5th RSI International Conference on Robotics and Mechatronics (ICRoM),25-27 Oct. 2017,ieeexplore
10.1109/VLSI-TSA.2018.8403807,Mobile/embedded DNN and AI SoCs,IEEE,Conferences,"Summary form only. Recently, Deep Neural Networks are changing not only the technology paradigm in electronics but also the society itself with Artificial Intelligence technologies. In this presentation, firstly, the status of AI and DNN SoCs will be reviewed from two perspectives; the data-center oriented and the mobile and embedded AIs. This dichotomy shows clearly the possible application areas for the emerging future AIs. Especially, mobile and embedded deep learning hardware will be introduced together with CNN (Convolutional Neural Network) and RNN (Recurrent Neural Network). In addition, real CMOS chip implementation results of mobile/embedded DNNs will be explained with measurement results. Secondly, KAIST's approach integrating both sides of brain, right-brain for ""approximation and adaptation hardware"" and left-brain for""precise and programmable Von Neumann architecture"", will be explained with novel design methodology. The deep neural networks and the specialized intelligent hardware (mimicking right brain) capable of statistical processing or learning and the multi-core processors (mimicking left brain) performing the precise computations including software AI are integrated on the same SoC. Based on this brain-mimicking SoCs, the object recognition and the augmented reality applications are implemented with low-power and high-performance for wearable devices such as smart glasses, autonomous vehicles, and intelligent robots.",https://ieeexplore.ieee.org/document/8403807/,"2018 International Symposium on VLSI Technology, Systems and Application (VLSI-TSA)",16-19 April 2018,ieeexplore
10.1109/VLSI-DAT.2018.8373285,Mobile/embedded DNN and AI SoCs,IEEE,Conferences,"Recently, Deep Neural Networks are changing not only the technology paradigm in electronics but also the society itself with Artificial Intelligence technologies. In this presentation, firstly, the status of AI and DNN SoCs will be reviewed from two perspectives; the data-center oriented and the mobile and embedded AIs. This dichotomy shows clearly the possible application areas for the emerging future AIs. Especially, mobile and embedded deep learning hardware will be introduced together with CNN (Convolutional Neural Network) and RNN (Recurrent Neural Network). In addition, real CMOS chip implementation results of mobile/embedded DNNs will be explained with measurement results. Secondly, KAIST's approach integrating both sides of brain, right-brain for ""approximation and adaptation hardware"" and left-brain for ""precise and programmable Von Neumann architecture"", will be explained with novel design methodology. The deep neural networks and the specialized intelligent hardware (mimicking right brain) capable of statistical processing or learning and the multi-core processors (mimicking left brain) performing the precise computations including software AI are integrated on the same SoC. Based on this brain-mimicking SoCs, the object recognition and the augmented reality applications are implemented with low-power and high-performance for wearable devices such as smart glasses, autonomous vehicles, and intelligent robots.",https://ieeexplore.ieee.org/document/8373285/,"2018 International Symposium on VLSI Design, Automation and Test (VLSI-DAT)",16-19 April 2018,ieeexplore
10.1109/ICARM49381.2020.9195341,Model-Based Reinforcement Learning For Robot Control,IEEE,Conferences,"Model-free deep reinforcement learning (MFRL) algorithms have achieved many impressive results. But they are generally stricken with high sample complexity, which puts forward a critical challenge for their application to real-world robots. Dynamic models are essential for robot control laws, but it is often hard to obtain accurate analytical dynamic models. Therefore a data-driven approach to learning models becomes significant for reinforcement learning to increase data efficiency. Model-based algorithms are effective methods to reduce sample complexity by learning the system dynamic model. However, in certain environments, it has been proven that learning an accurate system dynamic model is a formidable problem, and their asymptotic performance cannot achieve to the same level as model-free algorithms. In our work, we use an ensemble of deep neural networks to learn system dynamics and incorporate model uncertainty. Then in order to merge the high asymptotic performance of the advanced model-free methods, the deep deterministic policy gradient (DDPG) algorithm is adopted to optimize robot control policy. Furthermore, it has been implemented within ROS for controlling a Baxter robot in the simulation environment.",https://ieeexplore.ieee.org/document/9195341/,2020 5th International Conference on Advanced Robotics and Mechatronics (ICARM),18-21 Dec. 2020,ieeexplore
10.1109/ICRA.2016.7487661,Model-predictive control with stochastic collision avoidance using Bayesian policy optimization,IEEE,Conferences,"Robots are increasingly expected to move out of the controlled environment of research labs and into populated streets and workplaces. Collision avoidance in such cluttered and dynamic environments is of increasing importance as robots gain more autonomy. However, efficient avoidance is fundamentally difficult since computing safe trajectories may require considering both dynamics and uncertainty. While heuristics are often used in practice, we take a holistic stochastic trajectory optimization perspective that merges both collision avoidance and control. We examine dynamic obstacles moving without prior coordination, like pedestrians or vehicles. We find that common stochastic simplifications lead to poor approximations when obstacle behavior is difficult to predict. We instead compute efficient approximations by drawing upon techniques from machine learning. We propose to combine policy search with model-predictive control. This allows us to use recent fast constrained model-predictive control solvers, while gaining the stochastic properties of policy-based methods. We exploit recent advances in Bayesian optimization to efficiently solve the resulting probabilistically-constrained policy optimization problems. Finally, we present a real-time implementation of an obstacle avoiding controller for a quadcopter. We demonstrate the results in simulation as well as with real flight experiments.",https://ieeexplore.ieee.org/document/7487661/,2016 IEEE International Conference on Robotics and Automation (ICRA),16-21 May 2016,ieeexplore
10.1109/IJCNN.2017.7965938,Modeling direction selective visual neural network with ON and OFF pathways for extracting motion cues from cluttered background,IEEE,Conferences,"The nature endows animals robust vision systems for extracting and recognizing different motion cues, detecting predators, chasing preys/mates in dynamic and cluttered environments. Direction selective neurons (DSNs), with preference to certain orientation visual stimulus, have been found in both vertebrates and invertebrates for decades. In this paper, with respect to recent biological research progress in motion-detecting circuitry, we propose a novel way to model DSNs for recognizing movements on four cardinal directions. It is based on an architecture of ON and OFF visual pathways underlies a theory of splitting motion signals into parallel channels, encoding brightness increments and decrements separately. To enhance the edge selectivity and speed response to moving objects, we put forth a bio-plausible spatial-temporal network structure with multiple connections of same polarity ON/OFF cells. Each pair-wised combination is filtered with dynamic delay depending on sampling distance. The proposed vision system was challenged against image streams from both synthetic and cluttered real physical scenarios. The results demonstrated three major contributions: first, the neural network fulfilled the characteristics of a postulated physiological map of conveying visual information through different neuropile layers; second, the DSNs model can extract useful directional motion cues from cluttered background robustly and timely, which hits at potential of quick implementation in vision-based micro mobile robots; moreover, it also represents better speed response compared to a state-of-the-art elementary motion detector.",https://ieeexplore.ieee.org/document/7965938/,2017 International Joint Conference on Neural Networks (IJCNN),14-19 May 2017,ieeexplore
10.1109/ICRA.2015.7139899,Modeling of movement control architectures based on motion primitives using domain-specific languages,IEEE,Conferences,"This paper introduces a model-driven approach for engineering complex movement control architectures based on motion primitives, which in recent years have been a central development towards adaptive and flexible control of complex and compliant robots. We consider rich motor skills realized through the composition of motion primitives as our domain. In this domain we analyze the control architectures of representative example systems to identify common abstractions. It turns out that the introduced notion of motion primitives implemented as dynamical systems with machine learning capabilities, provide the computational building block for a large class of such control architectures. Building on the identified concepts, we introduce domain-specific languages that allow the compact specification of movement control architectures based on motion primitives and their coordination respectively. Using a proper tool chain, we show how to employ this model-driven approach in a case study for the real world example of automatic laundry grasping with the KUKA LWR-IV, where executable source-code is automatically generated from the domain-specific language specification.",https://ieeexplore.ieee.org/document/7139899/,2015 IEEE International Conference on Robotics and Automation (ICRA),26-30 May 2015,ieeexplore
10.1109/ICARM.2019.8834284,Motion Control of Non-Holonomic Constrained Mobile Robot Using Deep Reinforcement Learning,IEEE,Conferences,"For the motion control problem of non-holonomic constrained mobile robots, a point stabilization kinematic control law for mobile robot based on deep reinforcement learning is proposed. Firstly, a kinematic model of mobile robot is constructed to build memory for deep reinforcement learning, including the current state of the robot, the control action, the reward and the next state of the robot, which is generated through the connection between mobile robot and environment. Then, value network parameters in the real-time network are updated by a loss function, which is composed of a state-action value in current moment came from the value network of real-time network and a target value, the state-action value of next moment generated by the value network in target network. Next, the parameters of policy network of real-time network are updated according to the state-action value generated by value network of the real-time network in current moment. Finally, the parameters in the real-time network are weighted and averaged with the parameters in the target network, so the parameters of target network are updated to control mobile robot to stabilize with desired point. The simulation and experiment results show that the control algorithm based on deep reinforcement learning could effectively realize the point stabilization control of nonholonomic mobile robots.",https://ieeexplore.ieee.org/document/8834284/,2019 IEEE 4th International Conference on Advanced Robotics and Mechatronics (ICARM),3-5 July 2019,ieeexplore
10.1109/IROS.2018.8593871,"Motion Planning Among Dynamic, Decision-Making Agents with Deep Reinforcement Learning",IEEE,Conferences,"Robots that navigate among pedestrians use collision avoidance algorithms to enable safe and efficient operation. Recent works present deep reinforcement learning as a framework to model the complex interactions and cooperation. However, they are implemented using key assumptions about other agents' behavior that deviate from reality as the number of agents in the environment increases. This work extends our previous approach to develop an algorithm that learns collision avoidance among a variety of types of dynamic agents without assuming they follow any particular behavior rules. This work also introduces a strategy using LSTM that enables the algorithm to use observations of an arbitrary number of other agents, instead of previous methods that have a fixed observation size. The proposed algorithm outperforms our previous approach in simulation as the number of agents increases, and the algorithm is demonstrated on a fully autonomous robotic vehicle traveling at human walking speed.",https://ieeexplore.ieee.org/document/8593871/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ICAR.2013.6766513,Move and the robot will learn: Vision-based autonomous learning of object models,IEEE,Conferences,"As robots are increasingly deployed in complex real-world domains, visual object recognition continues to be an open problem. Existing algorithms for learning and recognizing objects are predominantly computationally expensive, and require considerable training or domain knowledge. Our algorithm enables robots to use motion cues to identify and focus on a set of interesting objects, automatically extracting appearance-based and contextual cues from a small number of images to efficiently learn representative models of these objects. Learned models exploit complementary strengths of: (a) relative spatial arrangement of gradient features; (b) graph-based models of neighborhoods of gradient features; (c) parts-based models of image segments; (d) color distributions; and (e) mixture models of local context. The learned models are used in conjunction with an energy minimization algorithm and a generative model of information fusion for reliable and efficient recognition in novel scenes. The algorithm is evaluated on mobile robots in indoor and outdoor domains, and on images from benchmark datasets.",https://ieeexplore.ieee.org/document/6766513/,2013 16th International Conference on Advanced Robotics (ICAR),25-29 Nov. 2013,ieeexplore
10.1109/ICTAI50040.2020.00088,Multi-Robot Collision Avoidance with Map-based Deep Reinforcement Learning,IEEE,Conferences,"Multi-robot collision avoidance in a communication-free environment is one of the key issues for mobile robotics and autonomous driving. In this paper, we propose a map-based deep reinforcement learning (DRL) approach for collision avoidance of multiple robots, where robots do not communicate with each other and only sense other robots' positions and the obstacles around them. We use the egocentric grid map of a robot to represent the environmental information around it, which can be easily generated by using multiple sensors or sensor fusion. The learned policy generated from the DRL model directly maps 3 frames of egocentric grid maps and the robot's relative local goal positions into low-level robot control commands. We first train a convolutional neural network for the navigation policy in a simulator of multiple mobile robots using proximal policy optimization (PPO). Then we deploy the trained model to real robots to perform collision avoidance in their navigation. We evaluate the approach with various scenarios both in the simulator and on three differential-drive mobile robots in the real world. Both qualitative and quantitative experiments show that our approach is efficient with a high success rate. The demonstration video can be found at https://youtu.be/jcLKlEXuFuk.",https://ieeexplore.ieee.org/document/9288300/,2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI),9-11 Nov. 2020,ieeexplore
10.1109/ICCNC.2019.8685667,Multi-Robot Enhanced Intelligent Multi-User Millimeter-Wave MIMO Systems under Uncertain Environment,IEEE,Conferences,"This paper investigates how to maximize the practical communication quality of multi-user millimeter-wave (mmWave) MIMO systems with uncertain environment through effectively using the mobility from multi-robots as dynamic relays and adopting machine learning techniques. mmWave MIMO has been considered as a promising wireless communication technology due to the high frequency usage efficiency from beamforming. However, the uncertain environment could seriously affect the effectiveness and practicality of beamforming since wireless channels may have a more complicated structure, and the coordination among multiple nodes could be more difficult. For instance, the uncertain distribution of mobile users could significantly affect the performance of wireless channels, and then significantly degrade practical communication quality. Therefore, this paper presents a novel Multi-Robot Enhanced Intelligent Multi-User Millimeter-Wave MIMO (MREI-MU-MIMO) system that adopt both dynamic codebook based beam training protocol and online reinforcement learning to supervise the mobility of multi-robot-relay as well as handle the serious effects form the uncertain environment. Firstly, a novel dynamic codebook development is presented that cannot only lower the complexity of existing beamforming codebooks and also handle the complicated channel structure under uncertainty during multi-user beam training. Then, a decentralized Deep Q-Network (DQN) rein-forcement learning algorithm has been developed to intelligently manage multi-robot mobility and further effectively assign the optimal MIMO to handle the uncertainty from environment. The effectiveness of the proposed design has been demonstrated through real-time simulation and experiment.",https://ieeexplore.ieee.org/document/8685667/,"2019 International Conference on Computing, Networking and Communications (ICNC)",18-21 Feb. 2019,ieeexplore
10.1109/INFOCOM42981.2021.9488669,Multi-Robot Path Planning for Mobile Sensing through Deep Reinforcement Learning,IEEE,Conferences,"Mobile sensing is an effective way to collect environmental data such as air quality, humidity and temperature at low costs. However, mobile robots are typically battery powered and have limited travel distances. To accelerate data collection in large geographical areas, it is beneficial to deploy multiple robots to perform tasks in parallel. In this paper, we investigate the Multi-Robot Informative Path Planning (MIPP) problem, namely, to plan the most informative paths in a target area subject to the budget constraints of multiple robots. We develop two deep reinforcement learning (RL) based cooperative strategies: independent learning through credit assignment and sequential rollout based learning for MIPP. Both strategies are highly scalable with the number of robots. Extensive experiments are conducted to evaluate the performance of the proposed and baseline approaches using real-world WiFi Received Signal Strength (RSS) data. In most cases, the RL based solutions achieve superior or similar performance as a baseline genetic algorithm (GA)-based solution but at only a fraction of running time during inference. Furthermore, when the budgets and initial positions of the robots change, the pre-trained policies can be applied directly.",https://ieeexplore.ieee.org/document/9488669/,IEEE INFOCOM 2021 - IEEE Conference on Computer Communications,10-13 May 2021,ieeexplore
10.1109/HUMANOIDS.2018.8624918,Multi-Sensor Fusion Based Robot Self-Activity Recognition,IEEE,Conferences,"Robots play more and more important roles in our daily life. To better complete assigned tasks, it is necessary for the robots to have the ability to recognize their self-activities in real time. To perceive the environment, robots usually equipped with rich sensors, which can be used to recognize their self-activities. However, the intrinsics of the sensors such as accelerometer, servomotor and gyroscope may have significant differences, individual sensor usually exhibits weak performance in perceiving the environment. Therefore, multi-sensor fusion becomes a promising technique so that to achieve better performance. In this paper, facing the issue of robot self-activity recognition, we propose a framework to fuse information from multiple sensory streams. Our framework takes Recurrent Neural Network(RNN) that uses Long Short-Term Memory(LSTM) units to model temporal information conveyed in multiple sensory streams. In the architecture, a hierarchy structure is used to learn the sensor-specific features, a shared layer is used to fuse the features extracted from multiple sensory streams. We collect a dataset on PKU-HR6.0 robot to evaluate the proposed framework. The experiment results demonstrate the effectiveness of the proposed framework.",https://ieeexplore.ieee.org/document/8624918/,2018 IEEE-RAS 18th International Conference on Humanoid Robots (Humanoids),6-9 Nov. 2018,ieeexplore
10.1109/IROS.2015.7354094,Multi-robot 6D graph SLAM connecting decoupled local reference filters,IEEE,Conferences,"Teams of mobile robots can be deployed in search and rescue missions to explore previously unknown environments. Methods for joint localization and mapping constitute the basis for (semi-)autonomous cooperative action, in particular when navigating in GPS-denied areas. As communication losses may occur, a decentralized solution is required. With these challenges in mind, we designed a submap-based SLAM system that relies on inertial measurements and stereo-vision to create multi-robot dense 3D maps. For online pose and map estimation, we integrate the results of keyframe-based local reference filters through incremental graph SLAM. To the best of our knowledge, we are the first to combine these two methods to benefit from their particular advantages for 6D multi-robot localization and mapping: Local reference filters on each robot provide real-time, long-term stable state estimates that are required for stabilization, control and fast obstacle avoidance, whereas online graph optimization provides global multi-robot pose and map estimates needed for cooperative planning. We propose a novel graph topology for a decoupled integration of local filter estimates from multiple robots into a SLAM graph according to the filters' uncertainty estimates and independence assumptions and evaluated its benefits on two different robots in indoor, outdoor and mixed scenarios. Further, we performed two extended experiments in a multi-robot setup to evaluate the full SLAM system, including visual robot detections and submap matches as inter-robot loop closure constraints.",https://ieeexplore.ieee.org/document/7354094/,2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),28 Sept.-2 Oct. 2015,ieeexplore
10.1109/ICRA48506.2021.9561586,Multimodal Anomaly Detection based on Deep Auto-Encoder for Object Slip Perception of Mobile Manipulation Robots,IEEE,Conferences,"Object slip perception is essential for mobile manipulation robots to perform manipulation tasks reliably in the dynamic real-world. Traditional approaches to robot arms’ slip perception use tactile or vision sensors. However, mobile robots still have to deal with noise in their sensor signals caused by the robot’s movement in a changing environment. To solve this problem, we present an anomaly detection method that utilizes multisensory data based on a deep autoencoder model. The proposed framework integrates heterogeneous data streams collected from various robot sensors, including RGB and depth cameras, a microphone, and a force-torque sensor. The integrated data is used to train a deep autoencoder to construct latent representations of the multisensory data that indicate the normal status. Anomalies can then be identified by error scores measured by the difference between the trained encoder’s latent values and the latent values of reconstructed input data. In order to evaluate the proposed framework, we conducted an experiment that mimics an object slip by a mobile service robot operating in a real-world environment with diverse household objects and different moving patterns. The experimental results verified that the proposed framework reliably detects anomalies in object slip situations despite various object types and robot behaviors, and visual and auditory noise in the environment.",https://ieeexplore.ieee.org/document/9561586/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ROBOT.2010.5509154,Multiple relative pose graphs for robust cooperative mapping,IEEE,Conferences,"This paper describes a new algorithm for cooperative and persistent simultaneous localization and mapping (SLAM) using multiple robots. Recent pose graph representations have proven very successful for single robot mapping and localization. Among these methods, incremental smoothing and mapping (iSAM) gives an exact incremental solution to the SLAM problem by solving a full nonlinear optimization problem in real-time. In this paper, we present a novel extension to iSAM to facilitate online multi-robot mapping based on multiple pose graphs. Our main contribution is a relative formulation of the relationship between multiple pose graphs that avoids the initialization problem and leads to an efficient solution when compared to a completely global formulation. The relative pose graphs are optimized together to provide a globally consistent multi-robot solution. Efficient access to covariances at any time for relative parameters is provided through iSAM, facilitating data association and loop closing. The performance of the technique is illustrated on various data sets including a publicly available multi-robot data set. Further evaluation is performed in a collaborative helicopter and ground robot experiment.",https://ieeexplore.ieee.org/document/5509154/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/IROS.2018.8593899,Multisensor Online Transfer Learning for 3D LiDAR-Based Human Detection with a Mobile Robot,IEEE,Conferences,"Human detection and tracking is an essential task for service robots, where the combined use of multiple sensors has potential advantages that are yet to be fully exploited. In this paper, we introduce a framework allowing a robot to learn a new 3D LiDAR-based human classifier from other sensors over time, taking advantage of a multisensor tracking system. The main innovation is the use of different detectors for existing sensors (i.e. RGB-D camera, 2D LiDAR) to train, online, a new 3D LiDAR-based human classifier based on a new “trajectory probability”. Our framework uses this probability to check whether new detection belongs to a human trajectory, estimated by different sensors and/or detectors, and to learn a human classifier in a semi-supervised fashion. The framework has been implemented and tested on a real-world dataset collected by a mobile robot. We present experiments illustrating that our system is able to effectively learn from different sensors and from the environment, and that the performance of the 3D LiDAR-based human classification improves with the number of sensors/detectors used.",https://ieeexplore.ieee.org/document/8593899/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ITNG.2011.116,Nerve: A Lightweight Middleware for Quality-of-service Networked Robotics,IEEE,Conferences,"Social robots must adapt to dynamic environments, human interaction partners and challenging new stringent tasks. Their inner software should be designed and deployed carefully because slight changes in the robot's requirements can have an important impact in the existing code. This paper focus on the design and implementation of a lightweight middleware for networked robotics called \textit{Nerve}, which guarantees the scalability and quality-of-service requirements for this kind of real-time software. Its benefits have been proved through its use in a Robot Learning by Imitation control architecture, but its design guidelines are general enough to be also applied with common distributed and real-time embedded applications.",https://ieeexplore.ieee.org/document/5945314/,2011 Eighth International Conference on Information Technology: New Generations,11-13 April 2011,ieeexplore
10.1109/ICEE.2018.8472657,Neural Control of Mobile Robot Motion Based on Feedback Error Learning and Mimetic Structure,IEEE,Conferences,"Mobile robots motion control is a basic problem in robotics and there are still some control difficulties such as uncertainty in a real implementation which should be considered. This paper is concerned with the neural control of wheeled mobile robots trajectory tracking and posture stabilization. In the trajectory-tracking problem, the Feedback Error Learning (FEL) structure is used and for the posture stabilization problem, the Mimetic structure is employed. These neural based structures use a classic controller, Dynamic Feedback Linearization (DFL), and help to improve the adaptiveness of it. The effectiveness of the proposed controllers is verified by simulation in Webots robotic simulator and on the e-puck which is a differential wheeled mobile robot. The simulation results verify the ability of the proposed methods for controlling the robot and handling uncertainties.",https://ieeexplore.ieee.org/document/8472657/,"Electrical Engineering (ICEE), Iranian Conference on",8-10 May 2018,ieeexplore
10.1109/ICIT.2004.1490796,Neural network based control of a four rotor helicopter,IEEE,Conferences,"In this paper the design and development of an intelligent controller based on neural networks for a hoverable flying robot to be capable of achieving vertical take off and landing and to be able to sustain a specified attitude is presented. The ability to be able to autonomously navigate through a predefined path was designated for a future phase. This work is different from most autonomous flying robots as it focuses on a four-propeller configuration. This is a very rare helicopter design because of its inherent instability and it is believed that an autonomous robot of this configuration has not yet been successfully developed. In addition, this project uses fixed pitch propellers instead of variable pitch rotors resulting in a greatly reduced cost and mechanical complexity. The downside is that this introduces significant additional challenges in the control. Relative stability was achieved in three axis and all the supporting modules were successfully designed and implemented. However, significant challenges were encountered including the complexities of creating a neural networks controller (NNC) to work in real-time in a slow microcontroller as well as to develop the training process.",https://ieeexplore.ieee.org/document/1490796/,"2004 IEEE International Conference on Industrial Technology, 2004. IEEE ICIT '04.",8-10 Dec. 2004,ieeexplore
10.1109/COASE.2008.4626446,Neural network based path planning for a multi-robot system with moving obstacles,IEEE,Conferences,"Recently, a coordinated hybrid agent (CHA) framework was proposed for the control of multi-agent systems (MASs). In the past few years, it has been applied to both homogeneous and heterogeneous multi-agent systems. In previous studies, the coordination among agents were implemented based on the designerpsilas knowledge of the system. For large complex systems, it would be desirable if we can plan the coordination among agents dynamically. It was demonstrated that an intelligent planner can be designed for the CHA framework to automatically generate desired actions for multiple robots in a multi-agent system. However, in previous studies, only static obstacles in the environment were considered. In this paper, a neural network based approach is proposed for a multi-robot system with moving obstacles. A biologically inspired neural network based intelligent planner is designed for the coordination of multi-agent systems. The dynamics of each neuron in the topologically organized neural network is characterized by a shunting neural equation. A landscape of the neural activities for all neurons of a CHA agent contains information about the agentpsilas local goal, and moving obstacles. The objective for building the intelligent planner is to plan actions for multiple mobile robots to coordinate with others and to achieve the global goal. The proposed approach is able to plan the paths for multiple robots while avoiding moving obstacles. The proposed approach is simulated using both Matlab and Vortex. The virtual physical world is built using Vortex to test and develop navigation strategies for robot platforms. The Vortex module executes control commands from the control system module, and provides the outputs describing the vehicle state and terrain information, which are in turn used in the control module to produce the control commands. Simulation results show that an intelligent planner can be designed for the CHA framework to control a large complex system so that coordination among agents can be achieved.",https://ieeexplore.ieee.org/document/4626446/,2008 IEEE International Conference on Automation Science and Engineering,23-26 Aug. 2008,ieeexplore
10.1109/CCMB.2014.7020689,Neuromodulation based control of autonomous robots in ROS environment,IEEE,Conferences,"The paper presents a control approach based on vertebrate neuromodulation and its implementation on autonomous robots in the open-source, open-access environment of robot operating system (ROS) within a cloud computing framework. A spiking neural network (SNN) is used to model the neuromodulatory function for generating context based behavioral responses of the robots to sensory input signals. The neural network incorporates three types of neurons- cholinergic and noradrenergic (ACh/NE) neurons for attention focusing and action selection, dopaminergic (DA) neurons for rewards- and curiosity-seeking, and serotonergic (5-HT) neurons for risk aversion behaviors. The model depicts description of neuron activity that is biologically realistic but computationally efficient to allow for large-scale simulation of thousands of neurons. The model is implemented using graphics processing units (GPUs) for parallel computing in real-time using the ROS environment. The model is implemented to study the risk-taking, risk-aversive, and distracted behaviors of the neuromodulated robots in single- and multi-robot configurations. The entire process is implemented in a distributed computing framework using ROS where the robots communicate wirelessly with the computing nodes through the on-board laptops. Results are presented for both single- and multi-robot configurations demonstrating interesting behaviors.",https://ieeexplore.ieee.org/document/7020689/,"2014 IEEE Symposium on Computational Intelligence, Cognitive Algorithms, Mind, and Brain (CCMB)",9-12 Dec. 2014,ieeexplore
10.1145/2830772.2830789,Neuromorphic accelerators: A comparison between neuroscience and machine-learning approaches,IEEE,Conferences,"A vast array of devices, ranging from industrial robots to self-driven cars or smartphones, require increasingly sophisticated processing of real-world input data (image, voice, radio, ...). Interestingly, hardware neural network accelerators are emerging again as attractive candidate architectures for such tasks. The neural network algorithms considered come from two, largely separate, domains: machine-learning and neuroscience. These neural networks have very different characteristics, so it is unclear which approach should be favored for hardware implementation. Yet, few studies compare them from a hardware perspective. We implement both types of networks down to the layout, and we compare the relative merit of each approach in terms of energy, speed, area cost, accuracy and functionality. Within the limit of our study (current SNN and machine learning NN algorithms, current best effort at hardware implementation efforts, and workloads used in this study), our analysis helps dispel the notion that hardware neural network accelerators inspired from neuroscience, such as SNN+STDP, are currently a competitive alternative to hardware neural networks accelerators inspired from machine-learning, such as MLP+BP: not only in terms of accuracy, but also in terms of hardware cost for realistic implementations, which is less expected. However, we also outline that SNN+STDP carry potential for reduced hardware cost compared to machine-learning networks at very large scales, if accuracy issues can be controlled (or for applications where they are less important). We also identify the key sources of inaccuracy of SNN+STDP which are less related to the loss of information due to spike coding than to the nature of the STDP learning algorithm. Finally, we outline that for the category of applications which require permanent online learning and moderate accuracy, SNN+STDP hardware accelerators could be a very cost-efficient solution.",https://ieeexplore.ieee.org/document/7856622/,2015 48th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO),5-9 Dec. 2015,ieeexplore
10.1109/IRC.2019.00061,"ORC—A Lightweight, Lightning-Fast Middleware",IEEE,Conferences,"Robotic tasks are commonly solved by integrating numerous different software and hardware modules into one working application. The necessary integration work typically contributes a considerable share of the total work required for a project, which is why past research on robotics computing has pushed towards generating higher-level abstraction layers, like middlewares. However, the current state-of-the-art cannot provide reliable, low-latency communication performance as we will show in the experimental evaluation. In this paper we propose the Open Robot Communication framework (ORC). Compared to previous middlewares, ORC is lightweight and geared towards applications with high-performance requirements. We consider ORC especially useful for applications with Human Robot Interaction or collaborative tasks involving multiple robots. In the paper, we compare the runtime performance of ORC to the robot operating system (ROS). We can show that ORC enables message transfer with delays far below one millisecond and we demonstrate the real-time capabilities of ORC in a force-control task implemented in Python.",https://ieeexplore.ieee.org/document/8675625/,2019 Third IEEE International Conference on Robotic Computing (IRC),25-27 Feb. 2019,ieeexplore
10.1109/SSCI.2017.8280907,Obstacle avoidance of hexapod robots using fuzzy Q-learning,IEEE,Conferences,"Safe and autonomous obstacle avoidance plays an important role in the navigation control of hexapod robots. In this paper, we combine the method of reinforcement learning with fuzzy control to achieve the autonomous obstacle avoidance for a hexapod robot in complex environments. A fuzzy Q-learning algorithm is first presented and an obstacle avoidance approach is proposed using the Fuzzy Q-learning algorithm regarding the specific requirements of the hexapod robot. Then, the proposed approach is implemented for a real hexapod robot system that uses ultrasonic sensors to detect the obstacles in an unknown environment and learns an optimal policy to avoid the obstacles. Several groups of experiments are carried out to verify the performance of the proposed approach.",https://ieeexplore.ieee.org/document/8280907/,2017 IEEE Symposium Series on Computational Intelligence (SSCI),27 Nov.-1 Dec. 2017,ieeexplore
10.1109/ICMLC.2005.1527447,Obstacle avoidance with multi-objective optimization by PSO in dynamic environment,IEEE,Conferences,"The second order motion model is one of the fundamental questions, a mostly important object in motion planning research of mobile robots, especially in complex environment. Based on the research of the second order motion model, this paper puts forward a new method for adjusting robots to avoid obstacles in dynamic environment. A mathematical model is first established in which environmental information such as, destination of a mobile robot, velocity and direction of obstacles are considered. Secondly, a new particle swarm optimization (PSO) algorithm is used to search for solution of the multi-objective optimization problem as described in the mathematical model. Finally, by adjusting the velocity and direction of the mobile robot to avoid obstacles in real time, the robot can reach the goal safely. Simulation experiment shows that this method is better than tradition artificial potential field (APF) algorithm and its improved algorithm based on genetic algorithm for obstacle avoidance.",https://ieeexplore.ieee.org/document/1527447/,2005 International Conference on Machine Learning and Cybernetics,18-21 Aug. 2005,ieeexplore
10.1109/URAI.2018.8441890,On Humanoid Co-Robot Locomotion when Mechanically Coupled to a Human Partner,IEEE,Conferences,"This work focuses on the implementation of mechanically coupled tasks between a humanoid robot and a human. The latter focus comes from the push for robots to work with humans in everyday life as an overarching goal for the field. Co-robots, or robots that work alongside humans, may be guided by the humans through physical contact, such as the human grasping the robot's hand to gently guide it along a desired path. In this work the single-handed mechanically coupled task of guiding a robot through a course is implemented with four different methods of human input. These methods include: 1) using only force-torque sensors in the wrist of the robot for the control input from the human while the arm is under high-gain position control, creating a rigid coupling between the human and the robot, 2) using the force-torque sensors in the wrist of the robot for the control input while the arm is under low-gain position control with gravity compensation, creating compliant coupling between the human and the robot, 3) using the position of the end-effector of the robot for the control input while the arm is under low-gain position control with gravity compensation, and 4) using the force-torque sensors in the wrist and the position of the end-effector of the robot for the control input while the arm is under low-gain position control with gravity compensation. Tests are performed on the real-world and simulated adult-size humanoid robot DRC-Hubo++. During these tests the human and robot are walking together “hand in hand” with the human guiding the robot in a “figure eight” path. These tests show that having a compliant arm on the robot, when the human is guiding it via moving its end-effector, is beneficial over a rigid arm.",https://ieeexplore.ieee.org/document/8441890/,2018 15th International Conference on Ubiquitous Robots (UR),26-30 June 2018,ieeexplore
10.1109/AIMS.2014.23,Online Tool for Benchmarking of Simulated Intervention Autonomous Underwater Vehicles: Evaluating Position Controllers in Changing Underwater Currents,IEEE,Conferences,"Benchmarking is nowadays an issue on robotic research platforms, due to the fact that it is not easy to reproduce previous experiments and knowing in detail in which real conditions other algorithms have been performed. Having a web-based tool to configure and execute benchmarks opens the door to new opportunities as the design of virtual tele-laboratories that permit the implementation of new algorithms using specific and detailed constraints. This is fundamental for designing benchmarks that allow the experiments to be made in a more scientific manner, taking into account that these experiments should be able to be reproduced again by other people under the same circumstances. In the context of underwater interventions with semi-autonomous robots, the situation gets even more interesting, specially those performed on real sea scenarios, which are expensive, and difficult to perform and reproduce. This paper presents the recent advances in the online configuration tool for benchmarking, a tool that is continuously being improved in our laboratory. Our last contribution focuses on evaluating position controllers for changing underwater currents and the possibility for the user to upload its own controllers to the benchmarking tool to get online performance results.",https://ieeexplore.ieee.org/document/7102468/,"2014 2nd International Conference on Artificial Intelligence, Modelling and Simulation",18-20 Nov. 2014,ieeexplore
10.1109/IROS.2016.7759410,Online joint learning of object concepts and language model using multimodal hierarchical Dirichlet process,IEEE,Conferences,"One of the biggest challenges in intelligent robotics is to build robots that can learn to use language. To this end, we think that the practical long-term on-line concept/word learning algorithm for robots is a key issue to be addressed. In this paper, we develop an unsupervised on-line learning algorithm that uses Bayesian nonparametrics for categorizing multimodal sensory signals such as audio, visual, and haptic information for robots. The robot uses its physical body to grasp and observe an object from various viewpoints as well as listen to the sound during the observation. The most important property of the proposed framework is to learn multimodal concepts and the language model simultaneously. This mutual learning framework of concepts and language significantly improves both speech recognition and multimodal categorization performances. We conducted a long-term experiment where a human subject interacted with a real robot over 100 hours using 499 objects. Some interesting results of the experiment are discussed in this paper.",https://ieeexplore.ieee.org/document/7759410/,2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),9-14 Oct. 2016,ieeexplore
10.1109/IROS.2017.8206344,Online multi-target learning of inverse dynamics models for computed-torque control of compliant manipulators,IEEE,Conferences,"Inverse dynamics models are applied to a plethora of robot control tasks such as computed-torque control, which are essential for trajectory execution. The analytical derivation of such dynamics models for robotic manipulators can be challenging and depends on their physical characteristics. This paper proposes a machine learning approach for modeling inverse dynamics and provides information about its implementation on a physical robotic system. The proposed algorithm can perform online multi-target learning, thus allowing efficient implementations on real robots. Our approach has been tested both offline, on datasets captured from three different robotic systems and online, on a physical system. The proposed algorithm exhibits state-of-the-art performance in terms of generalization ability and convergence. Furthermore, it has been implemented within ROS for controlling a Baxter robot. Evaluation results show that its performance is comparable to the built-in inverse dynamics model of the robot.",https://ieeexplore.ieee.org/document/8206344/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/HUMANOIDS47582.2021.9555670,Open-Ended Fine-Grained 3D Object Categorization by Combining Shape and Texture Features in Multiple Colorspaces,IEEE,Conferences,"As a consequence of an ever-increasing number of service robots, there is a growing demand for highly accurate real-time 3D object recognition. Considering the expansion of robot applications in more complex and dynamic environments, it is evident that it is not possible to pre-program all object categories and anticipate all exceptions in advance. Therefore, robots should have the functionality to learn about new object categories in an open-ended fashion while working in the environment. Towards this goal, we propose a deep transfer learning approach to generate a scale- and pose-invariant object representation by considering shape and texture information in multiple color spaces. The obtained global object representation is then fed to an instance-based object category learning and recognition, where a non-expert human user exists in the learning loop and can interactively guide the process of experience acquisition by teaching new object categories, or by correcting insufficient or erroneous categories. In this work, shape information encodes the common patterns of all categories, while texture information is used to describes the appearance of each instance in detail. Multiple color space combinations and network architectures are evaluated to find the most descriptive system. Experimental results showed that the proposed network architecture outperformed the selected state-of-the-art in terms of object classification accuracy and scalability. Furthermore, we performed a real robot experiment in the context of serve_a_beer scenario to show the real-time performance of the proposed approach.",https://ieeexplore.ieee.org/document/9555670/,2020 IEEE-RAS 20th International Conference on Humanoid Robots (Humanoids),19-21 July 2021,ieeexplore
10.1109/CACS.2015.7378370,Optimal robot path planning system by using a neural network-based approach,IEEE,Conferences,"This paper proposes an optimal robot path planning system that can build map, plan optimal paths, and maneuver mobile robots. The system constructs a grid-based map by using information on the locations of the origin and static obstacles. The system calculates the optimal trajectory by using a simplified neural network model and accordingly maneuvers a mobile robot. For dynamic obstacles, the mobile robot can sense the ambient environment and avoid possible collisions. A practical experiment using an Arduino-based platform was conducted to illustrate the effectiveness of the proposed methodology.",https://ieeexplore.ieee.org/document/7378370/,2015 International Automatic Control Conference (CACS),18-20 Nov. 2015,ieeexplore
10.1109/ICCE-Berlin47944.2019.8966156,Optimizing Deep Learning Based Semantic Video Segmentation on Embedded GPUs,IEEE,Conferences,"Decision making in many industries today is being improved drastically thanks to artificial intelligence and deep learning. New algorithms address challenges such as genome mapping, medical diagnostics, self-driving cars, autonomous robots and more. Deep learning in embedded systems requires high optimization due to the high computational demand, given that power, heat dissipation, size and price constraints are numerous. In this paper we analyze several acceleration methods which include utilization of GPUs for most complex variants of deep learning, such as semantic video segmentation operating in real time. Specifically, we propose mapping of acceleration routines commonly present within deep learning SDKs to different network layers in semantic segmentation. Finally, we evaluate one implementation utilizing the enumerated techniques for semantic segmentation of front camera in autonomous driving front view.",https://ieeexplore.ieee.org/document/8966156/,2019 IEEE 9th International Conference on Consumer Electronics (ICCE-Berlin),8-11 Sept. 2019,ieeexplore
10.1109/CDC.2006.377499,Path Generation Using Matrix Representations of Previous Robot State Data,IEEE,Conferences,"Humans learn by repetition and using past experiences. It is possible for robots to act in a similar fashion. By representing past path traversal experiences with matrices, a new path can be generated without relying on calculations of complex dynamics or control laws. This paper presents one approach for allowing robots to use past experience to generate new paths and control actions. This approach relies on using several matrices to associate each new input value with previous robot states. An example is provided and analyzed which shows a successful simulated implementation of this approach. In addition a real world test of the approach was conducted which demonstrates that the implementation not only generates new paths, but does so fast enough to be feasible for real time systems",https://ieeexplore.ieee.org/document/4178112/,Proceedings of the 45th IEEE Conference on Decision and Control,13-15 Dec. 2006,ieeexplore
10.1109/IWECAI50956.2020.00019,Path Planning Obstacle Avoidance Algorithm Based on Wheeled Robot,IEEE,Conferences,"There are many obstacles and movements in the indoor environment. Indoor robots need to cope with the changing environment. This paper studies the obstacle avoidance problem of wheeled robots moving in an unknown environment. Firstly, the dynamic path planning algorithm for robot autonomous obstacle avoidance is studied, and the algorithm is implemented in C# language. Then use the Unity3D game engine to simulate the algorithm. The innovations of this algorithm are as follows: 1. Vectorize the path of the robot; 2. Summarize the motion state of the obstacle and the robot into six cases. During the movement process, the obstacle movement state is continuously judged, and the speed and direction of the obstacle are analyzed. The judgment result must belong to six situations. The experiment proves that the algorithm can solve the obstacle avoidance problem when encountering obstacles of different speeds and sizes, and has stronger applicability.",https://ieeexplore.ieee.org/document/9221693/,2020 International Workshop on Electronic Communication and Artificial Intelligence (IWECAI),12-14 June 2020,ieeexplore
10.1109/DISA.2018.8490605,Path Planning on Robot Based on D* Lite Algorithm,IEEE,Conferences,"The increasing need of autonomous behavior of robots in fields of science and technology formed the requirement for path planning implemented by the robot without the human assistance. In this paper, D* Lite, which is a path planning graph-based algorithm, was used in order to compute the shortest path from a start to goal point in a real environment and make a Pepper robot move in a computed trajectory. The movement of robot was conducted in a static environment, with the map of the environment already known. This paper is a first step in the research focusing on a creation of a so-called intelligent workspace.",https://ieeexplore.ieee.org/document/8490605/,2018 World Symposium on Digital Intelligence for Systems and Machines (DISA),23-25 Aug. 2018,ieeexplore
10.23919/ICINS43215.2020.9134006,Path Planning with Improved Artificial Potential Field Method Based on Decision Tree,IEEE,Conferences,"Path planning is one of the key research directions in the field of mobile robots. It ensures that moving objects can reach the target point safely and without collision in a complex obstacle environment. The path planning is to search an optimal path from the starting point to the target point for the mobile robot in an environment with obstacles, according to certain evaluation criteria (such as the time, the best path, the minimum energy consumption, etc.). The path planning based on artificial potential field method has been paid more and more attention because of its advantages such as convenient calculation, simple implementation of hardware and outstanding real-time performance. However, the artificial potential field method has some limitations, such as the local minimum, the oscillation of moving objects among obstacles and so on. To solve these problems, we can introduce the idea of decision tree into the artificial potential field method for improvement. In machine learning, decision tree is usually used for classification. It is a prediction model, which represents a mapping relationship between object attributes and object values. By utilizing the advantages of decision tree in rule expression and extraction, an improved artificial potential field path planning model based on decision tree is constructed, which can realize real-time and accurate identification of current behavior and fast decision-making of next time behavior in path planning. Aiming at the dynamic path planning problem of mobile robots in indoor complex environment, based on the traditional artificial potential field method, this paper introduces the distance term into the potential field function, and proposes an improved artificial potential field method based on the idea of decision tree, to solve the local minimum, the oscillation between obstacles and concave obstacle problems. According to repulsion coefficient, deflection angle of resultant force and velocity, a reasonable classification decision is made to meet the needs of different obstacle distribution scenarios, and the effectiveness of the proposed method is verified by simulation experiments. Simulation results show that, compared with the traditional artificial potential field method, the planning time of improved algorithm is reduced by 50%, and the smoothness of path planning by the improved algorithm is increased by 43.3%.",https://ieeexplore.ieee.org/document/9134006/,2020 27th Saint Petersburg International Conference on Integrated Navigation Systems (ICINS),25-27 May 2020,ieeexplore
10.1109/ISIC.2002.1157740,Path planning for mobile robots using an improved reinforcement learning scheme,IEEE,Conferences,"The current method for establishing travel routes provides modeled environmental information. However, it is difficult to create an environment model for the environments in which mobile robots travel because the environment changes constantly due to the existence of moving objects, including pedestrians. In this study, we propose a path planning system for mobile robots using reinforcement-learning systems and Cerebellar Model Articulation Controllers (CMACs). We select the best travel route utilizing these reinforcement-learning systems. When a CMAC learns the value function of Q-Learning, it improves learning speed by utilizing generalizing action. CMACs enable us to reduce the time needed to select the best travel route. Using simulation and real robots, we perform a path-planning experiment. We report the results of simulation and experiment on traveling by on-line learning.",https://ieeexplore.ieee.org/document/1157740/,Proceedings of the IEEE Internatinal Symposium on Intelligent Control,30-30 Oct. 2002,ieeexplore
10.1109/SICE.2002.1195737,Path planning for mobile robots using an improved reinforcement learning scheme,IEEE,Conferences,"The current method for establishing travel routes provides modeled environmental information. However, it is difficult to create an environment model for the environments in which mobile robot travel because the environment changes constantly due to the existence of moving objects, Including pedestrians. In this study, we propose a path planning system for mobile robots using reinforcement-learning systems and cerebellar model articulation controllers (CMACs). We selected the best travel route utilizing these reinforcement-learning systems. When a CMAC learns the value function of Q-learning, it improves learning speed by utilizing the generalizing action. CMACs enable us to reduce the time needed to select the best travel route. Using simulation and real robots, we performed a path-planning experiment. We report the results of simulation and experiment on traveling by online learning.",https://ieeexplore.ieee.org/document/1195737/,Proceedings of the 41st SICE Annual Conference. SICE 2002.,5-7 Aug. 2002,ieeexplore
10.1109/ICCEAI52939.2021.00074,Pedestrian Recognition System for Smart Security Robot using Pedestrian Re-identification Algorithm,IEEE,Conferences,"The security system is an important guarantee for the safety of citizens' lives and property. In recent years, security robots have been more and more widely used in security systems. At present, domestic security robots generally lack of pedestrian recognition ability under complex circumstances. Therefore, this paper designs and implements pedestrian recognition system for smart security robots using improved pedestrian re-identification algorithm. Experiment result shows that the system has success rate of 90 % and response speed compliance rate of 94.4% under real circumstances, which is much better than traditional system.",https://ieeexplore.ieee.org/document/9544430/,2021 International Conference on Computer Engineering and Artificial Intelligence (ICCEAI),27-29 Aug. 2021,ieeexplore
10.1109/ICSMC.1999.816641,"Perception, reasoning and learning of multiple agent systems for robot soccer",IEEE,Conferences,"Presents a supervisory control strategy for coordination of soccer playing mobile robots. Within the framework of a hierarchical control structure, three layered components of supervisor, coordinator, and executor emulate the basic three concepts of human intelligence, perception, reasoning, and learning. A small size discrete event system model is derived and implemented in the supervisor and coordinator for state-action reasoning and coordination of multiple robotic agents for a successful soccer game. Experimental results of real soccer games are given to demonstrate the feasibility and effectiveness of the developed supervisory control strategy in terms of structural simplicity and computational speed for real-time control.",https://ieeexplore.ieee.org/document/816641/,"IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028)",12-15 Oct. 1999,ieeexplore
10.1109/ICECCT.2015.7226205,Performance analysis of path planning techniques for autonomous mobile robots,IEEE,Conferences,"This paper presents a comparative study on path planning techniques for autonomous mobile robots in a cluttered environment. It investigates four well known path planning algorithms and compares their performance with the proposed free configuration eigen-spaces (FCE) path planning method. In total, five path planning algorithms are considered towards the solution of the path planning problem under certain working parameters. These working parameters are the computation time needed to find a solution, the distance traveled and the amount of turning by the autonomous mobile robot. A comparison of results has been analyzed. This study will enable readers to identify, which of the proposed methods is most suitable for application under the working parameters the user wants to optimize. The findings have been summarized in the conclusion section. The techniques were implemented in the real-time robotic software Player/Stage. Further analysis were done using MATLAB mathematical computation software.",https://ieeexplore.ieee.org/document/7226205/,"2015 IEEE International Conference on Electrical, Computer and Communication Technologies (ICECCT)",5-7 March 2015,ieeexplore
10.1109/ROMAN.2009.5326164,Physical interaction learning: Behavior adaptation in cooperative human-robot tasks involving physical contact,IEEE,Conferences,"In order for humans and robots to engage in direct physical interaction several requirements have to be met. Among others, robots need to be able to adapt their behavior in order to facilitate the interaction with a human partner. This can be achieved using machine learning techniques. However, most machine learning scenarios to-date do not address the question of how learning can be achieved for tightly coupled, physical touch interactions between the learning agent and a human partner. This paper presents an example for such human in-the-loop learning scenarios and proposes a computationally cheap learning algorithm for this purpose. The efficiency of this method is evaluated in an experiment, where human care givers help an android robot to stand up.",https://ieeexplore.ieee.org/document/5326164/,RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication,27 Sept.-2 Oct. 2009,ieeexplore
10.1109/GCCE50665.2020.9291969,Policy Transfer from Simulation to Real World for Autonomous Control of an Omni Wheel Robot,IEEE,Conferences,"We aim to develop an autonomous mobile robot which supports workers in warehouse to reduce their burden. The robot acquire state-action policy to avoid obstacles and reach a destination by reinforcement learning using LiDAR sensor. In case of real-world application of reinforcement learning, the policy learned previously under simulation environment are generally diverted to real robots because of uncertainties that is unexpected under simulation environment, for example, friction, sensor noise and so on. In this paper, we proposed a method to refine action control of an omni wheel robot by transfer learning on real environment to deal with this problem. We conduct the experiment of searching the route for reaching a goal on real environment using transfer learning's results and verify the effectiveness of the policy acquired.",https://ieeexplore.ieee.org/document/9291969/,2020 IEEE 9th Global Conference on Consumer Electronics (GCCE),13-16 Oct. 2020,ieeexplore
10.1109/IROS.2013.6696568,Pose and paste — An intuitive interface for remote navigation of a multi-robot system,IEEE,Conferences,"We present Pose and Paste (P&amp;P) - an intuitive interface designed to facilitate interaction between a single user and a number of robots equipped with cameras. With this interface, a user wearing a head-mounted display is able to cycle through the real-time video streams originating from the robots' cameras. The user is also able to select a robot and remotely position it by simply walking or turning his/her head, i.e., control the robot's motion in a master/slave-type fashion. We report the results of an initial hardware experiment where a user located in the USA is tasked to position two quadrotor robots within a motion capture laboratory located in Germany. These results suggest that P&amp;P is a feasible approach to remotely inspect disaster affected sites. Lastly, we conduct a user study to compare P&amp;P with a baseline interface composed of a traditional computer monitor and a video game controller. The quantitative results and qualitative discussions resulting from this user study highlight how such multi-robot interfaces can be further improved.",https://ieeexplore.ieee.org/document/6696568/,2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,3-7 Nov. 2013,ieeexplore
10.1109/ICBSII51839.2021.9445124,Positioning the 5-DOF Robotic Arm using Single Stage Deep CNN Model,IEEE,Conferences,"In teleoperation mechanism, the surgical robots are controlled using hand gestures from remote location. The remote location robotic arm control using hand gesture recognition is a challenging computer vision problem. The hand action recognition under complex environment (cluttered background, lighting variation, scale variation etc.) is a difficult and time consuming process. In this paper, a light weight Convolutional Neural Network (CNN) model Single Shot Detector (SSD) Lite MobileNet-V2 is proposed for real-time hand gesture recognition. SSD Lite versions tend to run hand gesture recognition applications on low-power computing devices like Raspberry Pi due to its light weight and timely recognition. The model is deployed using a Camera and two Raspberry Pi Controllers For the hand gesture recognition and data transfer to the cloud server, the Raspberry Pi controller 1 is used. The Raspberry Pi Controller 2 receives the cloud information and controls the Robotic arm operations. The performance of the proposed model is also compared with a SSD Inception-V2 model for the MITI Hand dataset-II (MITI HD-II). The average precision, average recall and F1-score for SSD Lite MobileNet-V2 and SSD Inception-V2 models are analyzed by training and testing the model with the learning rate of 0.0002 using Adam optimizer. SSD MobileNet-V2 model obtained an Average precision of 98.74% and SSD Inception-V2 model as 99.27%, The prediction time for SSD Lite MobileNet-V2 model using Raspberry Pi controller takes only 0.67s whereas, 1.2s for SSD Inception-V2 Model.",https://ieeexplore.ieee.org/document/9445124/,"2021 Seventh International conference on Bio Signals, Images, and Instrumentation (ICBSII)",25-27 March 2021,ieeexplore
10.1109/RO-MAN46459.2019.8956461,Privacy First: Designing Responsible and Inclusive Social Robot Applications for in the Wild Studies,IEEE,Conferences,"Deploying social robots applications in public spaces for conducting in the wild studies is a significant challenge but critical to the advancement of social robotics. Real world environments are complex, dynamic, and uncertain. Human-Robot interactions can be unstructured and unanticipated. In addition, when the robot is intended to be a shared public resource, management issues such as user access and user privacy arise, leading to design choices that can impact on users' trust and the adoption of the designed system. In this paper we propose a user registration and login system for a social robot and report on people's preferences when registering their personal details with the robot to access services. This study is the first iteration of a larger body of work investigating potential use cases for the Pepper social robot at a government managed centre for startups and innovation. We prototyped and deployed a system for user registration with the robot, which gives users control over registering and accessing services with either face recognition technology or a QR code. The QR code played a critical role in increasing the number of users adopting the technology. We discuss the need to develop social robot applications that responsibly adhere to privacy principles, are inclusive, and cater for a broad spectrum of people.",https://ieeexplore.ieee.org/document/8956461/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/WACV45572.2020.9093599,Probabilistic Object Detection: Definition and Evaluation,IEEE,Conferences,"We introduce Probabilistic Object Detection, the task of detecting objects in images and accurately quantifying the spatial and semantic uncertainties of the detections. Given the lack of methods capable of assessing such probabilistic object detections, we present the new Probability-based Detection Quality measure (PDQ). Unlike AP-based measures, PDQ has no arbitrary thresholds and rewards spatial and label quality, and foreground/background separation quality while explicitly penalising false positive and false negative detections. We contrast PDQ with existing mAP and moLRP measures by evaluating state-of-the-art detectors and a Bayesian object detector based on Monte Carlo Dropout. Our experiments indicate that conventional object detectors tend to be spatially overconfident and thus perform poorly on the task of probabilistic object detection. Our paper aims to encourage the development of new object detection approaches that provide detections with accurately estimated spatial and label uncertainties and are of critical importance for deployment on robots and embodied AI systems in the real world.",https://ieeexplore.ieee.org/document/9093599/,2020 IEEE Winter Conference on Applications of Computer Vision (WACV),1-5 March 2020,ieeexplore
10.1109/IJCNN.2014.6889947,Qualitative approach for inverse kinematic modeling of a Compact Bionic Handling Assistant trunk,IEEE,Conferences,"Compact Bionic Handling Assistant (CBHA) is a continuum manipulator, with pneumatic-based actuation and compliant gripper. This bionic arm is attached to a mobile robot named Robotino. Inspired by the elephant's trunk, it can reproduce biological behaviors of trunks, tentacles, or snakes. Unlike rigid link robot manipulators, the development of high performance control algorithm of continuum robot manipulators remains a challenge, particularly due to their complex mechanical design, hyper-redundancy and presence of uncertainties. Numerous studies have been investigated for modeling of such complex systems. Such continuum robots, like the CBHA present a set of nonlinearities and uncertainties, making difficult to build an accurate analytical model, which can be used for control strategies development. Hence, learning approach becomes a suitable tool in such scenarios in order to capture un-modeled nonlinear behaviors of the continuous robots. In this paper, we present a qualitative modeling approach, based on neuronal model of the inverse kinematic of CBHA. A penalty term constraint is added to the inverse objective function into Distal Supervised Learning (DSL) scheme to select one particular inverse model from the redundancy manifold. The inverse kinematic neuronal model is validated by conducting a real-time implementation on a CBHA trunk.",https://ieeexplore.ieee.org/document/6889947/,2014 International Joint Conference on Neural Networks (IJCNN),6-11 July 2014,ieeexplore
10.1109/IROS40897.2019.8968072,Quickly Inserting Pegs into Uncertain Holes using Multi-view Images and Deep Network Trained on Synthetic Data,IEEE,Conferences,"This paper explores the use of robots to autonomously assemble parts with variations in colors and textures. Specifically, we focus on peg-in-hole assembly with some initial position uncertainty and holes located on surfaces of different colors and textures. Two in-hand cameras and a force-torque sensor are used to account for the position uncertainty. A program sequence comprising learning-based visual servoing, spiral search, and impedance control is implemented to perform the peg-in-hole task with feedback from the above sensors. Contributions are mainly made in the learning-based visual servoing component of the sequence, where a deep neural network is trained with various sets of synthetic data generated using the concept of domain randomization to predict where a hole is. In the experiments and analysis section, the network is analyzed and compared, and a real-world robotic system to insert pegs to holes using the proposed method is implemented. The results show that the implemented peg-in-hole assembly system can perform successful peg-in-hole insertions on surfaces with various colors and textures. It can generally speed up the entire peg-in-hole process, especially when the initial position uncertainty is large.",https://ieeexplore.ieee.org/document/8968072/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ICRA48506.2021.9561277,Rapid Pose Label Generation through Sparse Representation of Unknown Objects,IEEE,Conferences,"Deep Convolutional Neural Networks (CNNs) have been successfully deployed on robots for 6-DoF object pose estimation through visual perception. However, obtaining labeled data on a scale required for the supervised training of CNNs is a difficult task - exacerbated if the object is novel and a 3D model is unavailable. To this end, this work presents an approach for rapidly generating real-world, pose-annotated RGB-D data for unknown objects. Our method not only circumvents the need for a prior 3D object model (textured or otherwise) but also bypasses complicated setups of fiducial markers, turntables, and sensors. With the help of a human user, we first source minimalistic labelings of an ordered set of arbitrarily chosen keypoints over a set of RGB-D videos. Then, by solving an optimization problem, we combine these labels under a world frame to recover a sparse, keypoint-based representation of the object. The sparse representation leads to the development of a dense model and the pose labels for each image frame in the set of scenes. We show that the sparse model can also be efficiently used for scaling to a large number of new scenes. We demonstrate the practicality of the generated labeled dataset by training a CNN based 6-DoF object pose estimator.",https://ieeexplore.ieee.org/document/9561277/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICRA.2017.7989184,Rapidly exploring learning trees,IEEE,Conferences,"Inverse Reinforcement Learning (IRL) for path planning enables robots to learn cost functions for difficult tasks from demonstration, instead of hard-coding them. However, IRL methods face practical limitations that stem from the need to repeat costly planning procedures. In this paper, we propose Rapidly Exploring Learning Trees (RLT*), which learns the cost functions of Optimal Rapidly Exploring Random Trees (RRT*) from demonstration, thereby making inverse learning methods applicable to more complex tasks. Our approach extends Maximum Margin Planning to work with RRT* cost functions. Furthermore, we propose a caching scheme that greatly reduces the computational cost of this approach. Experimental results on simulated and real-robot data from a social navigation scenario show that RLT* achieves better performance at lower computational cost than existing methods. We also successfully deploy control policies learned with RLT* on a real telepresence robot.",https://ieeexplore.ieee.org/document/7989184/,2017 IEEE International Conference on Robotics and Automation (ICRA),29 May-3 June 2017,ieeexplore
10.1109/EMRTS.1999.777446,Rate modulation of soft real-time tasks in autonomous robot control systems,IEEE,Conferences,"Due to the high number of sensors managed and need to perform complex reasoning activities, real-time control systems of autonomous robots exhibit a high potential for overload, i.e., real-time tasks missing their deadlines. In these systems overload should be regarded as a likely occurrence and hence managed accordingly. In this paper we illustrate a novel scheduling technique for adaptation of soft real-time load to available computational capacity in the context of autonomous robot control architectures. The technique is based on rate modulation of a set of periodic tasks in a range of admissible rates. The technique is shown to be easily computable and several variations in implementation are reviewed within the paper.",https://ieeexplore.ieee.org/document/777446/,Proceedings of 11th Euromicro Conference on Real-Time Systems. Euromicro RTS'99,9-11 June 1999,ieeexplore
10.1109/ICACITE51222.2021.9404561,Real Time Expression Detection of Multiple Faces Using Deep Learning,IEEE,Conferences,"A facial expression is like a gesture which is executed with the facial muscles, and it conveys the emotional state of the subject to the observer. As technology is progressing it is important for the robots to understand human emotions for better communication. We investigate the field of facial expression recognition with deep learning by using Convolutional Neural Network (CNN) algorithm. The proposed framework is trained with FER2013 dataset and tested in real time. Several pooling layers are used in the training part for extracting the features out of the images and haarcascade classifier is used to identify the presence of face in the frame. Our system can recognize five universal emotions of the Facial Action Coding System (FACS) i.e., happy, sad, neutral, surprise and angry which can be identified by the face of a person. It can detect the expressions of multiple faces at the same time. The training accuracy obtained by the system is 73.12%. The real time experiment showed an excellent result.",https://ieeexplore.ieee.org/document/9404561/,2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE),4-5 March 2021,ieeexplore
10.1109/ICCCE.2008.4580693,Real time implementation of NARMA L2 feedback linearization and smoothed NARMA L2 controls of a single link manipulator,IEEE,Conferences,"Robotics is a field of modern technology which requires knowledge in vast areas such as electrical engineering, mechanical engineering, computer science as well as finance. Nonlinearities and parametric uncertainties are unavoidable problems faced in controlling robots in industrial plants. Tracking control of a single link manipulator driven by a permanent magnet brushed DC motor is a nonlinear dynamics due to effects of gravitational force, mass of the payload, posture of the manipulator and viscous friction coefficient. Furthermore uncertainties arise because of changes of the rotor resistance with temperature and random variations of friction while operating. Due to this fact classical PID controller can not be used effectively since it is developed based on linear system theory. Neural network control schemes for manipulator control problem have been proposed by researchers; in which their competency is validated through simulation studies. On the other hand, actual real time applications are rarely established. Instead of simulation studies, this paper is aimed to implement neural network controller in real time for controlling a DC motor driven single link manipulator. The work presented in this paper is concentrating on neural NARMA L2 control and its improvement called to as Smoothed NARMA L2 control. As proposed by K. S Narendra and Mukhopadhyay, Narma L2 control is one of the popular neural network architectures for prediction and control. The real time experimentation showed that the Smoothed NARMA L2 is effective for controlling the single link manipulator for both point-to-point and continuous path motion control.",https://ieeexplore.ieee.org/document/4580693/,2008 International Conference on Computer and Communication Engineering,13-15 May 2008,ieeexplore
10.1109/ICRAI.2012.6413407,Real time localization of mobile robotic platform via fusion of Inertial and Visual Navigation System,IEEE,Conferences,"Inertial Navigation System (INS) is one of the most important component of a mobile robotic platform, be it ground or air based. It is used to localize the mobile robotic platform in the real world and identify its location in terms of latitudes and longitudes or other related coordinate systems. Highly accurate and precise INS is quite expensive and is therefore not suitable for more general purpose applications. It is, therefore, a standard approach in mobile robotics to use a low grade commercial INS coupled with another navigation device to provide a more accurate triangulation. Generally, INS and Global Positioning System (GPS) are integrated using Kalman Filters to provide accurate localization information about the mobile robots. Although, in certain scenarios, the mobile robot is not able to acquire a GPS fix for long durations of time especially when navigating in indoor environments or in areas with inadequate GPS satellite coverage. In such cases, an additional source of location fix is required. This paper describes an accurate and stable data fusion filter which integrates the position of a mobile robot from a Visual Navigation System (VNS) with the position from an INS to accurately localize the robot in absence of GPS data. This research proposes a seven error states model and uses it in Kalman Filter for data fusion. The filter is tuned and tested using dynamic and static data from INS and VNS. Simulation and experimentation results show that the seven error states model based Kalman Filter provides a good balance between accuracy, robustness and processing efficiency for a real time implementation. Experiments also show that in absence of GPS data only a couple of fixes from the VNS are sufficient to quickly correct the position of the mobile robotic platform and three fixes at different times are sufficient for velocity correction of INS.",https://ieeexplore.ieee.org/document/6413407/,2012 International Conference of Robotics and Artificial Intelligence,22-23 Oct. 2012,ieeexplore
10.1109/SmartWorld.2018.00106,Real-Time Data Processing Architecture for Multi-Robots Based on Differential Federated Learning,IEEE,Conferences,"The emergency of ubiquitous intelligence in various things has become the ultimate cornerstone in building a smart interconnection of the physical world and the human world, which also caters to the idea of Internet of Things (IoT). Nowadays, robots as a new type of ubiquitous IoT devices have gained much attention. With the increasing number of distributed multi-robots, such smart environment generates unprecedented amounts of data. Robotic applications are faced with challenges of such big data: the serious real-time assurance and data privacy. Therefore, in order to obtain the big data values via knowledge sharing under the premise of ensuring the real-time data processing and data privacy, we propose a real-time data processing architecture for multi-robots based on the differential federated learning, called RT-robots architecture. A global shared model with differential privacy protection is trained on the cloud iteratively and distributed to multiple edge robots in each round, and the robotic tasks are processed locally in real time. Our implementation and experiments demonstrate that our architecture can be applied on multiple robotic recognition tasks, balance the trade-off between the performance and privacy.",https://ieeexplore.ieee.org/document/8560084/,"2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)",8-12 Oct. 2018,ieeexplore
10.1109/CNSI.2011.67,Real-Time Face-Detection Engine for Robustness to Variable Illumination and Rotated Faces,IEEE,Conferences,"In this paper, we proposes a novel hardware architecture and FPGA implementation method of high performance real-time face-detection engine for robustness to variable illumination and rotation. The proposed face detection algorithm improved its performance by using MCT (Modified Census Transform), rotation transformation and AdaBoost learning algorithm. For implementation, we used a QVGA class camera, LCD display, and Virtex5 LX330 FPGA made by Xilinx Corporation. The verification results showed that it is possible to detect at least 32 faces in a wide variety of sizes at a maximum speed of 43 frames per second in real time. This finding can be applied to artificial intelligence robots for human recognition, conventional security systems for identity certification, and cutting-edge digital cameras using image processing techniques.",https://ieeexplore.ieee.org/document/5954277/,"2011 First ACIS/JNU International Conference on Computers, Networks, Systems and Industrial Engineering",23-25 May 2011,ieeexplore
10.1109/SCIS-ISIS.2018.00037,Real-Time Image Semantic Segmentation Networks with Residual Depth-Wise Separable Blocks,IEEE,Conferences,"Semantic image segmentation plays a key role in obtaining pixel-level understanding of images. In recent years, researchers have tackled this problem by using deep learning methods instead of traditional computer vision methods. Because of the development of technologies like autonomous vehicles and indoor robots, segmentation techniques, that have not only high accuracy but also the capability of running in real-time on embedded platform and mobile devices, are in high demand. In this work, we have proposed a new convolutional module, named Residual depth-wise separable, and a fast and efficient convolutional neural network for segmentation. The proposed method is compared against other state of the art real-time models. The experiment results illustrate that our method is efficient in computation while achieves state of the art performance in term of accuracy.",https://ieeexplore.ieee.org/document/8716227/,2018 Joint 10th International Conference on Soft Computing and Intelligent Systems (SCIS) and 19th International Symposium on Advanced Intelligent Systems (ISIS),5-8 Dec. 2018,ieeexplore
10.1109/Cybermatics_2018.2018.00131,Real-Time Object Recognition Based on NAO Humanoid Robot,IEEE,Conferences,"This paper focuses on the real-time object recognition based indoor humanoid robots like Nao robots. Improving the perceptive ability of service robot has always been a research hotspot. The breakthrough of computer vision technology represented by object recognition provides a broader idea for this purpose. We deployed a micro-cloud layer that connects the robot with the computer vision, thereby realized the concepts of RaaS (Robot as a service). In this paper, in order to make the Nao robot to detect objects faster. We present an architecture about real-time object recognition on Nao, and offload the task of control and data collection from robot to a PC. Next, the image data is transmitted over Ethernet to the workstation, which runs multiple parallel image processing services. These services are built with the current popular deep neural network by TensorFlow and running on a GPU GTX1080 Ti. In the micro-cloud layer, we designed a universal robotic visual task queue model, and a PC registers the task queue to the LAN. There are multiple workers in the LAN, and each worker is an independent service processer. Service processer obtains the task queue from the network and processes the queue, and then the processer puts the results back to the manager. The experimental results of the Nao robot in the simulation and real word show that our model and method are effective. The robot can recognize about 90 kinds of common objects, and each frame of image processing time is about 100 milliseconds.",https://ieeexplore.ieee.org/document/8726687/,"2018 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)",30 July-3 Aug. 2018,ieeexplore
10.1109/ICMLC.2005.1527001,Real-Time Path Planning for Mobile Robots,IEEE,Conferences,"A new on-line real-time approach with obstacle avoidance for mobile robots moving in an uncertain environment has been proposed and implemented. With the integration of global planning and local planning, this path planning approach is based on polar coordinates in which the desirable direction angle is taken into consideration as an optimization index. Detecting unknown obstacles with local feedback information by robot’s sensor system, this approach orients the desirable direction of mobile robot so as to generate local sub-goal in every planning window. As a result, the difference between real direction angle and desirable direction angle of robot motion steers the mobile robot to detour collisions and advance toward the target without stopping to re-plan a path when new sensor data become available. This approach is not only simple and flexible, but also overcomes flaws of global planning and local planning. The effectiveness, feasibility, real-time performance, optimization capability, high precision and perfect stability are demonstrated by means of simulation examples.",https://ieeexplore.ieee.org/document/1527001/,2005 International Conference on Machine Learning and Cybernetics,18-21 Aug. 2005,ieeexplore
10.1109/CRV50864.2020.00032,Real-time Motion Planning for Robotic Teleoperation Using Dynamic-goal Deep Reinforcement Learning,IEEE,Conferences,"We propose Dynamic-goal Deep Reinforcement Learning (DGDRL) method to address the problem of robot arm motion planning in telemanipulation applications. This method intuitively maps human hand motions to a robot arm in real-time, while avoiding collisions, joint limits and singularities. We further propose a novel hardware setup, based on the HTC VIVE VR system, that enables users to smoothly control the robot tool position and orientation with hand motions, while monitoring its movements in a 3D virtual reality environment. A VIVE controller captures 6D hand movements and gives them as reference trajectories to a deep neural policy network for controlling the robot's joint movements. Our DGDRL method leverages the state-of-art Proximal Policy Optimization (PPO) algorithm for deep reinforcement learning to train the policy network with the robot joint values and reference trajectory observed at each iteration. Since training the network on a real robot is time-consuming and unsafe, we developed a simulation environment called RobotPath which provides kinematic modeling, collision analysis and a 3D VR graphical simulation of industrial robots. The deep neural network trained using RobotPath is then deployed on a physical robot (ABB IRB 120) to evaluate its performance. We show that the policies trained in the simulation environment can be successfully used for trajectory planning on a real robot. The the codes, data and video presenting our experiments are available at https://github.com/kavehkamali/ppoRobotPath.",https://ieeexplore.ieee.org/document/9108691/,2020 17th Conference on Computer and Robot Vision (CRV),13-15 May 2020,ieeexplore
10.1109/LifeTech52111.2021.9391811,Real-time Object Detection with Deep Learning for Robot Vision on Mixed Reality Device,IEEE,Conferences,"Mixed reality device sensing capabilities are valuable for robots, for example, the inertial measurement unit (IMU) sensor and time-of-flight (TOF) depth sensor can support the robot in navigating its environment. This paper demonstrates a deep learning (YOLO model) background, realtime object detection system implemented on mixed reality device. The goal of the system is to create a real-time communication system between HoloLens and Ubuntu systems to enable real-time object detection using the YOLO model. The experimental results show that the proposed method has a fast speed to achieve real-time object detection using HoloLens. This enables Microsoft HoloLens as a device for robot vision. To enhance human-robot interaction, we will apply it to a wearable robot arm system to automatically grasp objects in the future.",https://ieeexplore.ieee.org/document/9391811/,2021 IEEE 3rd Global Conference on Life Sciences and Technologies (LifeTech),9-11 March 2021,ieeexplore
10.1109/CCA.2007.4389266,Real-time Obstacle Avoidance Strategy for Mobile Robot Based On Improved Coordinating Potential Field with Genetic Algorithm,IEEE,Conferences,"To overcome the problems during navigation of mobile robots in dynamic environment using the traditional artificial potential field (APF) method, a novel improved method called coordinating potential field (CPF) is proposed. The local potential field is constructed by using local subgoals, which obtained by updating dynamic windows. The questions of local minima, oscillation between multiple obstacles and real-time dynamic obstacle avoidance are solved. At last multi-objective parameter optimization is implemented by using adaptive genetic algorithm. Simulation results indicate that this strategy is practicable and effective.",https://ieeexplore.ieee.org/document/4389266/,2007 IEEE International Conference on Control Applications,1-3 Oct. 2007,ieeexplore
10.1109/CEC.2003.1299618,Real-time adaptation technique to real robots: an experiment with a humanoid robot,IEEE,Conferences,"We introduce a technique that allows a real robot to execute a real-time learning, in which GP and RL are integrated. In our former research, we showed the result of an experiment with a real robot ""AIBO"" and proved the technique performed better than the traditional Q-learning method. Based on the proposed technique, we can acquire the common programs using a GP, applicable to various types of robots. We execute reinforcement learning with the acquired program in a real robot. In this way, the robot can adapt to its own operational characteristics and learn effective actions. In this paper, we show the experimental results in which a humanoid robot ""HOAP-1"" has been evolved to perform effectively to solve the box-moving task.",https://ieeexplore.ieee.org/document/1299618/,"The 2003 Congress on Evolutionary Computation, 2003. CEC '03.",8-12 Dec. 2003,ieeexplore
10.1109/INTECH.2017.8102423,Real-time emotional state detection from facial expression on embedded devices,IEEE,Conferences,"From the last decade, researches on human facial emotion recognition disclosed that computing models built on regression modelling can produce applicable performance. However, many systems need extensive computing power to be run that prevents its wide applications such as robots and smart devices. In this proposed system, a real-time automatic facial expression system was designed, implemented and tested on an embedded device such as FPGA that can be a first step for a specific facial expression recognition chip for a social robot. The system was built and simulated in MATLAB and then was built on FPGA and it can carry out real time continuously emotional state recognition at 30 fps with 47.44% accuracy. The proposed graphic user interface is able to display the participant video and two dimensional predict labels of the emotion in real time together.",https://ieeexplore.ieee.org/document/8102423/,2017 Seventh International Conference on Innovative Computing Technology (INTECH),16-18 Aug. 2017,ieeexplore
10.1109/ROMAN.1996.568870,Real-time facial interaction between human and 3D face robot agent,IEEE,Conferences,"We attempt to introduce a 3D realistic human-like animate face robot to human-robot communication modality. The face robot can recognize human facial expressions as well as produce realistic facial expressions in real time. For the animate face robot to communicate interactively, we propose a new concept of ""active human interface"", and we investigate the performance of real-time recognition of facial expressions by neutral network (NN) and the expression ability of facial messages on the face robot. We found that the NN recognition of facial expressions and face robots performance in generating facial expressions are of almost the same level as that in humans. We integrate these two component technologies for the face to produce facial expression in reaction to the recognition result of human facial expression in real time. This implies a high technological potential for the animate face robot to undertakes interactive communication with human when an artificial emotion being implemented.",https://ieeexplore.ieee.org/document/568870/,Proceedings 5th IEEE International Workshop on Robot and Human Communication. RO-MAN'96 TSUKUBA,11-14 Nov. 1996,ieeexplore
10.1109/IRIA53009.2021.9588681,Real-time gesture control UAV with a low resource framework,IEEE,Conferences,"This study showcases a low-resource framework that enables people with no technical know-how to interact with drones, it also explores the capabilities of 2D- computer vision and deep learning techniques for gesture based interface systems on a low-cost micro drone with an onboard RGB camera. This Human-Robot Interaction system processes the real-time human pose to allow a user to command the drone, i.e., by providing direction to move and execute actions. A linear PD controller and image processing techniques are implemented to track humans whilst maintaining a safe distance from the user by perceiving depth information through pose estimation. We incorporated the gesture recognition results into a drone using the Robot Operating System (ROS) and evaluated system performance indoor and outdoor. This low computation framework can be applied further to control robotic arms or mobile robots.",https://ieeexplore.ieee.org/document/9588681/,2021 International Symposium of Asian Control Association on Intelligent Robotics and Industrial Automation (IRIA),20-22 Sept. 2021,ieeexplore
10.1109/ROMAN.2016.7745248,Real-time human detection for robots using CNN with a feature-based layered pre-filter,IEEE,Conferences,"Convolutional neural networks (CNNs), in combination with big data, are increasingly being used to engineer robustness into visual classification systems including human detection. One significant challenge to using a CNN on a mobile robot, however, is the associated computational cost and detection rate of running the network. In this work, we demonstrate how fusion with a feature-based layered classifier can help. Not only does score-level fusion of a CNN with the layered classifier improve precision/recall for detecting people on a mobile robot, but using the layered system as a pre-filter can substantially reduce the computational cost of running a CNN - reducing the number of objects that need to be classified while still improving precision. The combined real-time system is implemented and evaluated on a two robots with very different GPU capabilities.",https://ieeexplore.ieee.org/document/7745248/,2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),26-31 Aug. 2016,ieeexplore
10.1109/ROBOT.1993.291973,Real-time implementation of neural network learning control of a flexible Space manipulator,IEEE,Conferences,"A neural network approach to online learning control and real-time implementation for a flexible space robot manipulator is presented. An overview of the motivation and system development of the self-mobile space modulator (SM/sup 2/) is given. The neural network learns control by updating feedforward dynamics based on feedback control input. Implementation issues associated with online training strategies are addressed and a single stochastic training scheme is presented. A recurrent neural network architecture with improved performance is proposed. Using the proposed learning scheme, the manipulator tracking error is reduced by 85% compared to that of conventional proportional-integral-derivative (PID) control. The approach possesses a high degree of generality and adaptability to various applications. It will be a valuable learning control method for robots working in unconstructed environments.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/291973/,[1993] Proceedings IEEE International Conference on Robotics and Automation,2-6 May 1993,ieeexplore
10.1109/ETS.2017.7968218,Real-time self-learning for control law adaptation in nonlinear systems using encoded check states,IEEE,Conferences,"With the wide proliferation of autonomous sense-and-control real-time systems (such as robots and self-driven cars), a key research objective is rapid recovery from the effects of anomalies and impairments arising from performance degradation of sensors and actuators and electro-mechanical subsystems due to field wear and tear. This must be achieved with minimal impact on system performance while maintaining low implementation overhead and high coverage of multi-parameter failure mechanisms. In this work, we propose a reinforcement learning framework for on-line control law adaptation in autonomous nonlinear systems assisted by system state encodings. These encodings are exploited to generate time-varying error signals whose (transient) waveforms in relation to the input stimulus, contain root-cause diagnostic information. This establishes a statistical correlation between the transient waveforms and the parameters of the optimal nonlinear controller under arbitrary multi-parameter perturbations of sensor/actuator and subsystem performances. Consequently this correlation is tapped, using pre-deployment supervised learning algorithms, to predict near-optimal controller parameter values whenever sufficiently large parameter deviations are detected (due to non-zero error signals). From these near-optimal starting conditions, an actor-critic reinforcement learning controller for nonlinear systems quickly converges to the optimal control law for the parameter-perturbed system (up to 10× faster than for systems not assisted by the diagnostic information provided by the state encoding driven error signal above). We implement the proposed methodology on two nonlinear systems demonstrating fast performance recovery in real time.",https://ieeexplore.ieee.org/document/7968218/,2017 22nd IEEE European Test Symposium (ETS),22-26 May 2017,ieeexplore
10.1109/ICSMC.2009.5346188,Real-valued Q-learning in multi-agent cooperation,IEEE,Conferences,"In this paper, we propose a Q-learning with continuous action policy and extend this algorithm to a multi-agent system. We examine this algorithm in a task that there are two robots taking action independently but connected with a straight bar. The robots must cooperate to move to the goal and avoid the obstacles in the environment. Conventional Q-learning needs a pre-defined and discrete state space but fails to identify the variances of the different situation in the same state. We introduce a stochastic recording real-valued unit to Q-learning to differentiate the actions corresponding to different state inputs but categorized to the same state. This unit can be regarded as an action evaluation module, which models and produces the expected evaluation signal and an action selection unit that generates an action with the expectation of better performance using a probability distribution function that estimates an optimal action selection policy. The results from both the simulation and experiment demonstrate better performance and applicability of the proposed learning model.",https://ieeexplore.ieee.org/document/5346188/,"2009 IEEE International Conference on Systems, Man and Cybernetics",11-14 Oct. 2009,ieeexplore
10.1109/SII.2010.5708353,Realization and analysis of giant-swing motion using Q-Learning,IEEE,Conferences,"Many research papers have reported studies on sports robots that realize giant-swing motion. However, almost all these robots were controlled using trajectory planning methods, and few robots realized giant-swing motion by learning. Consequently, in this study, we attempted to construct a humanoid robot that realizes giant-swing motion by Q-learning, a reinforcement learning technique. The significant aspect of our study is that few robotic models were constructed beforehand; the robot learns giant-swing motion only by interaction with the environment during simulations. Our implementation faced several problems such as imperfect perception of the velocity state and robot posture issues caused by using only the arm angle. However, our real robot realized giant-swing motion by averaging the Q value and by using rewards - the absolute angle of the foot angle and the angular velocity of the arm angle-in the simulated learning data; the sampling time was 250 ms. Furthermore, the feasibility of generalization of learning for realizing selective motion in the forward and backward rotational directions was investigated; it was revealed that the generalization of learning is feasible as long as it does not interfere with the robot's motions.",https://ieeexplore.ieee.org/document/5708353/,2010 IEEE/SICE International Symposium on System Integration,21-22 Dec. 2010,ieeexplore
10.1109/SMC.2019.8914044,Realizing an assembly task through virtual capture,IEEE,Conferences,"Modern manufacturing strategy requires the robotic infrastructure to be able to adapt to new products or to accomplish new tasks quickly. In order to respond to this demand, teaching a robot to realize a task by demonstration has regained popularity in recent years, especially for dual-arm or humanoid robots. One of the main issues using this method is to adapt the captured motion from the human demonstration to the robot's specific kinematics and control. In this paper we present a method where the motion and grasping adaptation is tackled during the capture. We demonstrate the validity of this method with an experiment where a humanoid robot realizes an assembly previously demonstrated by a user wearing a Head Mounted Display (HMD) performing an assembly task in a virtual environment.",https://ieeexplore.ieee.org/document/8914044/,"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)",6-9 Oct. 2019,ieeexplore
10.1109/ICARM52023.2021.9536145,Reducing the Dimension of the Configuration Space with Self Organizing Neural Networks,IEEE,Conferences,"For robotics, especially industrial applications, it is crucial to reactively plan safe motions through efficient algorithms. Planning is more powerful in the configuration space than the task space. However, for robots with many degrees of freedom, this is challenging and computationally expensive. Sophisticated techniques for motion planning such as the Wavefront algorithm are limited by the high dimensionality of the configuration space, especially for robots with many degrees of freedom. For a neural implementation of the Wavefront algorithm in the configuration space, neurons represent discrete configurations and synapses are used for path planning. In order to decrease the complexity, we reduce the search space by pruning superfluous neurons and synapses. We present different models of self-organizing neural networks for this reduction. The approach takes real-life human motion data as input and creates a representation with reduced dimension. We compare six different neural network models and adapt the Wavefront algorithm to the different structures of the reduced output spaces. The method is backed up by an extensive evaluation of the reduced spaces, including their suitability for path planning by the Wavefront algorithm.",https://ieeexplore.ieee.org/document/9536145/,2021 6th IEEE International Conference on Advanced Robotics and Mechatronics (ICARM),3-5 July 2021,ieeexplore
10.1109/ICRA.2019.8793627,Reinforcement Learning Meets Hybrid Zero Dynamics: A Case Study for RABBIT,IEEE,Conferences,"The design of feedback controllers for bipedal robots is challenging due to the hybrid nature of its dynamics and the complexity imposed by high-dimensional bipedal models. In this paper, we present a novel approach for the design of feedback controllers using Reinforcement Learning (RL) and Hybrid Zero Dynamics (HZD). Existing RL approaches for bipedal walking are inefficient as they do not consider the underlying physics, often requires substantial training, and the resulting controller may not be applicable to real robots. HZD is a powerful tool for bipedal control with local stability guarantees of the walking limit cycles. In this paper, we propose a non traditional RL structure that embeds the HZD framework into the policy learning. More specifically, we propose to use RL to find a control policy that maps from the robot's reduced order states to a set of parameters that define the desired trajectories for the robot's joints through the virtual constraints. Then, these trajectories are tracked using an adaptive PD controller. The method results in a stable and robust control policy that is able to track variable speed within a continuous interval. Robustness of the policy is evaluated by applying external forces to the torso of the robot. The proposed RL framework is implemented and demonstrated in OpenAI Gym with the MuJoCo physics engine based on the well-known RABBIT robot model.",https://ieeexplore.ieee.org/document/8793627/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/IROS45743.2020.9340948,Reinforcement co-Learning of Deep and Spiking Neural Networks for Energy-Efficient Mapless Navigation with Neuromorphic Hardware,IEEE,Conferences,"Energy-efficient mapless navigation is crucial for mobile robots as they explore unknown environments with limited on-board resources. Although the recent deep rein-forcement learning (DRL) approaches have been successfully applied to navigation, their high energy consumption limits their use in several robotic applications. Here, we propose a neuromorphic approach that combines the energy-efficiency of spiking neural networks with the optimality of DRL and benchmark it in learning control policies for mapless navigation. Our hybrid framework, spiking deep deterministic policy gradient (SDDPG), consists of a spiking actor network (SAN) and a deep critic network, where the two networks were trained jointly using gradient descent. The co-learning enabled synergistic information exchange between the two networks, allowing them to overcome each other's limitations through a shared representation learning. To evaluate our approach, we deployed the trained SAN on Intel's Loihi neuromorphic processor. When validated on simulated and real-world complex environments, our method on Loihi consumed 75 times less energy per inference as compared to DDPG on Jetson TX2, and also exhibited a higher rate of successful navigation to the goal, which ranged from 1% to 4.2% and depended on the forward-propagation timestep size. These results reinforce our ongoing efforts to design brain-inspired algorithms for controlling autonomous robots with neuromorphic hardware.",https://ieeexplore.ieee.org/document/9340948/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/FUZZY.1998.687475,Reinforcement function design and bias for efficient learning in mobile robots,IEEE,Conferences,"The main paradigm in sub-symbolic learning robot domain is the reinforcement learning method. Various techniques have been developed to deal with the memorization/generalization problem, demonstrating the superior ability of artificial neural network implementations. In this paper, we address the issue of designing the reinforcement so as to optimize the exploration part of the learning. We also present and summarize works relative to the use of bias intended to achieve the effective synthesis of the desired behavior. Demonstrative experiments involving a self-organizing map implementation of the Q-learning and real mobile robots (Nomad 200 and Khepera) in a task of obstacle avoidance behavior synthesis are described.",https://ieeexplore.ieee.org/document/687475/,1998 IEEE International Conference on Fuzzy Systems Proceedings. IEEE World Congress on Computational Intelligence (Cat. No.98CH36228),4-9 May 1998,ieeexplore
10.1049/cp.2012.1301,Relevance Vector Machine based multi-feature integration for semantic place recogntion,IET,Conferences,"In order to work in realistic scenarios, it is a desirable feature for autonomous robots to extract semantic concepts from environments. In this paper, A Relevance Vector Machine (RVM) based approach is presented for the task of visual semantic place recognition. The high sparsity and Bayesian property makes this approach capable of obtaining probabilistic confidence estimation, and computationally efficient during the online prediction stage. Meanwhile, in order to take advantage of discriminative powers of different feature descriptors, a multiple kernel technique is introduced in our system, resulting in a very flexible model where arbitrary feature descriptors can be integrated smoothly. In this paper we choose three popular descriptors for our implementation. Experiments carried out on real typical office environment datasets show the feasibility and robustness of our approach.",https://ieeexplore.ieee.org/document/6492908/,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),3-5 March 2012,ieeexplore
10.1109/DIS.2006.63,Remote Programming of Multirobot Systems within the UPC-UJI Telelaboratories: System Architecture and Agent-Based Multirobot Control,IEEE,Conferences,"One of the areas that needs more improvement within the e-learning environments via Internet (in fact they suppose a very big effort to be accomplished) is allowing students to access and practice real experiments is a real laboratory, instead of using simulations in Marin, R. et al. (2003). Real laboratories allow students to acquire methods, skills and experience related to real equipment, in a manner that is very close to the way they are being used in industry. The purpose of the project is the study, development and implementation of an e-learning environment to allow undergraduate students to practice subjects related to Robotics and Artificial Intelligence. The system, which is now at a preliminary stage, will allow the remote experimentation with real robotic devices (i.e. robots, cameras, etc.). It will enable the student to learn in a collaborative manner (remote participation with other students) where it will be possible to combine the on-site activities (performed ""in-situ"" within the real lab during the normal practical sessions), with the ""online"" one (performed remotely from home via the Internet). Moreover, the remote experiments within the e-laboratory to control the real robots can be performed by both, students and even scientist. This project is under development and it is carried out jointly by two Universities (UPC and UJI). In this article we present the system architecture and the way students and researchers have been able to perform a remote programming of multirobot systems via Web",https://ieeexplore.ieee.org/document/1633445/,IEEE Workshop on Distributed Intelligent Systems: Collective Intelligence and Its Applications (DIS'06),15-16 June 2006,ieeexplore
10.1109/WCICA.2008.4593442,Research and realization on multi-robot parking mission strategy,IEEE,Conferences,"Aiming at the complexity and unknown of the modern robot-team parking mission environment, we proposed the maximal obsidional uniform distribution principle, the first nearest parking-point was enclosed by another parking-point according to uniform distribution. Based on it, we used the ldquoHungary Methodrdquo to realize the shortest total path length parking strategy. It was to form a benefit matrix which was composed of each the outside path length of the inclosing circle from robots to parking points, and then the best assignment was obtained by using ldquoHungary Methodrdquo. In this paper, itpsilas also considered two parking assignment strategies, which were shortest system executing time strategy and scope of inclosing circle seeable view strategy. The experiment result is shown that the robot-team can complete the reconnaissance parking mission efficiently. Additionally, the real-time performance is also fine.",https://ieeexplore.ieee.org/document/4593442/,2008 7th World Congress on Intelligent Control and Automation,25-27 June 2008,ieeexplore
10.1109/ACCTCS52002.2021.00055,Research on Loop Closure Detection Method Based on ResNet,IEEE,Conferences,"SLAM technology is an important basis for autonomous navigation of robots, and loop closure detection is an important part of SLAM technology. Its task is to identify whether the robot has moved to its current position, which has a good role in drawing map. In this paper, a feature extraction model is obtained by training the custom data set on the ResNet50 residual network, which can extract features with better robustness. Then, the twin-network and terny-loss function are introduced to improve the network performance through weak supervised training. Finally, the cosine similarity method is used to calculate the similarity<sup>[6]</sup>. If the similarity exceeds the threshold, it is considered that there is a loop. After the comparison experiment between the proposed method and the traditional method on the open data set, it is found that the ResNet50 network model improves the feature extraction ability and the loop detection accuracy, which proves the feasibility and application value of this paper.",https://ieeexplore.ieee.org/document/9407669/,2021 Asia-Pacific Conference on Communications Technology and Computer Science (ACCTCS),22-24 Jan. 2021,ieeexplore
10.1109/IWECAI50956.2020.00040,Research on Multi-robot Task Allocation Algorithm Based on HADTQL,IEEE,Conferences,"This paper proposes forward a Heuristically Accelerated Dynamic Team Q-learning (HADTQL) algorithm for solving multi-robot collaborative task allocation problem based on multi-agent reinforcement learning. It aims at making multiple robots collaborate to avoid all obstacles and accomplish all tasks while optimizing the path they took relatively. Firstly, the author constructs an appropriate state action space according to the specific information about the environment. Secondly, the whole learning process is divided into two stages by using dynamic exploration coefficient, which ensures the diversity of the early learning and the stability of the later learning. Thirdly, in order to help robots with reasonable action selection, the improved reward function is adopted to provide real-time rewards by utilizing the experience generated by the reinforcement learning of multiple agents. Finally, the heuristic function is introduced to guide the multi-agent reinforcement learning for the next action selection. The simulation experiment shows that the proposed algorithm can find an optimal task execution sequence and complete all tasks collaboratively with a relatively optimal path under the premise of avoiding obstacles in the environment automatically. Compared with the Team Q-learning (TQL) algorithm, this algorithm can allocate tasks reasonably with the high effectiveness and practicability.",https://ieeexplore.ieee.org/document/9221763/,2020 International Workshop on Electronic Communication and Artificial Intelligence (IWECAI),12-14 June 2020,ieeexplore
10.1109/ICMA.2019.8816557,Research on V-SLAM Methods,IEEE,Conferences,"With the development of intelligent mobile robots, SLAM, especially V-SLAM, as the basic technology of robot localization and navigation, has the advantages of strong adaptability, high precision and strong intelligence compared with the traditional localization technology. It is widely used in smart devices such as unmanned aerial vehicle, automatic driving and sweeping robots. According to different implementation methods, the visual SLAM is divided into: filter V-SLAM based on probability model, key frame BA-based V-SLAM using nonlinear optimization theory, direct tracking of V-SLAM under the assumption of luminosity invariance, space occupying V-SLAM that focuses on building three-dimensional dense maps. This paper focuses on representative systems of various V-SLAMs and gives their respective applicable scenarios and characteristics. Finally, this article forecasts the development of V-SLAM combining with multi-information fusion technology, semantic deep and learning technology.",https://ieeexplore.ieee.org/document/8816557/,2019 IEEE International Conference on Mechatronics and Automation (ICMA),4-7 Aug. 2019,ieeexplore
10.1109/ICRA40945.2020.9197386,Residual Reactive Navigation: Combining Classical and Learned Navigation Strategies For Deployment in Unknown Environments,IEEE,Conferences,"In this work we focus on improving the efficiency and generalisation of learned navigation strategies when transferred from its training environment to previously unseen ones. We present an extension of the residual reinforcement learning framework from the robotic manipulation literature and adapt it to the vast and unstructured environments that mobile robots can operate in. The concept is based on learning a residual control effect to add to a typical sub-optimal classical controller in order to close the performance gap, whilst guiding the exploration process during training for improved data efficiency. We exploit this tight coupling and propose a novel deployment strategy, switching Residual Reactive Navigation (sRRN), which yields efficient trajectories whilst probabilistically switching to a classical controller in cases of high policy uncertainty. Our approach achieves improved performance over end-to-end alternatives and can be incorporated as part of a complete navigation stack for cluttered indoor navigation tasks in the real world. The code and training environment for this project is made publicly available at https://sites.google.com/view/srrn/home.",https://ieeexplore.ieee.org/document/9197386/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ACII.2013.88,Reversal Learning Based on Somatic Markers,IEEE,Conferences,"One of the main aspects in the field of Artificial Intelligence is the creation of agents with the ability to learn like human beings do. Based on made experiences humans are able to adapt their behaviour in order to solve tasks. Another important aspect of human decision making is the ability to discard learned behaviour when the usual decisions, concerning a stimulus, lead to a bad outcome. For robots intended to be embedded in a social environment, the adaptability of behaviour is an important factor. Research of human decision behaviour shows, that emotions play a decisive role, even for learning and reversal learning. In this paper, improvements and further results of a previously presented framework for decision making based on an emotional memory are presented. The improvements include the reduction of the amount of previous knowledge that has to be implemented and an evaluation concerning reversal learning. For evaluation purposes, a typical reversal learning task, performed by real subjects, has been used. The results show that this framework allows the adaption of behaviour comparable to human subjects and offers decisive improvements, which lead to better results in reversal learning tasks without the need to directly declare a task as such one.",https://ieeexplore.ieee.org/document/6681479/,2013 Humaine Association Conference on Affective Computing and Intelligent Interaction,2-5 Sept. 2013,ieeexplore
10.1109/ICRA.2015.7139395,RoboSherlock: Unstructured information processing for robot perception,IEEE,Conferences,"We present RoboSherlock, an open source software framework for implementing perception systems for robots performing human-scale everyday manipulation tasks. In RoboSherlock, perception and interpretation of realistic scenes is formulated as an unstructured information management (UIM) problem. The application of the UIM principle supports the implementation of perception systems that can answer task-relevant queries about objects in a scene, boost object recognition performance by combining the strengths of multiple perception algorithms, support knowledge-enabled reasoning about objects and enable automatic and knowledge-driven generation of processing pipelines. We demonstrate the potential of the proposed framework by three feasibility studies of systems for real-world scene perception that have been built on top of RoboSherlock.",https://ieeexplore.ieee.org/document/7139395/,2015 IEEE International Conference on Robotics and Automation (ICRA),26-30 May 2015,ieeexplore
10.1109/ROBIO49542.2019.8961517,Robot Control in Human Environment using Deep Reinforcement Learning and Convolutional Neural Network,IEEE,Conferences,"Deep reinforcement learning (DRL) has been employed in numerous applications where complex decision-making is needed. Robot control in a human environment is an example. Such algorithm offers possibilities to achieve end-to-end training which learns from image directly. However, training on a physical robotic system under human environments using DRL is inefficient and even dangerous. Several recent works have used simulators for training models before implementing to physical robots. Although simulation provides efficiency to obtain DRL trained models, it poses challenges for the transformation from simulation to reality. Since a human environment is often cluttered, dynamic and complex, the policy trained with simulation images is not applicable for reality. Therefore, in this paper, we propose a DRL method to achieve end-to-end training in simulation, as well as to adapt to reality without any further finetune. Firstly, a Deep Deterministic Policy Gradient algorithm (DDPG) is employed to learn policy for robot control. Secondly, a pre-trained Convolutional Neural Network algorithm (CNN) is used to visually track the target in image. This technique provides the efficient and safe DRL training in simulation while offering robust application when a real robot is placed in dynamic human environment. Simulation and experiment are conducted for validation and can be seen in the attached video. The results have shown successful demonstration under various complex environments.",https://ieeexplore.ieee.org/document/8961517/,2019 IEEE International Conference on Robotics and Biomimetics (ROBIO),6-8 Dec. 2019,ieeexplore
10.1109/IROS.2010.5650949,Robot Learning by Demonstration with local Gaussian process regression,IEEE,Conferences,"In recent years there was a tremendous progress in robotic systems, and however also increased expectations: A robot should be easy to program and reliable in task execution. Learning from Demonstration (LfD) offers a very promising alternative to classical engineering approaches. LfD is a very natural way for humans to interact with robots and will be an essential part of future service robots. In this work we first review heteroscedastic Gaussian processes and show how these can be used to encode a task. We then introduce a new Gaussian process regression model that clusters the input space into smaller subsets similar to the work in [11]. In the next step we show how these approaches fit into the Learning by Demonstration framework of [2], [3]. At the end we present an experiment on a real robot arm that shows how all these approaches interact.",https://ieeexplore.ieee.org/document/5650949/,2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,18-22 Oct. 2010,ieeexplore
10.1109/ICRA48506.2021.9560893,Robot Navigation in Constrained Pedestrian Environments using Reinforcement Learning,IEEE,Conferences,"Navigating fluently around pedestrians is a necessary capability for mobile robots deployed in human environments, such as buildings and homes. While research on social navigation has focused mainly on the scalability with the number of pedestrians in open spaces, typical indoor environments present the additional challenge of constrained spaces such as corridors and doorways that limit maneuverability and influence patterns of pedestrian interaction. We present an approach based on reinforcement learning (RL) to learn policies capable of dynamic adaptation to the presence of moving pedestrians while navigating between desired locations in constrained environments. The policy network receives guidance from a motion planner that provides waypoints to follow a globally planned trajectory, whereas RL handles the local interactions. We explore a compositional principle for multi-layout training and find that policies trained in a small set of geometrically simple layouts successfully generalize to more complex unseen layouts that exhibit composition of the structural elements available during training. Going beyond walls-world like domains, we show transfer of the learned policy to unseen 3D reconstructions of two real environments. These results support the applicability of the compositional principle to navigation in real-world buildings and indicate promising usage of multi-agent simulation within reconstructed environments for tasks that involve interaction. https://ai.stanford.edu/∼cdarpino/socialnavconstrained/",https://ieeexplore.ieee.org/document/9560893/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/RCAR49640.2020.9303282,Robot Programming by Demonstration with Oral Instructions for Assembly,IEEE,Conferences,"Programming by demonstration has been seen as a feasible solution for transferring human's skills to robots without too much time and labor cost. So far, applications of programming by demonstration in industrial assembly have attracted many researchers' attention. In practice, the robot control policy must give consideration to both efficiency and precision. Furthermore, it is difficult for one policy to handle the whole assembly process. To deal with these issues, a programming by demonstration with oral instructions method is developed in this article. With oral instructions, the demonstration data are segmented into pre-assembly phase and precise assembly phase. Moreover two related assembly policies are learned independently. Task-parametrized Gaussian mixture model and dynamic movement primitive are selected to prestructure the assembly policies for the two phases respectively on accounting of their properties. Effectiveness of the proposed method has been demonstrated by an assembly experiment.",https://ieeexplore.ieee.org/document/9303282/,2020 IEEE International Conference on Real-time Computing and Robotics (RCAR),28-29 Sept. 2020,ieeexplore
10.1109/ROBOT.2000.845355,Robot improv: using drama to create believable agents,IEEE,Conferences,"Believable agents usually depend upon explicit, model-based simulations of human emotions. This work appeals instead to the sensibilities of dramatic acting to create agents that are believable. The chosen task is that of comedy improvisation as it provides a solid demonstration of the agents' believability in the context of a high-level deliberative goal. Furthermore, this work employs physical robots as the actors, employing the real-time sensor values from the robots as inputs into the acting process. This paper describes the dramatic approach to acting that we used and describes the Java-based implementation on two Nomad Scout robots. Actual, improvised scripts created by the robots are included and analyzed.",https://ieeexplore.ieee.org/document/845355/,Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065),24-28 April 2000,ieeexplore
10.1109/ICRA48506.2021.9561545,Robot in a China Shop: Using Reinforcement Learning for Location-Specific Navigation Behaviour,IEEE,Conferences,"Robots need to be able to work in multiple different environments. Even when performing similar tasks, different behaviour should be deployed to best fit the current environment. In this paper, We propose a new approach to navigation, where it is treated as a multi-task learning problem. This enables the robot to learn to behave differently in visual navigation tasks for different environments while also learning shared expertise across environments. We evaluated our approach in both simulated environments as well as real-world data. Our method allows our system to converge with a 26% reduction in training time, while also increasing accuracy.",https://ieeexplore.ieee.org/document/9561545/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/IISA.2017.8316452,Robot painting recognition based on deep belief learning,IEEE,Conferences,"In a society where the number of elderly people is increasing rapidly, autonomous wheelchair robots are expected to be widely used for mobility of elderly people. In this paper we focus on how we can utilize wheelchair robots operating in museums. In this paper, we propose a deep learning based painting recognition and its application for the wheelchair robot. We consider the case when the user clicks on the painting he/she wants to see. The robot searches, recognizes and reaches the painting using deep learning. This is in difference from the most traditional methods where the robot explains the exhibited objects in a sequential order. The deep neural network generates a series of high dimensional features for each painting resulting in a high recognition rate. In our implementation, the wheelchair robot recognizes the painting in real time using the video stream.",https://ieeexplore.ieee.org/document/8316452/,"2017 8th International Conference on Information, Intelligence, Systems & Applications (IISA)",27-30 Aug. 2017,ieeexplore
10.1109/ROBIO.2011.6181679,"Robot self-preservation and adaptation to user preferences in game play, a preliminary study",IEEE,Conferences,"It is expected that in a near future, personal robots will be endowed with enough autonomy to function and live in an individual's home. This is while commercial robots are designed with default configuration and factory settings which may often be different to an individual's operating preferences. This paper presents how reinforcement learning is applied and utilised towards personalisation of a robot's behaviour. Two-level reinforcement learning has been implemented: first level is in charge of energy autonomy, i.e. how to survive, and second level is involved in adapting robot's behaviour to user's preferences. In both levels Q-learning algorithm has been applied. First level actions have been learnt in a simulated environment and then the results have been transferred to the real robot. Second level has been fully implemented in the real robot and learnt by human-robot interaction. Finally, experiments showing the performance of the system are presented.",https://ieeexplore.ieee.org/document/6181679/,2011 IEEE International Conference on Robotics and Biomimetics,7-11 Dec. 2011,ieeexplore
10.1109/RO-MAN47096.2020.9223428,Robot-Assisted Mindfulness Practice: Analysis of Neurophysiological Responses and Affective State Change,IEEE,Conferences,"Mindfulness is the state of paying attention to the present moment on purpose and meditation is the technique to obtain this state. This study aims to develop a robot assistant that facilitates mindfulness training by means of a Brain-Computer Interface (BCI) system. To achieve this goal, we collected EEG signals from two groups of subjects engaging in a meditative vs. non-meditative human-robot interaction (HRI) and evaluated cerebral hemispheric asymmetry, which is recognized as a well-defined indicator of emotional states. Moreover, using self-reported affective states, we strived to explain asymmetry changes based on pre- and post-experiment mood alterations. We found that unlike earlier meditation studies, the fronto-central activations in alpha and theta frequency bands were not influenced by robot-guided mindfulness practice, however there was a significantly greater right-sided activity in the occipital gamma band of Meditation group, which is attributed to increased sensory awareness and open monitoring. In addition, there was a significant main effect of Time on participant's self-reported affect, indicating an improved mood after interaction with the robot regardless of the interaction type. Our results suggest that EEG responses during robot-guided meditation hold promise in real-time detection and neurofeedback of mindful state to the user, however the experienced neurophysiological changes may differ based on the meditation practice and recruited tools. This study is the first to report EEG changes during mindfulness practice with a robot. We believe that our findings driven from an ecologically valid setting, can be used in development of future BCI systems that are integrated with social robots for health applications.",https://ieeexplore.ieee.org/document/9223428/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore
10.1109/ICRA.2019.8793720,Robots Learn Social Skills: End-to-End Learning of Co-Speech Gesture Generation for Humanoid Robots,IEEE,Conferences,"Co-speech gestures enhance interaction experiences between humans as well as between humans and robots. Most existing robots use rule-based speech-gesture association, but this requires human labor and prior knowledge of experts to be implemented. We present a learning-based co-speech gesture generation that is learned from 52 h of TED talks. The proposed end-to-end neural network model consists of an encoder for speech text understanding and a decoder to generate a sequence of gestures. The model successfully produces various gestures including iconic, metaphoric, deictic, and beat gestures. In a subjective evaluation, participants reported that the gestures were human-like and matched the speech content. We also demonstrate a co-speech gesture with a NAO robot working in real time.",https://ieeexplore.ieee.org/document/8793720/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ICSMC.1997.635206,Robots as responsible agents,IEEE,Conferences,"The quest for real autonomous robots leads us to discuss the problem about the best possible control architecture enabling that important characteristic. It has been broadly accepted that a hybrid architecture, i.e. putting together both reactive and deliberative paradigms is needed to efficiently execute tasks in realistic dynamic environments. Our proposal, which is being implemented to control a Robuterll mobile platform, involves the use of a two-layers architecture. Using symbolic representation for knowledge and goals at the deliberative level and sub-symbolic neural networks for implementing the behaviors at the reactive level. One of the main problems we are now addressing is how to make these two levels to communicate, to interact without being completely dependent on each other. The multi-agent system framework gives a flexible strategy for single agents cooperation and enables a set of behaviours to have a certain degree of autonomy. This reactive layer works together with the cognitive control agent where goals and commitments are logically represented through simple modal logic.",https://ieeexplore.ieee.org/document/635206/,"1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation",12-15 Oct. 1997,ieeexplore
10.1109/ICRA.2018.8462969,Robust Human Following by Deep Bayesian Trajectory Prediction for Home Service Robots,IEEE,Conferences,"The capability of following a person is crucial in service-oriented robots for human assistance and cooperation. Though a vast variety of following systems exist, they lack robustness against dynamic changes of the environment and relocating to continue following a lost target. Here we present a robust human following system that has the extendability to commercial service robot platforms having a RGB-D camera. The proposed framework integrates deep learning methods for perception and variational Bayesian techniques for trajectory prediction. Deep learning modules enable robots to accompany a person by detecting the target, learning the target and following while avoiding collision within the dynamic home environment. The variational Bayesian techniques robustly predict the trajectory of the target by empowering the following ability of the robot when target is lost. We experimentally demonstrate the capability of the deep Bayesian trajectory prediction method on real-time usage, following abilities, collision avoidance and trajectory prediction of the system. The proposed system was deployed at the RoboCup@Home 2017 Social Standard Platform League and successfully demonstrated its robust functions and smooth person following capability resulting in winning the 1st place.",https://ieeexplore.ieee.org/document/8462969/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/AICAI.2019.8701333,Robust LQR Based ANFIS Control of x-z Inverted Pendulum,IEEE,Conferences,"Inverted pendulum is a highly unstable, nonlinear and an under-actuated system. Its dynamics resembles many real-time systems such as segways, self-balancing robots, vertical take-off and landing aircraft (VTOL) and crane lifting containers etc. These real-time applications demand the need of a robust controller. In literature, many different control strategies have been discussed to stabilize an inverted pendulum, out of them, the most robust being fuzzy control and sliding mode control. The former is difficult to tune and has a problem of rule explosion for multivariable system, whereas the latter has a problem of discontinuity and chattering. To address the issues in fuzzy controller, a novel robust linear quadratic regulator (LQR) based adaptive-network fuzzy inference system (ANFIS) controller is proposed and implemented on the stabilization of x-z inverted pendulum. The proposed controller is able to solve the problem of robustness in the LQR controller as well as the difficulty in tuning along with rule explosion in fuzzy controller. Furthermore, the designed controller is tested for different pendulum masses and the results show that as compared with conventional PID controller, the proposed controller gives better performance in achieving lesser overshoot and settling time along with better robustness properties.",https://ieeexplore.ieee.org/document/8701333/,2019 Amity International Conference on Artificial Intelligence (AICAI),4-6 Feb. 2019,ieeexplore
10.1109/IROS.2018.8594067,Robust Object Recognition Through Symbiotic Deep Learning In Mobile Robots,IEEE,Conferences,"Despite the recent success of state-of-the-art deep learning algorithms in object recognition, when these are deployed as-is on a mobile service robot, we observed that they failed to recognize many objects in real human environments. In this paper, we introduce a learning algorithm in which robots address this flaw by asking humans for help, also known as a symbiotic autonomy approach. In particular, we bootstrap YOLOv2, a state-of-the-art deep neural network and train a new neural network, that we call HHELP, using only data collected from human help. Using an RGB camera and an onboard tablet, the robot proactively seeks human input to assist it in labeling surrounding objects. Pepper, located at CMU, and Monarch Mbot, located at ISR-Lisbon, were the service robots that we used to validate the proposed approach. We conducted a study in a realistic domestic environment over the course of 20 days with 6 research participants. To improve object detection, we used the two neural networks, YOLOv2 + HHELP, in parallel. Following this methodology, the robot was able to detect twice the number of objects compared to the initial YOLOv2 neural network, and achieved a higher mAP (mean Average Precision) score. Using the learning algorithm the robot also collected data about where an object was located and to whom it belonged to by asking humans. This enabled us to explore a future use case where robots can search for a specific person's object. We view the contribution of this work to be relevant for service robots in general, in addition to Pepper, and Mbot.",https://ieeexplore.ieee.org/document/8594067/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/SII.2011.6147636,Robust localization system using online / offline hybrid learning,IEEE,Conferences,"In this paper, we propose an online motion model parameter estimation method. To achieve accurate localization, accurate estimation of motion model parameters is needed. However, the true values of motion model parameters change sequentially according to alteration of surrounding environments. Therefore the online estimation is absolutely imperative. As a typical method to estimate motion model parameters sequentially, Augmented Kalman Filter (AKF) is there. AKF achieves parameter estimation through Kalman filtering algorithm. However, AKF has serious problems to be implemented in real robot operation. These problems are the accuracy of observation and the limitation to motion control of robots. To solve these problems and achieve accurate motion model parameter estimation, proposed method introduces discriminative training. The introduction of discriminative training increases the convergence performance and stability of parameter estimation through AKF. The proposal method achieves accurate motion model parameter estimation in real robot operation. This paper describes the efficiency of our technique through simulations and an outdoor experiment.",https://ieeexplore.ieee.org/document/6147636/,2011 IEEE/SICE International Symposium on System Integration (SII),20-22 Dec. 2011,ieeexplore
10.1109/IROS.2017.8206604,Robust real-time visual tracking using dual-frame deep comparison network integrated with correlation filters,IEEE,Conferences,"In recent years, applications of visual tracking algorithms has seen a substantial growth with deployments in intelligent robots such as drones for human tracking. The algorithms for such tasks has to be efficient in terms of computational cost while been robust, accurate and fast. Object tracking algorithms based on handcrafted heuristics and constraints are widely used in uav applications. The handcrafted heuristics are mostly implemented for task-oriented applications which limits the extensions in uav's capability beyond the predefined functions. This paper considers the challenges of tracking and landing an autonomous uav on a speed high moving target, and presents a visual tracking algorithm that integrates correlation filters with deep comparison network for real-time tracking with state-of-the-art accuracy. The method first tracks the target upto translation using an online learnt model via local search technique. The changes in scale is estimated by a deep comparison network (DCN) instead of the commonly used pyramidal approach. In a single network evaluation, DCN can estimate the changes in scale as well as compensate the drifting of the tracker by refining the object region estimated by the correlation filters. The network is end-to-end trained which attempts to learn a powerful matching function for object localization using a known template. Generally, the integrated framework can be viewed as coarse-to-fine level motion estimation. Moreover, the framework can redetect the lost target without a need for a separate detector.",https://ieeexplore.ieee.org/document/8206604/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/EURCON.2007.4400663,Role Selection Mechanism for the Soccer Robot System using Petri Net,IEEE,Conferences,"Robot soccer is a challenging platform for multi-agent research, involving topics such as real-time image processing and control, robot path planning, obstacle avoidance and machine learning. The system consists of a supervisory controller, and controllers for defending and goalkeeping robots. These controllers are designed using Petri net. The robot soccer game presents an uncertain and dynamic environment for cooperating agents. Dynamic role switching and formation control are crucial for a successful game. A soccer robot has to take an appropriate decision based on environment situation. With the role of a robot fixed as goalkeeper, the supervisor, according to the game situation, assigns the role of attacking or defending to the other robots and then respective controllers control the robots. The Petri net model is implemented in Petri net toolbox under MATLAB environment.",https://ieeexplore.ieee.org/document/4400663/,"EUROCON 2007 - The International Conference on ""Computer as a Tool""",9-12 Sept. 2007,ieeexplore
10.1109/SSRR.2019.8848957,Sample Efficient Reinforcement Learning for Navigation in Complex Environments,IEEE,Conferences,"Navigation of mobile robots in unstructured, time-varying environments is challenging. It becomes even more complicated in disaster scenarios where logistical difficulties, as well as technical issues such as reactive and time-varying obstacles, exist. These scenarios are too complex for classical obstacle avoidance methods to navigate through successfully. This paper presents a sample efficient reinforcement learning algorithm for navigation in complex environments. The approach augments training data with randomly generated target location data to accelerate learning. A Q-learning approach is implemented, which is capable of quick training with limited episodes. The procedure is tested in four scenarios in Gazebo and one scenario in a real-world experiment. In the two simulation scenarios with no obstacles, the method can learn to navigate towards the target in fewer than 200 episodes. For environments with moving obstacles, training takes slightly longer, but the process is still able to learn an effective policy quickly.",https://ieeexplore.ieee.org/document/8848957/,"2019 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)",2-4 Sept. 2019,ieeexplore
10.1109/IROS40897.2019.8967834,Sample-efficient Deep Reinforcement Learning with Imaginary Rollouts for Human-Robot Interaction,IEEE,Conferences,"Deep reinforcement learning has proven to be a great success in allowing agents to learn complex tasks. However, its application to actual robots can be prohibitively expensive. Furthermore, the unpredictability of human behavior in human-robot interaction tasks can hinder convergence to a good policy. In this paper, we present an architecture that allows agents to learn models of stochastic environments and use them to accelerate learning. We descirbe how an environment model can be learned online and used to generate synthetic transitions, as well as how an agent can leverage these synthetic data to accelerate learning. We validate our approach using an experiment in which a robotic arm has to complete a task composed of a series of actions based on human gestures. Results show that our approach leads to significantly faster learning, requiring much less interaction with the environment. Furthermore, we demonstrate how learned models can be used by a robot to produce optimal plans in real world applications.",https://ieeexplore.ieee.org/document/8967834/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/RoboSoft48309.2020.9116004,Scalable sim-to-real transfer of soft robot designs,IEEE,Conferences,"The manual design of soft robots and their controllers is notoriously challenging, but it could be augmented-or, in some cases, entirely replaced-by automated design tools. Machine learning algorithms can automatically propose, test, and refine designs in simulation, and the most promising ones can then be manufactured in reality (sim2real). However, it is currently not known how to guarantee that behavior generated in simulation can be preserved when deployed in reality. Although many previous studies have devised training protocols that facilitate sim2real transfer of control polices, little to no work has investigated the simulation-reality gap as a function of morphology. This is due in part to an overall lack of tools capable of systematically designing and rapidly manufacturing robots. Here we introduce a low cost, open source, and modular soft robot design and construction kit, and use it to simulate, fabricate, and measure the simulation-reality gap of minimally complex yet soft, locomoting machines. We prove the scalability of this approach by transferring an order of magnitude more robot designs from simulation to reality than any other method. The kit and its instructions can be found here: github.com/skriegman/sim2real4designs.",https://ieeexplore.ieee.org/document/9116004/,2020 3rd IEEE International Conference on Soft Robotics (RoboSoft),15 May-15 July 2020,ieeexplore
10.1109/ROBIO.2017.8324700,Search control in an unknown environment using shortest path calculation and Lyapunov technique,IEEE,Conferences,"Search control in an unknown space is a basic function of mobile autonomous robots. For search control, robustness against environmental change is important because environmental information is measured and updated at every moment. Robustness can be guaranteed by feedback controllers generated by global control Lyapunov functions (CLFs). To endow search control with the robustness properties of CLFs, Akiba et al. proposed search control based on a Lyapunov technique in an unknown space using a Q-learning algorithm. They showed that the robot reaches its destination with conventional control even if the destination is unknown. However, conventional control requires an offline calculation because the Q-learning algorithm has high calculation costs; hence, an online search is not achieved. Further, conventional control cannot be applied to complex environments such as those where humans live. In this research, we propose a Lyapunov based on search control in an unknown plane space. The proposed control employs Dijkstra's algorithm, and has lower calculation costs than conventional search control. Further, we successfully apply our method to mapping data in real environments via a simulation experiment.",https://ieeexplore.ieee.org/document/8324700/,2017 IEEE International Conference on Robotics and Biomimetics (ROBIO),5-8 Dec. 2017,ieeexplore
10.1109/CCIOT45285.2018.9032441,Segmental Deployment of Neural Network in Cloud Robotic System,IEEE,Conferences,"In this paper, we describe a new method for ep neural networks in the field of computer vision, which can effectively solve the difficulty of applying deep learning in the cloud robotic system. By segmenting the trained network, most of the computing tasks can be cut out and offloaded to the cloud. By effective feature extraction and compression methods, the computing power of robot and cloud can be integrated and coordinated. A method of selecting the split points of the network model and a method of data transmission and compression in the communication between robots and cloud after segmenting are given based on the characteristics of machine vision tasks, and the theoretical analysis is carried out. In the experiment, the effectiveness of all the above methods is verified by comparing the compression capability, response time and network performance of the actual network model. The experimental results show that with the use of segmental methods in cloud robotic system, the task of deep network is processed in real time, while the performance is almost guaranteed.",https://ieeexplore.ieee.org/document/9032441/,2018 IEEE 3rd International Conference on Cloud Computing and Internet of Things (CCIOT),20-21 Oct. 2018,ieeexplore
10.1109/ICRA.2019.8793744,Segmenting Unknown 3D Objects from Real Depth Images using Mask R-CNN Trained on Synthetic Data,IEEE,Conferences,"The ability to segment unknown objects in depth images has potential to enhance robot skills in grasping and object tracking. Recent computer vision research has demonstrated that Mask R-CNN can be trained to segment specific categories of objects in RGB images when massive hand-labeled datasets are available. As generating these datasets is time-consuming, we instead train with synthetic depth images. Many robots now use depth sensors, and recent results suggest training on synthetic depth data can transfer successfully to the real world. We present a method for automated dataset generation and rapidly generate a synthetic training dataset of 50,000 depth images and 320,000 object masks using simulated heaps of 3D CAD models. We train a variant of Mask R-CNN with domain randomization on the generated dataset to perform category-agnostic instance segmentation without any hand-labeled data and we evaluate the trained network, which we refer to as Synthetic Depth (SD) Mask R-CNN, on a set of real, high-resolution depth images of challenging, densely-cluttered bins containing objects with highly-varied geometry. SD Mask R-CNN outperforms point cloud clustering baselines by an absolute 15% in Average Precision and 20% in Average Recall on COCO benchmarks, and achieves performance levels similar to a Mask R-CNN trained on a massive, hand-labeled RGB dataset and fine-tuned on real images from the experimental setup. We deploy the model in an instance-specific grasping pipeline to demonstrate its usefulness in a robotics application. Code, the synthetic training dataset, and supplementary material are available at https://bit.ly/2letCuE.",https://ieeexplore.ieee.org/document/8793744/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ICRA.2018.8460655,Self-Supervised Deep Reinforcement Learning with Generalized Computation Graphs for Robot Navigation,IEEE,Conferences,"Enabling robots to autonomously navigate complex environments is essential for real-world deployment. Prior methods approach this problem by having the robot maintain an internal map of the world, and then use a localization and planning method to navigate through the internal map. However, these approaches often include a variety of assumptions, are computationally intensive, and do not learn from failures. In contrast, learning-based methods improve as the robot acts in the environment, but are difficult to deploy in the real-world due to their high sample complexity. To address the need to learn complex policies with few samples, we propose a generalized computation graph that subsumes value-based model-free methods and model-based methods, with specific instantiations interpolating between model-free and model-based. We then instantiate this graph to form a navigation model that learns from raw images and is sample efficient. Our simulated car experiments explore the design decisions of our navigation model, and show our approach outperforms single-step and <i>N</i>-step double Q-learning. We also evaluate our approach on a real-world RC car and show it can learn to navigate through a complex indoor environment with a few hours of fully autonomous, self-supervised training. Videos of the experiments and code can be found at github.com/gkahn13/gcg.",https://ieeexplore.ieee.org/document/8460655/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/ROBOT.2000.844830,Self-learning vision-guided robots for searching and grasping objects,IEEE,Conferences,"An approach to control vision-guided robots is introduced. It allows searching and grasping differently shaped objects that may be located anywhere in the robot's work space, even not visible in the initial fields of view of cameras. It eliminates the need for a calibration of the robot and of the vision system, it uses no world coordinates and no inverse perspective or kinematic transformations, and it comprises an automatic adaptation to changing parameters. The approach has been implemented on a calibration-free vision-guided manipulator with five degrees of freedom (DOF) and was evaluated in real-word experiments.",https://ieeexplore.ieee.org/document/844830/,Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065),24-28 April 2000,ieeexplore
10.1109/ROBOT.2002.1014331,Self-organized flocking with agent failure: Off-line optimization and demonstration with real robots,IEEE,Conferences,"This paper presents an investigation of flocking by teams of autonomous mobile robots using principles of Swarm Intelligence. First, we present a simple flocking task, and we describe a leaderless distributed flocking algorithm (LD) that is more conducive to implementation on embodied agents than the established algorithms used in computer animation. Next, we use an embodied simulator and reinforcement learning techniques to optimize LD performance under different conditions, showing that this method can be used not only to improve performance but also to gain insight into which algorithm components contribute most to system behavior. Finally, we demonstrate that a group of real robots executing LD with emulated sensors can successfully flock (even in the presence of individual agent failure) and that systematic characterization (and therefore optimization) of real robot flocking performance is achievable.",https://ieeexplore.ieee.org/document/1014331/,Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292),11-15 May 2002,ieeexplore
10.1109/ROMAN.2008.4600739,Semantic category acquisition in dialogue for interactive object learning,IEEE,Conferences,"An important aspect of humanoid robots in a natural environment is the ability to acquire new knowledge through learning mechanisms, which enhances an artificial system with the ability to adapt to a changing or new environment. In contrast to most learning algorithms applied in machine learning today, which mainly work with offline learning on training samples, such learning mechanisms need to be performed autonomously and through interaction with the environment or with other agents/humans. In this paper we describe a learning algorithm as a dialogue approach for learning semantic categories and object description in object learning. New objects are introduced to the robot and learning dialogues are conducted as a means of information acquisition. In dialogue, the robot can acquire semantic categories, type and properties of objects, learn new words for object descriptions and learn and association to visual identification from object recognition. In contrast to existing work, this approach combines recognition of real objects, new words learning and semantic categories in one learning dialogue. The presented approach has been implemented in a dialogue system and evaluated on the humanoid robot Armar III.",https://ieeexplore.ieee.org/document/4600739/,RO-MAN 2008 - The 17th IEEE International Symposium on Robot and Human Interactive Communication,1-3 Aug. 2008,ieeexplore
10.1109/FUZZ.2002.1006736,Sharing of exploring information using belief measure for multi robot exploration,IEEE,Conferences,"We consider the problem of sharing knowledge in multi-robot exploration. It is difficult for each robot to explore accurately because of sensor errors and dead reckoning errors. We use the belief measure as the expression of sensor values in each robot for exploring an unknown environment. Then, multiple robots share the knowledge about some targets or some obstacles of the environment considering the degree of trust for other robots. The key point of this method is that robots have not a common map, but each robot has his map for sharing exploring information. The effectiveness of our approach is demonstrated by a real experiment for the case of two mobile robots.",https://ieeexplore.ieee.org/document/1006736/,2002 IEEE World Congress on Computational Intelligence. 2002 IEEE International Conference on Fuzzy Systems. FUZZ-IEEE'02. Proceedings (Cat. No.02CH37291),12-17 May 2002,ieeexplore
10.1109/CVPR.2019.01165,Sim-Real Joint Reinforcement Transfer for 3D Indoor Navigation,IEEE,Conferences,"There has been an increasing interest in 3D indoor navigation, where a robot in an environment moves to a target according to an instruction. To deploy a robot for navigation in the physical world, lots of training data is required to learn an effective policy. It is quite labour intensive to obtain sufficient real environment data for training robots while synthetic data is much easier to construct by render-ing. Though it is promising to utilize the synthetic environments to facilitate navigation training in the real world, real environment are heterogeneous from synthetic environment in two aspects. First, the visual representation of the two environments have significant variances. Second, the houseplans of these two environments are quite different. There-fore two types of information,i.e. visual representation and policy behavior, need to be adapted in the reinforce mentmodel. The learning procedure of visual representation and that of policy behavior are presumably reciprocal. We pro-pose to jointly adapt visual representation and policy behavior to leverage the mutual impacts of environment and policy. Specifically, our method employs an adversarial feature adaptation model for visual representation transfer anda policy mimic strategy for policy behavior imitation. Experiment shows that our method outperforms the baseline by 19.47% without any additional human annotations.",https://ieeexplore.ieee.org/document/8953924/,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),15-20 June 2019,ieeexplore
10.1109/ICRAE48301.2019.9043822,Sim-to-real: Six-legged Robot Control with Deep Reinforcement Learning and Curriculum Learning,IEEE,Conferences,"Six-Iegged robots have higher stability and balance, which helps them face more complex terrain conditions, such as sand, swamp, mine and so forth. Therefore, it is necessary to study the gait planning of six-legged robot to adapt to complex terrain. In order to control six-legged robots to adapt to different terrains, we adopt the method of deep reinforcement learning (DRL) to plan the gait of six-legged robots. The main idea is training the robot through Actor-Critic network with proximal policy optimization (PPO), in which outputs are step length, step height and orientation of the robot. This is an end-to-end approach, which tries to make the robot learn by itself and finally achieve its safe arrival to the target point through complex terrains. In order to train a good model for our robots, simplified environment is adopted to accelerate the training process. We also use curriculum learning to speed up and optimize the training. Then, we verify the reliability of the method in simulation platform and finally transfer the learned model to real robot. Our experiment shows the effectiveness of deep reinforcement learning for locomotion of six-legged robots, the acceleration of the training process by means of curriculum learning, and the improvement of the training effect.",https://ieeexplore.ieee.org/document/9043822/,2019 4th International Conference on Robotics and Automation Engineering (ICRAE),22-24 Nov. 2019,ieeexplore
10.1109/RO-MAN50785.2021.9515431,Simplifying the A.I. Planning modeling for Human-Robot Collaboration,IEEE,Conferences,"For an effective deployment in manufacturing, Collaborative Robots should be capable of adapting their behavior to the state of the environment and to keep the user safe and engaged during the interaction. Artificial Intelligence (AI) enables robots to autonomously operate understanding the environment, planning their tasks and acting to achieve some given goals. However, the effective deployment of AI technologies in real industrial environments is not straightforward. There is a need for engineering tools facilitating communication and interaction between AI engineers and Domain experts. This paper proposes a novel software tool, called TENANT (Tool fostEriNg Ai plaNning in roboTics) whose aim is to facilitate the use of AI planning technologies by providing domain experts like e.g., production engineers, with a graphical software framework to synthesize AI planning models abstracting from syntactic features of the underlying planning formalism.",https://ieeexplore.ieee.org/document/9515431/,2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN),8-12 Aug. 2021,ieeexplore
10.1109/IJCNN.2000.859462,"Simulating the evolution of 2D pattern recognition on the CAM-Brain Machine, an evolvable hardware tool for building a 75 million neuron artificial brain",IEEE,Conferences,"This paper presents some simulation results of the evolution of 2D visual pattern recognizers to be implemented very shortly on real hardware, namely the ""CAM-Brain Machine"" (CBM), an FPGA based piece of evolvable hardware which implements a genetic algorithm (GA) to evolve a 3D cellular automata (CA) based neural network circuit module, of approximately 1,000 neurons, in about a second, i.e. a complete run of a GA, with tens of thousands of circuit growths and performance evaluations. Up to 65,000 of these modules, each of which is evolved with a humanly specified function, can be downloaded into a large RAM space, and interconnected according to humanly specified artificial brain architectures. This RAM, containing an artificial brain with up to 75 million neurons, is then updated by the CBM at a rate of 130 billion CA cells per second. Such speeds will enable real time control of robots and hopefully the birth of a new research field that we call ""brain building"". The first such artificial brain, to be built at STARLAB in 2000 and beyond, will be used to control the behaviors of a life sized kitten robot called ""Robokitty"". This kitten robot will need 2D pattern recognizers in the visual section of its artificial brain. This paper presents simulation results on the evolvability and generalization properties of such recognizers.",https://ieeexplore.ieee.org/document/859462/,Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium,27-27 July 2000,ieeexplore
10.1109/IROS.2018.8593518,Simultaneous End-User Programming of Goals and Actions for Robotic Shelf Organization,IEEE,Conferences,"Arrangement of items on shelves in stores or warehouses is a tedious, repetitive task that can be feasible for robots to perform. The diversity of products that are available in stores and the different setups and preferences of each store makes pre-programming a robot for this task extremely challenging. Instead, our work argues for enabling end-users to customize the robot to their specific objects and setup at deployment time by programming it themselves. To that end, this paper contributes (i) a task representation for shelf arrangements based on a large dataset of grocery store shelf images, (ii) a method for inferring goal configurations from user inputs including demonstrations and direct parameter specifications, and (iii) a system implementation of the proposed approach that allows simultaneously learning task goals and actions. We evaluate our goal inference approach with ten different teaching strategies that combine alternative user inputs in different ways on the large dataset of grocery configurations, as well as with real human teachers through an online user study (N=32). We evaluate our full system implemented on a Fetch mobile manipulator on eight benchmark tasks that demonstrate end-to-end programming and execution of shelf arrangement tasks.",https://ieeexplore.ieee.org/document/8593518/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ICHR.2010.5686285,SkyAI: Highly modularized reinforcement learning library,IEEE,Conferences,"This paper introduces a software library of reinforcement learning (RL) methods, named SkyAI. SkyAI is a highly modularized RL library for real/simulated robots to learn behaviors. Our ultimate goal is to develop an artificial intelligence (AI) program with which the robots can learn to behave as their users' wish. In this paper, we describe the concepts, the requirements, and the current implementation of SkyAI. SkyAI provides two conflicting features: high execution-speed enough for real robot systems and high flexibility to design learning systems. We also demonstrate the applications to crawling tasks of both a humanoid robot in simulation and a real spider robot.",https://ieeexplore.ieee.org/document/5686285/,2010 10th IEEE-RAS International Conference on Humanoid Robots,6-8 Dec. 2010,ieeexplore
10.1109/ICCSE49874.2020.9201679,Small Agricultural Phenotype Robot and Its Navigation and Obstacle Avoidance in Parallel Walls,IEEE,Conferences,"With the development of robotics, computer vision and artificial intelligence, the study of Plant phenotyping has entered a stage of rapid growth. For robots can be used for a large-scale, automatic and sustainable phenotype collection and data processing, it has also been followed closely by more and more research institutions and international seed giants, but currently the more mature phenotype robots are huge in size and expensive in configuration. Although their accuracy are high, but the popularity are poor, so it is difficult to popularize on a large scale, which is not conducive to collect plant phenotype data in a wider space and for the more plant varieties. On the other side, the small phenotype robots have low cost, simple operation, and are more suitable for large-scale promotion. The current research on plant phenotype small robots is mainly based on small wheeled robots. The robot is equipped with visual and optical sensors for collecting plant information, and uses machine vision and various sensors to achieve the robot's movement, positioning and obstacle avoidance. This paper uses the small wheeled mobile robot to simulate the navigation and obstacle avoidance of the phenotype collecting robot in parallel walls, and its effectiveness is proved by simulation experiment and real machine test.",https://ieeexplore.ieee.org/document/9201679/,2020 15th International Conference on Computer Science & Education (ICCSE),18-22 Aug. 2020,ieeexplore
10.1109/ICRA40945.2020.9197523,SnapNav: Learning Mapless Visual Navigation with Sparse Directional Guidance and Visual Reference,IEEE,Conferences,"Learning-based visual navigation still remains a challenging problem in robotics, with two overarching issues: how to transfer the learnt policy to unseen scenarios, and how to deploy the system on real robots. In this paper, we propose a deep neural network based visual navigation system, SnapNav. Unlike map-based navigation or Visual-Teach-and-Repeat (VT&amp;R), SnapNav only receives a few snapshots of the environment combined with directional guidance to allow it to execute the navigation task. Additionally, SnapNav can be easily deployed on real robots due to a two-level hierarchy: a high level commander that provides directional commands and a low level controller that provides real-time control and obstacle avoidance. This also allows us to effectively use simulated and real data to train the different layers of the hierarchy, facilitating robust control. Extensive experimental results show that SnapNav achieves a highly autonomous navigation ability compared to baseline models, enabling sparse, map-less navigation in previously unseen environments.",https://ieeexplore.ieee.org/document/9197523/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ICRA.2018.8460968,Socially Compliant Navigation Through Raw Depth Inputs with Generative Adversarial Imitation Learning,IEEE,Conferences,"We present an approach for mobile robots to learn to navigate in dynamic environments with pedestrians via raw depth inputs, in a socially compliant manner. To achieve this, we adopt a generative adversarial imitation learning (GAIL) strategy, which improves upon a pre-trained behavior cloning policy. Our approach overcomes the disadvantages of previous methods, as they heavily depend on the full knowledge of the location and velocity information of nearby pedestrians, which not only requires specific sensors, but also the extraction of such state information from raw sensory input could consume much computation time. In this paper, our proposed GAIL-based model performs directly on raw depth inputs and plans in real-time. Experiments show that our GAIL-based approach greatly improves the safety and efficiency of the behavior of mobile robots from pure behavior cloning. The real-world deployment also shows that our method is capable of guiding autonomous vehicles to navigate in a socially compliant manner directly through raw depth inputs. In addition, we release a simulation plugin for modeling pedestrian behaviors based on the social force model.",https://ieeexplore.ieee.org/document/8460968/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/ROMAN.2002.1045681,Socially interactive robots. Why our current beliefs about them still work,IEEE,Conferences,"Discussion about the application of scientific knowledge in robotics in order to build people helpers is widespread. The issue herein addressed is philosophically poignant, that of robots that are 'people'. It is currently popular to speak about robots and the image of Man. Behind this lurks the dialogical mind and the questions on its artificial existence. Without intending to defend or refute the discourse in favour of 'recreating' Man, a lesser familiar question is brought forth: 'Given that we are capable of creating a man (constructing a robot-person), what would the consequences of this be and would we be satisfied with such technology?' Thorny topic; it questions the entire knowledge foundation upon which strong AI/Robotics is positioned. The author argues for improved monitoring of technological progress and thus favours 'soft' (weak) implementation techniques.",https://ieeexplore.ieee.org/document/1045681/,Proceedings. 11th IEEE International Workshop on Robot and Human Interactive Communication,27-27 Sept. 2002,ieeexplore
10.1109/EMSOFT.2018.8537236,Special Session: Embedded Software for Robotics: Challenges and Future Directions,IEEE,Conferences,"This paper surveys recent challenges and solutions in the design, implementation, and verification of embedded software for robotics. Emphasis is placed on mobile robots, like self-driving cars. In design, it addresses programming support for robotic systems, secure state estimation, and ROS-based monitor generation. In the implementation phase, it describes the synthesis of control software using finite precision arithmetic, real-time platforms and architectures for safety-critical robotics, efficient implementation of neural network based-controllers, and standards for computer vision applications. The issues in verification include verification of neural network-based robotic controllers, and falsification of closed-loop control systems. The paper also describes notable open-source robotic platforms. Along the way, we highlight important research problems for developing the next generation of high-performance, low-resource-usage, correct embedded software.",https://ieeexplore.ieee.org/document/8537236/,2018 International Conference on Embedded Software (EMSOFT),30 Sept.-5 Oct. 2018,ieeexplore
10.1109/IMCEC.2018.8469727,Study on Interactive Robots with Contingent Responses,IEEE,Conferences,"In the study of human-robot interaction, how to engage humans with robots and how to measure the engagement level are the important questions. Current study and technology achieved user habit adaptable intelligent system, whereas this technology relies heavily on the history of user behaviour and it always take a long time for the robots to make adjustments. However, this technology can hardly meet the demand from society anymore as people are expecting robots to adapt to user preferences in a shorter period. Due to the massive calculation for computer and complexity of system, research on robots with contingent response is still at early stage. Most relevant studies focus on one specific task that involves interacting with users and there is one project that focuses on finding elements that determine user behaviours. An experiment is designed to better investigate the factors that determine user engagement level.",https://ieeexplore.ieee.org/document/8469727/,"2018 2nd IEEE Advanced Information Management,Communicates,Electronic and Automation Control Conference (IMCEC)",25-27 May 2018,ieeexplore
10.1109/SACI.2016.7507375,Superior vision: Always on human-like vision for intelligent devices,IEEE,Conferences,"Summary form only given. We live in a world of intelligent robots, drones and mobile phones/assistants. The technologies behind these products are heralded by a new wave of deep learning applications ported on mobile devices. The robotic and vision technologies behind these products will shift the applications of electronic devices to a more superior level of intelligence that will change our world. From a hardware point of view, these devices will become a hub of learning sensors that will be able to capture and learn from their surrounding environment and their context. On top of the aforementioned deep learning technologies, the most important sense for these devices will be their vision capabilities. To make this sense as close as possible to human vision, will require advanced technology to capture, process, understand and provide analytics in real time to enable their applications make critical “educated: decisions”. “Always on” vision capabilities are envisaged as the paradigm for the next generation of mobile This Keynote will cover in this context the state of the art in the domain of vision with the latest image processing, computer vision and deep learning algorithms implemented on various low-power processing architectures.",https://ieeexplore.ieee.org/document/7507375/,2016 IEEE 11th International Symposium on Applied Computational Intelligence and Informatics (SACI),12-14 May 2016,ieeexplore
10.1109/IIAI-AAI.2014.4,Table of contents,IEEE,Conferences,The following topics are dealt with: data mining; Japanese WordNet synonym misplacement detection; social network; recommender system; sentiment analysis; workshop-based instruction; Japanese public libraries; machine learning methods; collaborative Web presentation support system; SMS4 ultracompact hardware implementation; wireless sensor networks; personalized public transportation recommendation system; adaptive user interface; NIS-Apriori algorithm; GetRNIA software tool; rough set-based rule generation; tree-Ga bump hunting; neural network model; weighted citation network analysis; sound proofing ventilation unit; touch interaction; mutually dependent Markov decision processes; ozone treatment; dynamic query optimization; big data; learner activity recognition; IoT-security approach; nutrition-based vegetable production; farm product cultivation; polynomial time mat learning; C-deterministic regular formal graph system; article abstract key expression extraction; English text comprehension; online social games; knowledge creation; knowledge utilization; online stock trading; customer behavior analysis; project-based collaborative learning; in-field mobile game-based learning activities; e-portfolio system design; self-regulated learning ontological model; mobile augmented reality based scaffolding platform; context-aware mobile Japanese conversation learning system; English writing error classification; image processing; outside-class learning; exercise-centric teaching materials; UML modeling; online historical document reading literacy; MMORPG-based learning environment; computer courses; undergraduate education; energy management system; higher education; decentralised auction-based bandwidth allocation; wireless networked control systems; resource scheduling algorithm; embedded cloud computing; Poisson distribution; Japanese seismic activity; suspect vehicle detection; 3D network traffic visualization; Web information retrieval; agent based disaster evacuation assist system; electroencephalogram; random number generator; multiagent simulations; multicore environment; CPU scheduler; multithreaded processes; reserve-price biddings; real-time traffic signal control; evolutionary computation; robot-assisted rehabilitation system; hybrid automata; Batik motif classification; color-texture-based feature extraction; backpropagation; multimedia storytelling; e-tourism service; Web mining; search engine; simulation-based e-learning mobile application software; library classification training system; WebQuest learning strategy; context-aware ubiquitous English learning; support vector machine; RFID tag ownership transfer protocol; cognitive linguistics; collaborative software engineering learning; write-access reduction method; NVM-DRAM hybrid memory; garbage collection; parallel indexing scheme; lazy-updating snoop cache protocol; distributed storage system; ITS application; software engineering education; ophthalmic multimodal imaging system; injected bug classification; secure live virtual machine migration; flash memory management; genetic programming; heterogeneous databases; time series similarity search; concurrency control program generation; incremental data migration; multidatabase system; software release time decision making; analytic hierarchy process; interactive genetic algorithm; biometric intelligence; talking robots; archaeological ruin analysis; GIS; optical wireless pedestrian-support systems; visual impairment; extreme programming; Japanese e-commerce Web sites; Chinese sign language animation; hearing-impaired people mammography inspection; geographical maps; electroculogram; XML element retrieval technique; image recognition; reinforcement learning; ECU formal verification; gasoline direct injection engines; earthquake disaster simulation; smart devices for autistic children; RoboCup rescue simulation; inductive logic programming; master-slave asynchronous evolutionary hybrid algorithm; VANET routing optimization; and Web image sharing services.,https://ieeexplore.ieee.org/document/6913248/,2014 IIAI 3rd International Conference on Advanced Applied Informatics,31 Aug.-4 Sept. 2014,ieeexplore
10.1109/IEEECONF49454.2021.9382607,Teaching System for Multimodal Object Categorization by Human-Robot Interaction in Mixed Reality,IEEE,Conferences,"As service robots are becoming essential to support aging societies, teaching them how to perform general service tasks is still a major challenge preventing their deployment in daily-life environments. In addition, developing an artificial intelligence for general service tasks requires bottom-up, unsupervised approaches to let the robots learn from their own observations and interactions with the users. However, compared to the top-down, supervised approaches such as deep learning where the extent of the learning is directly related to the amount and variety of the pre-existing data provided to the robots, and thus relatively easy to understand from a human perspective, the learning status in bottom-up approaches is by their nature much harder to appreciate and visualize. To address these issues, we propose a teaching system for multimodal object categorization by human-robot interaction through Mixed Reality (MR) visualization. In particular, our proposed system enables a user to monitor and intervene in the robot's object categorization process based on Multimodal Latent Dirichlet Allocation (MLDA) to solve unexpected results and accelerate the learning. Our contribution is twofold by 1) describing the integration of a service robot, MR interactions, and MLDA object categorization in a unified system, and 2) proposing an MR user interface to teach robots through intuitive visualization and interactions.",https://ieeexplore.ieee.org/document/9382607/,2021 IEEE/SICE International Symposium on System Integration (SII),11-14 Jan. 2021,ieeexplore
10.1109/FIE.2008.4720346,"Teaching concepts in fuzzy logic using low cost robots, PDAs, and custom software",IEEE,Conferences,"Fuzzy logic is a topic traditionally taught in artificial intelligence, machine learning, and robotics courses. Students receive the necessary mathematical and theoretical foundation in lecture format. The final learning experience may require that students create and code their own fuzzy logic application that solves a real world problem. This can be an issue when the target is a bioengineering course that introduces classical control theory, fuzzy logic, neural networks, genetic algorithms and genetic programming through the use of a low cost robot, personal digital assistant (PDA) handheld computer, and custom PDA software. In this course, the concepts and theories discussed in lecture are reinforced and extended in a corresponding laboratory through the use of wireless robots and PDAs. Fuzzy logic libraries and software modules for laptops and desktop computers are readily available, however, when it comes to handheld computers no such libraries exist. Students are able to spend more time experimenting with different fuzzy logic controllers when a custom fuzzy logic library and PDA graphical user interface are utilized. In this paper we introduce and discuss a unique low cost wireless robot, a custom fuzzy logic library, a custom fuzzy logic GUI for the PDA, and the implementation results for the fuzzy logic section in a newly created bioengineering course. Diagnostic and summative assessment in the form of a pre-test and post-test was administered for each section of the course, however, only the results for the fuzzy logic section will be provided.",https://ieeexplore.ieee.org/document/4720346/,2008 38th Annual Frontiers in Education Conference,22-25 Oct. 2008,ieeexplore
10.1109/IROS.2013.6696802,Teaching mobile robots to cooperatively navigate in populated environments,IEEE,Conferences,"Mobile service robots are envisioned to operate in environments that are populated by humans and therefore ought to navigate in a socially compliant way. Since the desired behavior of the robots highly depends on the application, we need flexible means for teaching a robot a certain navigation policy. We present an approach that allows a mobile robot to learn how to navigate in the presence of humans while it is being teleoperated in its designated environment. Our method applies feature-based maximum entropy learning to derive a navigation policy from the interactions with the humans. The resulting policy maintains a probability distribution over the trajectories of all the agents that allows the robot to cooperatively avoid collisions with humans. In particular, our method reasons about multiple homotopy classes of the agents' trajectories, i. e., on which sides the agents pass each other. We implemented our approach on a real mobile robot and demonstrate that it is able to successfully navigate in an office environment in the presence of humans relying only on on-board sensors.",https://ieeexplore.ieee.org/document/6696802/,2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,3-7 Nov. 2013,ieeexplore
10.1109/ICARSC.2015.19,Testing a Fully Autonomous Robotic Salesman in Real Scenarios,IEEE,Conferences,"Over the past decades, the number of robots deployed in museums, trade shows and exhibitions have grown steadily. This new application domain has become a key research topic in the robotics community. Therefore, new robots are designed to interact with people in these domains, using natural and intuitive channels. Visual perception and speech processing have to be considered for these robots, as they should be able to detect people in their environment, recognize their degree of accessibility and engage them in social conversations. They also need to safely navigate around dynamic, uncontrolled environments. They must be equipped with planning and learning components, that allow them to adapt to different scenarios. Finally, they must attract the attention of the people, be kind and safe to interact with. In this paper, we describe our experience with Gualzru, a salesman robot endowed with the cognitive architecture RoboCog. This architecture synchronizes all previous processes in a social robot, using a common inner representation as the core of the system. The robot has been tested in crowded, public daily life environments, where it interacted with people that had never seen it before nor had a clue about its functionality. Experimental results presented in this paper demonstrate the capabilities of the robot and its limitations in these real scenarios, and define future improvement actions.",https://ieeexplore.ieee.org/document/7101621/,2015 IEEE International Conference on Autonomous Robot Systems and Competitions,8-10 April 2015,ieeexplore
10.1109/ICISCAE48440.2019.221655,The Construction of Portrait Identification Tracking System Based on Mask R-CNN,IEEE,Conferences,"A portrait identification and tracking system with strong real-time performance, good flexibility and controllable cost is designed and implemented in the paper. Firstly, Mask R-CNN neural network is used to extract the features of the target, and the COCO dataset is used to train and establish the portrait data model. As a result, accuracy of the portrait recognition is improved. Then, a portrait tracking system including monocular camera, data acquisition module, data processing module, steering gear and control system is built. And the ""Raspberry Pi"" control method is used to control the MG955 steering gear group. Finally, the recognition and tracking of characters can be realized through wired, WIFI, Bluetooth and other ways, which improves the universality of the system. The designed system has simple structure, complete functions and can be used for automatic aiming and tracking of other objects. The modular system can also be used for unmanned aerial vehicles, robots and other platforms.",https://ieeexplore.ieee.org/document/9075573/,2019 2nd International Conference on Information Systems and Computer Aided Education (ICISCAE),28-30 Sept. 2019,ieeexplore
10.1109/ICMLC.2002.1174408,The approach of extracting features from the local environment for mobile robot,IEEE,Conferences,"A new data fusion method to extract features from the local environment for a mobile robot's navigation has been developed and implemented. This method, named the obstacle group, compresses data in a series of levels in order to reduce the quantity of data for communication between modules in a distributed single-robot system, or between all the robots and the central station in a multi-robot system. The method based on a grid map and an active window has strong adaptability and is real-time in a crowded environment. Experimental results demonstrate that the robot can successfully avoid collisions and plan its path by using this method.",https://ieeexplore.ieee.org/document/1174408/,Proceedings. International Conference on Machine Learning and Cybernetics,4-5 Nov. 2002,ieeexplore
10.1109/IVS.1994.639471,The development of a fully autonomous ground vehicle (FAGV),IEEE,Conferences,"As a first step toward the creation of a fully autonomous vehicle that operates in a real world environment, we are currently developing a prototype autonomous ground vehicle (AGV) for use in factories and other industrial/business sites based on behavior-based artificial intelligence (AI) control. This flexible and fully autonomous AGV (FAGV) is expected to operate efficiently in a normal industrial environment without any external guidance. The crucial technique employed is a non-Cartesian way of organizing software agents for the creation of a highly responsive control program. The resulting software is considerably reduced in size. Through numerous experiments using mobile robots we confirmed that these new control programs excel in functionality, efficiency, flexibility and robustness. The second key technique in the planning stage is evolutionary computation, of which genetic algorithms are a principal technique. An online, real-time evolution of the control program will be incorporated in later phases of the project to make FAGVs adaptable to any given operational environment after deployment. The first prototype FAGV has an active vision and behaviour-based control system.",https://ieeexplore.ieee.org/document/639471/,Proceedings of the Intelligent Vehicles '94 Symposium,24-26 Oct. 1994,ieeexplore
10.1109/ISIE.1998.711559,The sensor-control Jacobian as a basis for controlling calibration-free robots,IEEE,Conferences,"A method for controlling the motions of robots is presented. It is based on the newly introduced sensor-control Jacobian matrix and avoids all quantitative modeling of the robot and the sensor system. The sensor-control Jacobian contains the coefficients that relate those changes in sensor data which are caused by a motion of the robot to the robot control words that caused the robot to move and, thus, the sensor data to change. A wide variety of tasks of robots can be reduced to minimizing the differences between actual sensor data and a set of hypothetical sensor data corresponding to some desired state. All these tasks can be solved by this method. The method is especially useful for calibration-free robots, since neither quantitative models of the mechanical, kinematic and control characteristics of the robot, nor knowledge of the sensor characteristics are required. The sensor-control Jacobian may be determined automatically in real time while the robot is operating. This yields a high degree of adaptability and flexibility against unforeseen changes in the robot's parameters. Because the concept has an open structure it allows further extensions and improvements, e.g., in terms of the utilization of sensor data redundancy and machine learning. For the purpose of evaluation, the concept has been implemented on a calibration-free camera-manipulator system. Real-world grasping experiments have demonstrated the effectiveness of the method.",https://ieeexplore.ieee.org/document/711559/,IEEE International Symposium on Industrial Electronics. Proceedings. ISIE'98 (Cat. No.98TH8357),7-10 July 1998,ieeexplore
10.1109/ICRA.2011.5980333,To look or not to look: A hierarchical representation for visual planning on mobile robots,IEEE,Conferences,"Mobile robots are increasingly being used in real-world applications due to the ready availability of high fidelity sensors and the development of sophisticated information processing algorithms. However, one key challenge to the widespread deployment of mobile robots equipped with multiple sensors and processing algorithms is the ability to autonomously tailor sensing and information processing to the task at hand. This paper poses this challenge as the task of planning under uncertainty, and more specifically as an instance of probabilistic sequential decision-making. A novel hierarchy of partially observable Markov decision processes (POMDPs) is incorporated, which uses constrained-convolutional policies and automatic belief propagation to achieve efficient and reliable operation on mobile robots. All algorithms are implemented and evaluated on simulated and physical robot platforms for the task of searching for target objects in dynamic indoor environments.",https://ieeexplore.ieee.org/document/5980333/,2011 IEEE International Conference on Robotics and Automation,9-13 May 2011,ieeexplore
10.1109/CoASE.2014.6899348,Toward safe close-proximity human-robot interaction with standard industrial robots,IEEE,Conferences,"Allowing humans and robots to interact in close proximity to each other has great potential for increasing the effectiveness of human-robot teams across a large variety of domains. However, as we move toward enabling humans and robots to interact at ever-decreasing distances of separation, effective safety technologies must also be developed. While new, inherently human-safe robot designs have been established, millions of industrial robots are already deployed worldwide, which makes it attractive to develop technologies that can turn these standard industrial robots into human-safe platforms. In this work, we present a real-time safety system capable of allowing safe human-robot interaction at very low distances of separation, without the need for robot hardware modification or replacement. By leveraging known robot joint angle values and accurate measurements of human positioning in the workspace, we can achieve precise robot speed adjustment by utilizing real-time measurements of separation distance. This, in turn, allows for collision prevention in a manner comfortable for the human user.We demonstrate our system achieves latencies below 9.64 ms with 95% probability, 11.10 ms with 99% probability, and 14.08 ms with 99.99% probability, resulting in robust real-time performance.",https://ieeexplore.ieee.org/document/6899348/,2014 IEEE International Conference on Automation Science and Engineering (CASE),18-22 Aug. 2014,ieeexplore
10.1109/IROS40897.2019.8968166,Towards a Robot Architecture for Situated Lifelong Object Learning,IEEE,Conferences,"The ability to acquire knowledge incrementally and after deployment is of utmost importance for robots operating in the real world. Moreover, robots that have to operate alongside people need to be able to interact in a way that is intuitive for the users, e.g., by understanding and producing natural language. In this paper we present a first prototype of a robot architecture developed for situated lifelong object learning. The system is able to communicate with its users through natural language and perform object learning and recognition on the spot through situated interactions. In this first stage, we evaluate the system in terms of recognition accuracy which gives an indirect measure of the quality of the collected data with the proposed pipeline. Our results show that the robot can use this data for both learning and recognition with acceptable incremental performance. We also discuss limitations and steps that are necessary in order to improve performance as well as to shed some light on system usability.",https://ieeexplore.ieee.org/document/8968166/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/IROS.2015.7354134,Towards bridging the reality gap between tensegrity simulation and robotic hardware,IEEE,Conferences,"Using a new hardware implementation of our designs for tunably compliant spine-like tensegrity robots, we show that the NASA Tensegrity Robotics Toolkit can effectively generate and predict desirable locomotion strategies for these many degree of freedom systems. Tensegrity, which provides structural integrity through a tension network, shows promise as a design strategy for more compliant robots capable of interaction with rugged environments, such as a tensegrity interplanetary probe prototype surviving multi-story drops. Due to the complexity of tensegrity structures, modeling through physics simulation and machine learning improves our ability to design and evaluate new structures and their controllers in a dynamic environment. The kinematics of our simulator, the open source NASA Tensegrity Robotics Toolkit, have been previously validated within 1.3% error on position through motion capture of the six strut robot ReCTeR. This paper provides additional validation of the dynamics through the direct comparison of the simulator to forces experienced by the latest version of the Tetraspine robot. These results give us confidence in our strategy of using tensegrity to impart future robotic systems with properties similar to biological systems such as increased flexibility, power, and mobility in extreme terrains.",https://ieeexplore.ieee.org/document/7354134/,2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),28 Sept.-2 Oct. 2015,ieeexplore
10.1109/INDIN.2012.6301137,Towards hierarchical self-optimization in autonomous groups of mobile robots,IEEE,Conferences,"We present a real-world scenario for investigating and demonstrating hierarchical self-optimization in autonomous groups of mobile robots. The scenario is highly dynamic and easily expandable. It offers adequate starting points for the integration of hierarchical self-optimization. Reinforcement learning, e. g., can be introduced in order to improve the individual behavior of a single robot. Also swarm intelligence algorithms can improve the overall team behavior with respect to common goals. A reference behavior system incorporating a dynamic role assignment and hierarchical state machines was implemented and has been applied to the miniature robot BeBot. The system was evaluated by conducting several tests.",https://ieeexplore.ieee.org/document/6301137/,IEEE 10th International Conference on Industrial Informatics,25-27 July 2012,ieeexplore
10.1109/ICAR46387.2019.8981600,Towards the Usage of Synthetic Data for Marker-Less Pose Estimation of Articulated Robots in RGB Images,IEEE,Conferences,"Pose estimation is a necessity for many applications in robotics incorporating interaction between the robot and external camera-equipped devices, e.g. mobile robots or Augmented Reality devices. In the practice of monocular cameras, one mostly takes advantage of pose estimation through fiducial marker detection. We propose a novel approach for marker-less robot pose estimation through monocular cameras utilizing 2D keypoint detection and 3D keypoint determination through readings from the encoders and forward kinematics. In particular, 2D-3D point correspondences enable the pose estimation through solving the Perspective-n-Point problem for calibrated cameras. The method does not rely on any depth data or initializations. The robust 2D keypoint detection is implemented by modern Convolutional Neural Networks trained on different dataset configurations of real and synthetic data in order to quantitatively evaluate robustness, precision and data efficiency. We demonstrate that the method provides robust pose estimation for random joint poses and benchmark the performance of different (synthetic) dataset configurations. Furthermore, we compare the accuracies to marker pose estimation and give an outlook towards enhancements and realtime capability.",https://ieeexplore.ieee.org/document/8981600/,2019 19th International Conference on Advanced Robotics (ICAR),2-6 Dec. 2019,ieeexplore
10.1109/ROBIO.2017.8324512,Trajectory tracking control of a unicycle-type mobile robot with a new planning algorithm,IEEE,Conferences,"Trajectory tracking control is one of the core techniques that impacts the auto-driving performance of a mobile robot. Whereas, there lacks enough work on reference trajectory generation and controller design for practical usage. This paper considers mobile robots with unicycle vehicle model on which most of automatic guided vehicles (AGVs) in real world are built. A new trajectory planning algorithm is developed, and is applied along with a control law considering constraints of the unicycle model and limited motor capabilities. The proposed algorithm is easy to be implemented on real world AGVs, and it yields a fast, accurate and robust trajectory tracking performance. The effectiveness of the algorithm is validated by simulation tests.",https://ieeexplore.ieee.org/document/8324512/,2017 IEEE International Conference on Robotics and Biomimetics (ROBIO),5-8 Dec. 2017,ieeexplore
10.1109/ICACR51161.2020.9265509,Transfer of Inter-Robotic Inductive Classifier,IEEE,Conferences,"In multi-robot deployments, the robots need to share and integrate their own experience and perform transfer learning. Under the assumption that the robots have the same morphology and carry equivalent sensory equipment, the problem of transfer learning can be considered incremental learning. Thus, the transfer learning problem inherits the challenges of incremental learning, such as catastrophic forgetting and concept drift. In catastrophic forgetting, the model abruptly forgets the previously learned knowledge during the learning process. The concept drift arises with different experiences between consecutively sampled models. However, state-of-the-art robotic transfer learning approaches do not address both challenges at once. In this paper, we propose to use an incremental classifier on a transfer learning problem. The feasibility of the proposed approach is demonstrated in a real deployment. The robot consistently merges two classifiers learned on two different tasks into a classifier that performs well on both tasks.",https://ieeexplore.ieee.org/document/9265509/,"2020 4th International Conference on Automation, Control and Robots (ICACR)",11-13 Oct. 2020,ieeexplore
10.1109/RO-MAN46459.2019.8956420,Trust Repair in Human-Swarm Teams+,IEEE,Conferences,"Swarm robots are coordinated via simple control laws to generate emergent behaviors such as flocking, rendezvous, and deployment. Human-swarm teaming has been widely proposed for scenarios, such as human-supervised teams of unmanned aerial vehicles (UAV) for disaster rescue, UAV and ground vehicle cooperation for building security, and soldier-UAV teaming in combat. Effective cooperation requires an appropriate level of trust, between a human and a swarm. When an UAV swarm is deployed in a real-world environment, its performance is subject to real-world factors, such as system reliability and wind disturbances. Degraded performance of a robot can cause undesired swarm behaviors, decreasing human trust. This loss of trust, in turn, can trigger human intervention in UAVs' task executions, decreasing cooperation effectiveness if inappropriate. Therefore, to promote effective cooperation we propose and test a trust-repairing method (Trust-repair) restoring performance and human trust in the swarm to an appropriate level by correcting undesired swarm behaviors. Faulty swarms caused by both external and internal factors were simulated to evaluate the performance of the Trust-repair algorithm in repairing swarm performance and restoring human trust. Results show that Trust-repair is effective in restoring trust to a level intermediate between normal and faulty conditions.",https://ieeexplore.ieee.org/document/8956420/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/HRI.2019.8673298,Using Decision Support Systems for Juries in Court: Comparing the Use of Real and CG Robots,IEEE,Conferences,"In this report, we investigate the factor of social presence of a robot by using an actual robot and comparing it with a CG robot studied in our previous study. A laboratory experiment is conducted using a simple jury decision-making task, where participants play the role of a jury and make decisions regarding the length of the sentence for a particular crime. During the task, a robot with expert knowledge provides suggestions regarding the length of the sentence based on other similar cases. Results show that participants who engaged with an actual robot showed higher conformity with the suggested length of a sentence compared to the participants who engaged with a CG robot presented through a computer monitor. This study shows results that are consistent with those of previous studies in that interacting with physically aware robots is more engaging and also shows its effects on decision-making in a court.",https://ieeexplore.ieee.org/document/8673298/,2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI),11-14 March 2019,ieeexplore
10.1109/iFUZZY50310.2020.9297367,Using Interval Type-2 Recurrent Fuzzy Cerebellar Model Articulation Controller Based on Improved Differential Evolution for Cooperative Carrying Controller of Mobile Robots,IEEE,Conferences,"Mobile robot is widely utilized in various fields such as navigation control, obstacle avoidance and object carrying. For keeping away from obstacles to avoid collision and preventing object carrying from dropping down, we propose a state manager (SM) designed to assist the mobile robots so that they can switch operation between wall-following carrying (WFC) and toward goal carrying (TGC) by different external condition. In this controlling model, interval type-2 recurrent fuzzy cerebellar model articulation controller (IT2RFCMAC), embedded with a modified evolutionary optimization and dynamic grouping differential evolution (DGDE), is implemented for WFC and TGC. By adopting reinforcement learning strategy, mobile robots equip with adaptively wall-following control to make cooperative carrying control in real.",https://ieeexplore.ieee.org/document/9297367/,2020 International Conference on Fuzzy Theory and Its Applications (iFUZZY),4-7 Nov. 2020,ieeexplore
10.1109/ICEPDS.2018.8571820,Using Robot and Electric Drive in Fall Prediction,IEEE,Conferences,"The global aging phenomenon has motivated active research in human fall injuries. The fall prevention has hence become a popular topic in health informatics. An effective fall prevention paradigm could save millions of people from injury and avoid considerable casualties. Through comparison studies, detail-oriented simulations, and pragmatic field tests, an effective fall prediction method has been developed by authors. The finding is presented in this paper. Three techniques for fall prediction are discussed in this paper. A comparison technique to mimic the traditional stateless fall prediction techniques, along with an algorithm using artificial neural network, was first implemented in authors' previous paper. Then a robotic scheme was developed to simulate human fall by transplanting a proven fall prediction paradigm for humanoid robots with controlled electric drive systems to human subjects. Due to its simulation nature far from the human fall scenarios in reality, the robotic paradigm has obvious limits in real world applications. It was also used more like a reference framework for our last scheme. Eventually we built the third approach that eliminated the above limitation. The third approach is elaborated in this paper. Our test and simulation have proved its pragmatic superiority over other two approaches, along with vast majority of traditional paradigms.",https://ieeexplore.ieee.org/document/8571820/,2018 X International Conference on Electrical Power Drive Systems (ICEPDS),3-6 Oct. 2018,ieeexplore
10.1109/IROS.2018.8593799,Utility Model Re-description within a Motivational System for Cognitive Robotics,IEEE,Conferences,"This paper describes a re-descriptive approach to the efficient acquisition of ever higher level and more precise utility models within the motivational system (MotivEn) of a cognitive architecture. The approach is based on a two-step process whereby, as a first step, simple imprecise sensor correlation related utility models are obtained from the interaction traces of the robot. These utility models allow the robot to increase the frequency of achieving goals, and thus, provide lots of traces that can be used to try to train precise value functions implemented as artificial neural networks. The approach is tested experimentally on a real robotic setup that involves the coordination of two robots.",https://ieeexplore.ieee.org/document/8593799/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/AERO.2015.7119180,Utilizing Artificial Intelligence to achieve a robust architecture for future robotic spacecraft,IEEE,Conferences,"This paper presents a novel failure-tolerant architecture for future robotic spacecraft. It is based on the Time and Space Partitioning (TSP) principle as well as a combination of Artificial Intelligence (AI) and traditional concepts for system failure detection, isolation and recovery (FDIR). Contrary to classic payload that is separated from the platform, robotic devices attached onto a satellite become an integral part of the spacecraft itself. Hence, the robot needs to be integrated into the overall satellite FDIR concept in order to prevent fatal damage upon hardware or software failure. In addition, complex dexterous manipulators as required for onorbit servicing (OOS) tasks may reach unexpected failure states, where classic FDIR methods reach the edge of their capabilities with respect to successfully detecting and resolving them. Combining, and partly replacing traditional methods with flexible AI approaches aims to yield a control environment that features increased robustness, safety and reliability for space robots. The developed architecture is based on a modular on-board operational framework that features deterministic partition scheduling, an OS abstraction layer and a middleware for standardized inter-component and external communication. The supervisor (SUV) concept is utilized for exception and health management as well as deterministic system control and error management. In addition, a Kohonen self-organizing map (SOM) approach was implemented yielding a real-time robot sensor confidence analysis and failure detection. The SOM features nonsupervized training given a typical set of defined world states. By compiling a set of reviewable three-dimensional maps, alternative strategies in case of a failure can be found, increasing operational robustness. As demonstrator, a satellite simulator was set up featuring a client satellite that is to be captured by a servicing satellite with a 7-DoF dexterous manipulator. The avionics and robot control were integrated on an embedded, space-qualified Airbus e.Cube on-board computer. The experiments showed that the integration of SOM for robot failure detection positively complemented the capabilities of traditional FDIR methods.",https://ieeexplore.ieee.org/document/7119180/,2015 IEEE Aerospace Conference,7-14 March 2015,ieeexplore
10.1109/SAMI.2016.7422985,Vehicle navigation by fuzzy cognitive maps using sonar and RFID technologies,IEEE,Conferences,"Emerging concept of the so-called intelligent space (IS) offers means for use of mobile autonomous devices like vehicles or robots in a very broad area without necessity for these devices to own all necessary sensors. From this reason also new navigation methods are developing, which utilize IS means, with the aim to offer maybe not so accurate but first of all cheep and reliable solutions for a wide variety of devices. Our paper deals with the examination of possibility to interconnect sparsely deployed RFID tags with sonars. As signals produced by these two technologies are often affected by uncertainty and incompleteness we use fuzzy logic for their processing as well as control of the entire navigation process. For this purpose a special type of a fuzzy cognitive map was proposed. The paper describes real navigation experiments with a simple vehicle and evaluates them by selected criteria. Based on obtained results their explanations and conclusions for potential future research are sketched.",https://ieeexplore.ieee.org/document/7422985/,2016 IEEE 14th International Symposium on Applied Machine Intelligence and Informatics (SAMI),21-23 Jan. 2016,ieeexplore
10.1109/IROS45743.2020.9341569,Velocity Regulation of 3D Bipedal Walking Robots with Uncertain Dynamics Through Adaptive Neural Network Controller,IEEE,Conferences,"This paper presents a neural-network based adaptive feedback control structure to regulate the velocity of 3D bipedal robots under dynamics uncertainties. Existing Hybrid Zero Dynamics (HZD)-based controllers regulate velocity through the implementation of heuristic regulators that do not consider model and environmental uncertainties, which may significantly affect the tracking performance of the controllers. In this paper, we address the uncertainties in the robot dynamics from the perspective of the reduced dimensional representation of virtual constraints and propose the integration of an adaptive neural network-based controller to regulate the robot velocity in the presence of model parameter uncertainties. The proposed approach yields improved tracking performance under dynamics uncertainties. The shallow adaptive neural network used in this paper does not require training a priori and has the potential to be implemented on the real-time robotic controller. A comparative simulation study of a 3D Cassie robot is presented to illustrate the performance of the proposed approach under various scenarios.",https://ieeexplore.ieee.org/document/9341569/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/VR.2019.8798186,Virtual Reality and Photogrammetry for Improved Reproducibility of Human-Robot Interaction Studies,IEEE,Conferences,"Collecting data in robotics, especially human-robot interactions, traditionally requires a physical robot in a prepared environment, that presents substantial scalability challenges. First, robots provide many possible points of system failure, while the availability of human participants is limited. Second, for tasks such as language learning, it is important to create environments that provide interesting' varied use cases. Traditionally, this requires prepared physical spaces for each scenario being studied. Finally, the expense associated with acquiring robots and preparing spaces places serious limitations on the reproducible quality of experiments. We therefore propose a novel mechanism for using virtual reality to simulate robotic sensor data in a series of prepared scenarios. This allows for a reproducible dataset that other labs can recreate using commodity VR hardware. We demonstrate the effectiveness of this approach with an implementation that includes a simulated physical context, a reconstruction of a human actor, and a reconstruction of a robot. This evaluation shows that even a simple “sandbox” environment allows us to simulate robot sensor data, as well as the movement (e.g., view-port) and speech of humans interacting with the robot in a prescribed scenario.",https://ieeexplore.ieee.org/document/8798186/,2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),23-27 March 2019,ieeexplore
10.1109/IROS45743.2020.9341344,Virtual Reality for Robots,IEEE,Conferences,"This paper applies the principles of Virtual Reality (VR) to robots, rather than living organisms. A simulator, of either physical states or information states, renders outputs to custom displays that fool the robot's sensors. This enables a robot to experience a combination of real and virtual sensor inputs, combining the efficiency of simulation and the benefits of real world sensor inputs. Thus, the robot can be taken through targeted experiences that are more realistic than pure simulation, yet more feasible and controllable than pure real-world experiences. We define two distinctive methods for applying VR to robots, namely black box and white box; based on these methods we identify potential applications, such as testing and verification procedures that are better than simulation, the study of spoofing attacks and anti-spoofing techniques, and sample generation for machine learning. A general mathematical framework is presented, along with a simple experiment, detailed examples, and discussion of the implications.",https://ieeexplore.ieee.org/document/9341344/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/SMICND.2005.1558827,Virtual environment for robots interfaces design and testing,IEEE,Conferences,"This paper refers to the implementation of a virtual environment for the robot interfaces testing. This software environment is very useful because, comparing to the experiments with real robots, it allow the testing and evaluation of different types of interfaces and different working environments with diverse configurations. A very important facility of this interactive software environment is the fact that the designers of the robots sensors and interfaces are able to work in parallel to design test, optimize and realize different control devices for the robot",https://ieeexplore.ieee.org/document/1558827/,"CAS 2005 Proceedings. 2005 International Semiconductor Conference, 2005.",3-5 Oct. 2005,ieeexplore
10.1109/AQTR.2006.254650,Vision based algorithm for path planning of a mobile robot by using cellular neural networks,IEEE,Conferences,"The paper presents a new vision based algorithm for mobile robots path planning in an environment with obstacles. Cellular neural networks (CNNs) processing techniques are used here for real time motion planning to reach a fixed target. The CNN methods have been considered a solution for image processing in autonomous mobile robots guidance. The choice of CNNs for the visual processing is based on the possibility of their hardware implementation in large networks on a single VLSI chip (cellular neural networks -universal machine, CNN-UM (Roska and Chua, 1993 and Kim et al., 2002))",https://ieeexplore.ieee.org/document/4022973/,"2006 IEEE International Conference on Automation, Quality and Testing, Robotics",25-28 May 2006,ieeexplore
10.1109/ICGEC.2012.151,Vision-Based Coordinate Transformation with Back Propagation Neural Networks on Mobile Robots,IEEE,Conferences,"Target tracking is important for vision-based robots to implement tasks of grasping, assembling and avoiding obstacles. the purpose of a target tracking system is to identify a target and then to estimate the position of the target. the targets' positions are usually described by various coordinate systems for different purposes. This study focuses on the problem of coordinate transformation on mobile robots and employs the techniques of Back-Propagation Neural Networks to discover the prediction models. with such prediction models, coordinate transformation can be done with less processing time. the techniques have been implemented and integrated with a four-wheeled vision-based security robot and has been verified in real environments. the experimental results show that the proposed method is able to produce simple and precise transformation models and improves the robot's performances.",https://ieeexplore.ieee.org/document/6456866/,2012 Sixth International Conference on Genetic and Evolutionary Computing,25-28 Aug. 2012,ieeexplore
10.1109/ICRA.2019.8794123,Visual Guidance and Automatic Control for Robotic Personalized Stent Graft Manufacturing,IEEE,Conferences,"Personalized stent graft is designed to treat Abdominal Aortic Aneurysms (AAA). Due to the individual difference in arterial structures, stent graft has to be custom made for each AAA patient. Robotic platforms for autonomous personalized stent graft manufacturing have been proposed in recently which rely upon stereo vision systems for coordinating multiple robots for fabricating customized stent grafts. This paper proposes a novel hybrid vision system for real-time visual-sevoing for personalized stent-graft manufacturing. To coordinate the robotic arms, this system is based on projecting a dynamic stereo microscope coordinate system onto a static wide angle view stereo webcam coordinate system. The multiple stereo camera configuration enables accurate localization of the needle in 3D during the sewing process. The scale-invariant feature transform (SIFT) method and color filtering are implemented for stereo matching and feature identifications for object localization. To maintain the clear view of the sewing process, a visual-servoing system is developed for guiding the stereo microscopes for tracking the needle movements. The deep deterministic policy gradient (DDPG) reinforcement learning algorithm is developed for real-time intelligent robotic control. Experimental results have shown that the robotic arm can learn to reach the desired targets autonomously.",https://ieeexplore.ieee.org/document/8794123/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/IECON.2019.8926916,Visual Subterranean Junction Recognition for MAVs based on Convolutional Neural Networks,IEEE,Conferences,"This article proposes a novel visual framework for detecting tunnel crossings/junctions in underground mine areas towards the autonomous navigation of Micro Aerial Vehicles (MAVs). Usually mine environments have complex geometries, including multiple crossings with different tunnels that challenge the autonomous planning of aerial robots. Towards the envisioned scenario of autonomous or semi-autonomous deployment of MAVs with limited Line-of-Sight in subterranean environments, the proposed module acknowledges the existence of junctions by providing crucial information to the autonomy and planning layers of the aerial vehicle. The capability for a junction detection is necessary in the majority of mission scenarios, including unknown area exploration, known area inspection and robot homing missions. The proposed novel method has the ability to feed the image stream from the vehicles on-board forward facing camera in a Convolutional Neural Network (CNN) classification architecture, expressed in four categories: 1) left junction, 2) right junction, 3) left &amp; right junction, and 4) no junction in the local vicinity of the vehicle. The core contribution stems for the incorporation of AlexNet in a transfer learning scheme for detecting multiple branches in a subterranean environment. The validity of the proposed method has been validated through multiple data-sets collected from real underground environments, demonstrating the performance and merits of the proposed module.",https://ieeexplore.ieee.org/document/8926916/,IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society,14-17 Oct. 2019,ieeexplore
10.1109/IROS.1997.655065,Visual navigation in an open environment without map,IEEE,Conferences,We describe how a mobile robot controlled only by visual information can retrieve a particular goal location in an open environment. Our model does not need a precise map nor to learn all the possible positions in the environment. The system is a neural architecture inspired from neurobiological studies using the recognition of visual patterns called landmarks. The robot merges this visual information and its azimuth to build a plastic representation of its location. This representation is used to learn the best movement to reach the goal. A simple and fast online learning of a few places located near the goal allows the robot to reach the goal from anywhere in its neighborhood. The system uses only an egocentric representation of the robot environment and presents very high generalization capabilities. We describe an efficient implementation tested on our robot in two real indoor environments. We show the limitations of the model and its possible extensions to create autonomous robots only guided by visual information.,https://ieeexplore.ieee.org/document/655065/,Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS '97,11-11 Sept. 1997,ieeexplore
10.1109/CDS49703.2020.00012,Welding Seam Recognition Robots Based on Edge Computing,IEEE,Conferences,"In order to meet the requirements of the accuracy and real-time performance during the working process of underwater welding robots, a scheme of welding seam recognition robots system based on the edge computing is proposed in this paper. A number of pre-processing methods for capturing welding seam image were designed, including Thresholding, Filtering and Edge Detect. A Convolutional Neural Network(CNN) model for welding seam recognition was also created. In the experiments, the image pre-processing and CNN algorithms were integrated in and deployed to the robots, and the learning and training algorithms of the CNN were deployed to the cloud servers. The image pre-processing methods filtered the interference in underwater operations and achieved the image compression and feature extraction. The cloud servers fulfilled the training and parameter optimization of the CNN, which improved the accuracy of welding seam image recognition.",https://ieeexplore.ieee.org/document/9275963/,2020 International Conference on Computing and Data Science (CDS),1-2 Aug. 2020,ieeexplore
10.1109/ICCA.2009.5410442,Wheeled mobile robot control using virtual pheromones and neural networks,IEEE,Conferences,"This paper presents a novel approach on the implementation of the concept of ¿virtual pheromones¿ for use in controlling autonomous mobile robots. Rather than being deployed in the environment, the virtual pheromones are stored in a map of the environment maintained and updated by a ¿pheromone server¿. This map acts like a shared memory for all the agents, by means of a radio communication link between each agent and the pheromone server. No direct communication between agents is required. The pheromone server can be implemented on a regular computer, a handheld device, or an embedded controller carried by a leader robot. The technique described is equally applicable for guiding individual robot and robot swarms. The experiments, performed with mobile robot Pioneer 3-DX show that this method allows significant simplification and cost reduction of the autonomous agents. Several possible applications are discussed.",https://ieeexplore.ieee.org/document/5410442/,2009 IEEE International Conference on Control and Automation,9-11 Dec. 2009,ieeexplore
10.1109/RCAR47638.2019.9043946,libSmart: an Open-Source Tool for Simple Integration of Deep Learning into Intelligent Robotic Systems,IEEE,Conferences,"Intelligent robotic systems can be empowered by advanced deep learning techniques. Robotic operations such as object recognition are well investigated by researchers involved in machine learning. However, these solutions have often led to ad-hoc implementation in experimental settings. Less reported is systematic implementation of deep learning models in industrial robots. The lack of standard implementation platforms has impeded widespread use of deep learning modules in industrial robots. It is of great importance to have development platforms that can coordinate several deep learning modules of a complex system. In this paper, a scalable deep-learning friendly robot task organization system named libSmart is introduced. Similar to ROS, the architecture of the proposed system allows users to plug and play various devices but the proposed architecture is also highly compatible with deep learning modules. Specifically, the deployment of deep learning models is handled using a novel data graph method with distributed computing. In this way, the computationally expensive training and inferencing processes of deep learning models can be handled with isolated accelerating hardware to reduce the overall system latency. Successful implementation of simultaneous object recognition and pose estimation by an industrial robot has been presented as a case study. The proposed system is open source for all users to build their own intelligent systems with customized deep-learning models. (https://github.com/RustIron/libSmart.git).",https://ieeexplore.ieee.org/document/9043946/,2019 IEEE International Conference on Real-time Computing and Robotics (RCAR),4-9 Aug. 2019,ieeexplore
10.1109/JIOT.2019.2917066,A 64-mW DNN-Based Visual Navigation Engine for Autonomous Nano-Drones,IEEE,Journals,"Fully miniaturized robots (e.g., drones), with artificial intelligence (AI)-based visual navigation capabilities, are extremely challenging drivers of Internet-of-Things edge intelligence capabilities. Visual navigation based on AI approaches, such as deep neural networks (DNNs) are becoming pervasive for standard-size drones, but are considered out of reach for nano-drones with a size of a few cm<sup>2</sup>. In this paper, we present the first (to the best of our knowledge) demonstration of a navigation engine for autonomous nano-drones capable of closed-loop end-to-end DNN-based visual navigation. To achieve this goal we developed a complete methodology for parallel execution of complex DNNs directly on board resource-constrained milliwatt-scale nodes. Our system is based on GAP8, a novel parallel ultralow-power computing platform, and a 27-g commercial, open-source Crazyflie 2.0 nano-quadrotor. As part of our general methodology, we discuss the software mapping techniques that enable the DroNet state-of-the-art deep convolutional neural network to be fully executed aboard within a strict 6 frame-per-second real-time constraint with no compromise in terms of flight results, while all processing is done with only 64 mW on average. Our navigation engine is flexible and can be used to span a wide performance range: at its peak performance corner, it achieves 18 frames/s while still consuming on average just 3.5% of the power envelope of the deployed nano-aircraft. To share our key findings with the embedded and robotics communities and foster further developments in autonomous nano-unmanned aerial vehicles (UAVs), we publicly release all our code, datasets, and trained networks.",https://ieeexplore.ieee.org/document/8715489/,IEEE Internet of Things Journal,Oct. 2019,ieeexplore
10.1109/TAMD.2011.2112766,A Biologically Inspired Architecture for an Autonomous and Social Robot,IEEE,Journals,"Lately, lots of effort has been put into the construction of robots able to live among humans. This fact has favored the development of personal or social robots, which are expected to behave in a natural way. This implies that these robots could meet certain requirements, for example, to be able to decide their own actions (autonomy), to be able to make deliberative plans (reasoning), or to be able to have an emotional behavior in order to facilitate human-robot interaction. In this paper, the authors present a bioinspired control architecture for an autonomous and social robot, which tries to accomplish some of these features. In order to develop this new architecture, authors have used as a base a prior hybrid control architecture (AD) that is also biologically inspired. Nevertheless, in the later, the task to be accomplished at each moment is determined by a fix sequence processed by the Main Sequencer. Therefore, the main sequencer of the architecture coordinates the previously programmed sequence of skills that must be executed. In the new architecture, the main sequencer is substituted by a decision making system based on drives, motivations, emotions, and self-learning, which decides the proper action at every moment according to robot's state. Consequently, the robot improves its autonomy since the added decision making system will determine the goal and consequently the skills to be executed. A basic version of this new architecture has been implemented on a real robotic platform. Some experiments are shown at the end of the paper.",https://ieeexplore.ieee.org/document/5711644/,IEEE Transactions on Autonomous Mental Development,Sept. 2011,ieeexplore
10.1109/TCDS.2020.2968056,A Framework of Hybrid Force/Motion Skills Learning for Robots,IEEE,Journals,"Human factors and human-centered design philosophy are highly desired in today's robotics applications such as human-robot interaction (HRI). Several studies showed that endowing robots of human-like interaction skills can not only make them more likeable but also improve their performance. In particular, skill transfer by imitation learning can increase the usability and acceptability of robots by users without computer programming skills. In fact, besides positional information, muscle stiffness of the human arm and contact force with the environment also play important roles in understanding and generating human-like manipulation behaviors for robots, e.g., in physical HRI and teleoperation. To this end, we present a novel robot learning framework based on dynamic movement primitives (DMPs), taking into consideration both the positional and contact force profiles for human-robot skills transferring. Distinguished from the conventional method involving only the motion information, the proposed framework combines two sets of DMPs, which are built to model the motion trajectory and the force variation of the robot manipulator, respectively. Thus, a hybrid force/motion control approach is taken to ensure the accurate tracking and reproduction of the desired positional and force motor skills. Meanwhile, in order to simplify the control system, a momentum-based force observer is applied to estimate the contact force instead of employing force sensors. To deploy the learned motion-force robot manipulation skills to a broader variety of tasks, the generalization of these DMP models in actual situations is also considered. Comparative experiments have been conducted using a Baxter robot to verify the effectiveness of the proposed learning framework on real-world scenarios like cleaning a table.",https://ieeexplore.ieee.org/document/8964480/,IEEE Transactions on Cognitive and Developmental Systems,March 2021,ieeexplore
10.1109/ACCESS.2021.3124386,A Multiple Pheromone Communication System for Swarm Intelligence,IEEE,Journals,"Pheromones are chemical substances essential for communication among social insects. In the application of swarm intelligence to real micro mobile robots, the deployment of a single virtual pheromone has emerged recently as a powerful real-time method for indirect communication. However, these studies usually exploit only one kind of pheromones in their task, neglecting the crucial fact that in the world of real insects, multiple pheromones play important roles in shaping stigmergic behaviors such as foraging or nest building. To explore the multiple pheromones mechanism which enable robots to solve complex collective tasks efficiently, we introduce an artificial multiple pheromone system (ColCOS<inline-formula> <tex-math notation=""LaTeX"">$\Phi $ </tex-math></inline-formula>) to support swarm intelligence research by enabling multiple robots to deploy and react to multiple pheromones simultaneously. The proposed system ColCOS<inline-formula> <tex-math notation=""LaTeX"">$\Phi $ </tex-math></inline-formula> uses optical signals to emulate different evaporating chemical substances i.e. pheromones. These emulated pheromones are represented by trails displayed on a wide LCD display screen positioned horizontally, on which multiple miniature robots can move freely. The color sensors beneath the robots can detect and identify lingering “pheromones” on the screen. Meanwhile, the release of any pheromone from each robot is enabled by monitoring its positional information over time with an overhead camera. No other communication methods apart from virtual pheromones are employed in this system. Two case studies have been carried out which have verified the feasibility and effectiveness of the proposed system in achieving complex swarm tasks as empowered by multiple pheromones. This novel platform is a timely and powerful tool for research into swarm intelligence.",https://ieeexplore.ieee.org/document/9594791/,IEEE Access,2021,ieeexplore
10.1109/TCIAIG.2012.2228483,A Neurally Controlled Computer Game Avatar With Humanlike Behavior,IEEE,Journals,"This paper describes the NeuroBot system, which uses a global workspace architecture, implemented in spiking neurons, to control an avatar within the Unreal Tournament 2004 (UT2004) computer game. This system is designed to display humanlike behavior within UT2004, which provides a good environment for comparing human and embodied AI behavior without the cost and difficulty of full humanoid robots. Using a biologically inspired approach, the architecture is loosely based on theories about the high-level control circuits in the brain, and it is the first neural implementation of a global workspace that has been embodied in a complex dynamic real-time environment. NeuroBot's humanlike behavior was tested by competing in the 2011 BotPrize competition, in which human judges play UT2004 and rate the humanness of other avatars that are controlled by a human or a bot. NeuroBot came a close second, achieving a humanness rating of 36%, while the most human human reached 67%. We also developed a humanness metric that combines a number of statistical measures of an avatar's behavior into a single number. In our experiments with this metric, NeuroBot was rated as 33% human, and the most human human achieved 73%.",https://ieeexplore.ieee.org/document/6357232/,IEEE Transactions on Computational Intelligence and AI in Games,March 2013,ieeexplore
10.1109/ACCESS.2021.3105102,A Novel Maximin-Based Multi-Objective Evolutionary Algorithm Using One-by-One Update Scheme for Multi-Robot Scheduling Optimization,IEEE,Journals,"With the continuous development of E-commerce, warehouse logistics is also facing emerging challenges, including more batches of orders and shorter order processing cycles. When more orders need to be processed simultaneously, some existing task scheduling methods may not be able to give a suitable plan, which delays order processing and reduces the efficiency of the warehouse. Therefore, the intelligent warehouse system that uses autonomous robots for automated storage and intelligent order scheduling is becoming mainstream. Based on this concept, we propose a multi-robot cooperative scheduling system in the intelligent warehouse. The aim of the multi-robot cooperative scheduling system of the intelligent storage is to drive many robots in an intelligent warehouse to perform the distributed tasks in an optimal (e.g., time-saving and energy-conserved) way. In this paper, we propose a multi-robot cooperative task scheduling model in the intelligent warehouse. For this model, we design a maximin-based multi-objective algorithm, which uses a one-by-one update scheme to select individuals. In this algorithm, two indicators are devised to discriminate the equivalent individuals with the same maximin fitness value in the environmental selection process. The results on benchmark test suite show that our algorithm is indeed a useful optimizer. Then it is applied to settle the multi-robot scheduling problem in the intelligence warehouse. Simulation experiment results demonstrate the efficiency of the proposed algorithm on the real-world scheduling problem.",https://ieeexplore.ieee.org/document/9514575/,IEEE Access,2021,ieeexplore
10.1109/OJITS.2020.3027146,A Plausibility-Based Fault Detection Method for High-Level Fusion Perception Systems,IEEE,Journals,"Trustworthy environment perception is the fundamental basis for the safe deployment of automated agents such as self-driving vehicles or intelligent robots. The problem remains that such trust is notoriously difficult to guarantee in the presence of systematic faults, e.g., non-traceable errors caused by machine learning functions. One way to tackle this issue without making rather specific assumptions about the perception process is plausibility checking. Similar to the reasoning of human intuition, the final outcome of a complex black-box procedure is verified against given expectations of an object's behavior. In this article, we apply and evaluate collaborative, sensor-generic plausibility checking as a mean to detect empirical perception faults from their statistical fingerprints. Our real use case is next-generation automated driving that uses a roadside sensor infrastructure for perception augmentation, represented here by test scenarios at a German highway and a city intersection. The plausibilization analysis is integrated naturally in the object fusion process, and helps to diagnose known and possibly yet unknown faults in distributed sensing systems.",https://ieeexplore.ieee.org/document/9207739/,IEEE Open Journal of Intelligent Transportation Systems,2020,ieeexplore
10.1109/TCYB.2019.2946090,A Robust Collision Perception Visual Neural Network With Specific Selectivity to Darker Objects,IEEE,Journals,"Building an efficient and reliable collision perception visual system is a challenging problem for future robots and autonomous vehicles. The biological visual neural networks, which have evolved over millions of years in nature and are working perfectly in the real world, could be ideal models for designing artificial vision systems. In the locust's visual pathways, a lobula giant movement detector (LGMD), that is, the LGMD2, has been identified as a looming perception neuron that responds most strongly to darker approaching objects relative to their backgrounds; similar situations which many ground vehicles and robots are often faced with. However, little has been done on modeling the LGMD2 and investigating its potential in robotics and vehicles. In this article, we build an LGMD2 visual neural network which possesses the similar collision selectivity of an LGMD2 neuron in locust via the modeling of biased-ON and -OFF pathways splitting visual signals into parallel ON/OFF channels. With stronger inhibition (bias) in the ON pathway, this model responds selectively to darker looming objects. The proposed model has been tested systematically with a range of stimuli including real-world scenarios. It has also been implemented in a micro-mobile robot and tested with real-time experiments. The experimental results have verified the effectiveness and robustness of the proposed model for detecting darker looming objects against various dynamic and cluttered backgrounds.",https://ieeexplore.ieee.org/document/8922628/,IEEE Transactions on Cybernetics,Dec. 2020,ieeexplore
10.1109/ACCESS.2020.3003991,A Software Architecture for Service Robots Manipulating Objects in Human Environments,IEEE,Journals,"This paper presents a software architecture for robots providing manipulation services autonomously in human environments. In an unstructured human environment, a service robot often needs to perform tasks even without human intervention and prior knowledge about tasks and environments. For autonomous execution of tasks, varied processes are necessary such as perceiving environments, representing knowledge, reasoning with the knowledge, and planning for task and motion. While developing each of the processes is important, integrating them into a working system for deployment is also important as a robotic system can bring tangible outcomes when it works in real world. However, such an architecture has been rarely realized in the literature owing to the difficulties of a full integration, deployment, understanding high-level goals without human interventions. In this work, we suggest a software architecture that integrates the components necessary to perform tasks by a real robot without human intervention. We show our architecture composed of deep learning based perception, symbolic reasoning, AI task planning, and geometric motion planning. We implement a deep neural network that produces information about the environment, which are then stored in a knowledge base. We implement a reasoner that processes the knowledge to use the result for task planning. We show our implementation of the symbolic task planner that generates a sequence of motion predicates. We implement an interface that computes geometric information necessary for motion planning to execute the symbolic task plans. We describe the deployment of the architecture through the result of lab tests and a public demonstration. The architecture is developed based on Robot Operating System (ROS) so compatible with any robot that is capable of object manipulation and mobile navigation running in ROS. We deploy the architecture to two different robot platforms to show the compatibility.",https://ieeexplore.ieee.org/document/9122008/,IEEE Access,2020,ieeexplore
10.1109/TASE.2020.3032075,A Virtual Mechanism Approach for Exploiting Functional Redundancy in Finishing Operations,IEEE,Journals,"We propose a new approach to programming by the demonstration of finishing operations. Such operations can be carried out by industrial robots in multiple ways because an industrial robot is typically functionally redundant with respect to a finishing task. In the proposed system, a human expert demonstrates a finishing operation, and the demonstrated motion is recorded in the Cartesian space. The robot’s kinematic model is augmented with a virtual mechanism, which is defined according to the applied finishing tool. This way, the kinematic model is expanded with additional degrees of freedom that can be exploited to compute the optimal joint space motion of the robot without altering the essential aspects of the Cartesian space task execution as demonstrated by the human expert. Finishing operations, such as polishing and grinding, occur in contact with the treated workpiece. Since information about the contact point position is needed to control the robot during the operation, we have developed a novel approach for accurate estimation of contact points using the measured forces and torques. Finally, we applied iterative learning control to refine the demonstrated operations and compensate for inaccurate calibration and different dynamics of the robot and human demonstrator. The proposed method was verified on real robots and real polishing and grinding tasks. <italic>Note to Practitioners</italic>—This work was motivated by the need for automation of finishing operations, such as polishing and grinding, on contemporary industrial robots. Existing approaches are both too complex and too time-consuming to be applied in flexible and small-scale production, which often requires the frequent deployment of new applications. Our approach is based on programming by demonstration and enables the programming of finishing operations also for users who are not specialists in robot programming. Programming by demonstration is especially useful for teaching finishing operations because it enables the transfer of expert knowledge about finishing skills to robots without providing lengthy task descriptions or manual coding. Besides the human demonstration of the desired operation, the proposed approach also requires the availability of the kinematic model for the machine tool applied to carry out the finishing operation. We provide several practical examples of grinding and polishing tools and how to integrate them into our approach. Another feature of the proposed system is that user demonstrations of finishing operations can be transferred between different combinations of robots and machine tools.",https://ieeexplore.ieee.org/document/9246671/,IEEE Transactions on Automation Science and Engineering,Oct. 2021,ieeexplore
10.1109/TSMC.2019.2912715,A Visual Leader-Following Approach With a T-D-R Framework for Quadruped Robots,IEEE,Journals,"The quadruped robot imitates the motions of four-legged animals with a superior flexibility and adaptability to complex terrains, compared with the wheeled and tracked robots. Its leader-following ability is unique to help a human to accomplish complex tasks in a more convenient way. However, long-term following is severely obstructed due to the high-frequency vibration of the quadruped robot and the unevenness of terrains. To solve this problem, a visual approach under a novel T-D-R framework is proposed. The proposed T-D-R framework is composed of a visual tracker based on correlation filter, a person detector with deep learning, and a person re-identification (re-ID) module. The result of the tracker is verified by the detector to improve tracking performance. Especially, the re-ID module is introduced to handle distractions and occlusion caused by other persons, where the convolutional correlation filter (CCF) is employed to discriminate the leader among multiple persons through recording the appearance information in the long run. By comparing the results of the tracker and the detector as well as their similarity scores with the leader identified by the re-ID module, a stable and real-time tracking of the leader can be guaranteed. Experiments reveal that our approach is effective in handling distractions, appearance changes, and illumination variations. A long-distance experiment on a quadruped robot indicates the validity of the proposed approach.",https://ieeexplore.ieee.org/document/8709995/,"IEEE Transactions on Systems, Man, and Cybernetics: Systems",April 2021,ieeexplore
10.1109/JAS.2017.7510622,A facial expression emotion recognition based human-robot interaction system,IEEE,Journals,"A facial expression emotion recognition based human-robot interaction (FEER-HRI) system is proposed, for which a four-layer system framework is designed. The FEER-HRI system enables the robots not only to recognize human emotions, but also to generate facial expression for adapting to human emotions. A facial emotion recognition method based on 2D-Gabor, uniform local binary pattern (LBP) operator, and multiclass extreme learning machine (ELM) classifier is presented, which is applied to real-time facial expression recognition for robots. Facial expressions of robots are represented by simple cartoon symbols and displayed by a LED screen equipped in the robots, which can be easily understood by human. Four scenarios, i.e., guiding, entertainment, home service and scene simulation are performed in the human-robot interaction experiment, in which smooth communication is realized by facial expression recognition of humans and facial expression generation of robots within 2 seconds. As a few prospective applications, the FEER-HRI system can be applied in home service, smart home, safe driving, and so on.",https://ieeexplore.ieee.org/document/8039024/,IEEE/CAA Journal of Automatica Sinica,2017,ieeexplore
10.1109/TMECH.2015.2396114,Adaptive Neural Network Control of a Compact Bionic Handling Arm,IEEE,Journals,"In this paper, autonomous control problem of a class of bionic continuum robots named “Compact Bionic Handling Arm” (CBHA) is addressed. These robots can reproduce biological behaviors of trunks, tentacles, or snakes. The modeling problem associated with continuum robots includes nonlinearities, structured and unstructured uncertainties, and the hyperredundancy. In addition to these problems, the CBHA comprises the hysteresis behavior of its actuators and a memory phenomenon related to its structure made of polyamide materials. These undesirable effects make it difficult to design a control system based on quantitative models of the CBHA. Thus, two subcontrollers are proposed in this paper. One, encapsulated in the other, and both implemented in real time allow controlling of the CBHA's end-effector position. The first subcontroller controls the CBHA's kinematics based on a distal supervised learning scheme. The second subcontroller controls the CBHA's kinetics based on an adaptive neural control. These subcontrollers allow a better assessment of the stability of the control architecture while ensuring the convergence of Cartesian errors. The obtained experimental results using a CBHA robot show an accurate tracking of the CBHA's end-effector position.",https://ieeexplore.ieee.org/document/7057549/,IEEE/ASME Transactions on Mechatronics,Dec. 2015,ieeexplore
10.1109/LRA.2020.2967296,Aerial Single-View Depth Completion With Image-Guided Uncertainty Estimation,IEEE,Journals,"On the pursuit of autonomous flying robots, the scientific community has been developing onboard real-time algorithms for localisation, mapping and planning. Despite recent progress, the available solutions still lack accuracy and robustness in many aspects. While mapping for autonomous cars had a substantive boost using deep-learning techniques to enhance LIDAR measurements using image-based depth completion, the large viewpoint variations experienced by aerial vehicles are still posing major challenges for learning-based mapping approaches. In this letter, we propose a depth completion and uncertainty estimation approach that better handles the challenges of aerial platforms, such as large viewpoint and depth variations, and limited computing resources. The core of our method is a novel compact network that performs both depth completion and confidence estimation using an image-guided approach. Real-time performance onboard a GPU suitable for small flying robots is achieved by sharing deep features between both tasks. Experiments demonstrate that our network outperforms the state-of-the-art in depth completion and uncertainty estimation for single-view methods on mobile GPUs. We further present a new photorealistic aerial depth completion dataset that exhibits more challenging depth completion scenarios than the established indoor and car driving datasets. The dataset includes an open-source, visual-inertial UAV simulator for photo-realistic data generation. Our results show that our network trained on this dataset can be directly deployed on real-world outdoor aerial public datasets without fine-tuning or style transfer.",https://ieeexplore.ieee.org/document/8962227/,IEEE Robotics and Automation Letters,April 2020,ieeexplore
10.1109/JIOT.2020.3004339,AirScope: Mobile Robots-Assisted Cooperative Indoor Air Quality Sensing by Distributed Deep Reinforcement Learning,IEEE,Journals,"Indoor air pollution has become a growing health risk, but it is challenging to provide low-cost air quality monitoring for the indoor environment. In this article, we present “AirScope,” a mobile sensing system that employs cooperative robots to monitor the indoor air quality. Since the wireless coverage can be incomplete in some indoor areas, AirScope allows the robots to defer uploading the data to the central server by utilizing their own data buffers. In order to guarantee the timeliness of the data in the server, AirScope aims to minimize the average data latency by properly planning the routes of the robots. Such a route planning strategy has to be implemented in a distributed way since the robots that are out of wireless coverage can only make plans on their own. In addition, the cooperation of the robots is also necessary because the aggregation of the robots in a small area increases the average data latency of the other unattended areas. To solve this distributed and cooperative routing planning problem, we propose a solution based on distributed deep Q-learning (DDQL). We evaluate the system performance by simulations and real-world experiments. The results show that AirScope is effective to reduce data latency, where the proposed DDQL is 8% better than the greedy algorithm and 24% better than the random strategy.",https://ieeexplore.ieee.org/document/9123492/,IEEE Internet of Things Journal,Sept. 2020,ieeexplore
10.1109/TASE.2020.3043636,An Ergodic Measure for Active Learning From Equilibrium,IEEE,Journals,"This article develops KL-ergodic exploration from equilibrium (KL-E<sup>3</sup>), a method for robotic systems to integrate stability into actively generating informative measurements through ergodic exploration. Ergodic exploration enables robotic systems to indirectly sample from informative spatial distributions globally, avoiding local optima, and without the need to evaluate the derivatives of the distribution against the robot dynamics. Using a hybrid systems theory, we derive a controller that allows a robot to exploit equilibrium policies (i.e., policies that solve a task) while allowing the robot to explore and generate informative data using an ergodic measure that can extend to high-dimensional states. We show that our method is able to maintain Lyapunov attractiveness with respect to the equilibrium task while actively generating data for learning tasks such, as Bayesian optimization, model learning, and off-policy reinforcement learning. In each example, we show that our proposed method is capable of generating an informative distribution of data while synthesizing smooth control signals. We illustrate these examples using simulated systems and provide simplification of our method for real-time online learning in robotic systems. <italic>Note to Practitioners</italic>—Robotic systems need to adapt to sensor measurements and learn to exploit an understanding of the world around them such that they can truly begin to experiment in the real world. Standard learning methods do not have any restrictions on how the robot can explore and learn, making the robot dynamically volatile. Those that do are often too restrictive in terms of the stability of the robot, resulting in a lack of improved learning due to poor data collection. Applying our method would allow robotic systems to be able to adapt online without the need for human intervention. We show that considering both the dynamics of the robot and the statistics of where the robot has been, we are able to naturally encode where the robot needs to explore and collect measurements for efficient learning that is dynamically safe. With our method, we are able to effectively learn while being energetically efficient compared with state-of-the-art active learning methods. Our approach accomplishes such tasks in a single execution of the robotic system, i.e., the robot does not need human intervention to reset it. Future work will consider multiagent robotic systems that actively learn and explore in a team of collaborative robots.",https://ieeexplore.ieee.org/document/9312988/,IEEE Transactions on Automation Science and Engineering,July 2021,ieeexplore
10.1109/OJCS.2020.3001839,An Instrument for Remote Kissing and Engineering Measurement of Its Communication Effects Including Modified Turing Test,IEEE,Journals,"Various communication systems have been developed to integrate the haptic channel in digital communication. Future directions of such haptic technologies are moving towards realistic virtual reality applications and human-robot social interaction. With the digitisation of touch, robots equipped with touch sensors and actuators can communicate with humans on a more emotional and intimate level, such as sharing a hug or kiss just like humans do. This paper presents the design guideline, implementation and evaluations of a novel haptic kissing machine for smart phones - the Kissenger machine. The key novelties and contributions of the paper are: (i) A novel haptic kissing device for mobile phones, which uses dynamic perpendicular force stimulation to transmit realistic sensations of kissing in order to enhance intimacy and emotional connection of digital communication; (ii) Extensive evaluations of the Kissenger machine, including a lab experiment that compares mediated kissing with Kissenger to real kissing, a unique haptic Turing test that involves the first academic study of human-machine kiss, and a field study of the effects of Kissenger on long distance relationships. The first experiment showed that mediated kissing with Kissenger elicited similar ratings for pleasure, arousal and user experience as real kissing. Experiment 2 confirmed our hypothesis that interrogators have a higher chance of winning the Imitation Game (Turing test) when Kissenger is used during the game. Results from experiment 3 showed that long relationship couples who used Kissenger for a week experienced increased relationship satisfaction and decreased perceived stress.",https://ieeexplore.ieee.org/document/9119758/,IEEE Open Journal of the Computer Society,2020,ieeexplore
10.1109/TASE.2004.840071,Artificial-intelligence approach for biomedical sample characterization using Raman spectroscopy,IEEE,Journals,"An artificial-intelligence approach is proposed to differentiate various biomedical samples via Raman spectroscopy technology to obtain accurate medical diagnosis and decision making. The complete process consists of noise filtering, fluorescence identification, optimization and elimination, spectral normalization, multivariate statistical analysis, and data clustering, as well as the final decision making. Numerous modeling, intelligent control, and system-identification schemes have been employed. By means of fuzzy control, genetic algorithms, and principal component analysis (PCA), as well as system identification, a systematic intelligent-control approach is formulated, which is capable of classifying diversified biomedical samples. Raman spectra are weak signals whose features are sensitive to a variety of noises, which have to be reduced to an acceptable level. Fuzzy logic has been known to interpret uncertainty, imprecision, and vague phenomena. Thus, a fuzzy controller is used for noise filtering. On the other hand, background fluorescence acts as a secondary intensity component within a raw Raman spectrograph, so its spectral baseline should be determined. By removing background fluorescence, intrinsic Raman spectrum can be extracted in consequence. To optimize this detrend process, genetic algorithms have been implemented for baseline-function global optimization by selecting an optimal combination of individual spectroscopic functions. Normalization is performed by standard normal variate (SNV) afterwards to compensate for scattering effects. Normalized intrinsic spectra can be used for sample differentiation, where the PCA approach distinguishes some signatures from different samples in terms of dominant principal components. Eventually, various principal components are accumulated for clustering using scatter plots. The long-term objective of this intelligent-control approach is to create a real-time technique for sample analysis, using a Raman spectrometer directly mounted at the end-effectors of medical robots, which is to enhance the robotic surgery.",https://ieeexplore.ieee.org/document/1381368/,IEEE Transactions on Automation Science and Engineering,Jan. 2005,ieeexplore
10.1109/ACCESS.2019.2958092,Automatic Elevator Button Localization Using a Combined Detecting and Tracking Framework for Multi-Story Navigation,IEEE,Journals,"Simultaneous localization and mapping (SLAM) is an important function for service robots to self-navigate modernized buildings. However, only a few existing applications allow them to automatically move between stories through elevator. Some approaches have accomplished with the aid of hardware; however, this study shows that computer vision can be a promising alternative for button localization. In this paper, we proposed a real-time multi-story SLAM system which overcomes the problem of detecting elevator buttons using a localization framework that combines tracking and detecting approaches. A two-stage deep neural network initially locates the original positions of the target buttons, and a part-based tracker follows the target buttons in real-time. A positive-negative classifier and deep learning neural network (particular for button shape detection) modify the tracker's output in every frame. To allow the robot to self-navigate, a 2D grid mapping approach was used for the localization and mapping. Then, when the robot navigates a floor, the A* algorithm generates the shortest path. In the experiment, two dynamic scenes (which include common elevator button localization challenges) were used to evaluate the efficiency of our approach, and compared it with other state-of-the-art methods. Our approach was also tested on a prototype robot system to assesses how well it can navigate a multi-story building. The results show that our method could overcome the common background challenges that occur inside an elevator, and in doing so, it enables the mobile robot to autonomously navigate a multi-story building.",https://ieeexplore.ieee.org/document/8926334/,IEEE Access,2020,ieeexplore
10.1109/ACCESS.2019.2925087,Automatic Gauge Detection via Geometric Fitting for Safety Inspection,IEEE,Journals,"For safety considerations in electrical substations, the inspection robots are recently deployed to monitor important devices and instruments with the presence of skilled technicians in the high-voltage environments. The captured images are transmitted to a data station and are usually analyzed manually. Toward automatic analysis, a common task is to detect gauges from captured images. This paper proposes a gauge detection algorithm based on the methodology of geometric fitting. We first use the Sobel filters to extract edges which usually contain the shapes of gauges. Then, we propose to use line fitting under the framework of random sample consensus (RANSAC) to remove straight lines that do not belong to gauges. Finally, the RANSAC ellipse fitting is proposed to find most fitted ellipse from the remaining edge points. The experimental results on a real-world dataset captured by the GuoZi Robotics demonstrate that our algorithm provides more accurate gauge detection results than several existing methods.",https://ieeexplore.ieee.org/document/8746263/,IEEE Access,2019,ieeexplore
10.1109/TFUZZ.2004.832532,Automatic design of fuzzy controllers for car-like autonomous robots,IEEE,Journals,"This paper describes the design and implementation of a fuzzy control system for a car-like autonomous vehicle. The problem addressed is the diagonal parking in a constrained space, a typical problem in motion control of nonholonomic robots. The architecture proposed for the fuzzy controller is a hierarchical scheme which combines seven modules working in series and in parallel. The rules of each module employ the adequate fuzzy operators for its task (making a decision or generating a smoothly varying control output), and they have been obtained from heuristic knowledge and numerical data (with geometric information) depending on the module requirements (some of them are constrained to provide paths of near-minimal lengths). The computer-aided design tools of the environment Xfuzzy 3.0 (developed by some of the authors) have been employed to automate the different design stages: 1) translation of heuristic knowledge into fuzzy rules; 2) extraction of fuzzy rules from numerical data and their tuning to give paths of near-minimal lengths; 3) offline verification of the control system behavior; and 4) its synthesis to be implemented in a true robot and be verified on line. Real experiments with the autonomous vehicle ROMEO 4R (designed and built at the Escuela Superior de Ingenieros, University of Seville, Seville, Spain) demonstrate the efficiency of the described controller and of the methodology followed in its design.",https://ieeexplore.ieee.org/document/1321074/,IEEE Transactions on Fuzzy Systems,Aug. 2004,ieeexplore
10.1109/TSMCB.2004.843270,Autonomous stair-climbing with miniature jumping robots,IEEE,Journals,"The problem of vision-guided control of miniature mobile robots is investigated. Untethered mobile robots with small physical dimensions of around 10 cm or less do not permit powerful onboard computers because of size and power constraints. These challenges have, in the past, reduced the functionality of such devices to that of a complex remote control vehicle with fancy sensors. With the help of a computationally more powerful entity such as a larger companion robot, the control loop can be closed. Using the miniature robot's video transmission or that of an observer to localize it in the world, control commands can be computed and relayed to the inept robot. The result is a system that exhibits autonomous capabilities. The framework presented here solves the problem of climbing stairs with the miniature Scout robot. The robot's unique locomotion mode, the jump, is employed to hop one step at a time. Methods for externally tracking the Scout are developed. A large number of real-world experiments are conducted and the results discussed.",https://ieeexplore.ieee.org/document/1408060/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",April 2005,ieeexplore
10.1109/TCDS.2019.2928820,BND*-DDQN: Learn to Steer Autonomously Through Deep Reinforcement Learning,IEEE,Journals,"It is vital for mobile robots to achieve safe autonomous steering in various changing environments. In this paper, a novel end-to-end network architecture is proposed for mobile robots to learn steering autonomously through deep reinforcement learning. Specifically, two sets of feature representations are first extracted from the depth inputs through two different input streams. The acquired features are then merged together to derive both linear and angular actions simultaneously. Moreover, a new action selection strategy is also introduced to achieve motion filtering by taking the consistency in angular velocity into account. Besides, in addition to the extrinsic rewards, the intrinsic bonuses are also adopted during training to improve the exploration capability. Furthermore, it is worth noting the proposed model is readily transferable from the simple virtual training environment to much more complicated real-world scenarios so that no further fine-tuning is required for real deployment. Compared to the existing methods, the proposed method demonstrates significant superiority in terms of average reward, convergence speed, success rate, and generalization capability. In addition, it exhibits outstanding performance in various cluttered real-world environments containing both static and dynamic obstacles. A video of our experiments can be found at https://youtu.be/19jrQGG1oCU.",https://ieeexplore.ieee.org/document/8764461/,IEEE Transactions on Cognitive and Developmental Systems,June 2021,ieeexplore
10.1109/LRA.2021.3111416,Binarized P-Network: Deep Reinforcement Learning of Robot Control from Raw Images on FPGA,IEEE,Journals,"This letter explores a deep reinforcement learning (DRL) approach for designing image-based control for edge robots to be implemented on Field Programmable Gate Arrays (FPGAs). Although FPGAs are more power-efficient than CPUs and GPUs, a typical DRL method cannot be applied since they are composed of many Logic Blocks (LBs) for high-speed logical operations but low-speed real-number operations. To cope with this problem, we propose a novel DRL algorithm called Binarized P-Network (BPN), which learns image-input control policies using Binarized Convolutional Neural Networks (BCNNs). To alleviate the instability of reinforcement learning caused by a BCNN with low function approximation accuracy, our BPN adopts a robust value update scheme called Conservative Value Iteration, which is tolerant of function approximation errors. We confirmed the BPN's effectiveness through applications to a visual tracking task in simulation and real-robot experiments with FPGA.",https://ieeexplore.ieee.org/document/9534708/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/70.88080,CONDOR: an architecture for controlling the Utah-MIT dexterous hand,IEEE,Journals,"The authors describe a fully implemented computational architecture (CONDOR) that controls the Utah-MIT dexterous hand and other complex robots. The architecture derives its power from the highly efficient real-time environment provided for its control processors, coupled with a development host that allows flexible program development. By mapping the memory of a dedicated group of processors into the address space of a host computer, efficient sharing of system resources between them is possible. The software is characterized by a few simple design concepts but provides the facilities out of which more powerful utilities such as a multiprocessor pseudo-terminal emulator, a transparent and fast file server, and a flexible symbolic debugger could be constructed.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/88080/,IEEE Transactions on Robotics and Automation,Oct. 1989,ieeexplore
10.1109/ACCESS.2018.2845855,Color Transfer Pulse-Coupled Neural Networks for Underwater Robotic Visual Systems,IEEE,Journals,"With rapid developments in cloud computing, artificial intelligence, and robotic systems, ever more complex tasks, such as space and ocean exploration, are being implemented by intelligent robots. Here, we propose an underwater image enhancement scheme for robotic visual systems. The proposed algorithm and its implementation enhances and outputs an image captured by an underwater robot in real time. In this scheme, pulse-coupled neural network (PCNN)-based image enhancement and color transfer algorithms are combined to enhance the underwater image. To avoid color imbalance in the underwater image and enhance details while suppressing noise, color correction is first carried out on the underwater image before converting it into the hue-saturation-intensity domain and enhancing it by PCNN. The enhanced result improves the color and contrast of the source image and enhances the details and edges of darker regions. Experiments are performed on real world data to demonstrate the effectiveness of the proposed scheme.",https://ieeexplore.ieee.org/document/8377996/,IEEE Access,2018,ieeexplore
10.1109/TEVC.2010.2058120,Compact Differential Evolution,IEEE,Journals,"This paper proposes the compact differential evolution (cDE) algorithm. cDE, like other compact evolutionary algorithms, does not process a population of solutions but its statistic description which evolves similarly to all the evolutionary algorithms. In addition, cDE employs the mutation and crossover typical of differential evolution (DE) thus reproducing its search logic. Unlike other compact evolutionary algorithms, in cDE, the survivor selection scheme of DE can be straightforwardly encoded. One important feature of the proposed cDE algorithm is the capability of efficiently performing an optimization process despite a limited memory requirement. This fact makes the cDE algorithm suitable for hardware contexts characterized by small computational power such as micro-controllers and commercial robots. In addition, due to its nature cDE uses an implicit randomization of the offspring generation which corrects and improves the DE search logic. An extensive numerical setup has been implemented in order to prove the viability of cDE and test its performance with respect to other modern compact evolutionary algorithms and state-of-the-art population-based DE algorithms. Test results show that cDE outperforms on a regular basis its corresponding population-based DE variant. Experiments have been repeated for four different mutation schemes. In addition cDE outperforms other modern compact algorithms and displays a competitive performance with respect to state-of-the-art population-based algorithms employing a DE logic. Finally, the cDE is applied to a challenging experimental case study regarding the on-line training of a nonlinear neural-network-based controller for a precise positioning system subject to changes of payload. The main peculiarity of this control application is that the control software is not implemented into a computer connected to the control system but directly on the micro-controller. Both numerical results on the test functions and experimental results on the real-world problem are very promising and allow us to think that cDE and future developments can be an efficient option for optimization in hardware environments characterized by limited memory.",https://ieeexplore.ieee.org/document/5675671/,IEEE Transactions on Evolutionary Computation,Feb. 2011,ieeexplore
10.1109/TIE.2015.2425359,Coordination of Multiple Robotic Fish With Applications to Underwater Robot Competition,IEEE,Journals,"This paper is concerned with the coordination control of multiple biomimetic robotic fish in highly dynamic aquatic environments by building a hybrid centralized system. With the aid of the results of biorobotics and control techniques, a radio-controlled multijoint robotic fish and its locomotion control are developed. To enable a closed control loop, a visual subsystem that is responsible for tracking of multiple moving objects is constructed and implemented in real time. Furthermore, a behavior-based hierarchical architecture in conjunction with fuzzy reinforcement learning is proposed to accomplish effective coordination among multiple swimming robots. Finally, experiments on 2vs2 water polo game are carried out to verify the proposed coordination control scheme. Over the past eight years, this multirobot platform has been successfully applied to international underwater robot competitions to promote innovative research and education in underwater robotics.",https://ieeexplore.ieee.org/document/7091905/,IEEE Transactions on Industrial Electronics,Feb. 2016,ieeexplore
10.1109/ACCESS.2020.3016893,Coping With Multiple Visual Motion Cues Under Extremely Constrained Computation Power of Micro Autonomous Robots,IEEE,Journals,"The perception of different visual motion cues is crucial for autonomous mobile robots to react to or interact with the dynamic visual world. It is still a great challenge for a micro mobile robot to cope with dynamic environments due to the restricted computational resources and the limited functionalities of its visual systems. In this study, we propose a compound visual neural system to automatically extract and fuse different visual motion cues in real-time using the extremely constrained computation power of micro mobile robots. The proposed visual system contains multiple bio-inspired visual motion perceptive neurons each with a unique role, for example to extract collision visual cues, darker collision cue and directional motion cues. In the embedded system, these multiple visual neurons share a similar presynaptic network to minimise the consumption of computation resources. In the postsynaptic part of the system, visual cues pass results to corresponding action neurons using lateral inhibition mechanism. The translational motion cues, which are identified by comparing pairs of directional cues, are given the highest priority, followed by the darker colliding cues and approaching cues. Systematic experiments with both virtual visual stimuli and real-world scenarios have been carried out to validate the system's functionality and reliability. The proposed methods have demonstrated that (1) with extremely limited computation power, it is still possible for a micro mobile robot to extract multiple visual motion cues robustly in a complex dynamic environment; (2) the cues extracted can be fused with a lateral inhibited postsynaptic network, thus enabling the micro robots to respond effectively with different actions, accordingly to different states, in real-time. The proposed embedded visual system has been modularised and can be easily implemented in other autonomous mobile platforms for real-time applications. The system could also be used by neurophysiologists to test new hypotheses pertaining to biological visual neural systems.",https://ieeexplore.ieee.org/document/9167216/,IEEE Access,2020,ieeexplore
10.1109/ACCESS.2020.2991441,DDL-SLAM: A Robust RGB-D SLAM in Dynamic Environments Combined With Deep Learning,IEEE,Journals,"Visual Simultaneous Localization and Mapping (VSLAM) has developed as the basic ability of robots in past few decades. There are a lot of open-sourced and impressive SLAM systems. However, the majority of the theories and approaches of SLAM systems at present are based on the static scene assumption, which is usually not practical in reality because moving objects are ubiquitous and inevitable under most circumstances. In this paper the DDL-SLAM (Dynamic Deep Learning SLAM) is proposed, a robust RGB-D SLAM system for dynamic scenarios that, based on ORB-SLAM2, adds the abilities of dynamic object segmentation and background inpainting. We are able to detect moving objects utilizing both semantic segmentation and multi-view geometry. Having a static scene map allows inpainting background of the frame which has been obscured by moving objects, therefore the localization accuracy is greatly improved in the dynamic environment. Experiment with a public RGB-D benchmark dataset, the results clarify that DDL-SLAM can significantly enhance the robustness and stability of the RGB-D SLAM system in the highly-dynamic environment.",https://ieeexplore.ieee.org/document/9082634/,IEEE Access,2020,ieeexplore
10.1109/TNNLS.2016.2545298,Embedded Streaming Deep Neural Networks Accelerator With Applications,IEEE,Journals,"Deep convolutional neural networks (DCNNs) have become a very powerful tool in visual perception. DCNNs have applications in autonomous robots, security systems, mobile phones, and automobiles, where high throughput of the feedforward evaluation phase and power efficiency are important. Because of this increased usage, many field-programmable gate array (FPGA)-based accelerators have been proposed. In this paper, we present an optimized streaming method for DCNNs' hardware accelerator on an embedded platform. The streaming method acts as a compiler, transforming a high-level representation of DCNNs into operation codes to execute applications in a hardware accelerator. The proposed method utilizes maximum computational resources available based on a novel-scheduled routing topology that combines data reuse and data concatenation. It is tested with a hardware accelerator implemented on the Xilinx Kintex-7 XC7K325T FPGA. The system fully explores weight-level and node-level parallelizations of DCNNs and achieves a peak performance of 247 G-ops while consuming less than 4 W of power. We test our system with applications on object classification and object detection in real-world scenarios. Our results indicate high-performance efficiency, outperforming all other presented platforms while running these applications.",https://ieeexplore.ieee.org/document/7450197/,IEEE Transactions on Neural Networks and Learning Systems,July 2017,ieeexplore
10.1109/TCDS.2016.2562121,Emergence of Altruistic Behavior Through the Minimization of Prediction Error,IEEE,Journals,"The emergence of altruistic behavior in infants fosters their social development and supports their involvement in our society. Altruistic tendencies, intended to benefit others with no apparent rewards, are also very useful for social robots that are designed to be used in our households. Yet, to make robots capable of learning how to help others as infants do, it is important to understand the mechanisms and motives responsible for the development of altruistic behavior. Further, understanding the mechanisms behind the early development of pro-social behavior would be a great contribution to the field of developmental psychology. To these ends, we hypothesize that infants from 14 months of age help others to minimize the differences between predicted actions and observations, that is, to minimize prediction errors. To evaluate our hypothesis, we created a computational model based on psychological studies and implemented it in real and simulated robots. Our system first acquires its own sensory-motor representation by interacting with its environment. Then, using its experience, the system recognizes and predicts others' actions and uses this prediction to estimate a prediction error. Our experiments demonstrated that our robots could spontaneously generate helping behaviors by being motivated by the minimization of prediction errors.",https://ieeexplore.ieee.org/document/7479539/,IEEE Transactions on Cognitive and Developmental Systems,Sept. 2016,ieeexplore
10.1109/TSMCA.2012.2210408,Emotional State Classification in Patient–Robot Interaction Using Wavelet Analysis and Statistics-Based Feature Selection,IEEE,Journals,"Due to a major shortage of nurses in the U.S., future healthcare service robots are expected to be used in tasks involving direct interaction with patients. Consequently, there is a need to design nursing robots with the capability to detect and respond to patient emotional states and to facilitate positive experiences in healthcare. The objective of this study was to develop a new computational algorithm for accurate patient emotional state classification in interaction with nursing robots during medical service. A simulated medicine delivery experiment was conducted at two nursing homes using a robot with different human-like features. Physiological signals, including heart rate (HR) and galvanic skin response (GSR), as well as subjective ratings of valence (happy-unhappy) and arousal (excited-bored) were collected on elderly residents. A three-stage emotional state classification algorithm was applied to these data, including: (1) physiological feature extraction; (2) statistical-based feature selection; and (3) a machine-learning model of emotional states. A pre-processed HR signal was used. GSR signals were nonstationary and noisy and were further processed using wavelet analysis. A set of wavelet coefficients, representing GSR features, was used as a basis for current emotional state classification. Arousal and valence were significantly explained by statistical features of the HR signal and GSR wavelet features. Wavelet-based de-noising of GSR signals led to an increase in the percentage of correct classifications of emotional states and clearer relationships among the physiological response and arousal and valence. The new algorithm may serve as an effective method for future service robot real-time detection of patient emotional states and behavior adaptation to promote positive healthcare experiences.",https://ieeexplore.ieee.org/document/6301777/,IEEE Transactions on Human-Machine Systems,Jan. 2013,ieeexplore
10.1109/LRA.2020.3012951,End-to-End Tactile Feedback Loop: From Soft Sensor Skin Over Deep GRU-Autoencoders to Tactile Stimulation,IEEE,Journals,"Tactile feedback is a key sensory channel that contributes to our ability to perform precise manipulations. In this regard, sensor skin provides robots with the sense of touch making them increasingly capable of dexterous object manipulation. However, in applications like teleoperation, the complex sensory input of an infinite number of different textures must be projected to the human user's skin in a meaningful manner. In addressing this issue, a deep gated recurrent unit-based autoencoder (GRU-AE) that captured the perceptual dimensions of tactile textures in latent space was deployed to implicitly understand unseen textures. The expression of unknown textures in this latent space allowed for the definition of a control law to effectively drive tactile displays and to convey tactile feedback in a psycho-physically meaningful manner. The approach was experimentally verified by evaluating the prediction performance of the GRU-AE on seen and unseen data that were gathered during active tactile exploration of objects commonly encountered in daily living. A user study on a custom-made tactile display was conducted in which real tactile perceptions in response to active tactile object exploration were compared to the emulated tactile feedback using the proposed tactile feedback loop. The results suggest that the deep GRU-AE for tactile display control offers an effective and intuitive method for efficient end-to-end tactile feedback during active tactile texture exploration.",https://ieeexplore.ieee.org/document/9152113/,IEEE Robotics and Automation Letters,Oct. 2020,ieeexplore
10.1109/ACCESS.2021.3101397,Energy-Efficient Edge-Fog-Cloud Architecture for IoT-Based Smart Agriculture Environment,IEEE,Journals,"The current agriculture systems compete to take advantage of industry advanced technologies, including the internet of things (IoT), cloud/fog/edge computing, artificial intelligence, and agricultural robots to monitor, track, analyze and process various functions and services in real-time. Additionally, these technologies can make the agricultural processes smarter and more cost-efficient by using automated systems and eliminating any human interventions, hence enhancing agricultural production to meet future expectations. Although the current agriculture systems that adopt the traditional cloud-based architecture have provided powerful computing infrastructure to distributed IoT sensors. However, the cost of energy consumption associated with transferring heterogeneous data over the multiple network tiers to process, analyze and store the sensor's information in the cloud has created a huge load on information and communication infrastructure. Besides, the energy consumed by cloud data centers has an environmental impact associated with using non-clean fuels, which usually release carbon emissions (CO<sub>2</sub>) to produce electricity. Thus, to tackle these issues, we propose a new integrated edge-fog-cloud architectural paradigm that promises to enhance the energy-efficient of smart agriculture systems and corresponding carbon emissions. This architecture allows data collection from several sensors to process and analyze the agriculture data that require real-time operation (e.g., weather temperature, soil moisture, soil acidity, irrigation, etc.) in several layers (edge, fog, and cloud). Thus, the real-time processing could be held by the edge and fog layers to reduce the load on the cloud layer, which will help to enhance the overall energy consumption and process the agriculture applications/services efficiently. Mathematical modeling is conducted using mixed-integer linear programming (MILP) for a smart agriculture environment, where the proposed architecture is implemented, and results are analyzed and compared to the traditional implementation. According to the results of thousands of agriculture sensors, the proposed architecture outperforms the traditional cloud-based architecture in terms of reducing the overall energy consumption by 36% and the carbon emissions by 43%. In addition to these achievements, the results show that our proposed architecture can reduce network traffic by up to 86%, which can reduce network congestion. Finally, we develop a heuristic algorithm to validate and mimic the presented approach, and it shows comparable results to the MILP model.",https://ieeexplore.ieee.org/document/9502114/,IEEE Access,2021,ieeexplore
10.1109/TSMCB.2010.2073702,Experimental Analysis of Mobile-Robot Teleoperation via Shared Impedance Control,IEEE,Journals,"In this paper, Internet-based teleoperation of mobile robots for obstacle avoidance is analyzed. A shared impedance-control scheme is presented, and the results of an experimental study for the evaluation of the effects of different teleoperation parameters are reported. In the experimental study, the effects of time delay, operator training, image-display alternatives (virtual model versus real images), viewpoint, and force-reflection method were studied. For this purpose, several hypotheses were formulated and tested through the experiments using the introduced quantitative and qualitative measures. A fuzzy force-reflection controller is also proposed as an alternative force-reflection technique, and its performance is compared with a conventional proportional-derivative-type force-reflection method. The experimental scheme was implemented using MATLAB XPC Target and Simulink. The results could serve as guidelines in the design of teleoperation systems for obstacle avoidance and could also provide directions for further investigations.",https://ieeexplore.ieee.org/document/5598539/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",April 2011,ieeexplore
10.1109/ACCESS.2020.3006958,Facial Micro-Expression Recognition Using Two-Dimensional Landmark Feature Maps,IEEE,Journals,"Emotion recognition based on facial expressions is very important for effective interaction of humans with artificial intelligence (AI) systems such as social robots. On the other hand, in real environment, it is much harder to recognize facial micro-expressions (FMEs) than facial general-expressions having rich emotions. In this paper, we propose a two-dimensional (2D) landmark feature map for effectively recognizing such FMEs. The proposed 2D landmark feature map (LFM) is obtained by transforming conventional coordinate-based landmark information into 2D image information. LFM is designed to have an advantageous property independent of the intensity of facial expression change. Also, we propose an LFM-based emotion recognition method that is an integrated framework of convolutional neural network (CNN) and long short-term memory (LSTM). Experimental results show that the proposed method achieves about 71% and 74% in the well-known micro-expression datasets, i.e., SMIC and CASME II, respectively, which outperforms the conventional methods. The performance of the proposed method was also verified through experiments on composite micro-expression dataset, which consists of SMIC, CAMSE II and SAMM, and cross-dataset validation using SMIC and CAMSE II. In addition, we prove that the proposed method is independent of facial expression intensity through an experiment on CK+ dataset. Finally, we demonstrate that the proposed method is valid even for the MAHNOB-HCI and MEVIEW datasets that are produced to monitor actual and wild emotional responses.",https://ieeexplore.ieee.org/document/9133091/,IEEE Access,2020,ieeexplore
10.1109/TRO.2019.2929015,Fault Detection in a Swarm of Physical Robots Based on Behavioral Outlier Detection,IEEE,Journals,"The ability to reliably detect faults is essential in many real-world tasks that robot swarms have the potential to perform. Most studies on fault detection in swarm robotics have been conducted exclusively in simulation, and they have focused on a single type of fault or a specific task. In a series of previous studies, we have developed a robust fault-detection approach in which robots in a swarm learn to distinguish between normal and faulty behaviors online. In this paper, we assess the performance of our fault-detection approach on a swarm of seven physical mobile robots. We experiment with three classic swarm robotics tasks and consider several types of faults in both sensors and actuators. Experimental results show that the robots are able to reliably detect the presence of hardware faults in one another even when the swarm behavior is changed during operation. This paper is thus an important step toward making robot swarms sufficiently reliable and dependable for real-world applications.",https://ieeexplore.ieee.org/document/8787875/,IEEE Transactions on Robotics,Dec. 2019,ieeexplore
10.1109/TCST.2017.2756962,Full-State Tracking Control for Flexible Joint Robots With Singular Perturbation Techniques,IEEE,Journals,"This paper proposes a practical method to realize multivariable full-state tracking control for industrial robots with elastic joints. Unlike existing methods, the proposed method does not require high-order derivatives of the link states such as acceleration and jerk. Therefore, the proposed method does not suffer from chatter related to inaccurate estimation of high-order derivatives. The method is derived by adopting a singular perturbation technique. A decoupled error dynamics is achieved by two decoupling control loops: a fast loop that controls the deflection error and a slow loop for tracking control on the link side. Our stability analysis based on a linear system shows that the proposed control system is stable as long as the fast system is at least twice as fast as the slow system. A practical method to select the gain is also presented such that the closed-loop poles are placed at the desired locations. In simulation, we compare the proposed method with feedback linearization. The results indicate that in an ideal scenario the proposed method can obtain a similar performance as feedback linearization. However, the proposed method obtains a superior performance in a realistic scenario. A real-world experiment with a six degree-of-freedom commercial industrial robot is carried out to further validate our approach.",https://ieeexplore.ieee.org/document/8065027/,IEEE Transactions on Control Systems Technology,Jan. 2019,ieeexplore
10.1109/TOH.2017.2753233,Functional Contour-following via Haptic Perception and Reinforcement Learning,IEEE,Journals,"Many tasks involve the fine manipulation of objects despite limited visual feedback. In such scenarios, tactile and proprioceptive feedback can be leveraged for task completion. We present an approach for real-time haptic perception and decision-making for a haptics-driven, functional contour-following task: the closure of a ziplock bag. This task is challenging for robots because the bag is deformable, transparent, and visually occluded by artificial fingertip sensors that are also compliant. A deep neural net classifier was trained to estimate the state of a zipper within a robot's pinch grasp. A Contextual Multi-Armed Bandit (C-MAB) reinforcement learning algorithm was implemented to maximize cumulative rewards by balancing exploration versus exploitation of the state-action space. The C-MAB learner outperformed a benchmark Q-learner by more efficiently exploring the state-action space while learning a hard-to-code task. The learned C-MAB policy was tested with novel ziplock bag scenarios and contours (wire, rope). Importantly, this work contributes to the development of reinforcement learning approaches that account for limited resources such as hardware life and researcher time. As robots are used to perform complex, physically interactive tasks in unstructured or unmodeled environments, it becomes important to develop methods that enable efficient and effective learning with physical testbeds.",https://ieeexplore.ieee.org/document/8039205/,IEEE Transactions on Haptics,1 Jan.-March 2018,ieeexplore
10.1109/ACCESS.2020.3043662,Ground-Level Mapping and Navigating for Agriculture Based on IoT and Computer Vision,IEEE,Journals,"Autonomous agricultural systems are a promising solution to bridge the gap between labor shortage for agriculture tasks and the continuing needs for increasing productivity in agriculture. Automated mapping and navigation system will be a cornerstone of most autonomous agricultural system. Accordingly, we propose a ground-level mapping and navigating system based on computer vision technology (Mesh Simultaneous Localization and Mapping algorithm, Mesh-SLAM) and Internet of Things (IoT), to generate a 3D farm map on both the edge side and cloud. The innovation of this system includes three layers as sub-systems that are 1) ground-level robot vehicles' layer for conducting frames collection only with a monocular camera, 2) edge node layer for image feature data edge computing and communication, and 3) cloud layer for general management and deep computing. High efficiency and speed of mapping stage are enabled by making the robot vehicles directly stream continuous frames to their corresponding edge node. Then each edge node, that coordinate a certain range of robots, applies a new Mesh-SLAM frame by frame, whose core is reconstructing the features map by a mesh-based algorithm with scalable units and reduce the feature data size by a filtering algorithm. Additionally, the cloud-computing allows comprehensive arrangement and heavily deep computing. The system is scalable to larger-scale fields and more complex environment by taking advantage of dynamically distributing the computation power to edges. Our evaluation indicates that: 1) this Mesh-SLAM algorithm outperforms in mapping and localization precision, accuracy, and yield prediction error (resolution at centimeter); and 2) The scalability and flexibility of the IoT architecture make the system modularized, easy adding/removing new functional modules or IoT sensors. We conclude the trade-off between cost and performance widely augments the feasibility and practical implementation of this system in real farms.",https://ieeexplore.ieee.org/document/9288741/,IEEE Access,2020,ieeexplore
10.1109/3477.499796,Hidden state and reinforcement learning with instance-based state identification,IEEE,Journals,"Real robots with real sensors are not omniscient. When a robot's next course of action depends on information that is hidden from the sensors because of problems such as occlusion, restricted range, bounded field of view and limited attention, we say the robot suffers from the hidden state problem. State identification techniques use history information to uncover hidden state. Some previous approaches to encoding history include: finite state machines, recurrent neural networks and genetic programming with indexed memory. A chief disadvantage of all these techniques is their long training time. This paper presents instance-based state identification, a new approach to reinforcement learning with state identification that learns with much fewer training steps. Noting that learning with history and learning in continuous spaces both share the property that they begin without knowing the granularity of the state space, the approach applies instance-based (or ""memory-based"") learning to history sequences-instead of recording instances in a continuous geometrical space, we record instances in action-percept-reward sequence space. The first implementation of this approach, called Nearest Sequence Memory, learns with an order of magnitude fewer steps than several previous approaches.",https://ieeexplore.ieee.org/document/499796/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",June 1996,ieeexplore
10.1109/ACCESS.2021.3063782,Hierarchical Decomposed-Objective Model Predictive Control for Autonomous Casualty Extraction,IEEE,Journals,"In recent years, several robots have been developed and deployed to perform casualty extraction tasks. However, the majority of these robots are overly complex, and require teleoperation via either a skilled operator or a specialised device, and often the operator must be present at the scene to navigate safely around the casualty. Instead, improving the autonomy of such robots can reduce the reliance on expert operators and potentially unstable communication systems, while still extracting the casualty in a safe manner. There are several stages in the casualty extraction procedure, from navigating to the location of the emergency, safely approaching and loading the casualty, to finally navigating back to the medical assistance location. In this paper, we propose a Hierarchical Decomposed-Objective based Model Predictive Control (HiDO-MPC) method for safely approaching and manoeuvring around the casualty. We implement this controller on ResQbot — a proof-of-concept mobile rescue robot we previously developed — capable of safely rescuing an injured person lying on the ground, i.e. performing the casualty extraction procedure. HiDO-MPC achieves the desired casualty extraction behaviour by decomposing the main objective into multiple sub-objectives with a hierarchical structure. At every time step, the controller evaluates this hierarchical decomposed objective and generates the optimal control decision. We have conducted a number of experiments both in simulation and using the real robot to evaluate the proposed method’s performance, and compare it with baseline approaches. The results demonstrate that the proposed control strategy gives significantly better results than baseline approaches in terms of accuracy, robustness, and execution time, when applied to casualty extraction scenarios.",https://ieeexplore.ieee.org/document/9369351/,IEEE Access,2021,ieeexplore
10.1109/ACCESS.2018.2873597,Hierarchical Semantic Mapping Using Convolutional Neural Networks for Intelligent Service Robotics,IEEE,Journals,"The introduction of service robots in the public domain has introduced a paradigm shift in how robots are interacting with people, where robots must learn to autonomously interact with the untrained public instead of being directed by trained personnel. As an example, a hospital service robot is told to deliver medicine to Patient Two in Ward Three. Without awareness of what “Patient Two” or “Ward Three” is, a service robot must systematically explore the environment to perform this task, which requires a long time. The implementation of a Semantic Map allows for robots to perceive the environment similar to people by associating semantic information with spatial information found in geometric maps. Currently, many semantic mapping works provide insufficient or incorrect semantic-metric information to allow a service robot to function dynamically in human-centric environments. This paper proposes a semantic map with a hierarchical semantic organization structure based on a hybrid metric-topological map leveraging convolutional neural networks and spatial room segmentation methods. Our results are validated using multiple simulated and real environments on our lab's custom developed mobile service robot and demonstrate an application of semantic maps by providing only vocal commands. We show that this proposed method provides better capabilities in terms of semantic map labeling and retain multiple levels of semantic information.",https://ieeexplore.ieee.org/document/8490234/,IEEE Access,2018,ieeexplore
10.1109/ACCESS.2020.3035725,Highlighted Map for Mobile Robot Localization and Its Generation Based on Reinforcement Learning,IEEE,Journals,"This article proposes a new kind of map for mobile robot localization and its generation method. We call the map a highlighted map, on which uniquely shaped objects (landmarks) in monotonous environments are highlighted. By using this map, robots can use such landmarks as clues for localization, and thus, their localization performance can be improved without having to update their sensors or online computation. Furthermore, this map can be easily combined with many other existing localization algorithms. We formulate the problem of making a highlighted map and propose a numerical optimization method based on reinforcement learning. This optimization method automatically identifies and emphasizes the important landmarks on the map. The generated highlighted map is adapted to situations such as the sensor characteristics and robot dynamics because this method uses the actual sensor measurement data. It is proven that the optimization converges under certain technical assumptions. We performed a numerical simulation and real-world experiment showing that the highlighted map provides better localization accuracy than a conventional map.",https://ieeexplore.ieee.org/document/9247228/,IEEE Access,2020,ieeexplore
10.1109/TMECH.2015.2490180,Hybrid Approach for Modeling and Solving of Kinematics of a Compact Bionic Handling Assistant Manipulator,IEEE,Journals,"This paper deals with a methodology for real-time solving of a complex kinematics of a class of continuum manipulators, namely the compact bionic handling assistant (CBHA). First, a quantitative approach is used to model kinematically the CBHA inspired from the modeling of parallel rigid manipulators. For this case, the CBHA is modeled as a series of vertebrae, where each vertebra is connected to the next one through a flexible link. The latter named an intervertebra is modeled by three universal-prismatic-spherical and one universal-prismatic joints. The kinematic models of the CBHA are derived from the inverse kinematic equations (IKE) of each intervertebra. A qualitative approach based on neural networks is used to provide approximated solutions of the IKE for real-time implementation. Thus, the combination of the advantages of quantitative and qualitative approaches allows proposing a hybrid methodology for accurate modeling and solving the kinematics of this class of continuum robots. A set of experiments is conducted using a CBHA in order to evaluate the level of efficiency of the proposed hybrid approach.",https://ieeexplore.ieee.org/document/7296659/,IEEE/ASME Transactions on Mechatronics,June 2016,ieeexplore
10.1109/ACCESS.2019.2949835,Hybrid Path Planning Algorithm Based on Membrane Pseudo-Bacterial Potential Field for Autonomous Mobile Robots,IEEE,Journals,"A hybrid path planning algorithm based on membrane pseudo-bacterial potential field (MemPBPF) is proposed. Membrane-inspired algorithms can reach an evolutionary behavior based on biochemical processes to find the best parameters for generating a feasible and safe path. The proposed MemPBPF algorithm uses a combination of the structure and rules of membrane computing. In that sense, the proposed MemPBPF algorithm contains dynamic membranes that include a pseudo-bacterial genetic algorithm for evolving the required parameters in the artificial potential field method. This hybridization between membrane computing, the pseudo-bacterial genetic algorithm, and the artificial potential field method provides an outperforming path planning algorithm for autonomous mobile robots. Computer simulation results demonstrate the effectiveness of the proposed MemPBPF algorithm in terms of path length considering collision avoidance and smoothness. Comparisons with two different versions employing a different number of elementary membranes and with other artificial potential field based algorithms are presented. The proposed MemPBPF algorithm yields improved performance in terms of time execution by using a parallel implementation on a multi-core computer. Therefore, the MemPBPF algorithm achieves high performance yielding competitive results for autonomous mobile robot navigation in complex and real scenarios.",https://ieeexplore.ieee.org/document/8884165/,IEEE Access,2019,ieeexplore
10.1109/ACCESS.2019.2894524,Hybrid Stochastic Exploration Using Grey Wolf Optimizer and Coordinated Multi-Robot Exploration Algorithms,IEEE,Journals,"Multi-robot exploration is a search of uncertainty in restricted space seeking to build a finite map by a group of robots. It has the main task to distribute the search assignments among robots in real time. In this paper, we proposed a stochastic optimization for multi-robot exploration that mimics the coordinated predatory behavior of grey wolves via simulation. Here, the robot movement is computed by the combined deterministic and metaheuristic techniques. It uses the Coordinated Multi-Robot Exploration and GreyWolf Optimizer algorithms as a new method called the hybrid stochastic exploration. Initially, the deterministic cost and utility determine the precedence of adjacent cells around a robot. Then, the stochastic optimization improves the overall solution. It implies that the robots evaluate the environment by the deterministic approach and move on using the metaheuristic algorithm. The proposed hybrid method was implemented on simple and complex maps and compared with the Coordinated Multi-Robot Exploration algorithm. The simulation results show that the stochastic optimization enhances the deterministic approach to completely explore and map out the areas.",https://ieeexplore.ieee.org/document/8631022/,IEEE Access,2019,ieeexplore
10.1109/TIE.2018.2864707,Incremental Updating Multirobot Formation Using Nonlinear Model Predictive Control Method With General Projection Neural Network,IEEE,Journals,"In this paper, an incremental centralized formation system is developed for controlling the multirobot formation with joining robots, and a nonlinear model predictive control (NMPC) method is implemented as the controller. The incremental updating method is used to update the system's state in real time, when there is a new robot joining during the formation process. Then, an NMPC approach is developed to reformulate the formation system into a convex nonlinear minimization problem, which can be further transformed into a quadratic programming (QP) with constraints. Then, a general projection neural network (GPNN) is implemented for solving this QP problem online to get the optimal inputs. In the end, two examples of incremental multirobot formation are demonstrated to verify the effectiveness of this method.",https://ieeexplore.ieee.org/document/8437254/,IEEE Transactions on Industrial Electronics,June 2019,ieeexplore
10.1109/TSMCC.2007.897491,Integration of Coordination Architecture and Behavior Fuzzy Learning in Quadruped Walking Robots,IEEE,Journals,"This paper presents the design and implementation of a coordination architecture for quadruped walking robots to learn and execute soccer-playing behaviors. A typical hybrid architecture combing reactive behaviors with deliberative reasoning is developed. The reactive behaviors directly map spatial information extracted from sensors into actions. The deliberative reasoning represents temporal constraints of a robot's strategy in terms of finite state machines. In order to achieve real-time and robust control performance in reactive behaviors, fuzzy logic controllers (FLCs) are used to encode the behaviors, and a two-stage learning scheme is adopted to make these FLCs adaptive to complex situations. The experimental results are provided to show the suitability of the architecture and effectiveness of the proposed learning scheme.",https://ieeexplore.ieee.org/document/4252246/,"IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)",July 2007,ieeexplore
10.1109/TSMCA.2009.2033029,Interactive Teaching for Vision-Based Mobile Robots: A Sensory-Motor Approach,IEEE,Journals,"For the last decade, we have been developing a vision-based architecture for mobile robot navigation. Using our bio-inspired model of navigation, robots can perform sensory-motor tasks in real time in unknown indoor as well as outdoor environments. We address here the problem of autonomous incremental learning of a sensory-motor task, demonstrated by an operator guiding a robot. The proposed system allows for semisupervision of task learning and is able to adapt the environmental partitioning to the complexity of the desired behavior. A real dialogue based on actions emerges from the interactive teaching. The interaction leads the robot to autonomously build a precise sensory-motor dynamics that approximates the behavior of the teacher. The usability of the system is highlighted by experiments on real robots, in both indoor and outdoor environments. Accuracy measures are also proposed in order to evaluate the learned behavior as compared to the expected behavioral attractor. These measures, used first in a real experiment and then in a simulated experiment, demonstrate how a real interaction between the teacher and the robot influences the learning process.",https://ieeexplore.ieee.org/document/5345874/,"IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans",Jan. 2010,ieeexplore
10.1109/LRA.2021.3060712,Joint Plant Instance Detection and Leaf Count Estimation for In-Field Plant Phenotyping,IEEE,Journals,"Precision management of agricultural fields as well as plant breeding are central factors for keeping yields high and to provide food, feed, and fiber for our society. A key element in breeding trials but also for targeted management actions is to analyze the growth state of individual plants objectively and at a large scale. In this letter, we address the problem of analyzing crops in real agricultural fields based on camera data recorded with mobile robots and to derive information about the plant development, e.g., to monitor phenotypic traits such as growth stage. We propose a novel single-stage object detection approach that localizes crops and weeds in the field. At the same time, it detects plant-specific leaf keypoints intending to estimate leaf count at a plant level, which is a key trait for classifying the growth stage. We implemented and thoroughly tested our approach on real sugar beet fields. As our experiments show, it performs the required detections and shows superior performance with respect to a state-of-the-art two-stage approach based on Mask R-CNN.",https://ieeexplore.ieee.org/document/9359471/,IEEE Robotics and Automation Letters,April 2021,ieeexplore
10.1109/TRA.2002.803459,LOST: localization-space trails for robot teams,IEEE,Journals,"We describe localization-space trails (LOST), a method that enables a team of robots to navigate between places of interest in an initially unknown environment using a trail of landmarks. The landmarks are not physical; they are waypoint coordinates generated online by each robot and shared with teammates. Waypoints are specified in each robot's local coordinate system, and contain references to features in the world that are relevant to the team's task and common to all robots. Using these task-level references, robots can share waypoints without maintaining a global coordinate system. The method is tested in a series of real-world multirobot experiments. The results demonstrate that the method: 1) copes with accumulating odometry error; 2) is robust to the failure of individual robots; 3) converges to the best route discovered by any robot in the team. In one experiment, a team of four autonomous mobile robots performs a resource transportation task in our uninstrumented office building. Despite significant divergence of their local coordinate systems, the robots are able to share waypoints, forming and following a common trail between two predetermined locations for more than three hours, traveling a total of 8.2 km (5.1 miles) before running out of power. Designed to scale to large populations, LOST is fully distributed, with low costs in processing, memory, and bandwidth. It combines metric data about the position of features in the world with instructions on how to get from one place to another; producing something between a map and a plan.",https://ieeexplore.ieee.org/document/1067999/,IEEE Transactions on Robotics and Automation,Oct. 2002,ieeexplore
10.1109/LRA.2020.3010739,Learning Force Control for Contact-Rich Manipulation Tasks With Rigid Position-Controlled Robots,IEEE,Journals,"Reinforcement Learning (RL) methods have been proven successful in solving manipulation tasks autonomously. However, RL is still not widely adopted on real robotic systems because working with real hardware entails additional challenges, especially when using rigid position-controlled manipulators. These challenges include the need for a robust controller to avoid undesired behavior, that risk damaging the robot and its environment, and constant supervision from a human operator. The main contributions of this work are, first, we proposed a learning-based force control framework combining RL techniques with traditional force control. Within said control scheme, we implemented two different conventional approaches to achieve force control with position-controlled robots; one is a modified parallel position/force control, and the other is an admittance control. Secondly, we empirically study both control schemes when used as the action space of the RL agent. Thirdly, we developed a fail-safe mechanism for safely training an RL agent on manipulation tasks using a real rigid robot manipulator. The proposed methods are validated both on simulation and a real robot with an UR3 e-series robotic arm.",https://ieeexplore.ieee.org/document/9145608/,IEEE Robotics and Automation Letters,Oct. 2020,ieeexplore
10.1109/LRA.2021.3116703,Learning Robot Exploration Strategy With 4D Point-Clouds-Like Information as Observations,IEEE,Journals,"Being able to explore unknown environments is a requirement for fully autonomous robots. Many learning-based methods have been proposed to learn an exploration strategy. In the frontier-based exploration, learning algorithms tend to learn the optimal or near-optimal frontier to explore. Most of these methods represent the environments as fixed size images and take these as inputs to neural networks. However, the size of environments is usually unknown, which makes these methods fail to generalize to real world scenarios. To address this issue, we present a novel state representation method based on 4D point-clouds-like information, including the locations, frontier, and distance information. We also design a neural network that can process these 4D point-clouds-like information and generate the estimated value for each frontier. Then this neural network is trained using the typical reinforcement learning framework. We test the performance of our proposed method by comparing it with other five methods and test its scalability on maps that are much larger than maps in the training set. The experiment results demonstrate that our proposed method needs shorter average traveling distances to explore whole environments and can be adopted in maps with arbitrarily sizes.",https://ieeexplore.ieee.org/document/9555230/,IEEE Robotics and Automation Letters,Jan. 2022,ieeexplore
10.1109/LRA.2021.3061374,Learning Variable Impedance Control via Inverse Reinforcement Learning for Force-Related Tasks,IEEE,Journals,"Many manipulation tasks require robots to interact with unknown environments. In such applications, the ability to adapt the impedance according to different task phases and environment constraints is crucial for safety and performance. Although many approaches based on deep reinforcement learning (RL) and learning from demonstration (LfD) have been proposed to obtain variable impedance skills on contact-rich manipulation tasks, these skills are typically task-specific and could be sensitive to changes in task settings. This letter proposes an inverse reinforcement learning (IRL) based approach to recover both the variable impedance policy and reward function from expert demonstrations. We explore different action space of the reward functions to achieve a more general representation of expert variable impedance skills. Experiments on two variable impedance tasks (Peg-in-Hole and Cup-on-Plate) were conducted in both simulations and on a real FANUC LR Mate 200iD/7 L industrial robot. The comparison results with behavior cloning and force-based IRL proved that the learned reward function in the gain action space has better transferability than in the force space. Experiment videos are available at https://msc.berkeley.edu/research/impedance-irl.html.",https://ieeexplore.ieee.org/document/9361101/,IEEE Robotics and Automation Letters,April 2021,ieeexplore
10.1109/TAMD.2015.2507439,Lifelong Augmentation of Multimodal Streaming Autobiographical Memories,IEEE,Journals,"Robot systems that interact with humans over extended periods of time will benefit from storing and recalling large amounts of accumulated sensorimotor and interaction data. We provide a principled framework for the cumulative organization of streaming autobiographical data so that data can be continuously processed and augmented as the processing and reasoning abilities of the agent develop and further interactions with humans take place. As an example, we show how a kinematic structure learning algorithm reasons a-posteriori about the skeleton of a human hand. A partner can be asked to provide feedback about the augmented memories, which can in turn be supplied to the reasoning processes in order to adapt their parameters. We employ active, multimodal remembering, so the robot as well as humans can gain insights of both the original and augmented memories. Our framework is capable of storing discrete and continuous data in real-time. The data can cover multiple modalities and several layers of abstraction (e.g., from raw sound signals over sentences to extracted meanings). We show a typical interaction with a human partner using an iCub humanoid robot. The framework is implemented in a platform-independent manner. In particular, we validate its multi platform capabilities using the iCub, Baxter and NAO robots. We also provide an interface to cloud based services, which allow automatic annotation of episodes. Our framework is geared towards the developmental robotics community, as it: 1) provides a variety of interfaces for other modules; 2) unifies previous works on autobiographical memory; and 3) is licensed as open source software.",https://ieeexplore.ieee.org/document/7350228/,IEEE Transactions on Cognitive and Developmental Systems,Sept. 2016,ieeexplore
10.1109/ACCESS.2020.2970728,LoPECS: A Low-Power Edge Computing System for Real-Time Autonomous Driving Services,IEEE,Journals,"To simultaneously enable multiple autonomous driving services on affordable embedded systems, we designed and implemented LoPECS, a Low-Power Edge Computing System for real-time autonomous robots and vehicles services. The contributions of this paper are three-fold: first, we developed a Heterogeneity-Aware Runtime Layer to fully utilize vehicle's heterogeneous computing resources to fulfill the real-time requirement of autonomous driving applications; second, we developed a vehicle-edge Coordinator to dynamically offload vehicle tasks to edge cloudlet to further optimize user experience in the way of prolonged battery life; third, we successfully integrated these components into LoPECS system and implemented it on Nvidia Jetson TX1. To the best of our knowledge, this is the first complete edge computing system in a production autonomous vehicle. Our implementation on Nvidia Jetson demonstrated that it could successfully support multiple autonomous driving services with only 11 W of power consumption, and hence proves the effectiveness of the proposed LoPECS system.",https://ieeexplore.ieee.org/document/8977507/,IEEE Access,2020,ieeexplore
10.1109/LRA.2020.2972819,Marker-Less Micro Aerial Vehicle Detection and Localization Using Convolutional Neural Networks,IEEE,Journals,"A relative localization system for micro aerial vehicles (MAVs), which is able to work without any markers or other specialized equipment, is presented in this letter. The system utilizes images from an onboard camera to detect nearby MAVs using a convolutional neural network. When compared to traditional computer vision-based relative localization systems, this approach removes the need for specialized markers to be placed on the MAVs, saving weight and space, while also enabling localization of noncooperating robots. The system is designed and implemented to run online, onboard an MAV platform in order to enable relative stabilization of several MAVs in a formation or swarm-like behavior, when operating in a closed feedback loop with the control system of the MAVs. We demonstrate the viability and robustness of the proposed method in real-world experiments. The method was also designed for the purpose of autonomous aerial interception and is a fitting complement to other MAV detection and relative localization methods for this purpose, as is shown in the experiments.",https://ieeexplore.ieee.org/document/8988144/,IEEE Robotics and Automation Letters,April 2020,ieeexplore
10.1109/LRA.2020.3010456,Multi-Robot Active Sensing and Environmental Model Learning With Distributed Gaussian Process,IEEE,Journals,"This letter deals with the problem of multiple robots working together to explore and gather at the global maximum of the unknown field. Given noisy sensor measurements obtained at the location of robots with no prior knowledge about the environmental map, Gaussian process regression can be an efficient solution to construct a map that represents spatial information with confidence intervals. However, because the conventional Gaussian process algorithm operates in a centralized manner, it is difficult to process information coming from multiple distributed sensors in real-time. In this work, we propose a multi-robot exploration algorithm that deals with the following challenges: i) distributed environmental map construction using networked sensing platforms; ii) online learning using successive measurements suitable for a multi-robot team; iii) multi-agent coordination to discover the highest peak of an unknown environmental field with collision avoidance. We demonstrate the effectiveness of our algorithm via simulation and a topographic survey experiment with multiple UAVs.",https://ieeexplore.ieee.org/document/9144385/,IEEE Robotics and Automation Letters,Oct. 2020,ieeexplore
10.1109/TAMD.2010.2086453,Multilevel Darwinist Brain (MDB): Artificial Evolution in a Cognitive Architecture for Real Robots,IEEE,Journals,"The multilevel Darwinist brain (MDB) is a cognitive architecture that follows an evolutionary approach to provide autonomous robots with lifelong adaptation. It has been tested in real robot on-line learning scenarios obtaining successful results that reinforce the evolutionary principles that constitute the main original contribution of the MDB. This preliminary work has lead to a series of improvements in the computational implementation of the architecture so as to achieve realistic operation in real time, which was the biggest problem of the approach due to the high computational cost induced by the evolutionary algorithms that make up the MDB core. The current implementation of the architecture is able to provide an autonomous robot with real time learning capabilities and the capability for continuously adapting to changing circumstances in its world, both internal and external, with minimal intervention of the designer. This paper aims at providing an overview or the architecture and its operation and defining what is required in the path towards a real cognitive robot following a developmental strategy. The design, implementation and basic operation of the MDB cognitive architecture are presented through some successful real robot learning examples to illustrate the validity of this evolutionary approach.",https://ieeexplore.ieee.org/document/5599851/,IEEE Transactions on Autonomous Mental Development,Dec. 2010,ieeexplore
10.1109/TIE.2007.903993,Multimodal Approach to Human-Face Detection and Tracking,IEEE,Journals,"The constructive need for robots to coexist with humans requires human-machine interaction. It is a challenge to operate these robots in such dynamic environments, which requires continuous decision-making and environment-attribute update in real-time. An autonomous robot guide is well suitable in places such as museums, libraries, schools, hospital, etc. This paper addresses a scenario where a robot tracks and follows a human. A neural network is utilized to learn the skin and nonskin colors. The skin-color probability map is utilized for skin classification and morphology-based preprocessing. Heuristic rule is used for face-ratio analysis and Bayesian cost analysis for label classification. A face-detection module, based on a 2D color model in the and YUV color space, is selected over the traditional skin-color model in a 3D color space. A modified continuously adaptive mean shift tracking mechanism in a 1D hue, saturation, and value color space is developed and implemented onto the mobile robot. In addition to the visual cues, the tracking process considers 16 sonar scan and tactile sensor readings from the robot to generate a robust measure of the person's distance from the robot. The robot thus decides an appropriate action, namely, to follow the human subject and perform obstacle avoidance. The proposed approach is orientation invariant under varying lighting conditions and invariant to natural transformations such as translation, rotation, and scaling. Such a multimodal solution is effective for face detection and tracking.",https://ieeexplore.ieee.org/document/4392479/,IEEE Transactions on Industrial Electronics,March 2008,ieeexplore
10.1109/TIM.2021.3102739,Object Detection Based on Fusion of Sparse Point Cloud and Image Information,IEEE,Journals,"With the rapid development of mobile robots, environmental perception based on a single sensor can hardly meet the task requirements of the robots for object detection and path planning in complex scenarios. In this article, an object detection fusion algorithm based on both the information of the LiDAR point cloud and the camera image is proposed. First, YOLOv4 is used to detect the objects in the image. Then, the point cloud is projected into the image, and the target point cloud is filtered out according to the range of the 2-D detection frame. The target point cloud is used to perform density clustering and generate the output of a bounding box with semantic labels. Meanwhile, the original point cloud data are processed by an improved four-neighborhood clustering algorithm based on the Euclidean distance and angle threshold to generate the output of another bounding box without semantic labels. Finally, the clusters obtained by different methods are fused and judged to produce the output of the final object detection results. The test using the KITTI dataset shows that the accuracy of the improved four-neighbor clustering algorithm is increased to 0.835. The final semantic segmentation results have an average positioning error of 0.033 and 0.073 m in the x- and y-directions. The average angular error of the vehicle direction is 0.90°. Compared with the other two types of point cloud segmentation networks, our approach has the highest accuracy and sufficient real-time performance, which can reach 9.96 Hz in the experiment.",https://ieeexplore.ieee.org/document/9507517/,IEEE Transactions on Instrumentation and Measurement,2021,ieeexplore
10.1109/LRA.2021.3076955,On the Emergence of Whole-Body Strategies From Humanoid Robot Push-Recovery Learning,IEEE,Journals,"Balancing and push-recovery are essential capabilities enabling humanoid robots to solve complex locomotion tasks. In this context, classical control systems tend to be based on simplified physical models and hard-coded strategies. Although successful in specific scenarios, this approach requires demanding tuning of parameters and switching logic between specifically-designed controllers for handling more general perturbations. We apply model-free Deep Reinforcement Learning for training a general and robust humanoid push-recovery policy in a simulation environment. Our method targets high-dimensional whole-body humanoid control and is validated on the iCub humanoid. Reward components incorporating expert knowledge on humanoid control enable fast learning of several robust behaviors by the same policy, spanning the entire body. We validate our method with extensive quantitative analyses in simulation, including out-of-sample tasks which demonstrate policy robustness and generalization, both key requirements towards real-world robot deployment.",https://ieeexplore.ieee.org/document/9420230/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/TNNLS.2014.2354400,Opportunistic Behavior in Motivated Learning Agents,IEEE,Journals,"This paper focuses on the novel motivated learning (ML) scheme and opportunistic behavior of an intelligent agent. It extends previously developed ML to opportunistic behavior in a multitask situation. Our paper describes the virtual world implementation of autonomous opportunistic agents learning in a dynamically changing environment, creating abstract goals, and taking advantage of arising opportunities to improve their performance. An opportunistic agent achieves better results than an agent based on ML only. It does so by minimizing the average value of all need signals rather than a dominating need. This paper applies to the design of autonomous embodied systems (robots) learning in real-time how to operate in a complex environment.",https://ieeexplore.ieee.org/document/6913540/,IEEE Transactions on Neural Networks and Learning Systems,Aug. 2015,ieeexplore
10.1109/TOH.2020.2975555,Perception of Tactile Directionality via Artificial Fingerpad Deformation and Convolutional Neural Networks,IEEE,Journals,"Humans can perceive tactile directionality with angular perception thresholds of 14-40° via fingerpad skin displacement. Using deformable, artificial tactile sensors, the ability to perceive tactile directionality was developed for a robotic system to aid in object manipulation tasks. Two convolutional neural networks (CNNs) were trained on tactile images created from fingerpad deformation measurements during perturbations to a handheld object. A primary CNN regression model provided a point estimate of tactile directionality over a range of grip forces, perturbation angles, and perturbation speeds. A secondary CNN model provided a variance estimate that was used to determine uncertainty about the point estimate. A 5-fold cross-validation was performed to evaluate model performance. The primary CNN produced tactile directionality point estimates with an error rate of 4.3% for a 20° angular resolution and was benchmarked against an open-source force estimation network. The model was implemented in real-time for interactions with an external agent and the environment with different object shapes and widths. The perception of tactile directionality could be used to enhance the situational awareness of human operators of telerobotic systems and to develop decision-making algorithms for context-appropriate responses by semi-autonomous robots.",https://ieeexplore.ieee.org/document/9007491/,IEEE Transactions on Haptics,Oct.-Dec. 2020,ieeexplore
10.1109/LRA.2019.2894217,Persistent and Robust Execution of MAPF Schedules in Warehouses,IEEE,Journals,"Multi-agent path finding (MAPF) is a well-studied problem in artificial intelligence that can be solved quickly in practice when using simplified agent assumptions. However, real-world applications, such as warehouse automation, require physical robots to function over long time horizons without collisions. We present an execution framework that can use existing single-shot MAPF planners and ensures robust execution in the presence of unknown or time-varying higher-order dynamic limits, unforeseen robot slow-downs, and unpredictable obstacle appearances. Our framework also naturally enables the overlap of re-planning and execution for persistent operation and requires little communication between robots and the centralized planner. We demonstrate our approach in warehouse simulations and in a mixed reality experiment using differential drive robots. We believe that our solution closes the gap between recent research in the artificial intelligence community and real-world applications.",https://ieeexplore.ieee.org/document/8620328/,IEEE Robotics and Automation Letters,April 2019,ieeexplore
10.1109/TNSRE.2017.2692520,Portable and Reconfigurable Wrist Robot Improves Hand Function for Post-Stroke Subjects,IEEE,Journals,"Rehabilitation robots have become increasingly popular for stroke rehabilitation. However, the high cost of robots hampers their implementation on a large scale. This paper implements the concept of a modular and reconfigurable robot, reducing its cost and size by adopting different therapeutic end effectors for different training movements using a single robot. The challenge is to increase the robot's portability and identify appropriate kinds of modular tools and configurations. Because literature on the effectiveness of this kind of rehabilitation robot is still scarce, this paper presents the design of a portable and reconfigurable rehabilitation robot and describes its use with a group of post-stroke patients for wrist and forearm training. Seven stroke subjects received training using a reconfigurable robot for 30 sessions, lasting 30 min per session. Post-training, statistical analysis showed significant improvement of 3.29 points (16.20%, p = 0.027) on the Fugl-Meyer assessment scale for forearm and wrist components. Significant improvement of active range of motion was detected in both pronation-supination (75.59%, p = 0.018) and wrist flexion-extension (56.12%, p = 0.018) after the training. These preliminary results demonstrate that the developed reconfigurable robot could improve subjects' wrist and forearm movement.",https://ieeexplore.ieee.org/document/7894193/,IEEE Transactions on Neural Systems and Rehabilitation Engineering,Oct. 2017,ieeexplore
10.1109/TNN.2006.877534,Prune-Able Fuzzy ART Neural Architecture for Robot Map Learning and Navigation in Dynamic Environments,IEEE,Journals,"Mobile robots must be able to build their own maps to navigate in unknown worlds. Expanding a previously proposed method based on the fuzzy ART neural architecture (FARTNA), this paper introduces a new online method for learning maps of unknown dynamic worlds. For this purpose the new Prune-able fuzzy adaptive resonance theory neural architecture (PAFARTNA) is introduced. It extends the FARTNA self-organizing neural network with novel mechanisms that provide important dynamic adaptation capabilities. Relevant PAFARTNA properties are formulated and demonstrated. A method is proposed for the perception of object removals, and then integrated with PAFARTNA. The proposed methods are integrated into a navigation architecture. With the new navigation architecture the mobile robot is able to navigate in changing worlds, and a degree of optimality is maintained, associated to a shortest path planning approach implemented in real-time over the underlying global world model. Experimental results obtained with a Nomad 200 robot are presented demonstrating the feasibility and effectiveness of the proposed methods",https://ieeexplore.ieee.org/document/1687933/,IEEE Transactions on Neural Networks,Sept. 2006,ieeexplore
10.1109/ACCESS.2021.3056149,READ-IoT: Reliable Event and Anomaly Detection Framework for the Internet of Things,IEEE,Journals,"Internet of Things (IoT) enables a myriad of applications by interconnecting software to physical objects. The objects range from wireless sensors to robots and include surveillance cameras. The applications are often critical (e.g. physical intrusion detection, fire fighting) and latency-sensitive. On the one hand, such applications rely on specific protocols (e.g. MQTT, COAP) and the network to communicate with the objects under very tight timeframe. On the other hand, anomalies (e.g. communication noise, sensors' failures, security attacks) are likely to occur in open IoT systems and can result by sending false alerts or the failure to properly detect critical events. To address that, IoT systems have to be equipped with anomaly detection processing in addition to the required event detection capability. This is a key feature that enables reliability and efficiency in IoT. However, anomaly detection systems can be themselves object of failures and attacks, and then can easily fall short to accomplish their mission. This paper introduces a Reliable Event and Anomaly Detection Framework for the Internet of Things (READ-IoT for short). The designed framework integrates events and anomalies detection into a single and common system that centralizes the management of both concepts. To enforce its reliability, the system relies on a reputation-aware provisioning of detection capabilities that takes into account the vulnerability of the deployment hosts. As for validation, READ-IoT was implemented and evaluated using two real life applications, i.e. a fire detection and an unauthorized person detection applications. Several scenarios of anomalies and events were conducted using NSL-KDD public dataset, as well as, generated data to simulate routing attacks. The obtained results and performance measurements show the efficiency of READ-IoT in terms of event detection accuracy and real-time processing.",https://ieeexplore.ieee.org/document/9343860/,IEEE Access,2021,ieeexplore
10.1109/LRA.2020.2998414,RILaaS: Robot Inference and Learning as a Service,IEEE,Journals,"Programming robots is complicated due to the lack of `plug-and-play' modules for skill acquisition. Virtualizing deployment of deep learning models can facilitate large-scale use/re-use of off-the-shelf functional behaviors. Deploying deep learning models on robots entails real-time, accurate and reliable inference service under varying query load. This letter introduces a novel Robot-Inference-and-Learning-as-a-Service (RILaaS) platform for low-latency and secure inference serving of deep models that can be deployed on robots. Unique features of RILaaS include: 1) low-latency and reliable serving with gRPC under dynamic loads by distributing queries over multiple servers on Edge and Cloud, 2) SSH based authentication coupled with SSL/TLS based encryption for security and privacy of the data, and 3) front-end REST API for sharing, monitoring and visualizing performance metrics of the available models. We report experiments to evaluate the RILaaS platform under varying loads of batch size, number of robots, and various model placement hosts on Cloud, Edge, and Fog for providing benchmark applications of object recognition and grasp planning as a service. We address the complexity of load balancing with a reinforcement learning algorithm that optimizes simulated profiles of networked robots; outperforming several baselines including round robin, least connections, and least model time with 68.30% and 14.04% decrease in round-trip latency time across models compared to the worst and the next best baseline respectively. Details and updates are available at: https://sites.google.com/view/rilaas.",https://ieeexplore.ieee.org/document/9103220/,IEEE Robotics and Automation Letters,July 2020,ieeexplore
10.1109/81.747195,Reaction-diffusion CNN algorithms to generate and control artificial locomotion,IEEE,Journals,"In this paper a physiological-behavioral approach to neural processing is used to realize artificial locomotion in mechatronic devices. The task has been realized by using a particular model of reaction-diffusion cellular neural networks (RD-CNN's) generating autowave fronts as well as Turing patterns. Moreover a programmable hardware cellular neural network structure is presented in order to model, generate, and control in real time some biorobots. The programmable hardware implementation gives the possibility of generating locomotion in real time and also to control the transition among several types of locomotion, with particular attention to hexapodes. The approach proposed allows not only the design of walking robots, but also the ability to build structures able to efficiently solve typical problems in industrial automation, such as online routing of objects moved on conveyor belts.",https://ieeexplore.ieee.org/document/747195/,IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications,Feb. 1999,ieeexplore
10.1109/TSMCB.2012.2192107,Robust Multiperson Detection and Tracking for Mobile Service and Social Robots,IEEE,Journals,"This paper proposes an efficient system which integrates multiple vision models for robust multiperson detection and tracking for mobile service and social robots in public environments. The core technique is a novel maximum likelihood (ML)-based algorithm which combines the multimodel detections in mean-shift tracking. First, a likelihood probability which integrates detections and similarity to local appearance is defined. Then, an expectation-maximization (EM)-like mean-shift algorithm is derived under the ML framework. In each iteration, the E-step estimates the associations to the detections, and the M-step locates the new position according to the ML criterion. To be robust to the complex crowded scenarios for multiperson tracking, an improved sequential strategy to perform the mean-shift tracking is proposed. Under this strategy, human objects are tracked sequentially according to their priority order. To balance the efficiency and robustness for real-time performance, at each stage, the first two objects from the list of the priority order are tested, and the one with the higher score is selected. The proposed method has been successfully implemented on real-world service and social robots. The vision system integrates stereo-based and histograms-of-oriented-gradients-based human detections, occlusion reasoning, and sequential mean-shift tracking. Various examples to show the advantages and robustness of the proposed system for multiperson tracking from mobile robots are presented. Quantitative evaluations on the performance of multiperson tracking are also performed. Experimental results indicate that significant improvements have been achieved by using the proposed method.",https://ieeexplore.ieee.org/document/6187748/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",Oct. 2012,ieeexplore
10.1109/TCST.2019.2914634,Robust Regressor-Free Control of Rigid Robots Using Function Approximations,IEEE,Journals,"This paper develops a novel regressor-free robust controller for rigid robots whose dynamics can be described using the Euler-Lagrange equations of motion. The function approximation technique (FAT) is used to represent the robot's inertia matrix, the Coriolis matrix, and the gravity vector as finite linear combinations of orthonormal basis functions. The proposed controller establishes a robust FAT control framework that uses a fixed control structure. The control objectives are to track reference trajectories in worst case scenarios where the robot dynamics are too costly to develop or otherwise unavailable. Detailed stability analysis via Lyapunov functions, the passivity property, and continuous switching laws shows uniform ultimate boundedness of the closed-loop dynamics. The simulation results of a three-degree-of-freedom (DOF) robot when the robot parameters are perturbed from their nominal values show good robustness of the proposed controller when compared with some well-established control methods. We also demonstrate success in the real-time experimental implementation of the proposed controller, which validates practicality for real-world robotic applications.",https://ieeexplore.ieee.org/document/8718993/,IEEE Transactions on Control Systems Technology,July 2020,ieeexplore
10.1109/TETC.2017.2769705,Robust Robot Tracking for Next-Generation Collaborative Robotics-Based Gaming Environments,IEEE,Journals,"The collaboration between humans and robots is one of the most disruptive and challenging research areas. Even considering advances in design and artificial intelligence, humans and robots could soon ally to perform together a number of different tasks. Robots could also became new playmates. In fact, an emerging trend is associated with the so-called phygital gaming, which builds upon the idea of merging the physical world with a virtual one in order to let physical and virtual entities, such as players, robots, animated characters and other game objects interact seamlessly as if they were all part of the same reality. This paper specifically focuses on mixed reality gaming environments that can be created by using floor projection, and tackles the issue of enabling accurate and robust tracking of off-the-shelf robots endowed with limited sensing capabilities. The proposed solution is implemented by fusing visual tracking data gathered via a fixed camera in a smart environment with odometry data obtained from robot's on-board sensors. The solution has been tested within a phygital gaming platform in a real usage scenario, by experimenting with a robotic game that exhibits many challenging situations which would be hard to manage using conventional tracking techniques.",https://ieeexplore.ieee.org/document/8094867/,IEEE Transactions on Emerging Topics in Computing,1 July-Sept. 2020,ieeexplore
10.1109/LRA.2017.2665694,Shakey 2016—How Much Does it Take to Redo Shakey the Robot?,IEEE,Journals,"Shakey the robot was one of the first autonomous robots that showed impressive capabilities of navigation and mobile manipulation. Since then, robotics research has made great progress, showing more and more capable robotic systems for a large variety of application domains and tasks. In this letter, we look back on decades of research by rebuilding Shakey with modern robotics technology in the open-source Shakey 2016 system. Hereby, we demonstrate the impact of research by showing that ideas from the original Shakey are still alive in state-of-the-art systems, while robotics in general has improved to deliver more robust and more capable software and hardware. Our Shakey 2016 system has been implemented on real robots and leverages mostly open-source software. We experimentally evaluate the system in real-world scenarios on a PR2 robot and a Turtlebot-based robot and particularly investigate the development effort. The experiments documented in this letter demonstrate that results from robotics research are readily available for building complex robots such as Shakey within a short amount of time and little effort.",https://ieeexplore.ieee.org/document/7847341/,IEEE Robotics and Automation Letters,April 2017,ieeexplore
10.1109/LRA.2020.3013848,Sim2Real Predictivity: Does Evaluation in Simulation Predict Real-World Performance?,IEEE,Journals,"Does progress in simulation translate to progress on robots? If one method outperforms another in simulation, how likely is that trend to hold in reality on a robot? We examine this question for embodied PointGoal navigation - developing engineering tools and a research paradigm for evaluating a simulator by its sim2real predictivity. First, we develop Habitat-PyRobot Bridge (HaPy), a library for seamless execution of identical code on simulated agents and robots - transferring simulation-trained agents to a LoCoBot platform with a one-line code change. Second, we investigate the sim2real predictivity of Habitat-Sim M. Savva et al., for PointGoal navigation. We 3D-scan a physical lab space to create a virtualized replica, and run parallel tests of 9 different models in reality and simulation. We present a new metric called Sim-vs-Real Correlation Coefficient (SRCC) to quantify predictivity. We find that SRCC for Habitat as used for the CVPR19 challenge is low (0.18 for the success metric), suggesting that performance differences in this simulator-based challenge do not persist after physical deployment. This gap is largely due to AI agents learning to exploit simulator imperfections - abusing collision dynamics to `slide' along walls, leading to shortcuts through otherwise non-navigable space. Naturally, such exploits do not work in the real world. Our experiments show that it is possible to tune simulation parameters to improve sim2real predictivity (e.g. improving SRCC<sub>Succ</sub> from 0.18 to 0.844) - increasing confidence that in-simulation comparisons will translate to deployed systems in reality.",https://ieeexplore.ieee.org/document/9158349/,IEEE Robotics and Automation Letters,Oct. 2020,ieeexplore
10.1109/TCDS.2016.2565542,Spatial Concept Acquisition for a Mobile Robot That Integrates Self-Localization and Unsupervised Word Discovery From Spoken Sentences,IEEE,Journals,"In this paper, we propose a novel unsupervised learning method for the lexical acquisition of words related to places visited by robots, from human continuous speech signals. We address the problem of learning novel words by a robot that has no prior knowledge of these words except for a primitive acoustic model. Furthermore, we propose a method that allows a robot to effectively use the learned words and their meanings for self-localization tasks. The proposed method is nonparametric Bayesian spatial concept acquisition method (SpCoA) that integrates the generative model for self-localization and the unsupervised word segmentation in uttered sentences via latent variables related to the spatial concept. We implemented the proposed method SpCoA on SIGVerse, which is a simulation environment, and TurtleBot2, which is a mobile robot in a real environment. Further, we conducted experiments for evaluating the performance of SpCoA. The experimental results showed that SpCoA enabled the robot to acquire the names of places from speech sentences. They also revealed that the robot could effectively utilize the acquired spatial concepts and reduce the uncertainty in self-localization.",https://ieeexplore.ieee.org/document/7467531/,IEEE Transactions on Cognitive and Developmental Systems,Dec. 2016,ieeexplore
10.1109/TCAD.2020.3012864,StereoEngine: An FPGA-Based Accelerator for Real-Time High-Quality Stereo Estimation With Binary Neural Network,IEEE,Journals,"Stereo estimation is essential to many applications such as mobile autonomous robots, most of which ask for real-time response, high energy, and storage efficiency. Deep neural networks (DNNs) have shown to yield significant gains in improving accuracy. However, these DNN-based algorithms are challenging to be deployed on energy and resource-constrained devices due to the high computational complexities of DNNs. In this article, we present StereoEngine, a fully pipelined end-to-end stereo vision accelerator that computes accurate dense depth in a real-time and energy-efficient manner. An efficient stereo algorithm is developed and optimized for a high-quality hardware-friendly implementation, that leverages binary neural network (BNN) to learn discriminative binary descriptors to improve the disparity. The design of StereoEngine is a standalone DNN-based stereo vision system where all processing procedures are implemented on a hardware platform. The effectiveness of StereoEngine is evaluated by comprehensive experiments. Compared with software-based implementations on the highend and embedded Nvidia GPUs, StereoEngine achieves up to 3×, 13×, and 50× speedups, as well as up to 211×, 58×, and 73× energy efficiency improvement, respectively. Furthermore, StereoEngine achieves leading accuracy when compared to state-of-the-art hardware implementations on the challenging KITTI dataset.",https://ieeexplore.ieee.org/document/9211569/,IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,Nov. 2020,ieeexplore
10.1109/TE.2012.2224867,SyRoTek—Distance Teaching of Mobile Robotics,IEEE,Journals,"E-learning is a modern and effective approach for training in various areas and at different levels of education. This paper gives an overview of SyRoTek, an e-learning platform for mobile robotics, artificial intelligence, control engineering, and related domains. SyRoTek provides remote access to a set of fully autonomous mobile robots placed in a restricted area with dynamically reconfigurable obstacles, which enables solving a huge variety of problems. A user is able to control the robots in real time by their own developed algorithms as well as being able to analyze gathered data and observe activity of the robots by provided interfaces. The system is currently used for education at the Czech Technical University in Prague, Prague, Czech Republic, and at the University of Buenos Aires, Buenos, Aires, Argentina, and it is freely accessible to other institutions. In addition to the system overview, this paper presents the experience gained from the actual deployment of the system in teaching activities.",https://ieeexplore.ieee.org/document/6341862/,IEEE Transactions on Education,Feb. 2013,ieeexplore
10.1109/JIOT.2021.3068736,Terra: A Smart and Sensible Digital Twin Framework for Robust Robot Deployment in Challenging Environments,IEEE,Journals,"Digital twin (DT) systems that replicate the physical world digitally are powerful tools for monitoring physical systems and evaluating algorithms, but current DT systems are commonly not applicable for robotic deployment and investigation. Meanwhile, current 3-D simulation-based robotic platforms do not model the dynamics of the physical world on-the-fly as done in DT systems, limiting their potential for the development of robotics in challenging environments. To tackle this issue, we propose the first robot-centered smart DT framework, namely, Terra, to facilitate the deployment of robots in challenging environments. The proposed Terra framework introduces a comprehensive DT representation to encode the useful real-time dynamics of both the physical world and the robot agent deployed therein. A multiview multimodality perception module is further devised for Terra to obtain high-level semantics and deliver a precise description of the current status of the environment and the robot agent. By mapping the perceived results to the virtual replica of the physical environment, Terra actively updates the action policy and sends it back to the agent, forming an integral and real-time information feedback loop. In practice, to help demonstrate the effectiveness and feasibility of the proposed framework, we deliberately set up a challenging unordered physical environment with many obstacles and a very simple robot aiming to fulfill a navigation task. Empirical results show that the proposed Terra framework successfully facilitates the robot to accomplish the task without causing hazards.",https://ieeexplore.ieee.org/document/9386242/,IEEE Internet of Things Journal,"15 Sept.15, 2021",ieeexplore
10.1109/TRO.2012.2228134,The Impact of Human–Robot Interfaces on the Learning of Visual Objects,IEEE,Journals,"This paper studies the impact of interfaces, allowing nonexpert users to efficiently and intuitively teach a robot to recognize new visual objects. We present challenges that need to be addressed for real-world deployment of robots capable of learning new visual objects in interaction with everyday users. We argue that in addition to robust machine learning and computer vision methods, well-designed interfaces are crucial for learning efficiency. In particular, we argue that interfaces can be key in helping nonexpert users to collect good learning examples and, thus, improve the performance of the overall learning system. Then, we present four alternative human-robot interfaces: Three are based on the use of a mediating artifact (smartphone, wiimote, wiimote and laser), and one is based on natural human gestures (with a Wizard-of-Oz recognition system). These interfaces mainly vary in the kind of feedback provided to the user, allowing him to understand more or less easily what the robot is perceiving and, thus, guide his way of providing training examples differently. We then evaluate the impact of these interfaces, in terms of learning efficiency, usability, and user's experience, through a real world and large-scale user study. In this experiment, we asked participants to teach a robot 12 different new visual objects in the context of a robotic game. This game happens in a home-like environment and was designed to motivate and engage users in an interaction where using the system was meaningful. We then discuss results that show significant differences among interfaces. In particular, we show that interfaces such as the smartphone interface allows nonexpert users to intuitively provide much better training examples to the robot, which is almost as good as expert users who are trained for this task and are aware of the different visual perception and machine learning issues. We also show that artifact-mediated teaching is significantly more efficient for robot learning, and equally good in terms of usability and user's experience, than teaching thanks to a gesture-based human-like interaction.",https://ieeexplore.ieee.org/document/6384810/,IEEE Transactions on Robotics,April 2013,ieeexplore
10.1109/70.88137,The vector field histogram-fast obstacle avoidance for mobile robots,IEEE,Journals,"A real-time obstacle avoidance method for mobile robots which has been developed and implemented is described. This method, named the vector field histogram (VFH), permits the detection of unknown obstacles and avoids collisions while simultaneously steering the mobile robot toward the target. The VFH method uses a two-dimensional Cartesian histogram grid as a world model. This world model is updated continuously with range data sampled by onboard range sensors. The VFH method subsequently uses a two-stage data-reduction process to compute the desired control commands for the vehicle. Experimental results from a mobile robot traversing densely cluttered obstacle courses in smooth and continuous motion and at an average speed of 0.6-0.7 m/s are shown. A comparison of the VFN method to earlier methods is given.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/88137/,IEEE Transactions on Robotics and Automation,June 1991,ieeexplore
10.1109/TCDS.2017.2712712,Toward Brain-Inspired Learning With the Neuromorphic Snake-Like Robot and the Neurorobotic Platform,IEEE,Journals,"Neurorobotic mimics the structural and functional principles of living creature systems. Modeling a single system by robotic hardware and software has existed for decades. However, an integrated toolset studying the interaction of all systems has not been demonstrated yet. We present a hybrid neuromorphic computing paradigm to bridge this gap by combining the neurorobotics platform (NRP) with the neuromorphic snake-like robot (NeuroSnake). This paradigm encompasses the virtual models, neuromorphic sensing and computing capabilities, and physical bio-inspired bodies, with which an experimenter can design and execute both in-silico and in-vivo robotic experimentation easily. The NRP is a public Web-based platform for easily testing brain models with virtual bodies and environments. The NeuroSnake is a bio-inspired robot equipped with a silico-retina sensor and neuromorphic computer for power-efficiency applications. We illustrate the efficiencies of our paradigm with an easy designing of a visual pursuit experiment in the NRP. We study two automatic behavior learning tasks which are further integrated into a complex task of semi-autonomous pole climbing. The result shows that robots could build new learning rules in a less explicit manner inspired by living creatures. Our method gives an alternative way to efficiently develop complex behavior control of the ro As spiking neural network is a bio-inspired neural network and the NeuroSnake robot is equipped with a spike-based silicon retina camera, the control system can be easily implemented via spiking neurons simulated on neuromorphic hardware, such as SpiNNaker.bot.",https://ieeexplore.ieee.org/document/7945270/,IEEE Transactions on Cognitive and Developmental Systems,March 2019,ieeexplore
10.1109/TASE.2017.2731371,Toward Socially Aware Robot Navigation in Dynamic and Crowded Environments: A Proactive Social Motion Model,IEEE,Journals,"Safe and social navigation is the key to deploying a mobile service robot in a human-centered environment. Widespread acceptability of mobile service robots in daily life is hindered by robot's inability to navigate in crowded and dynamic human environments in a socially acceptable way that would guarantee human safety and comfort. In this paper, we propose an effective proactive social motion model (PSMM) that enables a mobile service robot to navigate safely and socially in crowded and dynamic environments. The proposed method considers not only human states (position, orientation, motion, field of view, and hand poses) relative to the robot but also social interactive information about human-object and human group interactions. This allows development of the PSMM that consists of elements of an extended social force model and a hybrid reciprocal velocity obstacle technique. The PSMM is then combined with a path planning technique to generate a motion planning system that drives a mobile robot in a socially acceptable manner and produces respectful and polite behaviors akin to human movements. Note to Practitioners-In this paper, we validated the effectiveness and feasibility of the proposed proactive social motion model (PSMM) through both simulation and real-world experiments under the newly proposed human comfortable safety indices. To do that, we first implemented the entire navigation system using the open-source robot operating system. We then installed it in a simulated robot model and conducted experiments in a simulated shopping mall-like environment to verify its effectiveness. We also installed the proposed algorithm on our mobile robot platform and conducted experiments in our office-like laboratory environment. Our results show that the developed socially aware navigation framework allows a mobile robot to navigate safely, socially, and proactively while guaranteeing human safety and comfort in crowded and dynamic environments. In this paper, we examined the proposed PSMM with a set of predefined parameters selected based on our empirical experiences about the robot mechanism and selected social environment. However, in fact a mobile robot might need to adapt to various contextual and cultural situations in different social environments. Thus, it should be equipped with an online adaptive interactive learning mechanism allowing the robot to learn to auto-adjust their parameters according to such embedded environments. Using machine learning techniques, e.g., inverse reinforcement learning [1] to optimize the parameter set for the PSMM could be a promising research direction to improve adaptability of mobile service robots in different social environments. In the future, we will evaluate the proposed framework based on a wider variety of scenarios, particularly those with different social interaction situations and dynamic environments. Furthermore, various kinds of social cues and signals introduced in [2] and [3] will be applied to extend the proposed framework in more complicated social situations and contexts. Last but not least, we will investigate different machine learning techniques and incorporate them in the PSMM in order to allow the robot to automatically adapt to diverse social environments.",https://ieeexplore.ieee.org/document/8011466/,IEEE Transactions on Automation Science and Engineering,Oct. 2017,ieeexplore
10.1109/ACCESS.2020.3046730,Tracking In-Cabin Astronauts Using Deep Learning and Head Motion Clues,IEEE,Journals,"A person-following robot is under development for astronaut assistance on the Chinese Space Station. Real-time astronaut detection and tracking are the most important prerequisites for in-cabin flying assistant robots so that they can follow a specific astronaut and offer him/her assistance. In the limited space in the space station cabin, astronauts stand close to each other when working collaboratively; thus, large regions of their bodies tend to overlap in the image. In addition, because astronauts wear the same clothes most of the time, it is difficult to distinguish an individual astronaut using human body features. In this paper, we distinguish the astronauts by tracking their heads in the image. A deep learning model trained using big data is proposed for effective head detection. In addition, a motion model based on spatial clues is combined with the head detection results to track astronauts in the scene. A complete pipeline of the algorithm has been implemented and run efficiently on the Tegra X2 embedded AI microprocessor. A set of experiments were carried out and successfully validated the effectiveness of the proposed tracking algorithm. This algorithm is a step toward the implementation of robot assistants, especially in resource-limited environments.",https://ieeexplore.ieee.org/document/9305234/,IEEE Access,2021,ieeexplore
10.1109/LRA.2021.3070305,Underwater Soft Robot Modeling and Control With Differentiable Simulation,IEEE,Journals,"Underwater soft robots are challenging to model and control because of their high degrees of freedom and their intricate coupling with water. In this letter, we present a method that leverages the recent development in differentiable simulation coupled with a differentiable, analytical hydrodynamic model to assist with the modeling and control of an underwater soft robot. We apply this method to Starfish, a customized soft robot design that is easy to fabricate and intuitive to manipulate. Our method starts with data obtained from the real robot and alternates between simulation and experiments. Specifically, the simulation step uses gradients from a differentiable simulator to run system identification and trajectory optimization, and the experiment step executes the optimized trajectory on the robot to collect new data to be fed into simulation. Our demonstration on Starfish shows that proper usage of gradients from a differentiable simulator not only narrows down its simulation-to-reality gap but also improves the performance of an open-loop controller in real experiments.",https://ieeexplore.ieee.org/document/9392257/,IEEE Robotics and Automation Letters,July 2021,ieeexplore
10.1109/TAMD.2010.2097260,Using the Rhythm of Nonverbal Human–Robot Interaction as a Signal for Learning,IEEE,Journals,"Human-robot interaction is a key issue in order to build robots for everyone. The difficulty for people to understand how robots work and how they must be controlled will be one of the mains limit for broad robotics. In this paper, we study a new way of interacting with robots without needing to understand how robots work or to give them explicit instructions. This work is based on psychological data showing that synchronization and rhythm are very important features for pleasant interaction. We propose a biologically inspired architecture using rhythm detection to build an internal reward for learning. After showing the results of keyboard interactions, we present and discuss the results of real human-robots (Aibo and Nao) interactions. We show that our minimalist control architecture allows the discovery and learning of arbitrary sensorimotor associations games with expert users. With nonexpert users, we show that using only the rhythm information is not sufficient for learning all the associations due to the different strategies used by the human. Nevertheless, this last experiment shows that the rhythm is still allowing the discovery of subsets of associations, being one of the promising signal of tomorrow social applications.",https://ieeexplore.ieee.org/document/5664771/,IEEE Transactions on Autonomous Mental Development,March 2011,ieeexplore
10.1109/LRA.2018.2851148,Visual Navigation for Biped Humanoid Robots Using Deep Reinforcement Learning,IEEE,Journals,"In this letter, we propose a map-less visual navigation system for biped humanoid robots, which extracts information from color images to derive motion commands using deep reinforcement learning (DRL). The map-less visual navigation policy is trained using the Deep Deterministic Policy Gradients (DDPG) algorithm, which corresponds to an actor-critic DRL algorithm. The algorithm is implemented using two separate networks, one for the actor and one for the critic, but with similar structures. In addition to convolutional and fully connected layers, Long Short-Term Memory (LSTM) layers are included to address the limited observability present in the problem. As a proof of concept, we consider the case of robotic soccer using humanoid NAO V5 robots, which have reduced computational capabilities, and low-cost Red - Green - Blue (RGB) cameras as main sensors. The use of DRL allowed to obtain a complex and high performant policy from scratch, without any prior knowledge of the domain, or the dynamics involved. The visual navigation policy is trained in a robotic simulator and then successfully transferred to a physical robot, where it is able to run in 20 ms, allowing its use in real-time applications.",https://ieeexplore.ieee.org/document/8398461/,IEEE Robotics and Automation Letters,Oct. 2018,ieeexplore
10.1109/LRA.2021.3068106,Visual Navigation in Real-World Indoor Environments Using End-to-End Deep Reinforcement Learning,IEEE,Journals,"Visual navigation is essential for many applications in robotics, from manipulation, through mobile robotics to automated driving. Deep reinforcement learning (DRL) provides an elegant map-free approach integrating image processing, localization, and planning in one module, which can be trained and therefore optimized for a given environment. However, to date, DRL-based visual navigation was validated exclusively in simulation, where the simulator provides information that is not available in the real world, e.g., the robot's position or segmentation masks. This precludes the use of the learned policy on a real robot. Therefore, we present a novel approach that enables a direct deployment of the trained policy on real robots. We have designed a new powerful simulator capable of domain randomization. To facilitate the training, we propose visual auxiliary tasks and a tailored reward scheme. The policy is fine-tuned on images collected from real-world environments. We have evaluated the method on a mobile robot in a real office environment. The training took approximately 30 hours on a single GPU. In 30 navigation experiments, the robot reached a 0.3-meter neighbourhood of the goal in more than 86.7% of cases. This result makes the proposed method directly applicable to tasks like mobile manipulation.",https://ieeexplore.ieee.org/document/9384194/,IEEE Robotics and Automation Letters,July 2021,ieeexplore
10.1109/TSMCB.2010.2089978,"Walking Motion Generation, Synthesis, and Control for Biped Robot by Using PGRL, LPI, and Fuzzy Logic",IEEE,Journals,"This paper proposes the implementation of fuzzy motion control based on reinforcement learning (RL) and Lagrange polynomial interpolation (LPI) for gait synthesis of biped robots. First, the procedure of a walking gait is redefined into three states, and the parameters of this designed walking gait are determined. Then, the machine learning approach applied to adjusting the walking parameters is policy gradient RL (PGRL), which can execute real-time performance and directly modify the policy without calculating the dynamic function. Given a parameterized walking motion designed for biped robots, the PGRL algorithm automatically searches the set of possible parameters and finds the fastest possible walking motion. The reward function mainly considered is first the walking speed, which can be estimated from the vision system. However, the experiment illustrates that there are some stability problems in this kind of learning process. To solve these problems, the desired zero moment point trajectory is added to the reward function. The results show that the robot not only has more stable walking but also increases its walking speed after learning. This is more effective and attractive than manual trial-and-error tuning. LPI, moreover, is employed to transform the existing motions to the motion which has a revised angle determined by the fuzzy motion controller. Then, the biped robot can continuously walk in any desired direction through this fuzzy motion control. Finally, the fuzzy-based gait synthesis control is demonstrated by tasks and point- and line-target tracking. The experiments show the feasibility and effectiveness of gait learning with PGRL and the practicability of the proposed fuzzy motion control scheme.",https://ieeexplore.ieee.org/document/5640679/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",June 2011,ieeexplore
10.1109/JSEN.2020.3024094,k-Nearest Neighbor Classification for Pattern Recognition of a Reference Source Light for Machine Vision System,IEEE,Journals,"The design of machine vision applications allows automatic inspection, measuring systems, and robot guidance. Typical applications of industrial robots are based on no-contact sensors to give the robot information about the environment. Robot's machine vision requires photosensors or video cameras to make intelligent decisions about its localization. Video cameras used as image-capturing equipment are too costly in comparison with optical scanning systems (OSS). The OSS system provides spatial coordinates measurements that can be exploited to solve a wide variety of structural problems in real-time. Localization and guidance using machine learning (ML) techniques offer advantages due to signals captured can be transformed and be reduced for processing, storage, and displaying. The use of algorithms of ML enhances the performance of the optical system based on localization and guidance. Feature extraction represents an important part of ML techniques to transform the original raw data onto a low-dimensional subspace and holding relevant information. This work presents an improvement of an optical system based on <i>k</i>-nearest neighbor ( <i>k</i>-NN) technique to solve the object detection and localization problem. The utility of this improvement allows the optical system can discriminate between the reference source and the optical noise or interference. The OSS system presented in this article has been implemented in structural health monitoring to measure the angular position even under “lighting and weather conditions”. The feature extraction techniques used in this article were linear predictive coding (LPC), quartiles ( <i>Q</i><sub>iquartile</sub>), and autocorrelation coefficients (ACC). The results of using <i>k</i>-NN and autocorrelation coefficients and quartiles predicted more than 98% of correct classification by using a reference source light as a class 1 and a light bulb as an optical noise and called class 2.",https://ieeexplore.ieee.org/document/9195874/,IEEE Sensors Journal,"15 May15, 2021",ieeexplore
10.1109/IROS.1992.601935,"""Arnie P."" - A Robot Golfing System Using Binocular And A Heuristic Feedback Mechanism",IEEE,Conferences,"This paper describes a robot vision golfing system. The Automated Robotic Navigational unit with Intelligent Eye and Putter (ARNIE P)<sup>τ</sup>project was initiated to investigate the problems and develop software solutions for robotic tasks that require good hand-eye coordination and an intelligent sensor feedback mechanism. This system has only one frame buffer and no specialized hardware, so quasi-real time 3D tracking is accomplished in software using the Unix Spline facility. The single frame buffer and digitizer, stores and retains the location of the ball from two separate cameras during the time interval between the golf ball initially crossing a trigger scan line and the ball coming to a complete stop. The most novel aspect of this study is that by attempting to build or model a difficult perceptory task such as golf, which requires integrating many complicated computational pieces (binocular stereo vision, robot arm motion, heuristic feedback, learning), it appears to be a good plarform to experiment with artificial intelligence techniques and robotics.",https://ieeexplore.ieee.org/document/601935/,Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems,7-10 July 1992,ieeexplore
10.1109/AIMS52415.2021.9466061,3D Control System of Arm Robot Prototype for Skin Cancer Detection,IEEE,Conferences,"Arm robot has a lack of control systems that depend on desired control for assistive medical. Our laboratory robotics &amp; artificial intelligent at Padjadjaran University created skin cancer detection of arm robot with dark flow framework to identify skin cancer in real-time. The implementation of the arm robot was for increasing the accuracy, precision, and stability. The main purpose of this paper was to control an arm robot for skin cancer detection that is capable to scan the whole body skin to localize the skin cancers by driving the manipulator in circular or elliptical skimming. To initiate the communication with the arm robot which used Dynamixel as the actuators, we applied USB2Dynamixel as the communicator. SMPS2Dynamixel was used to supply the power into servo motors. 3D Control system software has designed, and it had some features such as; forward kinematic movement, inverse kinematic movement, and 3D simulation to help user visualize the position of the arm robot. Control software was built in MATLAB GUI environment and 3D simulation adapted Peter Corke Robotics Toolbox.",https://ieeexplore.ieee.org/document/9466061/,2021 International Conference on Artificial Intelligence and Mechatronics Systems (AIMS),28-30 April 2021,ieeexplore
10.1109/AIID51893.2021.9456574,3D scene geometry estimation method of substation inspection robot based on lightweight neural network,IEEE,Conferences,"Understanding 3D scene geometry from video is a basic subject of visual perception. It includes many classic computer vision tasks, such as depth recovery, traffic estimation, visual odometer. Recent work has proved that deep learning can be applied to scene understanding problems. But they all have some inherent limitations. For example, they need stereo cameras as additional devices for data acquisition, or can't explicitly deal with non-rigid and occlusion. The environment in the substation is complex, and there are many devices. In the working process of inspection robot, the target is very easy to be blocked, and it is difficult to deploy directly by traditional methods. In addition, the real-time performance of neural network is very important for electric inspection robot. In this paper, 3D scene geometry estimation method of substation inspection robot is proposed, which consists of two main parts: GeoNet module and pruning module. Experiments show that the proposed method can be effectively applied to electric inspection robot.",https://ieeexplore.ieee.org/document/9456574/,2021 IEEE International Conference on Artificial Intelligence and Industrial Design (AIID),28-30 May 2021,ieeexplore
10.1109/WCICA.2016.7578819,3D vision based fast badminton localization with prediction and error elimination for badminton robot,IEEE,Conferences,"In this paper, the problem of fast badminton localization problem is investigated for a class of badminton robots. More precisely, a manifold-learning based localization method is implemented for the improvement of hitting accuracy and effectiveness. Based on the localization results, a novel badminton trajectory prediction algorithm is designed based on 3D Vision in the real world. Furthermore, clock-synchronization combined with motion compensation methods are also proposed to better localization error elimination. In the end, the validity and usefulness of our proposed algorithm is demonstrated by numerical experiments.",https://ieeexplore.ieee.org/document/7578819/,2016 12th World Congress on Intelligent Control and Automation (WCICA),12-15 June 2016,ieeexplore
10.1109/ICRA.2018.8461228,3DOF Pedestrian Trajectory Prediction Learned from Long-Term Autonomous Mobile Robot Deployment Data,IEEE,Conferences,"This paper presents a novel 3DOF pedestrian trajectory prediction approach for autonomous mobile service robots. While most previously reported methods are based on learning of 2D positions in monocular camera images, our approach uses range-finder sensors to learn and predict 3DOF pose trajectories (i.e. 2D position plus 1D rotation within the world coordinate system). Our approach, T-Pose-LSTM (Temporal 3DOF-Pose Long-Short-Term Memory), is trained using long-term data from real-world robot deployments and aims to learn context-dependent (environment- and time-specific) human activities. Our approach incorporates long-term temporal information (i.e. date and time) with short-term pose observations as input. A sequence-to-sequence LSTM encoder-decoder is trained, which encodes observations into LSTM and then decodes the resulting predictions. On deployment, the approach can perform on-the-fly prediction in real-time. Instead of using manually annotated data, we rely on a robust human detection, tracking and SLAM system, providing us with examples in a global coordinate system. We validate the approach using more than 15 km of pedestrian trajectories recorded in a care home environment over a period of three months. The experiments show that the proposed T-Pose-LSTM model outperforms the state-of-the-art 2D-based method for human trajectory prediction in long-term mobile robot deployments.",https://ieeexplore.ieee.org/document/8461228/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/CNNA.1998.685360,A CNN stereo vision hardware system for autonomous robot navigation,IEEE,Conferences,"The high parallel analogue processing rate makes the cellular neural networks paradigm really useful in such a problems where real-time replies to external stimuli are required. The development of an effective system for autonomous robot navigation can find a valid support from this research. Moreover, the growth of new CNN algorithms can afford the necessary feedback to the hardware developers to improve their realisations. In this paper some measurements of a stereo-vision algorithm on a CNN hardware implementation (the 720DPCNN system) are given.",https://ieeexplore.ieee.org/document/685360/,1998 Fifth IEEE International Workshop on Cellular Neural Networks and their Applications. Proceedings (Cat. No.98TH8359),14-17 April 1998,ieeexplore
10.1109/ISCAS.2003.1205068,A CNN-based chip for robot locomotion control,IEEE,Conferences,"In this paper a VLSI chip for real-time locomotion control in legged robots is introduced. The control is based on the biological paradigm of Central Pattern Generator (CPG) and is implemented by a Cellular Neural Network (CNN). The gait generation is accomplished by the CNN and is fully analog, while a digital controller modulates the behavior of the CNN-based CPG to allow the locomotion system to adapt to sensory feedback. The chip is designed with a switched-capacitor technique, fundamental to address the speed control issue. Experimental results on the first prototype are illustrated. These results confirm the suitability of the approach and open the way to the design of a fully autonomous bio-inspired micro-robot.",https://ieeexplore.ieee.org/document/1205068/,"Proceedings of the 2003 International Symposium on Circuits and Systems, 2003. ISCAS '03.",25-28 May 2003,ieeexplore
10.1109/RTCSA.2018.00012,A Case Study of Cyber-Physical System Design: Autonomous Pick-and-Place Robot,IEEE,Conferences,"Although modern robots in warehousing systems can perform adequately in a goods-to-person model using hand-designed algorithms that are specialized to a particular environment, developing a robotic system that is capable of handling new products at an inexpensive cost remains a challenge. A conspicuous example of this challenge is seen in Amazon's use of autonomous robots to fetch customers' orders in their massive warehouses. To encourage advance in this technology, Amazon organized the competition, Amazon Picking Challenge that asked participants to develop their own hardware and software for the general task of picking a designated set of products from inventory shelves and then placing them at a target location (called a pick-and-place task). Current technology for pick-and-place tasks is still insufficient to meet the demand for low-cost automation. Handling awkward or oddly shaped object must still depend on hand-programming or specialized robotic systems, making manufacturing automation less flexible and expensive. In this paper, we shall present the design and implementation of a software system that is a step in advancing the technology toward full automation at reasonable costs. Our system integrates a set of state-of-the-art techniques in computer vision, deep-learning, trajectory optimization, visual servoing to create a library of skills that can be composed to perform a variety of robotic tasks. We demonstrate the capability of our system for performing autonomous pick-and-place tasks with an implementation using Hoppy, an industrial robotic arm in an environment similar to the Amazon Picking Challenge.",https://ieeexplore.ieee.org/document/8607230/,2018 IEEE 24th International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA),28-31 Aug. 2018,ieeexplore
10.1109/ACCC51160.2020.9347897,A Comparative Analysis of Kinematics of Industrial Robot KUKA KR 60–3 Using Scientific Computing Languages,IEEE,Conferences,"In the field of robotics, there are kinematic analysis methods that are responsible for describing the positions and orientations of the end effectors, as well as the angles, velocities and trajectories of industrial robots; such techniques are: forward kinematics, inverse kinematics and velocity kinematics. For the solutions of these complex mathematical calculations, the use of scientific computing languages or programs is required; which more and more algorithms, libraries and complements are implemented, that achieve a reduction in programming hours and result in the creation of better solutions in areas of all kinds. For this reason, the kinematics of the Industrial Robot KUKA KR 60-3 was programmed in the languages and programs most used in scientific computing, with the aim of comparing the performance (real time) when carrying out symbolic and numerical analysis in said studies.",https://ieeexplore.ieee.org/document/9347897/,2020 Asia Conference on Computers and Communications (ACCC),18-20 Sept. 2020,ieeexplore
10.1109/CACRE50138.2020.9230347,A Distributed Reward Algorithm for Inverse Kinematics of Arm Robot,IEEE,Conferences,"Traditional methods of inverse kinematics of robots always adopt analytical approach and numerical approach to solve the continuous state and action problems with experience and experiment mostly, which require much time and work in reality work scene, especially for robots with complex structure. This paper proposes a method based on reinforcement learning TD3 network, which is constructed by PyTorch to find the inverse solution from another point of view. A set of improved distributed multiple rewards which choose the position difference between adjacent joints as the reward standard are designed to optimize the solution, avoid solving unreachable points and prevent the mechanical structure from being damaged also in the environment of five-degree-of-freedom arm robot. The validity of above method is verified by simulation experiment results.",https://ieeexplore.ieee.org/document/9230347/,"2020 5th International Conference on Automation, Control and Robotics Engineering (CACRE)",19-20 Sept. 2020,ieeexplore
10.1109/ICRA.2019.8793690,A Fog Robotics Approach to Deep Robot Learning: Application to Object Recognition and Grasp Planning in Surface Decluttering,IEEE,Conferences,"The growing demand of industrial, automotive and service robots presents a challenge to the centralized Cloud Robotics model in terms of privacy, security, latency, bandwidth, and reliability. In this paper, we present a `Fog Robotics' approach to deep robot learning that distributes compute, storage and networking resources between the Cloud and the Edge in a federated manner. Deep models are trained on non-private (public) synthetic images in the Cloud; the models are adapted to the private real images of the environment at the Edge within a trusted network and subsequently, deployed as a service for low-latency and secure inference/prediction for other robots in the network. We apply this approach to surface decluttering, where a mobile robot picks and sorts objects from a cluttered floor by learning a deep object recognition and a grasp planning model. Experiments suggest that Fog Robotics can improve performance by sim-to-real domain adaptation in comparison to exclusively using Cloud or Edge resources, while reducing the inference cycle time by 4× to successfully declutter 86% of objects over 213 attempts.",https://ieeexplore.ieee.org/document/8793690/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/IJCNN48605.2020.9206637,A Lightweight Neural-Net with Assistive Mobile Robot for Human Fall Detection System,IEEE,Conferences,"Falls are a major health issue, particularly among the elderly. Increasing fall events require high service quality and dedicated medical treatment which is an economic burden. In the lack of appropriate care and support, serious injuries caused by fall will cost lives. Therefore, tracking systems with fall detection capabilities are required. Static-view sensors with machine learning techniques for human fall detection have been widely studied and achieved significant results. However, these systems unable to monitor a person if he or she is out of viewing angle which greatly impedes its performance. Mobile robots are an alternative for keeping the person in sight. However, existing mobile robots are unable to operate for a long time due to battery issues and movement constraints in complex environments. In this paper, we proposed a lightweight deep learning vision-based model for human fall detection with an assistive robot to provide assistance when a fall happens. The proposed detection system requires less computational power which can be implemented in a low-cost 2D camera and GPU board for real-time monitoring. The assistive robot equipped with various sensors that can perform SLAM, obstacle avoidance and navigation autonomously. Our proposed system integrates these two sub-systems to compensate for the weakness of each other to constitute a system that robust, adaptable, and high performance. The proposed method has been validated through a series of experiments.",https://ieeexplore.ieee.org/document/9206637/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/CSICC52343.2021.9420614,A New Approach for Mapping of Soccer Robot Agents Position to Real Filed Based on Multi-Core Fuzzy Clustering,IEEE,Conferences,"Mapping the position of soccer robot agents to a real field, is one of the essential issues in the practical implementation of scientific contributions in this context. The lack of a proper assignment affects the scientific implementation of many subjects, such as routing, obstacle avoidance, and robot guidance. For this reason, the use of a clustering method is proposed in this article. Upon the entrance of a new agent, its position is mapped to the real field based on the clustering algorithm. After this mapping, the system begins to work according to the position of the agents, which is defined as the position of the centers of the clusters, as well as the rules defined in the knowledge-base. Considering the unknown and dynamic environment of the robot, some objects inherit common traits from multiple clusters. One reasonable solution for considering the cluster overlaps is to assign a set of membership degrees to each of them. Multiple membership degree assignments result from the fuzzy nature of the clusters. Due to the reduction of segmentations and the shrinkage of the search space, fuzzy clustering generally faces less computational overhead, while the identification and handling of vague, noisy, and outlier data also become much easier in them. The approach of the proposed method is based on the feasibility ideas and uses multi-core learning to identify clusters with complex data structures. The feasibility score of each data represents the percentages of the properties that data inherits from the clusters. Automatically adjusting the weights of the cores in an optimization framework, the proposed method avoids the damage caused by problems such as adopting inefficient cores, or irrelevant features.",https://ieeexplore.ieee.org/document/9420614/,"2021 26th International Computer Conference, Computer Society of Iran (CSICC)",3-4 March 2021,ieeexplore
10.1109/FUZZ48607.2020.9177557,A Novel Self-Organizing PID Approach for Controlling Mobile Robot Locomotion,IEEE,Conferences,"A novel self-organizing fuzzy proportional-integral-derivative (SOF-PID) control system is proposed in this paper. The proposed system consists of a pair of control and reference models, both of which are implemented by a first-order autonomous learning multiple model (ALMMo) neuro-fuzzy system. The SOF-PID controller self-organizes and self-updates the structures and meta-parameters of both the control and reference models during the control process ""on the fly"". This gives the SOF-PID control system the capability of quickly adapting to entirely new operating environments without a full re-training. Moreover, the SOF-PID control system is free from user- and problem-specific parameters and is entirely data-driven. Simulations and real-world experiments with mobile robots demonstrate the effectiveness and validity of the proposed SOF-PID control system.",https://ieeexplore.ieee.org/document/9177557/,2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),19-24 July 2020,ieeexplore
10.1109/RAMECH.2011.6070484,A Q-learning based Cartesian model reference compliance controller implementation for a humanoid robot arm,IEEE,Conferences,This paper presents the implementation (real time and simulation) of a model-free Q-learning based discrete model reference compliance controller for a humanoid robot arm. The Reinforcement learning (RL) scheme uses a recently developed Q-learning scheme to develop an optimal policy on-line. The RL Cartesian (x and y) tracking controller with model reference compliance was implemented using two links (shoulder flexion and elbow flexion joints) of the right arm of the humanoid Bristol-Elumotion-Robotic-Torso II (BERT II) torso.,https://ieeexplore.ieee.org/document/6070484/,"2011 IEEE 5th International Conference on Robotics, Automation and Mechatronics (RAM)",17-19 Sept. 2011,ieeexplore
10.1109/RO-MAN46459.2019.8956259,A Reinforcement-Learning Approach for Adaptive and Comfortable Assistive Robot Monitoring Behavior,IEEE,Conferences,"Companion robots used in the field of elderly assistive care can be of great value in monitoring their everyday activities and well-being. However, in order to be accepted by the user, their behavior, while monitoring them, should not provide discomfort: robots must take into account the activity the user is performing and not be a distraction for them. In this paper, we propose a Reinforcement Learning approach to adaptively decide a monitoring distance and an approaching direction starting from an estimation of the current activity obtained by the use of a wearable device. Our goal is to improve user activity recognition performance without making the robot's presence uncomfortable for the monitored person. Results show that the proposed approach is promising for real scenario deployment, succeeding in accomplishing the task in more than 80%of episodes run.",https://ieeexplore.ieee.org/document/8956259/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/ICRA48506.2021.9561941,A Robot Walks into a Bar: Automatic Robot Joke Success Assessment,IEEE,Conferences,"Effective social robots should leverage humor’s unique ability to improve relationship connections and dispel stress, but current robots possess limited (if any) humorous abilities. In this paper, we aim to supplement one aspect of autonomous robots by giving robotic systems the ability to ""read the room"" to assess how their humorous statements are received by nearby people in real time. Using a dataset of the audio of crowd responses to a robotic comedian over multiple performances (first presented in past work), we establish human-labeled joke success ground truths and compare individual human rater accuracy against the outputs of lightweight Machine Learning (ML) approaches that are easy to deploy in real-time joke assessment. Our results indicate that all three ML approaches (naïve Bayes, support vector machines, and single-hidden-layer feedforward neural networks) performed significantly better than the baseline approach used in our past work. In particular, support vector machines and neural network approaches are comparable to a human rater in the task of assessing if a joke failed or not in certain cases. The products of this work will inform self-assessment techniques for robots and help social robotics researchers test their own assessment methods on realistic data from human crowds.",https://ieeexplore.ieee.org/document/9561941/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ROBIO.2006.340185,A Study of real-time EMG-driven Arm Wrestling Robot,IEEE,Conferences,"An EMG-driven arm wrestling robot (AWR) is being developed in our laboratories for the purposes of studying neuromuscular control of arm movements. The AWR arm have 2-DOF, integrated with mechanical arm, elbow/wrist force sensors, servo motor, encoder, 3-D MEMS accelerometer, and USB camera, is used to estimate tension developed by individual muscles based on recorded electromyograms (EMGs). The surface electromyographic signal form the upper limb is sampled from a real player in same conditions. By using the method of wavelet packet transformation (WPT) and auto regressive model (AR), the characteristics of EMG signals can be extracted. Artificial neural network is adopted to estimate the elbow joint torque. The effectiveness of the humanoid algorithm using torque control estimated via WRT and neural network is confirmed by experiments. The purpose of this paper is to describe the design objectives, fundamental components and implementation of our real-time, EMG-driven AWR arm.",https://ieeexplore.ieee.org/document/4142107/,2006 IEEE International Conference on Robotics and Biomimetics,17-20 Dec. 2006,ieeexplore
10.1109/ICSAI.2018.8599325,A Visual System of Citrus Picking Robot Using Convolutional Neural Networks,IEEE,Conferences,"To realize automatic fruit harvesting, there have been a lot of approaches of engineering since 1960s. However, for the complex natural environment, the study of robotic harvesting systems is still on the developing. In this paper, we propose to use several deep learning methods, which are the-state-of-the-art techniques of pattern recognition, to raise the accuracy of the citrus discrimination by visual sensors. The proposed methods include YOLOv3, ResNet50, and ResNet152, which are the advanced deep convolutional neural networks (CNNs). For the powerful ability of pattern recognition of these CNNS, the proposed visual system is able to distinguish not only citrus fruits but also leaves, branches, and fruits occluded by branch or leaves, and these functions are important for picking work of harvesting robot in the real environment. The recognition abilities of the three CNNs were confirmed by the experiment results, and ResNet152 showed the highest recognition rate. The recognition accuracy of the normal citrus in the natural environment was 95.35%, overlapped citrus fruits reached 97.86%, and 85.12% in the cases of leaves and branches of citrus trees.",https://ieeexplore.ieee.org/document/8599325/,2018 5th International Conference on Systems and Informatics (ICSAI),10-12 Nov. 2018,ieeexplore
10.1109/ROMAN.1995.531972,A basic study on dynamic control of facial expressions for Face Robot,IEEE,Conferences,"In order to develop an active human interface that realizes ""hear-to-heart"" virtual communication between an intelligent machine and human being, we have already reported the ""Face Robot"" which has a human-like face and can display facial expressions similar to that of a human being by using a flexible microactuator (FMA). For realizing real-time communication between intelligent machine and human being, the Face Robot must express its facial expressions at the almost same speed and in the same manner as a human being. However it is found that FMA can not cope with this kind of performance in expressing dynamic facial features. This paper deals with the development of new mini-actuator ""ACDIS"" for real-time display of Face Robot's facial expressions and also their control method. The developed double action piston type actuator is able to measure the displacement of the position in ACDIS by equipping a LED and a photo-transistor inside it. The opening time of the electro-magnetic valve is regulated for the displacement control of ACDIS by a PD control algorithm. The ACDIS is found to have sufficient performance in the speed of piston-movement and we undertake the experiment of real-time facial expression on the Face Robot and confirm that the display of human-like facial expression is successfully realized.",https://ieeexplore.ieee.org/document/531972/,Proceedings 4th IEEE International Workshop on Robot and Human Communication,5-7 July 1995,ieeexplore
10.1109/CEC.2003.1299627,A classifier system in real applications for robot navigation,IEEE,Conferences,"This paper presents an autonomous evolutionary system applied to control a mobile robot in unknown environments. The navigation system learns efficiently to deal with situations where the robot must capture targets avoiding collisions with obstacles. Toward this end, robot direction and speed must be properly defined. The evolutionary approach is based on a version of classifier systems, responsible for the proposition of a competitive process involving rules of elementary behaviour. A virtual environment is used to evolve the controller, a Khepera II robot is submitted to real navigation tasks, with no significant degradation in performance. As an additional experiment, the controller is also evolved in a real environment, and validated in a different and more complex environment, not previously experimented, attesting the generalization capability of the proposal.",https://ieeexplore.ieee.org/document/1299627/,"The 2003 Congress on Evolutionary Computation, 2003. CEC '03.",8-12 Dec. 2003,ieeexplore
10.1109/ROBOT.1998.676374,A control architecture to achieve manipulation task goals for a humanoid robot,IEEE,Conferences,"Focusing on the manipulation tasks to be executed by humanoid robots, principal requirements which are to be satisfied by hardware/software of the control system are considered. In order to meet the requirements, a novel type of hardware structure and software architecture is proposed. Since the target humanoid robot consists of multiple subsystems such as a central controller for brain, a vision controller for eye, and five motion sub-controllers for two arms, two hands, one spine, the on-board hardware control system is designed to have a distributed control structure connected by pseudo real-time Ethernet interfaces. A goal-achieving software architecture is also proposed which meets the requirements of semi-autonomy, reactivity, expandability, and object-orientedness. Specifically, in order to achieve reactivity, a coordination method is proposed to configure three kinds of executive modules, primitive module, flow-control module, and goal module, which have multiple exit states. The control architecture proposed has been implemented for performing toy-block assembly tasks on a humanoid robot as well as on the graphic simulator.",https://ieeexplore.ieee.org/document/676374/,Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),20-20 May 1998,ieeexplore
10.1109/ICRA.2012.6225245,A depth space approach to human-robot collision avoidance,IEEE,Conferences,"In this paper a real-time collision avoidance approach is presented for safe human-robot coexistence. The main contribution is a fast method to evaluate distances between the robot and possibly moving obstacles (including humans), based on the concept of depth space. The distances are used to generate repulsive vectors that are used to control the robot while executing a generic motion task. The repulsive vectors can also take advantage of an estimation of the obstacle velocity. In order to preserve the execution of a Cartesian task with a redundant manipulator, a simple collision avoidance algorithm has been implemented where different reaction behaviors are set up for the end-effector and for other control points along the robot structure. The complete collision avoidance framework, from perception of the environment to joint-level robot control, is presented for a 7-dof KUKA Light-Weight-Robot IV using the Microsoft Kinect sensor. Experimental results are reported for dynamic environments with obstacles and a human.",https://ieeexplore.ieee.org/document/6225245/,2012 IEEE International Conference on Robotics and Automation,14-18 May 2012,ieeexplore
10.1109/SSCI.2016.7849899,A fuzzy-based machine learning model for robot prediction of link quality,IEEE,Conferences,"With foresight into the state of the wireless channel, a robot can make various optimization decisions with regards to routing packets, planning mobility paths, or switching between diverse radios. However, the process of predicting link quality (LQ) is nontrivial due to the streaming and dynamic nature of radio wave propagation, which is complicated by robot mobility. Due to robot movement, the wireless propagation environment can change considerably in terms of distance, obstacles, noise, and interference. Therefore, LQ must be learned and regularly updated while the robot is online. However, the existing fuzzy-based models for assessing LQ are non-adaptable due to the absence of any learning mechanism. To address this issue, we introduce a fuzzy-based prediction model designed for the efficient online and incremental learning of LQ. The unique approach uses fuzzy logic to infer LQ based on the collective output from a series of offset classifiers and their posterior probabilities. In essence, the proposed model leverages machine learning for extracting the underlying functional relationship between the input and output variables, but deeper inferences are made from the output of the learning algorithms using fuzzy logic. Wireless link data from a real-world robot network was used to compare the model with the traditional linear regression approach. The results show statistically significant improvements in three out of the six real-world indoor and outdoor environments where the robot operated. Additionally, the novel approach offers a number of other benefits, including the flexibility to use fuzzy logic for model tuning, as well as the ability to make implementation efficiencies in terms of parallelization and the conservation of labeling resources.",https://ieeexplore.ieee.org/document/7849899/,2016 IEEE Symposium Series on Computational Intelligence (SSCI),6-9 Dec. 2016,ieeexplore
10.1109/ICCE-Asia.2016.7804752,A hardware architecture of face detection for human-robot interaction and its implementation,IEEE,Conferences,"This paper presents hardware architecture with low-complexity face detection (FD) and parallel processing of local binary pattern (LBP) generation and adaptive boosting (AdaBoost) algorithm using Haar features for the intelligent service robot system. We designed a fully pipelined architecture implemented with the design techniques, such as variable image scaling and parallel processing multiple classifiers without integral image generation, on the FPGA platform. The proposed architecture enables a real-time FD processing for a VGA video at 30 frames per second.",https://ieeexplore.ieee.org/document/7804752/,2016 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia),26-28 Oct. 2016,ieeexplore
10.1109/ICCAE.2010.5451340,A low cost microcontroller implementation of neural network based hurdle avoidance controller for a car-like robot,IEEE,Conferences,This paper describes the implementation of a neural network based hurdle avoidance controller for a car like robot using a low cost single chip 89C52 microcontroller. The neural network is the multilayer feed-forward network with back propagation training algorithm. The network is trained offline with tangent-sigmoid as activation function for neurons and is implemented in real time with piecewise linear approximation of tangent-sigmoid function. Results have shown that up-to twenty neurons in hidden layer can be deployed with the proposed technique using a single 89C52 microcontroller. The vehicle is tested in various environments containing obstacles and is found to avoid obstacles in its path successfully.,https://ieeexplore.ieee.org/document/5451340/,2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE),26-28 Feb. 2010,ieeexplore
10.1109/ROBOT.2001.933206,A method for obstacle avoidance and shooting action of the robot soccer,IEEE,Conferences,"A fuzzy-obstacle-avoidance-path algorithm for obstacle avoidance and a procedure for the shooting action of a soccer robot based on this algorithm are proposed. This algorithm contains a fuzzy system that is used to estimate the rotational velocity of the soccer robot. To demonstrate the effectiveness and applicability of the proposed method, two simulations are presented and a real-time implementation is developed.",https://ieeexplore.ieee.org/document/933206/,Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164),21-26 May 2001,ieeexplore
10.1109/ICIPS.1997.669208,A neural network approach to the elimination of road shadow for outdoor mobile robot,IEEE,Conferences,"A new method of road tracking oriented environmental noise elimination is presented for implementing navigation and control of land autonomous vehicles (ALV). The concept of vision based environmental noise is firstly introduced for the purpose of road and/or obstacle edge detection. Then, a representation of pyramid is proposed for vision processing. Furthermore, a fuzzy neural network is designed and implemented to recognize the environmental noises such as shadow and water prints on the road. With structure optimization by genetic algorithm and special training by classified samples, we use the network to guide our THMR-III (Tsinghua University Mobile Robot, Model 3) in the outdoor real world. Experiments have shown good properties for the ALV's ""perception-action"" behaviors, including obstacle avoidance, road following, wandering, etc. Although the work is still going on, we can see from the present results the better quality, adaptability and robustness of the above approach.",https://ieeexplore.ieee.org/document/669208/,1997 IEEE International Conference on Intelligent Processing Systems (Cat. No.97TH8335),28-31 Oct. 1997,ieeexplore
10.1109/IACC.1995.465839,A neural network system that controls and plans paths for a robot,IEEE,Conferences,"Proposes to solve the problems of direct/inverse kinematics and control of trajectories by multilevel perceptrons. The authors' solution admits a parallel implementation in real time. It does not need either to solve kinematic equations or robot trajectories, because it learns gradually by examples adaptively. The control system consists of different networks each of which specialises in solving a particular problem. This structure enables a modular approach to the problem accelerating convergence. The system obtains an acceptable trajectory and gives a parallel solution that could be used in real-time applications.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/465839/,Proceedings of IEEE/IAS International Conference on Industrial Automation and Control,5-7 Jan. 1995,ieeexplore
10.1109/ICSMC.1995.538227,A neural network-based robot safety system,IEEE,Conferences,"This paper presents a new approach for real-time robot safety system based on artificial neural networks. This approach includes a neural network detection unit and a neural network decision unit, implemented at an intermediate and high level of sensory processing, respectively. Both the detection and decision units have been implemented and tested by simulation, both separately and as an integrated unit. The response time of the integrated system measured on the 90 MHz, P5 microprocessor is less than 11 ms, and the correctness of safety decisions is 97%.",https://ieeexplore.ieee.org/document/538227/,"1995 IEEE International Conference on Systems, Man and Cybernetics. Intelligent Systems for the 21st Century",22-25 Oct. 1995,ieeexplore
10.1049/cp:19990285,A neural vision based controller for a robot footballer,IET,Conferences,"Robot football is growing in popularity both as a research topic and as a sporting event. The football setting provides rich interaction possibilities and a ready source of competition in an environment containing both predictable and non-deterministic elements. Successful players must be able to react quickly in real time, exhibit multiple competences and choose between several possibly conflicting goals. Opportunities exist to explore reflexive behaviour, strategic behaviour and even communication and social behaviour in team events. At the same time, artificial neural networks are increasingly being used in robot controllers to explore new biologically-inspired ideas relating to perception, memory and motor control. The research described in this paper attempts to combine these two areas of study to produce a framework for a neurally based and visually guided football-playing controller. A controller architecture is proposed in which a small set of high-level features in the robot's environment are extracted from raw image data by using a feedforward neural network. These feature signals, collectively termed the ""feature bus"", are then available for use by other controller modules. The feature bus signals are sufficiently general and high-level to be used with many different controller strategies, and their low dimensionality compared to the raw visual input makes the implementation of learning controllers more feasible.",https://ieeexplore.ieee.org/document/791354/,"Image Processing And Its Applications, 1999. Seventh International Conference on (Conf. Publ. No. 465)",13-15 July 1999,ieeexplore
10.1109/IJCNN.2015.7280750,A neurocomputational model implemented on humanoid robot for learning action selection,IEEE,Conferences,"Computational modeling of neural circuits enhances our comprehension of brain functions. In addition to the simulation of the models which helps to anticipate cognitive processes, embodiment of these models is essential. Such embodiment would provide the setting to explain neural functioning ongoing in real environments under oncoming sensory information besides giving opportunity of implementation of intelligent systems. Even studies pursued in neuroscience seem far from achieving all these aims in intelligent systems, the pre-results using cognitive models are faster than animal experiments in leading further the understanding of cognitive processes and designing related experiments. In this study, a computational model of basal ganglia, thalamus and cortex for action selection is extended with the point neuron approach to obtain a more realistic method to investigate the model in real time task on humanoid robot platform, Darwin-Op. The spiking neural network model of cortex consists of channels for each action to be elected and plastic alI-to-alI connections from the sensory stimuli to the basal ganglia structures which are modulated with reward. In the task, the sensory inputs, namely colors, are presented to the humanoid robot and it is expected that these sensory inputs would be associated with the predefined actions by modulating the connections. Furthermore, the rearrangement of these associations with reward is performed after learning is accomplished. In this way, the embodiment of computational-model provided more information on the evolution of connections through reward based learning in the action selection circuit.",https://ieeexplore.ieee.org/document/7280750/,2015 International Joint Conference on Neural Networks (IJCNN),12-17 July 2015,ieeexplore
10.1109/ROBIO.2013.6739654,A new method for mobile robot arm blind grasping using ultrasonic sensors and Artificial Neural Networks,IEEE,Conferences,"The paper presents a new method to realize mobile robot arm grasping in indoor laboratory environments. This method adopts a blind strategy, which does not need the robot arms be mounted any kind sensors and avoid calculating the complex kinematic equations of the arms. The method includes: (a) two robot on-board ultrasonic sensors in base are utilized to measure the distances between the robot base and the front arm grasping tables; (b) an Artificial Neural Networks (ANN) is proposed to learn/establish the nonlinear relationship between the ultrasonic distances and the joint controlling values. After executing the training step using sampling data, the ANN can forecast/generate the next-step joint controlling values fast and accurately by inputting a new pair of real-time ultrasonic measured distances; (c) to let the blind strategy matching with the transportation process, an arm controlling component with user interfaces is developed; and (d) a method named training arm is adopted to prepare the training data for the training procedure of the ANN model. Finally, an experiment proves that the proposed strategy has good performance in both of the accuracy and the real-time computation, which can be applied to the real-time arm operations for the mobile robot transportation in laboratory automation.",https://ieeexplore.ieee.org/document/6739654/,2013 IEEE International Conference on Robotics and Biomimetics (ROBIO),12-14 Dec. 2013,ieeexplore
10.1109/ICWAPR.2007.4420737,A new method of distance estimation for robot localization in real environment based on manifold learning,IEEE,Conferences,"A new distance estimation method for robot autonomous localization from high-dimensional camera images is proposed based on 4 popular manifold learning algorithms. The camera images are supposed to embed in a high-dimensional manifold, and then the dimension is reduced to estimate the corresponding coordinate of the robot. Two experiments show that the distance is estimated regardless of the illumination, motion noise and environment geometric features. Experiment results with 3 image sets acquiring from the real environment verify the feasibility and effectiveness of the scheme and algorithms proposed in this paper.",https://ieeexplore.ieee.org/document/4420737/,2007 International Conference on Wavelet Analysis and Pattern Recognition,2-4 Nov. 2007,ieeexplore
10.1109/WINCOM50532.2020.9272477,A new middleware for managing heterogeneous robot in ubiquitous environments,IEEE,Conferences,"Heterogeneity is one of the main issues for the deployment of the Industry 4.0. This is due to the diversity in the available robots and the IIoT devices. These equipments use different programming languages and communication protocols. To make the integration of such equipments easy, we propose TalkRoBots, a middleware that allows heterogeneous robots and IIoT devices to communicate together and exchange data in a transparent way. The middleware was experimented in a real scenario with different robots that demonstrate its efficiency.",https://ieeexplore.ieee.org/document/9272477/,2020 8th International Conference on Wireless Networks and Mobile Communications (WINCOM),27-29 Oct. 2020,ieeexplore
10.1109/SNPD.2016.7515880,A novel fuzzy omni-directional gait planning algorithm for biped robot,IEEE,Conferences,"Aiming at the problems in gait planning of the biped robots, including the complex model, low stability, etc., a novel fuzzy omni-directional gait planning algorithm (FOGPA) is proposed. At first, this method puts forward a new separated omni-directional gait planning model, which combines the straight walking planning algorithm based on the improved Hermite interpolation and the rotation motion together. And then, a fuzzy gait parameter adjustment algorithm is put forward to control the gait parameters including the step size and rotation speed dynamically. At last, the fuzzy control results are used to get the gait data of robot real-timely. The experiment results show that the FOGPA improves the stability and robustness of gait in a certain degree and also improves the adaptability to the complex environment of the robot.",https://ieeexplore.ieee.org/document/7515880/,"2016 17th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",30 May-1 June 2016,ieeexplore
10.1109/ICMLC.2011.6016883,A novel intelligent control system design for a humanoid robot,IEEE,Conferences,"This paper presents the design of an intelligent control system for a humanoid robot. A novel fuzzy cerebellar model articulation controller (FCMAC) is proposed; this controller incorporates the fuzzy system inference rule with a CMAC fast learning ability. This FCMAC is a generalization network; in some special cases it can be reduced to a fuzzy neural network or a CMAC. This FCMAC is used as the main controller for the trajectory tracking control of the robot. In this robotic system, an inertial navigation system (INS) including gyroscopes and accelerometers is used to measure the robot's attitude and acceleration for modifying the dynamic attitude of the robot. Moreover, a zero moment point (ZMP) compensator is used to on-line adjust the gait trajectories to improve the walking stability. The control system is implemented based on system on a programmable chip (SoPC) technology. Thus, this intelligent control system can achieve real-time on-line closed-loop feedback control of the humanoid robot. Experimental results show that the developed system can achieve favorable control performance for a high-order nonlinear humanoid robot.",https://ieeexplore.ieee.org/document/6016883/,2011 International Conference on Machine Learning and Cybernetics,10-13 July 2011,ieeexplore
10.1109/PEAM.2011.6135058,A novel on-line training solution using a Radial Basis Function Network to modify the inverse kinematic approximation of a robot-vision system,IEEE,Conferences,"This paper describes a new practical approach for approximating the inverse kinematics of a manipulator using an RBFN (Radial Basis Function Network). This neural network with its inherent learning ability can be an effective alternative solution for the inverse kinematics problem where traditional methods are impractical because the manipulator geometry cannot be easily determined, e.g. in a robot-vision system. However, sometimes a well-trained network cannot work effectively in the operational phase because the initial network training occurs in an environment that is not exactly the same as the environment where the system is actually deployed. In this paper, an on-line retraining solution using the Delta rule is presented for systems whose characteristics change due to environmental variations. Moreover, a “free interference rule” is also suggested to avoid learning interference where the training effect of a current training point may upset some of the weights which were trained with previous points. To verify the performance of the proposed approach, a practical experiment has been performed using a Mitsubishi PA10-6CE manipulator observed by a webcam. All application programmes, such as robot servo control, neural network, and image processing tool, were written in C/C++ and run in a real robotic system. The experimental results prove that the proposed approach is effective.",https://ieeexplore.ieee.org/document/6135058/,2011 IEEE Power Engineering and Automation Conference,8-9 Sept. 2011,ieeexplore
10.1109/ICSMC.1999.812484,A paradigm for intelligent motion planning of robot manipulators,IEEE,Conferences,"A paradigm for intelligent motion planning of robot manipulators is presented, and its implementation by some unconventional (AI, soft computing, computational intelligence) techniques is outlined. The article focuses on those aspects that lead, from an intelligent/unconventional point of view, to a unified framework for real-time motion planning, singularities prevention, and/or pseudoinverse robustness.",https://ieeexplore.ieee.org/document/812484/,"IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028)",12-15 Oct. 1999,ieeexplore
10.1109/IECON.1993.339087,A planning architecture for intelligent robot: fuzzy memory-based reasoning for real-time planning/control,IEEE,Conferences,"Our research's main objective is to design an architecture prototype to govern an intelligent robot which can work quickly and efficiently in a vague dynamical environment, typically where various robots and human cooperate each other to accomplish a common global goal. To realize such kind of system, a new planning and control architecture with abilities of real-time control and easy implementation of control knowledge is required. The architecture proposed here is based on the idea of memory-based reasoning systems and behavior-based control systems. Then, to confirm its performance, a simple simulation example of two mobile robots that cooperate to capture a target is showed.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/339087/,Proceedings of IECON '93 - 19th Annual Conference of IEEE Industrial Electronics,15-19 Nov. 1993,ieeexplore
10.1109/ROBIO.2014.7090487,A portable stand-alone bi-hemispherical neuronal network model of the cerebellum for adaptive robot control,IEEE,Conferences,"Development of computational models of the brain is relevant not only for deepening our understanding of the biological system but also for potential applications to various engineering problems. In this paper the implementation of a bi-hemispherical neuronal network model of the cerebellum (biCNN) in a stand-alone, portable real time (RT) device is presented. The biCNN is tested during a control engineering application, namely, control of a highly unstable two-wheel balancing robot. The RT device considered is the National Instruments myRIO-1900, which provides flexibility and portability to the biCNN. Execution times obtained with the RT device are compared with a personal computer implementation as reference. The results demonstrate the suitability of the RT implementation of the biCNN for robot control, and provide a successful bridge between the cerebellar research and engineering.",https://ieeexplore.ieee.org/document/7090487/,2014 IEEE International Conference on Robotics and Biomimetics (ROBIO 2014),5-10 Dec. 2014,ieeexplore
10.1109/ICCAS.2015.7364829,A precise position control of robot manipulator with eight joints,IEEE,Conferences,"We describe a new approach to the design and real-time implementation of an adaptive controller for robotic manipulator based on digital signal processors in this paper. The Texas Instruments DSPs(TMS320C80) chips are used in implementing real-time adaptive control algorithms to provide enhanced motion control performance for dual-arm robotic manipulators. In the proposed scheme, adaptation laws are derived from model reference adaptive control principle based on the improved direct Lyapunov method. The proposed adaptive controller consists of an adaptive feed-forward and feedback controller and time-varying auxiliary controller elements. The proposed control scheme is simple in structure, fast in computation, and suitable for real-time control. Moreover, this scheme does not require any accurate dynamic modeling, nor values of manipulator parameters and payload. Performance of the proposed adaptive controller is illustrated by simulation and experimental results for robot manipulator consisting of dual arm with four degrees of freedom at the joint space and cartesian space.",https://ieeexplore.ieee.org/document/7364829/,"2015 15th International Conference on Control, Automation and Systems (ICCAS)",13-16 Oct. 2015,ieeexplore
10.1109/IROS.1998.727453,A real-time library for the design of hybrid robot control architectures,IEEE,Conferences,"Describes a real-time library providing facilities useful in the design of robot control architectures. The library supports structured creation of reactive and deliberative modules, dynamic modification of relevant real-time parameters, generation of timing fault handlers, measurement and monitoring of execution times. This support enables adaptation of the rate of computation of real-time modules to the rate of change of the external world, and hence better tuning of robot behavior to the world uncertainty and dynamics. The real-time library has been put to work by designing a hybrid control architecture for a robot performing a kitting task. In the prototype experiment described in the paper, a Puma 560 robot manipulator is fed with parts by a small mobile robot. The control architecture governing Puma operations dynamically allocates computational resources to reactive and deliberative modules, according to the task level priorities.",https://ieeexplore.ieee.org/document/727453/,"Proceedings. 1998 IEEE/RSJ International Conference on Intelligent Robots and Systems. Innovations in Theory, Practice and Applications (Cat. No.98CH36190)",17-17 Oct. 1998,ieeexplore
10.1049/cp.2012.0975,A robot dance system based on real-time beat prediction,IET,Conferences,"In this paper, we present a robot with a system of tracking beats and downbeats from musical audio in real time as well as automatically synthesizing dance motions synchronized to the extracted musical events. And a real-time beat prediction approach improved by an off-line analysis is described, which has positive effects on the estimations of beat and downbeat. We also make an attempt to solve the problem of enabling a robot to understand the played music and accomplish dance compositions intelligently itself. Consequently, the experimental results are quite encouraging and show that our implemented robot, to some extent, has the ability of dancing in time to the music.",https://ieeexplore.ieee.org/document/6492582/,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),3-5 March 2012,ieeexplore
10.1109/IROS.2003.1250667,A robot that reinforcement-learns to identify and memorize important previous observations,IEEE,Conferences,"It is difficult to apply traditional reinforcement learning algorithms to robots, due to problems with large and continuous domains, partial observability, and limited numbers of learning experiences. This paper deals with these problems by combining: (1) reinforcement learning with memory, implemented using an LSTM recurrent neural network whose inputs are discrete events extracted from raw inputs; (2) online exploration and offline policy learning. An experiment with a real robot demonstrates the methodology's feasibility.",https://ieeexplore.ieee.org/document/1250667/,Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453),27-31 Oct. 2003,ieeexplore
10.1145/1957656.1957782,A robotic game to evaluate interfaces used to show and teach visual objects to a robot in real world condition,IEEE,Conferences,"In this paper, we present a real world user study of 4 interfaces designed to teach new visual objects to a social robot. This study was designed as a robotic game in order to maintain the user's motivation during the whole experiment. Among the 4 interfaces 3 were based on mediator objects such as an iPhone, a Wiimote and a laser pointer. They also provided the users with different kind of feedback of what the robot is perceiving. The fourth interface was a gesture based interface with a Wizard-of-Oz recognition system added to compare our mediator interfaces with a more natural interaction. Here, we specially studied the impact the interfaces have on the quality of the learning examples and the usability. We showed that providing non-expert users with a feedback of what the robot is perceiving is needed if one is interested in robust interaction. In particular, the iPhone interface allowed non-expert users to provide better learning examples due to its whole visual feedback. Furthermore, we also studied the user's gaming experience and found that in spite of its lower usability, the gestures interface was stated as entertaining as the other interfaces and increases the user's feeling of cooperating with the robot. Thus, we argue that this kind of interface could be well-suited for robotic game.",https://ieeexplore.ieee.org/document/6281349/,2011 6th ACM/IEEE International Conference on Human-Robot Interaction (HRI),8-11 March 2011,ieeexplore
,A robust control of mobile robot based on sonar sensors,IEEE,Conferences,"This paper describes the design and real implementation of wall following and fuzzy perception concept with a non-holonomic mobile robot named KHAN-Robo. The main focus of this paper is obtaining a fuzzy perception of the environment in the design of each reactive behavior and solving the problem of behavior combination to implement a fuzzy behavior based control architecture. It should be remarked that, the proposed technique of the nonholonomic constraints are considered in the design of each behavior. Furthermore, in order to improve the capabilities of the intelligent control system and its practical applicability, teleoperation and planned behaviors, together with their combination with reactive ones, have been considered. Experimental results, of an application to control the KHAN-Robo autonomous vehicle, demonstrate the robustness of the proposed method.",https://ieeexplore.ieee.org/document/6106329/,"2011 11th International Conference on Control, Automation and Systems",26-29 Oct. 2011,ieeexplore
10.1109/MFI-2003.2003.1232590,A robust real time position and force (hybrid) control of a robot manipulator in presence of uncertainties,IEEE,Conferences,"We examine the living intelligent biological systems and model the computational system components. We consider the situation of a kind of ""blind-tracking"" with constant force/torque by a human hand. The problem involves hand kinematics, hand motor control, and an adaptive judgment method from the position and force/torque reflection of the uncertain hyper plane. In this study, these control levels were designed using neural networks and fuzzy logic technologies. The control levels are coordinated amongst themselves forming the distributed artificial intelligent (DAI) system. The conclusive characteristic of the proposed controller was a one-step-ahead feedback control. This DAI-based control systems was implemented in the RX-90 industrial robot. Certainly these types of control system will help an industry to be autonomous and increase the productivity as well.",https://ieeexplore.ieee.org/document/1232590/,"Proceedings of IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems, MFI2003.",1-1 Aug. 2003,ieeexplore
10.1109/IJCNN.2017.7965912,A self-driving robot using deep convolutional neural networks on neuromorphic hardware,IEEE,Conferences,"Neuromorphic computing is a promising solution for reducing the size, weight and power of mobile embedded systems. In this paper, we introduce a realization of such a system by creating the first closed-loop battery-powered communication system between an IBM Neurosynaptic System (IBM TrueNorth chip) and an autonomous Android-Based Robotics platform. Using this system, we constructed a dataset of path following behavior by manually driving the Android-Based robot along steep mountain trails and recording video frames from the camera mounted on the robot along with the corresponding motor commands. We used this dataset to train a deep convolutional neural network implemented on the IBM NS1e board containing a TrueNorth chip of 4096 cores. The NS1e, which was mounted on the robot and powered by the robot's battery, resulted in a self-driving robot that could successfully traverse a steep mountain path in real time. To our knowledge, this represents the first time the IBM TrueNorth has been embedded on a mobile platform under closed-loop control.",https://ieeexplore.ieee.org/document/7965912/,2017 International Joint Conference on Neural Networks (IJCNN),14-19 May 2017,ieeexplore
10.1109/ICCITECHN.2016.7860248,A support vector machine approach for real time vision based human robot interaction,IEEE,Conferences,"Today humanoid robots are being exhibited to redact various task as a personal assistant of a human. To be an assistant, a robot needs to interact with human as a human. For this reason robot needs to understand the human gender, facial expression, facial gesture in real time. Ribo - A humanoid robot build in RoboSUST lab which has the ability to communicate in Bangla with the people speaking in Bengali. In this article the authors show the implementation of theoretical knowledge of the recognition of real time facial expression, detection of human gender and yes / no from facial gesture in Ribo. Real time facial expression and gender detection can be performed using Support Vector Machine (SVM). A prepared dataset containing the facial landmarks leveled as five different expression: sad, angry, smile, surprise and normal, is given to SVM to construct a classifier. For the prediction of any expression, facial images are taken in real time and provided the facial landmarks data to SVM. Local Binary Pattern(LBP) algorithm is used for extracting features from face images. These features leveled as male and female are responsible to build the classifier. The face gesture for detecting `yes/no' is performed by tracking the movement of face in a certain time. After those implementations the principal results will make a framework that will be used in Ribo to recognize human facial expression, facial gesture movement and detect human gender.",https://ieeexplore.ieee.org/document/7860248/,2016 19th International Conference on Computer and Information Technology (ICCIT),18-20 Dec. 2016,ieeexplore
10.1109/IJCNN.2004.1379924,A virtual exploring mobile robot for left ventricle contour tracking,IEEE,Conferences,"In this paper we describe a totally new and original approach for combining global and local information in medical image processing. We implemented a virtual mobile robot and trained it using fuzzy neural networks to recognize segments of the myocardium while he navigates autonomously around the left ventricle (LV) of the heart. On its journey around the heart, the virtual exploring robot applies appropriate local edge detection to delineate fully automatically the borders of the myocardium. This may sound unconventional but it has proven effective enough to be integrated in a clinical analytical software tool.",https://ieeexplore.ieee.org/document/1379924/,2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541),25-29 July 2004,ieeexplore
10.1109/IROS.1998.724594,A virtual target approach for resolving the limit cycle problem in navigation of a fuzzy behaviour-based mobile robot,IEEE,Conferences,"A virtual target approach is proposed for resolving the limit cycle problem in navigation of a behaviour-based mobile robot. Starting from the onset point of a possible limit cycle path, the real target is switched to a virtual location and the robot is navigated according to the virtual target set up temporarily and the real environment information sensed, until a switching back condition is reached. The condition for switching back to the real target is established using a specific change in the obstacle information sensed. The algorithm is described together with some particular considerations in implementation. Efficiency and effectiveness of the proposed approach are verified through simulation and experiments conducted with a Nomad 200 robot incorporating a fuzzy, behaviour-based controller.",https://ieeexplore.ieee.org/document/724594/,"Proceedings. 1998 IEEE/RSJ International Conference on Intelligent Robots and Systems. Innovations in Theory, Practice and Applications (Cat. No.98CH36190)",17-17 Oct. 1998,ieeexplore
10.1109/SMC.2019.8914201,A3C Based Motion Learning for an Autonomous Mobile Robot in Crowds,IEEE,Conferences,"The paper proposes a motion planning method using a deep reinforcement learning algorithm, Asynchronous Advantage Actor-Critic (A3C). For mobile robot navigation tasks in crowds, existing path planning based approaches are limited because the surrounding environments change dynamically. The correct motion in such a dynamic environment is underspecified, and a reinforcement learning approach is suitable for generating applicable motion. We propose an A3C based motion planning method for acquiring robot motion for a robot moving through crowds. The proposed method is evaluated in simulated crowds of pedestrians. The experiment section shows the basic performance depending on training parameters and some generated motion examples in the simulator. The learning results using real pedestrian motion are also shown.",https://ieeexplore.ieee.org/document/8914201/,"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)",6-9 Oct. 2019,ieeexplore
10.1109/OCEANS.2000.882252,Acoustic-based position discrimination of a moving robot,IEEE,Conferences,"A real-world experiment is described, demonstrating the possibility of discriminating positions of a mobile robot moving through an unknown, unprepared office room, solely based on broadband audible acoustic signals. The average distance of distinguishable positions was found to be less than 15 cm. Maximum length sequence measurements are used to obtain the impulse response of the room at the present position, and a modified vector distance measure is used to cluster the data via the Neural Gas algorithm. No further interpretation of the data is performed. The data analysis method is independent of the environment or the recording system (the robot), therefore it is potentially applicable to other environments and vehicles. The method is especially interesting for the navigation of AUVs in unknown environments, as acoustic signals represent a major source of information in the underwater world, being available under the broadest range of circumstances.",https://ieeexplore.ieee.org/document/882252/,OCEANS 2000 MTS/IEEE Conference and Exhibition. Conference Proceedings (Cat. No.00CH37158),11-14 Sept. 2000,ieeexplore
10.1109/IROS.2004.1389844,Acquisition of human-robot joint attention through real-time natural interaction,IEEE,Conferences,"Joint attention, a process to attend to the object that the other attends to is supposed to be important for human-robot communication as well as for human-human communication. We propose an architecture for acquiring joint attention within a certain time period for realizing natural human-robot interaction. The architecture has two featured modules: a self-organizing map that makes the leaning time shorter and an automatic visual attention selector that let the agent communicate with a human synchronously. We implemented the proposed architecture in a real robot agent and found that 30 minutes was enough for acquiring joint attention with two objects. We can conclude from preliminary experiments that even if the gaze preference of the robot is different from that of the human caregiver, it can acquire joint attention.",https://ieeexplore.ieee.org/document/1389844/,2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),28 Sept.-2 Oct. 2004,ieeexplore
10.1109/FUZZ-IEEE.2014.6891705,Active interaction control of a rehabilitation robot based on motion recognition and adaptive impedance control,IEEE,Conferences,"Although electromyography (EMG) signals and interaction force have been widely used in patient cooperative or interactive training, the conventional EMG based control usually breaks the process into a patient-driven phase and a separate passive phase, which is not desirable. In this research, an active interaction controller based on motion recognition and adaptive impedance control is proposed and implemented on a six-DOFs parallel robot for lower limb rehabilitation. The root mean square (RMS) features of EMG signals integrating with the support vector machine (SVM) classifier were used to online predict the lower limb intention in advance and to trigger the robot assistance. The impedance control strategy was adopted to directly influence the robot assistance velocity and allow the exercise to follow a physiological trajectory. Moreover, an adaptive scheme learned the muscle activity level in real time and adapted the robot impedance in accordance with patient's voluntary participation efforts. Experimental results on several healthy subjects demonstrated that the lower limb motion intention can be precisely predicted in advance, and the robot assistance mode was also adjustable based on human-robot interaction and muscle activity level of subjects. Comparing with the conventional EMG-triggered assistance methods, such a strategy can increase patient's motivation because the subject's movement intention, active efforts as well as the muscle activity level changes can be directly reflected in the trajectory pattern and the robot assistance speeds.",https://ieeexplore.ieee.org/document/6891705/,2014 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),6-11 July 2014,ieeexplore
10.1109/ICRoM.2014.6990997,Actor-critic neural network reinforcement learning for walking control of a 5-link bipedal robot,IEEE,Conferences,"Today, researches on adaptive control have focused on bio-inspired learning techniques to deal with real-life applications. Reinforcement Learning (RL) is one of these major techniques, which has been widely used in robot control tasks recently. On the other hand, artificial neural networks are an accurate approximation tool in nonlinear robotic dynamic control tasks. In this paper, our main goal was to combine the advantages of the artificial neural networks and the RL to reduce the learning time length and enhance the control accuracy. Therefore, we have implemented one of the promising RL approaches, actor-critic RL to control the actuation torques of a planar five-link bipedal robot and retain the passive torso in the vertical position. Our control agent consists of two three-layered neural network units, known as the critic and the actor for learning prediction and learning control tasks. These units are synchronized by the temporal difference error, which implements the eligibility trace vector to assign credit or blame for the error. Moreover, since the neural networks are implemented in both of the actor and the critic sections, we have added a learning database to reduce the probability of inaccurate approximation of the nonlinear functions. Results of our presented control method reveal its perfect performance in stable walking control of the bipedal robot.",https://ieeexplore.ieee.org/document/6990997/,2014 Second RSI/ISM International Conference on Robotics and Mechatronics (ICRoM),15-17 Oct. 2014,ieeexplore
10.1109/M2VIP.2017.8211476,Actuation planning and modeling of a soft swallowing robot,IEEE,Conferences,"The paper presents a new methodology to solve the actuation and modelling problems of a soft-bodied swallowing robot (SR), developed for human swallow evaluation. To solve the actuation problem, a central pattern generator (CPG) based novel actuation scheme is developed and implemented to generate peristalsis in the robot. Machine learning based technique is used to determine the governing dynamics of the robot because presently the robot does not have any differential equation to describe its actuation principle or its physics. To profile and sense the peristaltic waveform, a flat version of the robot containing pneumatic chambers for actuation has been proposed to approximate the deformation of the original SR and the CPG actuation scheme is used to command the flat SR so that the pneumatic chambers can be inflated. The logic of actuation is motivated from the swallowing phenomenon in humans, have been implemented in real time. An optical motion detection system (Vicon) is used to track the displacement of the air chambers of the robot and hence, to generate time-series data for determining the governing differential equations of the robot by using l<sub>1</sub> regularised machine learning technique. It is also concluded that the proposed method provides a promising new modelling technique for determining the governing dynamics of the robot where conventional modelling approaches are not applicable.",https://ieeexplore.ieee.org/document/8211476/,2017 24th International Conference on Mechatronics and Machine Vision in Practice (M2VIP),21-23 Nov. 2017,ieeexplore
10.1109/ICCAR52225.2021.9463494,Adaptive Self-Localization System for Low-Cost Autonomous Robot,IEEE,Conferences,"Due to the massive growth in autonomous vehicles, mobile robots applications are more prevalent today. To implement intelligent behaviors, the robot must have the ability to locate itself and adapt to different environments. Despite the recent developments in self-localization, long-term navigation with low-cost robot is still an active area of research. This paper develops a new self-localization system based on Neural Network (NN) method that is fused into a fuzzy logic navigation system using low-cost encoders. The proposed system allows the autonomous mobile robot to adapt itself to different environments and improve its localization based on the trained model. In the experiment, the system is tested with PowerBot robot in different real environments, and compared with one of the most well-known self-localization method (i.e., dead-reckoning). The test is conducted in different set-up to confirm that the proposed system significantly improved the accuracy without the need for additional sensors other than the encoders. It was able to adapt to different environment and accumulatively improved the results.",https://ieeexplore.ieee.org/document/9463494/,"2021 7th International Conference on Control, Automation and Robotics (ICCAR)",23-26 April 2021,ieeexplore
10.1109/IROS.1999.813009,Adaptive behavior acquisition for a distributed autonomous swimming robot based on real-world learning,IEEE,Conferences,"Proposes the construction of a ""strong"" autonomous mobile robot, which can acquire environment oriented behavior through learning, as a distributed autonomous system. It is thought that such a system has many advantages over other systems in terms of adaptability to the environment and so on. However, the potential of this type of system has yet to be demonstrated in experiments under real-world conditions. We conducted an experiment to determine whether a distributed autonomous swimming robot could acquire target-approaching behavior on a water surface which was set as the robot's work space. As a result, from a fairly simple coding, the robot acquired the reproducible target-approaching behavior using only local learning even in cases where a partial fault occurred, and the acquired actions also enabled the robot to approach the target in an environment with a narrow gate.",https://ieeexplore.ieee.org/document/813009/,Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289),17-21 Oct. 1999,ieeexplore
10.1109/IROS.2010.5650226,Adaptive motion control with visual feedback for a humanoid robot,IEEE,Conferences,"The performance of a soccer robot is highly dependent on its motion ability. The kicking motion is one of the most important motions in a soccer game. However, automatic, full body motion generation for humanoid robots presents a formidable computational challenge. At the current state the most common approaches of implementing this motion are based on key frame technique. Such solutions are inflexible, i.e., in order to adjust the aimed direction of the kick the robot has to walk around the ball. The adjustment costs a lot of time especially if some precise adjustments have to be done, e.g., for a penalty kick. In this paper we present an approach for adaptive control of the motions. We implemented our approach in order to solve the task of kicking the ball on a humanoid robot Nao. The approach was tested both in simulation and on a real robot.",https://ieeexplore.ieee.org/document/5650226/,2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,18-22 Oct. 2010,ieeexplore
10.1109/MESA.2016.7587103,Adaptive robust RBFNNs-based model estimator for a small quadrotor aircraft robot,IEEE,Conferences,"This paper presents an on-line estimator that incorporates adaptive MIMO radical basis function neural networks (RBFNNs) for model identification of quadrotor unmanned aerial vehicles (UAVs). The inputs and outputs of quadrotor aircrafts can be obtained from dynamic models or real attitude and position sensors. The adaptive learning rate is employed in the gradient descent method for the update of the weights of RBFNNs, and Lyapunov approach guarantees the stability of the global convergence of the modeling errors. The Welsch functions are also employed as the error functions to get rid of the influence from the noise due to disturbances like wind gusts. Simulation results using Robotics Toolbox for Matlab verify the effectiveness and robustness of the proposed estimator compared with results of traditional RBFNNs. Experiment results from real aircraft platform show that RBFNNs combining adaptive learning rate and Welsch error functions can approximate the overall system with high accuracy and robustness to disturbances.",https://ieeexplore.ieee.org/document/7587103/,2016 12th IEEE/ASME International Conference on Mechatronic and Embedded Systems and Applications (MESA),29-31 Aug. 2016,ieeexplore
10.1109/ICIT.1996.601644,Adaptive robust robot control using BP-SMENs,IEEE,Conferences,"This paper presents the development of a new adaptive recurrent neural network for the control of a nonlinear system represented by a two-link SCARA type planar robot manipulator. The standard backpropagation algorithm is used to adjust the weights of the networks. The proposed control system consists of an inverse neural model of robot (INNM), an INNM-based neural controller, a robust controller, a conventional PI controller, and a second order linear filter. To evaluate the performance of the proposed control scheme and neural network, a simulated SCARA type robot was studied and the results showed how well the proposed controller can minimise the error between an actual and desired end-effector trajectory. From simulation examples, the robot trajectory tracking showed superior performance that is very attractive for real-time implementation and application in complex industrial tasks. For comparison, the standard computed torque method is employed for controlling the robot.",https://ieeexplore.ieee.org/document/601644/,Proceedings of the IEEE International Conference on Industrial Technology (ICIT'96),2-6 Dec. 1996,ieeexplore
10.1109/RAAD.2010.5524575,Adaptive sliding mode controller design for mobile robot fault tolerant control. introducing ARTEMIC.,IEEE,Conferences,"Current real-time applications should timely deliver synchronized data-sets, minimize latency in their response and meet their performance specifications in the presence of disturbances and faults. The adaptive features of the designed controller are present at the lower control level using specific artificial intelligence techniques. Fuzzy inference system design is the fundamental element to generate an adaptive nonlinear controller for the robot operation in the presence of disturbances and modeling inaccuracies. This paper introduces an adaptive real-time distributed control application with fault tolerance capabilities for differential wheeled mobile robots, named ARTEMIC. Specific design, development and implementation details will be provided in this paper.",https://ieeexplore.ieee.org/document/5524575/,19th International Workshop on Robotics in Alpe-Adria-Danube Region (RAAD 2010),24-26 June 2010,ieeexplore
10.1109/ICRA40945.2020.9196582,Adversarial Skill Networks: Unsupervised Robot Skill Learning from Video,IEEE,Conferences,"Key challenges for the deployment of reinforcement learning (RL) agents in the real world are the discovery, representation and reuse of skills in the absence of a reward function. To this end, we propose a novel approach to learn a task-agnostic skill embedding space from unlabeled multi-view videos. Our method learns a general skill embedding independently from the task context by using an adversarial loss. We combine a metric learning loss, which utilizes temporal video coherence to learn a state representation, with an entropy-regularized adversarial skill-transfer loss. The metric learning loss learns a disentangled representation by attracting simultaneous viewpoints of the same observations and repelling visually similar frames from temporal neighbors. The adversarial skill-transfer loss enhances re-usability of learned skill embeddings over multiple task domains. We show that the learned embedding enables training of continuous control policies to solve novel tasks that require the interpolation of previously seen skills. Our extensive evaluation with both simulation and real world data demonstrates the effectiveness of our method in learning transferable skills from unlabeled interaction videos and composing them for new tasks. Code, pretrained models and dataset are available at http://robotskills.cs.uni-freiburg.de.",https://ieeexplore.ieee.org/document/9196582/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ICRA48506.2021.9562117,Agile Robot Navigation through Hallucinated Learning and Sober Deployment,IEEE,Conferences,"Learning from Hallucination (LfH) is a recent machine learning paradigm for autonomous navigation, which uses training data collected in completely safe environments and adds numerous imaginary obstacles to make the environment densely constrained, to learn navigation planners that produce feasible navigation even in highly constrained (more dangerous) spaces. However, LfH requires hallucinating the robot perception during deployment to match with the hallucinated training data, which creates a need for sometimes-infeasible prior knowledge and tends to generate very conservative planning. In this work, we propose a new LfH paradigm that does not require runtime hallucination—a feature we call ""sober deployment""—and can therefore adapt to more realistic navigation scenarios. This novel Hallucinated Learning and Sober Deployment (HLSD) paradigm is tested in a benchmark testbed of 300 simulated navigation environments with a wide range of difficulty levels, and in the real-world. In most cases, HLSD outperforms both the original LfH method and a classical navigation planner.",https://ieeexplore.ieee.org/document/9562117/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ISCSIC.2017.28,An Adaptive 2D Tracking Approach for Person Following Robot,IEEE,Conferences,"In this paper, we present a 2D appearance vision based tracking approach for human following robot. Generally, existing methods have high cost of computing and requirements of hardware which makes the difficulty of employing the function on service robot. Hence, minimizing the cost of tracking with slight loss of precision can benefit this area. We focus on approach based on 2D image data which reduce tracking into two dimensions and can minimize the cost of computation. Our approach presents a corporate strategy which utilizes central consensus of correspondence for 2D feature points pairwise to track and employ a semi-supervised learning detector to update appearance change. To overcome difficulties from environment change, we set an enhancing process for feature points and background segmentation through depth information. We carefully evaluate our approach with common challenges of visual tracking in static view and deploy a dynamic view a real-world following task. The experiment results illustrate that our tracking approach works against common risks at 2D appearance tracking and properly follows the user obtaining 25 fps performance on mobile platform.",https://ieeexplore.ieee.org/document/8294176/,2017 International Symposium on Computer Science and Intelligent Controls (ISCSIC),20-22 Oct. 2017,ieeexplore
10.1109/ICIRCA48905.2020.9182995,An Approach for Digital Farming using Mobile Robot,IEEE,Conferences,"Farming is the backbone of the Indian economy and it has been unchartered territory for a technological solution. As of late developments in Artificial Intelligence technology combined with Robotics has paved the way for an option of digital farming. As a matter of fact, Indian farming has been facing various challenges that include abrupt change in climatic conditions, spoiling of yields, soil nutrient requirement, pests/weed control and so forth. Robotics and Artificial Intelligence (AI) along with the integration of various sensors ensures the possibility of better outcome. In this work the simulation of Mobile robot for the purpose of seed sowing along with its movement has been presented. The implementation comprises of the Motor schema for the navigation of robot and Gale Shapley (GS) algorithm for stable match of seed and yield combination. Such a robotic system combined with AI in real time will form excellent means of farming in terms of yield.",https://ieeexplore.ieee.org/document/9182995/,2020 Second International Conference on Inventive Research in Computing Applications (ICIRCA),15-17 July 2020,ieeexplore
10.1109/COINS51742.2021.9524186,An Edge AI based Robot System for Search and Rescue Applications,IEEE,Conferences,"In this work, we propose an edge AI based robot system that contains drones and multi-legged robots for search and rescue applications. To accurately search for survivors in real-time, we integrate Tiny-YOLO into the drone design. Instead of adopting a microprocessor usually used in a robot, the FPGA device is adopted as the main hardware computing architecture of the multi-legged robot. A resource-efficient quantized neural network is implemented as a hardware module and integrated into the multi-legged robot for real-time detection. When a survivor is detected from robots, the corresponding information about GPS and the triangulation localization is thus delivered to the edge server. Then, rescuers can receive the notification message from the edge server by using their mobile devices. For survivor detection, experiments show the drone and the multi-legged robot can achieve 2.164 fps and 2.404 fps, respectively.",https://ieeexplore.ieee.org/document/9524186/,2021 IEEE International Conference on Omni-Layer Intelligent Systems (COINS),23-25 Aug. 2021,ieeexplore
10.1109/ROBIO.2006.340133,An Extension of the Distance-Propagating Dynamic System for Robot Path Planning to Safe Obstacle Clearance,IEEE,Conferences,"In this paper we extend our previously presented efficient distance-propagating dynamic system for real-time robot path planning in dynamic environments to the case where safety margins around obstacles are included. Inclusion of safety margins approximately triples the number of arithmetic operations, however, the distance-propagating dynamic system is still very computationally efficient. The algorithm uses a grid representation of the environment, which need not be regular, and is applicable to dynamic environments where both targets and obstacles are permitted to move. No prior knowledge of target or obstacle movement is assumed. Safety margins around obstacles are implemented as ""soft"" margins defined by local penalty functions around obstacles which represent the extra distance the robot is willing to travel in order to avoid passing through this margin. The path through which the robot travels minimizes the sum of the current known distance to a target and the cumulative local penalty functions along the path. The effectiveness of the algorithm is demonstrated through a number of simulations.",https://ieeexplore.ieee.org/document/4142070/,2006 IEEE International Conference on Robotics and Biomimetics,17-20 Dec. 2006,ieeexplore
10.1109/RCAR.2018.8621725,An Image Recognition Approach for Coal and Gangue Used in Pick-Up Robot,IEEE,Conferences,"Picking gangue from raw coal is a crucial step of coal production. Due to the potential for replacing manual workers, the study of pick-up robot is attracting much interest. Pick-up robots usually work in fixed working areas where the types of coals and gangues are unitary. Based on this fact, this paper proposes a simple, fast, and easily implemented approach for coal and gangue classification which is LS-SVM (Least Square Support Vector Machine) based using gray scale and texture as features. We firstly sampled the image dataset from Han City, Shaanxi province and Jizhong, Hebei province which are two main mining areas in China. The data of Han City consists of the images of lean coal and shale, and the data of Jizhong is coking coal and sandstone. By analyzing the gray scale and the texture of the sampled data, we discover that coal and gangue vary in the parameters including the mean and peak of gray scale, contrast ratio, and entropy. Therefore, these four parameters are chosen as features. We utilize LS-SVM as the machine learning model, and the model is trained with three groups of parameters separately. The first are the mean and peak of gray scale, the second are the contrast ratio and entropy which represents texture features, and the third are the peak of gray scale and the contrast ratio which integrates gray scale and texture features. After evaluation by using our sampled dataset, the model trained by the third group outperforms others. The classification results were 98.7% correct of coal and 96.6% correct of gangue for the data of Han city, and 98.6% correct of coal and 96.6% correct of gangue for the data of Jizhong.",https://ieeexplore.ieee.org/document/8621725/,2018 IEEE International Conference on Real-time Computing and Robotics (RCAR),1-5 Aug. 2018,ieeexplore
10.1109/ROMAN.2018.8525668,An Ontology-based Home Care Service Robot for Persons with Dementia,IEEE,Conferences,"In this paper, we introduce an ontology-based home care service robot that can provide personalized care for people who are in the early stage of dementia. The hardware and software framework encompassed in the proposed service robot was developed to carry out care services in their daily life at home. Specifically, to generate adaptive task plans in diverse caring situation, context reasoner and ontological model of dementia are included. Ontology includes various concepts that are related with the knowledge of caring dementia patient: dementia, dementia symptom, environment of around patient, and situation during patient's daily life. To evaluate if the proposed service robot could provide appropriate care service or not, experimental care scenario for helping a person with dementia take medicine was tried in the lab environment. Although tasks of the robot required for the experiment are rather simple, we have demonstrated that the robot could provide a personalized service that may be beneficial to dementia patient, family members and caregivers. In the future, we will add more care knowledge in the ontology and further develop a variety of care services. Additionally, we are going to test the care service robot in a real environment with actual dementia patient.",https://ieeexplore.ieee.org/document/8525668/,2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),27-31 Aug. 2018,ieeexplore
10.1109/ROMAN.2012.6343892,An active audition framework for auditory-driven HRI: Application to interactive robot dancing,IEEE,Conferences,"In this paper we propose a general active audition framework for auditory-driven Human-Robot Interaction (HRI). The proposed framework simultaneously processes speech and music on-the-fly, integrates perceptual models for robot audition, and supports verbal and non-verbal interactive communication by means of (pro)active behaviors. To ensure a reliable interaction, on top of the framework a behavior decision mechanism based on active audition policies the robot's actions according to the reliability of the acoustic signals for auditory processing. To validate the framework's application to general auditory-driven HRI, we propose the implementation of an interactive robot dancing system. This system integrates three preprocessing robot audition modules: sound source localization, sound source separation, and ego noise suppression; two modules for auditory perception: live audio beat tracking and automatic speech recognition; and multi-modal behaviors for verbal and non-verbal interaction: music-driven dancing and speech-driven dialoguing. To fully assess the system, we set up experimental and interactive real-world scenarios with highly dynamic acoustic conditions, and defined a set of evaluation criteria. The experimental tests revealed accurate and robust beat tracking and speech recognition, and convincing dance beat-synchrony. The interactive sessions confirmed the fundamental role of the behavior decision mechanism for actively maintaining a robust and natural human-robot interaction.",https://ieeexplore.ieee.org/document/6343892/,2012 IEEE RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication,9-13 Sept. 2012,ieeexplore
10.1109/ICIEV.2012.6317522,An adaptive Neuro-Fuzzy control approach for motion control of a robot arm,IEEE,Conferences,"This paper proposes an adaptive Neuro-Fuzzy control approach for controlling the link variables of a 4 degree-of-freedom Selective Compliant Assembly Robot Arm (SCARA) type robot arm / manipulator. In the real world environment, the mathematical models of many robots are often not accurate, due to the presence of continuous disturbances that effect their dynamic equations, in addition to errors in parameter knowledge. Consequently, method that rely less on precise mathematical models are often preferred. One such Adaptive Machine Learning Technique is proposed to be applied here, for motion control of the robot arm. The controller uses an inverse learning Adaptive Neuro-Fuzzy Inference System (ANFIS) model only to train itself from certain given robot trajectories. Ideally, these trajectories should be obtained by directly measuring the robot arm responses for given inputs to capture the actual dynamics in the presence of all uncertainties. However, for algorithm validation, trajectories generated through simulations based on mathematical models assumed to be reasonably accurate, can also be used for the training purpose. This approach is used for design and implementation of an ANFIS controller which is shown to act work satisfactorily. Further possible developments of this method are also outlined.",https://ieeexplore.ieee.org/document/6317522/,"2012 International Conference on Informatics, Electronics & Vision (ICIEV)",18-19 May 2012,ieeexplore
10.1109/RCAR.2017.8311855,An adaptive gait learning strategy for lower limb exoskeleton robot,IEEE,Conferences,"Adaptive gait tracking of lower limb exoskeleton robot is a significant research topic, The purpose of this paper is to help the wearer to find the most suitable gait from the exit gaits as soon as possible, A new method was presented to find and extract the characteristics of individual changes from the walking behavior to achieve automatic identification, In this paper, the lower limb joint angles were used as the gait feature, the joint angles of lower limb are important gait kinematics parameter, we got the joint angles of the lower limbs and the pressure distribution of the foot through the motion information acquisition system, and then we extracted the effective features of the signals. Finally we carried out the 2km/h, 3km/h, 4km/h walking experiment on a treadmill, and then the data was put into the Multilayer-layer perceptron neural networks for training, and the recognition rate is 93.85%. Accurate gait recognition is the basis for both the determination of the motion intention and the control strategy of the lower limb exoskeleton robot.",https://ieeexplore.ieee.org/document/8311855/,2017 IEEE International Conference on Real-time Computing and Robotics (RCAR),14-18 July 2017,ieeexplore
10.1109/IROS.1991.174539,An approach to on-line obstacle avoidance for robot arms,IEEE,Conferences,"Presents an approach to on-line obstacle avoidance for fixed-base robot manipulators. It guarantees a collision-free path for the robot during real-time operations. This approach is based on analytic geometry and is suitable for continuous path control. Considering the potential collision with obstacles, the next trajectory point to move to is corrected. This strategy is direct formulated in the operational space in which the tasks are described and applicable for two-dimensional as well as for three-dimensional space. Because this algorithm requires no access to joint control, it can be also used for commercial robots given the desired path. One can assign it for various robots, here the implementation for the PUMA 560 is presented as an example.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174539/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/FWC.2017.8368522,An auction based smart service robot implemented on a Fog Computing node,IEEE,Conferences,"Adopting AR/VR technology on smart retail services is gaining more momentum with the progress in indoor map scanning technology and the research on AI deep learning algorithms. In this paper we propose the use of a Fog computing node to generate an AR/VR view of the real store on a web page. The customers can then use the service robot to view the merchandise in the real store via the web and make purchases. Since the service robot is a precious resource on the AR/VR business model, we develop an auction method to optimize the customer satisfaction and the owner satisfaction in terms of customer waiting time and the average number of transactions that are assisted by the service robot respectively. We demonstrate that the auction method is a critical part in the AR/VR smart business services when the number of service robots is much less than the number of active customers from the web and that it performs better than the standard preemptive method.",https://ieeexplore.ieee.org/document/8368522/,2017 IEEE Fog World Congress (FWC),30 Oct.-1 Nov. 2017,ieeexplore
10.1109/ICRAE.2017.8291426,An educational robot system of visual question answering for preschoolers,IEEE,Conferences,"The educational robotics is a novel technology for preschooler's companion and can be used for lower level education. This paper presents an AI-based robot system for achieving educational aims, such as metacognition tutoring and geometrical thinking training, with characteristics of contextual teaching by mining knowledge from the real world directly. For metacognition tutoring in our system, objects in real world are detected and a set of learning materials associated with the objects is presented for learners. For example, when a cat is detected, the robot will teach learners to pronounce the “Cat” in different languages, and more knowledge about cat will be pushed to the learners. For geometrical thinking training, an automatic questioning-and-answering section is employed to engage the learner to think, which is carried by a voice interaction between learners and robots. In our experiment, a set of specific object images are captured to validate the feasibility and efficiency of the proposed system. Our study indicated that the proposed system succeeded in captivating the children and parents in maximizing the children's desire to explore.",https://ieeexplore.ieee.org/document/8291426/,2017 2nd International Conference on Robotics and Automation Engineering (ICRAE),29-31 Dec. 2017,ieeexplore
10.1109/ICSMC.2009.5346800,An embedded interval type-2 neuro-fuzzy controller for mobile robot navigation,IEEE,Conferences,"This paper describes intelligent navigation using an embedded interval type-2 neuro-fuzzy controller. Weightless neural network (WNNs) strategy is used because fast learning, easy hardware implementation and well suited to microcontroller-based-real-time systems. The WNNs utilizes previous sensor data and analyzes the situation of the current environment and classifies geometric feature such as U-shape, corridor and left or right corner. The behavior of mobile robot is implemented by means of interval type-2 fuzzy control rules can be generated directly from the WNNs classifier. This functionality is demonstrated on a mobile robot using modular platform and containing several microcontrollers implies the implementation of a robust architecture. The proposed architecture implemented using low cost range sensor and low cost microprocessor. The experiment results show, using that technique the source code is efficient. The mobile robot can recognize the current environment and to be able successfully avoid obstacle in real time and achieve smother motion compare than logic function and fuzzy type-1 controller.",https://ieeexplore.ieee.org/document/5346800/,"2009 IEEE International Conference on Systems, Man and Cybernetics",11-14 Oct. 2009,ieeexplore
10.1109/IROS.2007.4399219,An extended policy gradient algorithm for robot task learning,IEEE,Conferences,"In real-world robotic applications, many factors, both at low-level (e.g., vision and motion control parameters) and at high-level (e.g., the behaviors) determine the quality of the robot performance. Thus, for many tasks, robots require fine tuning of the parameters, in the implementation of behaviors and basic control actions, as well as in strategic decisional processes. In recent years, machine learning techniques have been used to find optimal parameter sets for different behaviors. However, a drawback of learning techniques is time consumption: in practical applications, methods designed for physical robots must be effective with small amounts of data. In this paper, we present a method for concurrent learning of best strategy and optimal parameters, by extending the policy gradient reinforcement learning algorithm. The results of our experimental work in a simulated environment and on a real robot show a very high convergence rate.",https://ieeexplore.ieee.org/document/4399219/,2007 IEEE/RSJ International Conference on Intelligent Robots and Systems,29 Oct.-2 Nov. 2007,ieeexplore
10.1049/cp.2012.1013,An improved method to robot's environment map-building based on the normal distribution transform,IET,Conferences,"According to the problem that the traditional map-building method has high complexity, a map-matching method based on the combination of normal distribution transform (NDT) and environment feature extraction is proposed. The real-time environment information is obtained by two dimension laser sensors, from which the geometric feature is extracted and it will be transformed into normal distribution using NDT method, then the map is matched the by Newton' s algorithm. The method can reduce the complexity of the traditional NDT process, improving the efficiency of the map-matching. The experiment results demonstrate the effectiveness and superiority of the method.",https://ieeexplore.ieee.org/document/6492620/,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),3-5 March 2012,ieeexplore
10.1109/IJCNN.2000.861486,An incremental growing neural network and its application to robot control,IEEE,Conferences,"This paper describes a novel network model, which is able to control its growth on the basis of the approximation requests. Two classes of self-tuning neural models are considered; namely Growing Neural Gas (GNG) and SoftMax function networks. We combined the two models into a new one: hence the name GNG-Soft networks. The resulting model is characterized by the effectiveness of the GNG in distributing the units within the input space and the approximation properties of SoftMax functions. We devised a method to estimate the approximation error in an incremental fashion. This measure has been used to tune the network growth rate. Results showing the performance of the network in a real-world robotic experiment are reported.",https://ieeexplore.ieee.org/document/861486/,Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium,27-27 July 2000,ieeexplore
10.1109/CIRA.2003.1222155,An incremental learning using schema extraction mechanism for autonomous mobile robot,IEEE,Conferences,"Recently, a number of skillful robots have been developed. One of them can walk and move upstairs just like human beings. However it can so far only demonstrate preprogrammed motions according to the external commands/situations. Therefore autonomous adaptation ability has been highly anticipated. Meanwhile, humans can learn new motions such as catching/kicking a ball, in spite of his/her high dimensional sensorimotor DOF (degree of freedom). In this learning process, it can be hypothesized that the learner actively constrains the DOF by him/her-self using learning skills, in this paper referred to as schema. In this study, a learning method for autonomous mobile robots operating in unknown environments is proposed, where not only a learning mechanism for sensorimotor mappings but also an extraction/re-use mechanism of the schema (i.e. constraint rules for learning) is implemented. Through the results of simulations and real experiments of mobile robot navigation, the validity of the proposed method is clarified.",https://ieeexplore.ieee.org/document/1222155/,Proceedings 2003 IEEE International Symposium on Computational Intelligence in Robotics and Automation. Computational Intelligence in Robotics and Automation for the New Millennium (Cat. No.03EX694),16-20 July 2003,ieeexplore
10.1109/ICPR.1992.201634,An intelligent mobile robot golfing system using binocular stereo vision,IEEE,Conferences,"This paper describes a robot vision golfing system. The ARNIE P/sup tau / (Automated Robotic Navigational unit with Intelligent Eye and Putter) project was initiated to investigate the problems and develop software solutions for robotic tasks that require good hand-eye coordination and an intelligent feedback mechanism. This system has only one frame buffer and no specialized hardware, so quasi-real-time 3D tracking is accomplished in software using the unix spline facility. Golf is a difficult perceptory task which requires the integration of many complicated computational tasks. It is therefore a good platform to experiment with artificial intelligence techniques and robotics.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/201634/,[1992] Proceedings. 11th IAPR International Conference on Pattern Recognition,30 Aug.-3 Sept. 1992,ieeexplore
10.1109/ROBOT.1992.220085,An optimal scheduling of pick place operations of a robot-vision-tracking system by using back-propagation and Hamming networks,IEEE,Conferences,"The authors present a neural network approach to solve the dynamic scheduling problem for pick-place operations of a robot-vision-tracking system. An optimal scheduling problem is formulated to minimize robot processing time without constraint violations. This is a real-time optimization problem which must be repeated for each group of objects. A scheme which uses neural networks to learn the mapping from object pattern space to optimal order space offline and to recall online what has been learned is presented. The idea was implemented in a real system to solve a problem in large commercial dishwashing operations. Experimental results have been shown that with four different objects, time savings of up to 21% are possible over first-come, first-served schemes currently used in industry.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/220085/,Proceedings 1992 IEEE International Conference on Robotics and Automation,12-14 May 1992,ieeexplore
10.1109/ISESD.2017.8253306,Analysis of artificial intelligence application using back propagation neural network and fuzzy logic controller on wall-following autonomous mobile robot,IEEE,Conferences,"This paper presents a comparison of two methods of artificial intelligence which applied in Wall following Autonomous Mobile Robot; both of them are Neural Network Back propagation and Fuzzy Logic. The robot has three input variables and two output variables. The inputs are distance between the robot and the wall which is sensed by HC-SR04 ultrasonic sensors. The output variables are the speed of the two wheels which is driving by 12 Volt DC motor. In this case mobile robot is designed to avoid the collision with any obstacles like wall or other mobile robots. In this implementation mobile robot is designed with a numbers of ultrasonic sensors and placed on certain position like center front, left front and left back. The sensor will send the data in real time. After being processed, the input produces output in form of speed value governing motor rotation mounted on both wheels of the robot to find the optimum point. In this comparison, both methods Backpropagation Neural Network and Fuzzy Logic are treated the same. Wall following Autonomous Mobile Robot is using Atmega2560 microcontroller. The logic is uploaded to the microcontroller. The result of the comparison of these two methods when applied in Wall-following Autonomous Mobile Robot is the movement of the robot using Neural Network Back propagation is faster than using Fuzzy Logic Controller.",https://ieeexplore.ieee.org/document/8253306/,2017 International Symposium on Electronics and Smart Devices (ISESD),17-19 Oct. 2017,ieeexplore
10.1109/ISIE.2007.4374936,Application of Fuzzy Neural Network in Parameter Optimization of Mobile Robot Path Planning Using Potential Field,IEEE,Conferences,"This paper discussed a new mobile robot path planning algorithm. It analyzed the traditional path planning algorithm that employs artificial potential field and fuzzy logic, and then develop a new method combing artificial potential field, neural network and fuzzy Logic, which realized real-time obstacle recognition and smooth motion in dynamic environment. This algorithm improves the traditional artificial potential field performance, while reducing its drawbacks' influence effectively. Experiment and simulation shows this method can make the robot avoid obstacles effectively and avoid being trapped in ""dead area"".",https://ieeexplore.ieee.org/document/4374936/,2007 IEEE International Symposium on Industrial Electronics,4-7 June 2007,ieeexplore
10.1109/IJCNN.1990.137866,Application of neural networks on robot grippers,IEEE,Conferences,"A new-generation general-purpose robot gripper system which applies an artificial neural network to guide a three-finger gripper has been designed. The simulation of the core part of the whole system, i.e. optimally placing three fingers for a stable grasp using the Hopfield net, has been conducted. The results obtained show that this scheme behaves in a promising fashion. The actual computation time is usually within several seconds if implemented in an analog neural net, making the real application attractive",https://ieeexplore.ieee.org/document/5726824/,1990 IJCNN International Joint Conference on Neural Networks,17-21 June 1990,ieeexplore
10.1109/CDC.1999.833361,Application of reinforcement learning control to a nonlinear dexterous robot,IEEE,Conferences,"In this paper, the effects of basic parameters in reinforcement learning control such as eligibility, action and critic network weights, system nonlinearities, gradient information, state-space partitioning, variance of exploration were studied in detail. We attempt to increase feasibility for practical applications, implementation, learning efficiency, and performance. Reinforcement learning is then applied for control of a nonlinear dexterous robot. This control problem dictates that the learning is performed online, based on binary and real valued reinforcement signal from a critic network, without knowing the system model nonlinearity. The learning algorithm consists of an action and critic networks that learn to keep the multifinger hand of the dexterous robot within desired limits.",https://ieeexplore.ieee.org/document/833361/,Proceedings of the 38th IEEE Conference on Decision and Control (Cat. No.99CH36304),7-10 Dec. 1999,ieeexplore
10.1109/IJCNN.2004.1380179,Applying KIV dynamic neural network model for real time navigation by mobile robot EMMA,IEEE,Conferences,"We use a biologically inspired dynamic neural network model to accomplish goal-oriented navigation by a mobile robot in a real environment with obstacles. This model is the KIV model of the brain. Real time navigation is a challenging task, especially when there is no a priori information about the environment. Our robot EMMA is designed to be autonomous using various sensory inputs, which are integrated to achieve an efficient navigation task. This paper focuses on the design, implementation, and evaluation of the performance of EMMA and gives a proof-of-principle in a real environment.",https://ieeexplore.ieee.org/document/1380179/,2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541),25-29 July 2004,ieeexplore
10.1109/ICNN.1996.549172,Applying self-organizing networks to recognizing rooms with behavior sequences of a mobile robot,IEEE,Conferences,"We describe the application of a self-organizing network to the robot which learns to recognize rooms (enclosures) using behavior sequences. In robotics research, most studies on recognizing environments have tried to build the precise geometric map with highly sensitive sensors. However many natural agents like animals recognize the environments with low sensitivity sensors, and a geometric map may not be necessary. Thus we attempt to build a mobile robot using a self-organizing network to recognize the enclosures, in which it acts, with low sensitivity and local sensors. The mobile robot is behavior-based and does wall-following in an enclosure. Then the sequences of behaviors executed in each enclosure are obtained. The sequences are transformed into real-value vectors, and inputted to the Kohonen self-organizing network. Unsupervised learning is done and a mobile robot becomes able to distinguish and identify enclosures. We fully implemented the system using a real mobile robot and made experiments for evaluating the ability. Consequently we found out the recognition of enclosures was done well and our method was robust against small obstacles in an enclosure.",https://ieeexplore.ieee.org/document/549172/,Proceedings of International Conference on Neural Networks (ICNN'96),3-6 June 1996,ieeexplore
10.1109/ICONIP.1999.845675,Artificial neural networks for autonomous robot control: reflective navigation and adaptive sensor calibration,IEEE,Conferences,"The authors present the application of artificial neural networks to the control of a mobile autonomous robot, which is acting in a totally unknown and-most importantly-dynamically changing environment. In particular, the employment of interacting 'simple', i.e. hand-designed, neural networks for navigation purposes is investigated as well as a variation of self-organizing maps for adaptive sensor calibration. We take a pragmatic point of view as the minimal condition imposed on the developed algorithms: that they do well on a real system acting in a real environment. Hence, the design of all of the implemented neural networks is clearly motivated by their applicability. In this context, special considerations are dedicated to ensure robustness, real-time capability and memory resourcefulness. In order to practically demonstrate the obtained results, the mini-robot Khepera is utilized as an experimentational platform, which is (due to its small size), a versatile tool for scientific investigation.",https://ieeexplore.ieee.org/document/845675/,ICONIP'99. ANZIIS'99 & ANNES'99 & ACNN'99. 6th International Conference on Neural Information Processing. Proceedings (Cat. No.99EX378),16-20 Nov. 1999,ieeexplore
10.1109/ICMLC.2004.1378596,Artificial neural networks for mobile robot acquiring heading angle,IEEE,Conferences,The RBF network is designed for the mobile robot to acquire the accurate and real-time heading angle that is significant for the successful localization. Several designs related to the network architecture and training has been made to construct the RBF network using the OLS algorithm. The results of the experiment show that the designed neural network can greatly improve the accuracy of the localization. The proposed localization system with combined sensors based on the RBF neural network is reliable to ensure the intelligent behaviors of the robot. The technical presentations in this paper can facilitate the application of artificial neural networks in the environmental robotics.,https://ieeexplore.ieee.org/document/1378596/,Proceedings of 2004 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.04EX826),26-29 Aug. 2004,ieeexplore
10.1109/ICRA.2018.8462967,Auctioning over Probabilistic Options for Temporal Logic-Based Multi-Robot Cooperation Under Uncertainty,IEEE,Conferences,"Coordinating a team of robots to fulfill a common task is still a demanding problem. This is even more the case when considering uncertainty in the environment, as well as temporal dependencies within the task specification. A multi-robot cooperation from a single goal specification requires mechanisms for decomposing the goal as well as an efficient planning for the team. However, planning action sequences offline is insufficient in real world applications. Rather, due to uncertainties, the robots also need to closely coordinate during execution and adjust their policies when additional observations are made. The framework presented in this paper enables the robot team to cooperatively fulfill tasks given as temporal logic specifications while explicitly considering uncertainty and incorporating observations during execution. We present the effectiveness of our ROS implementation of this approach in a case study scenario.",https://ieeexplore.ieee.org/document/8462967/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/SIU.2015.7130068,Audio-visual human tracking for active robot perception,IEEE,Conferences,"In this paper, a multimodal system is designed in the form of an active audio-vision in order to improve the perceptual capability of a robot in a noisy environment. The system running in real-time consists of 1) audition modality, 2) a complementary vision modality and 3) motion modality incorporating intelligent behaviors based on the data obtained from both modalities. The tasks of audition and vision are to detect, localize and track a speaker independently. The aim of motion modality is to enable a robot to have intelligent and human-like behaviors by using localization results from the sensor fusion. The system is implemented on a mobile robot platform in a real-time environment and the speaker tracking performance of the fusion is confirmed to be improved compared to each of sensory modalities.",https://ieeexplore.ieee.org/document/7130068/,2015 23nd Signal Processing and Communications Applications Conference (SIU),16-19 May 2015,ieeexplore
10.1109/AIVR46125.2019.00061,Augmented Reality for Human-Robot Cooperation in Aircraft Assembly,IEEE,Conferences,"Augmented Reality (AR) is often discussed as one of the enabling technologies in Industrie 4.0. In this paper, we describe a practical application, where Augmented Reality glasses are used not only for assembly assistance, but also as a means of communication to enable the orchestration of a hybrid team consisting of a human worker and two mobile robotic systems. The task of the hybrid team is to rivet so-called stringers onto an aircraft hull. While the two robots do the physically demanding, unergonomic and possibly hazardous tasks (squeezing and sealing rivets), the human takes over those responsibilities that need experience, multi-sensory sensitiveness and specialist knowledge. We describe the working scenario, the overall architecture and give design and implementation details on the AR application.",https://ieeexplore.ieee.org/document/8942239/,2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),9-11 Dec. 2019,ieeexplore
10.23919/MIPRO52101.2021.9597142,Automated Robot Control for a Game of Chess in Unity Game Engine through Artificial Intelligence,IEEE,Conferences,"The topic of this paper is to study the possibility of using Unity game development engine for robot control. The aim of the work is to create a virtual environment in which the game of chess is simulated, through a duel of two robots controlled by artificial intelligence. As part of the work, real robot models were implemented in the Unity game engine. The simulated robots were ABB's IRB-120 arms with two joints. The movement of the robot is fully simulated within the physics simulation in the Unity system. The Forward and Backward Reaching Inverse Kinematics (FABRIK) algorithm was used for the inverse kinematics algorithm. For calculating the next move, external artificial intelligence library Stockfish was used and integrated with the Unity game engine. The final application has automated moves between the robots, has the option of a simple change of the viewpoint through camera movement, and is intended to be used in future work for the control of a real robot.",https://ieeexplore.ieee.org/document/9597142/,"2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO)",27 Sept.-1 Oct. 2021,ieeexplore
10.1109/ICICIC.2009.121,Automatic Path Search for Roving Robot Using Reinforcement Learning,IEEE,Conferences,"Rapid advances in robot technology have been made in recent years. In connection with these advances, robots are expected to be utilized in a variety of places and environments. This study describes, (1) a method which allows a robot to measure the location of its destination in the real world based on an image obtained from a single camera, and (2) a method of navigating a robot to a destination which is selected by a user on a display showing the forward robot view. Consideration is also given to cases in which there are obstacles between the robot and the destination. Through the use of reinforcement learning, which is considered a promising candidate among autonomous control techniques, the roving robot tries to find the shortest way to the destination based on information concerning the locations of obstacles and the destination. This study also describes an image-based method of measuring a selected location, the results from a simulation of path finding using reinforcement learning, and the results from an experiment of navigation in a real environment. Finally, a summary of the main conclusions is provided.",https://ieeexplore.ieee.org/document/5412489/,"2009 Fourth International Conference on Innovative Computing, Information and Control (ICICIC)",7-9 Dec. 2009,ieeexplore
10.1109/IJCNN.2003.1223997,Automatic language acquisition by an autonomous robot,IEEE,Conferences,"There is no such thing as a disembodied mind. We posit that cognitive development can only occur through interaction with the physical world. To this end, we are developing a robotic platform for the purpose of studying cognition. We suggest that the central component of cognition is a memory which is primarily associative, one where learning occurs as the correlation of events from diverse inputs. We also posit that human-like cognition requires a well-integrated sensory-motor system, to provide these diverse inputs. As implemented in our robot, this system includes binaural hearing, stereo vision, tactile sense, and basic proprioceptive control. On top of these abilities, we are implementing and studying various models of processing, learning and decision making. Our goal is to produce a robot that will learn to carry out simple tasks in response to natural language requests. The robot's understanding of language will be learned concurrently with its other cognitive abilities. We have already developed a robust system and conducted a number or experiments on the way to this goal, some details of which appear in this paper. This is a first progress report of what we believe will be a long term project with significant implications.",https://ieeexplore.ieee.org/document/1223997/,"Proceedings of the International Joint Conference on Neural Networks, 2003.",20-24 July 2003,ieeexplore
10.1109/SYSOSE.2008.4724191,Autonomous navigation based on a Q-learning algorithm for a robot in a real environment,IEEE,Conferences,"This paper explores autonomous navigation and obstacle avoidance techniques based on Q-learning for a mobile robot in a real environment. The implemented algorithm focuses on simplicity and efficiency. The learning process takes place in both simulation and real world allowing the combination of a longer learning time in the simulator with a more accurate knowledge from the real world. After learning is completed in simulation and in the real world, the robot was able to navigate without hitting obstacles and able to generate control law for complex situations such as corners and small objects.",https://ieeexplore.ieee.org/document/4724191/,2008 IEEE International Conference on System of Systems Engineering,2-4 June 2008,ieeexplore
10.1109/ISIC.2002.1157759,Autonomous robot navigation based on fuzzy sensor fusion and reinforcement learning,IEEE,Conferences,"This paper presents the design and implementation of an autonomous robot navigation system for intelligent target collection in dynamic environments. A feature-based multi-stage fuzzy logic (MSFL) sensor fusion system is developed for target recognition, which is capable of mapping noisy sensor inputs into reliable decisions. The robot exploration and path planning are based on a grid map oriented reinforcement path learning system (GMRPL), which allows for long-term predictions and path adaptation via dynamic interactions with physical environments. In our implementation, the MSFL and GMRPL are integrated into a subsumption architecture for intelligent target-collecting applications. The subsumption architecture is a layered reactive agent structure that enables the robot to implement higher-layer functions including path learning and target recognition regardless of lower-layer functions such as obstacle detection and avoidance. Real-world application using a Khepera robot shows the robustness and flexibility of the developed system in dealing with robotic behavior such as target collecting in an ever-changing physical environment.",https://ieeexplore.ieee.org/document/1157759/,Proceedings of the IEEE Internatinal Symposium on Intelligent Control,30-30 Oct. 2002,ieeexplore
10.1109/CEC.2002.1004426,Autonomous robot navigation via intrinsic evolution,IEEE,Conferences,"This paper presents the design and implementation of an evolvable hardware based autonomous robot navigation system using intrinsic evolution. Distinguished from the traditional evolutionary approaches based on software simulation, an evolvable robot controller at the hardware gate-level that is capable of adapting dynamic changes in the environments is implemented. In our approach, the concept of Boolean function is used to construct the evolvable controller implemented on an FPGA-based robot turret, and evolutionary computing is applied as a learning tool to guide the artificial evolution at the hardware level. The effectiveness of the proposed evolvable autonomous robotic system is confirmed with the physical real-time implementation of robot navigation behaviors on light source following and obstacle avoidance using a robot with traction fault.",https://ieeexplore.ieee.org/document/1004426/,Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600),12-17 May 2002,ieeexplore
10.1109/IJCNN.2016.7727848,Bayesian perception of touch for control of robot emotion,IEEE,Conferences,"In this paper, we present a Bayesian approach for perception of touch and control of robot emotion. Touch is an important sensing modality for the development of social robots, and it is used in this work as stimulus through a human-robot interaction. A Bayesian framework is proposed for perception of various types of touch. This method together with a sequential analysis approach allow the robot to accumulate evidence from the interaction with humans to achieve accurate touch perception for adaptable control of robot emotions. Facial expressions are used to represent the emotions of the iCub humanoid. Emotions in the robotic platform, based on facial expressions, are handled by a control architecture that works with the output from the touch perception process. We validate the accuracy of our system with simulated and real robot touch experiments. Results from this work show that our method is suitable and accurate for perception of touch to control robot emotions, which is essential for the development of sociable robots.",https://ieeexplore.ieee.org/document/7727848/,2016 International Joint Conference on Neural Networks (IJCNN),24-29 July 2016,ieeexplore
10.1109/ROMOCO.2001.973435,"Behavior learning to predict using neural networks (NN): Ttowards a fast, cooperative and adversarial robot team (RoboCup)",IEEE,Conferences,"To build a fast, cooperative and adversarial robot team (RoboCup), prediction behaviors became necessary. In the paper, a behavior learning method using neural networks (NN) is developed to enhance the behavior of GMD mobile robots. In fact, the suggested NN called NN-Prediction learns to predict successfulness of the elementary behavior ""Kick"" the ball towards the goal in order to act as consequence. The training is carried out by the supervised gradient back-propagation learning paradigm. This NN-Prediction has been specified on the Dual Dynamics Designer, to be thereafter implemented and tested on both the Dual Dynamics Simulator and GMD mobile robots, and analyzed on the Real-Time Trace Tool. NN-prediction demonstrated, during the 4/sup th/ World Championships RoboCup 2000, cooperative and adversarial behaviors especially face to situations where the successfulness of ""Kick"" is not guaranteed. Then, a discussion is given dealing with the suggested prediction behavior and how it relates to some other works.",https://ieeexplore.ieee.org/document/973435/,Proceedings of the Second International Workshop on Robot Motion and Control. RoMoCo'01 (IEEE Cat. No.01EX535),20-20 Oct. 2001,ieeexplore
10.1109/IJCNN.2008.4633875,Bio-inspired stochastic chance-constrained multi-robot task allocation using WSN,IEEE,Conferences,"The multi-robot task allocation (MRTA) especially in unknown complex environment is one of the fundamental problems, a mostly important object in research of multi-robot. The MRTA problem is initially formulated as a chance-constrained optimization problem. Monte Carlo simulation is used to verify the accuracy of the solution provided by the algorithm. Ant colony optimization (ACO) algorithm based on bionic swarm intelligence was used. A hybrid intelligent algorithm combined Monte Carlo simulation and neural network is used for solving stochastic chance constrained models of MRTA. A practical implementation with real WSN and real mobile robots were carried out. In environment the successful implementation of tasks without collision validates the efficiency, stability and accuracy of the proposed algorithm. The convergence curve shows that as iterative generation grows, the utility increases and finally reaches a stable and optimal value. Results show that using sensor information fusion can greatly improve the efficiency. The algorithm is proved better than tradition algorithms without WSN for MRTA in real time.",https://ieeexplore.ieee.org/document/4633875/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/BIOROB.2018.8487202,Bioinspired Adaptive Spiking Neural Network to Control NAO Robot in a Pavlovian Conditioning Task,IEEE,Conferences,"The cerebellum has a central role in fine motor control and in various neural processes, as in associative paradigms. In this work, a bioinspired adaptive model, developed by means of a spiking neural network made of thousands of artificial neurons, has been leveraged to control a humanoid NAO robot in real-time. The learning properties of the system have been challenged in a classic cerebellum-driven paradigm, the Pavlovian timing association between two provided stimuli, here implemented as a laser-avoidance task. The neurophysiological principles used to develop the model, succeeded in driving an adaptive motor control protocol with acquisition and extinction phases. The spiking neural network model showed learning behaviors similar to the ones experimentally measured with human subjects in the same conditioning task. The model processed in real-time external inputs, encoded as spikes, and the generated spiking activity of its output neurons was decoded, in order to trigger the proper response with a correct timing. Three long-term plasticity rules have been embedded for different connections and with different time-scales. The plasticities shaped the firing activity of the output layer neurons of the network. In the Pavlovian protocol, the neurorobot successfully learned the correct timing association, generating appropriate responses. Therefore, the spiking cerebellar model was able to reproduce in the robotic platform how biological systems acquire and extinguish associative responses, dealing with noise and uncertainties of a real-world environment.",https://ieeexplore.ieee.org/document/8487202/,2018 7th IEEE International Conference on Biomedical Robotics and Biomechatronics (Biorob),26-29 Aug. 2018,ieeexplore
10.1109/IJCNN.2000.859467,Biologically inspired neural controllers for motor control in a quadruped robot,IEEE,Conferences,"This paper presents biologically inspired neural controllers for generating motor patterns in a quadruped robot. Sets of artificial neural networks are presented which provide 1) pattern generation and gait control, allowing continuous passage from walking to trotting to galloping, 2) control of sitting and lying down behaviors, and 3) control of scratching. The neural controllers consist of sets of oscillators composed of leaky-integrator neurons, which control pairs of flexor-extensor muscles attached to each joint. The networks receive sensory feedback proportional to the contraction of simulated muscles and to joint flexion. Similarly to what is observed in cats, locomotion can be initiated by either applying tonic (i.e. non-oscillating) input to the locomotion network or by sensory feedback from extending the legs. The networks are implemented in a quadruped robot. It is shown that computation can be carried out in real time and that the networks can generate the above mentioned motor behaviors.",https://ieeexplore.ieee.org/document/859467/,Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium,27-27 July 2000,ieeexplore
10.1109/IROS.2004.1389400,Biologically inspired optimal robot arm control with signal-dependent noise,IEEE,Conferences,"Progress in the field of humanoid robotics and the need to find simpler ways to program such robots has prompted research into computational models for robotic learning from human demonstration. To further investigate biologically inspired human-like robotic movement and imitation, we have constructed a framework based on three key features of human movement and planning: optimality, modularity and learning. In this paper we focus on the application of optimality principles to the production of human-like movement by a robot arm. Among computational theories of human movement, the signal-dependent noise, or minimum variance, model was chosen as a biologically realistic control scheme to produce human-like movement. A well known optimal control algorithm, the linear quadratic regulator, was adapted to implement this model. The scheme was applied both in simulation and on a real robot arm, which demonstrated human-like movement profiles in a point-to-point reaching experiment.",https://ieeexplore.ieee.org/document/1389400/,2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),28 Sept.-2 Oct. 2004,ieeexplore
10.1109/ROMAN.2017.8172296,Blame my telepresence robot joint effect of proxemics and attribution on interpersonal attraction,IEEE,Conferences,"When remote users share autonomy with a telepresence robot, questions arise as to how the behaviour of the robot is interpreted by local users. We investigated how a robot's violations of social norms under shared autonomy influence the local user's evaluation of the robot's remote users. Specifically, we examined how attribution of such violations to either the robot or the remote user influences social perception of the remote user. Using personal space invasion as a salient social norm violation, we conducted a within-subject experiment (n=20) to investigate these questions. Participants saw several people introducing themselves through a telepresence robot, personal space invasion and attribution were manipulated. We found a significant (p=0.007) joint effect of the manipulations on interpersonal attraction. After these first 20 participants our robot broke down, and we had to continue with another robot (n=20). We found a difference between the two robots, causing us to discard this data from our main analysis. Subsequent video annotation and comparison of the two robots suggests that accuracy of the followed trajectory modifies attribution. Our results offer insights into the mechanisms of attribution in interactions with a telepresence robot as a mediator.",https://ieeexplore.ieee.org/document/8172296/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/AIM.2019.8868855,Brain-robot Shared Control Based on Motor Imagery and Improved Bayes Filter<sup>*</sup>,IEEE,Conferences,"Brain-controlled robots are an innovative means of interacting and can also provide new solutions for disabled and stroke patients to communicate with the outside world. Since the poor real-time performance and poor accuracy of brain-computer interface (BCI) is not precise to control the robot directly, in order to avoid damage to the robot and humans in the process, this paper designs a brain-robot shared control system based on brain-computer interface. The motion direction of the robot controlled via four types of motor imagery (MI) signals. Feature extraction of MI signals is performed using common space pattern (CSP) combined with local characteristic-scale decomposition (LCD). The classification results are obtained with the appropriate features processed by the spectral regression discriminant analysis (SRDA) classifier. The Bayes filter algorithm is used to implement the robot shared control method, the belief of the robot's motion direction is calculated, and then the control ratio of the robot's autonomous motion and the BCI are assigned automatically. Considering that each control instruction given by BCI cost at least 1.5 seconds. To achieve better control effect at the interval between two instructions, the relationship with two steps of Bayes filter is redesigned, even if a new control data is not received, the robot will continuously update the measurement according to the previous control data, assign a new control ratio and execute the corresponding instruction, so that the robot can continuously adjust the movement intention and proportion during the instruction interval of BCI. The control effect was verified by online experiments. Using the improved Bayes filter algorithm, the success rate of the experiment is greatly improved, and the number of instructions used in single trial is reduced by 50%.",https://ieeexplore.ieee.org/document/8868855/,2019 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM),8-12 July 2019,ieeexplore
10.1109/IROS.2005.1545040,Broker: an interprocess communication solution for multi-robot systems,IEEE,Conferences,"We describe in this paper a novel implementation of the interprocess communication (IPC) technology, called Broker, in support of the development and the operation of a complex robot system. We view each robot system as a collection of processes that need to exchange information, e.g. motion commands and sensory data, in a flexible and convenient fashion, without affecting each other's operations in case of a process's scheduled termination or unexpected failure. We argue that the IPC technology provides an ideal framework for this purpose, and we carefully make our design decisions about its implementation based on the needs of robotics applications. Broker is programming language, operating system, and hardware platform independent and has served us well in a RoboCup project and collective robotics experiments, in both simulation and real-world environments.",https://ieeexplore.ieee.org/document/1545040/,2005 IEEE/RSJ International Conference on Intelligent Robots and Systems,2-6 Aug. 2005,ieeexplore
10.1109/ISCAS.2004.1329695,CNN wave based computation for robot navigation planning,IEEE,Conferences,"In this work a methodology for real-time robot navigation in a complex, dynamically changing environment, based on wave computation and implemented by cellular neural networks (CNNs) is introduced. The keypoint of the approach is to consider the environment in which the robot moves as an excitable medium. Obstacles and targets represent the source of autowave generation. The wavefronts propagating in the CNN medium provide to the robot all the information to achieve an adaptive motion avoiding the obstacles and directed to the target. In particular the paradigm of reaction-diffusion (RD) equations are used to implement a CNN-based wave computation for navigation control. Experimental results validating the approach are shown.",https://ieeexplore.ieee.org/document/1329695/,2004 IEEE International Symposium on Circuits and Systems (IEEE Cat. No.04CH37512),23-26 May 2004,ieeexplore
10.1109/IROS40897.2019.8967592,Can a Robot Become a Movie Director? Learning Artistic Principles for Aerial Cinematography,IEEE,Conferences,"Aerial filming is constantly gaining importance due to the recent advances in drone technology. It invites many intriguing, unsolved problems at the intersection of aesthetical and scientific challenges. In this work, we propose a deep reinforcement learning agent which supervises motion planning of a filming drone by making desirable shot mode selections based on aesthetical values of video shots. Unlike most of the current state-of-the-art approaches that require explicit guidance by a human expert, our drone learns how to make favorable viewpoint selections by experience. We propose a learning scheme that exploits aesthetical features of retrospective shots in order to extract a desirable policy for better prospective shots. We train our agent in realistic AirSim simulations using both a hand-crafted reward function as well as reward from direct human input. We then deploy the same agent on a real DJI M210 drone in order to test the generalization capability of our approach to real world conditions. To evaluate the success of our approach in the end, we conduct a comprehensive user study in which participants rate the shot quality of our methods. Videos of the system in action can be seen at https://youtu.be/qmVw6mfyEmw.",https://ieeexplore.ieee.org/document/8967592/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ROBIO.2017.8324803,Classification-lock tracking approach applied on person following robot,IEEE,Conferences,"The task of following a person in the real complex environment by camera still keeps at risk even the visual tracking technologies have been well studied in the last decade. Currently, most approaches only utilize single-shot initialization in the first frame and update their tracking models according to the result of the last frame. However, it leads to an uncorrected target selection once the inner appearance changes, i.e., a feature-rich object is moved out of the human. In this paper, we reveal a classification-lock tracking framework and apply our approach on a mobile platform. A pairwise cluster tracker is used to locate the person. A positive &amp; negative classifier is utilized to verify the tracker's result and update tracking model. In addition, a pre-trained CPU optimized neural network is employed to lock the tracking result to only be human. In the experiment, we deploy the common challenges of visual tracking both on the static scene and a real-following task. Furthermore, our approach is compared with other state-of-art approaches on common datasets. Results prove the tracking quality of our approach in both the static and the dynamic scenes. Our approach achieves the best average score on the common dataset.",https://ieeexplore.ieee.org/document/8324803/,2017 IEEE International Conference on Robotics and Biomimetics (ROBIO),5-8 Dec. 2017,ieeexplore
10.1109/ICCE46568.2020.9042997,Cliff-sensor-based Low-level Obstacle Detection for a Wheeled Robot in an Indoor Environment,IEEE,Conferences,"A ramp and uneven ground formed by a low-level obstacle - whose height is too low from the ground - often stalls a robot's navigation in an indoor environment. Few-centimeter differences between a low-level obstacle and a low-level non-obstacle are very difficult to be precisely measured in a constant distance at a mobile robot. In this paper, a wheeled mobile robot thus makes physical contact onto a low-level object, in order to measure such subtle differences. We use one or more cliff sensors typically in place for a mobile robot in order to avoid a drop-off. A wheeled robot climbs over a low-level object, classifies an obstacle vs. a non-obstacle using a cliff sensor's timeseries data, and rapidly backs up before getting stuck onto an obstacle. While adopting a simplified deep-learning architecture, we suggest a rapid and accurate obstacle detection technique in real-time. We implemented our technique on an embedded robot platform of LG Hom-Bot. The supplementary video on the physical robot experiment can be accessed at https://youtu.be/yK57S857_II.",https://ieeexplore.ieee.org/document/9042997/,2020 IEEE International Conference on Consumer Electronics (ICCE),4-6 Jan. 2020,ieeexplore
10.1109/IROS.2018.8594311,Cognition-enabled Framework for Mixed Human-Robot Rescue Teams,IEEE,Conferences,"With the advancements in robotic technology and the progress in human-robot interaction research, the interest in deploying mixed human-robot teams in rescue missions is increasing. Due to their complementary capabilities in terms of locomotion, visibility and reachability of areas, human-robot teams are considerably deployed in real-world settings, albeit the robotic agents in such scenarios are normally fully teleoperated. A major barrier to successful and efficient mission execution in those teams is the lack of cognitive skills in robotic systems. In this paper, we present a cognition-enabled framework and an implemented system where robotic agents are equipped with cognitive capabilities to naturally communicate with humans and autonomously perform tasks. The framework allows for natural tasking of robots, reasoning about robot behavior, capabilities and actions, and a common belief state representation for shared mission awareness of robots and human operators.",https://ieeexplore.ieee.org/document/8594311/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/INDIN.2011.6034840,Cognitive decision unit applied to autonomous biped robot NAO,IEEE,Conferences,"The novel approach to use meta-psychology - the theoretic foundation of psychoanalysis - as archetype for a decision making framework for autonomous agents was realized in simulations recently. In addition, multiple studies showed the capability of a robot to sense and interact in its environment. This work fills the gap between sensing, environmental interaction and decision making by grounding these topics with an agents internal needs using the concepts of meta-psychology. The bodies of typical agents are equipped with internal systems which can generate bodily needs - for example the urgent need for food. As proof-of-concept we implemented this concept on a simulated agent as well as on a physical real humanoid biped robot to additionally proof the concept within a fully controlled simulated environment. The use of the common humanoid robot platform NAO, which has 25 degrees of freedom and biped locomotion, enforced us to deal with complex situations and disturbed sensor readings. NAO provides various internal sensors like engine temperature or battery level as well as external sensors like sonar or cameras. An implemented visual marker detecting system allowed us to detect objects in the surrounding environmental, representing food or energy sources. We show, how it is possible to use the psychoanalytically inspired framework ARS to control a real world application, the robot NAO.",https://ieeexplore.ieee.org/document/6034840/,2011 9th IEEE International Conference on Industrial Informatics,26-29 July 2011,ieeexplore
10.1109/CARE.2013.6733739,Cognitive learning enabled real time object search robot,IEEE,Conferences,"Object Tracking is usually performed in the context of higher-level applications that require the location and/or shape of the object in every frame. Most works are focused on a specific application, such as tracking human, car, or pre-learned objects. All these require database and considerable amount of training time to detect the current object and to track it. In this paper we propose a method to track objects where a pre-stored database is not a requirement. The proposed method uses a combination of Scale Invariant Feature Transform (SIFT) based feature extraction, Kalman filter and Cognitive learning. The algorithm has the ability to make its own database of the objects in the due course of time by interacting with the user through text based communication. This algorithm is deployed on a search robot which does the operation of searching an object in real time upon a command from the user. The search operation of robot is made more flexible using Bluetooth wireless communication protocol.",https://ieeexplore.ieee.org/document/6733739/,"2013 International Conference on Control, Automation, Robotics and Embedded Systems (CARE)",16-18 Dec. 2013,ieeexplore
10.1109/MSM49833.2020.9202398,Collaborative Robot System for Playing Chess,IEEE,Conferences,"In recent years, number of collaborative robots industrial applications has made a significant increasment. Implementation of collaborative robots is a safe and effective way for designing robot-human cooperation systems. Combined with constantly developing artificial intelligence, collaborative systems are actually able to solve complex problems that require some sort of intelligence. For humans, board games are a good example of the visualization of robot intelligence. Such systems require estimation and detection of board and pieces in manipulator workspace, some kind of decision-making algorithms and robot control system to move pieces. The flagship of such systems are chess playing robots. The chess game has a defined and easy to understand set of rules which makes it interesting example of intelligent robotics systems application. In this paper, we present an implementation of collaborative robots for chess playing system which was designed to play against human or another robot. The system is able to track state of the game via camera, calculate the optimal move using implemented decision-making algorithm, detect illegal moves and execute pick-and-place task to physically move pieces. We test the developed system in a real-world setup and provide experimental results documenting the performance of proposed approach.",https://ieeexplore.ieee.org/document/9202398/,2020 International Conference Mechatronic Systems and Materials (MSM),1-3 July 2020,ieeexplore
10.1109/ICTAI.2019.00023,Collision-Free Path Finding for Dynamic Gaming and Real Time Robot Navigation,IEEE,Conferences,"Collision-free path finding is crucial for multi-agent traversing environments like gaming systems. An efficient and accurate technique is proposed for avoiding collisions with potential obstacles in virtual and real time environments. Potential field is a coherent technique but it eventuates with various problems like static map usage and pre-calculated potential field map of the environment. It is unsuitable for dynamically changing or unknown environments. Agents can get stuck inside a local minima incompetent in escaping without a workaround implementation. This paper presents efficient and accurate solutions to find collision free path using potential field for dynamic gaming and real time robot navigation. A surfing game in two testing environments with a Gamecar and a physical robot called Robocar is created with dynamic and solid obstacles. Sensor like proximity, line and ultrasonic are used along with the camera as different agents for path finding. The proposed intelligent agent (IA) technique is compared with other path planing algorithms and games in terms of time complexity, cost metrics, decision making complexity, action repertoire, interagent communication, reactivity and temporally continuous. It traverses for 135 meters(m) in 55.8 seconds(s) covering 20 goals and 419.3 m in 8.7 minutes while avoiding 10 local minimas successfully. Proposed technique shows comparable results to path finding with techniques using neural networks and A* algorithm. Experimental results prove the efficiency with run time overload, time complexity and resource consumption of the proposed technique.",https://ieeexplore.ieee.org/document/8995276/,2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI),4-6 Nov. 2019,ieeexplore
10.1109/HUMANOIDS.2017.8246935,Combining deep learning for visuomotor coordination with object identification to realize a high-level interface for robot object-picking,IEEE,Conferences,"We present a proof of concept to show how a deep network for end-to-end visuomotor learning to grasp is coupled with an attention focus mechanism for state-of-the-art object detection with convolutional neural networks. The cognitively motivated integration of both methods in a single robotic system allows us to realize a high-level interface to use the visuomotor network in environments with several objects, which otherwise would only be usable in environments with a single object. The resulting system is deployed on a humanoid robot, and we perform several real-world grasping experiments that demonstrate the feasibility of our approach.",https://ieeexplore.ieee.org/document/8246935/,2017 IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids),15-17 Nov. 2017,ieeexplore
10.23919/ICCAS47443.2019.8971680,Comparison of Object Recognition Approaches using Traditional Machine Vision and Modern Deep Learning Techniques for Mobile Robot,IEEE,Conferences,"In this paper, we consider the problem of object recognition for a mobile robot in an indoor environment using two different vision approaches. Our first approach uses HOG descriptor with SVM classifier as traditional machine vision model while the second approach uses Tiny-YOLOv3 as modern deep learning model. The purpose of this study is to gain intuitive insight of both approaches for understanding the principles behind these techniques through their practical implementation in real world. We train both approaches with our own dataset for doors. The proposed work is assessed through the real-world implementation of both approaches using mobile robot with Zed camera in real world indoor environment and the robustness has been evaluated by comparing and analyzing the experimental results of both models on same dataset.",https://ieeexplore.ieee.org/document/8971680/,"2019 19th International Conference on Control, Automation and Systems (ICCAS)",15-18 Oct. 2019,ieeexplore
10.1109/ROBIO.2009.4913338,Complex robot training tasks through bootstrapping system identification,IEEE,Conferences,"Many sensor-motor competences in mobile robotics applications exhibit complex, non-linear characteristics. Previous research has shown that polynomial NARMAX models can learn such complex tasks. However as the complexity of the task under investigation increases, representing the whole relationship in one single model using only raw sensory inputs would lead to large models. Training such models is extremely difficult, and, furthermore, obtained models often exhibit poor performances. This paper presents a bootsrapping method of generating complex robot training tasks using simple NARMAX models. We model the desired task by combining predefined low level sensor motor controllers. The viability of the proposed method is demonstrated by teaching a Scitos GS autonomous robot to achieve complex route learning tasks in the real world robotics experiments.",https://ieeexplore.ieee.org/document/4913338/,2008 IEEE International Conference on Robotics and Biomimetics,22-25 Feb. 2009,ieeexplore
10.1109/ICIT.2002.1189341,Computer based robot training in a virtual environment,IEEE,Conferences,"As more market segments are welcoming automation, the robotic field continues to expand. With the accepted breadth of viable industrial robotic applications increasing, the need for flexible robotic training also grows. In the area of simulation and offline programming there have been innovative developments to Computer Aided Robotics (CAR) Systems. New and notable releases have been introduced to the public, especially among the small, affordable, and easy to use systems. These CAR-Systems are mainly aimed at system integrators in general industry business fields to whom the complex, powerful software tools used by the automotive industry (and its suppliers) are oversized. In general, CAR-Systems are used to design robot cells and to create the offline programs necessary to reduce start-up time and to achieve a considerable degree of planning reliability. Another potential yet to be fully considered, is the use of such CAR-Systems as an inexpensive and user-friendly tool for robotics training. This paper will show the educational potential and possibility inherent in simulation and introduce a successful example of this new method of training. Finally, this presentation should be seen as an attempt to outline novel methods for future education in an industrial environment characterized by the increased occurrence and implementation of the virtual factory.",https://ieeexplore.ieee.org/document/1189341/,"2002 IEEE International Conference on Industrial Technology, 2002. IEEE ICIT '02.",11-14 Dec. 2002,ieeexplore
10.1109/IROS.2006.282163,Conceptual Design and Implementation of Arm Wrestling Robot,IEEE,Conferences,"In this paper, we develop a novel robotic arm wrestling system integrated with mechanical arm, elbow/wrist force sensors, servo motor, encoder, 3-D MEMS accelerometer, and USB camera. The arm wrestling robot (AWR) is intended to play arm wrestling game with real human on a table for entertainment. The designing scenario of the prototype model's hardware is performed. Elbow/wrist force sensors, as a crucial device in the force sensing system, are described in details. Software is developed for device driven and interface. The surface electromyographic (EMG) signals from the upper limb are sampled when a real player competes with the force testing system. By using the method of wavelet packet transformation (WPT), the high-frequency noises can be eliminated effectively and the characteristics of EMG signals can be extracted. Artificial neural network is adopted to estimate the elbow joint torque. The effectiveness of the humanoid algorithm using torque control estimated via WRT and neural network is confirmed by experiments",https://ieeexplore.ieee.org/document/4059139/,2006 IEEE/RSJ International Conference on Intelligent Robots and Systems,9-15 Oct. 2006,ieeexplore
10.1109/AITest.2019.00015,Constraint-Based Testing of An Industrial Multi-Robot Navigation System,IEEE,Conferences,"Intelligent multi-robot systems get more and more deployed in industrial settings to solve complex and repetitive tasks. Due to safety and economic reasons they need to operate dependably. To ensure a high degree of dependability, testing the deployed system has to be done in a rigorous way. Advanced multi-robot systems show a rich set of complex behaviors. Thus, these systems are difficult to test manually. Moreover, the space of potential environments and tasks for such systems is enormous. Therefore, methods that are able to explore this space in a structured way are needed. One way to address these issues is through model-based testing. In this paper we present an approach for testing the navigation system of a fleet of industrial transport robots. We show how all potential environments and navigation behaviors as well as requirements and restrictions can be represented in a formal constraint-based model. Moreover, we present the concept of coverage criteria in order to handle the potentially infinite space of test cases. Finally, we show how test cases can be derived from this model in an efficient way. In order to show the feasibility of the proposed approach we present an empirical evaluation of a prototype implementation using a real industrial use case.",https://ieeexplore.ieee.org/document/8718216/,2019 IEEE International Conference On Artificial Intelligence Testing (AITest),4-9 April 2019,ieeexplore
10.1109/IROS40897.2019.8967523,Contact Skill Imitation Learning for Robot-Independent Assembly Programming,IEEE,Conferences,"Robotic automation is a key driver for the advancement of technology. The skills of human workers, however, are difficult to program and seem currently unmatched by technical systems. In this work we present a data-driven approach to extract and learn robot-independent contact skills from human demonstrations in simulation environments, using a Long Short Term Memory (LSTM) network. Our model learns to generate error-correcting sequences of forces and torques in task space from object-relative motion, which industrial robots carry out through a Cartesian force control scheme on the real setup. This scheme uses forward dynamics computation of a virtually conditioned twin of the manipulator to solve the inverse kinematics problem. We evaluate our methods with an assembly experiment, in which our algorithm handles part tilting and jamming in order to succeed. The results show that the skill is robust towards localization uncertainty in task space and across different joint configurations of the robot. With our approach, non-experts can easily program force-sensitive assembly tasks in a robot-independent way.",https://ieeexplore.ieee.org/document/8967523/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/SAUPEC/RobMech/PRASA48453.2020.9041114,Context-Aware Action with a Small Mobile Robot,IEEE,Conferences,"Simultaneous advances in mobile GPU computing and real-time object recognition now enable machines to make decisions and take actions based on the detection of objects of interest in the environment. An implementation of a mobile robot system that combines autonomous exploration and mapping capabilities with a real-time object recognition method based on a deep neural network running on a mobile GPU, is described. The system is able to detect objects of interest and then take real-time actions to interact with the objects, in this case, by moving to acquire inspection-style images of the object, from multiple angles. The robot system is small, self-contained and runs on battery power. The system shows the potential for the development of robotic systems with context awareness, permitting advanced autonomy.",https://ieeexplore.ieee.org/document/9041114/,2020 International SAUPEC/RobMech/PRASA Conference,29-31 Jan. 2020,ieeexplore
10.1109/ICEEE.2011.6106626,Continuous-time neural control for a 2 DOF vertical robot manipulator,IEEE,Conferences,"This paper presents a continuous-time neural control scheme for identification and control of a two degrees of freedom (DOF) direct drive vertical robot manipulator model, on which effects due to friction and gravitational forces are both considered. A recurrent high-order neural network (RHONN) structure is proposed in order to identify the plant model to then, based on this neural structure, derive a neural controller using the backstepping design methodology. The trajectory tracking performance of the neural controller is illustrated via simulations results, which suggest the validity of the proposed approach for its implementation in real-time.",https://ieeexplore.ieee.org/document/6106626/,"2011 8th International Conference on Electrical Engineering, Computing Science and Automatic Control",26-28 Oct. 2011,ieeexplore
10.1109/ICRA40945.2020.9197209,Cooperative Multi-Robot Navigation in Dynamic Environment with Deep Reinforcement Learning,IEEE,Conferences,"The challenges of multi-robot navigation in dynamic environments lie in uncertainties in obstacle complexities, partially observation of robots, and policy implementation from simulations to the real world. This paper presents a cooperative approach to address the multi-robot navigation problem (MRNP) under dynamic environments using a deep reinforcement learning (DRL) framework, which can help multiple robots jointly achieve optimal paths despite a certain degree of obstacle complexities. The novelty of this work includes threefold: (1) developing a cooperative architecture that robots can exchange information with each other to select the optimal target locations; (2) developing a DRL based framework which can learn a navigation policy to generate the optimal paths for multiple robots; (3) developing a training mechanism based on dynamics randomization which can make the policy generalized and achieve the maximum performance in the real world. The method is tested with Gazebo simulations and 4 differential drive robots. Both simulation and experiment results validate the superior performance of the proposed method in terms of success rate and travel time when compared with the other state-of-art technologies.",https://ieeexplore.ieee.org/document/9197209/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/RCAR.2016.7784079,Coordination control of dual-arm robot based on modeled predictive control,IEEE,Conferences,"This paper presents a master-slave force hybrid coordinated motion control method which is based on the model predictive control (MPC) algorithm. In the paper, the kinematics model of the dual 6-DOF arms is build. Six axis force sensors are installed at the ends of the two arms, the master arm adopts the position control method and the based on the model predictive control algorithm DMC theory force/position hybrid control method is adopted in the slave arm. According to the kinematic model of the dual-arms, the end pose and joint angle rule conversion library is established, and the motion prediction model of the manipulator also is established. By using these models, the slave arm can acquire the position and direction of the master arm synchronously, and the current end position of the master arm is also used as the reference input value of the end position of the slave arm. The rotation operation sequence of the joint angle rule conversion library predicted model and end pose apply to the joint motor, drive the end of the robot arm to move to the target position. After doing these we could synchronously realize position tracking. In our experiment the current position tracking could be realized through the simulation analysis of six degree of freedom dual arm robot.",https://ieeexplore.ieee.org/document/7784079/,2016 IEEE International Conference on Real-time Computing and Robotics (RCAR),6-10 June 2016,ieeexplore
10.1109/IROS.2014.6942970,Coordination in human-robot teams using mental modeling and plan recognition,IEEE,Conferences,"Beliefs play an important role in human-robot teaming scenarios, where the robots must reason about other agents' intentions and beliefs in order to inform their own plan generation process, and to successfully coordinate plans with the other agents. In this paper, we cast the evolving and complex structure of beliefs, and inference over them, as a planning and plan recognition problem. We use agent beliefs and intentions modeled in terms of predicates in order to create an automated planning problem instance, which is then used along with a known and complete domain model in order to predict the plan of the agent whose beliefs are being modeled. Information extracted from this predicted plan is used to inform the planning process of the modeling agent, to enable coordination. We also look at an extension of this problem to a plan recognition problem. We conclude by presenting an evaluation of our technique through a case study implemented on a real robot.",https://ieeexplore.ieee.org/document/6942970/,2014 IEEE/RSJ International Conference on Intelligent Robots and Systems,14-18 Sept. 2014,ieeexplore
10.1109/IROS.2018.8593374,Cost of Transport Estimation for Legged Robot Based on Terrain Features Inference from Aerial Scan,IEEE,Conferences,"The effectiveness of the robot locomotion can be measured using the cost of transport (CoT) which represents the amount of energy that is needed for traversing from one place to another. Terrains excerpt different mechanical properties when crawled by a multi-legged robot, and thus different values of the CoT. It is therefore desirable to estimate the CoT in advance and plan the robot motion accordingly. However, the CoT might not be known prior the robot deployment, e.g., in extraterrestrial missions; hence, a robot has to learn different terrains as it crawls through the environment incrementally. In this work, we focus on estimating the CoT from visual and geometrical data of the crawled terrain. A thorough analysis of different terrain descriptors within the context of incremental learning is presented to select the best performing approach. We report on the achieved results and experimental verification of the selected approaches with a real hexapod robot crawling over six different terrains.",https://ieeexplore.ieee.org/document/8593374/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ICRA.2019.8794187,Deep Learning based Motion Prediction for Exoskeleton Robot Control in Upper Limb Rehabilitation,IEEE,Conferences,"The synchronization of the movement between exoskeleton robot and human arm is crucial for Robot-assisted training (RAT) in upper limb rehabilitation. In this paper, we propose a deep learning based motion prediction model which is applied to our recently developed 8 degrees-of-freedom (DoFs) upper limb rehabilitation exoskeleton, named NTUH-II. The human arm dynamics and surface electromyography (sEMG) can be first measured by two wireless sensors and used as input of deep learning model to predict user's motion. Then, the prediction can be used as desired motion trajectory of the exoskeleton. As a result, the robot arm can follow the movement on either side of the user's arm in real-time. Various experiments have been conducted to verify the performance of the proposed motion prediction model, and the results show that the proposed motion prediction implementation can reduce the mean absolute error and the average delay time of movement between human arm and robot arm.",https://ieeexplore.ieee.org/document/8794187/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/MSM49833.2020.9201666,Deep Learning-based Algorithm for Mobile Robot Control in Textureless Environment,IEEE,Conferences,"For the implementation of stereo image-based visual servoing algorithm in the eye-in-hand robotics applications, one of the main concerns is the accurate point feature detection and matching algorithm. Since the visual servoing is carried out in the textureless environment, the feature detection process is even more challenging. To fulfill the requirement of a robust and reliable point feature detection process, in this paper we present the novel deep learning-based algorithm. The approach based on convolutional neural networks and algorithm for detection of manufacturing entities is proposed and detected regions of interest are utilized for the improvement of the point feature detection algorithm. The proposed algorithm is experimentally evaluated in real-world settings by using wheeled nonholonomic mobile robot RAICO equipped with stereo vision system. The experimental results show the improvement of 58% in the accuracy of matched point features in the images obtained during the visual servoing process. Moreover, with the implementation of the proposed deep learning-based approach, the number of successful experimental runs has increased by 80%.",https://ieeexplore.ieee.org/document/9201666/,2020 International Conference Mechatronic Systems and Materials (MSM),1-3 July 2020,ieeexplore
10.1109/ROBIO.2018.8665274,Deep Reinforcement Learning Based Brachiation Control for Two-Link Bio-Primate Robot,IEEE,Conferences,"Manually designing an effective and efficient controller for complex mechanics, such as bio-inspired robots or underactuated mechanical system, typically are very difficult. It requires precise motion planning and dynamic control. Reinforcement learning or genetic algorithm based learning methods suffers from representing the high dimensional models. The combination of deep learning and reinforcement learning provide a feasible way to handle such difficulties. However, priori-less searching sometimes tends to be low efficient and usually finds the “mechanic” solution instead of the “natural” one. In this paper, the traditional nonlinear control concept is integrated into the deep reinforcement learning (DRL) framework. The whole process is implemented on the brachiation control problem of a two link bio-primate robot. Deep Deterministic Policy Gradient (DDPG) is used to search for the optimal control policy. The searching process is realized by interacting with the dynamic model instead of real robot. The energy based planning and control concept is adopted, which utilize the fact that when the shoulder joint angle is fixed, energy of the whole system keeps constant. By regulating the angle and energy, the robot can be restricted on a particular trajectory. The energy concept is encoded within the reward function and trained in the Gym environment. For varying targets point-to-point control, the network structure is also modified to accept the target coordinates. Effectiveness of the proposed methods are verified by simulation and experimental results.",https://ieeexplore.ieee.org/document/8665274/,2018 IEEE International Conference on Robotics and Biomimetics (ROBIO),12-15 Dec. 2018,ieeexplore
10.23919/ICCAS47443.2019.8971637,Deep Reinforcement Learning Based Robot Arm Manipulation with Efficient Training Data through Simulation,IEEE,Conferences,"Deep reinforcement learning trains neural networks using experiences sampled from the replay buffer, which is commonly updated at each time step. In this paper, we propose a method to update the replay buffer adaptively and selectively to train a robot arm to accomplish a suction task in simulation. The response time of the agent is thoroughly taken into account. The state transitions that remain stuck at the boundary of constraint are not stored. The policy trained with our method works better than the one with the common replay buffer update method. The result is demonstrated both by simulation and by experiment with a real robot arm.",https://ieeexplore.ieee.org/document/8971637/,"2019 19th International Conference on Control, Automation and Systems (ICCAS)",15-18 Oct. 2019,ieeexplore
10.1109/ICRA48506.2021.9561145,Deep Reinforcement Learning Framework for Underwater Locomotion of Soft Robot,IEEE,Conferences,"Soft robotics is an emerging technology with excellent application prospects. However, due to the inherent compliance of the materials used to build soft robots, it is extremely complicated to control soft robots accurately. In this paper, we introduce a data-based control framework for solving the soft robot underwater locomotion problem using deep reinforcement learning (DRL). We first built a soft robot that can swim based on the dielectric elastomer actuator (DEA). We then modeled it in a simulation for the purpose of training the neural network and tested the performance of the control framework through real experiments on the robot. The framework includes the following: a simulation method for the soft robot that can be used to collect data for training the neural network, the neural network controller of the swimming robot trained in the simulation environment, and the computer vision method to collect the observation space from the real robot using a camera. We confirmed the effectiveness of the learning method for the soft swimming robot in the simulation environment by allowing the robot to learn how to move from a random initial state to a specific direction. After obtaining the trained neural network through the simulation, we deployed it on the real robot and tested the performance of the control framework. The soft robot successfully achieved the goal of moving in a straight line in disturbed water. The experimental results suggest the potential of using deep reinforcement learning to improve the locomotion ability of mobile soft robots.",https://ieeexplore.ieee.org/document/9561145/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ROMAN.2017.8172429,Deep recurrent Q-learning of behavioral intervention delivery by a robot from demonstration data,IEEE,Conferences,"We present a learning from demonstration (LfD) framework that uses a deep recurrent Q-network (DRQN) to learn how to deliver a behavioral intervention (BI) from demonstrations performed by a human. The trained DRQN enables a robot to deliver a similar BI in an autonomous manner. BIs are highly structured procedures wherein children with developmental delays/disorders (e.g. autism, ADHD, etc.) are trained to perform new behaviors and life-skills. Mounting anecdotal evidence from human-robot interaction (HRI) research has shown that BI benefits from the use of robots as a delivery tool. Most of the HRI research on robot-based intervention relies on tele-operated robots. However, the need for autonomy has become increasingly evident, especially when it comes to the real-world deployment of these systems. The few studies that have used autonomy in robot-based BI relied on hand-picked features of the environment in order to trigger correct robot actions. Additionally, none of these automated architectures attempted to learn the BI from human demonstrations, though this appears to be the most natural way of learning. This paper represents the first attempt to design a robot that uses LfD to learn BI. We generate a model then correctly predict appropriate actions with greater than 80% accuracy. To the best of our knowledge, this is the first attempt to employ DRQN within an LfD framework to learn high level reasoning embedded in human actions and behaviors simply from observations.",https://ieeexplore.ieee.org/document/8172429/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/AINL-ISMW-FRUCT.2015.7382967,Design and implementation Raspberry Pi-based omni-wheel mobile robot,IEEE,Conferences,Nowadays simultaneous localization and mapping (SLAM) algorithms are being tested at least in two phases: software simulation and real hardware platform testing. This paper describes hardware design and control software for small size omni-directional wheels robot implemented for indoor testing SLAM algorithms.,https://ieeexplore.ieee.org/document/7382967/,"2015 Artificial Intelligence and Natural Language and Information Extraction, Social Media and Web Search FRUCT Conference (AINL-ISMW FRUCT)",9-14 Nov. 2015,ieeexplore
10.1109/ETFA.2015.7301549,Design and implementation for multiple-robot deployment in intelligent space,IEEE,Conferences,"This paper presents the problem of robot deployment for a number of scattered tasks. We aim to minimize the duration it takes for all robots to reach their assigned task locations. In previous work, we have proposed a team composed of one carrier robot (CR) and several servant robots to accomplish the mission. Then we have suggested an algorithm that determines a path of the CR for an efficient deployment under a few constraints, which is verified by simulations. Assuming that the servant robots are unmanned aerial vehicles (UAVs), the present paper extends the discussion to a real robot experiment. We design and implement a deployment system in intelligent space. The feasibility of the study is demonstrated through an experiment.",https://ieeexplore.ieee.org/document/7301549/,2015 IEEE 20th Conference on Emerging Technologies & Factory Automation (ETFA),8-11 Sept. 2015,ieeexplore
10.1109/ICMA.2017.8015890,Design and implementation of self-tuning control method for the underwater spherical robot,IEEE,Conferences,"Considering the complicated disturbance in underwater circumstance, usually it is difficult to solve the control problem when the robot changes its motion state or it is subject to ocean currents, its performance deteriorates since the fixed set of parameters is no longer valid for the new conditions. Thus, in this paper, an auto-tune PID (Proportional + Integral + Derivative)-like controller based on Neural Networks is applied to our amphibious spherical underwater robot, which has a great advantage on processing online for the robot due to their nonlinear dynamics. The Neural Networks (NN) plays the role of automatically estimating the suitable set of PID gains that achieves stability of the system. The NN adjusts online the controller gains that attain the smaller position tracking error. The performance of the NN-based controller is investigated in ADAMS and MATLAB cooperative simulation. The velocity of the spherical robot can be controlled to precisely track desired trajectory in body-fixed coordinate system. Additionally, real time experiments on our underwater spherical robot are conducted to show the effectiveness of the algorithm.",https://ieeexplore.ieee.org/document/8015890/,2017 IEEE International Conference on Mechatronics and Automation (ICMA),6-9 Aug. 2017,ieeexplore
10.1109/AIEA53260.2021.00013,Design of a Real-time Robot Control System oriented for Human-Robot Cooperation,IEEE,Conferences,"An open real-time control system based on the EtherCAT fieldbus communication technology is proposed to fulfill the high real-time requirement of the human-robot cooperation controller in this paper. An open source real-time kernel of Xenomai is employed as the real-time software platform of the robot control system. Based on this, four-layer interfaces architecture are accomplished, which are human-machine cooperation control layer, motion control layer, robot axis control layer and hardware abstraction layer, through the corresponding four real-time tasks to meet the demand of human-robot cooperation operations. In addition, the scheduling task is developed to manage the 4 real-time tasks. The dual buffer communication mechanisms and priority-based scheduling strategy between layers was exploited to synchronize these real-time tasks. The underlying hardware abstract interface and the human-robot collaborative control algorithm interface are opened in the control system as the quadric exploitation interfaces to meet the need of developing application tasks in real-time space. Experiment results which are conducted on a self-developed 6-DOF collaborative robot show that the proposed control system is effective in real-time control applications of human-robot cooperative control at the control cycle of 5 milliseconds.",https://ieeexplore.ieee.org/document/9525600/,2021 International Conference on Artificial Intelligence and Electromechanical Automation (AIEA),14-16 May 2021,ieeexplore
10.1109/CNNA.2000.876849,Design of a dedicated CNN chip for autonomous robot navigation,IEEE,Conferences,"Obstacle avoidance is the main issue in autonomous robotics. It requires a three-dimensional effective environment sensing in real time. Among the others, the stereo vision approach to environmental information extraction seems to be very appealing, even if it leads an extremely high computational cost. However, a high performance implementation of this algorithm on a cellular neural network is able to overcome these difficulties. In the paper, the design of a CNN chip well suited for this algorithm is presented. This chip, performing a real time processing of the stereo vision data, will improve the cruising speed of a robotic platform.",https://ieeexplore.ieee.org/document/876849/,Proceedings of the 2000 6th IEEE International Workshop on Cellular Neural Networks and their Applications (CNNA 2000) (Cat. No.00TH8509),25-25 May 2000,ieeexplore
10.1049/cp.2012.1101,Design of a real-time tracking robot based on simplified binocular positioning model,IET,Conferences,"A real-time-tracking robot based on binocular positioning is proposed in this essay. This system synthetically evaluates both color and morphological property of the target, realizing fast positioning with a simplified binocular positioning model. With the use of Kalman filter to predict the movement of the target, the system promptly adjusts the direction of the PTZ which carries the cameras, making it possible for the real time tracking of the target. Besides, the essay introduces an edge detection algorithm based on brightness equalization to eliminate possible false boundary lines caused by shadows or illumination. Finally, experiment results demonstrate the realtime performance and accuracy of the system.",https://ieeexplore.ieee.org/document/6492708/,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),3-5 March 2012,ieeexplore
10.1109/CMCE.2010.5609659,Design of mobile robot system with remote control based on CAN-bus,IEEE,Conferences,"In order to realizing remote control and information collection quickly and reliably, the mobile robot with remote control is designed. In the paper, according to analysis of the overall structure, hardware circuit of the robot system is designed. Because the CAN2.0 standard only makes physical layer protocol and data link layer protocol, application layer protocol is ruled according to robot control system. In the last part of this paper, the software of master/slave computer is introduced in detail. The experiment shows that running performance of robot control system is balanced, efficient and has satisfied the practical demand.",https://ieeexplore.ieee.org/document/5609659/,"2010 International Conference on Computer, Mechatronics, Control and Electronic Engineering",24-26 Aug. 2010,ieeexplore
10.1109/ICMA.2006.257524,"Design, Fabrication and Application of ARm Wrestling Robot",IEEE,Conferences,"This paper presents a novel 2 DOF robotic arm wrestling system integrated with mechanical arm, elbow/wrist force sensors, servo motor, encoder, 3-D MEMS accelerometer, and USB camera. The arm wrestling robot (AWR) is used to play arm wrestling game with human for entertainment. Based on the force testing equipment, we acquire the data of surface electromyographic (EMG) signals form target muscle when a real player competes with the robot. Wavelet transform and neural network are applied to extract the characteristics of EMG signals and estimate the joint torque. Experiment results have proved the validation of the wavelet neural network method",https://ieeexplore.ieee.org/document/4026383/,2006 International Conference on Mechatronics and Automation,25-28 June 2006,ieeexplore
10.1109/ICSMC.1998.726514,"Designing, making, and using a mobile robot",IEEE,Conferences,"Describes the building and control of a mobile robot which is capable of navigating in a well defined workspace by means of generating an optimal trajectory. The basic control architecture of the mobile robot is implemented with a combination of an MC68HC11 microcontroller and a personal computer. The kinematics of the proposed differential impulse is analyzed which allow us to select the appropriate steering DC motors and speed measurement requirements of the system. The motor control is performed by a PWM scheme and PI controllers. A path planning stage finds the optimal trajectory, taking a graphical description of the workspace and using potential fields and dynamic programming to solve the optimization problem and avoid the obstacles. Clearly there are two specific problems: building a complete device that will allow having an electric powered robot and the use of these resources to obtain controlled and collision-free movement in a real workspace.",https://ieeexplore.ieee.org/document/726514/,"SMC'98 Conference Proceedings. 1998 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.98CH36218)",14-14 Oct. 1998,ieeexplore
10.1109/ICoSTA48221.2020.1570615971,Detecting Features of Middle Size Soccer Field using Omnidirectional Camera for Robot Soccer ERSOW,IEEE,Conferences,"ERSOW (EEPIS Robot Soccer on Wheeled) is robot soccer developed by Politeknik Elektronika Negeri Surabaya that is designed and implemented on a Middle Size League division by following the rules of RoboCup, an international robot competition. One of the most famous division is a soccer robot, that is divided into two divisions: (1) SSL (Small Size League) and (2) MSL (Middle Size League). There are many research fields related to soccer robot which must be developed in robot ERSOW such as Artificial Intelligence (AI), Computer Vision, Embedded System, Mechanic Systems, and Hardware. This paper focuses on computer vision research for robot ERSOW, especially detecting features of the middle size soccer field, so that specific features of the field like X-junction, T-junction and L-junction can be detected to help robot positioning task where the result is represented into x and y in real-world coordinate. By knowing the position of the features, the robot position can be calculated. The localization system at robot ERSOW uses odometry, which has a large percentage of data errors. Therefore, we attempt to extract the feature of X-junction that is done to find its x and y coordinates and then the obtained coordinate can be used as a reference for correcting odometry data by AI.",https://ieeexplore.ieee.org/document/9079260/,2020 International Conference on Smart Technology and Applications (ICoSTA),20-20 Feb. 2020,ieeexplore
10.1109/ICCSPN46366.2019.9150190,Developing A Framework for A Tactile Internet Enabled Robot Assisted Real-Time Interactive Medical System,IEEE,Conferences,"In this paper we outline a high-level framework and architecture for a robotic assisted real time interactive medical system for use in developing countries to help cure the acute shortage of qualified skill medical personnel in the health sector in of an internet of skills domain. We explore the application of new and innovative advancements in technological areas such as AI, 5G mobile networks, the tactile internet networks, robotics and haptic technology to aid in the digital transfer of medical expertise over a wide geographical area. We describe and propose technical specifications of such systems and review existing literature and current technologies in these areas. We interrogate the potential benefits and challenges facing the deployment of these technologies.",https://ieeexplore.ieee.org/document/9150190/,"2019 International Conference on Communications, Signal Processing and Networks (ICCSPN)",29-31 May 2019,ieeexplore
10.1109/IECON48115.2021.9589075,Development of Agricultural Robot Platform with Virtual Laboratory Capabilities,IEEE,Conferences,"Agricultural robots are called to help in many tasks in emerging clean and sustainable agriculture. These complex electro-mechanical systems can actually integrate artificial intelligence (AI), the Internet of Things (IoT), sensors, actuators, and advanced control methods to accomplish functions in autonomous or in collaborative ways. Before the deployment of such techniques in the field, it is convenient to carry out laboratory validations. These last could be at the sub-system, e.g., sensors or servos operation, or the whole system level. This paper proposes the development of the hardware and software parts of a platform of agricultural robot. The proposed system, highly motivated by the restrictions imposed by COVID-19 context, enables laboratory tests virtualization while keeping real-time functionalities",https://ieeexplore.ieee.org/document/9589075/,IECON 2021 – 47th Annual Conference of the IEEE Industrial Electronics Society,13-16 Oct. 2021,ieeexplore
10.1109/ICIS.2018.8466473,Development of a GPU-Based Human Emotion Recognition Robot Eye for Service Robot by Using Convolutional Neural Network,IEEE,Conferences,"Service robots can be used widely to assist elderly and disable population due to the lack of caregivers in future. Real-time human tracking, detection, focusing and implementing various algorithms are a wide range of application in emotion recognition service robots. Therefore service robots must have a properly designed robot eye model to be human-friendly with accurate human-robot interaction. Developed robot eye can be recognized the human emotional states by using well trained deep convolutional neural networks (ConvNet). This paper describes graphics processing units (GPUs) based human emotion recognition robot eye by using ConvNet. Mainly, the robot eye performs two processes in the intelligent systems. They are the robot eye focus to the human face and head by using pre-trained haar cascade classifier and recognizes the human emotional states probability with percentages as happy, sad or relaxes by using pre-trained ConvNet. The developed robot eye was implemented and tested by using different people successfully and the results of them are presented. According to the results, the emotions are detected more than 85% of overall accuracy for each person.",https://ieeexplore.ieee.org/document/8466473/,2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS),6-8 June 2018,ieeexplore
10.1109/SII46433.2020.9025980,Development of a Web-Based Education System for Deep Reinforcement Learning-Based Autonomous Mobile Robot Navigation in Real World,IEEE,Conferences,"The technology that combined deep reinforcement learning and robotics is increasing interests in recent years. Although several online tools for studying this technology can be found, it is difficult for beginners to develop actual robot systems for autonomous navigation in the real world. In this study, we developed a web-based educational system that is able to help users to study mobile robot navigation based on deep reinforcement learning and develop actual robot systems. The proposed web system provides the following functions: setting the parameters of reinforcement learning for autonomous robot navigation, running learning scripts and monitoring status of the learning. The first experiment that a user develops an actual robot system was performed. In the experiment, the user tuned parameters on the web page started the training and obtained action policy models. The experimental results indicate the proposed system can be applied to develop an actual autonomous navigation system. Also, the user could decide better parameters through the trial and error process using the proposed system.",https://ieeexplore.ieee.org/document/9025980/,2020 IEEE/SICE International Symposium on System Integration (SII),12-15 Jan. 2020,ieeexplore
10.1109/ROBIO.2012.6491198,Development of a cricket interaction system utilizing mobile robot for behavioral data collection,IEEE,Conferences,"This paper describes about a prototype of active interaction experiment system between a cricket and an operated micro mobile robot and measured/collected data in real-time by using the system. The behavior selection of the cricket (Gyllus bimaculatus) is influenced by the experience or the context in living environment. Therefore, we are trying to investigate neuronal mechanisms underlying micro brain of the cricket. For gathering behavioral data, we are developing a control/measurement system for realizing active interaction experiment. The prototype is composed of a micro mobile robot as a physical interaction agent, a camera and a microphone and a computer commands to the micro mobile robot and record the data of video sequence, motion tracking and the audio. Experimental trial using the prototype was done and reported.",https://ieeexplore.ieee.org/document/6491198/,2012 IEEE International Conference on Robotics and Biomimetics (ROBIO),11-14 Dec. 2012,ieeexplore
10.1109/ISSNIP.2008.4761994,Development of a social learning mechanism for a humanoid robot,IEEE,Conferences,"A main purpose of humanoid robotic research is to develop a socially interactive robot by providing for a certain degree adaptability and flexibility in order to endow the robot with natural interactions with humans. In this paper, a social learning mechanism is proposed for enabling a humanoid robot to learn social behaviors through imitation. To achieve this goal, a novel imitation algorithm is proposed for transferring human social behaviors into a robot in real time. This approach considers the characteristic of motions for extracting symbolic postures, which consists of changing the points of motion directions. Reinforcement learning is utilized for extracting optimal symbolic postures and for incorporating the divisional cubic spline interpolation for generating a robotpsilas social behaviors through symbolic postures. In our experiment, we attempt to transfer three social cues: a ldquopointing gesture,rdquo a gesture for ldquoexplaining something attractively,rdquo and a gesture for expressing ldquoI donpsilat know.rdquo The experimental results confirmed the accuracy of the robot motion generation through the proposed mechanism for transferring natural social behaviors.",https://ieeexplore.ieee.org/document/4761994/,"2008 International Conference on Intelligent Sensors, Sensor Networks and Information Processing",15-18 Dec. 2008,ieeexplore
10.1109/FUZZY.2008.4630654,Differential reinforcement-type shaping Q-Learning method based on animal training for autonomous mobile robot,IEEE,Conferences,"The general idea of ldquoshapingrdquo used by ethology, behavior analysis or animal training is a remarkable method. ldquoShapingrdquo is a general idea that the learner is given a reinforcement signal step by step gradually and inductively forward the behavior from easy tasks to complicated tasks. In this paper, we propose a shaping reinforcement learning method took in a general idea of shaping to the reinforcement learning that can acquire a desired behavior by the repeated search autonomously. Three different shaping reinforcement learning methods used Q-learning, profit sharing, and actor-critic to check the efficiency of the shaping were proposed at first. Furthermore, we proposed the differential reinforcement-type shaping Q-learning (DR-SQL) applied a general idea of ldquodifferential reinforcementrdquo to reinforce a special behavior step by step such as real animal training, and confirmed the effectiveness of these methods by the simulation experiment of grid search problem.",https://ieeexplore.ieee.org/document/4630654/,2008 IEEE International Conference on Fuzzy Systems (IEEE World Congress on Computational Intelligence),1-6 June 2008,ieeexplore
10.1109/IJCNN48605.2020.9207522,Discrete-Time Lyapunov based Kinematic Control of Robot Manipulator using Actor-Critic Framework,IEEE,Conferences,"Stability and optimality are the two foremost re-quirements for robotic systems that are deployed in critical operations and are to work for long hours or under limited energy resources. To address these, in this work we present a novel Lyapunov stability based discrete-time optimal kinematic control of a robot manipulator using actor-critic (AC) framework. The robot is actuated using optimal joint-space velocity control input to track a time-varying end-effector trajectory in its task space. In comparison to the existing near-optimal kinematic control solutions for robot manipulator under AC framework, proposed controller exhibits guaranteed analytical stability. We derive a novel critic weight update law based on Lyapunov stability, thus ensuring that the weights are updated along the negative gradient of Lyapunov function. This eventually ensures closed-loop system stability and convergence to the optimal control in discrete-time. Extensive simulations are performed on a 3D model of 6-DoF Universal Robot (UR) 10 in Gazebo, followed by implementation on real UR 10 robot manipulator to show the efficacy of the proposed scheme.",https://ieeexplore.ieee.org/document/9207522/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1049/cp.2012.1127,Distributed parallel processing of mobile robot PF-SLAM,IET,Conferences,"Real-time property is a fundamental requirement for a practical robot system. For this purpose, this article proposes an implementation architecture of robot SLAM by adopting two parallel threads processing. Since the dominant factor which determines the computational complexity is the employed particle number, two distributed threads with different particle set size are executed simultaneously. Conventional PF-SLAM algorithm occupies one of threads, and the other thread which hires more particles is activated whenever robot has significant motion changes. Advantages of this presented idea are validated by experiment carried on Pioneer robot.",https://ieeexplore.ieee.org/document/6492734/,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),3-5 March 2012,ieeexplore
10.1109/EMBC.2015.7318719,EEG error potentials detection and classification using time-frequency features for robot reinforcement learning,IEEE,Conferences,"In thought-based steering of robots, error potentials (ErrP) can appear when the action resulting from the brain-machine interface (BMI) classifier/controller does not correspond to the user's thought. Using the Steady State Visual Evoked Potentials (SSVEP) techniques, ErrP, which appear when a classification error occurs, are not easily recognizable by only examining the temporal or frequency characteristics of EEG signals. A supplementary classification process is therefore needed to identify them in order to stop the course of the action and back up to a recovery state. This paper presents a set of time-frequency (t-f) features for the detection and classification of EEG ErrP in extra-brain activities due to misclassification observed by a user exploiting non-invasive BMI and robot control in the task space. The proposed features are able to characterize and detect ErrP activities in the t-f domain. These features are derived from the information embedded in the t-f representation of EEG signals, and include the Instantaneous Frequency (IF), t-f information complexity, SVD information, energy concentration and sub-bands' energies. The experiment results on real EEG data show that the use of the proposed t-f features for detecting and classifying EEG ErrP achieved an overall classification accuracy up to 97% for 50 EEG segments using 2-class SVM classifier.",https://ieeexplore.ieee.org/document/7318719/,2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),25-29 Aug. 2015,ieeexplore
10.1109/CSCloud-EdgeCom49738.2020.00050,Edge Computing-based 3D Pose Estimation and Calibration for Robot Arms,IEEE,Conferences,"Industrial robots are widely used in current production lines, and complex pipeline processes, especially those with different assembly requirements, are designed for intelligent manufacturing in the era of industry 4.0. During the new crown epidemic, a large number of car companies used the production line to transform production of medical materials such as masks and protective clothing, which provided a strong guarantee for fighting the epidemic. In this scenario, a pipeline is often assembled from robotic arms from multiple suppliers. The traditional methods is complex and takes a lot of time. In this paper, we propose a novel deep learning based robot arm 3D pose estimation and calibration model with simple Kinect stereo cameras which can be deployed on light-weight edge computing systems. The light-weight deep CNN model can detection 5 predefined key points based on RGB-D data. In this way, when the assembly line composed of different robot arms needs to be reassembled, our model can quickly provide the robot's pose information without additional tuning processes. Testing in Webots with Rokae xb4 robot arm model shows that our model can quickly estimate the key point of the robot arm.",https://ieeexplore.ieee.org/document/9170983/,2020 7th IEEE International Conference on Cyber Security and Cloud Computing (CSCloud)/2020 6th IEEE International Conference on Edge Computing and Scalable Cloud (EdgeCom),1-3 Aug. 2020,ieeexplore
10.1109/RCAR.2018.8621810,Efficient and Low-Cost Deep-Learning Based Gaze Estimator for Surgical Robot Control,IEEE,Conferences,"Surgical robots are playing more and more important role in modern operating room. However, operations by using surgical robot are not easy to handle by doctors. Vision based human-computer interaction (HCI) is a way to ease the difficulty to control surgical robots. While the problem of this method is that eyes tracking devices are expensive. In this paper, a low cost and robust deep-learning based on gaze estimator is proposed to control surgical robots. By this method, doctors can easily control the robot by specifying the starting point and ending point of the surgical robot using eye gazing. Surgical robots can also be controlled to move in 9 directions using controllers' eyes gazing information. A Densely Connected convolutional Neural Networks (Dense CNN) model for 9-direction/36-direction gaze estimation is built. The Dense CNN architecture has much more less trainable parameters compared to traditional CNN network architecture (AlexNet like/VGG like) which is more feasible to deploy on the Field-Programmable Gate Array (FPGA) and other hardware with limited memories.",https://ieeexplore.ieee.org/document/8621810/,2018 IEEE International Conference on Real-time Computing and Robotics (RCAR),1-5 Aug. 2018,ieeexplore
10.1109/ROMAN.2009.5326159,Efficient parsing of spoken inputs for human-robot interaction,IEEE,Conferences,"The use of deep parsers in spoken dialogue systems is usually subject to strong performance requirements. This is particularly the case in human-robot interaction, where the computing resources are limited and must be shared by many components in parallel. A real-time dialogue system must be capable of responding quickly to any given utterance, even in the presence of noisy, ambiguous or distorted input. The parser must therefore ensure that the number of analyses remains bounded at every processing step. The paper presents a practical approach to addressing this issue in the context of deep parsers designed for spoken dialogue. The approach is based on a word lattice parser combined with a statistical model for parse selection. Each word lattice is parsed incrementally, word by word, and a discriminative model is applied at each incremental step to prune the set of resulting partial analyses. The model incorporates a wide range of linguistic and contextual features and can be trained with a simple perceptron. The approach is fully implemented as part of a spoken dialogue system for human-robot interaction. Evaluation results on a Wizard-of-Oz test suite demonstrate significant improvements in parsing time.",https://ieeexplore.ieee.org/document/5326159/,RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication,27 Sept.-2 Oct. 2009,ieeexplore
10.1109/IROS.2012.6385832,Elastic strips: Implementation on a physical humanoid robot,IEEE,Conferences,"For robots to operate in human environments, they are required to react safely to unexpected changes in the work area. However, existing manipulation task planning methods take more than several seconds or minutes to update their solutions when environmental changes are recognized. Furthermore, the computation time exponentially increases in case of highly complex structures such as humanoid robots. Therefore, we propose a reactive system for high d.o.f. robots to perform interactive manipulation tasks under real-time conditions. The paper describes the implementation of the Elastic Strip Framework, a plan modification approach to update initial motion plans. To improve its real-time performance and reliability, the previous geometric approximation is replaced by an implicit method that constructs an elastic tunnel for collision checking. Additionally, in order to maintain a robust system even in exceptional situations, such as undetected obstacles, the force transformer module executes compliant motions, and the current elastic strip adapts the path tracking motion by monitoring tracking errors of the actual motion. The proposed system is applied to a Honda humanoid robot. Real-time performance is successfully demonstrated in real-world experiments.",https://ieeexplore.ieee.org/document/6385832/,2012 IEEE/RSJ International Conference on Intelligent Robots and Systems,7-12 Oct. 2012,ieeexplore
10.1109/ICE2T.2017.8215992,Elevator button and floor number recognition through hybrid image classification approach for navigation of service robot in buildings,IEEE,Conferences,"To successfully move a robot into the building, the elevator button and elevator floor number detection and recognition can play an important role. It can help a robot move in the building, just as it also can help a visually impaired person who wants to move another floor in the building. Due to vision-based approach, the difference in lighting condition and the complex background are the main obstacles in this research. A hybrid image classification model is presented in this research to overcome all these difficulties. This hybrid model is the combination of histogram of oriented gradients and bag of words models, which later reduces the dimension of image features by using the feature selection algorithm. An artificial neural network has been implemented to get the experimental result by training and testing. In order to get training performance, 1000 training image samples have been used and additional 1000 image samples also been used to get the testing performance. The experimental results of this research indicate that this proposed framework is important for real-time implementation to implement the elevator button and elevator floor number recognition framework.",https://ieeexplore.ieee.org/document/8215992/,2017 International Conference on Engineering Technology and Technopreneurship (ICE2T),18-20 Sept. 2017,ieeexplore
10.1109/ICIEV.2018.8641023,Embedded System based Bangla Intelligent Social Virtual Robot with Sentiment Analysis,IEEE,Conferences,"Bangla is the mother tongue of millions of people all over the world. Despite being a very popular language, any social virtual robot that can intelligently communicate in Bangla is a fairytale till now. One of the main reason of this is lack of rich text corpus and previous research on Bangla language. The proposed Bangla Intelligent Social Virtual Robot can communicate in Bangla intelligently and can express its reflective emotion virtually with the help of machine learning algorithms and sentiment analysis. In this paper, we discuss the approached system, design methodology and implementation details of first ever Bangla virtual embedded robot followed by the methodology of building a rich Bangla text corpus. The proposed embedded virtual robot turns out better performer when compared with only known Bangla intelligent chatbot named `Golpo' and the embedded system performance efficiency has been upgraded with the help CPU over-clocking technique.",https://ieeexplore.ieee.org/document/8641023/,"2018 Joint 7th International Conference on Informatics, Electronics & Vision (ICIEV) and 2018 2nd International Conference on Imaging, Vision & Pattern Recognition (icIVPR)",25-29 June 2018,ieeexplore
10.1109/ICCE.2018.8326229,End-to-end deep learning for autonomous navigation of mobile robot,IEEE,Conferences,"This paper proposes an end-to-end method for training convolutional neural networks for autonomous navigation of a mobile robot. Traditional approach for robot navigation consists of three steps. The first step is extracting visual features from the scene using the camera input. The second step is to figure out the current position by using a classifier on the extracted visual features. The last step is making a rule for moving the direction manually or training a model to handle the direction. In contrast to the traditional multi-step method, the proposed visuo-motor navigation system can directly output the linear and angular velocities of the robot from an input image in a single step. The trained model gives wheel velocities for navigation as outputs in real-time making it possible to be implanted on mobile robots such as robotic vacuum cleaner. The experimental results show an average linear velocity error of 2.2 cm/s and average angular velocity error of 3.03 degree/s. The robot deployed with the proposed model can navigate in a real-world environment by only using the camera without relying on any other sensors such as LiDAR, Radar, IR, GPS, IMU.",https://ieeexplore.ieee.org/document/8326229/,2018 IEEE International Conference on Consumer Electronics (ICCE),12-14 Jan. 2018,ieeexplore
10.1109/ICRA48506.2021.9562114,Enhancing Robot Perception in Grasping and Dexterous Manipulation through Crowdsourcing and Gamification,IEEE,Conferences,"Robot grasping and manipulation planning in unstructured and dynamic environments is heavily dependent on the attributes of manipulated objects. Although deep learning approaches have delivered exceptional performance in robot perception, human perception and reasoning are still superior in processing novel object classes. Moreover, training such models requires large datasets that are generally expensive to obtain. This work combines crowdsourcing and gamification to leverage human intelligence, enhancing the object recognition and attribute estimation aspects of robot perception. The framework employs an attribute matching system that encodes visual information into an online puzzle game, utilizing the collective intelligence of players to expand an initial attribute database and react to real-time perception conflicts. The framework is deployed and evaluated in a proof-of-concept application for enhancing object recognition in autonomous robot grasping and a model for estimating the response time is proposed. The obtained results demonstrate that given enough players, the framework can offer near real-time labeling of novel objects, based purely on visual information and human experience.",https://ieeexplore.ieee.org/document/9562114/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/IECON.2017.8217492,Enhancing the familiarity for humanoid robot pepper by adopting customizable motion,IEEE,Conferences,"Most of the works use sensor to recognize human gesture and teleoperate robot in real time for different usage. One of the purpose is social learning which human learn behavior and take place in the social context. Our research aims to let user create customizable gesture and motion for proper condition. This paper presented the method to replicates human gesture for robot imitation. If robot can adapt human like behavior to interact with human, it is potentially helpful to build intimate between human and robot. Human gesture were recorded and unnecessary noise was removed to smooth robot's motion. Furthermore, by changing motion speed it is possible to create different feeling so that it might be arouse human's interest and spice up the interaction. The experiment results show the parameter pair to implement motion on robot.",https://ieeexplore.ieee.org/document/8217492/,IECON 2017 - 43rd Annual Conference of the IEEE Industrial Electronics Society,29 Oct.-1 Nov. 2017,ieeexplore
10.1109/ICIA.2006.306024,Environmental Perception of Mobile Robot,IEEE,Conferences,"This paper builds a system to perceive the unknown environment based on multi-sensor data fusion. It enables the self-determined mobile robot to identify the type of the obstacles around it timely in the process of travel, and the mobile robot achieves more intelligent operations. First, the paper introduces the theory of the mobile robot's environmental perception and the configuration of the multi-sensor data fusion technology. Second, it combines the characteristics of neural network (NN) and brings forward that apply the MLP (multi-layer perception), which based on the improved back propagation (BP) arithmetic and four mature items of fusion rules, to perceive the real surroundings aiming at simplifying the former solving projects. Third, the paper presents a structure of multi-sensor data fusion, which two sub-networks for barrier recognition are separately built and incorporates with each other by parallel connection to form a high-powered recognition system. Finally, the results of experiment present that the method given by the paper are very pleasant",https://ieeexplore.ieee.org/document/4097957/,2006 IEEE International Conference on Information Acquisition,20-23 Aug. 2006,ieeexplore
10.1109/ICCAE.2009.52,Environmental Recognition Using RAM-Network Based Type-2 Fuzzy Neural for Navigation of Mobile Robot,IEEE,Conferences,"Reactive autonomous mobile robot navigating in real time environment is one of the most important requirements. Most of the systems have some common drawbacks such as, large computation, expensive equipment, hard implementation, and the complexity of the system. The work presented in this paper deals with a type-2 fuzzy-neural controller using RAM-based network to make navigation decisions. The proposed architecture can be implemented easily with low cost range sensor and low cost microprocessor. To minimize the execution time, we used a look-up table and that output stored into the robot RAM memory and becomes the current controller that drives the robot. This functionality is demonstrated on a mobile robot using a simple, 8 bit microcontroller with 512 bytes of RAM. The experiment results show that source code is efficient, works well, and the robot was able to successfully avoid obstacle in real time.",https://ieeexplore.ieee.org/document/4804536/,2009 International Conference on Computer and Automation Engineering,8-10 March 2009,ieeexplore
10.1109/ICRA40945.2020.9197510,Episodic Koopman Learning of Nonlinear Robot Dynamics with Application to Fast Multirotor Landing,IEEE,Conferences,"This paper presents a novel episodic method to learn a robot's nonlinear dynamics model and an increasingly optimal control sequence for a set of tasks. The method is based on the Koopman operator approach to nonlinear dynamical systems analysis, which models the flow of observables in a function space, rather than a flow in a state space. Practically, this method estimates a nonlinear diffeomorphism that lifts the dynamics to a higher dimensional space where they are linear. Efficient Model Predictive Control methods can then be applied to the lifted model. This approach allows for real time implementation in on-board hardware, with rigorous incorporation of both input and state constraints during learning. We demonstrate the method in a real-time implementation of fast multirotor landing, where the nonlinear ground effect is learned and used to improve landing speed and quality.",https://ieeexplore.ieee.org/document/9197510/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/WCICA.2000.863468,Estimated force emulation for space robot using neural networks,IEEE,Conferences,"This paper introduces the telerobotic system estimated force emulation using neural networks. A delay-compensating 3D stereo-graphic simulator is implemented in SGI ONYX/4 RE/sup 2/. The estimated force emulation can protect the real robot in time from being damaged in collision. The neural network is used to learn the mapping between the contact force error and the accommodated position command to the controller of the space robot. Finally, the controller can feel the emulated force with a two-hand 6-DOF master arm using the force feedback interface.",https://ieeexplore.ieee.org/document/863468/,Proceedings of the 3rd World Congress on Intelligent Control and Automation (Cat. No.00EX393),26 June-2 July 2000,ieeexplore
10.1109/INDIN.2017.8104924,Experiences in integrating Internet of Things and cloud services with the robot operating system,IEEE,Conferences,"New Internet of Things open source technologies, middlewares, and programming languages, make the quick integration of devices, systems and cloud services easier than never before. With their utilization, complex tasks such as object detection, tracking and tracing, can be easily realized, even by embedded devices in a fraction of time. The interplay of highly heterogeneous IoT devices and open source software, has been utilized in this work as a learning tool, in order to train developers and enhance their IoT skills. By designing, implementing, testing and deploying a rapid prototype, new knowledge is acquired, assessment of technologies and concepts is carried out, and the end-result, although developed in a constraint timeframe, is technologically promising, cost-effective and feature-rich. This work sheds some light on the prototype implemented and discusses the developer experiences and benefits of this IoT integration hands-on approach.",https://ieeexplore.ieee.org/document/8104924/,2017 IEEE 15th International Conference on Industrial Informatics (INDIN),24-26 July 2017,ieeexplore
10.1109/ICITA.2005.135,Experiences with simulated robot soccer as a teaching tool,IEEE,Conferences,"The development of assignments for undergraduate teaching typically requires a compromise between what is achievable by an average student and what engages the interest of a more advanced member of the class. Selecting a suitable compromise is particularly problematic for undergraduate artificial intelligence (AI) courses which typically attempt to cover a very broad range of topics, without delving too deeply into the details. Ideally, a single problem would be selected whose solution could be approached with more than one technique covered in the course, enabling students to carry out a comparative analysis of performance. Robot soccer simulation has provided an interesting platform for artificial intelligence research and is increasingly being used as a teaching apparatus. There are a number of limitations with existing simulation methodologies for this purpose. Current robot soccer simulators are aimed at research groups where accuracy is paramount and all facets of the real system must be emulated. However, many of the intricacies of a real robot soccer player are inappropriate for a teaching environment, as they detract from desired learning outcomes. Consequently, there is a need for a simulation that employs a simplified set of game rules and dynamics. This paper describes the design and implementation of such a framework and presents experiences gained from its use as a third year practical.",https://ieeexplore.ieee.org/document/1488833/,Third International Conference on Information Technology and Applications (ICITA'05),4-7 July 2005,ieeexplore
10.1109/Humanoids.2011.6100913,Exploiting previous experience to constrain robot sensorimotor learning,IEEE,Conferences,"A truly autonomous robot should be able to generalize known actions to new situations and to autonomously refine its knowledge base. In this paper we present a three stage approach to the problem of expanding and refining the database of sensorimotor knowledge. The first stage is based on the generalization of previously trained movements associated with a specific task, which results in a first approximation of a suitable control policy in a new situation. The second stage applies learning on the manifold defined by the previously acquired training data, which results in a learning problem of reduced dimensionality. The final tuning of the desired control policy is accomplished by learning in the full state space, where the dimensionality of the problem is much higher. The assumption is that the first two steps already provide a good initial estimate for the optimal control policy so that this final step only locally refines the parameters learned in the first two steps. This significantly reduces the number of test trials needed by standard reinforcement learning techniques. The proposed approach was evaluated in simulation as well as on the real robot in a ball throwing experiment.",https://ieeexplore.ieee.org/document/6100913/,2011 11th IEEE-RAS International Conference on Humanoid Robots,26-28 Oct. 2011,ieeexplore
10.1109/ICAIE50891.2020.00028,Exploration and Practice on Industrial Robot Experimental Teaching Based on Virtuality and Reality Combination,IEEE,Conferences,"In view of the common problems currently existing in the industrial robot experimental teaching in the higher vocational colleges, this paper, through deep integration of the traditional experimental teaching and the virtual simulation technology, proposes the industrial robot experimental teaching mode based on the combination of virtuality and reality. The teaching process is divided into three parts: pre-class, in-class and post-class, and the experimental teaching design is elaborated in details by taking the “material blocks handling experiment” as an example. Practices proved that the experimental teaching mode based on the virtuality and reality combination has improved the efficiency and quality of classroom teaching, enriched the after-school time of students and improved the depth and scope of learning, which played a positive role in promoting the specialty construction and talent cultivation, and could provide reference for the experimental teaching of related specialties in similar colleges and universities.",https://ieeexplore.ieee.org/document/9262587/,2020 International Conference on Artificial Intelligence and Education (ICAIE),26-28 June 2020,ieeexplore
10.1109/SIEDS49339.2020.9106581,"Explorer51 – Indoor Mapping, Discovery, and Navigation for an Autonomous Mobile Robot",IEEE,Conferences,"The nexus of robotics, autonomous systems, and artificial intelligence (AI) has the potential to change the nature of human guided exploration of indoor and outdoor spaces. Such autonomous mobile robots can be incorporated into a variety of applications, ranging from logistics and maintenance, to intelligence gathering, surveillance, and reconnaissance (ISR). One such example is that of a tele-operator using the robot to generate a map of the inside of a building while discovering and tagging the objects of interest. During this process, the tele-operator can also assign an area for the robot to navigate autonomously or return to a previously marked area/object of interest. Search and rescue and ISR abilities could be immensely improved with such capabilities. The goal of this research is to prototype and demonstrate the above autonomous capabilities in a mobile ground robot called Explorer51. Objectives include: (i) enabling an operator to drive the robot non-line of sight to explore a space by incorporating a first-person view (FPV) system to stream data from the robot to the base station; (ii) implementing automatic collision avoidance to prevent the operator from running the robot into obstacles; (iii) creating and saving 2D and 3D maps of the space in real time by using a 2D laser scanner, tracking, and depth/RGB cameras; (iv) locating and tagging objects of interest as waypoints within the map; (v) autonomously navigate within the map to reach a chosen waypoint. To accomplish these goals, we are using the AION Robotics R1 Unmanned Ground Vehicle (UGV) rover as the platform for Explorer51 to demonstrate the autonomous features. The rover runs the Robot Operating System (ROS) onboard an NVIDIA Jetson TX2 board, connected to a Pixhawk controller. Sensors include a 2D scanning LiDAR, depth camera, tracking camera, and an IMU. Using existing ROS packages such as Cartographer and TEB planner, we plan to implement ROS nodes for accomplishing these tasks. We plan to extend the mapping ability of the rover using Visual Inertial Odometry (VIO) using the cameras. In addition, we will explore the implementation of additional features such as autonomous target identification, waypoint marking, collision avoidance, and iterative trajectory optimization. The project will culminate in a series of demonstrations to showcase the autonomous navigation, and tele-operation abilities of the robot. Success will be evaluated based on ease of use by the tele-operator, collision avoidance ability, autonomous waypoint navigation accuracy, and robust map creation at high driving speeds.",https://ieeexplore.ieee.org/document/9106581/,2020 Systems and Information Engineering Design Symposium (SIEDS),24-24 April 2020,ieeexplore
10.1109/ROMAN.2017.8172449,Exploring data augmentation methods in reverberant human-robot voice communication,IEEE,Conferences,"Collecting training data is not an easy task especially in situation involving robots that require tremendous physical effort. The ability to augment data through synthetic means is a convenient tool to solve this problem. Therefore it is important to evaluate the extent of the usefulness of augmented data. In this paper, we will explore data augmentation schemes in reverberant environment and investigate a method to effectively select data. We experiment in a real reverberant environment condition and investigate both the traditional automatic speech recognition (ASR) system based on gaussian mixture model-hidden markov model (GMM-HMM) and the most current system based on Deep Neural Networks (i.e, HMM-DNN). Our results show that the combination of data augmentation and data selection, further improves system performance. In our experiments, we used real test data in a reverberant hands-free human-robot communication scenario.",https://ieeexplore.ieee.org/document/8172449/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/ICRA48506.2021.9561040,Extendable Navigation Network based Reinforcement Learning for Indoor Robot Exploration,IEEE,Conferences,This paper presents a navigation network based deep reinforcement learning framework for autonomous indoor robot exploration. The presented method features a pattern cognitive non-myopic exploration strategy that can better reflect universal preferences for structure. We propose the Extendable Navigation Network (ENN) to encode the partially observed high-dimensional indoor Euclidean space to a sparse graph representation. The robot’s motion is generated by a learned Q-network whose input is the ENN. The proposed framework is applied to a robot equipped with a 2D LIDAR sensor in the GAZEBO simulation where floor plans of real buildings are implemented. The experiments demonstrate the efficiency of the framework in terms of exploration time.,https://ieeexplore.ieee.org/document/9561040/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ROBOT.2003.1241690,Extended QDSEGA for controlling real robots - acquisition of locomotion patterns for snake-like robot,IEEE,Conferences,"Reinforcement learning is very effective for robot learning. It is because it does not need prior knowledge and has higher capability of reactive and adaptive behaviors. In our previous works, we proposed new reinforce learning algorithm: ""Q-learning with dynamic structuring of exploration space based on genetic algorithm (QDSEGA)"". It is designed for complicated systems with large action-state space like a robot with many redundant degrees of freedom. However the application of QDSEGA is restricted to static systems. A snake-like robot has many redundant degrees of freedom and the dynamics of the system are very important to complete the locomotion task. So application of usual reinforcement learning is very difficult. In this paper, we extend layered structure of QDSEGA so that it becomes possible to apply it to real robots that have complexities and dynamics. We apply it to acquisition of locomotion pattern of the snake-like robot and demonstrate the effectiveness and the validity of QDSEGA with the extended layered structure by simulation and experiment.",https://ieeexplore.ieee.org/document/1241690/,2003 IEEE International Conference on Robotics and Automation (Cat. No.03CH37422),14-19 Sept. 2003,ieeexplore
10.1109/FPT.2009.5377635,FPGA implementation of mixed integer quadratic programming solver for mobile robot control,IEEE,Conferences,"We propose a high-speed mixed integer quadratic programming (MIQP) solver on an FPGA. The MIQP solver can be applied to various optimizing applications including real-time robot control. In order to rapidly solve the MIQP problem, we implement reusing a first solution (first point), pipeline architecture, and multi-core architecture on the single FPGA. By making use of them, we confirmed that 79.5% of the cycle times are reduced, compared with straightforward sequential processing. The operating frequency is 67 MHz, although a core 2 duo PC requires 3.16 GHz in processing the same size problem. The power consumption of the MIQP solver is 4.2 W.",https://ieeexplore.ieee.org/document/5377635/,2009 International Conference on Field-Programmable Technology,9-11 Dec. 2009,ieeexplore
10.1109/ICSMC.1997.633250,Facial interaction between animated 3D face robot and human beings,IEEE,Conferences,"We study the realization of a realistic human-like response of an animated 3D face robot in communicative interaction with human beings. The face robot can produce human-like facial expressions and recognize human facial expressions using facial image data obtained by a CCD camera mounted inside the left eyeball. We developed the real time machine recognition of facial expressions by using a layered neural network and achieved a high correct recognition ratio of 85% with respect to 6 typical facial expressions of 15 subjects in 55 ms. We also developed a new small-size actuator for display of facial expressions on the face robot, giving the same speed in dynamic facial expressions as in human even in the case of a high-speed expression of ""surprise"". For facial interactive communication between the face robot and human beings, we integrated these two technologies to produce the facial expression in respond to the recognition result of the human facial expression in real time. This implies a high technological potential for the animated face robot to undertake interactive communication with human when an artificial emotion being implemented.",https://ieeexplore.ieee.org/document/633250/,"1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation",12-15 Oct. 1997,ieeexplore
10.1109/UR49135.2020.9144836,Fall detection based on CNN models implemented on a mobile robot,IEEE,Conferences,"Fall accidents are serious events that need to be addressed. Generally, elderly people could suffer these accidents that may lead injures or even death. The use of Convolutional Neural Networks (CNN) has achieved the state of the art for fall detection, but it requires a high computational cost. In this work, we propose an efficient CNN architecture with a reduced number of parameters, which is applied to fall detection in a service with a mobile robot, equipped with a resource-constrained hardware (Nvidia Jetson TX2 platform). Also, different pre-trained CNN models are compared to measure their performances in real scenarios, in addition with other functions like following people and navigation. Furthermore, fall detection is carried out by extraction of temporal features obtained with an Optical Flow extraction from two consecutive RGB images. The proposed network is confirmed by our results to be faster and more suitable for running on resource-constrained Hardware. Our model achieves 88.55% of accuracy using the proposed architecture and it works at 23.16 FPS on GPU and 10.23 FPS on CPU.",https://ieeexplore.ieee.org/document/9144836/,2020 17th International Conference on Ubiquitous Robots (UR),22-26 June 2020,ieeexplore
10.1109/ISPACS.2018.8923369,Fast Recognition and Control of Walking Mode for Humanoid Robot Based on Pressure Sensors and Nearest Neighbor Search,IEEE,Conferences,"In this paper, we propose a nearest-neighbor multi-reference learning system for control of humanoid-robot movements, using real-time data from pressure sensors embedded in the robot feet, which is processed with parallelized pipeline architecture for high-speed recognition of actual surface conditions. A first nearest-neighbor (1-NN) classifier is used to recognize the most similar reference pattern in terms of the smallest Euclidean distance. Our proposed architecture achieves a classification time of about 2.4μ s with a total power consumption of 8.53mW at 100 MHz operating frequency when implemented on a low-cost FPGA (Cyclone-V GX-Series). The analysis results are further useful for a next-generation-ASIC-based AI-chip design for a robust real-time robot-learning system.",https://ieeexplore.ieee.org/document/8923369/,2018 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS),27-30 Nov. 2018,ieeexplore
10.1109/RCAR.2018.8621723,Fault-Tolerant and Self-Adaptive Market-Based Coordination Using Hoplites Framework for Multi-Robot Patrolling Tasks,IEEE,Conferences,"An autonomous robot team can be employed for continuous coverage of a dynamic environment. In this paper, we propose a novel approach for creating multi-robot patrolling policies, which is fault-tolerant and self-adaptive. A dynamic priority queue and time-out replanning mechanism are maintained by each robot to schedule the tasks fault-tolerantly in the context of the market-based method. Hoplites framework is adapted by introducing a self-adaptive threshold adjustment and sharing mechanism to provide a high-level coordination. This work is demonstrated by a multi-robot patrolling task implemented on Robot Operating System (ROS). A flexible tool, Stage, is leveraged to provide the simulated environment. The experimental results validate the effectiveness and availability.",https://ieeexplore.ieee.org/document/8621723/,2018 IEEE International Conference on Real-time Computing and Robotics (RCAR),1-5 Aug. 2018,ieeexplore
10.1109/RIOS.2013.6595317,Flexible snake robot: Design and implementation,IEEE,Conferences,"This paper presents a snake robot able to pass different and difficult paths because of special physical form and movement joints mechanism. These snake robots have no passive wheels. The robot moves by friction between the robot body and the surface on which it is. The joints have been designed and fabricated in a way that each joint has two freedom grades and it may move 228 degrees in every direction. Each joint has two DC servo motors and the power is transferred from the motors output to the joint shaft through bevel gear. The flexibility of the robot makes possible to move forward, back and laterally by imitating real snake's moves. In this paper different measures have been presented in order to design and assemble the joints, motors driver, different ways to guide the robot and its vision.",https://ieeexplore.ieee.org/document/6595317/,2013 3rd Joint Conference of AI & Robotics and 5th RoboCup Iran Open International Symposium,8-8 April 2013,ieeexplore
10.1109/VR.2015.7223421,Flying robot manipulation system using a virtual plane,IEEE,Conferences,"The flexible movements of flying robots make it difficult for novices to manipulate them precisely with controllers such as a joystick and a proportional radio system. Moreover, the mapping of instructions between a robot and its reactions is not necessarily intuitive for users. We propose manipulation methods for flying robots using augmented reality technologies. In the proposed system, a virtual plane is superimposed on a flying robot and users control the robot by manipulating the virtual plane and drawing a moving path on it. We present the design and implementation of our system and describe experiments conducted to evaluate our methods.",https://ieeexplore.ieee.org/document/7223421/,2015 IEEE Virtual Reality (VR),23-27 March 2015,ieeexplore
10.1109/SII.2011.6147520,Forming an artificial pheromone potential field using mobile robot and RFID tags,IEEE,Conferences,"In the biological world, social insects such as ants and bees use a volatile substance called pheromone for their foraging or homing tasks. This study deals with how to utilize the concept of the chemical pheromone as an artificial potential field for robotic purposes. This paper first models a pheromone-based potential field, which is constructed through the interaction between mobile robot and RFID tags. The emphasis in the modeling of the system is on the possibility of the practical implementable ideas. The stability analysis of the pheromone potential field is carried out with the aim of implementing the model on a real robotic system. The comprehensive analysis on stability provides the criteria for how the parameters are to be set for the proper potential field, and has also led to a new filter design scheme called pheromone filter. The designed filter satisfies both the stability and accuracy of the field, and facilitates a more straightforward and practical implementation for building and shaping the potential field. The effectiveness of the proposed algorithm is validated through both computer simulation and real experiment.",https://ieeexplore.ieee.org/document/6147520/,2011 IEEE/SICE International Symposium on System Integration (SII),20-22 Dec. 2011,ieeexplore
10.1109/ROMAN.2017.8172498,Functional imitation task in the context of robot-assisted Autism Spectrum Disorder diagnostics: Preliminary investigations,IEEE,Conferences,"This paper presents a functional imitation task aimed at facilitating Autism Spectrum Disorder (ASD) diagnostics in children. Imitation plays a key role in the development of social skills at a young age, and studies have shown that the ability to imitate is impaired in children with ASD. Therefore, we expect imitation-based tasks to have diagnostic value. In this paper, we introduce two novel elements of human-robot interaction in the context of autism diagnostics. Instead of pure motoric imitation, we propose imitation tasks involving real objects in the environment. The introduction of physical objects strongly emphasizes joint attention skills, another area that is typically impaired in children with ASD. Furthermore, we present simple object detection, manipulation, tracking and gesture recognition algorithms, suitable for real-time, onboard execution on the small-scale humanoid robot NAO. The proposed system paves the way for fully autonomous execution of diagnostic tasks, which would simplify the deployment of robotic assistants in clinical settings. The source code for all described functionalities has been made publicly available as open-source software. We present a preliminary evaluation of the proposed system with a control group of typically developing preschool children and a group of seven children diagnosed with ASD.",https://ieeexplore.ieee.org/document/8172498/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/MMAR.2019.8864671,Fusion of Gesture and Speech for Increased Accuracy in Human Robot Interaction,IEEE,Conferences,"An approach for decision-level fusion for gesture and speech based human-robot interaction (HRI) is proposed. A rule-based method is compared with several machine learning approaches. Gestures and speech signals are initially classified using hidden Markov models, reaching accuracies of 89.6% and 84% respectively. The rule-based approach reached 91.6% while SVM, which was the best of all evaluated machine learning algorithms, reached an accuracy of 98.2% on the test data. A complete framework is deployed in real time humanoid robot (NAO) which proves the efficacy of the system.",https://ieeexplore.ieee.org/document/8864671/,2019 24th International Conference on Methods and Models in Automation and Robotics (MMAR),26-29 Aug. 2019,ieeexplore
10.1109/HRI.2010.5453172,FusionBot: A barista robot: Fusionbot serving coffees to visitors during technology exhibition event,IEEE,Conferences,"Summary form of only given: This video shows a service robot named FusionBot autonomously serving coffees to visitors on their request, which occurred during two days-long experiment in TechFest 2008 event. The coffee serving task involves taking coffee order from a visitor, identifying a cup and smart coffee machine, moving towards the coffee machine, communicating with the coffee machine and fetching the coffee cup to the visitor. The main purpose of this experiment is to explore and demonstrate the utility of an interactive service robot in smart home environment, thereby improving the quality of human life. Before conducting the experiments, visitors were given general procedural instructions and simple introduction on how the FusionBot works. Visitors then performed experiment tasks, i.e., ordering a cup of coffee. Thereafter, the visitors were asked to fill out the satisfaction questionnaires to find out their reaction and perception on the FusionBot. Of just over 100 survey questionnaires handed out, sixty eight (68) valid responses (i.e. 68%) were received. Over all, with regards to the FusionBot task satisfaction, more than half of respondents were satisfied with what the FusionBot can do. Nearly one quarter of the respondents indicated that it was not easy to communicate with the FusionBot. This could be due to occurrence of various background noises, which were falsely picked up by the FusionBot as speech input from the visitor. Similarly, less than one quarter indicated that it was not easy to learn how to use the FusionBot. This could be due to the not knowing what to do with the FusionBot and not knowing what the FusionBot does. The experiment was successful in two main dimensions; (1) the robot demonstrated the ability to interact with visitors and perform challenging real-world task autonomously, and (2) It provided some evidence towards the feasibility of using autonomous service robot and smart coffee machine to serve drink in a reception/home or acting as a host in an organization. While preliminary, the experiment also suggests that while developing a service robot; (1) static appearance is very important, (2) requires robust speech recognition and vision understanding, and finally (3) requires comprehensive training on speech and vision with respective data.",https://ieeexplore.ieee.org/document/5453172/,2010 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI),2-5 March 2010,ieeexplore
10.1109/FUZZY.2006.1681996,Fuzzy Logic based Active Map Learning for Autonomous Robot,IEEE,Conferences,"The paper proposes a fast map learning approach for real-time map building and active exploration in unknown indoor environments. This approach includes a map model, a map update method, an exploration method, and a map postprocessing method. The map adopts a grid-based representation and uses frequency value to measure the confidence that a cell is occupied by an obstacle. The exploration method is implemented by coordinating two novel behaviors: path-exploring behavior and environment-detection behavior. Fuzzy logic is used to implement the behavior design and coordination. The fast map update and path planning (i.e. the exploration method) make our approach a candidate for real-time implementation on mobile robots. The results are demonstrated by simulated experiments based on a Pioneer robot with eight forward sonar sensors.",https://ieeexplore.ieee.org/document/1681996/,2006 IEEE International Conference on Fuzzy Systems,16-21 July 2006,ieeexplore
10.1109/AIM.2009.5229761,Fuzzy and Neural controllers for acute obstacle avoidance in mobile robot navigation,IEEE,Conferences,"Robot navigation is the technique to guide the mobile robot move towards the desired goal where dynamic and unknown environment is involved. The environment is distinguished by variable terrain and also certain objects which are known as obstacles that may block the movement of the robot in reaching the desired destination. Fuzzy Logic (FL) and Artificial Neural Network (ANN) are used to assist autonomous mobile robot move, learn the environment and reach the desired goal. This research study is focused on exploring the four combinations of training algorithms composed of FL and ANN that avoid acute obstacles in the environment. Path Remembering algorithm proposed in this paper will assist the mobile robot to come out from acute obstacles. Virtual wall building method also is proposed in order to prevent the mobile robot reentering the same acute obstacle once it has been turned away from the wall. MATLAB simulation is developed to verify and validate the algorithms before they are implemented in real time on Team AmigoBottrade robot. The results obtained from both simulation and actual application confirmed the flexibility and robustness of the controllers designed in avoiding acute obstacles and a comparison of all the four combinations of algorithms is done to find the best combination of algorithms to perform the required navigation to avoid acute obstacles.",https://ieeexplore.ieee.org/document/5229761/,2009 IEEE/ASME International Conference on Advanced Intelligent Mechatronics,14-17 July 2009,ieeexplore
10.1109/FUZZY.1997.619465,Fuzzy behaviors combination to control a nonholonomic mobile robot using virtual perception memory,IEEE,Conferences,This paper presents the implementation of the combination of fuzzy reactive navigation behaviors using virtual perception memory. Robot control actions are generated by different fuzzy behavior components which cooperate to determine the motion of the vehicle. This approach differs from other methods in the use of a virtual perception memory to make a robot controller more robust with respect to temporary loss of sensorial information. Experimental results of an application to a real robot demonstrate the robustness of the proposed method.,https://ieeexplore.ieee.org/document/619465/,Proceedings of 6th International Fuzzy Systems Conference,5-5 July 1997,ieeexplore
10.1109/FUZZY.1996.551714,Fuzzy logic control of an obstacle avoidance robot,IEEE,Conferences,"A fuzzy controller is used to control an obstacle avoidance mobile robot. In this classical problem, the aim is to guide a mobile robot along its path to avoid any static obstacles in front of it. Obstacle avoidance in real-time is a mandatory feature for mobile robots in a dynamically unknown environment. The controller presented here uses three sub-controllers. The outputs are summed to produce a concerted effort to control the motors steering the robot away from obstacles. This fuzzy controller was implemented on a miniature robot. This robot is able to overcome its limitation on range accuracy to follow a left wall, maintaining a short distance from it, to avoid obstacles in front of it, and to decide whether a gap is wide enough for a ""side-step"" manoeuvre.",https://ieeexplore.ieee.org/document/551714/,Proceedings of IEEE 5th International Fuzzy Systems,11-11 Sept. 1996,ieeexplore
10.1109/ISMA.2009.5164850,Fuzzy motion-based control for a bi-steerable mobile robot navigation,IEEE,Conferences,"This paper presents an implementation of a Fuzzy Motion Controller (FMC) to endow the mobile robot Robucar with capability to achieve the action behavior allowing smooth motion generation with intelligence in real-time. The robot state space (velocity and distances) is modeled in discrete intervals leading to linguistic variables. The fuzzy motion control rules are derived and used in a fuzzy inference mechanism to give the final control command to the robot actuators. Simulation and experimental results show FMC capabilities in generating smooth motions, illustrating then its adaptivity and intelligence.",https://ieeexplore.ieee.org/document/5164850/,2009 6th International Symposium on Mechatronics and its Applications,23-26 March 2009,ieeexplore
10.1109/ICMLC.2004.1380726,Fuzzy predictive control of wheeled mobile robot based on multi-sensors,IEEE,Conferences,"During the wheeled mobile robot (WMR) navigation, the position estimation obtained by one sensor is unrealistic and useless. The composite navigation method based on multi-sensor is proposed, which provides redundancy and assures reliability and precision of the observed features. Considering the non-holonomic constraint between the ground and WMR, a fuzzy predictive control is presented where the weight matrix of the pose error is chosen by the real-time fuzzy algorithm. Here, the fuzzy predictive controller based on composite navigation is used on XUAT.AGV, which is a kind of WMR. It has been proved that the controller can improve the control reliability and precision of WMR through theory analysis and experiment.",https://ieeexplore.ieee.org/document/1380726/,Proceedings of 2004 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.04EX826),26-29 Aug. 2004,ieeexplore
10.1109/ROMAN.2004.1374845,Fuzzy reinforcement learning for an evolving virtual servant robot,IEEE,Conferences,"This work presents our research in the application of reinforcement learning algorithms for the generation of autonomous intelligent virtual robots, that can learn and enhance their task performance in assisting humans in housekeeping. For the control system architecture of the virtual agents, two algorithms, based on Watkins' Q(/spl lambda/) learning and the zeroth-level classifier system (ZLCS), are incorporated with fuzzy inference systems(FlS). Performance of these algorithms is evaluated and compared. A 3D application of a virtual robot whose task is to interact with virtual humans and offer optimal services on everyday in-house needs is designed and implemented. The learning systems are incorporated in the decision-making process of the virtual robot servant to allow itself to understand and evaluate the fuzzy value requirements and enhance its performance.",https://ieeexplore.ieee.org/document/1374845/,RO-MAN 2004. 13th IEEE International Workshop on Robot and Human Interactive Communication (IEEE Catalog No.04TH8759),22-22 Sept. 2004,ieeexplore
10.1109/ISKE47853.2019.9170343,Genetic Algorithm Integrated with Neural-Network for Tolman Mouse Robot Navigation,IEEE,Conferences,"Mapping building plays an important role in robot navigation, in order to facility agent with high level intelligence and mimic the major function of rat's space cell, a new mechanism of Genetic Algorithm Integrated with Neuralnetwork(GAIN) was proposed in this paper. Considering the scenario of unknown environment when agent explores the map, weights in neural network remain the same during agent's lifecycle and will be optimized by genetic algorithm. Several simulation was performed on Unity platform, especial the Tolman mouse maze experiment, including cross position learning experiment, spatial orientation experiment and roundabout experiment, had been reproduced by agent other than real rat. Furthermore, some extension of experiment has also done to further prove the feasibility of the algorithm. Simulation results verified the proposed GAIN algorithm can endow agent with cognitive map function.",https://ieeexplore.ieee.org/document/9170343/,2019 IEEE 14th International Conference on Intelligent Systems and Knowledge Engineering (ISKE),14-16 Nov. 2019,ieeexplore
10.1109/ROMAN.2009.5326235,Gestural teleoperation of a mobile robot based on visual recognition of sign language static handshapes,IEEE,Conferences,"This paper presents results achieved in the frames of a national research project (titled ldquoDIANOEMArdquo), where visual analysis and sign recognition techniques have been explored on Greek Sign Language (GSL) data. Besides GSL modelling, the aim was to develop a pilot application for teleoperating a mobile robot using natural hand signs. A small vocabulary of hand signs has been designed to enable desktopbased teleoperation at a high-level of supervisory telerobotic control. Real-time visual recognition of the hand images is performed by training a multi-layer perceptron (MLP) neural network. Various shape descriptors of the segmented hand posture images have been explored as inputs to the MLP network. These include Fourier shape descriptors on the contour of the segmented hand sign images, moments, compactness, eccentricity, and histogram of the curvature. We have examined which of these shape descriptors are best suited for real-time recognition of hand signs, in relation to the number and choice of hand postures, in order to achieve maximum recognition performance. The hand-sign recognizer has been integrated in a graphical user interface, and has been implemented with success on a pilot application for real-time desktop-based gestural teleoperation of a mobile robot vehicle.",https://ieeexplore.ieee.org/document/5326235/,RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication,27 Sept.-2 Oct. 2009,ieeexplore
10.1109/IJCNN.2015.7280540,Gesture based human multi-robot interaction,IEEE,Conferences,"The emergence of robot applications for non-technical users implies designing new ways of interaction between robotic platforms and users. The main goal of this work is the development of a gestural interface to interact with robots in a similar way as humans do, allowing the user to provide information of the task with non-verbal communication. The gesture recognition application has been implemented using the Microsoft's Kinect<sup>™</sup> v2 sensor. Hence, a real-time algorithm based on skeletal features is described to deal with both, static gestures and dynamic ones, being the latter recognized using a weighted Dynamic Time Warping method. The gesture recognition application has been implemented in a multi-robot case. A NAO humanoid robot is in charge of interacting with the users and respond to the visual signals they produce. Moreover, a wheeled Wifibot robot carries both the sensor and the NAO robot, easing navigation when necessary. A broad set of user tests have been carried out demonstrating that the system is, indeed, a natural approach to human robot interaction, with a fast response and easy to use, showing high gesture recognition rates.",https://ieeexplore.ieee.org/document/7280540/,2015 International Joint Conference on Neural Networks (IJCNN),12-17 July 2015,ieeexplore
10.1109/CACRE52464.2021.9501291,Give Me a Wrench!: Finding Tools for Human Partners in Human-Robot Collaborative Manufacturing Contexts,IEEE,Conferences,"Manufacturing processes can be optimized by enabling human-robot collaboration. A relevant goal in this area is to create a collaborative solution in which robots can provide assisting actions to humans, thereby, reducing menial labor as well as increasing productivity. The solution is based on implementing efficient hand-over of mechanical tools from robots to humans. Hand-over tasks are inevitable in human-robot collaborative manufacturing contexts. These tasks need three-step mechanism: object identification, object grasping, and the actual hand-over. This paper presents an approach for robots to find tools for human partners in human-robot collaboration via deep learning. This is achieved using the object detection system YOLOv3 for identification of commonly used mechanical tools. By training on a custom dataset of 800 images of mechanical tools created for the study, the tool recognition is implemented in realworld human-robot hand-over tasks. Experimental results show that the proposed approach achieves a high accuracy for identification of tools in real-world human-robot collaboration. Future work of this study is also discussed.",https://ieeexplore.ieee.org/document/9501291/,"2021 6th International Conference on Automation, Control and Robotics Engineering (CACRE)",15-17 July 2021,ieeexplore
10.1109/ICRA.2019.8793810,Goal-Driven Navigation for Non-holonomic Multi-Robot System by Learning Collision,IEEE,Conferences,"In this paper, we propose the reinforcement learning based multi-robot collision avoidance approach by learning collision. Dynamical path re-planning, which is massively used in classical collision avoidance methods, needs overall information of the environment. Also, training agent robots to avoid the collision and pursue a goal point simultaneously is inefficient since the agent should learn two tasks. As the number of tasks that the agent should learn increases, it is difficult to make the performance of an algorithm consistent, which is known as reproducibility issue. To overcome these limitations, Collision Avoidance by Learning Collision (CALC), which learns collision instead of avoiding an obstacle robot is suggested. To solve the collision avoidance problem efficiently, the proposed method divides the problem into training and planning. In the training algorithm, an agent robot learns how to collide with a single obstacle robot and then generates a trained policy. With the trained policy, the agent can pursue a goal point since the policy leads the agent to `collide' with the goal. Furthermore, by taking action in a reverse way from the trained policy, the agent can avoid multiple obstacle robots in the planning algorithm at once. The proposed method is validated both in the robot simulation and real robot experiment, and compared with the existing collision avoidance method.",https://ieeexplore.ieee.org/document/8793810/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/RO-MAN47096.2020.9223558,HATSUKI : An anime character like robot figure platform with anime-style expressions and imitation learning based action generation,IEEE,Conferences,"Japanese character figurines are popular and have a pivot position in Otaku culture. Although numerous robots have been developed, few have focused on otaku-culture or on embodying anime character figurines. Therefore, we take the first steps to bridge this gap by developing Hatsuki, which is a humanoid robot platform with anime based design. Hatsuki's novelty lies in its aesthetic design, 2D facial expressions, and anime-style behaviors that allows Hatsuki to deliver rich interaction experiences resembling anime-characters. We explain our design implementation process of Hatsuki, followed by our evaluations. In order to explore user impressions and opinions towards Hatsuki, we conducted a questionnaire in the world's largest anime-figurine event. The results indicate that participants were generally very satisfied with Hatsuki's design, and proposed various use case scenarios and deployment contexts for Hatsuki. The second evaluation focused on imitation learning, as such a method can provide better interaction ability in the real world and generate rich, context-adaptive behaviors in different situations. We made Hatsuki learn 11 actions, combining voice, facial expressions and motions, through the neural network based policy model with our proposed interface. Results show our approach was successfully able to generate the actions through self-organized contexts, which shows the potential for generalizing our approach in further actions under different contexts. Lastly, we present our future research direction for Hatsuki and provide our conclusion.",https://ieeexplore.ieee.org/document/9223558/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore
10.1109/ICIEA.2006.257252,Hand Posture Recognition in Gesture-Based Human-Robot Interaction,IEEE,Conferences,"Natural and friendly interface is critical for the development of service robots. Gesture-based interface offers a way to enable untrained users to interact with robots more easily and efficiently. In this paper, we present a posture recognition system implemented on a real humanoid service robot. The system applies the RCE neural network based color segmentation algorithm to separate hand images from complex backgrounds. The topological features of the hand are then extracted from the silhouette of the segmented hand region. Based on the analysis of these simple but distinctive features, hand postures are identified accurately. Experimental results on gesture-based robot programming demonstrated the effectiveness and robustness of the system",https://ieeexplore.ieee.org/document/4025853/,2006 1ST IEEE Conference on Industrial Electronics and Applications,24-26 May 2006,ieeexplore
10.1109/ICSMC.1996.565422,High speed neural control for robot navigation,IEEE,Conferences,"This paper addresses the real time control of the Khepera mobile robot navigation in a maze with reflector walls. Boolean neural networks such as RAM and GSN models are applied to drive the vehicle, following a light source, while avoiding obstacles. Both neural networks are implemented with simple logic and arithmetic functions (NOT, AND, OR, Addition, and Comparison), aiming to improve the system speed. The results obtained are compared with two other control strategies: multilayer perceptron and fuzzy logic.",https://ieeexplore.ieee.org/document/565422/,"1996 IEEE International Conference on Systems, Man and Cybernetics. Information Intelligence and Systems (Cat. No.96CH35929)",14-17 Oct. 1996,ieeexplore
10.1109/ICRA48506.2021.9561034,High-Speed Robot Navigation using Predicted Occupancy Maps,IEEE,Conferences,"Safe and high-speed navigation is a key enabling capability for real world deployment of robotic systems. A significant limitation of existing approaches is the computational bottleneck associated with explicit mapping and the limited field of view (FOV) of existing sensor technologies. In this paper, we study algorithmic approaches that allow the robot to predict spaces extending beyond the sensor horizon for robust planning at high speeds. We accomplish this using a generative neural network trained from real-world data without requiring human annotated labels. Further, we extend our existing control algorithms to support leveraging the predicted spaces to improve collision-free planning and navigation at high speeds. Our experiments are conducted on a physical robot based on the MIT race car using an RGBD sensor where were able to demonstrate improved performance at 4 m/s compared to a controller not operating on predicted regions of the map.",https://ieeexplore.ieee.org/document/9561034/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ACSOS49614.2020.00036,How far should I watch? Quantifying the effect of various observational capabilities on long-range situational awareness in multi-robot teams,IEEE,Conferences,"In our previous work, we showed that individual robots within a multi-robot team can gain long-distance situational awareness from passive observations of a single nearby neighbor without any explicit robot-to-robot communication. However, that prior work was developed only in simulation, and performance was not measured for real robot teams in physical space with realistic hardware limitations. Toward this end, we studied the performance of these methods in real robot scenarios with methods using more sophisticated techniques in machine learning to mitigate practical implementation problems. In this study, we further extend that work by characterizing the effects of changing history length and sensor range. Rather than finding that increasing history length and sensor range always yield better estimation performance, we find that the optimal history length and sensor range varies depending on the distance between the estimating robot and the robot being estimated. For estimation problems where the estimation target is nearby, longer histories actually degrade performance, and so sensor ranges could be increased instead. Conversely, for farther targets, history length is as valuable or more valuable than sensor range. Thus, just as optimal shutter speed varies with light availability and speed of the subject, passive situational awareness in multi-robot teams is best achieved with different strategies depending on proximity to locations of interest. All studies use the teams of Thymio II physical, two-wheeled robots in laboratory environments <sup>1</sup>.<sup>1</sup>Data and models used are available at https://github.com/PavlicLab/ACSOS2020_ReTLo_Extension.git.",https://ieeexplore.ieee.org/document/9196255/,2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS),17-21 Aug. 2020,ieeexplore
10.1109/CRV.2010.55,Human Upper Body Pose Recognition Using Adaboost Template for Natural Human Robot Interaction,IEEE,Conferences,"In this paper, we propose a novel Adaboost template to recognize human upper body poses from disparity images for natural human robot interaction (HRI). First, the upper body poses of standing persons are classified into seven categories of views. For each category, a mean template, variance template, and percentage template are generated. Then, the template region is divided into positive and negative regions, corresponding to the region of bodies and surrounding open space. A weak classifier is designed for each pixel in the template. A new EM-like Adaboost learning algorithm is designed to learn the Adaboost template. Different from existing Adaboost classifiers, we show that the Adaboost template can be used not only for recognition but also for adaptive top-down segmentation. By using Adaboost template, only a few positive samples for each category are required for learning. Comparison with conventional template matching techniques has been made. Experimental results show that significant improvements can be achieved in both cases. The method has been deployed in a social robot to estimate human attentions to the robot in real-time human robot interaction.",https://ieeexplore.ieee.org/document/5479162/,2010 Canadian Conference on Computer and Robot Vision,31 May-2 June 2010,ieeexplore
10.1109/SCISISIS50064.2020.9322719,Human-Robot Interaction Based on Facial Expression Recognition Using Deep Learning,IEEE,Conferences,"In recent years, many robots for the purpose of communicating with people have been developed. Such a robot is required to have human interaction and communication ability. In order to perform the interaction naturally, the nonverbal communication such as human facial expression and body movement is important. In this research, we propose a method to classify emotions from human face images by deep learning and generate a robot emotional reaction by Markovian emotional model. Here, we perform to learn human facial images with various emotions using CNN (Convolutional Neural Network) which is a kind of deep learning, and recognize human emotions from facial images in the human interaction. Based on the human emotion obtained by deep learning, the robot returns its emotional behavior to the human. In this research, we executed the interaction experiment using an real communication robot and this result is also reported in this paper.",https://ieeexplore.ieee.org/document/9322719/,2020 Joint 11th International Conference on Soft Computing and Intelligent Systems and 21st International Symposium on Advanced Intelligent Systems (SCIS-ISIS),5-8 Dec. 2020,ieeexplore
10.1109/YAC53711.2021.9486647,Human-Robot Interaction System Design for Manipulator Control Using Reinforcement Learning,IEEE,Conferences,"In this article, a novel human-robot interaction (HRI) system is presented and applied in the robotic arm coordinated operation control task. The presented HRI system includes two parts, the impedance model controller and the robotic arm controller, which allows the operator to manipulate the robotic arm to accomplish the given task with minimal human effort. First, the model-based reinforcement learning (RL) method is applied in the impedance model for operator adaptation. The impedance model controller can transform human input into the specific signal for the manipulator. Second, a novel adaptive manipulator controller is designed. In contrast to existing controllers, a velocity-free filter is implemented in our controller, which is developed to replace the manipulator actuator's speed signal. The effectiveness of the presented HRI system is verified by the simulation based on real manipulator parameters.",https://ieeexplore.ieee.org/document/9486647/,2021 36th Youth Academic Annual Conference of Chinese Association of Automation (YAC),28-30 May 2021,ieeexplore
10.1109/ICRA.2013.6630610,Human-friendly robot navigation in dynamic environments,IEEE,Conferences,"The vision-based mechanisms that pedestrians in social groups use to navigate in dynamic environments, avoiding obstacles and each others, have been subject to a large amount of research in social anthropology and biological sciences. We build on recent results in these fields to develop a novel fully-distributed algorithm for robot local navigation, which implements the same heuristics for mutual avoidance adopted by humans. The resulting trajectories are human-friendly, because they can intuitively be predicted and interpreted by humans, making the algorithm suitable for the use on robots sharing navigation spaces with humans. The algorithm is computationally light and simple to implement. We study its efficiency and safety in presence of sensing uncertainty, and demonstrate its implementation on real robots. Through extensive quantitative simulations we explore various parameters of the system and demonstrate its good properties in scenarios of different complexity. When the algorithm is implemented on robot swarms, we could observe emergent collective behaviors similar to those observed in human crowds.",https://ieeexplore.ieee.org/document/6630610/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/HUMANOIDS.2017.8246941,Human-robot interaction assessment using dynamic engagement profiles,IEEE,Conferences,"This paper addresses the use of convolutional neural networks for image analysis resulting in an engagement metric that can be used to assess the quality of human robot interactions. We propose a method based on a pretrained convolutional network able to map emotions onto a continuous [0-1] interval, where 0 represents disengaged and 1 fully engaged. The network shows a good accuracy at recognizing the engagement state of humans given positive emotions. A time based analysis of interaction experiments between small humanoid robots and humans provides time series of engagement estimates, which are further used to understand the nature of the interaction as well as the overall mood and interest of the participant during the experiment. The method allows a real-time implementation and supports a quantitative and qualitative assessment of a human robot interaction with respect to a positive engagement and is applicable to humanoid robotics as well as other related contexts.",https://ieeexplore.ieee.org/document/8246941/,2017 IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids),15-17 Nov. 2017,ieeexplore
10.1109/CSPA.2014.6805724,Humanoid localisation in a robot soccer competition using a single camera,IEEE,Conferences,"One of the main challenges in a humanoid robot soccer competition is registering robots on the field so that they can estimate their best possible positions. This paper proposes an initial self-localisation algorithm to estimate the distance between a robot and a goal post, which is used as a landmark. By manipulating a single camera, we can apply analytic geometry to determine the real world coordinates of a robot from the transformation image plane. An experiment was conducted from the perspective of a robot in a soccer competition. The robot was able to locate itself with a minimum mean square error rate. This technology has great potential for boosting attacking and defensive performance.",https://ieeexplore.ieee.org/document/6805724/,2014 IEEE 10th International Colloquium on Signal Processing and its Applications,7-9 March 2014,ieeexplore
10.1109/ICRA.2013.6631340,Humanoid robot posture-control learning in real-time based on human sensorimotor learning ability,IEEE,Conferences,"In this paper we propose a system capable of teaching humanoid robots new skills in real-time. The system aims to simplify the robot control and to provide a natural and intuitive interaction between the human and the robot. The key element of the system is exploitation of the human sensorimotor learning ability where a human demonstrator learns how to operate a robot in the same fashion as humans adapt to various everyday tasks. Another key aspect of the proposed system is that the robot learns the task simultaneously while the human is operating the robot. This enables the control of the robot to be gradually transferred from the human to the robot during the demonstration. The control is transferred based on the accuracy of the imitated task. We demonstrated our approach using an experiment where a human demonstrator taught a humanoid robot how to maintain the postural stability in the presence of the perturbations. To provide the appropriate feedback information of the robot's postural stability to the human sensorimotor system, we utilized a custom-built haptic interface. To absorb the demonstrated skill by the robot, we used Locally Weighted Projection Regression machine learning method. A novel approach was implemented to gradually transfer the control responsibility from the human to the incrementally built autonomous robot controller.",https://ieeexplore.ieee.org/document/6631340/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/EPIA.2005.341221,Hybrid State Machines with Timed Synchronization for Multi-Robot System Specification,IEEE,Conferences,"In multi-robot systems, the need for precise modeling or specification of agent behaviors arises due to the high complexity of the robot agent interactions and the dynamics of the environment. Since the behavior of agents usually can be understood as driven by external events and internal states, it is obvious to model multiagent systems by state transition diagrams. The corresponding formalisms come equipped with a formal semantics which is advantageous. In this paper, a combination of UML statecharts and hybrid automata is proposed, allowing formal system specification on different levels on abstraction on the one hand, and expressing real-time system behavior with continuous variables on the other hand. One important aspect of multi-robot systems is the need of coordination and hence synchronization of behavior. For both, statecharts and hybrid automata, it is assumed that synchronization takes zero time. This is sometimes unrealistic. Therefore, a new notation and implementation of synchronization is proposed here, which overcomes this problem. The proposed method is illustrated with a case study from the robotic soccer domain",https://ieeexplore.ieee.org/document/4145962/,2005 portuguese conference on artificial intelligence,5-8 Dec. 2005,ieeexplore
10.1109/IROS.1991.174485,Implementation of an active optical range sensor using laser slit for in-door intelligent mobile robot,IEEE,Conferences,"The sensor with real-time environment recognition ability is one of the key technologies for autonomous robots. The authors have designed and implemented a small size optical range sensor for their experimental mobile robot. The sensor consists of a laser slit generator, a CCD image sensor and a processing unit. Using this sensor, the real-time obstacle avoiding function is realized and added to the autonomous navigation aspect of the robot.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174485/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/ACC.2014.6859431,"Implementation of an adaptive, model free, learning controller on the Atlas robot",IEEE,Conferences,"Recent events in natural and man-made disasters have highlighted the limitation in man's ability to confine and mitigate damage in such scenarios. Therefore, there is an urgent need for robotic technology that can function in all environments and serve as a substitute to humans in disaster scenarios. This paper presents research efforts to advance walking technology of humanoid robots with application to the Boston Dynamics Atlas robot. The Atlas was designed as part of the DARPA Robotics Challenge (DRC). The paper contribution is in a model free, walking trajectory tracking controller that is tested using GAZEBO robotics simulator. Artificial neural networks are used to learn the robot's nonlinear dynamics on the fly using a neuroadaptive control algorithm. The learned nonlinear dynamics are utilized along with a filtered error signal to generate input torques to control the system. Results show that the ability to approximate the robot nonlinear dynamics allows for full-body control without the need of modeling such a complex system. This ability is what makes the control scheme utilized appealing for complex, real-life, robotic applications that occur in a non-laboratory setting.",https://ieeexplore.ieee.org/document/6859431/,2014 American Control Conference,4-6 June 2014,ieeexplore
10.1109/CONIELECOMP.2014.6808580,Implementation of an embedded system on a TS7800 board for robot control,IEEE,Conferences,"Growing Functional Modules (GFM) learning based controllers need to be experimented on real robots. In 2009, looking to develop a flexible and generic embedded interface for such robots, we decided to use a TS-7800 single board computer (SBC) with a Debian Linux operating system. Despite the many advantages of this board, implementing the embedded system has been a complex task. This paper describes the implementation of protocols through the TS-7800 different ports (RS232, TCP/IP, USB, analog and digital pins) as well as the connection of external boards (TS-ADC24, TS-DIO64, SSC-32 and LCD display). This implementation was required to connect a large range of actuators, sensors and other peripherals. Furthermore, the architecture of the embedded system is exposed in detail, including topics such as the XML configuration file that specifies the peripherals connected to the SBC, the concept of virtual sensors, the implementation of parallelism and the embedded system interface launcher. Technical aspects such as the optimization of video capture and processing are detailed because their execution required specific compilers versions, EABI emulation and extra libraries (openCV libjpg and libpngand libv4l). The final embedded system was implemented in a humanoid robot and connected to the GFM controller in charge of developing its equilibrium subsystem.",https://ieeexplore.ieee.org/document/6808580/,"2014 International Conference on Electronics, Communications and Computers (CONIELECOMP)",26-28 Feb. 2014,ieeexplore
10.1109/CEC.2003.1299606,Implementation of an immuno-genetic network on a real Khepera II robot,IEEE,Conferences,"The design of autonomous navigation systems for mobile robots, with simultaneous objectives to be satisfied such as garbage collection with integrity maintenance, requires refined coordination mechanisms to deal with modules of elementary behaviour. This paper shows the implementation on a real Khepera II robot of an immuno-genetic network for autonomous navigation that combines an evolutionary algorithm with a continuous immune network model. The proposed immuno-genetic system has the immune network implementing a dynamic process of decision-making, and the evolutionary algorithm defining the network structure. To be able to evaluate the controllers (immune networks) on the evolutionary process, a virtual environment was used for computer simulation, based on the characteristics of the navigation problem. The immune networks obtained by evolution were then analyzed and tested on new situations, presenting coordination capability in simple and more complex tasks. Some preliminary experiments on a real Khepera II robot demonstrate the feasibility of the evolved immune networks.",https://ieeexplore.ieee.org/document/1299606/,"The 2003 Congress on Evolutionary Computation, 2003. CEC '03.",8-12 Dec. 2003,ieeexplore
10.1109/iFuzzy.2013.6825409,Implementation of human following mission by using fuzzy head motion control and Q-learning wheel motion control for home service robot,IEEE,Conferences,"This paper mainly implements human following function for home service robot, May, developed in our laboratory. In order to follow the operator accurately, visual tracking is composed by Tracing-Learning-Detection (TLD) and Kinect skeleton, where TLD plays the role as re-detecting the situation that operator is occluded or disappeared, and Kinect skeleton is adopted to track all other situations while TLD is learning how to enlarge operator image patterns in order to enhance recognition rates. For the sake of improving tracking capability, fuzzy head motion control is added in the visual tracking system to compensate the constraints that the mobile platform of May cannot react rapidly. Every instant movement of the operator can be captured by fuzzy head motion control in real time. Q-learning is applied to discover the pose switching of the mobile platform such that May possesses more robust following ability. By Q-learning, states setting are based on three dimensional position, actions are created by the pose of four wheel independent steering and four wheel independent driven (4WIS4WID) platform, and rewards are established on state transitions. Finally, both the experimental results in the laboratory and competition consequents of Follow Me Mission in robot@home league at RoboCup Japan Open 2013 Tokyo demonstrate that our robot May can fluently switch its poses to follow operator by utilizing the proposed schemes.",https://ieeexplore.ieee.org/document/6825409/,2013 International Conference on Fuzzy Theory and Its Applications (iFUZZY),6-8 Dec. 2013,ieeexplore
10.1109/SMC.2017.8122654,Implementation of human-robot VQA interaction system with dynamic memory networks,IEEE,Conferences,"One of the major functions of intelligent robots such as social or home service robots is to interact with users in natural language. Moving on from simple conversation or retrieval of data stored in computer memory, we present a new Human-Robot Interaction (HRI) system which can understand and reason over environment around the user and provide information about it in a natural language. For its intelligent interaction, we integrated Dynamic Memory Networks (DMN), a deep learning network for Visual Question Answering (VQA). For its hardware, we built a robotic head platform with a tablet PC and a 3 DOF neck. Through an experiment where the user and the robot had question answering interaction in our customized environment and in real time, the feasibility our proposed system was validated, and the effectiveness of deep learning application in real world as well as a new insight on human robot interaction was demonstrated.",https://ieeexplore.ieee.org/document/8122654/,"2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",5-8 Oct. 2017,ieeexplore
10.1109/INES.1997.632397,Implementation of neural network sliding-mode controller for DD robot,IEEE,Conferences,"The experimental development of a trajectory tracking neural network controller based on the theory of continuous sliding-mode controllers is shown in the paper. The neural network control law was verified on a real direct drive 3 DOF PUMA mechanism. The new neural network sliding-mode controller was successfully tested for trajectory tracking sudden changes in the manipulator dynamics (load). The comparision between the neural network sliding mode controller, a computer torque method controller and a continuous sliding mode controller with PI-estimator for sudden load changes on the real robot mechanism is shown.",https://ieeexplore.ieee.org/document/632397/,Proceedings of IEEE International Conference on Intelligent Engineering Systems,17-17 Sept. 1997,ieeexplore
10.1109/I2CT.2014.7092212,Implementation of synthetic brain concept in humanoid robot,IEEE,Conferences,"This paper is elaborate the model of humanoid robot interacts with human being and perform various operation as per the command given by the human being. A humanoid robot having Synthetic brain can able to do Interaction, communication, Object detection, information acquisition about any object, response to voice command, chatting logically with human beings. Object detection will be done by this robot for that purpose there is use image processing concept (HAAR Technique), And to make the system intelligent that is whenever system interact, communicate, chat with human it gives proper response, question / answers there is integrates artificial intelligence and DFA / NFA automata and Prolog language concept for answering logically over the complex and relevant strings or data.",https://ieeexplore.ieee.org/document/7092212/,International Conference for Convergence for Technology-2014,6-8 April 2014,ieeexplore
10.1109/ELECSYM.2018.8615506,Improving Field and Ball Detector for Humanoid Robot Soccer EROS Platform,IEEE,Conferences,"Humanoid robot soccer perceives environment mostly through cameras. The performance decrement in our humanoid soccer platform (EROS) is primarily due to the visual perception that is less robust to the RoboCup new rule which specifically reducing color coding in the field. Notable works favorably employ simple color segmentation, image morphology, and blob detector due to simplicity in the implementation and run in real-time for most embedded hardware, while some employ a more advanced supervised learning running in sophisticated hardware to boost detection accuracy. In this paper, a visual perception system consisting of field and ball detection is developed in our platform EROS to address the RoboCup new rule. Color segmentation and image morphology are stacked with a more advanced supervised learning cascade classifier. In this way, the favorable color segmentation and image morphology help to reduce the number of object candidates while the cascade classifier helps to boost the accuracy of detection. Experiments show encouraging result for detecting field and ball position. Our approach has successfully been implemented in practice and achieves remarkably result in Indonesian humanoid robot soccer competition.",https://ieeexplore.ieee.org/document/8615506/,2018 International Electronics Symposium on Engineering Technology and Applications (IES-ETA),29-30 Oct. 2018,ieeexplore
10.1109/ROMAN.2017.8172491,Improving robot transparency: Real-time visualisation of robot AI substantially improves understanding in naive observers,IEEE,Conferences,"Deciphering the behaviour of intelligent others is a fundamental characteristic of our own intelligence. As we interact with complex intelligent artefacts, humans inevitably construct mental models to understand and predict their behaviour. If these models are incorrect or inadequate, we run the risk of self deception or even harm. Here we demonstrate that providing even a simple, abstracted real-time visualisation of a robot's AI can radically improve the transparency of machine cognition. Findings from both an online experiment using a video recording of a robot, and from direct observation of a robot show substantial improvements in observers' understanding of the robot's behaviour. Unexpectedly, this improved understanding was correlated in one condition with an increased perception that the robot was `thinking', but in no conditions was the robot's assessed intelligence impacted. In addition to our results, we describe our approach, tools used, implications, and potential future research directions.",https://ieeexplore.ieee.org/document/8172491/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/ICEE50131.2020.9260698,"Indoor and Outdoor Face Recognition for Social Robot, Sanbot Robot as Case Study",IEEE,Conferences,"The interaction between human and robots is of paramount importance in comforting robot and human in the context of social demand. For the purpose of human-robot interaction, the robot should have the ability to perform a variety of actions including face recognition, path planning, etc. In this paper, face recognition has been implemented on the Sanbot robot. Since the Sanbot robot is intended to work in real environment, therefore indoor and outdoor environment is taken into account in proposing the corresponding face recognition algorithm. For each case a robust pre-processing algorithm should be designed and which can circumvent a challenging problem in face recognition, namely, different lighting conditions (light intensity, angle of radiation, etc.). In case of indoor environment, faces in an captured image by the robot HD camera are found using a Haar-cascade algorithm. Afterwards, a histogram equalization is applied to face images in order to standardize them. Then commonly practiced Deep convolutional neural network structures such as Inception and ResNet are used to design a model and trained end-to-end on a customized dataset with strong augmentation. Finally, by using a voting method, proper prediction is carried out on each face. In what concerns the outdoor environment, which has more challenges, upon applying histogram Equalization on the captured image, faces are found using a MultiTask Cascaded Convolutional Neural Network. Then face images are aligned as head orientation are corrected. Finally, cropped face image is fed to Siamese Network in order to extract face features and verifying individuals. From several practical results it has been inferred that the accuracy of the indoor method is nearly 93% without voting and with voting 97%, and the outdoor method is about 95%.",https://ieeexplore.ieee.org/document/9260698/,2020 28th Iranian Conference on Electrical Engineering (ICEE),4-6 Aug. 2020,ieeexplore
10.1109/CASE48305.2020.9216902,Industrial Robot Grasping with Deep Learning using a Programmable Logic Controller (PLC),IEEE,Conferences,"Universal grasping of a diverse range of previously unseen objects from heaps is a grand challenge in e-commerce order fulfillment, manufacturing, and home service robotics. Recently, deep learning based grasping approaches have demonstrated results that make them increasingly interesting for industrial deployments. This paper explores the problem from an automation systems point-of-view. We develop a robotics grasping system using Dex-Net, which is fully integrated at the controller level. Two neural networks are deployed on a novel industrial AI hardware acceleration module close to a PLC with a power footprint of less than 10 W for the overall system. The software is tightly integrated with the hardware allowing for fast and efficient data processing and real-time communication. The success rate of grasping an object form a bin is up to 95% with more than 350 picks per hour, if object and receptive bins are in close proximity. The system was presented at the Hannover Fair 2019 (world's largest industrial trade fair) and other events, where it performed over 5,000 grasps per event.",https://ieeexplore.ieee.org/document/9216902/,2020 IEEE 16th International Conference on Automation Science and Engineering (CASE),20-21 Aug. 2020,ieeexplore
10.1109/ROBOT.1992.219999,Integrated planning and execution control of autonomous robot actions,IEEE,Conferences,"The authors describe an implemented integrated system allowing a mobile robot to plan its actions, taking into account temporal constraints, and to control their execution in real time. The general architecture has three levels, and the approach is related to hierarchical planning: the plan produced by the temporal planner is further refined at the control level, which in turn supervises its execution by a functional level. The framework of the French Mars Rover project VAP is used as an illustration of the various aspects discussed.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/219999/,Proceedings 1992 IEEE International Conference on Robotics and Automation,12-14 May 1992,ieeexplore
10.1109/ARIS50834.2020.9205772,Intelligent Robot for Worker Safety Surveillance: Deep Learning Perception and Visual Navigation,IEEE,Conferences,"The fatal injury rate for the construction industry is higher than the average for all industries. Recently, researchers have shown an increased interest in occupational safety in the construction industry. However, all the current methods using conventional machine learning with stationary cameras suffer from some severe limitations, perceptual aliasing (e.g., different places/objects can appear identical), occlusion (e.g., place/object appearance changes between visits), seasonal / illumination changes, significant viewpoint changes, etc. This paper proposes a perception module using end-to-end deep-learning and visual SLAM (Simultaneous Localization and Mapping) for an effective and efficient object recognition and navigation using a differential-drive mobile robot. Various deep-learning frameworks and visual navigation strategies with evaluation metrics are implemented and validated for the selection of the best model. The deep-learning model's predictions are evaluated via the metrics (model speed, accuracy, complexity, precision, recall, P-R curve, F1 score). The YOLOv3 shows the best trade-off among all algorithms, 57.9% mean average precision (mAP), in real-world settings, and can process 45 frames per second (FPS) on NVIDIA Jetson TX2 which makes it suitable for real-time detection, as well as a right candidate for deploying the neural network on a mobile robot. The evaluation metrics used for the comparison of laser SLAM are Root Mean Square Error (RMSE). The Google Cartographer SLAM shows the lowest RMSE and acceptable processing time. The experimental results demonstrate that the perception module can meet the requirements of head protection criteria in Occupational Safety and Health Administration (OSHA) standards for construction. To be more precise, this module can effectively detect construction worker's non-hardhat-use in different construction site conditions and can facilitate improved safety inspection and supervision.",https://ieeexplore.ieee.org/document/9205772/,2020 International Conference on Advanced Robotics and Intelligent Systems (ARIS),19-21 Aug. 2020,ieeexplore
10.1109/ICNN.1988.23981,Intelligent control of the Intelledex 605T robot manipulator,IEEE,Conferences,"The authors present the results of the experiments which indicate how controlled robotic motion might be achieved through pattern-based paradigms, implemented for real-time operation on the Intelledex 605T robot manipulator with artificial neural nets (ANN). Previous attempts at pattern-based control have often failed, primarily because of the need for storage of an enormous number of training-set patterns and the long times required for pattern processing. It is demonstrated that these problems can be overcome through use of artificial neural networks implemented by parallel distributed processing. The feedforward Rumelhart net is investigated for the constrained robot manipulator. The robot arm, with two degrees of freedom, must move its end effector toward an observed target in the presence of disturbances. Such a control action need not be programmed in detail. Presented with a small number of training situations, the ANN can generalize and perform in many different situations. Preliminary results obtained using an Intelledex 605T and an IBM PC/AT are described.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/23981/,IEEE 1988 International Conference on Neural Networks,24-27 July 1988,ieeexplore
10.1109/IROS.2005.1545188,Interactive evolution of human-robot communication in real world,IEEE,Conferences,"This paper describes how to implement interactive evolutionary computation (IEC) into a human-robot communication system. IEC is an evolutionary computation (EC) in which the fitness function is performed by human assessors. We used IEC to configure the human-robot communication system. We have already simulated IEC's application. In this paper, we implemented IEC into a real robot. Since this experiment leads considerable burdens on both the robot and experimental subjects, we propose the human-machine hybrid evaluation (HMHE) to increase the diversity within the genetic pool without increasing the number of interactions. We used a communication robot, WAMOEBA-3 (Waseda artificial mind on emotion base), which is appropriate for this experiment. In the experiment, human assessors interacted with WAMOEBA-3 in various ways. The fitness values increased gradually, and assessors felt the robot learnt the motions they desired. Therefore, it was confirmed that the IEC is most suitable as the communication learning system.",https://ieeexplore.ieee.org/document/1545188/,2005 IEEE/RSJ International Conference on Intelligent Robots and Systems,2-6 Aug. 2005,ieeexplore
10.1109/ICRAI47710.2019.8967365,Investigating Series-Parallel Actuation Arrangement in a Bioinspired Biped Robot,IEEE,Conferences,A bipedal robot with serial linkage legs having passive energy storage elements distal to the knee in a Series Parallel Elastic Actuation (SPEA) arrangement is presented to demonstrate and experiment on energy input and recovery during energy-intensive low frequency squatting. The robot is based on the hind legs of the Felidae family with bio-inspired linkage ratios and spring locations. The design places special emphasis on reduction of leg inertia by qualitative assessment of placement of heavier components including motors. Natural dynamics of the system are explored by allowing the assembly to fall from a height and observing its passive spring-damping characteristics and oscillatory frequency. The same is also investigated through computational simulations in the absence of real-world constraints such as joint friction. The effects of SPEA at the knee and ankle joint is observed on the ground-reaction force through the simulation environment. An interesting proposal of incorporating an engage-disengage spring at the knee joint is discussed.,https://ieeexplore.ieee.org/document/8967365/,2019 International Conference on Robotics and Automation in Industry (ICRAI),21-22 Oct. 2019,ieeexplore
10.1109/IJCNN.2003.1223995,Investigating models of social development using a humanoid robot,IEEE,Conferences,"Human social dynamics rely upon the ability to correctly attribute beliefs, goals, and percepts to other people. The set of abilities that allow an individual to infer these hidden mental states based on observed actions and behavior has been called a ""theory of mind"". Drawing from the models of Baron-Cohen (1995) and Leslie (1994), a novel architecture called embodied theory of mind was developed to link high-level cognitive skills to the low-level perceptual abilities of a humanoid robot. The implemented system determines visual saliency based on inherent object attributes, high-level task constraints, and the attentional states of others. Objects of interest are tracked in real-time to produce motion trajectories which are analyzed by a set of naive physical laws designed to discriminate animate from inanimate movement. Animate objects can be the source of attentional states (detected by finding faces and head orientation) as well as intentional states (determined by motion trajectories between objects). Individual components are evaluated by comparisons to human performance on similar tasks, and the complete system is evaluated in the context of a basic social learning mechanism that allows the robot to mimic observed movements.",https://ieeexplore.ieee.org/document/1223995/,"Proceedings of the International Joint Conference on Neural Networks, 2003.",20-24 July 2003,ieeexplore
10.1109/ROBIO.2006.340332,Landmark Design Using Projective Invariant for Mobile Robot Localization,IEEE,Conferences,"For the fast and accurate self-localization of mobile robots in navigation, artificial landmarks can be used very efficiently in the complex workspace. In this paper, in order to provide feedback and verification mechanisms in navigation technique, we design two types of artificial landmarks with symmetric rectangles and seven-part numbers, which show cross- ratio invariant under projective transformation. The fast landmark detection-recognition algorithm and self-localization are proposed and their feasibility and robustness are demonstrated by practical experiments in cluttered indoor environments and simulation experiment. Experimental results show that proposed landmark patterns are enough to be used in cluttered environment and landmark detection-recognition in cluttered scene is real-time robustly under various viewing angles, self-localization accuracy is high enough in the presence of additive random noise.",https://ieeexplore.ieee.org/document/4141977/,2006 IEEE International Conference on Robotics and Biomimetics,17-20 Dec. 2006,ieeexplore
10.1109/GCIS.2009.206,Layered Task Allocation in Multi-robot Systems,IEEE,Conferences,"A layered task allocation method is presented for multi-robot systems in a collaboration and adversarial, dynamic, real-time environment with unreliable communication in this paper. The process of task allocation is divided into three layers: task decomposition layer, task evaluation layer and task selection layer. In task decomposition layer, robots categorize their environments into corresponding modes, and fix subtasks in every mode as experts do, in order to reduce candidate tasks and decrease the complexity of task allocation. Q-Learning based on Adaptive Neuro Fuzzy Inference System (ANFIS) is adopted to compute utilities of candidate tasks in task evaluation layer. This can not only avoid the complicated opponent modeling but also make the learning more efficient. In task selection layer, task with the maximum utility is selected in application, but in learning, task is selected according to randomized Boltzmann exploration tactics in order to get more information for optimization. Simulation experiments implemented on simulated robotic soccer show that this approach improves performances of multi-robot systems greatly.",https://ieeexplore.ieee.org/document/5209028/,2009 WRI Global Congress on Intelligent Systems,19-21 May 2009,ieeexplore
10.1109/ROBIO.2007.4522258,Layered omnidirectional walking controller for the humanoid soccer robot,IEEE,Conferences,"This paper proposes the layered omnidirectional walking controller for the humanoid soccer robot. The gait of the robot can be parameterized using the destination posititon and the desired direction while reaching the destination. Its implementation in our RoboCup simulation team - SEU-3D is detailed in this paper. Our approach generates smooth robot trajectories without stop before changing direction or turning, and is fast enough to meet the real-time requirements. The proposed approach has been tested in the RoboCup soccer 3D server platform. The results showed that omnidirectional walking has advantages in dynamic environments.",https://ieeexplore.ieee.org/document/4522258/,2007 IEEE International Conference on Robotics and Biomimetics (ROBIO),15-18 Dec. 2007,ieeexplore
10.1109/ICTC49870.2020.9289214,Learning Control Policy with Previous Experiences from Robot Simulator,IEEE,Conferences,"Advances in deep reinforcement learning enabled cost-efficient training of control policy of physical robot actions from robot simulators. Learning control policy in a simulated environment is cost-efficient over learning in a real environment. Reward engineering is one of the key components to train efficient control policy. For tasks with long horizons such as navigation and manipulation, a sparse reward is providing limited information. The robot simulator for a physical engine of physical robot manipulation has made it easy for researchers in the field of deep reinforcement learning to simulate complicated robot manipulation environments. In this paper, A robot manipulation simulator and a deep RL framework are utilized for implement a training control policy by utilizing previous experiences. For implementation, Recent innovation Hindsight Experience Replay (HER) algorithms with previous experiences to calculate dense rewards from a sparse reward is leveraged . Proposed implementation showed an approach to investigate the reward engineering method to formulate dense reward in robot manipulator tasks.",https://ieeexplore.ieee.org/document/9289214/,2020 International Conference on Information and Communication Technology Convergence (ICTC),21-23 Oct. 2020,ieeexplore
10.1109/IROS45743.2020.9340865,Learning Human-Aware Robot Navigation from Physical Interaction via Inverse Reinforcement Learning,IEEE,Conferences,"Autonomous systems, such as delivery robots, are increasingly employed in indoor spaces to carry out activities alongside humans. This development poses the question of how robots can carry out their tasks while, at the same time, behaving in a socially compliant manner. Further, humans need to be able to communicate their preferences in a simple and intuitive way, and robots should adapt their behavior accordingly. This paper investigates force control as a natural means to interact with a mobile robot by pushing it along the desired trajectory. We employ inverse reinforcement learning (IRL) to learn from human interaction and adapt the robot behavior to its users' preferences, thereby eliminating the need to program the desired behavior manually. We evaluate our approach in a real-world experiment where test subjects interact with an autonomously navigating robot in close proximity. The results suggest that force control presents an intuitive means to interact with a mobile robot and show that our robot can quickly adapt to the test subjects' personal preferences.",https://ieeexplore.ieee.org/document/9340865/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ICRA.2016.7487509,Learning assistive strategies from a few user-robot interactions: Model-based reinforcement learning approach,IEEE,Conferences,"Designing an assistive strategy for exoskeletons is a key ingredient in movement assistance and rehabilitation. While several approaches have been explored, most studies are based on mechanical models of the human user, i.e., rigid-body dynamics or Center of Mass (CoM)-Zero Moment Point (ZMP) inverted pendulum moECenter of Massdel, or only focus on periodic movements with using oscillator models. On the other hand, the interactions between the user and the robot are often not considered explicitly because of its difficulty in modeling. In this paper, we propose to learn the assistive strategies directly from interactions between the user and the robot. We formulate the learning problem of assistive strategies as a policy search problem. To alleviate heavy burdens to the user for data acquisition, we exploit a data-efficient model-based reinforcement learning framework. To validate the effectiveness of our approach, an experimental platform composed of a real subject, an electromyography (EMG)-measurement system, and a simulated robot arm is developed. Then, a learning experiment with the assistive control task of the robot arm is conducted. As a result, proper assistive strategies that can achieve the robot control task and reduce EMG signals of the user are acquired only by 30 seconds interactions.",https://ieeexplore.ieee.org/document/7487509/,2016 IEEE International Conference on Robotics and Automation (ICRA),16-21 May 2016,ieeexplore
10.1109/IECON.1993.339280,Learning behavioral control by reinforcement for an autonomous mobile robot,IEEE,Conferences,"We present an implementation of a reinforcement learning algorithm through the use of a special neural network topology, the AHC (adaptive heuristic critic). The AHC constitutes a fusion supervisor of primitive behaviours in order to execute more complex robot behaviours as for example go to goal. This fusion supervisor is part of an architecture for the execution of mobile robot tasks which are composed of several primitive behaviours which act in a simultaneous or concurrent fashion. The architecture allows for learning to take place at the execution level, it incorporates the experience gained in executing primitive behaviours as well as the overall task. The implementation of the autonomous learning approach has been tested within OPMOR, a simulation environment for mobile robots and with our mobile platform UPM Robuter. Both simulated and real results are presented. The performance of the AHC neural network is adequate. Portions of this work have been implemented in the EEC ESPRIT 2483 PANORAMA Project.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/339280/,Proceedings of IECON '93 - 19th Annual Conference of IEEE Industrial Electronics,15-19 Nov. 1993,ieeexplore
10.1109/ROBIO.2017.8324818,Learning complex assembly skills from kinect based human robot interaction,IEEE,Conferences,"Acquiring complex assembly skills is still a challenging task for robot programming. Because of the sensory and body structure differences, the human knowledge has to be demonstrated, recorded, converted and finally learned by the robot, in an inexplicit and indirect way. During this process, “how to demonstrate”, “how to convert” and “how to learn” are the key problems. In this paper, Kinect sensor is utilized to provide the behavior information of the human demonstrator. Through natural human robot interaction, body skeleton and joint 3D coordinates are provided in real-time, which can fully describe the human intension and task related skills. To overcome the structural and individual differences, a Cartesian level unified mapping method is proposed to convert the human motion and match the specified robot. The recorded data set are modeled using Gaussian mixture model(GMM) and Gaussian mixture regression(GMR), which can extract redundancies across multiple demonstrations and build robust models to regenerate the dynamics of the recorded movements. The proposed methodologies are implemented in the imNEU humanoid robot platform. Experimental results verify the effectiveness.",https://ieeexplore.ieee.org/document/8324818/,2017 IEEE International Conference on Robotics and Biomimetics (ROBIO),5-8 Dec. 2017,ieeexplore
10.1109/IJCNN.1993.716991,Learning goal-directed navigation as attractor dynamics for a sensory motor system. (An experiment by the mobile robot YAMABICO),IEEE,Conferences,"This paper describes experimental results based on the authors' prior-proposed scheme: learning of sensory-based, goal-directed behavior. The scheme was implemented on the mobile robot ""YAMABICO"" and learning of a set of goal-directed navigations were conducted. The experiment assumed that the robot receives no global information such as position nor prior environment model. Instead, the robot was trained to learn adequate maneuvering in the adopted workspace by building a correct mapping between a spatio-temporal sequence of sensory inputs and maneuvering outputs on a neural structure. The experimental results showed that sufficient training generated rigid dynamical structure of a fixed point and limit cycling in the sensory-based state space, which realized robust navigations of homing and cyclic routing even against certain changes of environment as well as miscellaneous noises in the real world.",https://ieeexplore.ieee.org/document/716991/,"Proceedings of 1993 International Conference on Neural Networks (IJCNN-93-Nagoya, Japan)",25-29 Oct. 1993,ieeexplore
10.1109/IROS.2014.6943031,Learning robot tactile sensing for object manipulation,IEEE,Conferences,"Tactile sensing is a fundamental component of object manipulation and tool handling skills. With robots entering unstructured environments, tactile feedback also becomes an important ability for robot manipulation. In this work, we explore how a robot can learn to use tactile sensing in object manipulation tasks. We first address the problem of in-hand object localization and adapt three pose estimation algorithms from computer vision. Second, we employ dynamic motor primitives to learn robot movements from human demonstrations and record desired tactile signal trajectories. Then, we add tactile feedback to the control loop and apply relative entropy policy search to learn the parameters of the tactile coupling. Additionally, we show how the learning of tactile feedback can be performed more efficiently by reducing the dimensionality of the tactile information through spectral clustering and principal component analysis. Our approach is implemented on a real robot, which learns to perform a scraping task with a spatula in an altered environment.",https://ieeexplore.ieee.org/document/6943031/,2014 IEEE/RSJ International Conference on Intelligent Robots and Systems,14-18 Sept. 2014,ieeexplore
10.1109/ROBIO.2009.5420526,Learning-based action planning for real-time robot telecontrol with binocular vision in enhanced reality environment,IEEE,Conferences,"Action planning is one of the pivot issues in robot telecontrol, in which the action instructions are often given by the controller from remote site with the help of vision systems. In this paper, we present a learning-based strategy for action planning in robot telecontrol, in which the parameters of sophisticated actions of the remote robot equipped with a binocular vision system could be pre-scheduled with a virtual robot at the control terminal. The remote robot will then be 'taught' with the scheduled action plan with a series of parameter sets obtained form try-outs with the virtual robot and object in the enhanced environment, thus implementing dedicated actions assigned correctly. The action planning process is implemented within a enhanced reality environment, in which both the virtual and the real robot will be displayed simultaneously for the purpose of being deeply immersed. Experiment results demonstrate that the proposed method is capable of promoting the action precision of the remote robot, and effective and valid to designated applications, where action precision plays a critical role.",https://ieeexplore.ieee.org/document/5420526/,2009 IEEE International Conference on Robotics and Biomimetics (ROBIO),19-23 Dec. 2009,ieeexplore
10.1109/HRI.2019.8673212,Lifespan Design of Conversational Agent with Growth and Regression Metaphor for the Natural Supervision on Robot Intelligence,IEEE,Conferences,"Human's direct supervision on robot's erroneous behavior is crucial to enhance a robot intelligence for a `flawless' human-robot interaction. Motivating humans to engage more actively for this purpose is however difficult. To alleviate such strain, this research proposes a novel approach, a growth and regression metaphoric interaction design inspired from human's communicative, intellectual, social competence aspect of developmental stages. We implemented the interaction design principle unto a conversational agent combined with a set of synthetic sensors. Within this context, we aim to show that the agent successfully encourages the online labeling activity in response to the faulty behavior of robots as a supervision process. The field study is going to be conducted to evaluate the efficacy of our proposal by measuring the annotation performance of real-time activity events in the wild. We expect to provide a more effective and practical means to supervise robot by real-time data labeling process for long-term usage in the human-robot interaction.",https://ieeexplore.ieee.org/document/8673212/,2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI),11-14 March 2019,ieeexplore
10.1109/HSI49210.2020.9142636,Lightweight Convolutional Neural Network for Real-Time Face Detector on CPU Supporting Interaction of Service Robot,IEEE,Conferences,"Face detection plays an essential role in the success of the interaction between service robots and consumers. This method is the initial stage for face-related applications. Practical applications require face detection to work in real-time and can be implemented on low-cost devices such as CPU. Traditional methods have problems when the face is not frontal, blocked, and partially covered, but real-time speed is not an obstacle. On the other hand, deep learning has succeeded in accurately distinguishing facial features and backgrounds. Face sizes that tend to be medium and large when robot interaction with consumers so it can employ Convolutional Neural Networks (CNN) with light weights. In this paper, a real-time face detector is built that can work on the CPU. This detector will be implemented explicitly in service robots to support interactions with consumers. It can overcome the occlusion and not-frontal face. Detector architecture consists of the backbone as rapidly features extractor, transition module as a transformer of prediction map, and the dual-detection layer is head of a network prediction based on scale assignment. As a result, the detector can work at speeds of 301 frames per second on CPU without ignoring the accuracy.",https://ieeexplore.ieee.org/document/9142636/,2020 13th International Conference on Human System Interaction (HSI),6-8 June 2020,ieeexplore
10.23919/ChiCC.2018.8483251,Local Gaussian Processes for Identifying Complex Mobile robot System,IEEE,Conferences,"Nonparametric Gaussian processes regression (GPR) is an important tool in machine learning, can be applied in identifying nonlinear models from experimental data, especially, the prediction of mean and variance present the useful advantage. However, when dealing with the large number of training data for the prediction of a complex dynamics system, GPR is not suitable to implement in real-time learning systems. To reduce the computation effort, local learning algorithm is introduced to improve the global Gaussian processes (GP) model in this paper. In this paper, a convenient and effective method for building local model network is proposed and then local GP for weighted regression is performed. The proposed local GPR method is implemented on a simulated example of online identification and prediction fast for a complex dynamic system of wheeled mobile robot.",https://ieeexplore.ieee.org/document/8483251/,2018 37th Chinese Control Conference (CCC),25-27 July 2018,ieeexplore
10.1109/IROS.2004.1389735,Localization for robot mowers covering unmarked operational area,IEEE,Conferences,"The accurate localization is significant for both the accurate terrain acquisition and the successful area covering. Our research aims at the operational area without any manmade marks, the robot utilizes its localization system to establish the digital boundaries of the unmarked operational area. According to the specialties of outdoor environment and the practical mowing requirements, the localization system with combined sensors and the localization algorithm based on neural network are designed. The results of experiment show that the designed neural network can make the accuracy of the localization well improved. With the measurements of the ultrasonic sensors, an effective error-correction method based on the database of environmental features knowledge is proposed for the robot mower to correct its position errors in the real-time coverage operation. The localization information is reliable to ensure the intelligent behaviors of the robot mower. The technical presentations in this paper can facilitate the development of the environmental robotics.",https://ieeexplore.ieee.org/document/1389735/,2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),28 Sept.-2 Oct. 2004,ieeexplore
10.1109/AIM43001.2020.9158805,MISO Model Free Adaptive Control of Single Joint Rehabilitation Robot Driven by Pneumatic Artificial Muscles,IEEE,Conferences,"Pneumatic artificial muscles (PAMs) are widely used as actuators in the field of rehabilitation robots, but their intrinsic compliance properties make it difficult to control precisely. In this paper, an improved multiple input single output model free adaptive control (MISO-IMFAC) method is proposed for the modeling the uncertainty, high nonlinearity and time-variability of the single joint rehabilitation robot driven by antagonistic PAMs, so as to realize the high-precision control of the joint angle. Considering the influence of the error change of adjacent time on the actual control effect, a new control law is formed by adding a term representing error change to the original control input criterion function. The experiment is carried out on a real rehabilitation robot and four types of errors are used to evaluate the effectiveness of the control system. The results show that the control algorithm can improve the accuracy of angle trajectory tracking at different amplitudes. Compared with original algorithm, the experiment errors of MISO-IMFAC were significantly reduced. In addition, the MISO-IMFAC still maintains stable performance in the process of load variation and external disturbance.",https://ieeexplore.ieee.org/document/9158805/,2020 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM),6-9 July 2020,ieeexplore
10.1109/ICCSE.2014.6926425,MKL-SVM-based human detection for autonomous navigation of a robot,IEEE,Conferences,"This paper presents a classifier trained by a multiple kernel-learning support vector machine (MKL-SVM) to detect a human in sequential images from a video stream. The developed method consists of two aspects: multiple features consisting of HOG features and HOF features suitable for moving objects, and combined nonlinear kernels for SVM. For the purpose of real time application in autonomous navigation, the SimpleMKL algorithm is implemented into the proposed MKL-SVM classifier. It is able to converge rapidly with comparable efficiency through a weighted 2-norm regularization formulation with an additional constraint on the weights. The classifier is compared with the state-of-the-art linear SVM using a dataset called TUD-Brussels, which is available on line. The results show that the proposed classifier outperforms the Linear SVM with respect to accuracy.",https://ieeexplore.ieee.org/document/6926425/,2014 9th International Conference on Computer Science & Education,22-24 Aug. 2014,ieeexplore
10.1109/WACV.2009.5403083,ML-fusion based multi-model human detection and tracking for robust human-robot interfaces,IEEE,Conferences,"A novel stereo vision system for real-time human detection and tracking on a mobile service robot is presented in this paper. The system integrates the individually enhanced stereo-based human detection, HOG-based human detection, color-based tracking, and motion estimation for the robust detection and tracking of humans with large appearance and scale variations in real-world environments. A new framework of maximum likelihood based multi-model fusion is proposed to fuse these four human detection and tracking models according to the detection-track associations in 3D space, which is robust to the possible missed detections, false detections, and duplicated responses from the individual models. Multi-person tracking is implemented in a sequential near-to-far way, which well alleviates the difficulties caused by human-over-human occlusions. Extensive experimental results demonstrate the robustness of the proposed system under real-world scenarios with large variations in lighting conditions, cluttered backgrounds, human clothes and postures, and complex occlusion situations. Significant improvements in human detection and tracking have been achieved. The system has been deployed on six robot butlers to serve drinks, and showed encouraging performance in open ceremony events.",https://ieeexplore.ieee.org/document/5403083/,2009 Workshop on Applications of Computer Vision (WACV),7-8 Dec. 2009,ieeexplore
10.1109/MFI-2003.2003.1232635,Map generation based on the interaction between robot body and its surrounding environment,IEEE,Conferences,"This paper presents a method for map generation based on the interaction between a robot body and its surrounding environment. While a robot moves in the environment, the robot interacts with its surrounding environment. If the effect of the environment on the robot changes, such interactions also change. By observing the robot's body, our method detects such change of the interaction and generates a description representing the type of change and the location where such change is observed. In the current implementation, we assume that there are two types of the change in the interaction. The real robot experiments are conducted in order to show the validity of our method.",https://ieeexplore.ieee.org/document/1232635/,"Proceedings of IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems, MFI2003.",1-1 Aug. 2003,ieeexplore
10.1109/SSCI.2016.7850169,Memetic robot control evolution and adaption to reality,IEEE,Conferences,"Inspired by animals' ability to learn and adapt to changes in their environment during life, hybrid evolutionary algorithms have been developed and successfully applied in a number of research areas. This paper explores the effects of learning combined with a genetic algorithm to evolve control system parameters for a four-legged robot. Here, learning corresponds to the application of a local search algorithm on individuals during evolution. Two types of learning were implemented and tested, i.e. Baldwinian and Lamarckian learning. On the direct results from evolution in simulation, Lamarckian learning showed promising results, with a significant increase in final fitness compared with the results from evolution without learning. Further experiments with learning on the real robot demonstrated an efficient adaptation of the robot gait to the real world environment, and increased the performance to the level measured in simulation. This paper demonstrates that Lamarckian evolution is effective in improving the performance of robot controller evolution, and that the same learning process on the physical robot efficiently reduces the negative impact of the simulation-reality gap.",https://ieeexplore.ieee.org/document/7850169/,2016 IEEE Symposium Series on Computational Intelligence (SSCI),6-9 Dec. 2016,ieeexplore
10.1109/PUNECON.2018.8745403,Military Surveillance Robot Implementation Using Robot Operating System,IEEE,Conferences,"Robots are becoming more and more prevalent in many real world scenarios. Housekeeping, medical aid, human assistance are a few common implementations of robots. Military and Security are also major areas where robotics is being researched and implemented. Robots with the purpose of surveillance in war zones and terrorist scenarios need specific functionalities to perform their tasks with precision and efficiency. In this paper, we present a model of Military Surveillance Robot developed using Robot Operating System. The map generation based on Kinect sensor is presented and some test case scenarios are discussed with results.",https://ieeexplore.ieee.org/document/8745403/,2018 IEEE Punecon,30 Nov.-2 Dec. 2018,ieeexplore
10.23919/CCC50068.2020.9189320,Mobile Robot Path Planning Based on Improved Ant Colony Optimization Algorithm,IEEE,Conferences,"ACO (ant colony algorithm) is a kind of bionic optimization algorithm developed in recent decades, which has shown its excellent performance and great development potential in solving many complex problems. Q-learning, a type of reinforcement learning, has gained increasing popularity in autonomous mobile robot path recently. In order to effectively solve mobile robot path planning problem in obstacle avoidance environment, a path planning model and search algorithm based on improved ant colony optimization algorithm are proposed. The incentive model of reinforcement learning mechanism is introduced with the volatilization of pheromone concentration, establishing dynamic volatile function table.The group intelligent search iterative process of global position selection and local position selection is exploited to combine the volatilization of pheromone concentration with ant colony algorithm, dynamically adjusting the empirical parameter of the reward function by strengthening the data training experiment of Q-learning. To determine the constant parameters for simulation experiment, once the distance between the robot and the obstacle is less than a certain thresholds value, the 0-1 random number is used to randomly adjust the moving direction, avoiding the occurrence of mobile robot path matching deadlock. The study case shows that the proposed algorithm is proved to be better efficient and effective, thereby improving the search intensity and accuracy of the mobile robot path planning problem. And the experimental simulation shows that the proposed model and algorithm effectively solve mobile robot path planning problem that the parameter selection and the actual scene cannot be adapted in real time in traditional path planning problem.",https://ieeexplore.ieee.org/document/9189320/,2020 39th Chinese Control Conference (CCC),27-29 July 2020,ieeexplore
10.1109/SISY.2009.5291131,Mobile robot control using self-learning neural network,IEEE,Conferences,"The paper describes the concept of the navigation system for a mobile robot. The system is using a navigation algorithm based on self-learning neural network, necessary to form a movement plan for a robot. The algorithm is adapted and implemented to navigate real platform of a mobile robot equipped by two independent wheel drives, encoders and a set of short-range sonars. Navigation algorithm is placed into a PC, which is connected to mobile robot by wireless and wired links. Experiments have shown ability of collision-free navigation of mobile robot in real time.",https://ieeexplore.ieee.org/document/5291131/,2009 7th International Symposium on Intelligent Systems and Informatics,25-26 Sept. 2009,ieeexplore
10.1109/ROBOT.1998.681416,Mobile robot exploration and map-building with continuous localization,IEEE,Conferences,"Our research addresses how to integrate exploration and localization for mobile robots. A robot exploring and mapping an unknown environment needs to know its own location, but it may need a map in order to determine that location. In order to solve this problem, we have developed ARIEL, a mobile robot system that combines frontier based exploration with continuous localization. ARIEL explores by navigating to frontiers, regions on the boundary between unexplored space and space that is known to be open. ARIEL finds these regions in the occupancy grid map that it builds as it explores the world. ARIEL localizes by matching its recent perceptions with the information stored in the occupancy grid. We have implemented ARIEL on a real mobile robot and tested ARIEL in a real-world office environment. We present quantitative results that demonstrate that ARIEL can localize accurately while exploring, and thereby build accurate maps of its environment.",https://ieeexplore.ieee.org/document/681416/,Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),20-20 May 1998,ieeexplore
10.1109/ICSAI.2018.8599478,Mobile robot multi-resolution full coverage path planning algorithm,IEEE,Conferences,"The mobile robot can independently run the core as SLAM and path planning [1]. In the grid method drawing, high-precision positioning requires a high-resolution grid. When a mobile robot covers a certain working area, since the coverage width is constant each time, when high-efficiency coverage is required, a low-resolution grid is required for path planning, and a multi-resolution raster problem occurs. For the full coverage path planning problem of multi-resolution mobile robots, this paper proposes the use of high-precision grid positioning, low-resolution raster path planning coverage. In the normal grid traversal process, this paper adopts a mobile robot full coverage path planning algorithm based on bio-excitation network, which can be autonomous exploration traversal. This paper actually models its algorithm, and increases direction guidance and robot into dead zone. When escaping from the dead zone as soon as possible according to greedy thoughts, the algorithm has good real-time performance, can automatically avoid obstacles and escape from the dead zone, and there will be no large-scale folding back. Especially in the field of cleaning, the follow-on mobile robot can effectively clean the narrow area. It can make the cleaning car recycle garbage and has high cleaning efficiency. In the process of high resolution to low resolution, there are both moving obstacles and movable motion grids. This paper uses quadtree segmentation and Hilbert curve to traverse the motion grid to improve coverage and efficiency. The edge of the rule explores the purpose of reciprocating the entire region by reciprocating the unknown environment. In the experiment, it is proved that the algorithm of this paper has higher coverage efficiency by comparing with the original biological excitation network algorithm.",https://ieeexplore.ieee.org/document/8599478/,2018 5th International Conference on Systems and Informatics (ICSAI),10-12 Nov. 2018,ieeexplore
10.1109/ICRoM.2017.8466169,Mobile robot navigation based on Fuzzy Cognitive Map optimized with Grey Wolf Optimization Algorithm used in Augmented Reality,IEEE,Conferences,"This work presents a control technique for Mobile Robot Navigation using augmented reality (AR). This navigation technique is based on optimized Fuzzy Cognitive Map (FCM) and AR's Glyphs. AR's symbols are provided by the overhead camera. The patterns are made up of glyphs and a clear path. Six practical test are manipulated to examine the strength of optimizing FCM by a mobile robot for navigation with AR's symbols. The experiment examined the effectiveness of a Grey Wolf Optimization Algorithm (GWOA) in optimizing the FCM. Two practical experiments confirm that AR's Glyphs are an effective symbol for a robot to navigation in an unknown environment. A practical experiment reveals that a robot can use AR to manage its intended movement. Augmented reality, such as the Glyphs and a simplified map, are an effective tool for mobile robots to use in navigation in unknown environments. A prototype system is made to navigate the mobile robot by using AR and FCM.",https://ieeexplore.ieee.org/document/8466169/,2017 5th RSI International Conference on Robotics and Mechatronics (ICRoM),25-27 Oct. 2017,ieeexplore
10.1109/AMC.2006.1631674,Mobile robot navigation in an unknown environment,IEEE,Conferences,"This paper discusses application of an intelligent system in order to navigate in real-time a small size, four wheeled, indoor mobile robot accurately using ultra-light (160 gr), inexpensive laser range finder without prior information of the environment. A recurrent neural network is used to find the best path to the target of the robot. An accurate grid-based map is generated using a laser range finder scene and location found by a modified dead reckoning system. Finally a motion control method is presented. These approaches are implemented and tested in Resquake mobile robot",https://ieeexplore.ieee.org/document/1631674/,"9th IEEE International Workshop on Advanced Motion Control, 2006.",27-29 March 2006,ieeexplore
10.1109/ICARM49381.2020.9195341,Model-Based Reinforcement Learning For Robot Control,IEEE,Conferences,"Model-free deep reinforcement learning (MFRL) algorithms have achieved many impressive results. But they are generally stricken with high sample complexity, which puts forward a critical challenge for their application to real-world robots. Dynamic models are essential for robot control laws, but it is often hard to obtain accurate analytical dynamic models. Therefore a data-driven approach to learning models becomes significant for reinforcement learning to increase data efficiency. Model-based algorithms are effective methods to reduce sample complexity by learning the system dynamic model. However, in certain environments, it has been proven that learning an accurate system dynamic model is a formidable problem, and their asymptotic performance cannot achieve to the same level as model-free algorithms. In our work, we use an ensemble of deep neural networks to learn system dynamics and incorporate model uncertainty. Then in order to merge the high asymptotic performance of the advanced model-free methods, the deep deterministic policy gradient (DDPG) algorithm is adopted to optimize robot control policy. Furthermore, it has been implemented within ROS for controlling a Baxter robot in the simulation environment.",https://ieeexplore.ieee.org/document/9195341/,2020 5th International Conference on Advanced Robotics and Mechatronics (ICARM),18-21 Dec. 2020,ieeexplore
10.1109/ICARM.2019.8834284,Motion Control of Non-Holonomic Constrained Mobile Robot Using Deep Reinforcement Learning,IEEE,Conferences,"For the motion control problem of non-holonomic constrained mobile robots, a point stabilization kinematic control law for mobile robot based on deep reinforcement learning is proposed. Firstly, a kinematic model of mobile robot is constructed to build memory for deep reinforcement learning, including the current state of the robot, the control action, the reward and the next state of the robot, which is generated through the connection between mobile robot and environment. Then, value network parameters in the real-time network are updated by a loss function, which is composed of a state-action value in current moment came from the value network of real-time network and a target value, the state-action value of next moment generated by the value network in target network. Next, the parameters of policy network of real-time network are updated according to the state-action value generated by value network of the real-time network in current moment. Finally, the parameters in the real-time network are weighted and averaged with the parameters in the target network, so the parameters of target network are updated to control mobile robot to stabilize with desired point. The simulation and experiment results show that the control algorithm based on deep reinforcement learning could effectively realize the point stabilization control of nonholonomic mobile robots.",https://ieeexplore.ieee.org/document/8834284/,2019 IEEE 4th International Conference on Advanced Robotics and Mechatronics (ICARM),3-5 July 2019,ieeexplore
10.1109/IROS.2005.1545310,"Motion control of two-link flexible-joint robot with actuator nonlinearities, using backstepping and neural networks",IEEE,Conferences,"We present a state-feedback control of a two-link flexible-joint robot. The control algorithm does not require the mathematical model representing the robot. Three-layer neural networks approximate the unknown plant functions. The neural network weights are adapted on-line. We use backstepping control structure. We use variable structure control to provide robustness to all uncertainties. For simulation, we obtain parameter values of the Euler-Lagrange model from real experiment. We, then, add backlash, deadzone, and additive disturbances to the Euler-Lagrange model to closely replicate the actual robot. We show through simulation that our controller can handle these actuator nonlinearities effectively.",https://ieeexplore.ieee.org/document/1545310/,2005 IEEE/RSJ International Conference on Intelligent Robots and Systems,2-6 Aug. 2005,ieeexplore
10.1109/ICAR.2013.6766513,Move and the robot will learn: Vision-based autonomous learning of object models,IEEE,Conferences,"As robots are increasingly deployed in complex real-world domains, visual object recognition continues to be an open problem. Existing algorithms for learning and recognizing objects are predominantly computationally expensive, and require considerable training or domain knowledge. Our algorithm enables robots to use motion cues to identify and focus on a set of interesting objects, automatically extracting appearance-based and contextual cues from a small number of images to efficiently learn representative models of these objects. Learned models exploit complementary strengths of: (a) relative spatial arrangement of gradient features; (b) graph-based models of neighborhoods of gradient features; (c) parts-based models of image segments; (d) color distributions; and (e) mixture models of local context. The learned models are used in conjunction with an energy minimization algorithm and a generative model of information fusion for reliable and efficient recognition in novel scenes. The algorithm is evaluated on mobile robots in indoor and outdoor domains, and on images from benchmark datasets.",https://ieeexplore.ieee.org/document/6766513/,2013 16th International Conference on Advanced Robotics (ICAR),25-29 Nov. 2013,ieeexplore
10.1109/SSCI.2016.7850240,Multi-Channel Bayesian ART for robot fusion perception,IEEE,Conferences,"Multiple sensor data fusion is the technique of associate information from a number of different sensors to produce a robust and comprehensive description. Data fusion pose is using in various robotics application such as environment mapping, object recognition and robot localization. Their relation is generally hard coded and difficult to learn incrementally if new objects or events arise. In this paper, we propose a new learning architecture termed as Multi-Channel Bayesian ART which is very flexible can be adapted to new domains or different sensor configurations easily. The other advantages of the proposed method are: (1) it is capable of incremental on-line learning without forgetting previously-learned knowledge (2) It can process data real time and does not require any prior training to make it work in natural environment. The effectiveness of our proposed method is validated by real experimental results implemented on robot.",https://ieeexplore.ieee.org/document/7850240/,2016 IEEE Symposium Series on Computational Intelligence (SSCI),6-9 Dec. 2016,ieeexplore
10.1109/ICTAI50040.2020.00088,Multi-Robot Collision Avoidance with Map-based Deep Reinforcement Learning,IEEE,Conferences,"Multi-robot collision avoidance in a communication-free environment is one of the key issues for mobile robotics and autonomous driving. In this paper, we propose a map-based deep reinforcement learning (DRL) approach for collision avoidance of multiple robots, where robots do not communicate with each other and only sense other robots' positions and the obstacles around them. We use the egocentric grid map of a robot to represent the environmental information around it, which can be easily generated by using multiple sensors or sensor fusion. The learned policy generated from the DRL model directly maps 3 frames of egocentric grid maps and the robot's relative local goal positions into low-level robot control commands. We first train a convolutional neural network for the navigation policy in a simulator of multiple mobile robots using proximal policy optimization (PPO). Then we deploy the trained model to real robots to perform collision avoidance in their navigation. We evaluate the approach with various scenarios both in the simulator and on three differential-drive mobile robots in the real world. Both qualitative and quantitative experiments show that our approach is efficient with a high success rate. The demonstration video can be found at https://youtu.be/jcLKlEXuFuk.",https://ieeexplore.ieee.org/document/9288300/,2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI),9-11 Nov. 2020,ieeexplore
10.1109/ICCNC.2019.8685667,Multi-Robot Enhanced Intelligent Multi-User Millimeter-Wave MIMO Systems under Uncertain Environment,IEEE,Conferences,"This paper investigates how to maximize the practical communication quality of multi-user millimeter-wave (mmWave) MIMO systems with uncertain environment through effectively using the mobility from multi-robots as dynamic relays and adopting machine learning techniques. mmWave MIMO has been considered as a promising wireless communication technology due to the high frequency usage efficiency from beamforming. However, the uncertain environment could seriously affect the effectiveness and practicality of beamforming since wireless channels may have a more complicated structure, and the coordination among multiple nodes could be more difficult. For instance, the uncertain distribution of mobile users could significantly affect the performance of wireless channels, and then significantly degrade practical communication quality. Therefore, this paper presents a novel Multi-Robot Enhanced Intelligent Multi-User Millimeter-Wave MIMO (MREI-MU-MIMO) system that adopt both dynamic codebook based beam training protocol and online reinforcement learning to supervise the mobility of multi-robot-relay as well as handle the serious effects form the uncertain environment. Firstly, a novel dynamic codebook development is presented that cannot only lower the complexity of existing beamforming codebooks and also handle the complicated channel structure under uncertainty during multi-user beam training. Then, a decentralized Deep Q-Network (DQN) rein-forcement learning algorithm has been developed to intelligently manage multi-robot mobility and further effectively assign the optimal MIMO to handle the uncertainty from environment. The effectiveness of the proposed design has been demonstrated through real-time simulation and experiment.",https://ieeexplore.ieee.org/document/8685667/,"2019 International Conference on Computing, Networking and Communications (ICNC)",18-21 Feb. 2019,ieeexplore
10.1109/INFOCOM42981.2021.9488669,Multi-Robot Path Planning for Mobile Sensing through Deep Reinforcement Learning,IEEE,Conferences,"Mobile sensing is an effective way to collect environmental data such as air quality, humidity and temperature at low costs. However, mobile robots are typically battery powered and have limited travel distances. To accelerate data collection in large geographical areas, it is beneficial to deploy multiple robots to perform tasks in parallel. In this paper, we investigate the Multi-Robot Informative Path Planning (MIPP) problem, namely, to plan the most informative paths in a target area subject to the budget constraints of multiple robots. We develop two deep reinforcement learning (RL) based cooperative strategies: independent learning through credit assignment and sequential rollout based learning for MIPP. Both strategies are highly scalable with the number of robots. Extensive experiments are conducted to evaluate the performance of the proposed and baseline approaches using real-world WiFi Received Signal Strength (RSS) data. In most cases, the RL based solutions achieve superior or similar performance as a baseline genetic algorithm (GA)-based solution but at only a fraction of running time during inference. Furthermore, when the budgets and initial positions of the robots change, the pre-trained policies can be applied directly.",https://ieeexplore.ieee.org/document/9488669/,IEEE INFOCOM 2021 - IEEE Conference on Computer Communications,10-13 May 2021,ieeexplore
10.1109/HUMANOIDS.2018.8624918,Multi-Sensor Fusion Based Robot Self-Activity Recognition,IEEE,Conferences,"Robots play more and more important roles in our daily life. To better complete assigned tasks, it is necessary for the robots to have the ability to recognize their self-activities in real time. To perceive the environment, robots usually equipped with rich sensors, which can be used to recognize their self-activities. However, the intrinsics of the sensors such as accelerometer, servomotor and gyroscope may have significant differences, individual sensor usually exhibits weak performance in perceiving the environment. Therefore, multi-sensor fusion becomes a promising technique so that to achieve better performance. In this paper, facing the issue of robot self-activity recognition, we propose a framework to fuse information from multiple sensory streams. Our framework takes Recurrent Neural Network(RNN) that uses Long Short-Term Memory(LSTM) units to model temporal information conveyed in multiple sensory streams. In the architecture, a hierarchy structure is used to learn the sensor-specific features, a shared layer is used to fuse the features extracted from multiple sensory streams. We collect a dataset on PKU-HR6.0 robot to evaluate the proposed framework. The experiment results demonstrate the effectiveness of the proposed framework.",https://ieeexplore.ieee.org/document/8624918/,2018 IEEE-RAS 18th International Conference on Humanoid Robots (Humanoids),6-9 Nov. 2018,ieeexplore
10.1109/FUZZ.2002.1005041,Multi-axis fuzzy control and performance analysis for an industrial robot,IEEE,Conferences,"Robot control systems can be considered as complex systems, the design of the controller involving the determination of the dynamic model for the system. Fuzzy logic provides functional capability without the use of a system model or the characteristics associated with capturing the approximate, varying values found in real world systems. Development of a multi-axis fuzzy logic control system was implemented on an industrial robot, replacing the existing control and hardware systems with a new developmental system. During robot control no adaptation of the rule base or membership functions was carried out online; only system gain was modified in relation to link speed and joint error within predetermined design parameters. The fuzzy control system had to manage the effects of frictional and gravitational forces whilst compensating for the varying inertia components when each linkage is moving. Testing based on ISO 9283 for path accuracy and repeatability verified that real time control of three axes was achievable with values of 938 /spl mu/m and 864 /spl mu/m recorded for accuracy and repeatability, respectively.",https://ieeexplore.ieee.org/document/1005041/,2002 IEEE World Congress on Computational Intelligence. 2002 IEEE International Conference on Fuzzy Systems. FUZZ-IEEE'02. Proceedings (Cat. No.02CH37291),12-17 May 2002,ieeexplore
10.1109/IROS.2015.7354094,Multi-robot 6D graph SLAM connecting decoupled local reference filters,IEEE,Conferences,"Teams of mobile robots can be deployed in search and rescue missions to explore previously unknown environments. Methods for joint localization and mapping constitute the basis for (semi-)autonomous cooperative action, in particular when navigating in GPS-denied areas. As communication losses may occur, a decentralized solution is required. With these challenges in mind, we designed a submap-based SLAM system that relies on inertial measurements and stereo-vision to create multi-robot dense 3D maps. For online pose and map estimation, we integrate the results of keyframe-based local reference filters through incremental graph SLAM. To the best of our knowledge, we are the first to combine these two methods to benefit from their particular advantages for 6D multi-robot localization and mapping: Local reference filters on each robot provide real-time, long-term stable state estimates that are required for stabilization, control and fast obstacle avoidance, whereas online graph optimization provides global multi-robot pose and map estimates needed for cooperative planning. We propose a novel graph topology for a decoupled integration of local filter estimates from multiple robots into a SLAM graph according to the filters' uncertainty estimates and independence assumptions and evaluated its benefits on two different robots in indoor, outdoor and mixed scenarios. Further, we performed two extended experiments in a multi-robot setup to evaluate the full SLAM system, including visual robot detections and submap matches as inter-robot loop closure constraints.",https://ieeexplore.ieee.org/document/7354094/,2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),28 Sept.-2 Oct. 2015,ieeexplore
10.1109/FUZZY.1997.616431,Multilayered fuzzy behavior fusion for reactive control of an autonomous mobile robot,IEEE,Conferences,"Fuzzy linguistic rules provide an intuitive and powerful means for defining control behavior. Most applications that use fuzzy control feature a single layer of fuzzy inference, mapping a function from one or two inputs to equally few outputs. Highly complex systems, however, may benefit from qualitative rules as well if the control task is properly partitioned. This paper presents a modular fuzzy control architecture and inference engine. A control function is broken down into multiple agents, each of which samples a subset of a large sensor input space. Additional fuzzy agents are employed to fuse the recommendations of the local agents. Real-time implementation without special hardware is possible by using singleton output values during fuzzy rule evaluation. Using this system, a fuzzy behavior-based reactive control system has been implemented on an autonomous mobile robot MARGE, with great success.",https://ieeexplore.ieee.org/document/616431/,Proceedings of 6th International Fuzzy Systems Conference,5-5 July 1997,ieeexplore
10.1109/ISKE.2010.5680764,Multilevel fuzzy navigation control scheme applied to a monitoring mobile robot,IEEE,Conferences,"The design, construction and real time performance of a mobile monitoring system based on a Khepera mobile robot are presented. The functions performed by the system are: (a) line following, (b) obstacle avoidance, (c) identification of test points along the path, (d) recognition of the mark (bar code) located at each test point and, (e) measuring of a physical parameter. For the navigation, an innovative multilevel fuzzy control scheme is implemented in which the fuzzy sensor fusion, related to the perception of the environment, reduces the complexity of the navigation function. Other distinctive characteristics are the identification of test points by means of a Kohonen's neural network and the processing of a one-dimensional video signal for recognition of landmarks located at each test point.",https://ieeexplore.ieee.org/document/5680764/,2010 IEEE International Conference on Intelligent Systems and Knowledge Engineering,15-16 Nov. 2010,ieeexplore
10.1109/ROMAN.1995.531939,Multimedia sensing system for robot,IEEE,Conferences,"The purpose of this study is to realize a multimedia sensing system for robot. Using both image and sound processing, the system makes a robot track the person who is speaking. The sound direction is calculated from the phase difference between the sounds arriving at the right and left microphones (ears) of the robot. Then by detecting the synchronization between the sound and image changes, the system identifies the speaker. Furthermore, by introducing a multi-level synchronization checking and context analysis, the action pattern of the robot can be regulated to make the robot perform in a complicated environment with plural speakers. All the processes are performed in real-time. The proposed system is implemented in the information assistant robot ""Hadaly"".",https://ieeexplore.ieee.org/document/531939/,Proceedings 4th IEEE International Workshop on Robot and Human Communication,5-7 July 1995,ieeexplore
10.1109/CEC.2007.4424774,Multiple sensors data integration using MFAM for mobile robot navigation,IEEE,Conferences,"The mobile robot navigation with complex environment needs more input space to match the environmental data into robot outputs in order to perform realistic task. At the same time, the number of rules at the rule base needs to be optimized to reduce the computing time and to provide the possibilities for real time operation. In this paper, the optimization of fuzzy rules using a modified fuzzy associative memory (MFAM) is designed and implemented. MFAM provides good flexibility to use multiple input space and reduction of rule base for robot navigation. This paper presents the MFAM model to generate the rule base for robot navigation. The behavior rules obtained from MFAM model are tested using simulation and real world experiments, and the results are discussed in the paper and compared with the existing methods.",https://ieeexplore.ieee.org/document/4424774/,2007 IEEE Congress on Evolutionary Computation,25-28 Sept. 2007,ieeexplore
10.1109/IROS.2018.8593899,Multisensor Online Transfer Learning for 3D LiDAR-Based Human Detection with a Mobile Robot,IEEE,Conferences,"Human detection and tracking is an essential task for service robots, where the combined use of multiple sensors has potential advantages that are yet to be fully exploited. In this paper, we introduce a framework allowing a robot to learn a new 3D LiDAR-based human classifier from other sensors over time, taking advantage of a multisensor tracking system. The main innovation is the use of different detectors for existing sensors (i.e. RGB-D camera, 2D LiDAR) to train, online, a new 3D LiDAR-based human classifier based on a new “trajectory probability”. Our framework uses this probability to check whether new detection belongs to a human trajectory, estimated by different sensors and/or detectors, and to learn a human classifier in a semi-supervised fashion. The framework has been implemented and tested on a real-world dataset collected by a mobile robot. We present experiments illustrating that our system is able to effectively learn from different sensors and from the environment, and that the performance of the 3D LiDAR-based human classification improves with the number of sensors/detectors used.",https://ieeexplore.ieee.org/document/8593899/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ICMLC.2016.7872960,Muscle-gesture robot hand control based on sEMG signals with wavelet transform features and neural network classifier,IEEE,Conferences,"In this paper, we propose a muscle gesture-computer interface (MGCI) system for a five-fingered robotic hand control employing a commercial wearable MYO gesture armband. Eight channels of surface EMG (sEMG) signals were acquired and segmented. Then four levels of Daubechies 5 Wavelet family were performed to analyze the EMG signal. Totally 72 features were extracted from the EMG raw data for 16 hand motions recognition utilizing artificial Neural Networks. The average of best overall classification rate during off-line training is 87.8%. Consequently, real-time hand gesture recognition was implemented to evaluate the performance of the proposed system and the average recognition accuracy was 89.38%. Finally, it was applied to control a five-fingered robot hand.",https://ieeexplore.ieee.org/document/7872960/,2016 International Conference on Machine Learning and Cybernetics (ICMLC),10-13 July 2016,ieeexplore
10.1109/IECON.2000.972604,NN controller of the constrained robot under unknown constraint,IEEE,Conferences,"In this paper, the problems faced in the constrained force control is studied (uncertainties in dynamic model and the unknown constraints). A neural network (NN) controller is proposed based on the derived dynamic model of robot in the task space. The feed-forward neural network is used to adaptively compensate for the uncertainties in the robot dynamics. Training signals are proposed for the feed-forward neural network controller. The NN weights are tuned online, with no off-line learning phase required. An online estimation algorithm is developed to estimate the local shape of the constraint surface by using measured data on the force and position of the end-effector. The suggested controller is simple in structure and can be implemented easily. Real-time experiments are conducted using the five-bar robot to demonstrate the effectiveness of the proposed controller.",https://ieeexplore.ieee.org/document/972604/,"2000 26th Annual Conference of the IEEE Industrial Electronics Society. IECON 2000. 2000 IEEE International Conference on Industrial Electronics, Control and Instrumentation. 21st Century Technologies",22-28 Oct. 2000,ieeexplore
10.1109/ICMA52036.2021.9512587,Natural Residual Reinforcement Learning for Bicycle Robot Control,IEEE,Conferences,"This work focuses on motion control of the bicycle robot by using the proposed NRRL algorithm. Unlike the traditional RL algorithm, decomposing the main tasks into subtasks manually and introducing qualitative prior knowledge to the agent have been applied in the NRRL algorithm. Simulation results show that better performance and better sample efficiency of the proposed NRRL algorithm have been achieved in terms of balance control and path tracking of bicycle robot. It's believed that the NRRL algorithm is available on the real physical bicycle robot, and the deployment of the algorithm will be realized soon, as the real physical bicycle robot has been constructed currently.",https://ieeexplore.ieee.org/document/9512587/,2021 IEEE International Conference on Mechatronics and Automation (ICMA),8-11 Aug. 2021,ieeexplore
10.1109/ICNSC.2009.4919323,Navigation and path search for roving robot using reinforcement learning,IEEE,Conferences,"The robot technology is rapidly developing in recent years. In connection with this technology, a robot activity is expected in various places or various environments. Therefore, this study describes 1) how the location of the destination of the robot in real world is measured based on the image obtained by one camera and 2) how the robot is navigated to the destination where a user points out on the display, on which the forward scene is imaged. The cases where there are some obstacles on the way to the destination are considered. The roving robot tries to find the shortest way to the destination based on the information on the locations of the obstacles and the destination by using the reinforcement learning, which is a hopeful candidate in the autonomous control technique. In addition, the measurement method for the indicated location based on the image is described, the simulation result for the path search by using the reinforcement leaning is shown, and the experiment result of navigation in real field is shown. Finally, the main conclusions are summarized.",https://ieeexplore.ieee.org/document/4919323/,"2009 International Conference on Networking, Sensing and Control",26-29 March 2009,ieeexplore
10.1109/ICEE.2018.8472657,Neural Control of Mobile Robot Motion Based on Feedback Error Learning and Mimetic Structure,IEEE,Conferences,"Mobile robots motion control is a basic problem in robotics and there are still some control difficulties such as uncertainty in a real implementation which should be considered. This paper is concerned with the neural control of wheeled mobile robots trajectory tracking and posture stabilization. In the trajectory-tracking problem, the Feedback Error Learning (FEL) structure is used and for the posture stabilization problem, the Mimetic structure is employed. These neural based structures use a classic controller, Dynamic Feedback Linearization (DFL), and help to improve the adaptiveness of it. The effectiveness of the proposed controllers is verified by simulation in Webots robotic simulator and on the e-puck which is a differential wheeled mobile robot. The simulation results verify the ability of the proposed methods for controlling the robot and handling uncertainties.",https://ieeexplore.ieee.org/document/8472657/,"Electrical Engineering (ICEE), Iranian Conference on",8-10 May 2018,ieeexplore
10.1109/CIMCA.2008.133,Neural Dynamic Control of a Nonholonomic Mobile Robot Incorporating the Actuator Dynamics,IEEE,Conferences,"In this paper, a trajectory tracking control for a nonholonomic mobile robot by the integration of a kinematic controller and neural dynamic controller is investigated, where the wheel actuator (e.g., dc motor) dynamics is integrated with mobile robot dynamics and kinematics so that the actuator input voltages are the control inputs. The proposed neural dynamic controller (PNDC), based on the sliding mode theory, is applied to compensate the mobile robot dynamics, bounded unknown disturbances, and influence of payload. This controller is obtained by modeling the Radial Basis Functions Neural Networks (RBFNNs) of the centripetal and Coriolis matrix through of the inertia matrix of the mobile robot dynamics. Thus, PNDC is constituted of static RBFNNs only, what makes possible the reduction of the size of the RBFNNs, of the computational load and the implementation in real time. Stability analysis and numerical simulations are provided to show the effectiveness of the PNDC.",https://ieeexplore.ieee.org/document/5172687/,2008 International Conference on Computational Intelligence for Modelling Control & Automation,10-12 Dec. 2008,ieeexplore
10.1109/AIM.2009.5229901,Neural Q-Learning controller for mobile robot,IEEE,Conferences,"In recent years, increasing trend in application of autonomous mobile robot worldwide has highlighted the importance of path planning controller in robotics-related fields, especially where dynamic and unknown environment is involved. Writing a good robot controller program can be a very time consuming process. It is inevitably wasting of resources and efforts if we have to rewrite the controller over and over again whenever there is emergence of changes in the environment. Reinforcement Learning (RL) algorithms and Artificial Neural Network (ANN) are used to assist autonomous mobile robot to learn in an unrecognized environment. This research study is focused on exploring integration of multi-layer neural network and Q-Learning as an online learning controller. Learning process is divided into two stages. In the initial stage the agent will map the environment through collecting state-action information according to the Q-Learning procedure. Second training process involves neural network training which will utilize the state-action information gathered in earlier phase as training samples. During final application of the controller, Q-Learning would be used as the primary navigating tool whereas the trained neural network will be employed when approximation is needed. MATLAB simulation was developed to verify the validity of the algorithm before it is real-time implemented on the real world using Team AmigoBottrade robot. The results obtained from both simulation and actual application confirmed on-spot learning ability of the controller accompanied with certain degree of flexibility and robustness.",https://ieeexplore.ieee.org/document/5229901/,2009 IEEE/ASME International Conference on Advanced Intelligent Mechatronics,14-17 July 2009,ieeexplore
10.1109/IROS.1991.174585,Neural network approach to path planning for two dimensional robot motion,IEEE,Conferences,"A method for robot obstacle avoidance and path planning is proposed. The algorithm is based on a camera image feedback loop utilizing a neural network for image processing. The method can successfully generate collision-free paths in a 2D robot workspace containing randomly-placed polygonal obstacles. The control algorithm is simple and robust and has low computational requirements. Controller simulation implemented on a personal computer can generate collision-free robot paths in real time, requiring approximately 1 sec. per robot move.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174585/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/ROBOT.1995.525344,Neural network based iterative learning controller for robot manipulators,IEEE,Conferences,"An efficient neural network based learning control scheme is proposed to solve the trajectory tracking controI problem of robot manipulators. The proposed approach has four distinctive characteristics: 1) good tracking performance can be achieved during the first learning trial; 2) learning algorithm for adjusting neural network weights is independent of the manipulator dynamic model, thus displays strong robustness to torque disturbances and model parameter uncertainty; 3) no acceleration measurement or estimation is needed; and 4) real-time implementation with a higher sampling rate is readily possible. Simulation results on a 3 degree-of-freedom manipulator are presented to show its validity.",https://ieeexplore.ieee.org/document/525344/,Proceedings of 1995 IEEE International Conference on Robotics and Automation,21-27 May 1995,ieeexplore
10.1109/COASE.2008.4626446,Neural network based path planning for a multi-robot system with moving obstacles,IEEE,Conferences,"Recently, a coordinated hybrid agent (CHA) framework was proposed for the control of multi-agent systems (MASs). In the past few years, it has been applied to both homogeneous and heterogeneous multi-agent systems. In previous studies, the coordination among agents were implemented based on the designerpsilas knowledge of the system. For large complex systems, it would be desirable if we can plan the coordination among agents dynamically. It was demonstrated that an intelligent planner can be designed for the CHA framework to automatically generate desired actions for multiple robots in a multi-agent system. However, in previous studies, only static obstacles in the environment were considered. In this paper, a neural network based approach is proposed for a multi-robot system with moving obstacles. A biologically inspired neural network based intelligent planner is designed for the coordination of multi-agent systems. The dynamics of each neuron in the topologically organized neural network is characterized by a shunting neural equation. A landscape of the neural activities for all neurons of a CHA agent contains information about the agentpsilas local goal, and moving obstacles. The objective for building the intelligent planner is to plan actions for multiple mobile robots to coordinate with others and to achieve the global goal. The proposed approach is able to plan the paths for multiple robots while avoiding moving obstacles. The proposed approach is simulated using both Matlab and Vortex. The virtual physical world is built using Vortex to test and develop navigation strategies for robot platforms. The Vortex module executes control commands from the control system module, and provides the outputs describing the vehicle state and terrain information, which are in turn used in the control module to produce the control commands. Simulation results show that an intelligent planner can be designed for the CHA framework to control a large complex system so that coordination among agents can be achieved.",https://ieeexplore.ieee.org/document/4626446/,2008 IEEE International Conference on Automation Science and Engineering,23-26 Aug. 2008,ieeexplore
10.1109/ISESD.2016.7886710,Neural network implementation for invers kinematic model of arm drawing robot,IEEE,Conferences,"Nowadays, the research in robotics field is growing. One of the studies in robotics is the control method of the robotic arm movement. In this research, a 3 DOF arm drawing robot was built. An inverse kinematic models of the robot arm is made using artificial neural network method. Artificial neural network model was implemented in a GUI application. The ANN model can work in real-time to control arm robot movement to reach certain coordinates. Based on test results, the inverse kinematic models of the arm drawing robot had an error rate under 2%. It is of 0.16% for X coordinate and 0.46% for Y coordinate.",https://ieeexplore.ieee.org/document/7886710/,2016 International Symposium on Electronics and Smart Devices (ISESD),29-30 Nov. 2016,ieeexplore
10.1109/IJCNN.1991.170673,Neural network servo control of a robot manipulator joint in real-time,IEEE,Conferences,"Empirical results are presented for a real-time experiment where a feedforward neural network is used to replace an existing proportional-derivative (P-D) servo controller and trained online in real-time using a performance measure to control positioning of a robot manipulator joint. The optimized neural network controller was tested online as both a fixed and adaptive controller, with step and ramp input commands, under different joint loading conditions. The results are compared to the existing P-D controller.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/170673/,[Proceedings] 1991 IEEE International Joint Conference on Neural Networks,18-21 Nov. 1991,ieeexplore
10.1109/IROS.2003.1250614,Non-learning artificial neural network approach to motion planning for the Pioneer robot,IEEE,Conferences,This paper describes the implementation of a biologically-inspired non-learning artificial neural network for robot motion planning on the Pioneer 2DX robot. This motion planner fits within the Saphira operating system. The deliberative ANN motion planner is able to respond to changing situations in real time and complements the reactive behaviours.,https://ieeexplore.ieee.org/document/1250614/,Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453),27-31 Oct. 2003,ieeexplore
10.1109/ICCIS.2017.8274769,Object detection and recognition of intelligent service robot based on deep learning,IEEE,Conferences,"Object detection and recognition is the premise and foundation for intelligent service robot to understand the surrounding environment and make intelligent decisions. In this paper, aiming at the accuracy and real-time performance of object detection and recognition of service robot in complex scenes, an end to end object detection and recognition algorithm based on deep learning is proposed. Firstly, the local multi branch deep convolution neural network is adopted to enhance the feature representation capability of the model by enhancing the convolution module function. Then, combining the anchor point mechanism, the object class and position regression prediction is carried out on the multi-layer feature map. When the local features and the global features are fully fused, the natural multi-scale detection and recognition is realized on multiple receptive fields. Finally, a network acceleration module is designed for GPU parallel acceleration on high performance NVIDIA TX1 embedded board. The experiment was carried out on SIASUN second generation intelligent service robot. The experimental results show that the algorithm has both good accuracy and real-time performance.",https://ieeexplore.ieee.org/document/8274769/,"2017 IEEE International Conference on Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics, Automation and Mechatronics (RAM)",19-21 Nov. 2017,ieeexplore
10.1109/ICIEAM.2019.8742984,Objects Geometry Comparative Analysis Method for Industrial Robot Vision System,IEEE,Conferences,"At present, in computer vision systems, neural networks are used to process information received by the system from cameras. The recognition of all objects on the image is an extremely resource-intensive task, the solution of which consumes most of the computing power. For that reason, systems based on neural networks cannot be fully utilized for real-time systems due to limited computing resources. To build real-time computer vision systems, the authors suggested using the contour comparison method. The method allows to supervise the geometry of objects, conduct presorting and screen out defective parts, thereby the pressure on neural networks will reduce. The method is implemented in the Java. The created software performs image processing and objects search on it, that are the most similar to the template. The results of the experiment showed that the desired object is correctly determined on a noisy image and the proposed method can be used to solve the problem of pattern recognition in technical vision systems.",https://ieeexplore.ieee.org/document/8742984/,"2019 International Conference on Industrial Engineering, Applications and Manufacturing (ICIEAM)",25-29 March 2019,ieeexplore
10.1109/IECON.2006.347441,Obstacle avoidance algorithm based on biological patterns for anthropomorphic robot manipulator,IEEE,Conferences,"This study addresses the problem of collision-free controlling of 3-DOF (degree of freedom) anthropomorphic manipulators with given a priori unrestricted trajectory. The robot constraints resulting from the physical robot's actuators are also taken into account during the robot movement. Obstacle avoidance algorithm is based on penalty function, which is minimized when collision is predicted. Mathematical construction of penalty function and minimization process allows modeling of variety behaviors of robot elusion moves. Implementation of artificial neural network (ANN) inside the control process gives the additional flexibility needed to remember most important robot behaviors based on biological pattern of human arm moves. Thanks to the fast collisions' detection, the presented algorithm appears to be applicable to the industrial real-time implementations. Numerical simulations of the anthropomorphic manipulator operating in three dimensional space with obstacles is also presented",https://ieeexplore.ieee.org/document/4152937/,IECON 2006 - 32nd Annual Conference on IEEE Industrial Electronics,6-10 Nov. 2006,ieeexplore
10.1109/ICRA48506.2021.9561790,Occupancy Map Inpainting for Online Robot Navigation,IEEE,Conferences,"In this work, we focus on mobile robot navigation in indoor environments where occlusions and field-of-view limitations hinder onboard sensing capabilities. We show that the footprint of a camera mounted on a robot can be drastically improved using learning-based approaches. Specifically, we consider the task of building an occupancy map for autonomous navigation of a robot equipped with a depth camera. In our approach, a local occupancy map is first computed using measurements from the camera directly. Afterwards, an inpainting network adds further information, the occupancy probabilities of unseen grid cells, to the map. A novel aspect of our approach is that rather than direct supervision from ground truth, we combine the information from a second camera with a better field-of-view for supervision. The training focuses on predicting extensions of the sensed data. To test the effectiveness of our approach, we use a robot setup with a single camera placed at 0.5m above the ground. We compare the navigation performance using raw maps from only this camera’s input (baseline) versus using inpainted maps augmented with our network. Our method outperforms the baseline approach even in completely new environments not included in the training set and can yield 21% shorter paths than the baseline approach. A real-time implementation of our method on a mobile robot is also tested in home and office environments.",https://ieeexplore.ieee.org/document/9561790/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICRA.2013.6630740,Off-line path integral reinforcement learning using stochastic robot dynamics approximated by sparse pseudo-input Gaussian processes: Application to humanoid robot motor learning in the real environment,IEEE,Conferences,"We develop fast reinforcement learning (RL) framework using the approximated dynamics of a humanoid robot. Although RL is a useful non-linear optimizer, applying it to real robotic systems is usually difficult due to the large number of iterations required to acquire suitable policies. In this study, we approximate the dynamics using data from a real robot with sparse pseudo-input Gaussian processes (SPGPs). By using SPGPs, we estimated the probability distribution considering both the input vector and output signal variances. In real environments, since the observations from robotic sensors include large noise, SPGPs can suitably approximate the stochastic dynamics of a real humanoid robot. We use the approximated dynamics to improve the performance of a movement task in a path integral RL framework, which updates a policy from the sampled trajectories of the state and action vectors and the cost. We implemented our proposed method on a real humanoid robot and tested on a via-point reaching task. The robot achieved successful performance with fewer number of interactions with the real environment by using the proposed method than a conventional approach which dose not use the simulated dynamics.",https://ieeexplore.ieee.org/document/6630740/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/ROBIO.2013.6739747,Omnidirectional vision based mobile robot topological localization,IEEE,Conferences,"A robust omni-directional vision based localization method that allows us to obtain accurate mobile robot pose of large indoor environments is proposed. To implement the localization based on vision. In a learning step, the robot is manually guided on a path and an omni-directional image frames sequence is recorded. From this sequence a topological map is built with robust affine and scale invariant features extraction and matching algorithm. Each topological node represented by a set of panoramic images described with affine and scale invariant features. In the on-line localization stage, the robot localizes itself to the most likely node through robust Monte Carlo localization algorithm, and ambiguous robot pose estimation is resolved by this high probability distribution method. This enables the system to deal with perceptual aliasing or absence of reliable observation data. Experiment results carried out with a real robot in an indoor environment show the performance of the proposed method.",https://ieeexplore.ieee.org/document/6739747/,2013 IEEE International Conference on Robotics and Biomimetics (ROBIO),12-14 Dec. 2013,ieeexplore
10.1109/URAI.2018.8441890,On Humanoid Co-Robot Locomotion when Mechanically Coupled to a Human Partner,IEEE,Conferences,"This work focuses on the implementation of mechanically coupled tasks between a humanoid robot and a human. The latter focus comes from the push for robots to work with humans in everyday life as an overarching goal for the field. Co-robots, or robots that work alongside humans, may be guided by the humans through physical contact, such as the human grasping the robot's hand to gently guide it along a desired path. In this work the single-handed mechanically coupled task of guiding a robot through a course is implemented with four different methods of human input. These methods include: 1) using only force-torque sensors in the wrist of the robot for the control input from the human while the arm is under high-gain position control, creating a rigid coupling between the human and the robot, 2) using the force-torque sensors in the wrist of the robot for the control input while the arm is under low-gain position control with gravity compensation, creating compliant coupling between the human and the robot, 3) using the position of the end-effector of the robot for the control input while the arm is under low-gain position control with gravity compensation, and 4) using the force-torque sensors in the wrist and the position of the end-effector of the robot for the control input while the arm is under low-gain position control with gravity compensation. Tests are performed on the real-world and simulated adult-size humanoid robot DRC-Hubo++. During these tests the human and robot are walking together “hand in hand” with the human guiding the robot in a “figure eight” path. These tests show that having a compliant arm on the robot, when the human is guiding it via moving its end-effector, is beneficial over a rigid arm.",https://ieeexplore.ieee.org/document/8441890/,2018 15th International Conference on Ubiquitous Robots (UR),26-30 June 2018,ieeexplore
10.1109/ICAS.2006.40,On the conception of an autonomous and modular robot based on an Event Driven OSEK System with deterministic real-time behavior,IEEE,Conferences,"In this paper, we are interested in the design of an autonomous and modular self-reconfigurable robot having self-assembly capability and deterministic behavior. The ability of a modular robot to meet its mission strongly depends on the artificial intelligence software and on the underlying hardware and software architecture. The artificial intelligence software of a robot is mapped into several elementary tasks with different real-time constraints. We propose in this paper a real-time analysis taking into account kernel overheads for the validation of the real-time behavior of an artificial intelligence software. We study the OSEK operating system that requires few hardware resources and is cost effective. The overheads are due to the context switching mechanism which activates, terminates, and reschedules tasks, and to the periodic timer used to create the time base which is necessary for the periodic tasks model. We show how to take into account those overheads in the feasibility conditions. We compare the theoretical worst case response time obtained with kernel overheads to the response time obtained on a task set, on a real robot, based on the event driven OSEK implementation. We show that the kernel overheads cannot be neglected and that the theoretical results are valid and can be used to ensure a deterministic behavior of the robot",https://ieeexplore.ieee.org/document/1690225/,International Conference on Autonomic and Autonomous Systems (ICAS'06),19-21 July 2006,ieeexplore
10.1109/MWSCAS.1991.251981,On the fast robot dynamic parameters learning,IEEE,Conferences,"A computationally efficient solution to the problem of identifying the dynamic parameters of a robot manipulator is presented. The identification procedure is based on a simplified form of the dynamics. The approach has three important characteristics. First, being based on the Lagrangian representation, the equations are linear in the dynamic parameters, which makes possible the application of linear identification techniques. Second, the dynamic parameters are easily recognized, extracted, and grouped. Third, the equations are amenable to the implementation of parallel processing schemes. For the identification a recursive least squares algorithm is used. The algorithm is distributed over a network of transputers. Real-time results have been produced to demonstrate the speedup and efficiency of the proposed technique. A case study is given for the first three links of the Stanford Arm positioning system.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/251981/,[1991] Proceedings of the 34th Midwest Symposium on Circuits and Systems,14-17 May 1992,ieeexplore
10.1109/ICMA.2019.8816298,Online Learning of the Inverse Dynamics with Parallel Drifting Gaussian Processes: Implementation of an Approach for Feedforward Control of a Parallel Kinematic Industrial Robot,IEEE,Conferences,"The present paper deals with an online approach to learn the inverse dynamics of any robot. This is realized by the use of Gaussian Processes drifting parallel along the system data. An extension by a database enables the efficient use of data points from the past. The central component of this work is the implementation of such a method in a controller in order to achieve the actual goal: the feedforward control of an industrial robot by means of machine learning. This is done by splitting the procedure into two threads running parallel so that the prediction is decoupled from the computing-intensive training of the models. Experiments show that the method reduces the tracking errors more clearly than an elaborately identified rigid body model including friction. For a defined trajectory, the squared areas of the tracking errors of all axes are reduced by more than 54% compared to motion without pre-control. In addition, a highly dynamic pick-and-place experiment is used to investigate the possible changes in system dynamics. Compared to an offline trained model, the approximation error of the proposed online approach is smaller for the remaining time of the experiment after an initial phase. Furthermore, this error is smaller throughout the experiment for online learning with parallel drifting Gaussian Processes than when using a single one.",https://ieeexplore.ieee.org/document/8816298/,2019 IEEE International Conference on Mechatronics and Automation (ICMA),4-7 Aug. 2019,ieeexplore
10.1109/ICRA.2012.6224998,Online audio beat tracking for a dancing robot in the presence of ego-motion noise in a real environment,IEEE,Conferences,"This paper presents the design and implementation of a real-time real-world beat tracking system which runs on a dancing robot. The main problem of such a robot is that, while it is moving, ego noise is generated due to its motors, and this directly degrades the quality of the audio signal features used for beat tracking. Therefore, we propose to incorporate ego noise reduction as a pre-processing stage prior to our tempo induction and beat tracking system. The beat tracking algorithm is based on an online strategy of competing agents sequentially processing a continuous musical input, while considering parallel hypotheses regarding tempo and beats. This system is applied to a humanoid robot processing the audio from its embedded microphones on-the-fly, while performing simplistic dancing motions. A detailed and multi-criteria based evaluation of the system across different music genres and varying stationary/non-stationary noise conditions is presented. It shows improved performance and noise robustness, outperforming our conventional beat tracker (i.e., without ego noise suppression) by 15.2 points in tempo estimation and 15.0 points in beat-times prediction.",https://ieeexplore.ieee.org/document/6224998/,2012 IEEE International Conference on Robotics and Automation,14-18 May 2012,ieeexplore
10.1109/ICSMC.1998.726546,Online learning neural network controller for pneumatic robot position control,IEEE,Conferences,"This paper presents the implementation of online learning neural network controller in the pneumatic robot position servo control. The advantages of this design include: the ability to compensate for nonlinearities, and it is insensitive to system parameter time-varying. The traditional PID controller is replaced by neural network controller trained online to learn the inverse model of the pneumatic manipulator by backpropagation of the performance error. The simulation studies and experimental results on the PID controller, online learning neural network controller and off-line training neural network controller, are presented and discussed.",https://ieeexplore.ieee.org/document/726546/,"SMC'98 Conference Proceedings. 1998 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.98CH36218)",14-14 Oct. 1998,ieeexplore
10.1109/ICMA.2012.6285128,Online learning of COM trajectory for humanoid robot locomotion,IEEE,Conferences,"Center Of Mass (COM) trajectory is an essential factor for stable and natural robot locomotion. Unlike previous research in which COM trajectory either restricted by ZMP trajectory or directly predefined by simple function such as sinusoid, this research aims to establish the COM trajectory by online autonomous learning under the objective of locomotion stability and naturalness, which is expressed as a self-consistent measure in this paper. It provides an alternative that may avoid or weaken the mismatch between theoretical planning and practical implementation. The experimental results on a real humanoid robot PKU-HR4 show its effectiveness and promising future.",https://ieeexplore.ieee.org/document/6285128/,2012 IEEE International Conference on Mechatronics and Automation,5-8 Aug. 2012,ieeexplore
10.1109/CACS.2015.7378370,Optimal robot path planning system by using a neural network-based approach,IEEE,Conferences,"This paper proposes an optimal robot path planning system that can build map, plan optimal paths, and maneuver mobile robots. The system constructs a grid-based map by using information on the locations of the origin and static obstacles. The system calculates the optimal trajectory by using a simplified neural network model and accordingly maneuvers a mobile robot. For dynamic obstacles, the mobile robot can sense the ambient environment and avoid possible collisions. A practical experiment using an Arduino-based platform was conducted to illustrate the effectiveness of the proposed methodology.",https://ieeexplore.ieee.org/document/7378370/,2015 International Automatic Control Conference (CACS),18-20 Nov. 2015,ieeexplore
10.1109/UR49135.2020.9144838,Outdoor Robot Navigation System using Game-Based DQN and Augmented Reality,IEEE,Conferences,"This paper presents a deep reinforcement learning based robot outdoor navigation method using visual information. The deep q network (DQN) maps the visual data to robot action in a goal location reaching task. An advantage of the proposed method is that the implemented DQN is trained in the first-person shooter (FPS) game-based simulated environment provided by ViZDoom. The FPS simulated environment reduces the differences between the training and the real environments resulting in a good performance of trained DQNs. In our implementation a marker-based augmented reality algorithm with a simple object detection method is used to train the DQN. The proposed outdoor navigation system is tested in the simulation and real robot implementation, with no additional training. Experimental results showed that the navigation system trained inside the game-based simulation can guide the real robot in outdoor goal directed navigation tasks.",https://ieeexplore.ieee.org/document/9144838/,2020 17th International Conference on Ubiquitous Robots (UR),22-26 June 2020,ieeexplore
10.1109/ICMTMA.2009.402,Overall Inverse Kinematics Analysis of Parallel Robot Leg for Rescue Based on Rodrigues Parameters,IEEE,Conferences,"A new method to describe the position-stance of parallel robot leg was proposed based on the Rodrigues theory. Comparing with others methods, the kinematic model with Rodrigues parameters has the advantages including least computational parameters, no trigonometric function calculation and convenient real-time control. The model of the inverse kinematics was established and the inverse solutions of the position-stance were obtained by analyzing the topologic structure of the parallel robot leg with 3-RPS limb. According to the vectors of the manipulator, the velocity and acceleration models of moving platform, limbs and end-effector were deduced. By comparing with the normal walking gait of a human subject, the end-point trajectory of the parallel robot leg was better programmed. The experiment results showed the structure characteristics of the parallel robot leg and validated the model of the inverse kinematics. It was concluded that the parallel robot leg can fulfil the kinematic demand in the unconfigurable environment.",https://ieeexplore.ieee.org/document/5203157/,2009 International Conference on Measuring Technology and Mechatronics Automation,11-12 April 2009,ieeexplore
10.1109/ROBOT.1991.131722,Parallel robot motion planning,IEEE,Conferences,"A fast, parallel method for computing configuration space maps is presented. The method is made possible by recognizing that one can compute a family of primitive maps which can be combined by superposition based on the distribution of real obstacles. This motion planner has been implemented for the first three degrees-of-freedom of a Puma robot in *Lisp on a Connection Machine with 8 K processors. A six degree-of-freedom version of the algorithm which performs a sequential search of the six-dimensional configuration space, building three-dimensional cross sections in parallel, has also been implemented.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/131722/,Proceedings. 1991 IEEE International Conference on Robotics and Automation,9-11 April 1991,ieeexplore
10.1109/CDC.2006.377499,Path Generation Using Matrix Representations of Previous Robot State Data,IEEE,Conferences,"Humans learn by repetition and using past experiences. It is possible for robots to act in a similar fashion. By representing past path traversal experiences with matrices, a new path can be generated without relying on calculations of complex dynamics or control laws. This paper presents one approach for allowing robots to use past experience to generate new paths and control actions. This approach relies on using several matrices to associate each new input value with previous robot states. An example is provided and analyzed which shows a successful simulated implementation of this approach. In addition a real world test of the approach was conducted which demonstrates that the implementation not only generates new paths, but does so fast enough to be feasible for real time systems",https://ieeexplore.ieee.org/document/4178112/,Proceedings of the 45th IEEE Conference on Decision and Control,13-15 Dec. 2006,ieeexplore
10.1109/IWECAI50956.2020.00019,Path Planning Obstacle Avoidance Algorithm Based on Wheeled Robot,IEEE,Conferences,"There are many obstacles and movements in the indoor environment. Indoor robots need to cope with the changing environment. This paper studies the obstacle avoidance problem of wheeled robots moving in an unknown environment. Firstly, the dynamic path planning algorithm for robot autonomous obstacle avoidance is studied, and the algorithm is implemented in C# language. Then use the Unity3D game engine to simulate the algorithm. The innovations of this algorithm are as follows: 1. Vectorize the path of the robot; 2. Summarize the motion state of the obstacle and the robot into six cases. During the movement process, the obstacle movement state is continuously judged, and the speed and direction of the obstacle are analyzed. The judgment result must belong to six situations. The experiment proves that the algorithm can solve the obstacle avoidance problem when encountering obstacles of different speeds and sizes, and has stronger applicability.",https://ieeexplore.ieee.org/document/9221693/,2020 International Workshop on Electronic Communication and Artificial Intelligence (IWECAI),12-14 June 2020,ieeexplore
10.1109/DISA.2018.8490605,Path Planning on Robot Based on D* Lite Algorithm,IEEE,Conferences,"The increasing need of autonomous behavior of robots in fields of science and technology formed the requirement for path planning implemented by the robot without the human assistance. In this paper, D* Lite, which is a path planning graph-based algorithm, was used in order to compute the shortest path from a start to goal point in a real environment and make a Pepper robot move in a computed trajectory. The movement of robot was conducted in a static environment, with the map of the environment already known. This paper is a first step in the research focusing on a creation of a so-called intelligent workspace.",https://ieeexplore.ieee.org/document/8490605/,2018 World Symposium on Digital Intelligence for Systems and Machines (DISA),23-25 Aug. 2018,ieeexplore
10.1109/URAI.2012.6463006,Path planning through maze routing for a mobile robot with nonholonomic constraints,IEEE,Conferences,"A comprehensive technique to plan path for a mobile robot with nonholonomic constraints through maze routing technique has been presented. Our robot uses a stereo vision based approach to detect the obstacles by creating dense 3D point clouds from the stereo images. ROS packages have been implemented on the robot for specific tasks of providing: i) Linear and angular velocity commands, ii) Calibration and rectification of the stereo images for generating point clouds, iii) Simulating the URDF (Unified Robot Description Format) module in real time, with respect to the real robot and iv) For visualizing the sensor data. For efficient path planning a hybrid technique using Lee's algorithm, modified by Hadlock and Soukup's algorithm has been implemented. Different path planning results have been shown using the maze routing algorithms. Preliminary results shows that Lee's algorithm is more time consuming in comparison with other algorithms. A hybrid of Lee's with Soukup's algorithm is more efficient but unpredictable for minimal path. A hybrid of Lee's with Hadlock's algorithm is the most efficient and least time consuming.",https://ieeexplore.ieee.org/document/6463006/,2012 9th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI),26-28 Nov. 2012,ieeexplore
10.1109/ICCEAI52939.2021.00074,Pedestrian Recognition System for Smart Security Robot using Pedestrian Re-identification Algorithm,IEEE,Conferences,"The security system is an important guarantee for the safety of citizens' lives and property. In recent years, security robots have been more and more widely used in security systems. At present, domestic security robots generally lack of pedestrian recognition ability under complex circumstances. Therefore, this paper designs and implements pedestrian recognition system for smart security robots using improved pedestrian re-identification algorithm. Experiment result shows that the system has success rate of 90 % and response speed compliance rate of 94.4% under real circumstances, which is much better than traditional system.",https://ieeexplore.ieee.org/document/9544430/,2021 International Conference on Computer Engineering and Artificial Intelligence (ICCEAI),27-29 Aug. 2021,ieeexplore
10.1109/ICSMC.1999.816641,"Perception, reasoning and learning of multiple agent systems for robot soccer",IEEE,Conferences,"Presents a supervisory control strategy for coordination of soccer playing mobile robots. Within the framework of a hierarchical control structure, three layered components of supervisor, coordinator, and executor emulate the basic three concepts of human intelligence, perception, reasoning, and learning. A small size discrete event system model is derived and implemented in the supervisor and coordinator for state-action reasoning and coordination of multiple robotic agents for a successful soccer game. Experimental results of real soccer games are given to demonstrate the feasibility and effectiveness of the developed supervisory control strategy in terms of structural simplicity and computational speed for real-time control.",https://ieeexplore.ieee.org/document/816641/,"IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028)",12-15 Oct. 1999,ieeexplore
10.1109/ICSMC.1996.571370,Perception-action method for mobile robot plan and control based on driving experience,IEEE,Conferences,"A method of navigation and control for mobile robot is introduced. It combines task planning and path tracking together with the principle of ""perception-action"" under the guidance of ""goal planning"". First, we discuss the behavior of the mobile robot in an outdoor real world for the purpose of setting up a mixed layered architecture with ""perception-action"" and ""goal planning"". Then a simple but effective approach of sensor based navigation and control is described for the implementation of the architecture. Finally, we give some improvements based on the human-driving experience concerning path tracking and control for the mobile robot moving on outdoor semistructured roads. The experiments carried out on our THMR-III (Tsinghua Mobile Robot III) mobile robot navigating in the real world showed the method described was effective and robust.",https://ieeexplore.ieee.org/document/571370/,"1996 IEEE International Conference on Systems, Man and Cybernetics. Information Intelligence and Systems (Cat. No.96CH35929)",14-17 Oct. 1996,ieeexplore
10.1109/ICRA.2011.5979792,Physical human robot interaction in imitation learning,IEEE,Conferences,"This video presents our recent research on the integration of physical human-robot interaction (pHRI) into imitation learning. First, a marker control approach for real time human motion imitation is shown. Secondly, physical coaching in addition to observational learning is applied for the incremental learning of motion primitives. Last, we extend imitation learning to learning pHRI which includes the establishment of intended physical contacts. The proposed methods were implemented and tested using the IRT humanoid robot and DLR's humanoid upper-body robot Justin.",https://ieeexplore.ieee.org/document/5979792/,2011 IEEE International Conference on Robotics and Automation,9-13 May 2011,ieeexplore
10.1109/ROMAN.2009.5326164,Physical interaction learning: Behavior adaptation in cooperative human-robot tasks involving physical contact,IEEE,Conferences,"In order for humans and robots to engage in direct physical interaction several requirements have to be met. Among others, robots need to be able to adapt their behavior in order to facilitate the interaction with a human partner. This can be achieved using machine learning techniques. However, most machine learning scenarios to-date do not address the question of how learning can be achieved for tightly coupled, physical touch interactions between the learning agent and a human partner. This paper presents an example for such human in-the-loop learning scenarios and proposes a computationally cheap learning algorithm for this purpose. The efficiency of this method is evaluated in an experiment, where human care givers help an android robot to stand up.",https://ieeexplore.ieee.org/document/5326164/,RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication,27 Sept.-2 Oct. 2009,ieeexplore
10.1109/ICRA.2018.8462927,Planning Ergonomic Sequences of Actions in Human-Robot Interaction,IEEE,Conferences,"In this paper, we define the problem of human-robot collaboration as a combined task and motion planning problem which is extended to the multi-agent case (human and robot). Our proposed approach allows us to explicitly take into account ergonomic cost, synchrony and concurrency of behavior in an optimization formulation. We show simulated results as well as an experiment with a real robot combined with a user study. Results show that optimizing over a sequence of actions leads to more ergonomic situations.",https://ieeexplore.ieee.org/document/8462927/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/CIRA.2005.1554245,Plenary talk June 29; The 3<sup>rd</sup>Generation of Robotics: Ubiquitous Robot,IEEE,Conferences,"This talk shows its possibility of implementation in real life through demonstrations using a Sobot, Rity: i) continuous interface between physical and virtual worlds ii) seamless transmission of Sobot between a PC and a Mobot, and iii) omnipresence of Sobot. Rity, developed at the Robot Intelligence Technology (RIT) Laboratory, KAIST, is a Sobot implemented as a 12 DOF artificial creature in the virtual 3D world created in a PC. It has virtual sensors to survive in the virtual world and physical sensors attached to the PC to interact with the real world. Based on sensor information it can express its emotion, and interact with human beings through a web camera in the real world. It can generate behaviors autonomously and has its own IP. This means that it can be accessed through a network at anywhere and anytime using any device. With this technique omnipresence of Sobot can be realized in a ubiquitous space. The eventual goal of this research is to integrate Sobot, Embot, and Mobot to build up a Ubibot so that ubiquitous services through it can be available in a ubiquitous era",https://ieeexplore.ieee.org/document/1554245/,2005 International Symposium on Computational Intelligence in Robotics and Automation,27-30 June 2005,ieeexplore
10.1109/GCCE50665.2020.9291969,Policy Transfer from Simulation to Real World for Autonomous Control of an Omni Wheel Robot,IEEE,Conferences,"We aim to develop an autonomous mobile robot which supports workers in warehouse to reduce their burden. The robot acquire state-action policy to avoid obstacles and reach a destination by reinforcement learning using LiDAR sensor. In case of real-world application of reinforcement learning, the policy learned previously under simulation environment are generally diverted to real robots because of uncertainties that is unexpected under simulation environment, for example, friction, sensor noise and so on. In this paper, we proposed a method to refine action control of an omni wheel robot by transfer learning on real environment to deal with this problem. We conduct the experiment of searching the route for reaching a goal on real environment using transfer learning's results and verify the effectiveness of the policy acquired.",https://ieeexplore.ieee.org/document/9291969/,2020 IEEE 9th Global Conference on Consumer Electronics (GCCE),13-16 Oct. 2020,ieeexplore
10.1109/IROS.2013.6696568,Pose and paste — An intuitive interface for remote navigation of a multi-robot system,IEEE,Conferences,"We present Pose and Paste (P&amp;P) - an intuitive interface designed to facilitate interaction between a single user and a number of robots equipped with cameras. With this interface, a user wearing a head-mounted display is able to cycle through the real-time video streams originating from the robots' cameras. The user is also able to select a robot and remotely position it by simply walking or turning his/her head, i.e., control the robot's motion in a master/slave-type fashion. We report the results of an initial hardware experiment where a user located in the USA is tasked to position two quadrotor robots within a motion capture laboratory located in Germany. These results suggest that P&amp;P is a feasible approach to remotely inspect disaster affected sites. Lastly, we conduct a user study to compare P&amp;P with a baseline interface composed of a traditional computer monitor and a video game controller. The quantitative results and qualitative discussions resulting from this user study highlight how such multi-robot interfaces can be further improved.",https://ieeexplore.ieee.org/document/6696568/,2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,3-7 Nov. 2013,ieeexplore
10.1109/ICRA.2014.6907470,Posture control of a three-segmented tracked robot with torque minimization during step climbing,IEEE,Conferences,"In this paper, we present a posture control scheme for step climbing by an in-house developed three-segmented tracked robot, miniUGV. The posture control scheme results in minimum torque at the actuated joints of the segments. Non-linear optimization is carried out offline for progressively decreasing distance of the robot from the step with torque minimization as objective function and force balance, motor torque limits, slippage avoidance and interference avoidance constraints. The resulting angles of the joints are fitted to a third degree polynomial as a function of the robot distance from the step and the step height. It is shown that a single set of polynomial functions is sufficient for climbing steps of all permissible heights and angles of attack of the front segment. The methodology has been verified through simulation followed by implementation on the real robot. As a consequence of this optimization we find that the average current reduced by more than thirty percent, reducing power consumption and confirming the efficacy of the optimization framework.",https://ieeexplore.ieee.org/document/6907470/,2014 IEEE International Conference on Robotics and Automation (ICRA),31 May-7 June 2014,ieeexplore
10.1109/IJCNN.2014.6889830,Predictive Hebbian association of time-delayed inputs with actions in a developmental robot platform,IEEE,Conferences,"The work described here explores a neural network architecture that can be embedded directly in the realtime sensorimotor coordination loop of a developmental robot platform. We take inspiration from the way children are able to learn while interacting with a teacher, in particular the use of prediction of the teacher actions to improve own learning. The architecture is based on two neural networks that operate online, and in parallel, one for learning and one for prediction. A Hebbian learning rule is used to associate the high-dimensional afferent sensor input at different time-delays with the current efferent motor commands corresponding to the teacher demonstration. The predictions of future motor commands are used to limit the growth of the neural network weights, and to enable the robot to smoothly continue movements the teacher has begun. Results on a simulated iCub robot learning object interaction tasks are presented, including an analysis of the sensitivity to changes in the task setup. We also outline the first implementation on the real iCub platform.",https://ieeexplore.ieee.org/document/6889830/,2014 International Joint Conference on Neural Networks (IJCNN),6-11 July 2014,ieeexplore
10.1109/RO-MAN46459.2019.8956461,Privacy First: Designing Responsible and Inclusive Social Robot Applications for in the Wild Studies,IEEE,Conferences,"Deploying social robots applications in public spaces for conducting in the wild studies is a significant challenge but critical to the advancement of social robotics. Real world environments are complex, dynamic, and uncertain. Human-Robot interactions can be unstructured and unanticipated. In addition, when the robot is intended to be a shared public resource, management issues such as user access and user privacy arise, leading to design choices that can impact on users' trust and the adoption of the designed system. In this paper we propose a user registration and login system for a social robot and report on people's preferences when registering their personal details with the robot to access services. This study is the first iteration of a larger body of work investigating potential use cases for the Pepper social robot at a government managed centre for startups and innovation. We prototyped and deployed a system for user registration with the robot, which gives users control over registering and accessing services with either face recognition technology or a QR code. The QR code played a critical role in increasing the number of users adopting the technology. We discuss the need to develop social robot applications that responsibly adhere to privacy principles, are inclusive, and cater for a broad spectrum of people.",https://ieeexplore.ieee.org/document/8956461/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/IROS.2018.8594180,Proactive Robot Assistants for Freeform Collaborative Tasks Through Multimodal Recognition of Generic Subtasks,IEEE,Conferences,"Successful human-robot collaboration depends on a shared understanding of task state and current goals. In nonlinear or freeform tasks without an explicit task model, robot partners are unable to provide assistance without the ability to translate perception into meaningful task knowledge. In this paper, we explore the utility of multimodal recurrent neural networks (RNNs) with long short-term memory (LSTM) units for real-time subtask recognition in order to provide context-aware assistance during generic assembly tasks. We train RNNs to recognize specific subtasks in individual modalities, then combine the high-level representations of these networks through a nonlinear connection layer to create a multimodal subtask recognition system. We report results from implementing the system on a robot that uses the subtask recognition system to provide predictive assistance to a human partner during a laboratory experiment involving a human-robot team completing an assembly task. Generalizability of the system is evaluated through training and testing on separate tasks with some similar subtasks. Our results demonstrate the value of such a system in providing assistance to human partners during a freeform assembly scenario and increasing humans' perception of the robot's agency and usefulness.",https://ieeexplore.ieee.org/document/8594180/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/IMTC.1999.776982,Problems and solutions in acquisition and interpretation of sensorial data on a mobile robot,IEEE,Conferences,"We discuss some guidelines to cope with problems that arise when using cheap and simple sensors on mobile, autonomous, robotic agents. In particular we focus on the perceptual aliasing problem and on the possibility to perform active sensor data acquisition. We present a robotic architecture that we have implemented on a real robot following the proposed guidelines. The obtained mobile robot satisfies the design specifications, navigating autonomously in an unstructured environment.",https://ieeexplore.ieee.org/document/776982/,IMTC/99. Proceedings of the 16th IEEE Instrumentation and Measurement Technology Conference (Cat. No.99CH36309),24-26 May 1999,ieeexplore
10.1109/EMRTS.1999.777446,Rate modulation of soft real-time tasks in autonomous robot control systems,IEEE,Conferences,"Due to the high number of sensors managed and need to perform complex reasoning activities, real-time control systems of autonomous robots exhibit a high potential for overload, i.e., real-time tasks missing their deadlines. In these systems overload should be regarded as a likely occurrence and hence managed accordingly. In this paper we illustrate a novel scheduling technique for adaptation of soft real-time load to available computational capacity in the context of autonomous robot control architectures. The technique is based on rate modulation of a set of periodic tasks in a range of admissible rates. The technique is shown to be easily computable and several variations in implementation are reviewed within the paper.",https://ieeexplore.ieee.org/document/777446/,Proceedings of 11th Euromicro Conference on Real-Time Systems. Euromicro RTS'99,9-11 June 1999,ieeexplore
10.1109/ISIE.2005.1529114,Real time implementation of a selective attention model for the intelligent robot with autonomous mental development,IEEE,Conferences,"We propose a biologically motivated selective attention model to find an object based on context free search for an intelligent robot with an autonomous mental development (AMD) mechanism. For real-time operation of the selective attention model in the robot system, we have considered a way to reduce the computational load of the selective attention model, which uses a simplified symmetry operation with retina-topic sampling and look-up table in the localized candidate attention region. As a result, our model can perform within 270 ms at Pentium-4 2.8Ghz, and obtain a plausible human-like visual scan path in order to pay attention to an object preferentially. Then, we implemented an intelligent mobile robot with selective attention for an AMD mechanism.",https://ieeexplore.ieee.org/document/1529114/,"Proceedings of the IEEE International Symposium on Industrial Electronics, 2005. ISIE 2005.",20-23 June 2005,ieeexplore
10.1109/RISSP.2003.1285735,Real time reactive strategies based on potential fields for robot soccer,IEEE,Conferences,"Soccer robot games are rapidly becoming a major research tool in field of AI, machine vision and motion control. The dynamism of the environment in the size of state space makes such a design challenging. In this paper we develop optimal reactive strategies for the game using groundtruth data from experts, with potential fields as base of the strategies. Experiment shows that the strategy has good active characteristics and can satisfy the game demand.",https://ieeexplore.ieee.org/document/1285735/,"IEEE International Conference on Robotics, Intelligent Systems and Signal Processing, 2003. Proceedings. 2003",8-13 Oct. 2003,ieeexplore
10.1109/WCICA.2000.863455,Real time tracking in robot teleoperation system,IEEE,Conferences,"The robot teleoperation system based on stereo vision was developed by the State Key Lab of Intelligent Technology and System of Tsinghua University. The paper presents the design frame of the whole system, and describes in detail some of the key design and implementation problems. Finally, the paper analyses the difficulty of applying this technology to virtual reality and augmented reality systems, and some suggestions are provided. The success of this system can contribute to further research on augmented reality.",https://ieeexplore.ieee.org/document/863455/,Proceedings of the 3rd World Congress on Intelligent Control and Automation (Cat. No.00EX393),26 June-2 July 2000,ieeexplore
10.1109/ICMLC.2006.259112,Real-Time Implementation of a PD+DFNNS Controller for Compliance Robot,IEEE,Conferences,"This paper presents the compliance control of a robot manipulator under a constrained environment. The controller design proposed herein is based on the intelligence adaptive control scheme. In this design, the DFNNs (dynamic fuzzy neural networks) and PD feedback controllers control the position and the contact force of robot end-effector. The DFNNs controller is employed to compensate for environmental variations such as payload mass and disturbance torque during the operation process; PD feedback controllers control the position and the contact force of end-effector. Applying these controllers allows us to adapt the manipulator to the unknown surface of the surrounding environment and to have close contact with the curved surface",https://ieeexplore.ieee.org/document/4028106/,2006 International Conference on Machine Learning and Cybernetics,13-16 Aug. 2006,ieeexplore
10.1109/Cybermatics_2018.2018.00131,Real-Time Object Recognition Based on NAO Humanoid Robot,IEEE,Conferences,"This paper focuses on the real-time object recognition based indoor humanoid robots like Nao robots. Improving the perceptive ability of service robot has always been a research hotspot. The breakthrough of computer vision technology represented by object recognition provides a broader idea for this purpose. We deployed a micro-cloud layer that connects the robot with the computer vision, thereby realized the concepts of RaaS (Robot as a service). In this paper, in order to make the Nao robot to detect objects faster. We present an architecture about real-time object recognition on Nao, and offload the task of control and data collection from robot to a PC. Next, the image data is transmitted over Ethernet to the workstation, which runs multiple parallel image processing services. These services are built with the current popular deep neural network by TensorFlow and running on a GPU GTX1080 Ti. In the micro-cloud layer, we designed a universal robotic visual task queue model, and a PC registers the task queue to the LAN. There are multiple workers in the LAN, and each worker is an independent service processer. Service processer obtains the task queue from the network and processes the queue, and then the processer puts the results back to the manager. The experimental results of the Nao robot in the simulation and real word show that our model and method are effective. The robot can recognize about 90 kinds of common objects, and each frame of image processing time is about 100 milliseconds.",https://ieeexplore.ieee.org/document/8726687/,"2018 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)",30 July-3 Aug. 2018,ieeexplore
10.1109/IROS45743.2020.9341760,Real-Time Robot End-Effector Pose Estimation with Deep Network,IEEE,Conferences,"In this paper, we propose a novel algorithm that estimates the pose of the robot end effector using depth vision. The input to our system is the segmented robot hand point cloud from a depth sensor. Then a neural network takes a point cloud as input and outputs the position and orientation of the robot end effector in the camera frame. The estimated pose can serve as the input of the controller of the robot to reach a specific pose in the camera frame. The training process of the neural network takes the simulated rendered point cloud generated from different poses of the robot hand mesh. At test time, one estimation of a single robot hand pose is reduced to 10ms on gpu and 14ms on cpu, which makes it suitable for close loop robot control system that requires to estimate hand pose in an online fashion. We design a robot hand pose estimation experiment to validate the effectiveness of our algorithm working in the real situation. The platform we used includes a Kinova Jaco 2 robot arm and a Kinect v2 depth sensor. We describe all the processes that use vision to improve the accuracy of pose estimation of the robot end-effector. We demonstrate the possibility of using point cloud to directly estimate the robot's end-effector pose and incorporate the estimated pose into the controller design of the robot arm.",https://ieeexplore.ieee.org/document/9341760/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/SYSOSE.2015.7151922,Real-time FPGA decentralized inverse optimal neural control for a Shrimp robot,IEEE,Conferences,"This paper presents a field programmable gate array (FPGA) implementation for a decentralized inverse optimal neural controller for unknown nonlinear systems, in presence of external disturbances and parameter uncertainties. This controller is based on two techniques: first, an identifier using a discrete-time recurrent high order neural network (RHONN) trained with an extended Kalman filter (EKF) algorithm; second, on the basis of the neural identifier a controller which uses inverse optimal control, is designed to avoid solving the Hamilton Jacobi Bellman (HJB) equation. The proposed scheme is implemented in real-time to control a Shrimp robot.",https://ieeexplore.ieee.org/document/7151922/,2015 10th System of Systems Engineering Conference (SoSE),17-20 May 2015,ieeexplore
10.1109/LifeTech52111.2021.9391811,Real-time Object Detection with Deep Learning for Robot Vision on Mixed Reality Device,IEEE,Conferences,"Mixed reality device sensing capabilities are valuable for robots, for example, the inertial measurement unit (IMU) sensor and time-of-flight (TOF) depth sensor can support the robot in navigating its environment. This paper demonstrates a deep learning (YOLO model) background, realtime object detection system implemented on mixed reality device. The goal of the system is to create a real-time communication system between HoloLens and Ubuntu systems to enable real-time object detection using the YOLO model. The experimental results show that the proposed method has a fast speed to achieve real-time object detection using HoloLens. This enables Microsoft HoloLens as a device for robot vision. To enhance human-robot interaction, we will apply it to a wearable robot arm system to automatically grasp objects in the future.",https://ieeexplore.ieee.org/document/9391811/,2021 IEEE 3rd Global Conference on Life Sciences and Technologies (LifeTech),9-11 March 2021,ieeexplore
10.1109/CCA.2007.4389266,Real-time Obstacle Avoidance Strategy for Mobile Robot Based On Improved Coordinating Potential Field with Genetic Algorithm,IEEE,Conferences,"To overcome the problems during navigation of mobile robots in dynamic environment using the traditional artificial potential field (APF) method, a novel improved method called coordinating potential field (CPF) is proposed. The local potential field is constructed by using local subgoals, which obtained by updating dynamic windows. The questions of local minima, oscillation between multiple obstacles and real-time dynamic obstacle avoidance are solved. At last multi-objective parameter optimization is implemented by using adaptive genetic algorithm. Simulation results indicate that this strategy is practicable and effective.",https://ieeexplore.ieee.org/document/4389266/,2007 IEEE International Conference on Control Applications,1-3 Oct. 2007,ieeexplore
10.1109/CEC.2003.1299618,Real-time adaptation technique to real robots: an experiment with a humanoid robot,IEEE,Conferences,"We introduce a technique that allows a real robot to execute a real-time learning, in which GP and RL are integrated. In our former research, we showed the result of an experiment with a real robot ""AIBO"" and proved the technique performed better than the traditional Q-learning method. Based on the proposed technique, we can acquire the common programs using a GP, applicable to various types of robots. We execute reinforcement learning with the acquired program in a real robot. In this way, the robot can adapt to its own operational characteristics and learn effective actions. In this paper, we show the experimental results in which a humanoid robot ""HOAP-1"" has been evolved to perform effectively to solve the box-moving task.",https://ieeexplore.ieee.org/document/1299618/,"The 2003 Congress on Evolutionary Computation, 2003. CEC '03.",8-12 Dec. 2003,ieeexplore
10.1109/ICCAS.2008.4694293,Real-time adaptive control of robot manipulator based on neural network compensator,IEEE,Conferences,"This paper presents two kinds of adaptive control schemes for robot manipulator which has the parametric uncertainties. In order to compensate these uncertainties, we use the NN (neural network system) that has the capability to approximate any nonlinear function over the compact input space. In the proposed control schemes, we need not derive the linear formulation of robot dynamic equation and tune the parameters. We also suggest the robust adaptive control laws in all proposed schemes for decreasing the effect of approximation error. To reduce the number of neural of network, we consider the properties of robot dynamics and the decomposition of the uncertainty function. The proposed controllers are robust not only to the structured uncertainty such as payload parameter, but also to the unstructured one such as friction model and disturbance. The validity of the control scheme is shown by computer simulations and experiment of dual-arm robot manipulator.",https://ieeexplore.ieee.org/document/4694293/,"2008 International Conference on Control, Automation and Systems",14-17 Oct. 2008,ieeexplore
10.1109/CCA.1994.381367,Real-time control of a robot using neural networks,IEEE,Conferences,"The real-time computation of the robot kinematics is very important. The basic transformations are the direct kinematic transformation (DKT) and the inverse kinematic transformation (IKT). The DKT can be computed in a straightforward way using the Denavit-Hartenberg notation. No such general method yet exists for the IKT, although this transformation is of major interest for control purposes. In this paper a neural network is presented that maps the IKT independent of the type of robot. After training, the network achieves very good accuracy and may easily be implemented in real-time. The performance of the algorithm is tested an the RTX robot, a SCARA-type robot with six degrees of freedom. This robot is controlled by a distributed control system. A host computer realizes the continuous path control and a network of 5 slave-transputers is used to compute the local controls and to drive the DC servomotors.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/381367/,1994 Proceedings of IEEE International Conference on Control and Applications,24-26 Aug. 1994,ieeexplore
10.1109/IJCNN.2013.6706785,Real-time decentralized inverse optimal neural control for a Shrimp robot,IEEE,Conferences,"This paper deals with a decentralized inverse optimal neural controller for MIMO discrete-time unknown nonlinear systems, in a presence of external disturbances and parameter uncertainties. It uses two techniques: first, an identifier based on a discrete-time recurrent high order neural network (RHONN) trained with an extended Kalman filter (EKF) algorithm; second, on the basis of the real identifier a controller which uses inverse optimal control, is designed to avoid solving the Hamilton Jacobi Bellman (HJB) equation. The proposed scheme is implemented in real-time to control a Shrimp robot.",https://ieeexplore.ieee.org/document/6706785/,The 2013 International Joint Conference on Neural Networks (IJCNN),4-9 Aug. 2013,ieeexplore
10.1109/CCA.2009.5280998,Real-time decentralized neural backstepping controller for a robot manipulator,IEEE,Conferences,This paper deals with adaptive trajectory tracking for discrete-time MIMO nonlinear systems. A high order neural network (HONN) is used to approximate a decentralized control law designed by the backstepping technique as applied to a block strict feedback form (BSFF). The HONN learning is performed online by an Extended Kalman Filter (EKF) algorithm. The proposed scheme is implemented in real-time to control a two DOF robot manipulator.,https://ieeexplore.ieee.org/document/5280998/,"2009 IEEE Control Applications, (CCA) & Intelligent Control, (ISIC)",8-10 July 2009,ieeexplore
10.1109/IROS.2009.5354338,Real-time decentralized neural block controller for a robot manipulator,IEEE,Conferences,"This paper presents a discrete-time decentralized control scheme for identification and trajectory tracking of a two degrees of freedom (DOF) robot manipulator. A recurrent high order neural network (RHONN) structure is used to identify the plant model and based on this model, a discrete-time control law is derived, which combines discrete-time block control and sliding modes techniques. The neural network learning is performed online by Kalman filtering. A controller is designed for each joint, using only local angular position and velocity measurements. These simple local joint controllers allow trajectory tracking with reduced computations. The proposed scheme is implemented in real-time to control a two DOF robot manipulator.",https://ieeexplore.ieee.org/document/5354338/,2009 IEEE/RSJ International Conference on Intelligent Robots and Systems,10-15 Oct. 2009,ieeexplore
10.1109/ROMAN.1996.568870,Real-time facial interaction between human and 3D face robot agent,IEEE,Conferences,"We attempt to introduce a 3D realistic human-like animate face robot to human-robot communication modality. The face robot can recognize human facial expressions as well as produce realistic facial expressions in real time. For the animate face robot to communicate interactively, we propose a new concept of ""active human interface"", and we investigate the performance of real-time recognition of facial expressions by neutral network (NN) and the expression ability of facial messages on the face robot. We found that the NN recognition of facial expressions and face robots performance in generating facial expressions are of almost the same level as that in humans. We integrate these two component technologies for the face to produce facial expression in reaction to the recognition result of human facial expression in real time. This implies a high technological potential for the animate face robot to undertakes interactive communication with human when an artificial emotion being implemented.",https://ieeexplore.ieee.org/document/568870/,Proceedings 5th IEEE International Workshop on Robot and Human Communication. RO-MAN'96 TSUKUBA,11-14 Nov. 1996,ieeexplore
10.1109/ISIC.2010.5612924,Real-time five DOF robot control using a decentralized neural backstepping scheme,IEEE,Conferences,This paper presents a discrete-time decentralized control scheme for trajectory tracking of a five degrees of freedom (DOF) redundant robot. A high order neural network (HONN) is used to approximate a decentralized control law designed by the backstepping technique as applied to a block strict feedback form (BSFF). The neural network learning is performed on-line by Kalman filtering. The controllers are designed for each joint using only local angular position and velocity measurements. These simple local joint controllers allow trajectory tracking with reduced computations. The applicability of the proposed scheme is illustrated via real-time implementation.,https://ieeexplore.ieee.org/document/5612924/,2010 IEEE International Symposium on Intelligent Control,8-10 Sept. 2010,ieeexplore
10.1109/ICAR.1997.620222,Real-time navigation of a mobile robot using Kohonen's topology conserving neural network,IEEE,Conferences,"This paper proposes a real-time sensor based navigation method using Kohonen's topology conserving network for navigation of a mobile robot in any uncertain environment. The sensory information including target location with respect to current location of the mobile robot, have been discretely conserved using a two dimensional Kohonen lattice. Reinforcement learning based on a stochastic real valued technique have been implemented to compute the action space for this Kohonen lattice. The proposed scheme learns the input and output weight space of the Kohonen lattice which is generalized to any workspace. The effectiveness of the proposed scheme has been established by simulation where the complete domain of the input-space is quantized based on experience on sensory data encountered in real-time. The input-output mapping conserved by the Kohonen lattice during simulation was used to guide a mobile robot in a real-time environment. Successful navigation of the mobile robot without further training confirms the robustness of the proposed scheme.",https://ieeexplore.ieee.org/document/620222/,1997 8th International Conference on Advanced Robotics. Proceedings. ICAR'97,7-9 July 1997,ieeexplore
10.1109/ROBOT.2001.932598,Real-time robot learning,IEEE,Conferences,"This paper presents the design, implementation and testing of a real-time system using computer vision and machine learning techniques to demonstrate learning behavior in a miniature mobile robot. The miniature robot, through environmental sensing, learns to navigate a maze choosing the optimum route. Several reinforcement learning based algorithms, such as the Q-learning, Q(/spl lambda/)-learning, fast online Q(/spl lambda/)-learning and DYNA structure, are considered. Experimental results based on simulation and an integrated real-time system are presented for varying density of obstacles in a 15/spl times/15 maze.",https://ieeexplore.ieee.org/document/932598/,Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164),21-26 May 2001,ieeexplore
10.1109/ICACEH51803.2020.9366217,Realization of Human and Fish Robot Interaction with Artificial Intelligence Using Hand Gesture,IEEE,Conferences,This study mimicked a real fish movement in the aquarium which was controlled by hand signals. The main idea to develop an aquarium robotic fish with hand gestures. Control actions include directions and stop and go of the fish. The inputs are given by human hands known as bio-mimetic ornamental. We implemented control algorithms to recognize hand gestures. The experimental results showed the effective control of robot fish with hand gestures.,https://ieeexplore.ieee.org/document/9366217/,"2020 IEEE 2nd International Conference on Architecture, Construction, Environment and Hydraulics (ICACEH)",25-27 Dec. 2020,ieeexplore
10.1109/GTSD50082.2020.9303087,Receptionist and Security Robot Using Face Recognition with Standardized Data Collecting Method,IEEE,Conferences,"Face recognition has become the front runner for deep learning applications in the real world and this paper focuses on its implementation in a human-robot interaction and security system. For this specific project, it is inherent that restraints are created to allow the system to produce greater performance within the requirements of a receptionist and security robot. A k-nearest neighbors classifier is applied to further enhance the accuracy of face recognition. By sequencing images from videos, we create large datasets to train our own classifier in various conditions to increase its accuracy and lower false-positive rates in poor lighting environments. With the goal of creating a service robot, we have standardized our method of data collection for new inputs that will assist the recognition process in variable conditions of operation. The resulting product is a system that can accurately predict known and unknown faces with Asian features.",https://ieeexplore.ieee.org/document/9303087/,2020 5th International Conference on Green Technology and Sustainable Development (GTSD),27-28 Nov. 2020,ieeexplore
10.1109/IRDS.2002.1043897,Recognizing and remembering individuals: online and unsupervised face recognition for humanoid robot,IEEE,Conferences,"Individual recognition is a widely reported phenomenon in the animal world, where it contributes to successful maternal interaction, parental care, group breeding, cooperation, mate choice, etc. This work addresses the question of how one may implement such social competence in a humanoid robot. We argue that the robot must be able to recognize people and learn about their various characteristics through embodied social interaction. Thus, we proposed an initial implementation of an online and unsupervised face recognition system for Kismet, our sociable robotic platform. We show how specific features of this particular application drove our decision and implementation process, challenged by the difficulty of the face recognition problem, which has so far been explored in the supervised manner. Experimental results are reported to illustrate what was solved and the lessons learned from the current implementation.",https://ieeexplore.ieee.org/document/1043897/,IEEE/RSJ International Conference on Intelligent Robots and Systems,30 Sept.-4 Oct. 2002,ieeexplore
10.1109/BioRob49111.2020.9224392,Reinforcement Learning Assist-as-needed Control for Robot Assisted Gait Training,IEEE,Conferences,"The primary goal of an assist-as-needed (AAN) controller is to maximize subjects' active participation during motor training tasks while allowing moderate tracking errors to encourage human learning of a target movement. Impedance control is typically employed by AAN controllers to create a compliant force-field around the desired motion trajectory. To accommodate different individuals with varying motor abilities, most of the existing AAN controllers require extensive manual tuning of the control parameters, resulting in a tedious and time-consuming process. In this paper, we propose a reinforcement learning AAN controller that can autonomously reshape the force-field in real-time based on subjects' training performances. The use of action-dependent heuristic dynamic programming enables a model-free implementation of the proposed controller. To experimentally validate the controller, a group of healthy individuals participated in a gait training session wherein they were asked to learn a modified gait pattern with the help of a powered ankle-foot orthosis. Results indicated the potential of the proposed control strategy for robot-assisted gait training.",https://ieeexplore.ieee.org/document/9224392/,2020 8th IEEE RAS/EMBS International Conference for Biomedical Robotics and Biomechatronics (BioRob),29 Nov.-1 Dec. 2020,ieeexplore
10.1109/CIRA.2007.382878,Reinforcement Learning with a Supervisor for a Mobile Robot in a Real-world Environment,IEEE,Conferences,"This paper describes two experiments with supervised reinforcement learning (RL) on a real, mobile robot. Two types of experiments were preformed. One tests the robot's reliability in implementing a navigation task it has been taught by a supervisor. The other, in which new obstacles are placed along the previously learned path to the goal, measures the robot's robustness to changes in environment. Supervision consisted of human-guided, remote-controlled runs through a navigation task during the initial stages of reinforcement learning. The RL algorithms deployed enabled the robot to learn a path to a goal yet retain the ability to explore different solutions when confronted with a new obstacle. Experimental analysis was based on measurements of average time to reach the goal, the number of failed states encountered during an episode, and how closely the RL learner matched the supervisor's actions.",https://ieeexplore.ieee.org/document/4269878/,2007 International Symposium on Computational Intelligence in Robotics and Automation,20-23 June 2007,ieeexplore
10.1109/ICSMC.2012.6377767,Reinforcement learning-based tracking control for wheeled mobile robot,IEEE,Conferences,This paper proposes a new method to design a reinforcement learning-based integrated kinematic and dynamic tracking control scheme for a nonholonomic wheeled mobile robot. The scheme uses just only one neural network to design an online adaptive synchronous policy iteration algorithm implemented as an actor critic structure. Our tuning law for the single neural network not only learns online a tracking-HJB equation to approximate both the optimal cost and the optimal adaptive control law but also guarantees closed-loop stability in real-time. The convergence and stability of the overall system are proven by Lyapunov theory. The simulation results for wheeled mobile robot verify the effectiveness of the proposed controller.,https://ieeexplore.ieee.org/document/6377767/,"2012 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",14-17 Oct. 2012,ieeexplore
10.1109/CYBER.2012.6392582,Reinforecement learning-based optimal tracking control for wheeled mobile robot,IEEE,Conferences,This paper proposes a new method to design a reinforcement learning-based integrated kinematic and dynamic tracking control scheme for a nonholonomic wheeled mobile robot. The scheme uses just only one neural network to design an online adaptive synchronous policy iteration algorithm implemented as an actor critic structure. Our tuning law for the single neural network not only learns online a tracking-HJB equation to approximate both the optimal cost and the optimal control law but also guarantees closed-loop stability in real-time. The convergence and stability of the overall system are proven by Lyapunov theory. The simulation results for wheeled mobile robot verify the effectiveness of the proposed controller.,https://ieeexplore.ieee.org/document/6392582/,"2012 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER)",27-31 May 2012,ieeexplore
10.1109/WCICA.2008.4593442,Research and realization on multi-robot parking mission strategy,IEEE,Conferences,"Aiming at the complexity and unknown of the modern robot-team parking mission environment, we proposed the maximal obsidional uniform distribution principle, the first nearest parking-point was enclosed by another parking-point according to uniform distribution. Based on it, we used the ldquoHungary Methodrdquo to realize the shortest total path length parking strategy. It was to form a benefit matrix which was composed of each the outside path length of the inclosing circle from robots to parking points, and then the best assignment was obtained by using ldquoHungary Methodrdquo. In this paper, itpsilas also considered two parking assignment strategies, which were shortest system executing time strategy and scope of inclosing circle seeable view strategy. The experiment result is shown that the robot-team can complete the reconnaissance parking mission efficiently. Additionally, the real-time performance is also fine.",https://ieeexplore.ieee.org/document/4593442/,2008 7th World Congress on Intelligent Control and Automation,25-27 June 2008,ieeexplore
10.1109/IWECAI50956.2020.00040,Research on Multi-robot Task Allocation Algorithm Based on HADTQL,IEEE,Conferences,"This paper proposes forward a Heuristically Accelerated Dynamic Team Q-learning (HADTQL) algorithm for solving multi-robot collaborative task allocation problem based on multi-agent reinforcement learning. It aims at making multiple robots collaborate to avoid all obstacles and accomplish all tasks while optimizing the path they took relatively. Firstly, the author constructs an appropriate state action space according to the specific information about the environment. Secondly, the whole learning process is divided into two stages by using dynamic exploration coefficient, which ensures the diversity of the early learning and the stability of the later learning. Thirdly, in order to help robots with reasonable action selection, the improved reward function is adopted to provide real-time rewards by utilizing the experience generated by the reinforcement learning of multiple agents. Finally, the heuristic function is introduced to guide the multi-agent reinforcement learning for the next action selection. The simulation experiment shows that the proposed algorithm can find an optimal task execution sequence and complete all tasks collaboratively with a relatively optimal path under the premise of avoiding obstacles in the environment automatically. Compared with the Team Q-learning (TQL) algorithm, this algorithm can allocate tasks reasonably with the high effectiveness and practicability.",https://ieeexplore.ieee.org/document/9221763/,2020 International Workshop on Electronic Communication and Artificial Intelligence (IWECAI),12-14 June 2020,ieeexplore
10.1109/CESA.2006.4281951,Research on RBF-PID Control for the 6-DOF Motion Base in Construction Tele-robot System,IEEE,Conferences,"In this paper, according to the real experiment device, we deduced the model of the electro-hydraulic servo valve and the dissymmetric hydraulic cylinder, a new RBF-PID controller was developed based on it to form a closed-loop system for the 6-DOF motion base in a tele-robotic system. To verify the validity of the design, a simulation is done. The simulation results show that RBF neural network is effective for electro hydraulic servo control systems. To control the 6-DOF realistic motions according to the signals of six acceleration sensors on the construction tele-robot, an experiment is also done. The validity of the control system was confirmed by experiment result. The control system performs steadily. And the experimental result indicates that the RBF neural network can enhances the robust control, which has reality significance.",https://ieeexplore.ieee.org/document/4281951/,"The Proceedings of the Multiconference on ""Computational Engineering in Systems Applications""",4-6 Oct. 2006,ieeexplore
10.1109/RCAR47638.2019.9044114,Research on omnidirectional mobile robot motion control based on integration of traction and steering wheel,IEEE,Conferences,"In order to solve the automatic transportation of heavy materials under the limited working space of production workshops and warehouses, two sets of heavy-duty omnidirectional mobile robot motion control systems with steering wheel drive units were designed. The steering wheel combination drive unit of the “walking + steering” set is used to build the mobile robot chassis, and the mechatronics servo system and mathematical model of multi-motor coordinated motion are constructed. The communication between the controller and the steering wheel combination drive unit is established through the CAN bus. The specific implementation is to capture and analyze the control signal through the controller to obtain the desired motion mode, to obtain the motion of each set of steering wheel unit through the mathematical model, and to realize the desired motion through the synthesis of each set of steering wheel unit motion. It has been verified by experiments that the two sets of steering wheel unit-driven mobile robot control system realizes the zero turning radius, 360-degree omnidirectional movement of the robot and rotation during the movement. It can be used for flexible work in tight spaces.",https://ieeexplore.ieee.org/document/9044114/,2019 IEEE International Conference on Real-time Computing and Robotics (RCAR),4-9 Aug. 2019,ieeexplore
10.1109/WCICA.2004.1343675,Research on remote controlled robot motion control system based on agent theory,IEEE,Conferences,"This paper introduces remote controlled robot motion control system based on agent theory. Task planning and reactive behavior control are discussed and implemented. This paper describes design of manager agent and motion control agent in detail. Agent theory are implemented in the robot control system to realize distributed intelligence based on M/A/R(Man/Agent/Robot) architecture. Thereby autonomy, reliability and real-time operation are improved.",https://ieeexplore.ieee.org/document/1343675/,Fifth World Congress on Intelligent Control and Automation (IEEE Cat. No.04EX788),15-19 June 2004,ieeexplore
10.1109/ICRA.2019.8794127,Residual Reinforcement Learning for Robot Control,IEEE,Conferences,"Conventional feedback control methods can solve various types of robot control problems very efficiently by capturing the structure with explicit models, such as rigid body equations of motion. However, many control problems in modern manufacturing deal with contacts and friction, which are difficult to capture with first-order physical modeling. Hence, applying control design methodologies to these kinds of problems often results in brittle and inaccurate controllers, which have to be manually tuned for deployment. Reinforcement learning (RL) methods have been demonstrated to be capable of learning continuous robot controllers from interactions with the environment, even for problems that include friction and contacts. In this paper, we study how we can solve difficult control problems in the real world by decomposing them into a part that is solved efficiently by conventional feedback control methods, and the residual which is solved with RL. The final control policy is a superposition of both control signals. We demonstrate our approach by training an agent to successfully perform a real-world block assembly task involving contacts and unstable objects.",https://ieeexplore.ieee.org/document/8794127/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/IROS45743.2020.9341469,Risk-Sensitive Sequential Action Control with Multi-Modal Human Trajectory Forecasting for Safe Crowd-Robot Interaction,IEEE,Conferences,"This paper presents a novel online framework for safe crowd-robot interaction based on risk-sensitive stochastic optimal control, wherein the risk is modeled by the entropic risk measure. The sampling-based model predictive control relies on mode insertion gradient optimization for this risk measure as well as Trajectron++, a state-of-the-art generative model that produces multimodal probabilistic trajectory forecasts for multiple interacting agents. Our modular approach decouples the crowd-robot interaction into learning-based prediction and model-based control, which is advantageous compared to end-to-end policy learning methods in that it allows the robot's desired behavior to be specified at run time. In particular, we show that the robot exhibits diverse interaction behavior by varying the risk sensitivity parameter. A simulation study and a real-world experiment show that the proposed online framework can accomplish safe and efficient navigation while avoiding collisions with more than 50 humans in the scene.",https://ieeexplore.ieee.org/document/9341469/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ICRA.2015.7139395,RoboSherlock: Unstructured information processing for robot perception,IEEE,Conferences,"We present RoboSherlock, an open source software framework for implementing perception systems for robots performing human-scale everyday manipulation tasks. In RoboSherlock, perception and interpretation of realistic scenes is formulated as an unstructured information management (UIM) problem. The application of the UIM principle supports the implementation of perception systems that can answer task-relevant queries about objects in a scene, boost object recognition performance by combining the strengths of multiple perception algorithms, support knowledge-enabled reasoning about objects and enable automatic and knowledge-driven generation of processing pipelines. We demonstrate the potential of the proposed framework by three feasibility studies of systems for real-world scene perception that have been built on top of RoboSherlock.",https://ieeexplore.ieee.org/document/7139395/,2015 IEEE International Conference on Robotics and Automation (ICRA),26-30 May 2015,ieeexplore
10.1109/ROBIO49542.2019.8961517,Robot Control in Human Environment using Deep Reinforcement Learning and Convolutional Neural Network,IEEE,Conferences,"Deep reinforcement learning (DRL) has been employed in numerous applications where complex decision-making is needed. Robot control in a human environment is an example. Such algorithm offers possibilities to achieve end-to-end training which learns from image directly. However, training on a physical robotic system under human environments using DRL is inefficient and even dangerous. Several recent works have used simulators for training models before implementing to physical robots. Although simulation provides efficiency to obtain DRL trained models, it poses challenges for the transformation from simulation to reality. Since a human environment is often cluttered, dynamic and complex, the policy trained with simulation images is not applicable for reality. Therefore, in this paper, we propose a DRL method to achieve end-to-end training in simulation, as well as to adapt to reality without any further finetune. Firstly, a Deep Deterministic Policy Gradient algorithm (DDPG) is employed to learn policy for robot control. Secondly, a pre-trained Convolutional Neural Network algorithm (CNN) is used to visually track the target in image. This technique provides the efficient and safe DRL training in simulation while offering robust application when a real robot is placed in dynamic human environment. Simulation and experiment are conducted for validation and can be seen in the attached video. The results have shown successful demonstration under various complex environments.",https://ieeexplore.ieee.org/document/8961517/,2019 IEEE International Conference on Robotics and Biomimetics (ROBIO),6-8 Dec. 2019,ieeexplore
10.1109/SAIS53221.2021.9483964,Robot First Aid: Autonomous Vehicles Could Help in Emergencies,IEEE,Conferences,"Safety is of critical importance in designing autonomous vehicles (AVs) that will be able to perform effectively in complex, mixed-traffic, real-world urban environments. Some prior research has looked at how to proactively avoid accidents with safe distancing and driver monitoring, but currently little research has explored strategies to recover afterwards from emergencies, from crime to natural disasters. The current short paper reports on our ongoing work using a speculative prototyping approach to explore this expansive design space, in the context of how a robot inside an AV could be deployed to support first aid. As a result, we present some proposals for how to detect emergencies, and examine and help victims, as well as lessons learned in prototyping. Thereby, our aim is to stimulate discussion and ideation that-by considering the prevalence of Murphy's law in our complex world, and the various technical, ethical, and practical concerns raised-could potentially lead to useful safety innovations.",https://ieeexplore.ieee.org/document/9483964/,2021 Swedish Artificial Intelligence Society Workshop (SAIS),14-15 June 2021,ieeexplore
10.1109/IROS.2010.5650949,Robot Learning by Demonstration with local Gaussian process regression,IEEE,Conferences,"In recent years there was a tremendous progress in robotic systems, and however also increased expectations: A robot should be easy to program and reliable in task execution. Learning from Demonstration (LfD) offers a very promising alternative to classical engineering approaches. LfD is a very natural way for humans to interact with robots and will be an essential part of future service robots. In this work we first review heteroscedastic Gaussian processes and show how these can be used to encode a task. We then introduce a new Gaussian process regression model that clusters the input space into smaller subsets similar to the work in [11]. In the next step we show how these approaches fit into the Learning by Demonstration framework of [2], [3]. At the end we present an experiment on a real robot arm that shows how all these approaches interact.",https://ieeexplore.ieee.org/document/5650949/,2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,18-22 Oct. 2010,ieeexplore
10.1109/IROS40897.2019.8968306,Robot Learning via Human Adversarial Games,IEEE,Conferences,"Much work in robotics has focused on “humanin-the-loop” learning techniques that improve the efficiency of the learning process. However, these algorithms have made the strong assumption of a cooperating human supervisor that assists the robot. In reality, human observers tend to also act in an adversarial manner towards deployed robotic systems. We show that this can in fact improve the robustness of the learned models by proposing a physical framework that leverages perturbations applied by a human adversary, guiding the robot towards more robust models. In a manipulation task, we show that grasping success improves significantly when the robot trains with a human adversary as compared to training in a self-supervised manner.",https://ieeexplore.ieee.org/document/8968306/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ICRA48506.2021.9560893,Robot Navigation in Constrained Pedestrian Environments using Reinforcement Learning,IEEE,Conferences,"Navigating fluently around pedestrians is a necessary capability for mobile robots deployed in human environments, such as buildings and homes. While research on social navigation has focused mainly on the scalability with the number of pedestrians in open spaces, typical indoor environments present the additional challenge of constrained spaces such as corridors and doorways that limit maneuverability and influence patterns of pedestrian interaction. We present an approach based on reinforcement learning (RL) to learn policies capable of dynamic adaptation to the presence of moving pedestrians while navigating between desired locations in constrained environments. The policy network receives guidance from a motion planner that provides waypoints to follow a globally planned trajectory, whereas RL handles the local interactions. We explore a compositional principle for multi-layout training and find that policies trained in a small set of geometrically simple layouts successfully generalize to more complex unseen layouts that exhibit composition of the structural elements available during training. Going beyond walls-world like domains, we show transfer of the learned policy to unseen 3D reconstructions of two real environments. These results support the applicability of the compositional principle to navigation in real-world buildings and indicate promising usage of multi-agent simulation within reconstructed environments for tasks that involve interaction. https://ai.stanford.edu/∼cdarpino/socialnavconstrained/",https://ieeexplore.ieee.org/document/9560893/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICNSC48988.2020.9238090,Robot Navigation with Map-Based Deep Reinforcement Learning,IEEE,Conferences,"This paper proposes an end-to-end deep reinforcement learning approach for mobile robot navigation with dynamic obstacles avoidance. Using experience collected in a simulation environment, a convolutional neural network (CNN) is trained to predict proper steering actions of a robot from its egocentric local occupancy maps, which accommodate various sensors and fusion algorithms. The trained neural network is then transferred and executed on a real-world mobile robot to guide its local path planning. The new approach is evaluated both qualitatively and quantitatively in simulation and realworld robot experiments. The results show that the map-based end-to-end navigation model is easy to be deployed to a robotic platform, robust to sensor noise and outperforms other existing DRL-based models in many indicators.",https://ieeexplore.ieee.org/document/9238090/,"2020 IEEE International Conference on Networking, Sensing and Control (ICNSC)",30 Oct.-2 Nov. 2020,ieeexplore
10.1109/RCAR49640.2020.9303282,Robot Programming by Demonstration with Oral Instructions for Assembly,IEEE,Conferences,"Programming by demonstration has been seen as a feasible solution for transferring human's skills to robots without too much time and labor cost. So far, applications of programming by demonstration in industrial assembly have attracted many researchers' attention. In practice, the robot control policy must give consideration to both efficiency and precision. Furthermore, it is difficult for one policy to handle the whole assembly process. To deal with these issues, a programming by demonstration with oral instructions method is developed in this article. With oral instructions, the demonstration data are segmented into pre-assembly phase and precise assembly phase. Moreover two related assembly policies are learned independently. Task-parametrized Gaussian mixture model and dynamic movement primitive are selected to prestructure the assembly policies for the two phases respectively on accounting of their properties. Effectiveness of the proposed method has been demonstrated by an assembly experiment.",https://ieeexplore.ieee.org/document/9303282/,2020 IEEE International Conference on Real-time Computing and Robotics (RCAR),28-29 Sept. 2020,ieeexplore
10.1109/IJCNN.2010.5596709,Robot guiding with obstacle avoidance algorithm for uncertain enviroments based on DTCNN,IEEE,Conferences,"This paper introduces two applications of Discrete Time Cellular Non-Linear Networks (DTCNN) in a robot guiding avoiding obstacles algorithm and prove the feasibility of both applications: a high data rate one, using a CMOS camera, and small data rate one, using ultrasonic sensors. The key value of DTCNNs is the locally connections and the parallelism in processing. These characteristics permit a hardware implementation, in our case over a Field Programmable Gate Arraw (FPGA) and a real time template based algorithm processing. A camera and an ultrasonic sensor are used as avoiding obstacles system, requiring both implementations, different inputs informations: the first one complex environment information and the later for basic situations information where impulsive response is required. Both input can have an enhanced behaviour within DTCNN structure.",https://ieeexplore.ieee.org/document/5596709/,The 2010 International Joint Conference on Neural Networks (IJCNN),18-23 July 2010,ieeexplore
10.1109/MECHATRONIKA.2014.7018286,Robot imitation of human arm via Artificial Neural Network,IEEE,Conferences,"In this study, a robot arm that can imitate human arm is designed and presented. The potentiometers are located to the joints of the human arm in order to detect movements of human gestures, and data were collected by this way. The collected data named as “movement of human arm” are classified by the help of Artificial Neural Network (ANN). The robot performs its movements according to the classified movements of the human. Real robot and real data are used in this study. Obtained results show that the learning application of imitating human action via the robot was successfully implemented. With this application, the platforms of robot arm in an industrial environment can be controlled more easily; on the other hand, robotic automation systems which have the capability of making a standard movements of a human can become more resistant to the errors.",https://ieeexplore.ieee.org/document/7018286/,Proceedings of the 16th International Conference on Mechatronics - Mechatronika 2014,3-5 Dec. 2014,ieeexplore
10.1109/ROBOT.2000.845355,Robot improv: using drama to create believable agents,IEEE,Conferences,"Believable agents usually depend upon explicit, model-based simulations of human emotions. This work appeals instead to the sensibilities of dramatic acting to create agents that are believable. The chosen task is that of comedy improvisation as it provides a solid demonstration of the agents' believability in the context of a high-level deliberative goal. Furthermore, this work employs physical robots as the actors, employing the real-time sensor values from the robots as inputs into the acting process. This paper describes the dramatic approach to acting that we used and describes the Java-based implementation on two Nomad Scout robots. Actual, improvised scripts created by the robots are included and analyzed.",https://ieeexplore.ieee.org/document/845355/,Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065),24-28 April 2000,ieeexplore
10.1109/ICRA48506.2021.9561545,Robot in a China Shop: Using Reinforcement Learning for Location-Specific Navigation Behaviour,IEEE,Conferences,"Robots need to be able to work in multiple different environments. Even when performing similar tasks, different behaviour should be deployed to best fit the current environment. In this paper, We propose a new approach to navigation, where it is treated as a multi-task learning problem. This enables the robot to learn to behave differently in visual navigation tasks for different environments while also learning shared expertise across environments. We evaluated our approach in both simulated environments as well as real-world data. Our method allows our system to converge with a 26% reduction in training time, while also increasing accuracy.",https://ieeexplore.ieee.org/document/9561545/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICSMC.2008.4811760,Robot navigation using KFLANN place field,IEEE,Conferences,"This paper presents an implementation of place cells for a robot navigation using the K-iterations fast learning artificial neural networks (KFLANN) clustering algorithm. The KFLANN possesses several desirable properties suitable for place cell robot navigation tasks. The technique proposed is able to autonomously adjust the resolution of cells according to the complexity of the environment. This is achieved through two parameters known as the tolerance and the vigilance of the network. In addition, a navigation system consisting of a topological map building and a place cell path planning strategy is presented. A physical implementation of the system was developed on an autonomous platform and actual results were obtained. The experimental results obtained indicate that the system was able to navigate successfully through the experimental space and also tolerate unexpected discrepancies arising from motor and sensor errors present in a real environment. Furthermore, despite abrupt changes in an environment due to the deliberate introduction of obstacles, the system was still able to cope without changes to the program. The experiment was also extended to include a kidnapped robot scenario and the results were favorable, indicating a positive use of allothetic cue recognition capabilities.",https://ieeexplore.ieee.org/document/4811760/,"2008 IEEE International Conference on Systems, Man and Cybernetics",12-15 Oct. 2008,ieeexplore
10.1109/IISA.2017.8316452,Robot painting recognition based on deep belief learning,IEEE,Conferences,"In a society where the number of elderly people is increasing rapidly, autonomous wheelchair robots are expected to be widely used for mobility of elderly people. In this paper we focus on how we can utilize wheelchair robots operating in museums. In this paper, we propose a deep learning based painting recognition and its application for the wheelchair robot. We consider the case when the user clicks on the painting he/she wants to see. The robot searches, recognizes and reaches the painting using deep learning. This is in difference from the most traditional methods where the robot explains the exhibited objects in a sequential order. The deep neural network generates a series of high dimensional features for each painting resulting in a high recognition rate. In our implementation, the wheelchair robot recognizes the painting in real time using the video stream.",https://ieeexplore.ieee.org/document/8316452/,"2017 8th International Conference on Information, Intelligence, Systems & Applications (IISA)",27-30 Aug. 2017,ieeexplore
10.1109/SMC.2016.7844958,Robot position control in pipes using Q Learning,IEEE,Conferences,"In the most critical hydro crisis in Brazil, 37 percent of the whole amount of treated water is wasted before reaching consumers. A robot with a position control to travel inside a pipe is an important step in the pursuit of an autonomous solution to detect and correct pipes failures. This paper shows a Q Learning controller algorithm implemented using a microcontroller in a mechanical body of a commercial pipe inspection robot. Using only the measurements of a gyroscope, and controlling the wheels' motors on the left and right sides, the controller learned the best set of movements to ride inside a 300mm sewer pipe, in the tested conditions. Real tests in a 300mm pipe were performed using the developed algorithm and it was compared to a random movement and to a straight forward movement.",https://ieeexplore.ieee.org/document/7844958/,"2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",9-12 Oct. 2016,ieeexplore
10.1145/1957656.1957814,Robot self-initiative and personalization by learning through repeated interactions,IEEE,Conferences,"We have developed a robotic system that interacts with the user, and through repeated interactions, adapts to the user so that the system becomes semi-autonomous and acts proactively. In this work we show how to design a system to meet a user's preferences, show how robot pro-activity can be learned and provide an integrated system using verbal instructions. All these behaviors are implemented in a real platform that achieves all these behaviors and is evaluated in terms of user acceptability and efficiency of interaction.",https://ieeexplore.ieee.org/document/6281377/,2011 6th ACM/IEEE International Conference on Human-Robot Interaction (HRI),8-11 March 2011,ieeexplore
10.1109/ROBIO.2011.6181679,"Robot self-preservation and adaptation to user preferences in game play, a preliminary study",IEEE,Conferences,"It is expected that in a near future, personal robots will be endowed with enough autonomy to function and live in an individual's home. This is while commercial robots are designed with default configuration and factory settings which may often be different to an individual's operating preferences. This paper presents how reinforcement learning is applied and utilised towards personalisation of a robot's behaviour. Two-level reinforcement learning has been implemented: first level is in charge of energy autonomy, i.e. how to survive, and second level is involved in adapting robot's behaviour to user's preferences. In both levels Q-learning algorithm has been applied. First level actions have been learnt in a simulated environment and then the results have been transferred to the real robot. Second level has been fully implemented in the real robot and learnt by human-robot interaction. Finally, experiments showing the performance of the system are presented.",https://ieeexplore.ieee.org/document/6181679/,2011 IEEE International Conference on Robotics and Biomimetics,7-11 Dec. 2011,ieeexplore
10.1109/ROMAN.1995.531984,Robot teaching with operating stick using the virtual reality system,IEEE,Conferences,"A new robot teaching system using the virtual reality technology is constructed. Operations in the point-to-point type robot teaching system are classified. Problems in the conventional system with data glove input device are clarified. Instead of data glove input, a new method using operating stick is proposed and the corresponding robot teaching with operating stick is presented. Experiments on robot teaching using operating stick are carried out and the results are discussed in detail. The effectiveness of the new method was confirmed by the experiment results.",https://ieeexplore.ieee.org/document/531984/,Proceedings 4th IEEE International Workshop on Robot and Human Communication,5-7 July 1995,ieeexplore
10.1109/RO-MAN47096.2020.9223428,Robot-Assisted Mindfulness Practice: Analysis of Neurophysiological Responses and Affective State Change,IEEE,Conferences,"Mindfulness is the state of paying attention to the present moment on purpose and meditation is the technique to obtain this state. This study aims to develop a robot assistant that facilitates mindfulness training by means of a Brain-Computer Interface (BCI) system. To achieve this goal, we collected EEG signals from two groups of subjects engaging in a meditative vs. non-meditative human-robot interaction (HRI) and evaluated cerebral hemispheric asymmetry, which is recognized as a well-defined indicator of emotional states. Moreover, using self-reported affective states, we strived to explain asymmetry changes based on pre- and post-experiment mood alterations. We found that unlike earlier meditation studies, the fronto-central activations in alpha and theta frequency bands were not influenced by robot-guided mindfulness practice, however there was a significantly greater right-sided activity in the occipital gamma band of Meditation group, which is attributed to increased sensory awareness and open monitoring. In addition, there was a significant main effect of Time on participant's self-reported affect, indicating an improved mood after interaction with the robot regardless of the interaction type. Our results suggest that EEG responses during robot-guided meditation hold promise in real-time detection and neurofeedback of mindful state to the user, however the experienced neurophysiological changes may differ based on the meditation practice and recruited tools. This study is the first to report EEG changes during mindfulness practice with a robot. We believe that our findings driven from an ecologically valid setting, can be used in development of future BCI systems that are integrated with social robots for health applications.",https://ieeexplore.ieee.org/document/9223428/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore
10.1109/RO-MAN47096.2020.9223566,Robust Real-Time Hand Gestural Recognition for Non-Verbal Communication with Tabletop Robot Haru,IEEE,Conferences,"In this paper, we present our work in close-distance non-verbal communication with tabletop robot Haru through hand gestural interaction. We implemented a novel hand gestural understanding system by training a machine-learning architecture for real-time hand gesture recognition with the Leap Motion. The proposed system is activated based on the velocity of a user's palm and index finger movement, and subsequently labels the detected movement segments under an early classification scheme. Our system is able to combine multiple gesture labels for recognition of consecutive gestures without clear movement boundaries. System evaluation is conducted on data simulating real human-robot interaction conditions, taking into account relevant performance variables such as movement style, timing and posture. Our results show robustness in hand gesture classification performance under variant conditions. We furthermore examine system behavior under sequential data input, paving the way towards seamless and natural real-time close-distance hand-gestural communication in the future.",https://ieeexplore.ieee.org/document/9223566/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore
10.1109/CCDC.2019.8832613,Robust Zhang Neural Network for Tracking Control of Parallel Robot Manipulators With Unknown Parameters,IEEE,Conferences,"Under the situation of parameter uncertainty, the tracking control of parallel robot manipulators is a challenging problem in robotic research. Unlike conventional Zhang neural network (ZNN) relying on the assumption that the robot parameter information is fully and accurately known, this paper proposes a robust Zhang neural network (RZNN) for tracking control problems solving of parallel robot manipulators in the absence of parameter information. The proposed RZNN features the full utilization of effector feedback information, and shows a robust tracking performance even with unknown robot parameter information. Then, the continuous-time model of the RZNN is discretized via Euler forward formula (EFF) for numerical implementation. Finally, comprehensive simulative experiments including robustness test verify the effectiveness of the RZNN model for the real-time tracking control of parallel robot manipulators with unknown parameters.",https://ieeexplore.ieee.org/document/8832613/,2019 Chinese Control And Decision Conference (CCDC),3-5 June 2019,ieeexplore
10.1109/HUMANOIDS.2014.7041487,Robust fall detection with an assistive humanoid robot,IEEE,Conferences,"Summary form only given. In this video we introduce a robot assistant that monitors a person in a household environment to promptly detect fall events. In contrast to the use of a fixed sensor, the humanoid robot will track and keep the moving person in the scene while performing daily activities. For this purpose, we extended the humanoid Nao<sup>1</sup> with a depth sensor<sup>2</sup> attached to its head. The tracking framework implemented with OpenNI<sup>3</sup> segments and tracks the person's position and body posture. We use a learning neural framework for processing the extracted body features and detecting abnormal behaviors, e.g. a fall event [1]. The neural architecture consists of a hierarchy of self-organizing neural networks for attenuating noise caused by tracking errors and detecting fall events from video stream in real time. The tracking application, the neural framework, and the humanoid actuators communicate over Robot Operating System (ROS)<sup>4</sup>. We use communication over the ROS network implemented with publisher-subscriber nodes. When a fall event is detected, Nao will approach the person and ask whether assistance is needed. In any case, Nao will take a picture of the scene that can be sent to the caregiver or a relative for further human evaluation and agile intervention. The combination of this sensor technology with our neural network approach allows to tailor the robust detection of falls independently from the background surroundings and in the presence of noise (tracking errors and occlusions) introduced by a real-world scenario. The video shows experiments run in a home-like environment.",https://ieeexplore.ieee.org/document/7041487/,2014 IEEE-RAS International Conference on Humanoid Robots,18-20 Nov. 2014,ieeexplore
10.1109/EURCON.2007.4400663,Role Selection Mechanism for the Soccer Robot System using Petri Net,IEEE,Conferences,"Robot soccer is a challenging platform for multi-agent research, involving topics such as real-time image processing and control, robot path planning, obstacle avoidance and machine learning. The system consists of a supervisory controller, and controllers for defending and goalkeeping robots. These controllers are designed using Petri net. The robot soccer game presents an uncertain and dynamic environment for cooperating agents. Dynamic role switching and formation control are crucial for a successful game. A soccer robot has to take an appropriate decision based on environment situation. With the role of a robot fixed as goalkeeper, the supervisor, according to the game situation, assigns the role of attacking or defending to the other robots and then respective controllers control the robots. The Petri net model is implemented in Petri net toolbox under MATLAB environment.",https://ieeexplore.ieee.org/document/4400663/,"EUROCON 2007 - The International Conference on ""Computer as a Tool""",9-12 Sept. 2007,ieeexplore
10.1109/ICIAS.2012.6306173,SCARA robot control using neural networks,IEEE,Conferences,"A SCARA industrial robot model is identified based on a 4-axis structure using Lagrangian mechanics, also the dynamic model for the electromechanical actuator and motion transmission systems is identified. A conventional PD controller is implemented and compared to neural networks control system to achieve precise position control of SCARA manipulator. The performance of the modeled system is simulated using several desired tracking motion for each joint. Neural networks control method has shown a remarkable improvement of tracking capabilities for the SCARA robot over conventional PD controller. The proposed neural network controller has the potential to accurately control real-time manipulator applications.",https://ieeexplore.ieee.org/document/6306173/,2012 4th International Conference on Intelligent and Advanced Systems (ICIAS2012),12-14 June 2012,ieeexplore
10.1109/ICRA48506.2021.9561020,SQRP: Sensing Quality-aware Robot Programming System for Non-expert Programmers,IEEE,Conferences,"Robot programming typically makes use of a set of mechanical skills that is acquired by machine learning. Because there is in general no guarantee that machine learning produces robot programs that are free of surprising behavior, the safe execution of a robot program must utilize monitoring modules that take sensor data as inputs in real time to ensure the correctness of the skill execution. Owing to the fact that sensors and monitoring algorithms are usually subject to physical restrictions and that effective robot programming is sensitive to the selection of skill parameters, these considerations may lead to different sensor input qualities such as the view coverage of a vision system that determines whether a skill can be successfully deployed in performing a task. Choosing improper skill parameters may cause the monitoring modules to delay or miss the detection of important events such as a mechanical failure. These failures may reduce the throughput in robotic manufacturing and could even cause a destructive system crash. To address above issues, we propose a sensing quality-aware robot programming system that automatically computes the sensing qualities as a function of the robot’s environment and uses the information to guide non-expert users to select proper skill parameters in the programming phase. We demonstrate our system framework on a 6DOF robot arm for an object pick-up task.",https://ieeexplore.ieee.org/document/9561020/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/IROS40897.2019.8967834,Sample-efficient Deep Reinforcement Learning with Imaginary Rollouts for Human-Robot Interaction,IEEE,Conferences,"Deep reinforcement learning has proven to be a great success in allowing agents to learn complex tasks. However, its application to actual robots can be prohibitively expensive. Furthermore, the unpredictability of human behavior in human-robot interaction tasks can hinder convergence to a good policy. In this paper, we present an architecture that allows agents to learn models of stochastic environments and use them to accelerate learning. We descirbe how an environment model can be learned online and used to generate synthetic transitions, as well as how an agent can leverage these synthetic data to accelerate learning. We validate our approach using an experiment in which a robotic arm has to complete a task composed of a series of actions based on human gestures. Results show that our approach leads to significantly faster learning, requiring much less interaction with the environment. Furthermore, we demonstrate how learned models can be used by a robot to produce optimal plans in real world applications.",https://ieeexplore.ieee.org/document/8967834/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/RoboSoft48309.2020.9116004,Scalable sim-to-real transfer of soft robot designs,IEEE,Conferences,"The manual design of soft robots and their controllers is notoriously challenging, but it could be augmented-or, in some cases, entirely replaced-by automated design tools. Machine learning algorithms can automatically propose, test, and refine designs in simulation, and the most promising ones can then be manufactured in reality (sim2real). However, it is currently not known how to guarantee that behavior generated in simulation can be preserved when deployed in reality. Although many previous studies have devised training protocols that facilitate sim2real transfer of control polices, little to no work has investigated the simulation-reality gap as a function of morphology. This is due in part to an overall lack of tools capable of systematically designing and rapidly manufacturing robots. Here we introduce a low cost, open source, and modular soft robot design and construction kit, and use it to simulate, fabricate, and measure the simulation-reality gap of minimally complex yet soft, locomoting machines. We prove the scalability of this approach by transferring an order of magnitude more robot designs from simulation to reality than any other method. The kit and its instructions can be found here: github.com/skriegman/sim2real4designs.",https://ieeexplore.ieee.org/document/9116004/,2020 3rd IEEE International Conference on Soft Robotics (RoboSoft),15 May-15 July 2020,ieeexplore
10.1109/CIMCA.2005.1631415,Self-Organization of Spiking Neural Network Generating Autonomous Behavior in a Real Mobile Robot,IEEE,Conferences,"In this paper, we study the relation between neural dynamics and robot behavior to develop self-organization algorithm of spiking neural network applicable to autonomous robot. We first formulated a spiking neural network model whose inputs and outputs were analog. We then implemented it into a miniature mobile robot Khepera. In order to see whether or not a solution(s) for the given task exists with the spiking neural network, the robot was evolved with the genetic algorithm (GA) in an environment. The robot acquired the obstacle avoidance and navigation task successfully, exhibiting the presence of the solution. Then, a self-organization algorithm based on the use-dependent synaptic potentiation and depotentiation was formulated and implemented into the robot. In the environment, the robot gradually organized the network and the obstacle avoidance behavior was formed. The time needed for the training was much less than with genetic evolution, approximately one fifth (1/5)",https://ieeexplore.ieee.org/document/1631415/,"International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC'06)",28-30 Nov. 2005,ieeexplore
10.1109/ICRA.2018.8460655,Self-Supervised Deep Reinforcement Learning with Generalized Computation Graphs for Robot Navigation,IEEE,Conferences,"Enabling robots to autonomously navigate complex environments is essential for real-world deployment. Prior methods approach this problem by having the robot maintain an internal map of the world, and then use a localization and planning method to navigate through the internal map. However, these approaches often include a variety of assumptions, are computationally intensive, and do not learn from failures. In contrast, learning-based methods improve as the robot acts in the environment, but are difficult to deploy in the real-world due to their high sample complexity. To address the need to learn complex policies with few samples, we propose a generalized computation graph that subsumes value-based model-free methods and model-based methods, with specific instantiations interpolating between model-free and model-based. We then instantiate this graph to form a navigation model that learns from raw images and is sample efficient. Our simulated car experiments explore the design decisions of our navigation model, and show our approach outperforms single-step and <i>N</i>-step double Q-learning. We also evaluate our approach on a real-world RC car and show it can learn to navigate through a complex indoor environment with a few hours of fully autonomous, self-supervised training. Videos of the experiments and code can be found at github.com/gkahn13/gcg.",https://ieeexplore.ieee.org/document/8460655/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/IJCNN.2002.1005521,Self-organization of behavioral primitives as multiple attractor dynamics: a robot experiment,IEEE,Conferences,"I investigated how behavior primitives are self-organized in my previously (Tani, 2001) proposed ""forwarding forward model"" neural network model in the context of robot imitation learning. The model is characterized with the so-called parametric biases which adaptively modulate for embedding different behavior patterns in a single recurrent neural net in a distributed way. My experiments, using a real robot, showed that a set of end-point and oscillatory behavior patterns are learned as fixed points and limit cycle dynamics respectively with adapting parametric bias for each. Further analysis showed that diverse behavior patterns other than learned patterns were also generated because of self-organization of the nonlinear map between the parametric biases and behavior patterns. It is concluded that such diversity emerges because primitives are represented distributedly in the network.",https://ieeexplore.ieee.org/document/1005521/,Proceedings of the 2002 International Joint Conference on Neural Networks. IJCNN'02 (Cat. No.02CH37290),12-17 May 2002,ieeexplore
10.1109/ICSMC.1997.625763,Self-organized learning and its implementation of robot movements,IEEE,Conferences,The self-organizing map algorithm using an artificial neural network originally developed by Kohonen and extended and modified later provides a distributed and autonomous learning procedure in engineering modeling of the human sensory-motor mapping mechanism. Its extension and adaptation to a control problem of a robot manipulator has been intensively discussed in past years. In this article the application of the self-organizing map algorithm to the generation of a visuo-motor map is focused on. A task-oriented inverse kinematic solution to a redundant manipulator is formed and real-time implementation of the map on a mechanical manipulator is performed.,https://ieeexplore.ieee.org/document/625763/,"1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation",12-15 Oct. 1997,ieeexplore
10.1109/ROBOT.2006.1642213,Self-organizing approach for robot's behavior imitation,IEEE,Conferences,"In this paper, an approach for behavior imitation using visual information was introduced. The imitation process is done by a self organizing neural network module. From several demonstrations of task operation, a vision system captures movement of the demonstrator mobile robot and associated objects in an operation field. Then, the movement features are extracted to present to an imitation engine. Finally, skill or decision policy from teacher's demonstration is extracted and embedded into a self organizing neural network without explicit external supervisory signals. A simple action selection algorithm for choosing action from learned network is proposed. The algorithm was implemented and tested on a simulated robot and a real mobile robot to imitate two simple robot soccer behaviors: approaching the target and obstacle avoidance. Furthermore, the concept of similarity measure is introduced to evaluate imitation performance from the demonstrator",https://ieeexplore.ieee.org/document/1642213/,"Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006.",15-19 May 2006,ieeexplore
10.1109/ROBOT.1996.506506,Semantic learning by an autonomous mobile robot,IEEE,Conferences,Describes the design and implementation of a learning system for control of an autonomous mobile robot. The robot learns reactive behaviors that allow it to retreat from potential collisions and to explore its environment by seeking out nearby objects. No external teaching input is required. Results from experiments with a real robot are presented. The learned reactive behaviors become the basis for the acquisition of more complex behaviors. Sensory/motor states are classified and then associated with lexical items to form a simple command language which is then used to direct the robot.,https://ieeexplore.ieee.org/document/506506/,Proceedings of IEEE International Conference on Robotics and Automation,22-28 April 1996,ieeexplore
10.1109/IROS.2017.8206048,Sensor fusion for robot control through deep reinforcement learning,IEEE,Conferences,"Deep reinforcement learning is becoming increasingly popular for robot control algorithms, with the aim for a robot to self-learn useful feature representations from unstructured sensory input leading to the optimal actuation policy. In addition to sensors mounted on the robot, sensors might also be deployed in the environment, although these might need to be accessed via an unreliable wireless connection. In this paper, we demonstrate deep neural network architectures that are able to fuse information generated by multiple sensors and are robust to sensor failures at runtime. We evaluate our method on a search and pick task for a robot both in simulation and the real world.",https://ieeexplore.ieee.org/document/8206048/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/FUZZ.2002.1006736,Sharing of exploring information using belief measure for multi robot exploration,IEEE,Conferences,"We consider the problem of sharing knowledge in multi-robot exploration. It is difficult for each robot to explore accurately because of sensor errors and dead reckoning errors. We use the belief measure as the expression of sensor values in each robot for exploring an unknown environment. Then, multiple robots share the knowledge about some targets or some obstacles of the environment considering the degree of trust for other robots. The key point of this method is that robots have not a common map, but each robot has his map for sharing exploring information. The effectiveness of our approach is demonstrated by a real experiment for the case of two mobile robots.",https://ieeexplore.ieee.org/document/1006736/,2002 IEEE World Congress on Computational Intelligence. 2002 IEEE International Conference on Fuzzy Systems. FUZZ-IEEE'02. Proceedings (Cat. No.02CH37291),12-17 May 2002,ieeexplore
10.1109/ICRAE48301.2019.9043822,Sim-to-real: Six-legged Robot Control with Deep Reinforcement Learning and Curriculum Learning,IEEE,Conferences,"Six-Iegged robots have higher stability and balance, which helps them face more complex terrain conditions, such as sand, swamp, mine and so forth. Therefore, it is necessary to study the gait planning of six-legged robot to adapt to complex terrain. In order to control six-legged robots to adapt to different terrains, we adopt the method of deep reinforcement learning (DRL) to plan the gait of six-legged robots. The main idea is training the robot through Actor-Critic network with proximal policy optimization (PPO), in which outputs are step length, step height and orientation of the robot. This is an end-to-end approach, which tries to make the robot learn by itself and finally achieve its safe arrival to the target point through complex terrains. In order to train a good model for our robots, simplified environment is adopted to accelerate the training process. We also use curriculum learning to speed up and optimize the training. Then, we verify the reliability of the method in simulation platform and finally transfer the learned model to real robot. Our experiment shows the effectiveness of deep reinforcement learning for locomotion of six-legged robots, the acceleration of the training process by means of curriculum learning, and the improvement of the training effect.",https://ieeexplore.ieee.org/document/9043822/,2019 4th International Conference on Robotics and Automation Engineering (ICRAE),22-24 Nov. 2019,ieeexplore
10.1109/RO-MAN50785.2021.9515431,Simplifying the A.I. Planning modeling for Human-Robot Collaboration,IEEE,Conferences,"For an effective deployment in manufacturing, Collaborative Robots should be capable of adapting their behavior to the state of the environment and to keep the user safe and engaged during the interaction. Artificial Intelligence (AI) enables robots to autonomously operate understanding the environment, planning their tasks and acting to achieve some given goals. However, the effective deployment of AI technologies in real industrial environments is not straightforward. There is a need for engineering tools facilitating communication and interaction between AI engineers and Domain experts. This paper proposes a novel software tool, called TENANT (Tool fostEriNg Ai plaNning in roboTics) whose aim is to facilitate the use of AI planning technologies by providing domain experts like e.g., production engineers, with a graphical software framework to synthesize AI planning models abstracting from syntactic features of the underlying planning formalism.",https://ieeexplore.ieee.org/document/9515431/,2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN),8-12 Aug. 2021,ieeexplore
10.1109/ICAR.2015.7251437,Simultaneous human-robot adaptation for effective skill transfer,IEEE,Conferences,"In this paper, we propose and implement a human-in-the loop robot skill synthesis framework that involves simultaneous adaptation of the human and the robot. In this framework, the human demonstrator learns to control the robot in real-time to make it perform a given task. At the same time, the robot learns from the human guided control creating a non-trivial coupled dynamical system. The research question we address is how this system can be tuned to facilitate faster skill transfer or improve the performance level of the transferred skill. In the current paper we report our initial work for the latter. At the beginning of the skill transfer session, the human demonstrator controls the robot exclusively as in teleoperation. As the task performance improves the robot takes increasingly more share in control, eventually reaching full autonomy. The proposed framework is implemented and shown to work on a physical cart-pole setup. To assess whether simultaneous learning has advantage over the standard sequential learning (where the robot learns from the human observation but does not interfere with the control) experiments with two groups of subjects were performed. The results indicate that the final autonomous controller obtained via simultaneous learning has a higher performance measured as the average deviation from the upright posture of the pole.",https://ieeexplore.ieee.org/document/7251437/,2015 International Conference on Advanced Robotics (ICAR),27-31 July 2015,ieeexplore
10.1109/ICCSE49874.2020.9201679,Small Agricultural Phenotype Robot and Its Navigation and Obstacle Avoidance in Parallel Walls,IEEE,Conferences,"With the development of robotics, computer vision and artificial intelligence, the study of Plant phenotyping has entered a stage of rapid growth. For robots can be used for a large-scale, automatic and sustainable phenotype collection and data processing, it has also been followed closely by more and more research institutions and international seed giants, but currently the more mature phenotype robots are huge in size and expensive in configuration. Although their accuracy are high, but the popularity are poor, so it is difficult to popularize on a large scale, which is not conducive to collect plant phenotype data in a wider space and for the more plant varieties. On the other side, the small phenotype robots have low cost, simple operation, and are more suitable for large-scale promotion. The current research on plant phenotype small robots is mainly based on small wheeled robots. The robot is equipped with visual and optical sensors for collecting plant information, and uses machine vision and various sensors to achieve the robot's movement, positioning and obstacle avoidance. This paper uses the small wheeled mobile robot to simulate the navigation and obstacle avoidance of the phenotype collecting robot in parallel walls, and its effectiveness is proved by simulation experiment and real machine test.",https://ieeexplore.ieee.org/document/9201679/,2020 15th International Conference on Computer Science & Education (ICCSE),18-22 Aug. 2020,ieeexplore
10.1109/SaCoNeT.2018.8585616,Smart Navigation of Mobile Robot Using Neural Network Controller,IEEE,Conferences,"The field of autonomous navigation of mobile robot is advancing so fast especially with the development of machine learning algorithms. This study aims to introduce a neural network controller that controls the trajectory and the obstacle avoidance of a non-holonomic mobile robot.We train the robot in environment containing multiple obstacles with different places. This paper includes both a kinematic and a dynamic study of a mobile robot. Different training schemes have been studied that tackle the learning objectives differently. The trained controller is producing the Pulse Width Modulation (PWM) signals that could be implemented in a microprocessor and validated by simulations. Unlike some other recent approaches, this work was validated by a 3D simulation which is similar to the real model.",https://ieeexplore.ieee.org/document/8585616/,2018 International Conference on Smart Communications in Network Technologies (SaCoNeT),27-31 Oct. 2018,ieeexplore
10.1109/ROBOT.2004.1308781,Software approach for the autonomous inspection robot MAKRO,IEEE,Conferences,"The sewer inspection robot MAKRO is an autonomous multi-segment robot with worm-like shape driven by wheels. It is currently under development in the project MAKRO-PLUS. The robot has to navigate autonomously within sewer systems. Its first tasks is to take water probes, analyze them onboard, and measure positions of manholes and pipes to detect pollution loaded sewage and to improve current maps of sewer systems. One of the challenging problems is the control software, which should enable the robot to navigate in the sewer system and perform the inspection tasks autonomously, while always taking care of its own safety. Tests in our test environment and in a real sewer system show promising results. This paper focuses on the software approach. To manage the complexity a layered architecture has been chosen, each layer defining a different level of abstraction. After determining the abstraction levels, we use different methods for implementation. For the highest abstraction level a standard AI-planning algorithm is used. For the next level, finite state automata has been chosen. For ""simple"" task implementation we use a modular C++ based method (MCA2), which is also used on the lowest software level.",https://ieeexplore.ieee.org/document/1308781/,"IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004",26 April-1 May 2004,ieeexplore
10.1109/ICCE46568.2020.9042995,Stroke Signs Detection System by SNS Agency Robot,IEEE,Conferences,"This paper proposes a system which implements the Cincinnati Prehospital Stroke Scale (CPSS), the widely used screening method for the initial symptoms of a stroke, in a communication robot. AI on cloud analyses an acquired video through a conversation with the robot in real time and automatically determines the abnormalities. The judgement result is informed to his/her families by SNS. This study implemented two of the three CPSS scales such as “Arms” and “Speech”, we confirmed that the system enables to acquire, analyze and notify the information in real time.",https://ieeexplore.ieee.org/document/9042995/,2020 IEEE International Conference on Consumer Electronics (ICCE),4-6 Jan. 2020,ieeexplore
10.1109/WCICA.2008.4592802,Study on robot perception system of multi-sensors information fusion based on fuzzy neural network,IEEE,Conferences,"This paper developed three subsystems of robot perceptive system: visual, aural and olfactory for a three DOF robot perceptive system, which can get the primary location of the target by aural sensor, the exact location and tailing of the target, and estimation the location parameter by CCD camera. The olfactory sensor was used to detect whether there were dangerous gases around or not. The multi-sensor fusion model and arithmetic based on fuzzy neural network were presented in this paper, design the input and output of every layer, utilized BP arithmetic to adjust the weight and the parameter of the fuzzy neural network and obtained different subject functions thereby created relevant fuzzy rules to actualize fuzzy decision. Finish the precise location and real-time tracking. Simulating the perceptive process of the robot used Matlab, obtained the curves of the practical output and the experiment output, validated the validity of using fuzzy neural network to fuse the visual and aural heterogeneous-sensors.",https://ieeexplore.ieee.org/document/4592802/,2008 7th World Congress on Intelligent Control and Automation,25-27 June 2008,ieeexplore
10.1109/IJCNN.2008.4634389,Supporting mixed initiative human-robot interaction: A script-based cognitive architecture approach,IEEE,Conferences,"As complex indoor-robot systems are developed and deployed into the real-world, the demand for human-robot interaction is increasing. Mixed-initiative human-robot interaction is a good method to coordinate actions of a human and a robot in a complementary fashion. In order to support such interactions, we employ scripts that are rich, flexible, and extensible for a robotpsilas interactions in a variety of situations. Scripts are amenable for expressing knowledge in an applicable form, especially describing a sequence of actions in organizing tasks. In this paper, we propose a script-based cognitive architecture for collaboration, which is based on three-level cognitive models. It incorporates dynamic Bayesian network (DBN) to automatically govern action sequences in the scripts and detect userpsilas intention or goal. Starting from an understanding of user initiatives, our intelligent task manager suggests the most relevant initiatives for an efficient collaboration. DBN has been evaluated in real indoor task scenarios for its efficacy in interaction reduction, error minimization, and task satisfaction.",https://ieeexplore.ieee.org/document/4634389/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/ICMA52036.2021.9512666,Target Detection and Tracking of Ground Mobile Robot Based on Improved Single Shot Multibox Detector Network,IEEE,Conferences,"To solve the problems of slow labeling speed of the traditional labellmg data set establishment method, and slow running speed of target classification and detection algorithm based on Single Shot Multibox Detector(SSD) deep learning network, this paper proposes a fast data set labeling algorithm and a fast SSD network for target real-time detection and tracking research. First, a data set is established quickly by using TLD target detection and tracking algorithms, cropping and mirroring methods are used to strengthen the data set. Then, SSD backbone network is improved based on depth-wise separable convolution to establish a fast SSD network. Finally, the ground mobile robot in RoboMasters(RM) competition is used as the detection and tracking target indoors and outdoors, as well as with other different scenarios with shield to test the real-time performance, accuracy and effectiveness of the algorithm. The results show that compared with traditional SSD network research, in terms of the analysis and processing system deployed on low-performance hardware, the improved fast SSD network can better meet the real-time requirements of target detection and tracking.",https://ieeexplore.ieee.org/document/9512666/,2021 IEEE International Conference on Mechatronics and Automation (ICMA),8-11 Aug. 2021,ieeexplore
10.1109/IROS.1999.812762,Task-model based human robot cooperation using vision,IEEE,Conferences,"In order to assist a human, the robot must recognize human motion in real time by vision, and must plan and execute the needed assistance motion based on the task purpose and the context. In this research, we tried to solve such problems. We defined the abstract task model, analyzed the human demonstration by using events and an event stack, and automatically generated the task models needed in the assistance by the robot. The robot planned and executed the appropriate assistance motions based on the task: models according to the human motions in the cooperation with the human. We implemented a 3D object recognition system and a human grasp recognition system by using trinocular stereo color cameras and a real time range finder. The effectiveness of these methods was tested through an experiment in which the human and the robotic hand assembled toy parts in cooperation.",https://ieeexplore.ieee.org/document/812762/,Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289),17-21 Oct. 1999,ieeexplore
10.1109/IEEECONF49454.2021.9382607,Teaching System for Multimodal Object Categorization by Human-Robot Interaction in Mixed Reality,IEEE,Conferences,"As service robots are becoming essential to support aging societies, teaching them how to perform general service tasks is still a major challenge preventing their deployment in daily-life environments. In addition, developing an artificial intelligence for general service tasks requires bottom-up, unsupervised approaches to let the robots learn from their own observations and interactions with the users. However, compared to the top-down, supervised approaches such as deep learning where the extent of the learning is directly related to the amount and variety of the pre-existing data provided to the robots, and thus relatively easy to understand from a human perspective, the learning status in bottom-up approaches is by their nature much harder to appreciate and visualize. To address these issues, we propose a teaching system for multimodal object categorization by human-robot interaction through Mixed Reality (MR) visualization. In particular, our proposed system enables a user to monitor and intervene in the robot's object categorization process based on Multimodal Latent Dirichlet Allocation (MLDA) to solve unexpected results and accelerate the learning. Our contribution is twofold by 1) describing the integration of a service robot, MR interactions, and MLDA object categorization in a unified system, and 2) proposing an MR user interface to teach robots through intuitive visualization and interactions.",https://ieeexplore.ieee.org/document/9382607/,2021 IEEE/SICE International Symposium on System Integration (SII),11-14 Jan. 2021,ieeexplore
10.1109/ICIA.2006.305788,The Design and Implementation of OpenGL-based Comprehensive Educational Robot System,IEEE,Conferences,"In this paper, the authors present the design and implementation of MountTai, a cost effective OpenGL based comprehensive educational robot system for China's primary and high school education. Firstly the system's goal and framework is introduced, then it is described the MountTai robot's functions and construction in hardware. The paper expatiates at length how VR technology is used to implement the system software as well as how the software's functions are designed to illustrate robotics in different perspectives relating to mechanics, electronics, communication, artificial intelligence, language programming. The Web-based teaching course dedicated to robot-DIY tutorials is also shown. Finally, concluding remarks for future works are given.",https://ieeexplore.ieee.org/document/4097992/,2006 IEEE International Conference on Information Acquisition,20-23 Aug. 2006,ieeexplore
10.1109/RCAR52367.2021.9517509,The Measuring ZMP of Self-Balancing Exoskeleton Robot is Calibrated by Using The Neural Network,IEEE,Conferences,"The exoskeleton robot is an auxiliary device to help the disabled people walk, and the self-balancing exoskeleton robot is one which is to keep balance without the assistance of external crutches. In order to keep the balance of the self-balancing exoskeleton robot, it is necessary to get the position of the Zero Moment Point by measuring the pressure of the footplate, and make the position of ZMP in range of supporting area. In this experiment, the footplate is used with the double-deck structure, this structure is compared with the single-deck structure, the double-dack structure will not lose the information of the collected ZMP without direct touch with the sensor, and it is lighter than another structure with dozens of sensors. But there is an inevitable structural coupling in the double-deck structure, which makes the ZMP have a large measurement error. In order to solve this problem, a novel idea is proposed, with the help of the powerful processing and learning capabilities of the neural network, four kinds of neural networks are used to calibrate measured position of ZMP so that reducing error of the measured ZMP. By comparing position of the actual ZMP before and after the calibration with the ideal position of ZMP and computing the errors to judge the effect of the calibration. Through experimental comparison, it is concluded that the different neural networks eliminate error of the measured ZMP in different extent. When the GRNN neural network is used to calibrate position of ZMP, the effect is the most ideal.",https://ieeexplore.ieee.org/document/9517509/,2021 IEEE International Conference on Real-time Computing and Robotics (RCAR),15-19 July 2021,ieeexplore
10.1109/ICMLC.2002.1174408,The approach of extracting features from the local environment for mobile robot,IEEE,Conferences,"A new data fusion method to extract features from the local environment for a mobile robot's navigation has been developed and implemented. This method, named the obstacle group, compresses data in a series of levels in order to reduce the quantity of data for communication between modules in a distributed single-robot system, or between all the robots and the central station in a multi-robot system. The method based on a grid map and an active window has strong adaptability and is real-time in a crowded environment. Experimental results demonstrate that the robot can successfully avoid collisions and plan its path by using this method.",https://ieeexplore.ieee.org/document/1174408/,Proceedings. International Conference on Machine Learning and Cybernetics,4-5 Nov. 2002,ieeexplore
10.1109/IJCNN.2008.4633777,"The development of a hybrid, distributed architecture for multiagent systems and its application in robot soccer",IEEE,Conferences,"Several issues still need to be unraveled in the development of multiagent systems equipped with global vision, as in robot soccer leagues. Here, we underscore three of them (1) real-time constraints on recognition of scene objects; (2) acquisition of environment knowledge; and (3) distribution and allocation of control competencies shared between the repertoire of the agentpsilas reactive behavior, and the central control entitypsilas strategic and deliberative behavior. The objective of this article is to describe the implementation of a distributed and hybrid reactive-deliberative control architecture for a multiagent system, equipped with global vision camera and agent local sensor and cameras. This multiple agent system was developed for application in robot soccer. We present the digital image processing techniques applied, as well as the proposed control architecture aimed at satisfying the constraints of this kind of application.",https://ieeexplore.ieee.org/document/4633777/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/CECNET.2011.5768706,The research application of inspection robot for the smart grid,IEEE,Conferences,"Catering to the new strategic project of smart grid, this paper introduces a design of high-voltage transmission inspection robot, which worked on earth wire and so that automatically inspection on the entire transmission line becomes the reality. Robot control system using hierarchical control structure, included remote management host, robot control ontology and motor drives. Under the auto-operation mode, it makes its own decisions for planning the sequence of operations according to knowledge data base without the upper layer's involvement. Using image recognition obstacle and expert data base, the combined method of using laser sensor over obstacles, the inspection robot autonomous obstacle had came true. The experiment and test results show that the inspection robot system has possessed the capabilities of navigation and inspection tasks on the power lines. It has a good application prospect.",https://ieeexplore.ieee.org/document/5768706/,"2011 International Conference on Consumer Electronics, Communications and Networks (CECNet)",16-18 April 2011,ieeexplore
10.1109/BEC.2010.5631008,Timed Automata based provably correct robot control,IEEE,Conferences,"This paper presents a feasibility study on the usage of Uppaal Timed Automata (UPTA) for deliberative level robotic control. The study is based on the Scrub Nurse Robot case-study. Our experience confirms that UPTA model based control enables the control loop to be defined and maintained during the robot operation autonomously with minimum human intervention. Specifically, in our robot architecture the control model is constructed automatically using unsupervised learning. Correctness of the model is verified on-the-fly against safety, reachability, and performance requirements. Finally, it is demonstrated that UPTA model based robot control, action planning and model updates have natural implementation based on existing model execution and conformance testing tool Uppaal Tron.",https://ieeexplore.ieee.org/document/5631008/,2010 12th Biennial Baltic Electronics Conference,4-6 Oct. 2010,ieeexplore
10.1109/CoASE.2014.6899348,Toward safe close-proximity human-robot interaction with standard industrial robots,IEEE,Conferences,"Allowing humans and robots to interact in close proximity to each other has great potential for increasing the effectiveness of human-robot teams across a large variety of domains. However, as we move toward enabling humans and robots to interact at ever-decreasing distances of separation, effective safety technologies must also be developed. While new, inherently human-safe robot designs have been established, millions of industrial robots are already deployed worldwide, which makes it attractive to develop technologies that can turn these standard industrial robots into human-safe platforms. In this work, we present a real-time safety system capable of allowing safe human-robot interaction at very low distances of separation, without the need for robot hardware modification or replacement. By leveraging known robot joint angle values and accurate measurements of human positioning in the workspace, we can achieve precise robot speed adjustment by utilizing real-time measurements of separation distance. This, in turn, allows for collision prevention in a manner comfortable for the human user.We demonstrate our system achieves latencies below 9.64 ms with 95% probability, 11.10 ms with 99% probability, and 14.08 ms with 99.99% probability, resulting in robust real-time performance.",https://ieeexplore.ieee.org/document/6899348/,2014 IEEE International Conference on Automation Science and Engineering (CASE),18-22 Aug. 2014,ieeexplore
10.1109/RO-MAN50785.2021.9515348,Towards Out-of-Sight Predictive Tracking for Long-Term Indoor Navigation of Non-Holonomic Person Following Robot<sup>*</sup>,IEEE,Conferences,"The ability to predict the movements of the target person allows a person following robot (PFR) to coexist with the person while still complying with the social norms. In human-robot collaboration, this is an essential requisite for long-term time-dependent navigation and not losing sight of the person during momentary occlusions that may arise from a crowd due to static or dynamic obstacles, other human beings, or intersections in the local surrounding. The PFR must not only traverse to the previously unknown goal position but also relocate the target person after the miss, and resume following. In this paper, we try to solve this as a coupled motion-planning and control problem by formulating a model predictive control (MPC) controller with non-linear constraints for a wheeled differential-drive robot. And, using a human motion prediction strategy based on the recorded pose and trajectory information of both the moving target person and the PFR, add additional constraints to the same MPC, to recompute the optimal controls to the wheels. We make comparisons with RNNs like LSTM and Early Relocation for learning the best-predicted reference path.MPC is best suited for complex constrained problems because it allows the PFR to periodically update the tracking information, as well as to adapt to the moving person’s stride. We show the results using a simulated indoor environment and lay the foundation for its implementation on a real robot. Our proposed method offers a robust person following behaviour without the explicit need for policy learning or offline computation, allowing us to design a generalized framework.",https://ieeexplore.ieee.org/document/9515348/,2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN),8-12 Aug. 2021,ieeexplore
10.1109/AIVR.2018.00060,Towards a Music Visualization on Robot (MVR) Prototype,IEEE,Conferences,"This paper presents a Music Visualization on Robot (MVR) prototype system which automatically links the flashlight, color and emotion of a robot through music. The MVR system is divided into three portions. Firstly, the system calculates the waiting time for a flashlight by beat tracking. Secondly, the system calculates the emotion correlated with music mood. Thirdly, the system links the color with emotion. To illustrate the prototype on a robot, the prototype implementation is based on a programmable robot called Zenbo because Zenbo has 8 LED light colors on 2 wheels and 24 face emotions to support various compositions.",https://ieeexplore.ieee.org/document/8613679/,2018 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),10-12 Dec. 2018,ieeexplore
10.1109/IROS40897.2019.8968166,Towards a Robot Architecture for Situated Lifelong Object Learning,IEEE,Conferences,"The ability to acquire knowledge incrementally and after deployment is of utmost importance for robots operating in the real world. Moreover, robots that have to operate alongside people need to be able to interact in a way that is intuitive for the users, e.g., by understanding and producing natural language. In this paper we present a first prototype of a robot architecture developed for situated lifelong object learning. The system is able to communicate with its users through natural language and perform object learning and recognition on the spot through situated interactions. In this first stage, we evaluate the system in terms of recognition accuracy which gives an indirect measure of the quality of the collected data with the proposed pipeline. Our results show that the robot can use this data for both learning and recognition with acceptable incremental performance. We also discuss limitations and steps that are necessary in order to improve performance as well as to shed some light on system usability.",https://ieeexplore.ieee.org/document/8968166/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/IJCNN.2008.4633874,Tracking a moving object with mobile robot based on vision,IEEE,Conferences,"The paper proposes a real-time tracking algorithm for a moving object with mobile robot based on vision using adaptive color matching and Kalman filter. The adaptive color matching can limit the region containing moving object on vision image plane. It can adjust color matching threshold to reduce the influence of lighting variations in the scene. Kalman filter is used as our prediction module to calculate motion vectors of moving object in the robot coordinate system. A view window containing the position of moving object estimated by Kalman filter is determined on image plane to reduce the image processing area. Color matching threshold can adjust itself adaptively in view window, which is used as an updating module. Experimental results show that the algorithm can adapt to lighting variations and has good tracking precision. It can also be implemented in real time.",https://ieeexplore.ieee.org/document/4633874/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/ICCICT.2012.6398104,Tracking of a target person using face recognition by surveillance robot,IEEE,Conferences,"In this paper we designed an experimental setup in order to have human-robot interaction i.e. first we are going to detect the face and after that we recognise the detected face. Afterwards we get the persons upper body torso color as a key feature. As we extracted the color feature we can compute the moments and also evaluate the motion parameters so that the surveillance robot can track the person accordingly. We also had introduced Speech module in order to have a interaction between the remote and base station. Surveillance robot must track the targeted person in a robust manner in indoor and outdoor environment in different light and dynamic varying conditions. In our proposed setup we use PCA which is going to recognise the person in a real time environment and should communicate to the person via speech module deployed in the surveillance robot, as face recognition works on real time environment we are getting average recognition rate of 98%. Experiment demonstration validates the efficient performance of the approach.",https://ieeexplore.ieee.org/document/6398104/,"2012 International Conference on Communication, Information & Computing Technology (ICCICT)",19-20 Oct. 2012,ieeexplore
10.1109/WHC.2017.7989900,Training in divergent and convergent force fields during 6-DOF teleoperation with a robot-assisted surgical system,IEEE,Conferences,"The technical skills of surgeons directly affect patient outcomes, yet how to train surgeons in a way that maximizes their learning speed and optimizes their performance is an open question. Recent studies in human motor learning have shown benefits of using force fields during training in point-to-point reaching tasks. Teleoperation systems enable the application of these force fields during the learning of more complex and real-world activities. We performed a study in which participants used the da Vinci Research Kit, a teleoperated robot-assisted surgical system, to perform a peg transfer task - a standard manipulation task used in minimally invasive surgery training. We investigated the effect on learning of training in three different groups: (1) without applying any force, (2) with a divergent force field, which pushes the user away from the desired path if they deviate from it, and (3) with a convergent force field, which pushes the user back to the desired path. We found no statistically significant differences in performance among the different training groups at the end of the experiment, but some differences were evident throughout the training. Thus, training in the divergent and convergent fields may involve different learning mechanisms, but does not worsen performance.",https://ieeexplore.ieee.org/document/7989900/,2017 IEEE World Haptics Conference (WHC),6-9 June 2017,ieeexplore
10.1109/ICINFA.2010.5512384,Trajectory planning of autonomous robot using advanced fuzzy controller,IEEE,Conferences,"To move a obstacle from a certain position to the predefined destination, robot needs various kinds of elements, like control algorithm, hardware, etc. General human can selects the distance between him and destination by numerical supervised learning, and establish the moving plan to the destination, generally called `Trajectory planning.' He(or she) can make a trajectory planning against the obstacles which is placed on the path to the destination. The kinds of obstacle can be active obstacle, which is moving on the trajectory, or passive obstacle, which is stationary one. For the kinds of stationary obstacle is height difference between road and sidewalk, stairs, a ramp. And the active obstacles include a human, a vehicle that shows active motion. To make a trajectory planning for the stationary obstacle, autonomous mobile robot can be assume that it is placed at the center of the map, and from the distance information between autonomous mobile robot and obstacles using the advanced fuzzy controller, mobile robot can make a trajectory planning. But in case of active moving obstacle, there are many components and information is needed to process because its moving trace should be considered in real time. As mentioned above, for the proposed algorithm, various kinds of things should be considered to move to the destination. Obviously, autonomous driving of the mobile robot can provide conveniences to the human-being with the various kinds of aspects. In this paper, obstacle avoidance algorithm for the trajectory planning using advanced fuzzy controller is described in detail, and demonstrated proposed algorithm through the real experiment.",https://ieeexplore.ieee.org/document/5512384/,The 2010 IEEE International Conference on Information and Automation,20-23 June 2010,ieeexplore
10.1109/ROBIO.2017.8324512,Trajectory tracking control of a unicycle-type mobile robot with a new planning algorithm,IEEE,Conferences,"Trajectory tracking control is one of the core techniques that impacts the auto-driving performance of a mobile robot. Whereas, there lacks enough work on reference trajectory generation and controller design for practical usage. This paper considers mobile robots with unicycle vehicle model on which most of automatic guided vehicles (AGVs) in real world are built. A new trajectory planning algorithm is developed, and is applied along with a control law considering constraints of the unicycle model and limited motor capabilities. The proposed algorithm is easy to be implemented on real world AGVs, and it yields a fast, accurate and robust trajectory tracking performance. The effectiveness of the algorithm is validated by simulation tests.",https://ieeexplore.ieee.org/document/8324512/,2017 IEEE International Conference on Robotics and Biomimetics (ROBIO),5-8 Dec. 2017,ieeexplore
10.1109/ROBOT.2010.5509160,Transfer of skills between human operators through haptic training with robot coordination,IEEE,Conferences,"In this paper, we discuss a coordinated haptic training architecture useful for transferring expertise in teleoperation-based manipulation between two human users. The objective is to construct a reality-based haptic interaction system for knowledge transfer by linking an expert's skill with robotic movement in real time. The benefits from this approach include 1) a representation of an expert's knowledge into a more compact and general form by learning from a minimized set of training samples, and 2) an increase in the capability of a novice user by coupling learned skills absorbed by a robotic system with haptic feedback. In order to evaluate our ideas and present the effectiveness of our paradigm, human handwriting is selected as our experiment of interest. For the learning algorithms, artificial neural network (ANN) and support vector machine (SVM) are utilized and their performances are compared. For the evaluation of the performance of the output of the learning modules, a modified Longest Common Subsequence (LCSS) algorithm is implemented. Results show that one or two experts' samples are sufficient for the generation of haptic training knowledge, which can successfully recreate manipulation motion with a robotic system and transfer haptic forces to an untrained user with a haptic device. Also in the case of handwriting comparison, the similarity measures result in up to an 88% match even with a minimized set of training samples.",https://ieeexplore.ieee.org/document/5509160/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/ROBOT.1998.680515,Unsupervised learning to recognize environments from behavior sequences in a mobile robot,IEEE,Conferences,"We describe the development of a mobile robot which does unsupervised learning for recognizing environments from behavior sequences. Most studies on recognizing an environment have tried to build precise geometric maps with high sensitive and global sensors. However such precise and global information may not be obtained in real environments. Furthermore unsupervised-learning is necessary for recognition in unknown environments without help of a teacher. Thus we attempt to build a mobile robot which does unsupervised-learning to recognize environments with low sensitivity and local sensors. The mobile robot is behavior-based and does wall-following in enclosures. Then the sequences of behaviors executed in each enclosure are transformed into input vectors for a self-organizing network. Learning without a teacher is done, and the robot becomes able to identify enclosures. Moreover we developed a method to identify environments independent of a start point using a partial sequence. We have fully implemented the system with a real mobile robot, and made experiments for evaluating the ability. As a result, we found out that the environment recognition was done well and our method was adaptive to noisy environments.",https://ieeexplore.ieee.org/document/680515/,Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),20-20 May 1998,ieeexplore
10.1109/ICEPDS.2018.8571820,Using Robot and Electric Drive in Fall Prediction,IEEE,Conferences,"The global aging phenomenon has motivated active research in human fall injuries. The fall prevention has hence become a popular topic in health informatics. An effective fall prevention paradigm could save millions of people from injury and avoid considerable casualties. Through comparison studies, detail-oriented simulations, and pragmatic field tests, an effective fall prediction method has been developed by authors. The finding is presented in this paper. Three techniques for fall prediction are discussed in this paper. A comparison technique to mimic the traditional stateless fall prediction techniques, along with an algorithm using artificial neural network, was first implemented in authors' previous paper. Then a robotic scheme was developed to simulate human fall by transplanting a proven fall prediction paradigm for humanoid robots with controlled electric drive systems to human subjects. Due to its simulation nature far from the human fall scenarios in reality, the robotic paradigm has obvious limits in real world applications. It was also used more like a reference framework for our last scheme. Eventually we built the third approach that eliminated the above limitation. The third approach is elaborated in this paper. Our test and simulation have proved its pragmatic superiority over other two approaches, along with vast majority of traditional paradigms.",https://ieeexplore.ieee.org/document/8571820/,2018 X International Conference on Electrical Power Drive Systems (ICEPDS),3-6 Oct. 2018,ieeexplore
10.1109/SPW50608.2020.00045,Using Taint Analysis and Reinforcement Learning (TARL) to Repair Autonomous Robot Software,IEEE,Conferences,"It is important to be able to establish formal performance bounds for autonomous systems. However, formal verification techniques require a model of the environment in which the system operates; a challenge for autonomous systems, especially those expected to operate over longer timescales. This paper describes work in progress to automate the monitor and repair of ROS-based autonomous robot software written for an apriori partially known and possibly incorrect environment model. A taint analysis method is used to automatically extract the dataflow sequence from input topic to publish topic, and instrument that code. A unique reinforcement learning approximation of MDP utility is calculated, an empirical and non-invasive characterization of the inherent objectives of the software designers. By comparing design (a-priori) utility with deploy (deployed system) utility, we show, using a small but real ROS example, that it's possible to monitor a performance criterion and relate violations of the criterion to parts of the software. The software is then patched using automated software repair techniques and evaluated against the original off-line utility.",https://ieeexplore.ieee.org/document/9283859/,2020 IEEE Security and Privacy Workshops (SPW),21-21 May 2020,ieeexplore
10.1109/HNICEM.2018.8666242,Utilization of Fuzzy Logic Control in a Waste Robot,IEEE,Conferences,"This research aimed to design and develop an autonomous robot to feasibly address waste disposal issues in common indoor places. The researchers explored opportunities to improve path planning using Fuzzy Logic Control (FLC). The researchers utilized a Microcontroller Unit (MCU) to control input proximity, sound, and infrared sensors, and output geared Direct Current (DC) motors through machine learning and electromechanical interface. The researchers simulated an adaptive algorithm using Mamdani-type FLC model, implemented using C programming language, then downloaded as machine code to a real prototype. Based on significant test results, the waste robot accurately detected human interference, a feature that would be pivotal in overcoming individual indifferences on waste management.",https://ieeexplore.ieee.org/document/8666242/,"2018 IEEE 10th International Conference on Humanoid, Nanotechnology, Information Technology,Communication and Control, Environment and Management (HNICEM)",29 Nov.-2 Dec. 2018,ieeexplore
10.1109/VR.2019.8798186,Virtual Reality and Photogrammetry for Improved Reproducibility of Human-Robot Interaction Studies,IEEE,Conferences,"Collecting data in robotics, especially human-robot interactions, traditionally requires a physical robot in a prepared environment, that presents substantial scalability challenges. First, robots provide many possible points of system failure, while the availability of human participants is limited. Second, for tasks such as language learning, it is important to create environments that provide interesting' varied use cases. Traditionally, this requires prepared physical spaces for each scenario being studied. Finally, the expense associated with acquiring robots and preparing spaces places serious limitations on the reproducible quality of experiments. We therefore propose a novel mechanism for using virtual reality to simulate robotic sensor data in a series of prepared scenarios. This allows for a reproducible dataset that other labs can recreate using commodity VR hardware. We demonstrate the effectiveness of this approach with an implementation that includes a simulated physical context, a reconstruction of a human actor, and a reconstruction of a robot. This evaluation shows that even a simple “sandbox” environment allows us to simulate robot sensor data, as well as the movement (e.g., view-port) and speech of humans interacting with the robot in a prescribed scenario.",https://ieeexplore.ieee.org/document/8798186/,2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),23-27 March 2019,ieeexplore
10.1109/AQTR.2006.254650,Vision based algorithm for path planning of a mobile robot by using cellular neural networks,IEEE,Conferences,"The paper presents a new vision based algorithm for mobile robots path planning in an environment with obstacles. Cellular neural networks (CNNs) processing techniques are used here for real time motion planning to reach a fixed target. The CNN methods have been considered a solution for image processing in autonomous mobile robots guidance. The choice of CNNs for the visual processing is based on the possibility of their hardware implementation in large networks on a single VLSI chip (cellular neural networks -universal machine, CNN-UM (Roska and Chua, 1993 and Kim et al., 2002))",https://ieeexplore.ieee.org/document/4022973/,"2006 IEEE International Conference on Automation, Quality and Testing, Robotics",25-28 May 2006,ieeexplore
10.1109/FSKD.2017.8393254,Visual control system design of wheeled inverted pendulum robot based on Beaglebone Black,IEEE,Conferences,"The wheeled inverted pendulum robot has broad prospects of applications in real life. It can use two coaxial wheels to achieve the body self-balancing, forward moving and turning. But the general wheeled inverted pendulum robot seldom has vision function to perceive enviromental change. In order to realize the robust visual control, a wheeled inverted-pendulum vision robot with attitude sensors, photoelectric encoders, ultrasonic sensors and so on is designed based on Beaglebone Black board. The moving object is separated in the space domain by obtaining the image sequence which is sent by a robot-mounted camera, and the modeling, identification and tracking of target sequence are implemented in the time domain. The balance PD, speed PI and steering PD controllers are designed to realize the dynamic balance, forward and steering function of the robot. To satisfy the functional requirements of the visual tracking system, an improved tracking-learning-detection algorithm based on kernelized correlation filtering is used, and a tracking anomaly based on spatial context is detected to determine the tracking state and reduce the error rate. Experimental results show that the robot reaches the requirement of design and achieves better visual control effectiveness.",https://ieeexplore.ieee.org/document/8393254/,"2017 13th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)",29-31 July 2017,ieeexplore
10.1109/ICRoM.2014.6990935,Visual servoing control of robot manipulator with Jacobian matrix estimation,IEEE,Conferences,"Visual servoing system is a system to control a robot by visual feedback. This paper presents a visual servoing control that drives the end-effector of a real robot manipulator from any arbitrary start position to the desired positions. The control law is obtained using inverse Jacobian matrix. Since there is not access to the model of the robot, artificial neural networks are used to estimate of inverse Jacobian matrix. There are many challenges in practical implementation such as: how to calculate Jacobian matrix, determining the intelligent structure for estimation of Jacobian matrix, recognition coordinate of each joint with image processing and changes in illumination. We proposed appropriate solutions to solve the mentioned challenges. The experimental results in the real robot show that the control system can move the end-effector to target positions from any arbitrary start position with good accuracy.",https://ieeexplore.ieee.org/document/6990935/,2014 Second RSI/ISM International Conference on Robotics and Mechatronics (ICRoM),15-17 Oct. 2014,ieeexplore
10.1109/ICMLA.2007.19,Web-based maze robot learning using fuzzy motion control system,IEEE,Conferences,"In this study, a Web based maze robot system has been designed and implemented for solving different maze algorithms with the help of machine learning approaches. The robot system has a map-based heuristic maze solving algorithm. The algorithm used for solving the maze is based on map creation and produces a control signal for robot direction. Robot motions were controlled by a fuzzy motion control system running on a chip. The control algorithm can be easily changed with the help of an algorithm via web interface controlled by the control center. The control center program powered by MATLAB functions and special libraries (image and control) in DELPHI manage all robotic activities. These activities are: command interpreter, image capturing, processing and serving, machine learning techniques, Web serving, database management, communication with robot, and compiling microcontroller programs. The results have shown that the proposed, designed and implemented system provides amazing new features to the applicants doing their real-time programming exercises on Web.",https://ieeexplore.ieee.org/document/4457243/,Sixth International Conference on Machine Learning and Applications (ICMLA 2007),13-15 Dec. 2007,ieeexplore
10.1109/ICCA.2009.5410442,Wheeled mobile robot control using virtual pheromones and neural networks,IEEE,Conferences,"This paper presents a novel approach on the implementation of the concept of ¿virtual pheromones¿ for use in controlling autonomous mobile robots. Rather than being deployed in the environment, the virtual pheromones are stored in a map of the environment maintained and updated by a ¿pheromone server¿. This map acts like a shared memory for all the agents, by means of a radio communication link between each agent and the pheromone server. No direct communication between agents is required. The pheromone server can be implemented on a regular computer, a handheld device, or an embedded controller carried by a leader robot. The technique described is equally applicable for guiding individual robot and robot swarms. The experiments, performed with mobile robot Pioneer 3-DX show that this method allows significant simplification and cost reduction of the autonomous agents. Several possible applications are discussed.",https://ieeexplore.ieee.org/document/5410442/,2009 IEEE International Conference on Control and Automation,9-11 Dec. 2009,ieeexplore
10.1109/ICAE50557.2020.9350386,XNOR-YOLO: The High Precision of The Ball and Goal Detecting on The Barelang-FC Robot Soccer,IEEE,Conferences,"The essential part in developing the humanoid robot which is able to play soccer is the vision system. The vision system needs to be fast and accurate in detecting the surrounding objects on the field such as the ball, goal, teammates, or even the opponent. One of the powerful methods which was able to generate the object detection quickly with high accuracy was the deep learning. However, this method proceeded a huge computation. Even if it was generated on the GPU, it would still generat a low speed of detecting. Therefore, the high precision and fast detecting of the object method need to be considered in this area. In order to overcome this problem, we proposed the combination of the XNOR-Network (XNOR-Net) towards YOLOv3 running on the GPU with the same layer configuration as the tinyYOLO. To testify the performance of this method, some experiments has been carried out in real-time application by implementing it in the NVDIA Jetson TX1 GPU. From the experiment results, this method is able to detect the object faster than other object detection in detecting the ball and goal colored by white and generated 30 FPS in detecting each object.",https://ieeexplore.ieee.org/document/9350386/,2020 3rd International Conference on Applied Engineering (ICAE),7-8 Oct. 2020,ieeexplore
10.1109/CBS.2018.8612261,sEMG-Based Torque Estimation Using Time-Delay ANN for Control of an Upper-Limb Rehabilitation Robot,IEEE,Conferences,"Robotic-assisted rehabilitation of the upper limb following neurological injury can achieve best possible functional recovery when patients are engaged in the therapy. However, implementation of active training is still difficult as it's challenging to detect human motion intention online and impose corresponding robot control. This paper introduces a novel upper-limb rehabilitation robot, and proposes a sEMG-driven (sEMG: surface Electromyography) torque estimation model based on artificial neural networks (ANN). The robot has three DOFs, of which the first two DOFs adopt a planar parallel structure, and the wrist module has an exoskeleton form. In this study, we design an impedance controller and an admittance controller for the first two DOFs and the wrist module, respectively. Specifically, for the first two DOFs, the assistance/resistance force at the end-effector was controlled according to its motions and desired interaction impedance; for the wrist module, an sEMG armband was used to collect 8 channels of sEMG signals from the forearm muscles, and a time-delay ANN model was developed to estimate the wrist pronation/supination torque, based on which the wrist rotation was controlled according to the human motion intention. To overcome the overfitting problem, besides the experimental samples of wrist rotation, both resting and co-contraction samples were collected for training. Finally, combining with the design of a virtual reality game and force fields, the proposed methods were implemented and tested experimentally on the upper-limb rehabilitation robot.",https://ieeexplore.ieee.org/document/8612261/,2018 IEEE International Conference on Cyborg and Bionic Systems (CBS),25-27 Oct. 2018,ieeexplore
10.1109/TSMCC.2004.840063,"""Sticky Hands"": learning and generalization for cooperative physical interactions with a humanoid robot",IEEE,Journals,"""Sticky Hands"" is a physical game for two people involving gentle contact with the hands. The aim is to develop relaxed and elegant motion together, achieve physical sensitivity-improving reactions, and experience an interaction at an intimate yet comfortable level for spiritual development and physical relaxation. We developed a control system for a humanoid robot allowing it to play Sticky Hands with a human partner. We present a real implementation including a physical system, robot control, and a motion learning algorithm based on a generalizable intelligent system capable itself of generalizing observed trajectories' translation, orientation, scale and velocity to new data, operating with scalable speed and storage efficiency bounds, and coping with contact trajectories that evolve over time. Our robot control is capable of physical cooperation in a force domain, using minimal sensor input. We analyze robot-human interaction and relate characteristics of our motion learning algorithm with recorded motion profiles. We discuss our results in the context of realistic motion generation and present a theoretical discussion of stylistic and affective motion generation based on, and motivating cross-disciplinary research in computer graphics, human motion production and motion perception.",https://ieeexplore.ieee.org/document/1522534/,"IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)",Nov. 2005,ieeexplore
10.1109/ACCESS.2020.2983488,3D Semantic Map Construction Using Improved ORB-SLAM2 for Mobile Robot in Edge Computing Environment,IEEE,Journals,"Although the existing localization and mapping (SLAM) technology of indoor mobile robot has made great development, its intelligence and environmental perception ability still cannot meet the needs of service and inspection. Therefore, based on edge computing environment, a 3D semantic map construction of mobile robot based on improved ORB-SALM2 is proposed. Firstly, the improved yolov3 algorithm is used to detect indoor objects, and then the real-time semantic segmentation network model based on deep learning is used to segment indoor objects to achieve the classification of pixel points of objects on two-dimensional images, and BAFF feature fusion algorithm is introduced to improve the accuracy of semantic segmentation model. Then, through the SLAM system, we estimate the pose of the image in the result of semantic segmentation, and use the depth information to project it into the three-dimensional environment to build the three-dimensional semantic map. Finally, the experiment platform of mobile robot is built to verify the stability of ORB-D and thermal imaging sensor registration technology, the accuracy and real-time of building three-dimensional environment thermal field map, and the accuracy of robot positioning using thermal infrared and depth image.",https://ieeexplore.ieee.org/document/9047931/,IEEE Access,2020,ieeexplore
10.1109/TAMD.2011.2112766,A Biologically Inspired Architecture for an Autonomous and Social Robot,IEEE,Journals,"Lately, lots of effort has been put into the construction of robots able to live among humans. This fact has favored the development of personal or social robots, which are expected to behave in a natural way. This implies that these robots could meet certain requirements, for example, to be able to decide their own actions (autonomy), to be able to make deliberative plans (reasoning), or to be able to have an emotional behavior in order to facilitate human-robot interaction. In this paper, the authors present a bioinspired control architecture for an autonomous and social robot, which tries to accomplish some of these features. In order to develop this new architecture, authors have used as a base a prior hybrid control architecture (AD) that is also biologically inspired. Nevertheless, in the later, the task to be accomplished at each moment is determined by a fix sequence processed by the Main Sequencer. Therefore, the main sequencer of the architecture coordinates the previously programmed sequence of skills that must be executed. In the new architecture, the main sequencer is substituted by a decision making system based on drives, motivations, emotions, and self-learning, which decides the proper action at every moment according to robot's state. Consequently, the robot improves its autonomy since the added decision making system will determine the goal and consequently the skills to be executed. A basic version of this new architecture has been implemented on a real robotic platform. Some experiments are shown at the end of the paper.",https://ieeexplore.ieee.org/document/5711644/,IEEE Transactions on Autonomous Mental Development,Sept. 2011,ieeexplore
10.1109/ACCESS.2021.3091642,A Human-Robot Interaction System Calculating Visual Focus of Human’s Attention Level,IEEE,Journals,"Attention is the mental awareness of human on a particular object or a piece of information. The level of attention indicates how intense the focus is on an object or an instance. In this study, several types of human attention level have been observed. After introducing image segmentation and detection technique for facial features, eyeball movement and gaze estimation were measured. Eye movement were assessed using the video data, and a total of 10197 data instances were manually labelled for the attention level. Then Artificial Neural Network (ANN) and Recurrent Neural Network-Long Short Term Memory (LSTM) based Deep learning (DL) architectures have been proposed for analysing the data. Next, the trained DL model has been implanted into a robotic system that is capable of detecting various features; ultimately leading to the calculation of visual attention for reading, browsing, and writing purposes. This system is capable of checking the attention level of the participants and also can detect if participants are present or not. Based on a certain level of visual focus of attention (VFOA), this system interacts with the person, generates awareness and establishes verbal or visual communication with that person. The proposed ML techniques have achieved almost 99.24% validation accuracy and 99.43% test accuracy. It is also shown in the comparative study that, since the dataset volumes are limited, ANN is more suitable for attention level calculation than RNN-LSTM. We hope that the implemented robotic structure manifests the real-world implication of the proposed method.",https://ieeexplore.ieee.org/document/9462086/,IEEE Access,2021,ieeexplore
10.1109/TAMD.2011.2164404,A Multiple Context Brain for Experiments With Robot Consciousness,IEEE,Journals,"The PURR-PUSS system (PP) is a versatile model of a human-like brain, designed to be implemented in parallel hardware and embodied in the head of a robot moving in the real world. The aim of the research with PP is to try out mechanisms for learning, intelligence and consciousness. Limitations of resources have dictated that the experiments with PP are made on a personal computer by simulating the brain and robot body in a microworld. The unique features of PP are multiple context and novelty-seeking. In this paper, a squash-pop microworld is described first, so that concrete examples can be given for a brief review of the PP system, followed by two new features called trail memory, to realize Baars' global workspace, and belief memory, to realize Rosenthal's higher order thoughts and Johnson-Laird's conscious reasoning. The extended system, PP*, is designed to give consciousness to the subconscious PP, but higher order thoughts and conscious reasoning prove to be elusive. A definition of a conscious robot provides a measure of progress.",https://ieeexplore.ieee.org/document/5986693/,IEEE Transactions on Autonomous Mental Development,Dec. 2011,ieeexplore
10.1109/TSMC.2013.2297398,A Multiple-Feature and Multiple-Kernel Scene Segmentation Algorithm for Humanoid Robot,IEEE,Journals,"This paper presents a multiple-feature and multiple-kernel support vector machine (MFMK-SVM) methodology to achieve a more reliable and robust segmentation performance for humanoid robot. The pixel wise intensity, gradient, and C1 SMF features are extracted via the local homogeneity model and Gabor filter, which would be used as inputs of MFMK-SVM model. It may provide multiple features of the samples for easier implementation and efficient computation of MFMK-SVM model. A new clustering method, which is called feature validity-interval type-2 fuzzy C-means (FV-IT2FCM) clustering algorithm, is proposed by integrating a type-2 fuzzy criterion in the clustering optimization process to improve the robustness and reliability of clustering results by the iterative optimization. Furthermore, the clustering validity is employed to select the training samples for the learning of the MFMKSVM model. The MFMK-SVM scene segmentation method is able to fully take advantage of the multiple features of scene image and the ability of multiple kernels. Experiments on the BSDS dataset and real natural socene images demonstrate the superior performance of our proposed method.",https://ieeexplore.ieee.org/document/6717184/,IEEE Transactions on Cybernetics,Nov. 2014,ieeexplore
10.1109/TSMC.2019.2956321,A Novel Approach to Image-Sequence-Based Mobile Robot Place Recognition,IEEE,Journals,"Visual place recognition is a challenging problem in simultaneous localization and mapping (SLAM) due to a large variability of the scene appearance. A place is usually described by a single-frame image in conventional place recognition algorithms. However, it is unlikely to completely describe the place appearance using a single frame image. Moreover, it is more sensitive to the change of environments. In this article, a novel image-sequence-based framework for place detection and recognition is proposed. Rather than a single frame image, a place is represented by an image sequence in this article. Position invariant robust feature (PIRF) descriptors are extracted from images and processed by the incremental bag-of-words (BoWs) for feature extraction. The robot automatically partitions the sequentially acquired images into different image sequences according to the change of the environmental appearance. Then, the echo state network (ESN) is applied to model each image sequence. The resultant states of the ESN are used as features of the corresponding image sequence for place recognition. The proposed method is evaluated on two public datasets. Experimental comparisons with the FAB-MAP 2.0 and SeqSLAM are conducted. Finally, a real-world experiment on place recognition with a mobile robot is performed to further verify the proposed method.",https://ieeexplore.ieee.org/document/8931657/,"IEEE Transactions on Systems, Man, and Cybernetics: Systems",Sept. 2021,ieeexplore
10.1109/ACCESS.2021.3105102,A Novel Maximin-Based Multi-Objective Evolutionary Algorithm Using One-by-One Update Scheme for Multi-Robot Scheduling Optimization,IEEE,Journals,"With the continuous development of E-commerce, warehouse logistics is also facing emerging challenges, including more batches of orders and shorter order processing cycles. When more orders need to be processed simultaneously, some existing task scheduling methods may not be able to give a suitable plan, which delays order processing and reduces the efficiency of the warehouse. Therefore, the intelligent warehouse system that uses autonomous robots for automated storage and intelligent order scheduling is becoming mainstream. Based on this concept, we propose a multi-robot cooperative scheduling system in the intelligent warehouse. The aim of the multi-robot cooperative scheduling system of the intelligent storage is to drive many robots in an intelligent warehouse to perform the distributed tasks in an optimal (e.g., time-saving and energy-conserved) way. In this paper, we propose a multi-robot cooperative task scheduling model in the intelligent warehouse. For this model, we design a maximin-based multi-objective algorithm, which uses a one-by-one update scheme to select individuals. In this algorithm, two indicators are devised to discriminate the equivalent individuals with the same maximin fitness value in the environmental selection process. The results on benchmark test suite show that our algorithm is indeed a useful optimizer. Then it is applied to settle the multi-robot scheduling problem in the intelligence warehouse. Simulation experiment results demonstrate the efficiency of the proposed algorithm on the real-world scheduling problem.",https://ieeexplore.ieee.org/document/9514575/,IEEE Access,2021,ieeexplore
10.1109/JSEN.2020.3042665,A Searching Space Constrained Partial to Full Registration Approach With Applications in Airport Trolley Deployment Robot,IEEE,Journals,"For airports with high passenger and luggage flows, a large number of staff members have to be hired to deploy the scattered passenger luggage trolleys. To release humans from the repetitive and laborious job, we develop an autonomous trolley deployment robot to detect, transport and collect the scattered idle trolleys to recycling points. This paper will firstly illustrate the entire collection pipeline of the deployment robot system and then address the key challenge: partial to full point set registration. With the perception framework, the robot can detect the idle trolleys and acquire the pose of the trolleys on the ground, and then capture the trolley from behind, along the same direction for subsequent grasping and manipulation. With RGB-D camera and a segmentation Convolutional Neural Network, the robot can generate a partial surface point cloud of the detected trolley. The resulting point cloud, data and a pre-scanned full trolley point cloud, model, are matched by an implicit pose. To tackle the low accuracy and long computation time issues, a novel searching space-constrained point set registration algorithm is proposed to register the two overlapping point sets. Based on Branch-and-Bound (BnB) mechanism, the error between data and model is iteratively optimized. The constraint of searching space speeds up the global searching of the optimal pose, by pruning the candidate spaces which is impossible to contain the optimal result. To evaluate the performance, an airport trolley segmentation dataset and a point cloud dataset for registration are constructed. Experimental results on the datasets and synthetic dataset show that our method achieves higher accuracy and success rate than the previous methods. The experiments demonstrated in video clips validate the developed system works in real-world applications.",https://ieeexplore.ieee.org/document/9281085/,IEEE Sensors Journal,"15 May15, 2021",ieeexplore
10.1109/JPROC.2018.2840045,A Value-Driven Eldercare Robot: Virtual and Physical Instantiations of a Case-Supported Principle-Based Behavior Paradigm,IEEE,Journals,"In this paper, a case-supported principle-based behavior paradigm is proposed to help ensure ethical behavior of autonomous machines. We argue that ethically significant behavior of autonomous systems should be guided by explicit ethical principles determined through a consensus of ethicists. Such a consensus is likely to emerge in many areas in which autonomous systems are apt to be deployed and for the actions they are liable to undertake. We believe that this is the case since we are more likely to agree on how machines ought to treat us than on how human beings ought to treat one another. Given such a consensus, particular cases of ethical dilemmas where ethicists agree on the ethically relevant features and the right course of action can be used to help discover principles that balance these features when they are in conflict. Such principles not only help ensure ethical behavior of complex and dynamic systems but also can serve as a basis for justification of this behavior. The requirements, methods, implementation, and evaluation components of the paradigm are detailed as well as its instantiation in both a simulated and real robot functioning in the domain of eldercare.",https://ieeexplore.ieee.org/document/8500162/,Proceedings of the IEEE,March 2019,ieeexplore
10.1109/JAS.2017.7510622,A facial expression emotion recognition based human-robot interaction system,IEEE,Journals,"A facial expression emotion recognition based human-robot interaction (FEER-HRI) system is proposed, for which a four-layer system framework is designed. The FEER-HRI system enables the robots not only to recognize human emotions, but also to generate facial expression for adapting to human emotions. A facial emotion recognition method based on 2D-Gabor, uniform local binary pattern (LBP) operator, and multiclass extreme learning machine (ELM) classifier is presented, which is applied to real-time facial expression recognition for robots. Facial expressions of robots are represented by simple cartoon symbols and displayed by a LED screen equipped in the robots, which can be easily understood by human. Four scenarios, i.e., guiding, entertainment, home service and scene simulation are performed in the human-robot interaction experiment, in which smooth communication is realized by facial expression recognition of humans and facial expression generation of robots within 2 seconds. As a few prospective applications, the FEER-HRI system can be applied in home service, smart home, safe driving, and so on.",https://ieeexplore.ieee.org/document/8039024/,IEEE/CAA Journal of Automatica Sinica,2017,ieeexplore
10.1109/TNSRE.2020.3038175,AI Therapist Realizing Expert Verbal Cues for Effective Robot-Assisted Gait Training,IEEE,Journals,"Repetitive and specific verbal cues by a therapist are essential in aiding a patient's motivation and improving the motor learning process. The verbal cues comprise various expressions, sentences, volumes, and timings, depending on the therapist's proficiency. This paper proposes an AI therapist (AI-T) that implements the verbal cues of professional therapists having extensive experience with robot-assisted gait training using the SUBAR for stroke patients. The AI-T was developed using a neuro-fuzzy system, a machine learning technique leveraging the benefits of fuzzy logic and artificial neural networks. The AI-T was trained with the professional therapist's verbal cue data, as well as clinical and robotic data collected from robot-assisted gait training with real stroke patients. Ten clinical data and 16 robotic data are input variables, and six verbal cues are output variables. Fifty-eight stroke patients wore the SUBAR, a gait training robot, and participated in the robot-assisted gait training. A total of 9059 verbal cue data, 580 clinical data of stroke patients, and 144 944 robotic data were collected from 693 training sessions. Test results show that the trained AI-T can implement six types of verbal cues with 93.7% accuracy for the 1812 verbal cue data of the professional therapist. Currently, the trained AI-T is deployed in the SUBAR and provides six verbal cues to stroke patients in robot-assisted gait training.",https://ieeexplore.ieee.org/document/9260225/,IEEE Transactions on Neural Systems and Rehabilitation Engineering,Dec. 2020,ieeexplore
10.1109/TCDS.2018.2846778,Adaptive Behavior Acquisition of a Robot Based on Affective Feedback and Improvised Teleoperation,IEEE,Journals,"In socially assistive robotics, especially for children with autism spectrum disorder (ASD), adapting the behavior of the robot according to the personal characteristics of each individual is one of the important challenges. Machine learning techniques are promising approaches to endow a robot with the capability of adapting its behavior through the interaction. It is critical to prepare a rich data set such as a set of behaviors with teaching signals for each individual with ASD to allow application of the state-of-the-art machine learning techniques; however, this is typically difficult to prepare in advance owing to the diverseness of ASD and the complexity of the motion design of the robot. This paper proposes a framework to acquire the personalized behavior set of a robot by combining a robot teleoperation method and a wearable device for detecting the affective cue of a child with ASD while interacting with the robot. The developed system allows the human operator to improvise the robot's behavior flexibly in real-time to explore the preferred interaction manner and motion patterns of each child. The preferred motion patterns are extracted and evaluated based on the affective state of the child estimated by the wearable device, and stored in the personal database for each individual with ASD. We conducted a free-interaction experiment with ten participants with ASD and demonstrated that the proposed system successfully described the interaction between the robot and the participant for acquiring the appropriate behaviors of the robot.",https://ieeexplore.ieee.org/document/8383948/,IEEE Transactions on Cognitive and Developmental Systems,Sept. 2019,ieeexplore
10.1109/TCST.2012.2191969,Adaptive PD Controller Modeled via Support Vector Regression for a Biped Robot,IEEE,Journals,"The real-time balance control of an eight link biped robot using a zero moment point (ZMP) dynamic model is difficult due to the processing time of the corresponding equations. To overcome this limitation, an intelligent computing control technique is used. This technique is based on support vector regression (SVR). The method uses the ZMP error and its variation as inputs, and the output is the correction of the robot's torso necessary for its sagittal balance. The SVR is trained based on simulation data and their performance is verified with a real biped robot. The ZMP is calculated by reading four force sensors placed under each robot's foot. The gait implemented in this biped is similar to a human gait that is acquired and adapted to the robot's size. Some experiments are presented, and the results show that the implemented gait combined with the SVR controller can be used to control this biped robot. The SVR controller performs the control in 0.2 ms.",https://ieeexplore.ieee.org/document/6180212/,IEEE Transactions on Control Systems Technology,May 2013,ieeexplore
10.1109/JIOT.2020.2979413,Adversarial Learning-Enabled Automatic WiFi Indoor Radio Map Construction and Adaptation With Mobile Robot,IEEE,Journals,"Location-based service (LBS) has become an indispensable part of our daily lives. Realizing accurate LBS in indoor environments is still a challenging task. WiFi fingerprinting-based indoor positioning system (IPS) has achieved encouraging results recently, but the time and labor overhead of constructing a dense WiFi radio map remains the key bottleneck that hinders it for real-world large-scale implementation. In this article, we propose WiGAN an automatic fine-grained indoor ratio map construction and the adaptation scheme empowered by the Gaussian process regression conditioned least-squares generative adversarial networks (GPR-GANs) with a mobile robot. First, we develop a mobile robotic platform that constructs the spatial map and radio map simultaneously in the easily accessed free space. GPR-GAN first establishes a Gaussian process regression (GPR) model using the real received signal strength (RSS) measurements collected by our robotic platform via LiDAR SLAM in the free space. Then, the outputs of the GPR are adopted as the input of GAN's generator. The learning objective of GAN is to synthesize realistic RSS data in a constrained space where it has not been covered and model the irregular RSS distributions in complex indoor environments. Real-world experiments were conducted in a real-world indoor environment, which confirms the feasibility, high accuracy, and superiority of WiGAN over existing solutions in terms of both RSS estimation accuracy and localization accuracy.",https://ieeexplore.ieee.org/document/9031749/,IEEE Internet of Things Journal,Aug. 2020,ieeexplore
10.1109/21.3461,An approach to an expert robot welding system,IEEE,Journals,"Adaptive control and sensory processing techniques in robotic arc welding are discussed. The gas metal arc welding and gas tungsten arc welding processes are considered, along with a literature review of aspects of welding automation. Topics covered include process modeling, detection and measurement of process features, real-time control, and implementation considerations. An approach for an adaptive welding system is presented. The proposed architecture fits within the scope of an ambitious project to develop an expert welding robot. Different levels of automation are discussed, from the decision level to the closed-loop control of process variables and torch trajectory.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/3461/,"IEEE Transactions on Systems, Man, and Cybernetics",March-April 1988,ieeexplore
10.1109/ACCESS.2021.3079427,Autonomous Endoscope Robot Positioning Using Instrument Segmentation With Virtual Reality Visualization,IEEE,Journals,"This paper presents a method for endoscope's autonomous positioning by a robotic endoscope holder for minimally invasive surgery. The method improves human-robot cooperation in robot-assisted surgery by allowing the endoscope holder to acknowledge the surgeon's view projection and navigate the camera without manual control. The real-time prediction of next desired camera location is estimated using segmented instrument's tip locations from endoscope video and surgeon's attention focus given by tracked virtual reality headset. To tackle the issue of real-time surgical instrument segmentation for more precise instrument tip localization, we propose the YOLOv3 and ResNet Combined Neural Network. The method showed an 86.6% IoU across MICCAI'17 Endovis datasets with 30 frames per second processing speed. The proposed pipeline was implemented in ROS on Ubuntu with visualization running under Windows operating system in Unity3D. The simulation demonstrates the robotic arm, endoscope, and surgical environment visualized in 3D in the virtual reality headset to provide a stable view of the endoscope and improve the surgeon's perception of the operating environment.",https://ieeexplore.ieee.org/document/9429186/,IEEE Access,2021,ieeexplore
10.1109/TSMCA.2003.811766,Autonomous fuzzy parking control of a car-like mobile robot,IEEE,Journals,"This paper is devoted to design and implement a car-like mobile robot (CLMR) that possesses autonomous garage-parking and parallel-parking capability by using real-time image processing. For fuzzy garage-parking control (FGPC) and fuzzy parallel-parking control (FPPC), feasible reference trajectories are provided for the fuzzy logic controller to maneuver the steering angle of the CLMR. We propose two FGPC methods and two FPPC methods to back-drive or head-in the CLMR to the garage and the parking lot, respectively. Simulation results illustrate the effectiveness of the developed schemes. The overall experimental setup of the parking system developed in this paper is composed of a host computer, a communication module, a CLMR, and a vision system. Finally, the image-based real-time implementation experiments of the CLMR demonstrate the feasibility and effectiveness of the proposed schemes.",https://ieeexplore.ieee.org/document/1235979/,"IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans",July 2003,ieeexplore
10.1109/ACCESS.2021.3093340,Ball Motion Control in the Table Tennis Robot System Using Time-Series Deep Reinforcement Learning,IEEE,Journals,"One of the biggest challenges hindering a table tennis robot to play as well as a professional player is the ball’s accurate motion control, which depends on various factors such as the incoming ball’s position, linear, spin velocity and so forth. Unfortunately, some factors are almost impossible to be directly measured in real practice, such as the ball’s spin velocity, which is difficult to be estimated from vision due to the little texture on the ball’s surface. To perform accurate motion control in table tennis, this study proposes to learn a ball stroke strategy to guarantee desirable “target landing location” and the “over-net height” which are two key indicators to evaluate the quality of a stroke. To overcome the spin velocity challenge, a deep reinforcement learning (DRL) based stroke approach is developed with the spin velocity estimation capability, through which the system can predict the relative spin velocity of the ball and stroke it back accurately by iteratively learning from the robot-environment interactions. To pre-train the DRL-based strategy effectively, this paper develops a virtual table tennis playing environment, through which various simulated data can be collected. For the real table tennis robot implementation, experimental results demonstrate the superior performance of the proposed control strategy compared to that of the traditional aerodynamics-based method with an average landing error around 80mm and the landing-within-table probability higher than 70%.",https://ieeexplore.ieee.org/document/9467347/,IEEE Access,2021,ieeexplore
10.1109/LRA.2021.3111416,Binarized P-Network: Deep Reinforcement Learning of Robot Control from Raw Images on FPGA,IEEE,Journals,"This letter explores a deep reinforcement learning (DRL) approach for designing image-based control for edge robots to be implemented on Field Programmable Gate Arrays (FPGAs). Although FPGAs are more power-efficient than CPUs and GPUs, a typical DRL method cannot be applied since they are composed of many Logic Blocks (LBs) for high-speed logical operations but low-speed real-number operations. To cope with this problem, we propose a novel DRL algorithm called Binarized P-Network (BPN), which learns image-input control policies using Binarized Convolutional Neural Networks (BCNNs). To alleviate the instability of reinforcement learning caused by a BCNN with low function approximation accuracy, our BPN adopts a robust value update scheme called Conservative Value Iteration, which is tolerant of function approximation errors. We confirmed the BPN's effectiveness through applications to a visual tracking task in simulation and real-robot experiments with FPGA.",https://ieeexplore.ieee.org/document/9534708/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/TSMCB.2009.2018138,Cerebellar-Inspired Adaptive Control of a Robot Eye Actuated by Pneumatic Artificial Muscles,IEEE,Journals,"In this paper, a model of cerebellar function is implemented and evaluated in the control of a robot eye actuated by pneumatic artificial muscles. The investigated control problem is stabilization of the visual image in response to disturbances. This is analogous to the vestibuloocular reflex (VOR) in humans. The cerebellar model is structurally based on the adaptive filter, and the learning rule is computationally analogous to least-mean squares, where parameter adaptation at the parallel fiber/Purkinje cell synapse is driven by the correlation of the sensory error signal (carried by the climbing fiber) and the motor command signal. Convergence of the algorithm is first analyzed in simulation on a model of the robot and then tested online in both one and two degrees of freedom. The results show that this model of neural function successfully works on a real-world problem, providing empirical evidence for validating: 1) the generic cerebellar learning algorithm; 2) the function of the cerebellum in the VOR; and 3) the signal transmission between functional neural components of the VOR.",https://ieeexplore.ieee.org/document/4814555/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",Dec. 2009,ieeexplore
10.1109/TII.2020.2991764,Continuous Image Generation From Low-Update-Rate Images and Physical Sensors Through a Conditional GAN for Robot Teleoperation,IEEE,Journals,"When a robot is teleoperated, its operator control is based on transmitted images. Network limitations and/or a remote distance usually cause delays or interruptions of the image transmission, which is one of the reasons for the instability of teleoperation systems. In this article, we propose a high-update-rate image generation method using past low update image and current grip position and electrical motor current of gripper received by sensors during teleoperation via a conditional generative adversarial network. The main challenge is that such a network can generate current high-update-rate images from past low-update-rate one, the current high-update-rate grip force, and the grip angle. We equipped a robot gripper with a camera and a grip force sensor and collected a large data set of robot vision, grip force, and grip angle sequences; objects with deformation, including irregular deformation, and rigid objects were tested in the experiment to verify the possibility of high-update-rate image generation under various grip conditions. We found that the proposed network allows the generation of current images with high update rate.",https://ieeexplore.ieee.org/document/9084292/,IEEE Transactions on Industrial Informatics,March 2021,ieeexplore
10.1109/TSMCB.2006.874131,Control Architecture for Human–Robot Integration: Application to a Robotic Wheelchair,IEEE,Journals,"Completely autonomous performance of a mobile robot within noncontrolled and dynamic environments is not possible yet due to different reasons including environment uncertainty, sensor/software robustness, limited robotic abilities, etc. But in assistant applications in which a human is always present, she/he can make up for the lack of robot autonomy by helping it when needed. In this paper, the authors propose human-robot integration as a mechanism to augment/improve the robot autonomy in daily scenarios. Through the human-robot-integration concept, the authors take a further step in the typical human-robot relation, since they consider her/him as a constituent part of the human-robot system, which takes full advantage of the sum of their abilities. In order to materialize this human integration into the system, they present a control architecture, called architecture for human-robot integration, which enables her/him from a high decisional level, i.e., deliberating a plan, to a physical low level, i.e., opening a door. The presented control architecture has been implemented to test the human-robot integration on a real robotic application. In particular, several real experiences have been conducted on a robotic wheelchair aimed to provide mobility to elderly people",https://ieeexplore.ieee.org/document/1703648/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",Oct. 2006,ieeexplore
10.1109/TIE.2015.2425359,Coordination of Multiple Robotic Fish With Applications to Underwater Robot Competition,IEEE,Journals,"This paper is concerned with the coordination control of multiple biomimetic robotic fish in highly dynamic aquatic environments by building a hybrid centralized system. With the aid of the results of biorobotics and control techniques, a radio-controlled multijoint robotic fish and its locomotion control are developed. To enable a closed control loop, a visual subsystem that is responsible for tracking of multiple moving objects is constructed and implemented in real time. Furthermore, a behavior-based hierarchical architecture in conjunction with fuzzy reinforcement learning is proposed to accomplish effective coordination among multiple swimming robots. Finally, experiments on 2vs2 water polo game are carried out to verify the proposed coordination control scheme. Over the past eight years, this multirobot platform has been successfully applied to international underwater robot competitions to promote innovative research and education in underwater robotics.",https://ieeexplore.ieee.org/document/7091905/,IEEE Transactions on Industrial Electronics,Feb. 2016,ieeexplore
10.1109/ACCESS.2020.3033550,Developing a Lightweight Rock-Paper-Scissors Framework for Human-Robot Collaborative Gaming,IEEE,Journals,"We present a novel implementation of a Rock-Paper-Scissors (RPS) game interaction with a social robot. The framework is tailored to be computationally lightweight, as well as entertaining and visually appealing through collaboration with designers and animators. The fundamental gesture recognition pipeline employs a Leap motion device and two separate machine learning architectures to evaluate kinematic hand data on-the-fly. The first architecture is used to recognize and segment human motion activity in order to initialize the RPS play, and the second architecture is used to classify hand gestures into rock, paper or scissors. The employed tabletop robot interacts in the RPS play through unique animated gestural movements and vocalizations designed by animators which communicate the robot's choices as well as cognitive reflection on winning, losing and draw states. Performance of both learning architectures is carefully evaluated with respect to accuracy, reliability and run time performance under different feature and classifier types. Moreover, we assess our system during an interactive RPS play between robot and human. Experimental results show that the proposed system is robust to user variations and play style in real environment conditions. As such, it offers a powerful application for the subsequent exploration of social human-machine interaction.",https://ieeexplore.ieee.org/document/9239276/,IEEE Access,2020,ieeexplore
10.1109/3516.537045,Development and integration of generic components for a teachable vision-based mobile robot,IEEE,Journals,"This paper presents a mobile robotic system for human assistance in navigation-the robot navigates by receiving visual instructions from a human being and is able to replicate them autonomously. We describe three generic components defined as the HOST, the VISION, and the CONTROL components as well as their integration in our teachable mobile robot. These components are connected to each other via a transputer serial link, namely they are loosely coupled, they work in parallel and are asynchronous with each other. Each component is described with a peculiar feature of extensibility. Especially in the VISION component, there are two major features. The first one is a correlator which each vision board possesses. The correlator does block-matching between the template and the grabbed images in real-time. The other is the PIM library which manages the visual tasks over limited parallel visual resources of the mobile robot. These features of our design enable the system to be real-time and allow for efficient and extensible software development. In order to show the feasibility of our system design, we present a preliminary experiment of the route teaching on our mobile robot.",https://ieeexplore.ieee.org/document/537045/,IEEE/ASME Transactions on Mechatronics,Sept. 1996,ieeexplore
10.1109/TMECH.2013.2294180,Development of a Laser-Range-Finder-Based Human Tracking and Control Algorithm for a Marathoner Service Robot,IEEE,Journals,"This paper presents a human detection algorithm and an obstacle avoidance algorithm for a marathoner service robot (MSR) that provides a service to a marathoner while training. To be used as a MSR, the mobile robot should have the abilities to follow a running human and avoid dynamically moving obstacles in an unstructured outdoor environment. To detect a human by a laser range finder (LRF), we defined features of the human body in LRF data and employed a support vector data description method. In order to avoid moving obstacles while tracking a running person, we defined a weighted radius for each obstacle using the relative velocity between the robot and an obstacle. For smoothly bypassing obstacles without collision, a dynamic obstacle avoidance algorithm for the MSR is implemented, which directly employed a real-time position vector between the robot and the shortest path around the obstacle. We verified the feasibility of these proposed algorithms through experimentation in different outdoor environments.",https://ieeexplore.ieee.org/document/6690173/,IEEE/ASME Transactions on Mechatronics,Dec. 2014,ieeexplore
10.1109/TSMCA.2012.2210408,Emotional State Classification in Patient–Robot Interaction Using Wavelet Analysis and Statistics-Based Feature Selection,IEEE,Journals,"Due to a major shortage of nurses in the U.S., future healthcare service robots are expected to be used in tasks involving direct interaction with patients. Consequently, there is a need to design nursing robots with the capability to detect and respond to patient emotional states and to facilitate positive experiences in healthcare. The objective of this study was to develop a new computational algorithm for accurate patient emotional state classification in interaction with nursing robots during medical service. A simulated medicine delivery experiment was conducted at two nursing homes using a robot with different human-like features. Physiological signals, including heart rate (HR) and galvanic skin response (GSR), as well as subjective ratings of valence (happy-unhappy) and arousal (excited-bored) were collected on elderly residents. A three-stage emotional state classification algorithm was applied to these data, including: (1) physiological feature extraction; (2) statistical-based feature selection; and (3) a machine-learning model of emotional states. A pre-processed HR signal was used. GSR signals were nonstationary and noisy and were further processed using wavelet analysis. A set of wavelet coefficients, representing GSR features, was used as a basis for current emotional state classification. Arousal and valence were significantly explained by statistical features of the HR signal and GSR wavelet features. Wavelet-based de-noising of GSR signals led to an increase in the percentage of correct classifications of emotional states and clearer relationships among the physiological response and arousal and valence. The new algorithm may serve as an effective method for future service robot real-time detection of patient emotional states and behavior adaptation to promote positive healthcare experiences.",https://ieeexplore.ieee.org/document/6301777/,IEEE Transactions on Human-Machine Systems,Jan. 2013,ieeexplore
10.1109/70.650165,Environment prediction for a mobile robot in a dynamic environment,IEEE,Journals,"The problem of navigating a mobile robot among moving obstacles is usually solved on the condition of knowing the velocity of obstacles. However, it is difficult to provide such information to a robot in real time. In this paper, we present an environment predictor that provides an estimate of future environment configuration by fusing multisensor data in real time. The predictor is implemented by an artificial neural network (ANN) trained using a relative-error-backpropagation (REBP) algorithm. The REBP algorithm enables the ANN to provide output data with a minimum relative error, which is better than conventional backpropagation (BP) algorithms in this prediction application. The mobile robot can, therefore, respond to anticipated changes in the environment. The performance is verified by prediction simulation and navigation experiments.",https://ieeexplore.ieee.org/document/650165/,IEEE Transactions on Robotics and Automation,Dec. 1997,ieeexplore
10.1109/3477.499791,Evolution of homing navigation in a real mobile robot,IEEE,Journals,In this paper we describe the evolution of a discrete-time recurrent neural network to control a real mobile robot. In all our experiments the evolutionary procedure is carried out entirely on the physical robot without human intervention. We show that the autonomous development of a set of behaviors for locating a battery charger and periodically returning to it can be achieved by lifting constraints in the design of the robot/environment interactions that were employed in a preliminary experiment. The emergent homing behavior is based on the autonomous development of an internal neural topographic map (which is not pre-designed) that allows the robot to choose the appropriate trajectory as function of location and remaining energy.,https://ieeexplore.ieee.org/document/499791/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",June 1996,ieeexplore
10.1109/TSMCB.2010.2073702,Experimental Analysis of Mobile-Robot Teleoperation via Shared Impedance Control,IEEE,Journals,"In this paper, Internet-based teleoperation of mobile robots for obstacle avoidance is analyzed. A shared impedance-control scheme is presented, and the results of an experimental study for the evaluation of the effects of different teleoperation parameters are reported. In the experimental study, the effects of time delay, operator training, image-display alternatives (virtual model versus real images), viewpoint, and force-reflection method were studied. For this purpose, several hypotheses were formulated and tested through the experiments using the introduced quantitative and qualitative measures. A fuzzy force-reflection controller is also proposed as an alternative force-reflection technique, and its performance is compared with a conventional proportional-derivative-type force-reflection method. The experimental scheme was implemented using MATLAB XPC Target and Simulink. The results could serve as guidelines in the design of teleoperation systems for obstacle avoidance and could also provide directions for further investigations.",https://ieeexplore.ieee.org/document/5598539/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",April 2011,ieeexplore
10.1109/LRA.2020.2979656,Guided Constrained Policy Optimization for Dynamic Quadrupedal Robot Locomotion,IEEE,Journals,"Deep reinforcement learning (RL) uses model-free techniques to optimize task-specific control policies. Despite having emerged as a promising approach for complex problems, RL is still hard to use reliably for real-world applications. Apart from challenges such as precise reward function tuning, inaccurate sensing and actuation, and non-deterministic response, existing RL methods do not guarantee behavior within required safety constraints that are crucial for real robot scenarios. In this regard, we introduce guided constrained policy optimization (GCPO), an RL framework based upon our implementation of constrained proximal policy optimization (CPPO) for tracking base velocity commands while following the defined constraints. We introduce schemes which encourage state recovery into constrained regions in case of constraint violations. We present experimental results of our training method and test it on the real ANYmal quadruped robot. We compare our approach against the unconstrained RL method and show that guided constrained RL offers faster convergence close to the desired optimum resulting in an optimal, yet physically feasible, robotic control behavior without the need for precise reward function tuning.",https://ieeexplore.ieee.org/document/9028178/,IEEE Robotics and Automation Letters,April 2020,ieeexplore
10.1109/ACCESS.2020.3035725,Highlighted Map for Mobile Robot Localization and Its Generation Based on Reinforcement Learning,IEEE,Journals,"This article proposes a new kind of map for mobile robot localization and its generation method. We call the map a highlighted map, on which uniquely shaped objects (landmarks) in monotonous environments are highlighted. By using this map, robots can use such landmarks as clues for localization, and thus, their localization performance can be improved without having to update their sensors or online computation. Furthermore, this map can be easily combined with many other existing localization algorithms. We formulate the problem of making a highlighted map and propose a numerical optimization method based on reinforcement learning. This optimization method automatically identifies and emphasizes the important landmarks on the map. The generated highlighted map is adapted to situations such as the sensor characteristics and robot dynamics because this method uses the actual sensor measurement data. It is proven that the optimization converges under certain technical assumptions. We performed a numerical simulation and real-world experiment showing that the highlighted map provides better localization accuracy than a conventional map.",https://ieeexplore.ieee.org/document/9247228/,IEEE Access,2020,ieeexplore
10.1109/TOH.2020.3029043,Human-Inspired Haptic Perception and Control in Robot-Assisted Milling Surgery,IEEE,Journals,"Bone milling is one of the most widely used and high-risk procedures in various types of surgeries, and it is important to be noted that the experienced surgeon can perform such an operation safely. The objective of this article is to enhance the safety of the robot-assisted milling operation with the inspiration of human haptic perception. The emergence, coding and perception of the human haptic are introduced. Following this, a single axis accelerometer that measures the vibration of the surgical power tool is mounted in the robot arm, and the recorded acceleration signal is encoded as parallel stream of binary data. The data are subsequently inputted to the Hopfield network so as to identify the milling state. Inspired by human inference procedure, the fuzzy logic controller is introduced to control the robot to track the desired state when performing bone milling operations. A real-time implementation of the proposed method on a digital signal processing is also described. The experimental results in milling porcine spines prove that the robot accurately discriminates different milling states even when the additive noise is serious, and the safe motion control of the robot is also realized.",https://ieeexplore.ieee.org/document/9220848/,IEEE Transactions on Haptics,1 April-June 2021,ieeexplore
10.1109/ACCESS.2019.2894524,Hybrid Stochastic Exploration Using Grey Wolf Optimizer and Coordinated Multi-Robot Exploration Algorithms,IEEE,Journals,"Multi-robot exploration is a search of uncertainty in restricted space seeking to build a finite map by a group of robots. It has the main task to distribute the search assignments among robots in real time. In this paper, we proposed a stochastic optimization for multi-robot exploration that mimics the coordinated predatory behavior of grey wolves via simulation. Here, the robot movement is computed by the combined deterministic and metaheuristic techniques. It uses the Coordinated Multi-Robot Exploration and GreyWolf Optimizer algorithms as a new method called the hybrid stochastic exploration. Initially, the deterministic cost and utility determine the precedence of adjacent cells around a robot. Then, the stochastic optimization improves the overall solution. It implies that the robots evaluate the environment by the deterministic approach and move on using the metaheuristic algorithm. The proposed hybrid method was implemented on simple and complex maps and compared with the Coordinated Multi-Robot Exploration algorithm. The simulation results show that the stochastic optimization enhances the deterministic approach to completely explore and map out the areas.",https://ieeexplore.ieee.org/document/8631022/,IEEE Access,2019,ieeexplore
10.1109/TMECH.2013.2245337,Image-Based Visual Servoing of a 7-DOF Robot Manipulator Using an Adaptive Distributed Fuzzy PD Controller,IEEE,Journals,"This paper is concerned with the design and implementation of a distributed proportional-derivative (PD) controller of a 7-degrees of freedom (DOF) robot manipulator using the Takagi-Sugeno (T-S) fuzzy framework. Existing machine learning approaches to visual servoing involve system identification of image and kinematic Jacobians. In contrast, the proposed approach actuates a control signal primarily as a function of the error and derivative of the error in the desired visual feature space. This approach leads to a significant reduction in the computational burden as compared to model-based approaches, as well as existing learning approaches to model inverse kinematics. The simplicity of the controller structure will make it attractive in industrial implementations where PD/PID type schemes are in common use. While the initial values of PD gain are learned with the help of model-based controller, an online adaptation scheme has been proposed that is capable of compensating for local uncertainties associated with the system and its environment. Rigorous experiments have been performed to show that visual servoing tasks such as reaching a static target and tracking of a moving target can be achieved using the proposed distributed PD controller. It is shown that the proposed adaptive scheme can dynamically tune the controller parameters during visual servoing, so as to improve its initial performance based on parameters obtained while mimicking the model-based controller. The proposed control scheme is applied and assessed in real-time experiments using an uncalibrated eye-in-hand robotic system with a 7-DOF PowerCube robot manipulator.",https://ieeexplore.ieee.org/document/6471828/,IEEE/ASME Transactions on Mechatronics,April 2014,ieeexplore
10.1109/ACCESS.2021.3057808,Intuitive Robot Teleoperation Through Multi-Sensor Informed Mixed Reality Visual Aids,IEEE,Journals,"Mobile robotic systems have evolved to include sensors capable of truthfully describing robot status and operating environment as accurately and reliably as never before. This possibility is challenged by effective sensor data exploitation, because of the cognitive load an operator is exposed to, due to the large amount of data and time-dependency constraints. This paper addresses this challenge in remote-vehicle teleoperation by proposing an intuitive way to present sensor data to users by means of using mixed reality and visual aids within the user interface. We propose a method for organizing information presentation and a set of visual aids to facilitate visual communication of data in teleoperation control panels. The resulting sensor-information presentation appears coherent and intuitive, making it easier for an operator to catch and comprehend information meaning. This increases situational awareness and speeds up decision-making. Our method is implemented on a real mobile robotic system operating outdoor equipped with on-board internal and external sensors, GPS, and a reconstructed 3D graphical model provided by an assistant drone. Experimentation verified feasibility while intuitive and comprehensive visual communication was confirmed through an assessment, which encourages further developments.",https://ieeexplore.ieee.org/document/9349454/,IEEE Access,2021,ieeexplore
10.1109/TRA.2002.803459,LOST: localization-space trails for robot teams,IEEE,Journals,"We describe localization-space trails (LOST), a method that enables a team of robots to navigate between places of interest in an initially unknown environment using a trail of landmarks. The landmarks are not physical; they are waypoint coordinates generated online by each robot and shared with teammates. Waypoints are specified in each robot's local coordinate system, and contain references to features in the world that are relevant to the team's task and common to all robots. Using these task-level references, robots can share waypoints without maintaining a global coordinate system. The method is tested in a series of real-world multirobot experiments. The results demonstrate that the method: 1) copes with accumulating odometry error; 2) is robust to the failure of individual robots; 3) converges to the best route discovered by any robot in the team. In one experiment, a team of four autonomous mobile robots performs a resource transportation task in our uninstrumented office building. Despite significant divergence of their local coordinate systems, the robots are able to share waypoints, forming and following a common trail between two predetermined locations for more than three hours, traveling a total of 8.2 km (5.1 miles) before running out of power. Designed to scale to large populations, LOST is fully distributed, with low costs in processing, memory, and bandwidth. It combines metric data about the position of features in the world with instructions on how to get from one place to another; producing something between a map and a plan.",https://ieeexplore.ieee.org/document/1067999/,IEEE Transactions on Robotics and Automation,Oct. 2002,ieeexplore
10.1109/LRA.2021.3116703,Learning Robot Exploration Strategy With 4D Point-Clouds-Like Information as Observations,IEEE,Journals,"Being able to explore unknown environments is a requirement for fully autonomous robots. Many learning-based methods have been proposed to learn an exploration strategy. In the frontier-based exploration, learning algorithms tend to learn the optimal or near-optimal frontier to explore. Most of these methods represent the environments as fixed size images and take these as inputs to neural networks. However, the size of environments is usually unknown, which makes these methods fail to generalize to real world scenarios. To address this issue, we present a novel state representation method based on 4D point-clouds-like information, including the locations, frontier, and distance information. We also design a neural network that can process these 4D point-clouds-like information and generate the estimated value for each frontier. Then this neural network is trained using the typical reinforcement learning framework. We test the performance of our proposed method by comparing it with other five methods and test its scalability on maps that are much larger than maps in the training set. The experiment results demonstrate that our proposed method needs shorter average traveling distances to explore whole environments and can be adopted in maps with arbitrarily sizes.",https://ieeexplore.ieee.org/document/9555230/,IEEE Robotics and Automation Letters,Jan. 2022,ieeexplore
10.1109/TASE.2017.2783342,MASD: A Multimodal Assembly Skill Decoding System for Robot Programming by Demonstration,IEEE,Journals,"Programming by demonstration (PBD) transforms the robot programming from the code level to automated interface between robot and human, promoting the flexibility of robotized automation. In this paper, we focus on programming the industrial robot for assembly tasks by parsing the human demonstration into a series of assembly skills and compiling the skill to the robot executables. To achieve this goal, an identification system using multimodal information to recognize the assembly skill, called MASD, is proposed including: 1) an initial learning stage using a hierarchical model to recognize the action by considering the features from action-object effect, gesture, and trajectory and 2) a retrospective thinking stage using a segmentation method to cut the continuous demonstrations into multiple assembly skills optimally. Using MASD, the demonstration of assembly tasks can be explained with high accuracy in real time, driving a hypothesis that a PBD system on the top of MASD can be extended to more realistic assembly tasks beyond pure positional moving and picking. In experiments, the skill identification module is used to recognize the five kinds of assembly skills in demonstrations of both single and multiple assembly skills, and outperforms the comparative action identification methods. Besides integrated with the MASD, the PBD system can generate the program based on the demonstration and successfully enable an ABB industrial robotic arm simulator to assemble a flashlight and a switch, verifying the initial hypothesis. Note to Practitioners-In the conventional robotized automation, the key role of the robot mainly owes to its capacity for repeating a wide variety of tasks with high speed and accuracy in long term, with a cost of days to months of programming for deployment. On the other hand, the new trend of customization brings the new characteristics: production in short cycle and small volume. This irreversible momentum urges the robot to switch from task to task efficiently. The biggest bottleneck here is the tedious programming, which also has high prerequisites for most practitioners in manufacturing. This situation motivates the development of a PBD system that can understand the assembly skills performed by the human experts in the demonstration and accordingly generate the program for robot's execution of the taught task. In this paper, we present a skill decoding system to parse the observational raw demonstration into symbolic sequences, which is the crucial bridge to enable the automatic programming. The system achieves high performance in recognition and is tailored for the PBD in assembly tasks by considering both advantages and disadvantages in the background of assembly, such as controllable environment and limited computational resources. It is particularly useful for assembly tasks with modularized actions based on a set of standard parts. At the perspective of industrial application, the PBD upon the proposed system is a promising solution to improve the flexibility of manufacture, which is expected to be true in midterm but an important step toward this goal.",https://ieeexplore.ieee.org/document/8263146/,IEEE Transactions on Automation Science and Engineering,Oct. 2018,ieeexplore
10.1109/TIE.2016.2590379,Modified ZNN for Time-Varying Quadratic Programming With Inherent Tolerance to Noises and Its Application to Kinematic Redundancy Resolution of Robot Manipulators,IEEE,Journals,"For quadratic programming (QP), it is usually assumed that the solving process is free of measurement noises or that the denoising has been conducted before the computation. However, time is precious for time-varying QP (TVQP) in practice. Preprocessing for denoising may consume extra time, and consequently violates real-time requirements. Therefore, a model with inherent noise tolerance is urgently needed to solve TVQP problems in real time. In this paper, we make progress along this direction by proposing a modified Zhang neural network (MZNN) model for the solution of TVQP. The original Zhang neural network model and the gradient neural network model are employed for comparisons with the MZNN model. In addition, theoretical analyses show that, without measurement noise, the proposed MZNN model globally converges to the exact real-time solution of the TVQP problem in an exponential manner and that, in the presence of measurement noises, the proposed MZNN model has a satisfactory performance. Finally, two illustrative simulation examples as well as a physical experiment are provided and analyzed to substantiate the efficacy and superiority of the proposed MZNN model for TVQP problem solving.",https://ieeexplore.ieee.org/document/7508995/,IEEE Transactions on Industrial Electronics,Nov. 2016,ieeexplore
10.1109/LRA.2020.3010456,Multi-Robot Active Sensing and Environmental Model Learning With Distributed Gaussian Process,IEEE,Journals,"This letter deals with the problem of multiple robots working together to explore and gather at the global maximum of the unknown field. Given noisy sensor measurements obtained at the location of robots with no prior knowledge about the environmental map, Gaussian process regression can be an efficient solution to construct a map that represents spatial information with confidence intervals. However, because the conventional Gaussian process algorithm operates in a centralized manner, it is difficult to process information coming from multiple distributed sensors in real-time. In this work, we propose a multi-robot exploration algorithm that deals with the following challenges: i) distributed environmental map construction using networked sensing platforms; ii) online learning using successive measurements suitable for a multi-robot team; iii) multi-agent coordination to discover the highest peak of an unknown environmental field with collision avoidance. We demonstrate the effectiveness of our algorithm via simulation and a topographic survey experiment with multiple UAVs.",https://ieeexplore.ieee.org/document/9144385/,IEEE Robotics and Automation Letters,Oct. 2020,ieeexplore
10.1109/ACCESS.2019.2899940,Multi-Task Cascaded Convolutional Networks Based Intelligent Fruit Detection for Designing Automated Robot,IEEE,Journals,"Effective and efficient fruit detection is considered crucial for designing automated robot (AuRo) for yield estimation, disease control, harvesting, sorting, and grading. Several fruit detection schemes for designing AuRo have been developed during the last decades. However, conventional fruit detection methods are deficient in the real-time response, accuracy, and extensibility. This paper proposes an improved multi-task cascaded convolutional network-based intelligent fruit detection method. This method has the capability to make the AuRo work in real time with high accuracy. Moreover, based on the relationship between the diversity samples of the dataset and the parameters of neural networks' evolution, this paper presents an improved augmented method, a procedure that is based on image fusion to improve the detector performance. The experiment results demonstrated that the proposed detector performed immaculately both in terms of accuracy and time-cost. Furthermore, the extensive experiment also demonstrated that the proposed technique has the capacity and good portability to work with other akin objects conveniently.",https://ieeexplore.ieee.org/document/8643367/,IEEE Access,2019,ieeexplore
10.1109/TNNLS.2020.2980038,Mutual-Collision-Avoidance Scheme Synthesized by Neural Networks for Dual Redundant Robot Manipulators Executing Cooperative Tasks,IEEE,Journals,"Collision between dual robot manipulators during working process will lead to task failure and even robot damage. To avoid mutual collision of dual robot manipulators while doing collaboration tasks, a novel recurrent neural network (RNN)-based mutual-collision-avoidance (MCA) scheme for solving the motion planning problem of dual manipulators is proposed and exploited. Because of the high accuracy and low computation complexity, the linear variational inequality-based primal-dual neural network is used to solve the proposed scheme. The proposed scheme is applied to the collaboration trajectory tracking and cup-stacking tasks, and shows its effectiveness for avoiding collision between the dual robot manipulators. Through network iteration and online learning, the dual robot manipulators will learn the ability of MCA. Moreover, a line-segment-based distance measure algorithm is proposed to calculate the minimum distance between the dual manipulators. If the computed minimum distance is less than the first safe-related distance threshold, a speed brake operation is executed and guarantees that the robot cannot exceed the second safe-related distance threshold. Furthermore, the proposed MCA strategy is formulated as a standard quadratic programming problem, which is further solved by an RNN. Computer simulations and a real dual robot experiment further verify the effectiveness, accuracy, and physical realizability of the RNN-based MCA scheme when manipulators cooperatively execute the end-effector tasks.",https://ieeexplore.ieee.org/document/9072323/,IEEE Transactions on Neural Networks and Learning Systems,March 2021,ieeexplore
10.1109/TIE.2005.847576,Obstacle avoidance of a mobile robot using hybrid learning approach,IEEE,Journals,"in this paper, a hybrid learning approach for obstacle avoidance of a mobile robot is presented. the key features of the approach are, firstly, innate hardwired behaviors which are used to bootstrap learning in the mobile robot system. a neuro-fuzzy controller is developed from a pre-wired or innate controller based on supervised learning in a simulation environment. the fuzzy inference system has been constructed based on the generalized dynamic fuzzy neural networks learning algorithm of Wu and Er, whereby structure and parameters identification are carried out automatically and simultaneously. Secondly, the neuro-fuzzy controller is capable of re-adapting in a new environment. After carrying out the learning phase on a simulated robot, the controller is implemented on a real robot. A reinforcement learning method based on the fuzzy actor-critic learning algorithm is employed so that the system can re-adapt to a new environment without human intervention. In this phase, the structure of the fuzzy inference system and the parameters of the antecedent parts of fuzzy rules are frozen, and reinforcement learning is applied to further tune the parameters in the consequent parts of the fuzzy rules. Through the hybrid learning approach, an efficient and compact neuro-fuzzy system is generated for obstacle avoidance of a mobile robot in the real world.",https://ieeexplore.ieee.org/document/1435700/,IEEE Transactions on Industrial Electronics,June 2005,ieeexplore
10.1109/LRA.2021.3076955,On the Emergence of Whole-Body Strategies From Humanoid Robot Push-Recovery Learning,IEEE,Journals,"Balancing and push-recovery are essential capabilities enabling humanoid robots to solve complex locomotion tasks. In this context, classical control systems tend to be based on simplified physical models and hard-coded strategies. Although successful in specific scenarios, this approach requires demanding tuning of parameters and switching logic between specifically-designed controllers for handling more general perturbations. We apply model-free Deep Reinforcement Learning for training a general and robust humanoid push-recovery policy in a simulation environment. Our method targets high-dimensional whole-body humanoid control and is validated on the iCub humanoid. Reward components incorporating expert knowledge on humanoid control enable fast learning of several robust behaviors by the same policy, spanning the entire body. We validate our method with extensive quantitative analyses in simulation, including out-of-sample tasks which demonstrate policy robustness and generalization, both key requirements towards real-world robot deployment.",https://ieeexplore.ieee.org/document/9420230/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/ACCESS.2020.3048877,"Online Measuring of Robot Positions Using Inertial Measurement Units, Sensor Fusion and Artificial Intelligence",IEEE,Journals,"This research introduces a new method to estimate the position of a robot's Tool Center Point (TCP) using Inertial Measurement Units (IMUs), sensor fusion and Artificial Neural Networks (ANNs). The objective is to make an accurate estimate of TCP navigation, using the signals from an IMU as resources of a neural network capable of predicting the position. Considering that the IMU sensors suffer noise in the measurements and the noise progresses over time, this proposal employs a technique that eliminates the filtering step, and the process is done internally by the network. The work employs a non-parametric approach to reset the reference dynamically, minimize noise from sensors, and converge positioning to a nominal result. This method offers a solution for fast, cheap, and efficient robot calibration. The work does not want to replace current techniques but to introduce a new design to the literature. The concept does not require sophisticated mechanical parts and the production line to be idle during the calibration process, and the results show that the developed technique can accurately predict the TCP position with millimeter errors and in real-time. The study also implemented the concept with other neural networks, for which it used a smaller set of data in an attempt to reduce training time. The research used the Multilayer Perceptron and XGBRegressor networks to test the approach introduced with others algorithms. Different applications that need real-time positioning can benefit from the proposal.",https://ieeexplore.ieee.org/document/9312193/,IEEE Access,2021,ieeexplore
10.1109/TNSRE.2017.2692520,Portable and Reconfigurable Wrist Robot Improves Hand Function for Post-Stroke Subjects,IEEE,Journals,"Rehabilitation robots have become increasingly popular for stroke rehabilitation. However, the high cost of robots hampers their implementation on a large scale. This paper implements the concept of a modular and reconfigurable robot, reducing its cost and size by adopting different therapeutic end effectors for different training movements using a single robot. The challenge is to increase the robot's portability and identify appropriate kinds of modular tools and configurations. Because literature on the effectiveness of this kind of rehabilitation robot is still scarce, this paper presents the design of a portable and reconfigurable rehabilitation robot and describes its use with a group of post-stroke patients for wrist and forearm training. Seven stroke subjects received training using a reconfigurable robot for 30 sessions, lasting 30 min per session. Post-training, statistical analysis showed significant improvement of 3.29 points (16.20%, p = 0.027) on the Fugl-Meyer assessment scale for forearm and wrist components. Significant improvement of active range of motion was detected in both pronation-supination (75.59%, p = 0.018) and wrist flexion-extension (56.12%, p = 0.018) after the training. These preliminary results demonstrate that the developed reconfigurable robot could improve subjects' wrist and forearm movement.",https://ieeexplore.ieee.org/document/7894193/,IEEE Transactions on Neural Systems and Rehabilitation Engineering,Oct. 2017,ieeexplore
10.1109/TNN.2006.877534,Prune-Able Fuzzy ART Neural Architecture for Robot Map Learning and Navigation in Dynamic Environments,IEEE,Journals,"Mobile robots must be able to build their own maps to navigate in unknown worlds. Expanding a previously proposed method based on the fuzzy ART neural architecture (FARTNA), this paper introduces a new online method for learning maps of unknown dynamic worlds. For this purpose the new Prune-able fuzzy adaptive resonance theory neural architecture (PAFARTNA) is introduced. It extends the FARTNA self-organizing neural network with novel mechanisms that provide important dynamic adaptation capabilities. Relevant PAFARTNA properties are formulated and demonstrated. A method is proposed for the perception of object removals, and then integrated with PAFARTNA. The proposed methods are integrated into a navigation architecture. With the new navigation architecture the mobile robot is able to navigate in changing worlds, and a degree of optimality is maintained, associated to a shortest path planning approach implemented in real-time over the underlying global world model. Experimental results obtained with a Nomad 200 robot are presented demonstrating the feasibility and effectiveness of the proposed methods",https://ieeexplore.ieee.org/document/1687933/,IEEE Transactions on Neural Networks,Sept. 2006,ieeexplore
10.1109/LRA.2020.2998414,RILaaS: Robot Inference and Learning as a Service,IEEE,Journals,"Programming robots is complicated due to the lack of `plug-and-play' modules for skill acquisition. Virtualizing deployment of deep learning models can facilitate large-scale use/re-use of off-the-shelf functional behaviors. Deploying deep learning models on robots entails real-time, accurate and reliable inference service under varying query load. This letter introduces a novel Robot-Inference-and-Learning-as-a-Service (RILaaS) platform for low-latency and secure inference serving of deep models that can be deployed on robots. Unique features of RILaaS include: 1) low-latency and reliable serving with gRPC under dynamic loads by distributing queries over multiple servers on Edge and Cloud, 2) SSH based authentication coupled with SSL/TLS based encryption for security and privacy of the data, and 3) front-end REST API for sharing, monitoring and visualizing performance metrics of the available models. We report experiments to evaluate the RILaaS platform under varying loads of batch size, number of robots, and various model placement hosts on Cloud, Edge, and Fog for providing benchmark applications of object recognition and grasp planning as a service. We address the complexity of load balancing with a reinforcement learning algorithm that optimizes simulated profiles of networked robots; outperforming several baselines including round robin, least connections, and least model time with 68.30% and 14.04% decrease in round-trip latency time across models compared to the worst and the next best baseline respectively. Details and updates are available at: https://sites.google.com/view/rilaas.",https://ieeexplore.ieee.org/document/9103220/,IEEE Robotics and Automation Letters,July 2020,ieeexplore
10.1109/TCSI.2004.827654,Reaction-diffusion navigation robot control: from chemical to VLSI analogic processors,IEEE,Journals,"We introduce a new methodology and experimental implementations for real-time wave-based robot navigation in a complex, dynamically changing environment. The main idea behind the approach is to consider the robot arena as an excitable medium, in which moving objects-obstacles and the target-are represented by sites of autowave generation: the target generates attractive waves, while the obstacles repulsive ones. The moving robot detects traveling and colliding wave fronts and uses the information about dynamics of the autowaves to adapt its direction of collision-free motion toward the target. This approach allows us to achieve a highly adaptive robot behavior and thus an optimal path along which the robot reaches the target while avoiding obstacles. At the computational and experimental levels, we adopt principles of computation in reaction-diffusion (RD) nonlinear active media. Nonlinear media where autowaves are used for information processing purposes can therefore be considered as RD computing devices. In this paper, we design and experiment with three types of RD processors: experimental and computational Belousov-Zhabotinsky chemical processor, computational CNN processor, and experimental RD-CNN very large-scale integration chip-the complex analog and logic computing engine (CACE1k). We demonstrate how to experimentally implement robot navigation using space-time snapshots of active chemical medium and how to overcome low-speed limitation of this ""wetware"" implementation in CNN-based silicon processors.",https://ieeexplore.ieee.org/document/1296805/,IEEE Transactions on Circuits and Systems I: Regular Papers,May 2004,ieeexplore
10.1109/TCYB.2013.2275291,Real-Time Multiple Human Perception With Color-Depth Cameras on a Mobile Robot,IEEE,Journals,"The ability to perceive humans is an essential requirement for safe and efficient human-robot interaction. In real-world applications, the need for a robot to interact in real time with multiple humans in a dynamic, 3-D environment presents a significant challenge. The recent availability of commercial color-depth cameras allow for the creation of a system that makes use of the depth dimension, thus enabling a robot to observe its environment and perceive in the 3-D space. Here we present a system for 3-D multiple human perception in real time from a moving robot equipped with a color-depth camera and a consumer-grade computer. Our approach reduces computation time to achieve real-time performance through a unique combination of new ideas and established techniques. We remove the ground and ceiling planes from the 3-D point cloud input to separate candidate point clusters. We introduce the novel information concept, depth of interest, which we use to identify candidates for detection, and that avoids the computationally expensive scanning-window methods of other approaches. We utilize a cascade of detectors to distinguish humans from objects, in which we make intelligent reuse of intermediary features in successive detectors to improve computation. Because of the high computational cost of some methods, we represent our candidate tracking algorithm with a decision directed acyclic graph, which allows us to use the most computationally intense techniques only where necessary. We detail the successful implementation of our novel approach on a mobile robot and examine its performance in scenarios with real-world challenges, including occlusion, robot motion, nonupright humans, humans leaving and reentering the field of view (i.e., the reidentification challenge), human-object and human-human interaction. We conclude with the observation that the incorporation of the depth information, together with the use of modern techniques in new ways, we are able to create an accurate system for real-time 3-D perception of humans by a mobile robot.",https://ieeexplore.ieee.org/document/6583249/,IEEE Transactions on Cybernetics,Oct. 2013,ieeexplore
10.1109/LRA.2021.3102318,Real-Time Obstacle Avoidance Using Dual-Type Proximity Sensor for Safe Human-Robot Interaction,IEEE,Journals,"This letter introduces a dual-type proximity sensor and a control strategy for a robot manipulator to realize safe human-robot interactions (HRI) by using the sensor. Safety is an essential condition for HRI in practical scenarios. To achieve this condition, information about the relationship between an external objects and the robot is required. To obtain this information, we employ a dual-type proximity sensor, which consists of capacitive and inductive transducers and can detect the distance between a robot and external objects. Further, we propose a real-time trajectory planning method to deal with obstacles by using admittance control and distance measurements. To update the motion of the manipulator according to our control strategy, a Weight-Prioritized solution based on a QP (quadratic programming) formalism was applied. Further, the problem of self-sensing is solved via machine learning using a training dataset consisting of data corresponding to random joint positions. The proposed method was implemented on a collaborate robot (UR10). Experiments were conducted considering realistic human-robot interactions, and safety improvement was validated.",https://ieeexplore.ieee.org/document/9508896/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/70.265922,Real-time vision-based robot localization,IEEE,Journals,"This paper describes an algorithm for determining robot location from visual landmarks. This algorithm determines both the correspondence between observed landmarks (in this case vertical edges in the environment) and a stored map, and computes the location of the robot using those correspondences. The primary advantages of this algorithm are its use of a single geometric tolerance to describe observation error, its ability to recognize ambiguous sets of correspondences, its ability to compute bounds on the error in localization, and fast execution. The algorithm has been implemented and tested on a mobile robot system. In several hundred trials it has never failed, and computes location accurate to within a centimeter in less than 0.5 s.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/265922/,IEEE Transactions on Robotics and Automation,Dec. 1993,ieeexplore
10.1109/ACCESS.2020.3018026,Reinforcement Learning for Position Control Problem of a Mobile Robot,IEEE,Journals,"Due to the increase in complexity in autonomous vehicles, most of the existing control systems are proving to be inadequate. Reinforcement Learning is gaining traction as it is posed to overcome these difficulties in a natural way. This approach allows an agent that interacts with the environment to get rewards for appropriate actions, learning to improve its performance continuously. The article describes the design and development of an algorithm to control the position of a wheeled mobile robot using Reinforcement Learning. One main advantage of this approach concerning traditional control algorithms is that the learning process is carried out automatically with a recursive procedure forward in time. Moreover, given the fidelity of the model for the particular implementation described in this work, the whole learning process can be carried out in simulation. This fact avoids damages to the actual robot during the learning stage. It shows that the position control of the robot (or similar specific tasks) can be done without the need to know the dynamic model of the system explicitly. Its main drawback is that the learning stage can take a long time to finish and that it depends on the complexity of the task and the availability of adequate hardware resources. This work provides a comparison between the proposed approach and traditional existing control laws in simulation and real environments. The article also discusses the main effects of using different controlled variables in the performance of the developed control law.",https://ieeexplore.ieee.org/document/9171241/,IEEE Access,2020,ieeexplore
10.1109/LRA.2021.3057055,Robot Learning With Crash Constraints,IEEE,Journals,"In the past decade, numerous machine learning algorithms have been shown to successfully learn optimal policies to control real robotic systems. However, it is common to encounter failing behaviors as the learning loop progresses. Specifically, in robot applications where failing is undesired but not catastrophic, many algorithms struggle with leveraging data obtained from failures. This is usually caused by (i) the failed experiment ending prematurely, or (ii) the acquired data being scarce or corrupted. Both complicate the design of proper reward functions to penalize failures. In this letter, we propose a framework that addresses those issues. We consider failing behaviors as those that violate a constraint and address the problem of learning with crash constraints, where no data is obtained upon constraint violation. The no-data case is addressed by a novel GP model (GPCR) for the constraint that combines discrete events (failure/success) with continuous observations (only obtained upon success). We demonstrate the effectiveness of our framework on simulated benchmarks and on a real jumping quadruped, where the constraint threshold is unknown a priori. Experimental data is collected, by means of constrained Bayesian optimization, directly on the real robot. Our results outperform manual tuning and GPCR proves useful on estimating the constraint threshold.",https://ieeexplore.ieee.org/document/9345965/,IEEE Robotics and Automation Letters,April 2021,ieeexplore
10.1109/ACCESS.2020.3043524,Robot Variable Impedance Skill Transfer and Learning Framework Based on a Simplified Human Arm Impedance Model,IEEE,Journals,"A variable impedance skill transfer framework is introduced and experimentally evaluated in this article. This framework mainly includes the following: 1. a real-time estimation algorithm of arm endpoint stiffness based on the human arm endpoint impedance model, and 2. the tele-impedance demonstration (tele-demonstration) method and Gaussian mixture model (GMM)-based learning from demonstration (LfD) method, which are designed according to the impedance model and the variable impedance skill transfer process. The modelling of the human arm endpoint impedance is inspired by human operation habits. The model can modify the task stiffness in three Cartesian directions based on the arm configuration and muscle co-contraction effect. The model parameters and their values are identified by performing a perturbation-based arm endpoint impedance identification experiment. The real-time impedance model is used for tele-demonstration and obtaining multimodality learning data, including human arm position and impedance information. These multimodality learning data are used for the variable impedance skill learning and generalization, and an electrical switch skill is learned and generalized by a compliant robotic arm in the experiments to execute a variable impedance interaction task in a dynamic uncertain environment.",https://ieeexplore.ieee.org/document/9289843/,IEEE Access,2020,ieeexplore
10.1109/TETC.2017.2769705,Robust Robot Tracking for Next-Generation Collaborative Robotics-Based Gaming Environments,IEEE,Journals,"The collaboration between humans and robots is one of the most disruptive and challenging research areas. Even considering advances in design and artificial intelligence, humans and robots could soon ally to perform together a number of different tasks. Robots could also became new playmates. In fact, an emerging trend is associated with the so-called phygital gaming, which builds upon the idea of merging the physical world with a virtual one in order to let physical and virtual entities, such as players, robots, animated characters and other game objects interact seamlessly as if they were all part of the same reality. This paper specifically focuses on mixed reality gaming environments that can be created by using floor projection, and tackles the issue of enabling accurate and robust tracking of off-the-shelf robots endowed with limited sensing capabilities. The proposed solution is implemented by fusing visual tracking data gathered via a fixed camera in a smart environment with odometry data obtained from robot's on-board sensors. The solution has been tested within a phygital gaming platform in a real usage scenario, by experimenting with a robotic game that exhibits many challenging situations which would be hard to manage using conventional tracking techniques.",https://ieeexplore.ieee.org/document/8094867/,IEEE Transactions on Emerging Topics in Computing,1 July-Sept. 2020,ieeexplore
10.1109/TNN.2009.2032183,SVR Versus Neural-Fuzzy Network Controllers for the Sagittal Balance of a Biped Robot,IEEE,Journals,"The real-time balance control of an eight-link biped robot using a zero moment point (ZMP) dynamic model is difficult due to the processing time of the corresponding equations. To overcome this limitation, two alternative intelligent computing control techniques were compared: one based on support vector regression (SVR) and another based on a first-order Takagi-Sugeno-Kang (TSK)-type neural-fuzzy (NF) network. Both methods use the ZMP error and its variation as inputs and the output is the correction of the robot's torso necessary for its sagittal balance. The SVR and the NF were trained based on simulation data and their performance was verified with a real biped robot. Two performance indexes are proposed to evaluate and compare the online performance of the two control methods. The ZMP is calculated by reading four force sensors placed under each robot's foot. The gait implemented in this biped is similar to a human gait that was acquired and adapted to the robot's size. Some experiments are presented and the results show that the implemented gait combined either with the SVR controller or with the TSK NF network controller can be used to control this biped robot. The SVR and the NF controllers exhibit similar stability, but the SVR controller runs about 50 times faster.",https://ieeexplore.ieee.org/document/5276806/,IEEE Transactions on Neural Networks,Dec. 2009,ieeexplore
10.1109/TSMCA.2003.809171,Self-organization of behavioral primitives as multiple attractor dynamics: A robot experiment,IEEE,Journals,"This paper investigates how behavior primitives are self-organized in a neural network model utilizing a distributed representation scheme. The model is characterized by so-called parametric biases which adaptively modulate the encoding of different behavior patterns in a single recurrent neural net (RNN). Our experiments, using a real robot arm, showed that a set of end-point and oscillatory behavior patterns are learned by self-organizing fixed points and limit cycle dynamics that form behavior primitives. It was also found that diverse novel behavior patterns can be generated by modulating the parametric biases arbitrarily. Our analysis showed that such diversity in behavior generation emerges because a nonlinear map is self-organized between the space of parametric biases and that of the behavior patterns. The origin of the observed nonlinearity from the distributed representation is discussed. This paper investigates how behavior primitives are self-organized in a neural network model utilizing a distributed representation scheme. Our robot experiments showed that a set of end-point and oscillatory behavior patterns are learned by self-organizing fixed points and limit cycle dynamics that form behavior primitives. It was also found that diverse novel behavior patterns, in addition to previously learned patterns, can be generated by taking advantage of nonlinear effects that emerge from the distributed representation.",https://ieeexplore.ieee.org/document/1235981/,"IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans",July 2003,ieeexplore
10.1109/LRA.2017.2665694,Shakey 2016—How Much Does it Take to Redo Shakey the Robot?,IEEE,Journals,"Shakey the robot was one of the first autonomous robots that showed impressive capabilities of navigation and mobile manipulation. Since then, robotics research has made great progress, showing more and more capable robotic systems for a large variety of application domains and tasks. In this letter, we look back on decades of research by rebuilding Shakey with modern robotics technology in the open-source Shakey 2016 system. Hereby, we demonstrate the impact of research by showing that ideas from the original Shakey are still alive in state-of-the-art systems, while robotics in general has improved to deliver more robust and more capable software and hardware. Our Shakey 2016 system has been implemented on real robots and leverages mostly open-source software. We experimentally evaluate the system in real-world scenarios on a PR2 robot and a Turtlebot-based robot and particularly investigate the development effort. The experiments documented in this letter demonstrate that results from robotics research are readily available for building complex robots such as Shakey within a short amount of time and little effort.",https://ieeexplore.ieee.org/document/7847341/,IEEE Robotics and Automation Letters,April 2017,ieeexplore
10.1109/TCDS.2016.2565542,Spatial Concept Acquisition for a Mobile Robot That Integrates Self-Localization and Unsupervised Word Discovery From Spoken Sentences,IEEE,Journals,"In this paper, we propose a novel unsupervised learning method for the lexical acquisition of words related to places visited by robots, from human continuous speech signals. We address the problem of learning novel words by a robot that has no prior knowledge of these words except for a primitive acoustic model. Furthermore, we propose a method that allows a robot to effectively use the learned words and their meanings for self-localization tasks. The proposed method is nonparametric Bayesian spatial concept acquisition method (SpCoA) that integrates the generative model for self-localization and the unsupervised word segmentation in uttered sentences via latent variables related to the spatial concept. We implemented the proposed method SpCoA on SIGVerse, which is a simulation environment, and TurtleBot2, which is a mobile robot in a real environment. Further, we conducted experiments for evaluating the performance of SpCoA. The experimental results showed that SpCoA enabled the robot to acquire the names of places from speech sentences. They also revealed that the robot could effectively utilize the acquired spatial concepts and reduce the uncertainty in self-localization.",https://ieeexplore.ieee.org/document/7467531/,IEEE Transactions on Cognitive and Developmental Systems,Dec. 2016,ieeexplore
10.1109/ACCESS.2021.3111706,Tennis Robot Design via Internet of Things and Deep Learning,IEEE,Journals,"To efficiently integrate deep learning (DL) and Internet of Things (IoT) with tennis robot research, the concept and characteristics of mask region-convolutional neural network (Mask R-CNN) under DL are analyzed. Then, the IoT radio frequency identification (RFID) is introduced and the suitable RFID structure is established. Moreover, the real-time intelligent image recognition tennis robot is designed, and simulation experiment on the robot is performed. The results show that when the positioning label is eight, the convergence speed of the optimized algorithm is improved relative to the unoptimized one, and the error is reduced by 0.82. The positioning algorithm proposed in this research has high convergence speed and small system error. The positioning accuracy of the tennis robot is improved by at least 6%, the positioning targets are close to the target to be located, and the tennis robot has the best shortest path effect. In addition, the tennis recognition algorithm based on Mask R-CNN can accurately distinguish dense tennis balls with high accuracy. It shows that the tennis robot positioning algorithm and target recognition algorithm proposed in this research are of practical adoption value.",https://ieeexplore.ieee.org/document/9535167/,IEEE Access,2021,ieeexplore
10.1109/JIOT.2021.3068736,Terra: A Smart and Sensible Digital Twin Framework for Robust Robot Deployment in Challenging Environments,IEEE,Journals,"Digital twin (DT) systems that replicate the physical world digitally are powerful tools for monitoring physical systems and evaluating algorithms, but current DT systems are commonly not applicable for robotic deployment and investigation. Meanwhile, current 3-D simulation-based robotic platforms do not model the dynamics of the physical world on-the-fly as done in DT systems, limiting their potential for the development of robotics in challenging environments. To tackle this issue, we propose the first robot-centered smart DT framework, namely, Terra, to facilitate the deployment of robots in challenging environments. The proposed Terra framework introduces a comprehensive DT representation to encode the useful real-time dynamics of both the physical world and the robot agent deployed therein. A multiview multimodality perception module is further devised for Terra to obtain high-level semantics and deliver a precise description of the current status of the environment and the robot agent. By mapping the perceived results to the virtual replica of the physical environment, Terra actively updates the action policy and sends it back to the agent, forming an integral and real-time information feedback loop. In practice, to help demonstrate the effectiveness and feasibility of the proposed framework, we deliberately set up a challenging unordered physical environment with many obstacles and a very simple robot aiming to fulfill a navigation task. Empirical results show that the proposed Terra framework successfully facilitates the robot to accomplish the task without causing hazards.",https://ieeexplore.ieee.org/document/9386242/,IEEE Internet of Things Journal,"15 Sept.15, 2021",ieeexplore
10.1109/ACCESS.2020.2978077,The Experience-Memory Q-Learning Algorithm for Robot Path Planning in Unknown Environment,IEEE,Journals,"In order to solve the problem of slow convergence speed and long planned path when the robot plans a path in unknown environment by using Q-learning algorithm, we propose the Experience-Memory Q-Learning (EMQL) algorithm based on the continuous update of the shortest distance from the current state node to the start point. The autonomous learning ability of the robot is enhanced by the different role assignments of two tables in the proposed algorithm. EM table with $(m*1)$ dimension is designed to record the distance information, reflecting the learning process of the robot. Q table is adopted as an auxiliary guidance for the experience transfer strategy and experience reuse strategy, and these strategies enable the robot accomplish the task even if the destination is changed or the path is blocked. Further, the learning efficiency of the robot in the EMQL algorithm is improved by the dual reward mechanism consisting of static reward and dynamic reward. The static reward is designed to prevent the robot from exploring a state node excessively. The dynamic reward is responsible for helping the robot avoid searching blindly in unknown environment. We test the effectiveness of the proposed algorithm on both grid maps and road network maps. The comparison results in planning time, iteration times and path length show that the performance of the EMQL algorithm is superior to Q-learning algorithm in convergence speed and optimization ability. Additionally, the practicability of the proposed algorithm is validated in a real-world experiment using the Turtlebot3 burger robot.",https://ieeexplore.ieee.org/document/9022975/,IEEE Access,2020,ieeexplore
10.1109/TRO.2012.2228134,The Impact of Human–Robot Interfaces on the Learning of Visual Objects,IEEE,Journals,"This paper studies the impact of interfaces, allowing nonexpert users to efficiently and intuitively teach a robot to recognize new visual objects. We present challenges that need to be addressed for real-world deployment of robots capable of learning new visual objects in interaction with everyday users. We argue that in addition to robust machine learning and computer vision methods, well-designed interfaces are crucial for learning efficiency. In particular, we argue that interfaces can be key in helping nonexpert users to collect good learning examples and, thus, improve the performance of the overall learning system. Then, we present four alternative human-robot interfaces: Three are based on the use of a mediating artifact (smartphone, wiimote, wiimote and laser), and one is based on natural human gestures (with a Wizard-of-Oz recognition system). These interfaces mainly vary in the kind of feedback provided to the user, allowing him to understand more or less easily what the robot is perceiving and, thus, guide his way of providing training examples differently. We then evaluate the impact of these interfaces, in terms of learning efficiency, usability, and user's experience, through a real world and large-scale user study. In this experiment, we asked participants to teach a robot 12 different new visual objects in the context of a robotic game. This game happens in a home-like environment and was designed to motivate and engage users in an interaction where using the system was meaningful. We then discuss results that show significant differences among interfaces. In particular, we show that interfaces such as the smartphone interface allows nonexpert users to intuitively provide much better training examples to the robot, which is almost as good as expert users who are trained for this task and are aware of the different visual perception and machine learning issues. We also show that artifact-mediated teaching is significantly more efficient for robot learning, and equally good in terms of usability and user's experience, than teaching thanks to a gesture-based human-like interaction.",https://ieeexplore.ieee.org/document/6384810/,IEEE Transactions on Robotics,April 2013,ieeexplore
10.1109/TCDS.2017.2712712,Toward Brain-Inspired Learning With the Neuromorphic Snake-Like Robot and the Neurorobotic Platform,IEEE,Journals,"Neurorobotic mimics the structural and functional principles of living creature systems. Modeling a single system by robotic hardware and software has existed for decades. However, an integrated toolset studying the interaction of all systems has not been demonstrated yet. We present a hybrid neuromorphic computing paradigm to bridge this gap by combining the neurorobotics platform (NRP) with the neuromorphic snake-like robot (NeuroSnake). This paradigm encompasses the virtual models, neuromorphic sensing and computing capabilities, and physical bio-inspired bodies, with which an experimenter can design and execute both in-silico and in-vivo robotic experimentation easily. The NRP is a public Web-based platform for easily testing brain models with virtual bodies and environments. The NeuroSnake is a bio-inspired robot equipped with a silico-retina sensor and neuromorphic computer for power-efficiency applications. We illustrate the efficiencies of our paradigm with an easy designing of a visual pursuit experiment in the NRP. We study two automatic behavior learning tasks which are further integrated into a complex task of semi-autonomous pole climbing. The result shows that robots could build new learning rules in a less explicit manner inspired by living creatures. Our method gives an alternative way to efficiently develop complex behavior control of the ro As spiking neural network is a bio-inspired neural network and the NeuroSnake robot is equipped with a spike-based silicon retina camera, the control system can be easily implemented via spiking neurons simulated on neuromorphic hardware, such as SpiNNaker.bot.",https://ieeexplore.ieee.org/document/7945270/,IEEE Transactions on Cognitive and Developmental Systems,March 2019,ieeexplore
10.1109/TASE.2017.2731371,Toward Socially Aware Robot Navigation in Dynamic and Crowded Environments: A Proactive Social Motion Model,IEEE,Journals,"Safe and social navigation is the key to deploying a mobile service robot in a human-centered environment. Widespread acceptability of mobile service robots in daily life is hindered by robot's inability to navigate in crowded and dynamic human environments in a socially acceptable way that would guarantee human safety and comfort. In this paper, we propose an effective proactive social motion model (PSMM) that enables a mobile service robot to navigate safely and socially in crowded and dynamic environments. The proposed method considers not only human states (position, orientation, motion, field of view, and hand poses) relative to the robot but also social interactive information about human-object and human group interactions. This allows development of the PSMM that consists of elements of an extended social force model and a hybrid reciprocal velocity obstacle technique. The PSMM is then combined with a path planning technique to generate a motion planning system that drives a mobile robot in a socially acceptable manner and produces respectful and polite behaviors akin to human movements. Note to Practitioners-In this paper, we validated the effectiveness and feasibility of the proposed proactive social motion model (PSMM) through both simulation and real-world experiments under the newly proposed human comfortable safety indices. To do that, we first implemented the entire navigation system using the open-source robot operating system. We then installed it in a simulated robot model and conducted experiments in a simulated shopping mall-like environment to verify its effectiveness. We also installed the proposed algorithm on our mobile robot platform and conducted experiments in our office-like laboratory environment. Our results show that the developed socially aware navigation framework allows a mobile robot to navigate safely, socially, and proactively while guaranteeing human safety and comfort in crowded and dynamic environments. In this paper, we examined the proposed PSMM with a set of predefined parameters selected based on our empirical experiences about the robot mechanism and selected social environment. However, in fact a mobile robot might need to adapt to various contextual and cultural situations in different social environments. Thus, it should be equipped with an online adaptive interactive learning mechanism allowing the robot to learn to auto-adjust their parameters according to such embedded environments. Using machine learning techniques, e.g., inverse reinforcement learning [1] to optimize the parameter set for the PSMM could be a promising research direction to improve adaptability of mobile service robots in different social environments. In the future, we will evaluate the proposed framework based on a wider variety of scenarios, particularly those with different social interaction situations and dynamic environments. Furthermore, various kinds of social cues and signals introduced in [2] and [3] will be applied to extend the proposed framework in more complicated social situations and contexts. Last but not least, we will investigate different machine learning techniques and incorporate them in the PSMM in order to allow the robot to automatically adapt to diverse social environments.",https://ieeexplore.ieee.org/document/8011466/,IEEE Transactions on Automation Science and Engineering,Oct. 2017,ieeexplore
10.1109/ACCESS.2021.3080517,Towards Open and Expandable Cognitive AI Architectures for Large-Scale Multi-Agent Human-Robot Collaborative Learning,IEEE,Journals,"Learning from Demonstration (LfD) constitutes one of the most robust methodologies for constructing efficient cognitive robotic systems. Despite the large body of research works already reported, current key technological challenges include those of multi-agent learning and long-term autonomy. Towards this direction, a novel cognitive architecture for multi-agent LfD robotic learning is introduced in this paper, targeting to enable the reliable deployment of open, scalable and expandable robotic systems in large-scale and complex environments. In particular, the designed architecture capitalizes on the recent advances in the Artificial Intelligence (AI) (and especially the Deep Learning (DL)) field, by establishing a Federated Learning (FL)-based framework for incarnating a multi-human multi-robot collaborative learning environment. The fundamental conceptualization relies on employing multiple AI-empowered cognitive processes (implementing various robotic tasks) that operate at the edge nodes of a network of robotic platforms, while global AI models (underpinning the aforementioned robotic tasks) are collectively created and shared among the network, by elegantly combining information from a large number of human-robot interaction instances. Regarding pivotal novelties, the designed cognitive architecture a) introduces a new FL-based formalism that extends the conventional LfD learning paradigm to support large-scale multi-agent operational settings, b) elaborates previous FL-based self-learning robotic schemes so as to incorporate the human in the learning loop and c) consolidates the fundamental principles of FL with additional sophisticated AI-enabled learning methodologies for modelling the multi-level inter-dependencies among the robotic tasks. The applicability of the proposed framework is explained using an example of a real-world industrial case study (subject to ongoing research activities) for agile production-based Critical Raw Materials (CRM) recovery.",https://ieeexplore.ieee.org/document/9431107/,IEEE Access,2021,ieeexplore
10.1109/LRA.2021.3070305,Underwater Soft Robot Modeling and Control With Differentiable Simulation,IEEE,Journals,"Underwater soft robots are challenging to model and control because of their high degrees of freedom and their intricate coupling with water. In this letter, we present a method that leverages the recent development in differentiable simulation coupled with a differentiable, analytical hydrodynamic model to assist with the modeling and control of an underwater soft robot. We apply this method to Starfish, a customized soft robot design that is easy to fabricate and intuitive to manipulate. Our method starts with data obtained from the real robot and alternates between simulation and experiments. Specifically, the simulation step uses gradients from a differentiable simulator to run system identification and trajectory optimization, and the experiment step executes the optimized trajectory on the robot to collect new data to be fed into simulation. Our demonstration on Starfish shows that proper usage of gradients from a differentiable simulator not only narrows down its simulation-to-reality gap but also improves the performance of an open-loop controller in real experiments.",https://ieeexplore.ieee.org/document/9392257/,IEEE Robotics and Automation Letters,July 2021,ieeexplore
10.1109/TAMD.2010.2097260,Using the Rhythm of Nonverbal Human–Robot Interaction as a Signal for Learning,IEEE,Journals,"Human-robot interaction is a key issue in order to build robots for everyone. The difficulty for people to understand how robots work and how they must be controlled will be one of the mains limit for broad robotics. In this paper, we study a new way of interacting with robots without needing to understand how robots work or to give them explicit instructions. This work is based on psychological data showing that synchronization and rhythm are very important features for pleasant interaction. We propose a biologically inspired architecture using rhythm detection to build an internal reward for learning. After showing the results of keyboard interactions, we present and discuss the results of real human-robots (Aibo and Nao) interactions. We show that our minimalist control architecture allows the discovery and learning of arbitrary sensorimotor associations games with expert users. With nonexpert users, we show that using only the rhythm information is not sufficient for learning all the associations due to the different strategies used by the human. Nevertheless, this last experiment shows that the rhythm is still allowing the discovery of subsets of associations, being one of the promising signal of tomorrow social applications.",https://ieeexplore.ieee.org/document/5664771/,IEEE Transactions on Autonomous Mental Development,March 2011,ieeexplore
10.1109/TSMCB.2010.2089978,"Walking Motion Generation, Synthesis, and Control for Biped Robot by Using PGRL, LPI, and Fuzzy Logic",IEEE,Journals,"This paper proposes the implementation of fuzzy motion control based on reinforcement learning (RL) and Lagrange polynomial interpolation (LPI) for gait synthesis of biped robots. First, the procedure of a walking gait is redefined into three states, and the parameters of this designed walking gait are determined. Then, the machine learning approach applied to adjusting the walking parameters is policy gradient RL (PGRL), which can execute real-time performance and directly modify the policy without calculating the dynamic function. Given a parameterized walking motion designed for biped robots, the PGRL algorithm automatically searches the set of possible parameters and finds the fastest possible walking motion. The reward function mainly considered is first the walking speed, which can be estimated from the vision system. However, the experiment illustrates that there are some stability problems in this kind of learning process. To solve these problems, the desired zero moment point trajectory is added to the reward function. The results show that the robot not only has more stable walking but also increases its walking speed after learning. This is more effective and attractive than manual trial-and-error tuning. LPI, moreover, is employed to transform the existing motions to the motion which has a revised angle determined by the fuzzy motion controller. Then, the biped robot can continuously walk in any desired direction through this fuzzy motion control. Finally, the fuzzy-based gait synthesis control is demonstrated by tasks and point- and line-target tracking. The experiments show the feasibility and effectiveness of gait learning with PGRL and the practicability of the proposed fuzzy motion control scheme.",https://ieeexplore.ieee.org/document/5640679/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",June 2011,ieeexplore
10.1109/ACCESS.2020.3030963,Waypoint Mobile Robot Exploration Based on Biologically Inspired Algorithms,IEEE,Journals,"This article proposes stochastic exploration algorithms for mobile robot exploration problems. Navigation with uncertain conditions in the absence of initial parameters is a situation wherein precomputation and prediction are impossible for a robot. Therefore, stochastic optimization techniques were applied to find the optimal solution for the robot exploration problem. Driving to the unknown areas, the robot updates the frontier line of sensor visibility during the exploration mission. The points of the frontier line are assumed as the swarm population with their own positions and costs, which allows the computation of the next global waypoint. The calculation of global waypoints is carried out by a nature-inspired optimization algorithm that can place a waypoint in uncertainties. This study offers to apply three metaheuristic algorithms individually, such as Whale Optimization, Grey Wolf Optimizer, and Particle Swarm Optimization algorithms, for comparison and testing their performances in the mobile robotics. At first, the simulations based on the proposed exploration algorithms were implemented and evaluated in a created environment. The results were compared in a single and average cases. Then, the real-world experiments using Grey Wolf Optimizer exploration algorithm were conducted in the different types of environments using MATLAB-ROS integration tool. These results proved the effectiveness and applicability of the bio-inspired optimization algorithm in the mobile robotics.",https://ieeexplore.ieee.org/document/9223657/,IEEE Access,2020,ieeexplore
10.1109/LRA.2019.2961598,When Your Robot Breaks: Active Learning During Plant Failure,IEEE,Journals,"Detecting and adapting to catastrophic failures in robotic systems requires a robot to learn its new dynamics quickly and safely to best accomplish its goals. To address this challenging problem, we propose probabilistically-safe, online learning techniques to infer the altered dynamics of a robot at the moment a failure (e.g., physical damage) occurs. We combine model predictive control and active learning within a chance-constrained optimization framework to safely and efficiently learn the new plant model of the robot. We leverage a neural network for function approximation in learning the latent dynamics of the robot under failure conditions. Our framework generalizes to various damage conditions while being computationally light-weight to advance real-time deployment. We empirically validate within a virtual environment that we can regain control of a severely damaged aircraft in seconds and require only 0.1 seconds to find safe, information-rich trajectories, outperforming state-of-the-art approaches.",https://ieeexplore.ieee.org/document/8938725/,IEEE Robotics and Automation Letters,April 2020,ieeexplore
10.1109/JIOT.2020.2986685,WiFi-Based Indoor Robot Positioning Using Deep Fuzzy Forests,IEEE,Journals,"Addressing the positioning problem of a mobile robot remains challenging to date despite many years of research. Indoor robot positioning strategies developed in the literature either rely on sophisticated computer vision techniques to handle visual inputs or require strong domain knowledge for nonvisual sensors. Although some systems have been deployed, the former may be lacking due to the intrinsic limitation of cameras (such as calibration, data association, system initialization, etc.) and the latter usually only works under certain environment layouts and additional equipment. To cope with those issues, we design a lightweight indoor robot positioning system which operates on cost-effective WiFi-based received signal strength (RSS) and could be readily pluggable into any existing WiFi network infrastructures. Moreover, a novel deep fuzzy forest is proposed to inherit the merits of decision trees and deep neural networks within an end-to-end trainable architecture. Real-world indoor localization experiments are conducted and results demonstrate the superiority of the proposed method over the existing approaches.",https://ieeexplore.ieee.org/document/9060874/,IEEE Internet of Things Journal,Nov. 2020,ieeexplore
10.1109/IROS.1992.601935,"""Arnie P."" - A Robot Golfing System Using Binocular And A Heuristic Feedback Mechanism",IEEE,Conferences,"This paper describes a robot vision golfing system. The Automated Robotic Navigational unit with Intelligent Eye and Putter (ARNIE P)<sup>τ</sup>project was initiated to investigate the problems and develop software solutions for robotic tasks that require good hand-eye coordination and an intelligent sensor feedback mechanism. This system has only one frame buffer and no specialized hardware, so quasi-real time 3D tracking is accomplished in software using the Unix Spline facility. The single frame buffer and digitizer, stores and retains the location of the ball from two separate cameras during the time interval between the golf ball initially crossing a trigger scan line and the ball coming to a complete stop. The most novel aspect of this study is that by attempting to build or model a difficult perceptory task such as golf, which requires integrating many complicated computational pieces (binocular stereo vision, robot arm motion, heuristic feedback, learning), it appears to be a good plarform to experiment with artificial intelligence techniques and robotics.",https://ieeexplore.ieee.org/document/601935/,Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems,7-10 July 1992,ieeexplore
10.1109/IJCNN48605.2020.9207496,"""I’m Sorry Dave, I’m Afraid I Can’t Do That"" Deep Q-Learning from Forbidden Actions",IEEE,Conferences,"The use of Reinforcement Learning (RL) is still restricted to simulation or to enhance human-operated systems through recommendations. Real-world environments (e.g. industrial robots or power grids) are generally designed with safety constraints in mind implemented in the shape of valid actions masks or contingency controllers. For example, the range of motion and the angles of the motors of a robot can be limited to physical boundaries. Violating constraints thus results in rejected actions or entering in a safe mode driven by an external controller, making RL agents incapable of learning from their mistakes. In this paper, we propose a simple modification of a state-of-the-art deep RL algorithm (DQN), enabling learning from forbidden actions. To do so, the standard Q-learning update is enhanced with an extra safety loss inspired by structured classification. We empirically show that it reduces the number of hit constraints during the learning phase and accelerates convergence to near-optimal policies compared to using standard DQN. Experiments are done on a Visual Grid World Environment and the TextWorld domain.",https://ieeexplore.ieee.org/document/9207496/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/ISSCC.2019.8662455,2.5 A 40×40 Four-Neighbor Time-Based In-Memory Computing Graph ASIC Chip Featuring Wavefront Expansion and 2D Gradient Control,IEEE,Conferences,"Single-source shortest path (SSP) problems have a rich history of algorithm development [1-3]. SSP has many applications including AI decision making, robot navigation, VLSI signal routing, autonomous vehicles and many other classes of problems that can be mapped onto graphs. Conventional algorithms rely on sequentially traversing the search space, which is inherently limited by traditional computer architecture. In graphs which become very large, this slow processing time can become a bottleneck in real world applications. We propose a time-based ASIC to address this issue. Our design leverages a dedicated hardware implementation to solve these problems in linear time complexity with superior energy efficiency. A $40\times40$ four-neighbor grid implements a wavefront (WF) expansion with a first-in lockout mechanism to enable traceback. Outside the array, a programmable resistive ladder provides bias voltages to the edge cells, which enables pulse shaping reminiscent of the A* algorithm [3].",https://ieeexplore.ieee.org/document/8662455/,2019 IEEE International Solid- State Circuits Conference - (ISSCC),17-21 Feb. 2019,ieeexplore
10.1109/AIMS52415.2021.9466061,3D Control System of Arm Robot Prototype for Skin Cancer Detection,IEEE,Conferences,"Arm robot has a lack of control systems that depend on desired control for assistive medical. Our laboratory robotics &amp; artificial intelligent at Padjadjaran University created skin cancer detection of arm robot with dark flow framework to identify skin cancer in real-time. The implementation of the arm robot was for increasing the accuracy, precision, and stability. The main purpose of this paper was to control an arm robot for skin cancer detection that is capable to scan the whole body skin to localize the skin cancers by driving the manipulator in circular or elliptical skimming. To initiate the communication with the arm robot which used Dynamixel as the actuators, we applied USB2Dynamixel as the communicator. SMPS2Dynamixel was used to supply the power into servo motors. 3D Control system software has designed, and it had some features such as; forward kinematic movement, inverse kinematic movement, and 3D simulation to help user visualize the position of the arm robot. Control software was built in MATLAB GUI environment and 3D simulation adapted Peter Corke Robotics Toolbox.",https://ieeexplore.ieee.org/document/9466061/,2021 International Conference on Artificial Intelligence and Mechatronics Systems (AIMS),28-30 April 2021,ieeexplore
10.1109/ICRA.2013.6631080,"3D modeling, distance and gradient computation for motion planning: A direct GPGPU approach",IEEE,Conferences,"The Kinect sensor and KinectFusion algorithm have revolutionized environment modeling. We bring these advances to optimization-based motion planning by computing the obstacle and self-collision avoidance objective functions and their gradients directly from the KinectFusion model on the GPU without ever transferring any model to the CPU. Based on this, we implement a proof-of-concept motion planner which we validate in an experiment with a 19-DOF humanoid robot using real data from a tabletop work space. The summed-up time from taking the first look at the scene until the planned path avoiding an obstacle on the table is executed is only three seconds.",https://ieeexplore.ieee.org/document/6631080/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/HUMANOIDS.2016.7803415,3D object segmentation for shelf bin picking by humanoid with deep learning and occupancy voxel grid map,IEEE,Conferences,"Picking objects in a narrow space such as shelf bins is an important task for humanoid to extract target object from environment. In those situations, however, there are many occlusions between the camera and objects, and this makes it difficult to segment the target object three dimensionally because of the lack of three dimensional sensor inputs. We address this problem with accumulating segmentation result with multiple camera angles, and generating voxel model of the target object. Our approach consists of two components: first is object probability prediction for input image with convolutional networks, and second is generating voxel grid map which is designed for object segmentation. We evaluated the method with the picking task experiment for target objects in narrow shelf bins. Our method generates dense 3D object segments even with occlusions, and the real robot successfully picked target objects from the narrow space.",https://ieeexplore.ieee.org/document/7803415/,2016 IEEE-RAS 16th International Conference on Humanoid Robots (Humanoids),15-17 Nov. 2016,ieeexplore
10.1109/AIID51893.2021.9456574,3D scene geometry estimation method of substation inspection robot based on lightweight neural network,IEEE,Conferences,"Understanding 3D scene geometry from video is a basic subject of visual perception. It includes many classic computer vision tasks, such as depth recovery, traffic estimation, visual odometer. Recent work has proved that deep learning can be applied to scene understanding problems. But they all have some inherent limitations. For example, they need stereo cameras as additional devices for data acquisition, or can't explicitly deal with non-rigid and occlusion. The environment in the substation is complex, and there are many devices. In the working process of inspection robot, the target is very easy to be blocked, and it is difficult to deploy directly by traditional methods. In addition, the real-time performance of neural network is very important for electric inspection robot. In this paper, 3D scene geometry estimation method of substation inspection robot is proposed, which consists of two main parts: GeoNet module and pruning module. Experiments show that the proposed method can be effectively applied to electric inspection robot.",https://ieeexplore.ieee.org/document/9456574/,2021 IEEE International Conference on Artificial Intelligence and Industrial Design (AIID),28-30 May 2021,ieeexplore
10.1109/ICRA.2018.8461228,3DOF Pedestrian Trajectory Prediction Learned from Long-Term Autonomous Mobile Robot Deployment Data,IEEE,Conferences,"This paper presents a novel 3DOF pedestrian trajectory prediction approach for autonomous mobile service robots. While most previously reported methods are based on learning of 2D positions in monocular camera images, our approach uses range-finder sensors to learn and predict 3DOF pose trajectories (i.e. 2D position plus 1D rotation within the world coordinate system). Our approach, T-Pose-LSTM (Temporal 3DOF-Pose Long-Short-Term Memory), is trained using long-term data from real-world robot deployments and aims to learn context-dependent (environment- and time-specific) human activities. Our approach incorporates long-term temporal information (i.e. date and time) with short-term pose observations as input. A sequence-to-sequence LSTM encoder-decoder is trained, which encodes observations into LSTM and then decodes the resulting predictions. On deployment, the approach can perform on-the-fly prediction in real-time. Instead of using manually annotated data, we rely on a robust human detection, tracking and SLAM system, providing us with examples in a global coordinate system. We validate the approach using more than 15 km of pedestrian trajectories recorded in a care home environment over a period of three months. The experiments show that the proposed T-Pose-LSTM model outperforms the state-of-the-art 2D-based method for human trajectory prediction in long-term mobile robot deployments.",https://ieeexplore.ieee.org/document/8461228/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/CNNA.1998.685360,A CNN stereo vision hardware system for autonomous robot navigation,IEEE,Conferences,"The high parallel analogue processing rate makes the cellular neural networks paradigm really useful in such a problems where real-time replies to external stimuli are required. The development of an effective system for autonomous robot navigation can find a valid support from this research. Moreover, the growth of new CNN algorithms can afford the necessary feedback to the hardware developers to improve their realisations. In this paper some measurements of a stereo-vision algorithm on a CNN hardware implementation (the 720DPCNN system) are given.",https://ieeexplore.ieee.org/document/685360/,1998 Fifth IEEE International Workshop on Cellular Neural Networks and their Applications. Proceedings (Cat. No.98TH8359),14-17 April 1998,ieeexplore
10.1109/ISCAS.2003.1205068,A CNN-based chip for robot locomotion control,IEEE,Conferences,"In this paper a VLSI chip for real-time locomotion control in legged robots is introduced. The control is based on the biological paradigm of Central Pattern Generator (CPG) and is implemented by a Cellular Neural Network (CNN). The gait generation is accomplished by the CNN and is fully analog, while a digital controller modulates the behavior of the CNN-based CPG to allow the locomotion system to adapt to sensory feedback. The chip is designed with a switched-capacitor technique, fundamental to address the speed control issue. Experimental results on the first prototype are illustrated. These results confirm the suitability of the approach and open the way to the design of a fully autonomous bio-inspired micro-robot.",https://ieeexplore.ieee.org/document/1205068/,"Proceedings of the 2003 International Symposium on Circuits and Systems, 2003. ISCAS '03.",25-28 May 2003,ieeexplore
10.1109/ACCC51160.2020.9347897,A Comparative Analysis of Kinematics of Industrial Robot KUKA KR 60–3 Using Scientific Computing Languages,IEEE,Conferences,"In the field of robotics, there are kinematic analysis methods that are responsible for describing the positions and orientations of the end effectors, as well as the angles, velocities and trajectories of industrial robots; such techniques are: forward kinematics, inverse kinematics and velocity kinematics. For the solutions of these complex mathematical calculations, the use of scientific computing languages or programs is required; which more and more algorithms, libraries and complements are implemented, that achieve a reduction in programming hours and result in the creation of better solutions in areas of all kinds. For this reason, the kinematics of the Industrial Robot KUKA KR 60-3 was programmed in the languages and programs most used in scientific computing, with the aim of comparing the performance (real time) when carrying out symbolic and numerical analysis in said studies.",https://ieeexplore.ieee.org/document/9347897/,2020 Asia Conference on Computers and Communications (ACCC),18-20 Sept. 2020,ieeexplore
10.1109/FDL53530.2021.9568376,A Container-based Design Methodology for Robotic Applications on Kubernetes Edge-Cloud architectures,IEEE,Conferences,"Programming modern Robots' missions and behavior has become a very challenging task. The always increasing level of autonomy of such platforms requires the integration of multi-domain software applications to implement artificial intelligence, cognition, and human-robot/robot-robot interaction applications. In addition, to satisfy both functional and nonfunctional requirements such as reliability and energy efficiency, robotic SW applications have to be properly developed to take advantage of heterogeneous (Edge-Fog-Cloud) architectures. In this context, containerization and orchestration are becoming a standard practice as they allow for better information flow among different network levels as well as increased modularity in the use of software components. Nevertheless, the adoption of such a practice along the design flow, from simulation to the deployment of complex robotic applications by addressing the de-facto development standards (i.e., robotic operating system - ROS - compliancy for robotic applications) is still an open problem. We present a design methodology based on Docker and Kubernetes that enables containerization and orchestration of ROS-based robotic SW applications for heterogeneous and hierarchical HW architectures. The design methodology allows for (i) integration and verification of multi-domain components since early in the design flow, (ii) task-to-container mapping techniques to guarantee minimum overhead in terms of performance and memory footprint, and (iii) multi-domain verification of functional and non-functional constraints before deployment. We present the results obtained in a real case of study, in which the design methodology has been applied to program the mission of a Robotnik RB-Kairos mobile robot in an industrial agile production chain. The source code of the mobile robot is publicly available on GitHub.",https://ieeexplore.ieee.org/document/9568376/,2021 Forum on specification & Design Languages (FDL),8-10 Sept. 2021,ieeexplore
10.1109/CACRE50138.2020.9230347,A Distributed Reward Algorithm for Inverse Kinematics of Arm Robot,IEEE,Conferences,"Traditional methods of inverse kinematics of robots always adopt analytical approach and numerical approach to solve the continuous state and action problems with experience and experiment mostly, which require much time and work in reality work scene, especially for robots with complex structure. This paper proposes a method based on reinforcement learning TD3 network, which is constructed by PyTorch to find the inverse solution from another point of view. A set of improved distributed multiple rewards which choose the position difference between adjacent joints as the reward standard are designed to optimize the solution, avoid solving unreachable points and prevent the mechanical structure from being damaged also in the environment of five-degree-of-freedom arm robot. The validity of above method is verified by simulation experiment results.",https://ieeexplore.ieee.org/document/9230347/,"2020 5th International Conference on Automation, Control and Robotics Engineering (CACRE)",19-20 Sept. 2020,ieeexplore
10.1109/IJCNN48605.2020.9207308,A Few-shot Dynamic Obstacle Avoidance Strategy in Unknown Environments,IEEE,Conferences,"Obstacle avoidance is one of the basic capabilities of intelligent mobile robots. With the diversification of the application environment, mobile robots are required to avoid obstacles with higher generality. Benefit from the development of mobile platform and deep learning algorithm in recent years, we conceive a few-shot dynamic obstacle avoidance strategy to meet this higher generality demand. Under this metric-based meta-learning method, mobile robots can quickly adapt to unknown environments by learning from several samples. In order to verify its effectiveness, we use this strategy to train a model and deploy it to the mobile robot and run multiple obstacle avoidance recognition tests in the real-world environment. The results of experiments performed on the mobile robot platform illustrates a good performance and verifies our proposed strategy. In addition to analyzing the experimental results, the advantages, disadvantages as well as application potential of the proposed strategy as a decision aid are also discussed.",https://ieeexplore.ieee.org/document/9207308/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/ICRA.2019.8793690,A Fog Robotics Approach to Deep Robot Learning: Application to Object Recognition and Grasp Planning in Surface Decluttering,IEEE,Conferences,"The growing demand of industrial, automotive and service robots presents a challenge to the centralized Cloud Robotics model in terms of privacy, security, latency, bandwidth, and reliability. In this paper, we present a `Fog Robotics' approach to deep robot learning that distributes compute, storage and networking resources between the Cloud and the Edge in a federated manner. Deep models are trained on non-private (public) synthetic images in the Cloud; the models are adapted to the private real images of the environment at the Edge within a trusted network and subsequently, deployed as a service for low-latency and secure inference/prediction for other robots in the network. We apply this approach to surface decluttering, where a mobile robot picks and sorts objects from a cluttered floor by learning a deep object recognition and a grasp planning model. Experiments suggest that Fog Robotics can improve performance by sim-to-real domain adaptation in comparison to exclusively using Cloud or Edge resources, while reducing the inference cycle time by 4× to successfully declutter 86% of objects over 213 attempts.",https://ieeexplore.ieee.org/document/8793690/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ICST46873.2019.9047714,A Fundamental Experiment on Contact Position Estimation on Vision based Dome-type Soft Tactile Sensor using Ready-made Medium,IEEE,Conferences,"Tactile sensors are critical components in robotics fields. Recently, soft tactile sensor utilizing vision is actively developed for safe human machine interaction. Some researches use novel custom-made medium in order to achieve tactile sensing. Deep learning can recognize pattern from any vision data when it has sufficient dataset, i.e., the system does not require specific pattern embedded hardware for the pattern recognition. To achieve soft tactile sensor's economical application for robot fingers, this paper presents a fundamental experiment on contract position estimation on vision based dome-type soft tactile sensor utilizing ready-made silicon as a medium and convolutional neural network. In order to estimate and classify the contact position, convolutional neural network (CNN) was applied. The modified VGGNet architecture was coded using Tensorflow and Keras. 1000 images were taken to train the modified VGG network; 200 images were taken for each neutral, left, right, lower, upper direction. For each direction, fingertip, pencil, ruler, and table corner were utilized to capture various situations. After checking the results of the test set, the trained model was applied to the embedded board and checked the contact position estimation in real-time. The experiment showed high accuracy on classifying the con-tact position of the vision based dome-type soft tactile sensor in real time. This contact position estimation system will be critical for the finger-typed robots since the system is reasonably small and it will reduce significant amount of manufacturing cost for the safe human machine interaction system. For the future work, we will acquire more image data and apply more advanced network architecture to improve accuracy.",https://ieeexplore.ieee.org/document/9047714/,2019 13th International Conference on Sensing Technology (ICST),2-4 Dec. 2019,ieeexplore
10.1109/ICMSS.2011.5999339,A Human-Machine Interaction System: A Voice Command Learning System Using PL-G-SOM,IEEE,Conferences,"This paper proposes a voice command learning system for partner robots acquiring communication ability with instructors. Parameter-less Growing Self-Organizing Map (PL-G-SOM), an intelligent pattern recognition model given by our previous work, is used and computational feeling of robots is also adopted to improve the human-machine interaction system. AIBO robot was used in the experiment and the results of real environment showed the effectiveness of the proposed methods.",https://ieeexplore.ieee.org/document/5999339/,2011 International Conference on Management and Service Science,12-14 Aug. 2011,ieeexplore
10.1109/IJCNN48605.2020.9206637,A Lightweight Neural-Net with Assistive Mobile Robot for Human Fall Detection System,IEEE,Conferences,"Falls are a major health issue, particularly among the elderly. Increasing fall events require high service quality and dedicated medical treatment which is an economic burden. In the lack of appropriate care and support, serious injuries caused by fall will cost lives. Therefore, tracking systems with fall detection capabilities are required. Static-view sensors with machine learning techniques for human fall detection have been widely studied and achieved significant results. However, these systems unable to monitor a person if he or she is out of viewing angle which greatly impedes its performance. Mobile robots are an alternative for keeping the person in sight. However, existing mobile robots are unable to operate for a long time due to battery issues and movement constraints in complex environments. In this paper, we proposed a lightweight deep learning vision-based model for human fall detection with an assistive robot to provide assistance when a fall happens. The proposed detection system requires less computational power which can be implemented in a low-cost 2D camera and GPU board for real-time monitoring. The assistive robot equipped with various sensors that can perform SLAM, obstacle avoidance and navigation autonomously. Our proposed system integrates these two sub-systems to compensate for the weakness of each other to constitute a system that robust, adaptable, and high performance. The proposed method has been validated through a series of experiments.",https://ieeexplore.ieee.org/document/9206637/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/UEMCON47517.2019.8993080,A Low-Cost Arm Robotic Platform based on Myoelectric Control for Rehabilitation Engineering,IEEE,Conferences,"Rehabilitation robotics is a recent kind of service robot that include devices such as robotic prosthesis and exoskeletons. These devices could help motor disabled people to rehabilitate their motor functions, and could provide functional compensation to accomplish motor activities. In order to control robotic prosthesis and exoskeletons it is required to identify human movement intention, to be converted into commands for the device. Motor impaired people may use surface electromyography (sEMG) signals to control these devices, taking into account that sEMG signals directly reflects the human motion intention. Myoelectric control is an advanced technique related with the detection, processing, classification, and application of sEMG signals to control human-assisting robots or rehabilitation devices. Despite recent advances with myoelectric control algorithms, currently there is still an important need to develop suitable methods involving usability, for controlling prosthesis and exoskeletons in a natural way. Traditionally, acquiring EMG signals and developing myoelectric control algorithms require expensive hardware. With the advent of low-cost technologies (i.e. sensors, actuators, controllers) and hardware support of simulation software packages as Matlab, affordable research tools could be used to develop novel myoelectric control algorithms. This work describes the implementation and validation of a Matlab-based robotic arm using low-cost technologies such as Arduino commanded using myoelectric control. The platform permits implementation of a variety of EMG-based algorithms. It was carried out a set of experiments aimed to evaluate the platform, through an application of pattern recognition based myoelectric control to identify and execute seven movements of the robotic upper limb: 1-forearm pronation; 2- forearm supination; 3-wrist flexion; 4-wrist extension; 5- elbow flexion; 6- elbow extension; 7-resting. The algorithm use a feature extraction stage based on a combination of time and frequency domain features (mean absolute value, waveform length, root mean square) and a widely used k-NN classifier. Obtained mean classification errors were 5.9%. As future work, additional features in the myoelectric control algorithm will be evaluated, for real-time applications.",https://ieeexplore.ieee.org/document/8993080/,"2019 IEEE 10th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)",10-12 Oct. 2019,ieeexplore
10.1109/CSCWD.2019.8791879,A Mapping Approach of Virtual-Real UR10 Twins Based on Long Short-Term Memory Neural Net,IEEE,Conferences,"Cyber-physical system integrates physical entity and its virtual model, which facilitates intelligent manufacturing a lot. Due to the geometric and non-geometric factors, transmission delay between actual and virtual environment, errors exist between desired position and actual position in real-time movement. Thus the accuracy and efficiency need to be improved. In this paper, a mapping approach of the actual UR10 robot and its virtual model based on long short-term memory neural network is developed to implement the synchronization of the virtual-real UR10 twins' behaviors in cyber-physical system. The virtual model can reflect and control the behaviors of UR10 in real time and vice versa. This method is based on a time recursive structure thus takes the temporal property of trajectory points into account. A prototype system is developed to validate its effectiveness. Experimental validation is conducted to compare the LSTM based calibration method with existing kinematic methods and multilayer perceptron neural net based methods. As demonstrated in the experiment results, the real-time mapping model of the virtual-real UR1O twins' behaviors can be obtained.",https://ieeexplore.ieee.org/document/8791879/,2019 IEEE 23rd International Conference on Computer Supported Cooperative Work in Design (CSCWD),6-8 May 2019,ieeexplore
10.1109/UR49135.2020.9144789,A Markerless Deep Learning-based 6 Degrees of Freedom Pose Estimation for Mobile Robots using RGB Data,IEEE,Conferences,"Augmented Reality has been subject to various integration efforts within industries due to its ability to enhance human machine interaction and understanding. Neural networks have achieved remarkable results in areas of computer vision, which bear great potential to assist and facilitate an enhanced Augmented Reality experience. However, most neural networks are computationally intensive and demand huge processing power, thus are not suitable for deployment on Augmented Reality devices. In this work, we propose a method to deploy state of the art neural networks for real time 3D object localization on augmented reality devices. As a result, we provide a more automated method of calibrating the AR devices with mobile robotic systems. To accelerate the calibration process and enhance user experience, we focus on fast 2D detection approaches which are extracting the 3D pose of the object fast and accurately by using only 2D input. The results are implemented into an Augmented Reality application for intuitive robot control and sensor data visualization. For the 6D annotation of 2D images, we developed an annotation tool, which is, to our knowledge, the first open source tool to be available. We achieve feasible results which are generally applicable to any AR device, thus making this work promising for further research in combining high demanding neural networks with Internet of Things devices.",https://ieeexplore.ieee.org/document/9144789/,2020 17th International Conference on Ubiquitous Robots (UR),22-26 June 2020,ieeexplore
10.1109/ROBIO49542.2019.8961822,A Model-Free Method-Based Shape Reconstruction for Cable-Driven Continuum Manipulator Using Artificial Neural Network,IEEE,Conferences,"The robot-assisted natural orifice transluminal surgery (NOTES) typically involves applying the lengthy and slender continuum instruments/manipulators to get access to the target lesion sites, and then performs complex operations. However, due to the strong-nonlinearity of continuum robotic manipulators and the confined and tortuous anatomical paths, it's difficult to establish accurate inverse kinematics (IK) model to achieve precise motion control and real-time shape sensing for accurately modeling their shapes. To tackle such difficulties, a model-free method based on neural network have been proposed to solve the IK problem and reconstruct the shape of a continuum manipulator at the same time using the training results from the electromagnetic (EM) tracking approach. For the IK problem, the relationship between the tip position and the corresponding cable lengths can be learned and for the shape estimation problem, the mapping from the cable lengths to the shape of the continuum robot can be established. A dataset of 500 random continuum manipulator postures was used to train the neural network, with recorded EM sensors-tracked positions logged synchronously to the cable lengths. Experiment results show the proposed model-free method could achieve high accuracy and reliable inverse kinematics and shape reconstruction outcomes.",https://ieeexplore.ieee.org/document/8961822/,2019 IEEE International Conference on Robotics and Biomimetics (ROBIO),6-8 Dec. 2019,ieeexplore
10.1109/RoSE52553.2021.00011,A Modeling Tool for Reconfigurable Skills in ROS,IEEE,Conferences,"Known attempts to build autonomous robots rely on complex control architectures, often implemented with the Robot Operating System platform (ROS). The implementation of adaptable architectures is very often ad hoc, quickly gets cumbersome and expensive. Reusable solutions that support complex, runtime reasoning for robot adaptation have been seen in the adoption of ontologies. While the usage of ontologies significantly increases system reuse and maintainability, it requires additional effort from the application developers to translate requirements into formal rules that can be used by an ontological reasoner. In this paper, we present a design tool that facilitates the specification of reconfigurable robot skills. Based on the specified skills, we generate corresponding runtime models for self-adaptation that can be directly deployed to a running robot that uses a reasoning approach based on ontologies. We demonstrate the applicability of the tool in a real robot performing a patrolling mission at a university campus.",https://ieeexplore.ieee.org/document/9474550/,2021 IEEE/ACM 3rd International Workshop on Robotics Software Engineering (RoSE),2-2 June 2021,ieeexplore
10.1109/IROS.2018.8594036,A Neurorobotic Experiment for Crossmodal Conflict Resolution in Complex Environments *,IEEE,Conferences,"Crossmodal conflict resolution is crucial for robot sensorimotor coupling through the interaction with the environment, yielding swift and robust behaviour also in noisy conditions. In this paper, we propose a neurorobotic experiment in which an iCub robot exhibits human-like responses in a complex crossmodal environment. To better understand how humans deal with multisensory conflicts, we conducted a behavioural study exposing 33 subjects to congruent and incongruent dynamic audio-visual cues. In contrast to previous studies using simplified stimuli, we designed a scenario with four animated avatars and observed that the magnitude and extension of the visual bias are related to the semantics embedded in the scene, i.e., visual cues that are congruent with environmental statistics (moving lips and vocalization) induce the strongest bias. We implement a deep learning model that processes stereophonic sound, facial features, and body motion to trigger a discrete behavioural response. After training the model, we exposed the iCub to the same experimental conditions as the human subjects, showing that the robot can replicate similar responses in real time. Our interdisciplinary work provides important insights into how crossmodal conflict resolution can be modelled in robots and introduces future research directions for the efficient combination of sensory observations with internally generated knowledge and expectations.",https://ieeexplore.ieee.org/document/8594036/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/CSICC52343.2021.9420614,A New Approach for Mapping of Soccer Robot Agents Position to Real Filed Based on Multi-Core Fuzzy Clustering,IEEE,Conferences,"Mapping the position of soccer robot agents to a real field, is one of the essential issues in the practical implementation of scientific contributions in this context. The lack of a proper assignment affects the scientific implementation of many subjects, such as routing, obstacle avoidance, and robot guidance. For this reason, the use of a clustering method is proposed in this article. Upon the entrance of a new agent, its position is mapped to the real field based on the clustering algorithm. After this mapping, the system begins to work according to the position of the agents, which is defined as the position of the centers of the clusters, as well as the rules defined in the knowledge-base. Considering the unknown and dynamic environment of the robot, some objects inherit common traits from multiple clusters. One reasonable solution for considering the cluster overlaps is to assign a set of membership degrees to each of them. Multiple membership degree assignments result from the fuzzy nature of the clusters. Due to the reduction of segmentations and the shrinkage of the search space, fuzzy clustering generally faces less computational overhead, while the identification and handling of vague, noisy, and outlier data also become much easier in them. The approach of the proposed method is based on the feasibility ideas and uses multi-core learning to identify clusters with complex data structures. The feasibility score of each data represents the percentages of the properties that data inherits from the clusters. Automatically adjusting the weights of the cores in an optimization framework, the proposed method avoids the damage caused by problems such as adopting inefficient cores, or irrelevant features.",https://ieeexplore.ieee.org/document/9420614/,"2021 26th International Computer Conference, Computer Society of Iran (CSICC)",3-4 March 2021,ieeexplore
10.1109/ECICE47484.2019.8942691,A Novel Dynamic Hand Gesture and Movement Trajectory Recognition model for Non-Touch HRI Interface,IEEE,Conferences,"Efficient Human Robot Interaction (HRI) interface is very much demandable for controlling the semi-autonomous robots. Hand gesture recognition is an effective form of non-touch instruction. Thus, human hand gesture recognition is mostly used technique for HRI. However, in most research, some sensor devices or marker are incorporate with the hand or a large number of hand image and hand gesture sequence is stored and process for gesture recognition in machine learning techniques, which are costly and demand complex computation. From this point of view, an efficient dynamic hand gesture and movement trajectory recognition system is proposed in this paper, which can be used in real-time fashion for effective HRI interface. In the proposed dynamic gesture recognition system, hand images and skeleton information are extracted for Kinect sensor. Hands are segmented from the video frame using a skin color segmentation model from the region of interest (ROI) around the palm position of both hands. The hand open and close states are identified by calculating the position of palm and extreme position of Figure for activating the instruction recognition. The trajectory of segmented hands and the hands open state are considered for formulating the model of gesture with respect to the selected index points of body skeleton. Finally, several gesture models are derived to recognize the instruction during temporal gesture movement. For validating the proposed model, an experimental environment is setup in experimental lab. Ten volunteers are considered and tested the proposed system for six gesture instructions. According to the experiment, the proposed system shows 94.5% average recognition accuracy for dynamic motion instruction identification.",https://ieeexplore.ieee.org/document/8942691/,"2019 IEEE Eurasia Conference on IOT, Communication and Engineering (ECICE)",3-6 Oct. 2019,ieeexplore
10.1109/RAMECH.2011.6070484,A Q-learning based Cartesian model reference compliance controller implementation for a humanoid robot arm,IEEE,Conferences,This paper presents the implementation (real time and simulation) of a model-free Q-learning based discrete model reference compliance controller for a humanoid robot arm. The Reinforcement learning (RL) scheme uses a recently developed Q-learning scheme to develop an optimal policy on-line. The RL Cartesian (x and y) tracking controller with model reference compliance was implemented using two links (shoulder flexion and elbow flexion joints) of the right arm of the humanoid Bristol-Elumotion-Robotic-Torso II (BERT II) torso.,https://ieeexplore.ieee.org/document/6070484/,"2011 IEEE 5th International Conference on Robotics, Automation and Mechatronics (RAM)",17-19 Sept. 2011,ieeexplore
10.1109/NAECON.2018.8556769,A Rapid Situational Awareness Development Framework for Heterogeneous Manned-Unmanned Teams,IEEE,Conferences,"This paper presents a robust framework for configuring and deploying a heterogeneous team of smart unmanned systems and human agents in dynamic and un-modeled environments to rapidly build mission critical situational awareness with selective details of potential areas of interest, especially focusing on minimized cognitive loading of the human agents. Five key components, namely control, communication, artificial intelligence (AI), platform, and visualization, merge seamlessly into a holistic framework to deliver this rapid situational awareness development capability to the heterogeneous manned unmanned team (MUM-T). In this framework, the overall control is seen as a combination of agent level control and mission level control. A common software, Robot Operating System (ROS), is used to establish communication, and consequently consensus, among the heterogeneous swarm of unmanned systems. These unmanned platforms are customized with co-processing hardware that can execute advanced artificial intelligence machine learning (AI/ML) modules to not only deliver stable and cooperative performance of these unmanned platforms in the swarm but also support human-centric human robot interaction (HRI). Finally, to reduce the cognitive burden on the human agents, a triaged visualization scheme, enabled through mixed reality (MR) technology, is implemented. This paper presents a preliminary proof of concept study for the presented hybrid map (i.e. 2D mapping with 3D detailing) construction framework, tested with a heterogeneous swarm of unmanned aerial vehicles (UAVs) of varying capabilities, teamed with a human operator.",https://ieeexplore.ieee.org/document/8556769/,NAECON 2018 - IEEE National Aerospace and Electronics Conference,23-26 July 2018,ieeexplore
10.1109/RO-MAN46459.2019.8956259,A Reinforcement-Learning Approach for Adaptive and Comfortable Assistive Robot Monitoring Behavior,IEEE,Conferences,"Companion robots used in the field of elderly assistive care can be of great value in monitoring their everyday activities and well-being. However, in order to be accepted by the user, their behavior, while monitoring them, should not provide discomfort: robots must take into account the activity the user is performing and not be a distraction for them. In this paper, we propose a Reinforcement Learning approach to adaptively decide a monitoring distance and an approaching direction starting from an estimation of the current activity obtained by the use of a wearable device. Our goal is to improve user activity recognition performance without making the robot's presence uncomfortable for the monitored person. Results show that the proposed approach is promising for real scenario deployment, succeeding in accomplishing the task in more than 80%of episodes run.",https://ieeexplore.ieee.org/document/8956259/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/IROS.2018.8593714,A Software Framework for Planning Under Partial Observability,IEEE,Conferences,"Planning under partial observability is both challenging and critical for reliable robot operation. The past decade has seen substantial advances in this domain: The mathematically principled approach for addressing such problems, namely the Partially Observable Markov Decision Process (POMDP), has started to become practical for various robotics tasks. Good approximate solutions for problems framed as POMDPs can now be computed on-line, with a few classes of problems being solved in near real-time. However, applications of these more recent advances are often hindered by the lack of easy-to-use software tools. Implementation of state of the art algorithms exist, but most (if not all)require the POMDP model to be hard-coded inside the program, increasing the difficulty of applying them. To alleviate this problem, we propose a software toolkit, called On-line POMDP Planning Toolkit (OPPT)(downloadable from http://robotics.itee.uq.edu.au/~oppt). By providing a well-defined and general abstract solver API, OPPT enables the user to quickly implement new POMDP solvers. Furthermore, OPPT provides an easy-to-use plug-in architecture with interfaces to the high-fidelity simulator Gazebo that, in conjunction with user-friendly configuration files, allows users to specify POMDP models of a standard class of robot motion planning under partial observability problems with no additional coding effort.",https://ieeexplore.ieee.org/document/8593714/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ROBIO.2006.340185,A Study of real-time EMG-driven Arm Wrestling Robot,IEEE,Conferences,"An EMG-driven arm wrestling robot (AWR) is being developed in our laboratories for the purposes of studying neuromuscular control of arm movements. The AWR arm have 2-DOF, integrated with mechanical arm, elbow/wrist force sensors, servo motor, encoder, 3-D MEMS accelerometer, and USB camera, is used to estimate tension developed by individual muscles based on recorded electromyograms (EMGs). The surface electromyographic signal form the upper limb is sampled from a real player in same conditions. By using the method of wavelet packet transformation (WPT) and auto regressive model (AR), the characteristics of EMG signals can be extracted. Artificial neural network is adopted to estimate the elbow joint torque. The effectiveness of the humanoid algorithm using torque control estimated via WRT and neural network is confirmed by experiments. The purpose of this paper is to describe the design objectives, fundamental components and implementation of our real-time, EMG-driven AWR arm.",https://ieeexplore.ieee.org/document/4142107/,2006 IEEE International Conference on Robotics and Biomimetics,17-20 Dec. 2006,ieeexplore
10.1109/SysCon48628.2021.9447129,A System For P300 Detection Applied To Vehicle Navigation,IEEE,Conferences,"Brain-machine interface (BMI) systems are used to classify biological signals from the brain, such as electroencephalogram (EEG) data, to determine control commands. There are several different signals that can be used for the interface. Among them, one finds the P300 signal. The P300 signal is a potential signal that is passively produced when a user observes, hears or pays attention to a desired stimulus. This signal has been used in conjunction with a graphical user interface (Gill) to allow a person to choose commands from a list of possible actions. Traditionally, the visual stimuli are repeated and averaged to increase classification accuracy, which, in turn, reduces the maximum possible command rate. In order to improve command rate, this paper describes a system wherein feature extraction and classifier training could be tested offline. Then, live testing in a mobile robot steering simulation was carried out. Finally, a live experiment is reported. The features to be used in classification are selected using a genetic algorithm (GA). Using the chosen features, 78.3% signal detection accuracy was achieved fur single epochs. Using multiple-epochs to improve classifier performance in simulated and real-world steering experiments we were able to successfully navigate a simple maze while maintaining classifier accuracy (Sim: 79.9±5.3%, Real: 88.8±10.1%).",https://ieeexplore.ieee.org/document/9447129/,2021 IEEE International Systems Conference (SysCon),15 April-15 May 2021,ieeexplore
10.1109/ICSAI.2018.8599325,A Visual System of Citrus Picking Robot Using Convolutional Neural Networks,IEEE,Conferences,"To realize automatic fruit harvesting, there have been a lot of approaches of engineering since 1960s. However, for the complex natural environment, the study of robotic harvesting systems is still on the developing. In this paper, we propose to use several deep learning methods, which are the-state-of-the-art techniques of pattern recognition, to raise the accuracy of the citrus discrimination by visual sensors. The proposed methods include YOLOv3, ResNet50, and ResNet152, which are the advanced deep convolutional neural networks (CNNs). For the powerful ability of pattern recognition of these CNNS, the proposed visual system is able to distinguish not only citrus fruits but also leaves, branches, and fruits occluded by branch or leaves, and these functions are important for picking work of harvesting robot in the real environment. The recognition abilities of the three CNNs were confirmed by the experiment results, and ResNet152 showed the highest recognition rate. The recognition accuracy of the normal citrus in the natural environment was 95.35%, overlapped citrus fruits reached 97.86%, and 85.12% in the cases of leaves and branches of citrus trees.",https://ieeexplore.ieee.org/document/8599325/,2018 5th International Conference on Systems and Informatics (ICSAI),10-12 Nov. 2018,ieeexplore
10.1109/ITAIC.2019.8785467,A Weights and Improved Adaptive Artificial Fish Swarm Algorithm for Path Planning,IEEE,Conferences,"A weight and improved adaptive artificial fish swarm algorithm(WIA-AFSA) is proposed to deal with the problem of mobile robots path planning have low optimization accuracy and premature convergence under real environment. Firstly, introduced an improved aggregation degree factor to obtain an adaptive step and visual strategy, which can reflect the actual changes in the optimal state of the artificial fish swarm search, and better balance the global and local search capabilities. At the same time, the weight evaluation factor is introduced in the pray, swarm and follow behavior of the artificial fish, which effectively avoids the algorithm falling into the local optimum and premature. The benchmark function is used to test the performance of the algorithm. The results show that the algorithm has good searching ability and convergence. Simulation experiments of path planning based on raster model were carried out to verify the superiority of wia-afsa algorithm in robot navigation. Finally, the path planning experiment of the robot in real environment proves the effectiveness and practicability of the proposed algorithm.",https://ieeexplore.ieee.org/document/8785467/,2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC),24-26 May 2019,ieeexplore
10.1109/ROMAN.1995.531972,A basic study on dynamic control of facial expressions for Face Robot,IEEE,Conferences,"In order to develop an active human interface that realizes ""hear-to-heart"" virtual communication between an intelligent machine and human being, we have already reported the ""Face Robot"" which has a human-like face and can display facial expressions similar to that of a human being by using a flexible microactuator (FMA). For realizing real-time communication between intelligent machine and human being, the Face Robot must express its facial expressions at the almost same speed and in the same manner as a human being. However it is found that FMA can not cope with this kind of performance in expressing dynamic facial features. This paper deals with the development of new mini-actuator ""ACDIS"" for real-time display of Face Robot's facial expressions and also their control method. The developed double action piston type actuator is able to measure the displacement of the position in ACDIS by equipping a LED and a photo-transistor inside it. The opening time of the electro-magnetic valve is regulated for the displacement control of ACDIS by a PD control algorithm. The ACDIS is found to have sufficient performance in the speed of piston-movement and we undertake the experiment of real-time facial expression on the Face Robot and confirm that the display of human-like facial expression is successfully realized.",https://ieeexplore.ieee.org/document/531972/,Proceedings 4th IEEE International Workshop on Robot and Human Communication,5-7 July 1995,ieeexplore
10.1109/ROBIO.2014.7090308,A chaotic neural network as motor path generator for mobile robotics,IEEE,Conferences,This work aims at developing a motor path generator for applications in mobile robotics based on a chaotic neural network. The computational paradigm inspired by the neural structure of microcircuits located in the human prefrontal cortex is adapted to work in real-time and used to generate the joints trajectories of a lightweight quadruped robot. The recurrent neural network was implemented in Matlab and a software framework was developed to test the performances of the system with the robot dynamic model. Preliminary results demonstrate the capability of the neural controller to learn period signals in a short period of time allowing adaptation during the robot operation.,https://ieeexplore.ieee.org/document/7090308/,2014 IEEE International Conference on Robotics and Biomimetics (ROBIO 2014),5-10 Dec. 2014,ieeexplore
10.1109/CEC.2003.1299627,A classifier system in real applications for robot navigation,IEEE,Conferences,"This paper presents an autonomous evolutionary system applied to control a mobile robot in unknown environments. The navigation system learns efficiently to deal with situations where the robot must capture targets avoiding collisions with obstacles. Toward this end, robot direction and speed must be properly defined. The evolutionary approach is based on a version of classifier systems, responsible for the proposition of a competitive process involving rules of elementary behaviour. A virtual environment is used to evolve the controller, a Khepera II robot is submitted to real navigation tasks, with no significant degradation in performance. As an additional experiment, the controller is also evolved in a real environment, and validated in a different and more complex environment, not previously experimented, attesting the generalization capability of the proposal.",https://ieeexplore.ieee.org/document/1299627/,"The 2003 Congress on Evolutionary Computation, 2003. CEC '03.",8-12 Dec. 2003,ieeexplore
10.1109/IJCNN.2010.5596771,A cognitive developmental robotics architecture for lifelong learning by evolution in real robots,IEEE,Conferences,"This paper is devoted to a detailed presentation of the current state of the Multilevel Darwinist Brain (MDB) cognitive architecture for lifelong learning in real robots. This architecture follows the cognitive developmental robotics approach and it is based on concepts like embodiment, open-ended lifelong learning, autonomous knowledge acquisition or adaptive behaviors and motivations. In addition, this version of the MDB architecture incorporates several improvements related with more practical issues, which are the result of the experience gained through several experiments with real robots in the last few years. The MDB uses evolutionary algorithms in the knowledge acquisition process, which implies the need of paying attention to the efficiency of the computational implementation. Here, we first describe the cognitive model on which the basic operation of the architecture is based and, secondly, we detail the main aspects and working of the current version of the MDB. Finally, we have designed a very simple but illustrative real robot lifelong learning example, where we can show how to set up an experiment using the MDB. Hence, with this simple example we show the successful behavior of the MDB cognitive developmental robotics principles.",https://ieeexplore.ieee.org/document/5596771/,The 2010 International Joint Conference on Neural Networks (IJCNN),18-23 July 2010,ieeexplore
10.1109/IROS.1998.727477,A constraint-based controller for soccer-playing robots,IEEE,Conferences,"Soccer meets the requirements of the situated agent approach and as a task domain is sufficiently rich to support research integrating many branches of robotics and AI. A robot is an integrated system, with a controller embedded in its plant. A robotic system is the coupling of a robot to its environment. Robotic systems are, in general, hybrid dynamic systems, consisting of continuous, discrete and event-driven components. Constraint nets provide a semantic model for modeling hybrid dynamic systems. Controllers are embedded constraint solvers that solve constraints in real-time. A controller for our new softbot soccer team, UBC Dynamo98, has been modeled in constraint nets, and implemented in Java, using the Java Beans architecture. The paper demonstrates that the formal constraint net approach is a practical tool for designing and implementing controllers for robots in multi-agent real-time environments.",https://ieeexplore.ieee.org/document/727477/,"Proceedings. 1998 IEEE/RSJ International Conference on Intelligent Robots and Systems. Innovations in Theory, Practice and Applications (Cat. No.98CH36190)",17-17 Oct. 1998,ieeexplore
10.1109/ROBOT.1998.676374,A control architecture to achieve manipulation task goals for a humanoid robot,IEEE,Conferences,"Focusing on the manipulation tasks to be executed by humanoid robots, principal requirements which are to be satisfied by hardware/software of the control system are considered. In order to meet the requirements, a novel type of hardware structure and software architecture is proposed. Since the target humanoid robot consists of multiple subsystems such as a central controller for brain, a vision controller for eye, and five motion sub-controllers for two arms, two hands, one spine, the on-board hardware control system is designed to have a distributed control structure connected by pseudo real-time Ethernet interfaces. A goal-achieving software architecture is also proposed which meets the requirements of semi-autonomy, reactivity, expandability, and object-orientedness. Specifically, in order to achieve reactivity, a coordination method is proposed to configure three kinds of executive modules, primitive module, flow-control module, and goal module, which have multiple exit states. The control architecture proposed has been implemented for performing toy-block assembly tasks on a humanoid robot as well as on the graphic simulator.",https://ieeexplore.ieee.org/document/676374/,Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),20-20 May 1998,ieeexplore
10.1109/ICRA.2012.6225245,A depth space approach to human-robot collision avoidance,IEEE,Conferences,"In this paper a real-time collision avoidance approach is presented for safe human-robot coexistence. The main contribution is a fast method to evaluate distances between the robot and possibly moving obstacles (including humans), based on the concept of depth space. The distances are used to generate repulsive vectors that are used to control the robot while executing a generic motion task. The repulsive vectors can also take advantage of an estimation of the obstacle velocity. In order to preserve the execution of a Cartesian task with a redundant manipulator, a simple collision avoidance algorithm has been implemented where different reaction behaviors are set up for the end-effector and for other control points along the robot structure. The complete collision avoidance framework, from perception of the environment to joint-level robot control, is presented for a 7-dof KUKA Light-Weight-Robot IV using the Microsoft Kinect sensor. Experimental results are reported for dynamic environments with obstacles and a human.",https://ieeexplore.ieee.org/document/6225245/,2012 IEEE International Conference on Robotics and Automation,14-18 May 2012,ieeexplore
10.1109/IJCNN.2014.6889900,A developmental perspective on humanoid skill learning using a hierarchical SOM-based encoding,IEEE,Conferences,"Hand-coding is an impractical approach to developing motion repertoires for humanoid robots, requiring both task and programming expertise. Physical demonstration of skills, on the other hand, is an approach with which humans are both competent and familiar. When following a programming-by-demonstration approach, the adaptiveness of a robot can be further increased by giving it the ability to compose novel skills from skills already acquired from demonstration. We have previously presented [1] an extension to the Piaget-inspired Constructivist Learning Architecture [2], featuring a hierarchical SOM-based algorithm that encodes skills as a hierarchy of fixed-length subsequences. At the core of the extended algorithm lies a novel principle for comparing long-term memory and short-term memory, represented as connection weights and decaying node activation values, respectively. In this article, we present an in-depth analysis of how this comparison, can provide a robot control algorithm that is both state-sensitive and goal oriented. We present results from experiments using an abstract chain walk problem that includes hidden states, to demonstrate how the algorithm disambiguates states and selects actions yielding higher rewards. Furthermore, we present results from an experiment where we use programming-by-demonstration to encode and reproduce a figure-8 gesture with a Nao humanoid robot. The results show that our algorithm is capable of identifying hidden states in both real and abstract problem domains.",https://ieeexplore.ieee.org/document/6889900/,2014 International Joint Conference on Neural Networks (IJCNN),6-11 July 2014,ieeexplore
10.1109/ISIC.2003.1253933,A dynamically sized Radial Basis Function neural network for joint control of a PUMA 500 manipulator,IEEE,Conferences,"We present the design and analysis of a neural control structure for joint control of a PUMA 500 robot manipulator. We lay out the design considerations and steps to build an experimental electronic control system to control the shoulder joint of the manipulator. We review the use of neural networks for on-line learning closed-loop control applications. The 'curse of dimensionality', a problem encountered when using Radial Basis Function (RBF) neural networks, is addressed and a neuron-node resource-allocating algorithm is investigated to overcome this problem. An on-line learning neural-control structure, employing this resource-allocating algorithm, is proposed, implemented and successfully tested to improve the position accuracy of the robot manipulator. All the implementations are executed on a 16-bit microcontroller in real-time, developed using integer arithmetic in the programming language C. The program listings are available upon email request.",https://ieeexplore.ieee.org/document/1253933/,Proceedings of the 2003 IEEE International Symposium on Intelligent Control,8-8 Oct. 2003,ieeexplore
10.1109/CIRA.1999.809937,A fuzzy approach to hand functioning in virtual programming,IEEE,Conferences,"Virtual assembly allows human operators to use their hands manipulating the graphics representation of machinery parts and programming assembly tasks directly in a 3D operation space. The imprecise measurements of data gloves and uncertainty of human factors, however, make the incorporation of human hands an error-probing and time-consuming task. This paper investigates the application of fuzzy logic in posture recognition. It presents a simple yet efficient method to handle the imprecision in both the registered sample patterns and run-time glove inputs. Experiment results demonstrate the advantages of using this approach in robot programming of virtual assembly systems.",https://ieeexplore.ieee.org/document/809937/,Proceedings 1999 IEEE International Symposium on Computational Intelligence in Robotics and Automation. CIRA'99 (Cat. No.99EX375),8-9 Nov. 1999,ieeexplore
10.1109/SSCI.2016.7849899,A fuzzy-based machine learning model for robot prediction of link quality,IEEE,Conferences,"With foresight into the state of the wireless channel, a robot can make various optimization decisions with regards to routing packets, planning mobility paths, or switching between diverse radios. However, the process of predicting link quality (LQ) is nontrivial due to the streaming and dynamic nature of radio wave propagation, which is complicated by robot mobility. Due to robot movement, the wireless propagation environment can change considerably in terms of distance, obstacles, noise, and interference. Therefore, LQ must be learned and regularly updated while the robot is online. However, the existing fuzzy-based models for assessing LQ are non-adaptable due to the absence of any learning mechanism. To address this issue, we introduce a fuzzy-based prediction model designed for the efficient online and incremental learning of LQ. The unique approach uses fuzzy logic to infer LQ based on the collective output from a series of offset classifiers and their posterior probabilities. In essence, the proposed model leverages machine learning for extracting the underlying functional relationship between the input and output variables, but deeper inferences are made from the output of the learning algorithms using fuzzy logic. Wireless link data from a real-world robot network was used to compare the model with the traditional linear regression approach. The results show statistically significant improvements in three out of the six real-world indoor and outdoor environments where the robot operated. Additionally, the novel approach offers a number of other benefits, including the flexibility to use fuzzy logic for model tuning, as well as the ability to make implementation efficiencies in terms of parallelization and the conservation of labeling resources.",https://ieeexplore.ieee.org/document/7849899/,2016 IEEE Symposium Series on Computational Intelligence (SSCI),6-9 Dec. 2016,ieeexplore
10.1109/INDIN.2013.6622897,A genetic algorithm for optimizing vector-based paths of industrial manipulators,IEEE,Conferences,"Nowadays there is a vast amount of IT tools specialized in vector graphics. The data generated by those tools could be used to describe the path of industrial manipulators as a set of vectors. The main problem is that the sequence/direction of those vectors is not meant to be executed by a robot and attempting to do it, would result in inefficient cycle times of the robot. Therefore it is necessary to generate an execution plan that minimizes the cost of carrying out the vector-based path. The number of possible execution actions has a factorial growth and it is unfeasible to evaluate each of them. This paper proposes the use of a genetic algorithm to optimize this task. The main contribution of this work is a chromosome encoding structure and modifications to the Partially Mapped Crossover operator in order to comply with the constraints of this optimization problem. The algorithm was implemented and tested in a real industrial manipulator.",https://ieeexplore.ieee.org/document/6622897/,2013 11th IEEE International Conference on Industrial Informatics (INDIN),29-31 July 2013,ieeexplore
10.1109/ICCE-Asia.2016.7804752,A hardware architecture of face detection for human-robot interaction and its implementation,IEEE,Conferences,"This paper presents hardware architecture with low-complexity face detection (FD) and parallel processing of local binary pattern (LBP) generation and adaptive boosting (AdaBoost) algorithm using Haar features for the intelligent service robot system. We designed a fully pipelined architecture implemented with the design techniques, such as variable image scaling and parallel processing multiple classifiers without integral image generation, on the FPGA platform. The proposed architecture enables a real-time FD processing for a VGA video at 30 frames per second.",https://ieeexplore.ieee.org/document/7804752/,2016 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia),26-28 Oct. 2016,ieeexplore
10.1109/ECBS.2003.1194801,A hybrid architecture for visualization and decision making in battlespace environments,IEEE,Conferences,"This article presents a hybrid software/hardware architecture for commander's decision support in tactical operations. The architecture builds on the symbolic, object-oriented visualization software called Advanced Tactical Architecture for Combat Knowledge System (ATACKS). The extension discussed here is the design of a real-time robot agent layer that interacts wirelessly with ATACKS. This layer enacts decisions made by software agents (wargamers), continuously relays the execution states back to ATACKS, and updates its actions as advocated by replanning algorithms. The software layer is briefly described followed by the specification of the real-time requirements for the robotic architecture. The design and implementation are given with a small example that illustrates the hybrid system's operation.",https://ieeexplore.ieee.org/document/1194801/,"10th IEEE International Conference and Workshop on the Engineering of Computer-Based Systems, 2003. Proceedings.",7-10 April 2003,ieeexplore
10.1109/IROS.2013.6696771,A learning-based approach to robust binaural sound localization,IEEE,Conferences,"Sound source localization is an important feature designed and implemented on robots and intelligent systems. Like other artificial audition tasks, it is constrained to multiple problems, notably sound reflections and noises. This paper presents a sound source azimuth estimation approach in reverberant environments. It exploits binaural signals in a humanoid robotic context. Interaural Time and Level Differences (ITD and ILD) are extracted on multiple frequency bands and combined with a neural network-based learning scheme. A cue filtering process is used to reduce the reverberations effects. The system has been evaluated with simulation and real data, in multiple aspects covering realistic robot operating conditions, and was proven satisfying and effective as will be shown and discussed in the paper.",https://ieeexplore.ieee.org/document/6696771/,2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,3-7 Nov. 2013,ieeexplore
10.1109/ICCAE.2010.5451340,A low cost microcontroller implementation of neural network based hurdle avoidance controller for a car-like robot,IEEE,Conferences,This paper describes the implementation of a neural network based hurdle avoidance controller for a car like robot using a low cost single chip 89C52 microcontroller. The neural network is the multilayer feed-forward network with back propagation training algorithm. The network is trained offline with tangent-sigmoid as activation function for neurons and is implemented in real time with piecewise linear approximation of tangent-sigmoid function. Results have shown that up-to twenty neurons in hidden layer can be deployed with the proposed technique using a single 89C52 microcontroller. The vehicle is tested in various environments containing obstacles and is found to avoid obstacles in its path successfully.,https://ieeexplore.ieee.org/document/5451340/,2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE),26-28 Feb. 2010,ieeexplore
10.1109/ICCS45141.2019.9065549,A low power Artificial Intelligence Processor for Autonomous Mobile Robots,IEEE,Conferences,"The robot which makes use of AI as a mode of processing is getting more popular day by day, starting from the autonomous room cleaning robot to Amazon Prime Air. This autonomous robot overtakes traditional robots in following aspects such as implementing effective decision making in order to reduce the computational overhead by reducing the overall power usage of the robot. In this report, we have designed a low power [1] AIP without compensating in performance. The AIP which we have designed is a 64 processing element that uses parallel processing architecture. A map with 8 different routes is created in Xilinx where it calculates the shortest path from the source to destination using conditional operators. A* algorithm is implemented in Matlab to calculate the shortest distance and Dijkstra's algorithm is converted to VHDL using Vivado HLS coder. A neural network is also created using Matlab to detect and avoid real time obstacle. The overall power report of the processor is implemented in Cadence.",https://ieeexplore.ieee.org/document/9065549/,2019 International Conference on Intelligent Computing and Control Systems (ICCS),15-17 May 2019,ieeexplore
10.1109/IROS.1996.571054,A method for expecting the features of objects and enabling real-time vision processing,IEEE,Conferences,"This paper presents a mathematical analysis of image processing, algorithms designed according to the results of this analysis, and their implementation. We prove that the search of objects features can be accelerated without loss of precision by using an inhomogeneous density of the sensitive cells the parameters space is composed of. In other words, the visual analysis should be concentrated in the region of the features space around the expected object position. The improvement relative to an uniform cell density is quantified using a cost function corresponding to time and precision optimisation. We show that a Kohonen neural network can be used for efficient image processing, and simulate this strategy. We introduce a simpler algorithm for the case that the object positions are Gauss-distributed around the expected position. This algorithm has been implemented it on a robot guided by a vision system. The robot learned to process images efficiently during the manoeuvres and after that was able to track objects moving in a fast and unpredictable manner.",https://ieeexplore.ieee.org/document/571054/,Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems. IROS '96,8-8 Nov. 1996,ieeexplore
10.1109/ROBOT.2001.933206,A method for obstacle avoidance and shooting action of the robot soccer,IEEE,Conferences,"A fuzzy-obstacle-avoidance-path algorithm for obstacle avoidance and a procedure for the shooting action of a soccer robot based on this algorithm are proposed. This algorithm contains a fuzzy system that is used to estimate the rotational velocity of the soccer robot. To demonstrate the effectiveness and applicability of the proposed method, two simulations are presented and a real-time implementation is developed.",https://ieeexplore.ieee.org/document/933206/,Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164),21-26 May 2001,ieeexplore
,A multi-agent framework for coordination of intelligent assistive technologies,IEEE,Conferences,"Intelligent care for the future is the IntelliCare project's main priority. This paper describes the design of a generic multi-agent framework for coordination of intelligent assistive technologies. The paper overviews technologies and software systems suitable for context awareness and housekeeping tasks, especially for performing a multi-robot cleaning-task activity. It also describes conducted work in the design of a multi-agent platform for coordination of intelligent assistive technologies. Instead of using traditional robot odometry estimation methods, we have tested an independent indoor localization system for real-time localization. We conducted an experiment in two steps: first, creating and testing interaction interfaces with and between robotic systems, and secondly, wrapping all in a multi-agent system, defining a vacuuming-cleaning ontology. With the pose data from an indoor localization system, is it possible to compare with real robot positions. From this, we can make some platform assumptions regarding heterogeneous robot cooperation, by thinking further i.e. sharing workspace with humans.",https://ieeexplore.ieee.org/document/5556631/,5th Iberian Conference on Information Systems and Technologies,16-19 June 2010,ieeexplore
10.1109/ICIPS.1997.669208,A neural network approach to the elimination of road shadow for outdoor mobile robot,IEEE,Conferences,"A new method of road tracking oriented environmental noise elimination is presented for implementing navigation and control of land autonomous vehicles (ALV). The concept of vision based environmental noise is firstly introduced for the purpose of road and/or obstacle edge detection. Then, a representation of pyramid is proposed for vision processing. Furthermore, a fuzzy neural network is designed and implemented to recognize the environmental noises such as shadow and water prints on the road. With structure optimization by genetic algorithm and special training by classified samples, we use the network to guide our THMR-III (Tsinghua University Mobile Robot, Model 3) in the outdoor real world. Experiments have shown good properties for the ALV's ""perception-action"" behaviors, including obstacle avoidance, road following, wandering, etc. Although the work is still going on, we can see from the present results the better quality, adaptability and robustness of the above approach.",https://ieeexplore.ieee.org/document/669208/,1997 IEEE International Conference on Intelligent Processing Systems (Cat. No.97TH8335),28-31 Oct. 1997,ieeexplore
10.23919/ECC.2001.7076440,A neural network implementation of real-time fuzzy predictive control,IEEE,Conferences,"Fuzzy predictive controllers have been applied to several applications with good control performance. However, this methodology often leads to nonconvex optimization problems, which are difficult to solve for fast processes, i.e. processes with small sampling times. This paper proposes a new methodology to apply a fuzzy predictive controller in real-time by using a neural network architecture, which receives data from the process and computes the control actions. Thus, the neural network is learned off-line, and its final structure guarantees that control actions are computed very rapidly. An internal model control structure is used to cope with model-plant mismatches and disturbances. The proposed methodology is tested in a realistic simulation of an experimental robot manipulator, where force and position are both controlled. The proposed scheme reveals very good control performance.",https://ieeexplore.ieee.org/document/7076440/,2001 European Control Conference (ECC),4-7 Sept. 2001,ieeexplore
10.1109/IACC.1995.465839,A neural network system that controls and plans paths for a robot,IEEE,Conferences,"Proposes to solve the problems of direct/inverse kinematics and control of trajectories by multilevel perceptrons. The authors' solution admits a parallel implementation in real time. It does not need either to solve kinematic equations or robot trajectories, because it learns gradually by examples adaptively. The control system consists of different networks each of which specialises in solving a particular problem. This structure enables a modular approach to the problem accelerating convergence. The system obtains an acceptable trajectory and gives a parallel solution that could be used in real-time applications.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/465839/,Proceedings of IEEE/IAS International Conference on Industrial Automation and Control,5-7 Jan. 1995,ieeexplore
10.1109/ICSMC.1995.538227,A neural network-based robot safety system,IEEE,Conferences,"This paper presents a new approach for real-time robot safety system based on artificial neural networks. This approach includes a neural network detection unit and a neural network decision unit, implemented at an intermediate and high level of sensory processing, respectively. Both the detection and decision units have been implemented and tested by simulation, both separately and as an integrated unit. The response time of the integrated system measured on the 90 MHz, P5 microprocessor is less than 11 ms, and the correctness of safety decisions is 97%.",https://ieeexplore.ieee.org/document/538227/,"1995 IEEE International Conference on Systems, Man and Cybernetics. Intelligent Systems for the 21st Century",22-25 Oct. 1995,ieeexplore
10.1049/cp:19990285,A neural vision based controller for a robot footballer,IET,Conferences,"Robot football is growing in popularity both as a research topic and as a sporting event. The football setting provides rich interaction possibilities and a ready source of competition in an environment containing both predictable and non-deterministic elements. Successful players must be able to react quickly in real time, exhibit multiple competences and choose between several possibly conflicting goals. Opportunities exist to explore reflexive behaviour, strategic behaviour and even communication and social behaviour in team events. At the same time, artificial neural networks are increasingly being used in robot controllers to explore new biologically-inspired ideas relating to perception, memory and motor control. The research described in this paper attempts to combine these two areas of study to produce a framework for a neurally based and visually guided football-playing controller. A controller architecture is proposed in which a small set of high-level features in the robot's environment are extracted from raw image data by using a feedforward neural network. These feature signals, collectively termed the ""feature bus"", are then available for use by other controller modules. The feature bus signals are sufficiently general and high-level to be used with many different controller strategies, and their low dimensionality compared to the raw visual input makes the implementation of learning controllers more feasible.",https://ieeexplore.ieee.org/document/791354/,"Image Processing And Its Applications, 1999. Seventh International Conference on (Conf. Publ. No. 465)",13-15 July 1999,ieeexplore
10.1109/IJCNN.2015.7280750,A neurocomputational model implemented on humanoid robot for learning action selection,IEEE,Conferences,"Computational modeling of neural circuits enhances our comprehension of brain functions. In addition to the simulation of the models which helps to anticipate cognitive processes, embodiment of these models is essential. Such embodiment would provide the setting to explain neural functioning ongoing in real environments under oncoming sensory information besides giving opportunity of implementation of intelligent systems. Even studies pursued in neuroscience seem far from achieving all these aims in intelligent systems, the pre-results using cognitive models are faster than animal experiments in leading further the understanding of cognitive processes and designing related experiments. In this study, a computational model of basal ganglia, thalamus and cortex for action selection is extended with the point neuron approach to obtain a more realistic method to investigate the model in real time task on humanoid robot platform, Darwin-Op. The spiking neural network model of cortex consists of channels for each action to be elected and plastic alI-to-alI connections from the sensory stimuli to the basal ganglia structures which are modulated with reward. In the task, the sensory inputs, namely colors, are presented to the humanoid robot and it is expected that these sensory inputs would be associated with the predefined actions by modulating the connections. Furthermore, the rearrangement of these associations with reward is performed after learning is accomplished. In this way, the embodiment of computational-model provided more information on the evolution of connections through reward based learning in the action selection circuit.",https://ieeexplore.ieee.org/document/7280750/,2015 International Joint Conference on Neural Networks (IJCNN),12-17 July 2015,ieeexplore
10.1109/ICRoM.2015.7367862,A new adaptive neural network based observer for robotic manipulators,IEEE,Conferences,"In this paper, a new neural network based observer is proposed for a class of nonlinear systems. The proposed observer can applied to estimate nonlinear systems with a high nonlinearity without any prior knowledge about system. This features help the proposed neuro-observer for real implementation and to use it in practice. The Lyapunov's direct method employed to show the stability and estimating performance of the proposed scheme. Simulation results on a two DOF robot manipulator are presented to show the efficiency of the proposed neural network based observer.",https://ieeexplore.ieee.org/document/7367862/,2015 3rd RSI International Conference on Robotics and Mechatronics (ICROM),7-9 Oct. 2015,ieeexplore
10.1109/ROBIO.2013.6739654,A new method for mobile robot arm blind grasping using ultrasonic sensors and Artificial Neural Networks,IEEE,Conferences,"The paper presents a new method to realize mobile robot arm grasping in indoor laboratory environments. This method adopts a blind strategy, which does not need the robot arms be mounted any kind sensors and avoid calculating the complex kinematic equations of the arms. The method includes: (a) two robot on-board ultrasonic sensors in base are utilized to measure the distances between the robot base and the front arm grasping tables; (b) an Artificial Neural Networks (ANN) is proposed to learn/establish the nonlinear relationship between the ultrasonic distances and the joint controlling values. After executing the training step using sampling data, the ANN can forecast/generate the next-step joint controlling values fast and accurately by inputting a new pair of real-time ultrasonic measured distances; (c) to let the blind strategy matching with the transportation process, an arm controlling component with user interfaces is developed; and (d) a method named training arm is adopted to prepare the training data for the training procedure of the ANN model. Finally, an experiment proves that the proposed strategy has good performance in both of the accuracy and the real-time computation, which can be applied to the real-time arm operations for the mobile robot transportation in laboratory automation.",https://ieeexplore.ieee.org/document/6739654/,2013 IEEE International Conference on Robotics and Biomimetics (ROBIO),12-14 Dec. 2013,ieeexplore
10.1109/ICWAPR.2007.4420737,A new method of distance estimation for robot localization in real environment based on manifold learning,IEEE,Conferences,"A new distance estimation method for robot autonomous localization from high-dimensional camera images is proposed based on 4 popular manifold learning algorithms. The camera images are supposed to embed in a high-dimensional manifold, and then the dimension is reduced to estimate the corresponding coordinate of the robot. Two experiments show that the distance is estimated regardless of the illumination, motion noise and environment geometric features. Experiment results with 3 image sets acquiring from the real environment verify the feasibility and effectiveness of the scheme and algorithms proposed in this paper.",https://ieeexplore.ieee.org/document/4420737/,2007 International Conference on Wavelet Analysis and Pattern Recognition,2-4 Nov. 2007,ieeexplore
10.1109/SNPD.2016.7515880,A novel fuzzy omni-directional gait planning algorithm for biped robot,IEEE,Conferences,"Aiming at the problems in gait planning of the biped robots, including the complex model, low stability, etc., a novel fuzzy omni-directional gait planning algorithm (FOGPA) is proposed. At first, this method puts forward a new separated omni-directional gait planning model, which combines the straight walking planning algorithm based on the improved Hermite interpolation and the rotation motion together. And then, a fuzzy gait parameter adjustment algorithm is put forward to control the gait parameters including the step size and rotation speed dynamically. At last, the fuzzy control results are used to get the gait data of robot real-timely. The experiment results show that the FOGPA improves the stability and robustness of gait in a certain degree and also improves the adaptability to the complex environment of the robot.",https://ieeexplore.ieee.org/document/7515880/,"2016 17th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)",30 May-1 June 2016,ieeexplore
10.1109/HAPTICS.2014.6775492,A novel haptic interface and control algorithm for robotic rehabilitation of stoke patients,IEEE,Conferences,"Rehabilitation robots are gradually becoming popular for stroke rehabilitation to improve motor recovery. By using a robot, the patient may perform the training more frequently on their own, but they must be motivated to do so. Therefore, this project develops a set of rehabilitation training programs with different haptic modalities on Compact Rehabilitation Robot (CR2) - a robot used to train upper and lower limbs reaching movement. The paper present the developed haptic interface, Haptic Sense with five configurable haptic modalities that include sensations of weight, wall, spring, sponge and visual amplification. A combination of several haptic modalities was implemented into virtual reality games, Water Drop - a progressive training game with up to nine levels of difficulties that requires user to move the cup to collect the water drops.",https://ieeexplore.ieee.org/document/6775492/,2014 IEEE Haptics Symposium (HAPTICS),23-26 Feb. 2014,ieeexplore
10.1109/ICMLC.2011.6016883,A novel intelligent control system design for a humanoid robot,IEEE,Conferences,"This paper presents the design of an intelligent control system for a humanoid robot. A novel fuzzy cerebellar model articulation controller (FCMAC) is proposed; this controller incorporates the fuzzy system inference rule with a CMAC fast learning ability. This FCMAC is a generalization network; in some special cases it can be reduced to a fuzzy neural network or a CMAC. This FCMAC is used as the main controller for the trajectory tracking control of the robot. In this robotic system, an inertial navigation system (INS) including gyroscopes and accelerometers is used to measure the robot's attitude and acceleration for modifying the dynamic attitude of the robot. Moreover, a zero moment point (ZMP) compensator is used to on-line adjust the gait trajectories to improve the walking stability. The control system is implemented based on system on a programmable chip (SoPC) technology. Thus, this intelligent control system can achieve real-time on-line closed-loop feedback control of the humanoid robot. Experimental results show that the developed system can achieve favorable control performance for a high-order nonlinear humanoid robot.",https://ieeexplore.ieee.org/document/6016883/,2011 International Conference on Machine Learning and Cybernetics,10-13 July 2011,ieeexplore
10.1049/cp:19940180,A novel neural adaptive controller for robots,IET,Conferences,"Existing industrial robotic manipulators have proven to be limited in many applications, e.g. both their payload capability and manipulation speeds are limited. This paper presents a novel neural adaptive controller-intelligent gain scheduling-(IGS) for robotic manipulators. It advances the idea of mapping the nonlinear relationship between robot working conditions (e.g. payload, speed, etc.) and its controller gains. This scheme is simple, inexpensive, and especially, attractive for its possible implementation in real-time. Simulation has shown promising results.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/327097/,1994 International Conference on Control - Control '94.,21-24 March 1994,ieeexplore
10.1109/PEAM.2011.6135058,A novel on-line training solution using a Radial Basis Function Network to modify the inverse kinematic approximation of a robot-vision system,IEEE,Conferences,"This paper describes a new practical approach for approximating the inverse kinematics of a manipulator using an RBFN (Radial Basis Function Network). This neural network with its inherent learning ability can be an effective alternative solution for the inverse kinematics problem where traditional methods are impractical because the manipulator geometry cannot be easily determined, e.g. in a robot-vision system. However, sometimes a well-trained network cannot work effectively in the operational phase because the initial network training occurs in an environment that is not exactly the same as the environment where the system is actually deployed. In this paper, an on-line retraining solution using the Delta rule is presented for systems whose characteristics change due to environmental variations. Moreover, a “free interference rule” is also suggested to avoid learning interference where the training effect of a current training point may upset some of the weights which were trained with previous points. To verify the performance of the proposed approach, a practical experiment has been performed using a Mitsubishi PA10-6CE manipulator observed by a webcam. All application programmes, such as robot servo control, neural network, and image processing tool, were written in C/C++ and run in a real robotic system. The experimental results prove that the proposed approach is effective.",https://ieeexplore.ieee.org/document/6135058/,2011 IEEE Power Engineering and Automation Conference,8-9 Sept. 2011,ieeexplore
10.1109/ICSMC.1999.812484,A paradigm for intelligent motion planning of robot manipulators,IEEE,Conferences,"A paradigm for intelligent motion planning of robot manipulators is presented, and its implementation by some unconventional (AI, soft computing, computational intelligence) techniques is outlined. The article focuses on those aspects that lead, from an intelligent/unconventional point of view, to a unified framework for real-time motion planning, singularities prevention, and/or pseudoinverse robustness.",https://ieeexplore.ieee.org/document/812484/,"IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028)",12-15 Oct. 1999,ieeexplore
10.1109/IJCNN.2003.1223697,A performance comparison of TRACA - an incremental on-line learning algorithm,IEEE,Conferences,"TRACA (Temporal Reinforcement-learning and Classification Architecture) is a learning system intended for robot-navigation tasks. One problem in this area is input-generalisation. Input generalisation requires learning a small set of internal states which represent useful abstractions of the much larger set of actual states. As such, the input-generalisation problem is fundamentally similar to the classical problems of classification, concept learning and discrimination. The priorities when evaluating a system for on-line robot learning include a small number of trials, predictive accuracy and minimal parameter tuning. Other requirements are the ability to learn without predefined classes (i.e. classes must be learned during training) and an efficient and adaptable representation. This paper evaluates the performance of TRACA, a new learning algorithm, on a number of common classification tasks. The same set of parameters is used to obtain all TRACA's results, which are then compared to the results obtained by other well-known algorithms. On most tasks, TRACA's predictive accuracy is within a few percent of the best performing systems compared. Furthermore, TRACA's result is often achieved with less training experience. In a final experiment TRACA is trialled on a robot navigation task that requires discrimination of a number of discrete locations.",https://ieeexplore.ieee.org/document/1223697/,"Proceedings of the International Joint Conference on Neural Networks, 2003.",20-24 July 2003,ieeexplore
10.1109/IECON.1993.339087,A planning architecture for intelligent robot: fuzzy memory-based reasoning for real-time planning/control,IEEE,Conferences,"Our research's main objective is to design an architecture prototype to govern an intelligent robot which can work quickly and efficiently in a vague dynamical environment, typically where various robots and human cooperate each other to accomplish a common global goal. To realize such kind of system, a new planning and control architecture with abilities of real-time control and easy implementation of control knowledge is required. The architecture proposed here is based on the idea of memory-based reasoning systems and behavior-based control systems. Then, to confirm its performance, a simple simulation example of two mobile robots that cooperate to capture a target is showed.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/339087/,Proceedings of IECON '93 - 19th Annual Conference of IEEE Industrial Electronics,15-19 Nov. 1993,ieeexplore
10.1109/ROBIO.2014.7090487,A portable stand-alone bi-hemispherical neuronal network model of the cerebellum for adaptive robot control,IEEE,Conferences,"Development of computational models of the brain is relevant not only for deepening our understanding of the biological system but also for potential applications to various engineering problems. In this paper the implementation of a bi-hemispherical neuronal network model of the cerebellum (biCNN) in a stand-alone, portable real time (RT) device is presented. The biCNN is tested during a control engineering application, namely, control of a highly unstable two-wheel balancing robot. The RT device considered is the National Instruments myRIO-1900, which provides flexibility and portability to the biCNN. Execution times obtained with the RT device are compared with a personal computer implementation as reference. The results demonstrate the suitability of the RT implementation of the biCNN for robot control, and provide a successful bridge between the cerebellar research and engineering.",https://ieeexplore.ieee.org/document/7090487/,2014 IEEE International Conference on Robotics and Biomimetics (ROBIO 2014),5-10 Dec. 2014,ieeexplore
10.1109/ICCAS.2015.7364829,A precise position control of robot manipulator with eight joints,IEEE,Conferences,"We describe a new approach to the design and real-time implementation of an adaptive controller for robotic manipulator based on digital signal processors in this paper. The Texas Instruments DSPs(TMS320C80) chips are used in implementing real-time adaptive control algorithms to provide enhanced motion control performance for dual-arm robotic manipulators. In the proposed scheme, adaptation laws are derived from model reference adaptive control principle based on the improved direct Lyapunov method. The proposed adaptive controller consists of an adaptive feed-forward and feedback controller and time-varying auxiliary controller elements. The proposed control scheme is simple in structure, fast in computation, and suitable for real-time control. Moreover, this scheme does not require any accurate dynamic modeling, nor values of manipulator parameters and payload. Performance of the proposed adaptive controller is illustrated by simulation and experimental results for robot manipulator consisting of dual arm with four degrees of freedom at the joint space and cartesian space.",https://ieeexplore.ieee.org/document/7364829/,"2015 15th International Conference on Control, Automation and Systems (ICCAS)",13-16 Oct. 2015,ieeexplore
10.1109/IROS.1998.727453,A real-time library for the design of hybrid robot control architectures,IEEE,Conferences,"Describes a real-time library providing facilities useful in the design of robot control architectures. The library supports structured creation of reactive and deliberative modules, dynamic modification of relevant real-time parameters, generation of timing fault handlers, measurement and monitoring of execution times. This support enables adaptation of the rate of computation of real-time modules to the rate of change of the external world, and hence better tuning of robot behavior to the world uncertainty and dynamics. The real-time library has been put to work by designing a hybrid control architecture for a robot performing a kitting task. In the prototype experiment described in the paper, a Puma 560 robot manipulator is fed with parts by a small mobile robot. The control architecture governing Puma operations dynamically allocates computational resources to reactive and deliberative modules, according to the task level priorities.",https://ieeexplore.ieee.org/document/727453/,"Proceedings. 1998 IEEE/RSJ International Conference on Intelligent Robots and Systems. Innovations in Theory, Practice and Applications (Cat. No.98CH36190)",17-17 Oct. 1998,ieeexplore
10.1109/SICE.2002.1195611,A reinforcement learning using adaptive state space construction strategy for real autonomous mobile robots,IEEE,Conferences,"In the recent robotics, much attention has been focused on utilizing reinforcement learning for designing robot controllers. However, there still exists difficulties, one of them is well known as state space explosion problem. As the state space for a learning system becomes continuous and high dimensional, its combinational state space exponentially explodes and the learning process is time consuming. In this paper, we propose an adaptive state space recruitment strategy for reinforcement learning, which enables the system to divide state space gradually according to task complexity and progress of learning. Some simulation results and real robot implementation show the validity of the method.",https://ieeexplore.ieee.org/document/1195611/,Proceedings of the 41st SICE Annual Conference. SICE 2002.,5-7 Aug. 2002,ieeexplore
10.1109/IRDS.2002.1041504,A reinforcement learning with adaptive state space recruitment strategy for real autonomous mobile robots,IEEE,Conferences,"In the recent robotics, much attention has been focused on utilizing reinforcement learning for designing robot controllers. However, there still exists difficulties, one of them is well known as state space explosion problem. As the state space for learning system becomes continuous and high dimensional, the learning process results in time-consuming since its combinational states explodes exponentially. In order to adopt reinforcement learning for such complicated systems, it should be taken not only ""adaptability"" but ""computational efficiencies"" into account. In the paper, we propose an adaptive state space recruitment strategy for reinforcement learning, which enables the system to divide state space gradually according to task complexity and progress of learning. Some simulation results and real robot implementation show the validity of the method.",https://ieeexplore.ieee.org/document/1041504/,IEEE/RSJ International Conference on Intelligent Robots and Systems,30 Sept.-4 Oct. 2002,ieeexplore
10.1049/cp.2012.0975,A robot dance system based on real-time beat prediction,IET,Conferences,"In this paper, we present a robot with a system of tracking beats and downbeats from musical audio in real time as well as automatically synthesizing dance motions synchronized to the extracted musical events. And a real-time beat prediction approach improved by an off-line analysis is described, which has positive effects on the estimations of beat and downbeat. We also make an attempt to solve the problem of enabling a robot to understand the played music and accomplish dance compositions intelligently itself. Consequently, the experimental results are quite encouraging and show that our implemented robot, to some extent, has the ability of dancing in time to the music.",https://ieeexplore.ieee.org/document/6492582/,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),3-5 March 2012,ieeexplore
10.1109/IROS.2003.1250667,A robot that reinforcement-learns to identify and memorize important previous observations,IEEE,Conferences,"It is difficult to apply traditional reinforcement learning algorithms to robots, due to problems with large and continuous domains, partial observability, and limited numbers of learning experiences. This paper deals with these problems by combining: (1) reinforcement learning with memory, implemented using an LSTM recurrent neural network whose inputs are discrete events extracted from raw inputs; (2) online exploration and offline policy learning. An experiment with a real robot demonstrates the methodology's feasibility.",https://ieeexplore.ieee.org/document/1250667/,Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453),27-31 Oct. 2003,ieeexplore
10.1145/1957656.1957782,A robotic game to evaluate interfaces used to show and teach visual objects to a robot in real world condition,IEEE,Conferences,"In this paper, we present a real world user study of 4 interfaces designed to teach new visual objects to a social robot. This study was designed as a robotic game in order to maintain the user's motivation during the whole experiment. Among the 4 interfaces 3 were based on mediator objects such as an iPhone, a Wiimote and a laser pointer. They also provided the users with different kind of feedback of what the robot is perceiving. The fourth interface was a gesture based interface with a Wizard-of-Oz recognition system added to compare our mediator interfaces with a more natural interaction. Here, we specially studied the impact the interfaces have on the quality of the learning examples and the usability. We showed that providing non-expert users with a feedback of what the robot is perceiving is needed if one is interested in robust interaction. In particular, the iPhone interface allowed non-expert users to provide better learning examples due to its whole visual feedback. Furthermore, we also studied the user's gaming experience and found that in spite of its lower usability, the gestures interface was stated as entertaining as the other interfaces and increases the user's feeling of cooperating with the robot. Thus, we argue that this kind of interface could be well-suited for robotic game.",https://ieeexplore.ieee.org/document/6281349/,2011 6th ACM/IEEE International Conference on Human-Robot Interaction (HRI),8-11 March 2011,ieeexplore
10.1109/MFI-2003.2003.1232590,A robust real time position and force (hybrid) control of a robot manipulator in presence of uncertainties,IEEE,Conferences,"We examine the living intelligent biological systems and model the computational system components. We consider the situation of a kind of ""blind-tracking"" with constant force/torque by a human hand. The problem involves hand kinematics, hand motor control, and an adaptive judgment method from the position and force/torque reflection of the uncertain hyper plane. In this study, these control levels were designed using neural networks and fuzzy logic technologies. The control levels are coordinated amongst themselves forming the distributed artificial intelligent (DAI) system. The conclusive characteristic of the proposed controller was a one-step-ahead feedback control. This DAI-based control systems was implemented in the RX-90 industrial robot. Certainly these types of control system will help an industry to be autonomous and increase the productivity as well.",https://ieeexplore.ieee.org/document/1232590/,"Proceedings of IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems, MFI2003.",1-1 Aug. 2003,ieeexplore
10.1109/IJCNN.2017.7965912,A self-driving robot using deep convolutional neural networks on neuromorphic hardware,IEEE,Conferences,"Neuromorphic computing is a promising solution for reducing the size, weight and power of mobile embedded systems. In this paper, we introduce a realization of such a system by creating the first closed-loop battery-powered communication system between an IBM Neurosynaptic System (IBM TrueNorth chip) and an autonomous Android-Based Robotics platform. Using this system, we constructed a dataset of path following behavior by manually driving the Android-Based robot along steep mountain trails and recording video frames from the camera mounted on the robot along with the corresponding motor commands. We used this dataset to train a deep convolutional neural network implemented on the IBM NS1e board containing a TrueNorth chip of 4096 cores. The NS1e, which was mounted on the robot and powered by the robot's battery, resulted in a self-driving robot that could successfully traverse a steep mountain path in real time. To our knowledge, this represents the first time the IBM TrueNorth has been embedded on a mobile platform under closed-loop control.",https://ieeexplore.ieee.org/document/7965912/,2017 International Joint Conference on Neural Networks (IJCNN),14-19 May 2017,ieeexplore
10.1109/ISIE.2010.5637497,A society of agents for service robots,IEEE,Conferences,"This article presents an agent based distributed software architecture for machine and robot control. The functionality of agents of this architecture has been inspired by Marvin Minsky's definition of the term in his book “The Society of Mind” (1986) [1]. Minsky, widely considered to be one of the fathers of artificial intelligence, tried to describe from an engineering point of view, in this book, how he thought the mind works: “I'll call “Society of Mind” this scheme in which each mind is made of many smaller processes. These we'll call agents. Each mental agent by itself can only do some simple thing that needs no mind or thought at all. Yet when we join these agents in societies-in certain very special ways-this leads to true intelligence.” Societies of simple behaving agents have been implemented in Fatronik, in real robots, and have been demonstrated to be able to perform complex tasks in industrial environments. This article explains the features of such societies of agents and presents their implementation in a real robot.",https://ieeexplore.ieee.org/document/5637497/,2010 IEEE International Symposium on Industrial Electronics,4-7 July 2010,ieeexplore
10.1109/CADCG.2009.5246869,A study on autonomous animated robots: Anibots,IEEE,Conferences,"In this paper, we demonstrate a design of autonomous virtual creatures (called animated robots: Anibots in this paper) and develop a design tool for animated robots. An animated robot can behave autonomously by using its own sensors and controllers on three-dimensional physically modeled environment. The developed tool can enable us to execute the simulation of Anibots on physical environment at any time during the modeling process. In order to simulate more realistic world, an approximate fluid environment model with low computational costs is presented. It is shown that a combinatorial use of neural network implementation for controllers and the genetic algorithm (GA) or the particle swarm optimization (PSO) is effective for emerging more realistic autonomous behaviours of animated robots.",https://ieeexplore.ieee.org/document/5246869/,2009 11th IEEE International Conference on Computer-Aided Design and Computer Graphics,19-21 Aug. 2009,ieeexplore
10.1109/ROMAN.1993.367699,A successive learning neuro control system shooting irregular moving object,IEEE,Conferences,"A successive learning control system based on a neural network technique with a genetic algorithm has been developed to simulate a human real-time learning process. As an application experiment, a 3 degree-of-freedom arm robot shoots a ball equipped with a CCD camera at an irregular moving basket. Where the hitting rate is improved by the successive learning control and the final value was 23% in average, 40% in maximum.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/367699/,Proceedings of 1993 2nd IEEE International Workshop on Robot and Human Communication,3-5 Nov. 1993,ieeexplore
10.1109/ICCITECHN.2016.7860248,A support vector machine approach for real time vision based human robot interaction,IEEE,Conferences,"Today humanoid robots are being exhibited to redact various task as a personal assistant of a human. To be an assistant, a robot needs to interact with human as a human. For this reason robot needs to understand the human gender, facial expression, facial gesture in real time. Ribo - A humanoid robot build in RoboSUST lab which has the ability to communicate in Bangla with the people speaking in Bengali. In this article the authors show the implementation of theoretical knowledge of the recognition of real time facial expression, detection of human gender and yes / no from facial gesture in Ribo. Real time facial expression and gender detection can be performed using Support Vector Machine (SVM). A prepared dataset containing the facial landmarks leveled as five different expression: sad, angry, smile, surprise and normal, is given to SVM to construct a classifier. For the prediction of any expression, facial images are taken in real time and provided the facial landmarks data to SVM. Local Binary Pattern(LBP) algorithm is used for extracting features from face images. These features leveled as male and female are responsible to build the classifier. The face gesture for detecting `yes/no' is performed by tracking the movement of face in a certain time. After those implementations the principal results will make a framework that will be used in Ribo to recognize human facial expression, facial gesture movement and detect human gender.",https://ieeexplore.ieee.org/document/7860248/,2016 19th International Conference on Computer and Information Technology (ICCIT),18-20 Dec. 2016,ieeexplore
10.1109/ICAT.2013.6728900,A teleoperating interface for ground vehicles using autonomous flying cameras,IEEE,Conferences,"Navigating remote robots and providing awareness of the remote environment is essential in many teleoperated tasks. An external view on the remote robot, a bird's eye view, is thought to improve operator performance. In this paper we explore a novel design for providing such a third-person view for a ground vehicle using a dynamic, external camera mounted on a quadcopter. Compared to earlier methods that use 3D reconstruction to create third-person views, our approach comprises a true third-person view through a video feed. We so provide visually rich, live information to the operator. In an experiment simulating a search and rescue mission in a simplified environment, we compared our proposed design to a pole-mounted camera and to a traditional front-mounted camera. The third-person perspective provided by our flying camera and pole-mounted camera resulted in fewer collisions and more victims being located, compared to the front-mounted camera.",https://ieeexplore.ieee.org/document/6728900/,2013 23rd International Conference on Artificial Reality and Telexistence (ICAT),11-13 Dec. 2013,ieeexplore
10.1109/IROS.1994.407376,A two-phase navigation system for mobile robots in dynamic environments,IEEE,Conferences,"This paper presents an implemented navigation system for mobile robots in dynamic environments. In order to take advantage of existing knowledge of the world and to deal with unknown obstacles in real time, our system divides motion planning into global path planning and local reactive navigation. The former uses genetic algorithm methods to find a collision-free path; the latter is implemented using neural network techniques to track the path generated by the global planner while avoiding unknown obstacles on the way. As a result, the system can adapt to dynamic environmental changes. Our experiments, both in simulation and on a real robot, showed that the system can find a reasonably good free path in a fraction of the time necessary to find an optimal free path, and it can effectively achieve its goal configurations without collision.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/407376/,Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS'94),12-16 Sept. 1994,ieeexplore
10.1109/ICSMC.2004.1400779,A user-oriented framework for the design and implementation of pet robots,IEEE,Conferences,"In recent years, application of intelligent autonomous robots for home amusement has become an important research criterion, and pet robots have been designed to become the electronic toys for the next generation. To develop pet robots that can act in real time in the real world, this work adopts the behavior-based control architecture. In our control framework, an imitation-based learning system is included to build robot behaviors. Moreover an emotional model is embedded to the control architecture. By giving the pet robot an emotional model it can explicitly express its internal conditions through its various external behaviors, as the real living creature does. To evaluate the proposed framework, we have developed an interactive environment and successfully used it to design a pet robot.",https://ieeexplore.ieee.org/document/1400779/,"2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)",10-13 Oct. 2004,ieeexplore
10.1109/IJCNN.2004.1379924,A virtual exploring mobile robot for left ventricle contour tracking,IEEE,Conferences,"In this paper we describe a totally new and original approach for combining global and local information in medical image processing. We implemented a virtual mobile robot and trained it using fuzzy neural networks to recognize segments of the myocardium while he navigates autonomously around the left ventricle (LV) of the heart. On its journey around the heart, the virtual exploring robot applies appropriate local edge detection to delineate fully automatically the borders of the myocardium. This may sound unconventional but it has proven effective enough to be integrated in a clinical analytical software tool.",https://ieeexplore.ieee.org/document/1379924/,2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541),25-29 July 2004,ieeexplore
10.1109/IROS.1998.724594,A virtual target approach for resolving the limit cycle problem in navigation of a fuzzy behaviour-based mobile robot,IEEE,Conferences,"A virtual target approach is proposed for resolving the limit cycle problem in navigation of a behaviour-based mobile robot. Starting from the onset point of a possible limit cycle path, the real target is switched to a virtual location and the robot is navigated according to the virtual target set up temporarily and the real environment information sensed, until a switching back condition is reached. The condition for switching back to the real target is established using a specific change in the obstacle information sensed. The algorithm is described together with some particular considerations in implementation. Efficiency and effectiveness of the proposed approach are verified through simulation and experiments conducted with a Nomad 200 robot incorporating a fuzzy, behaviour-based controller.",https://ieeexplore.ieee.org/document/724594/,"Proceedings. 1998 IEEE/RSJ International Conference on Intelligent Robots and Systems. Innovations in Theory, Practice and Applications (Cat. No.98CH36190)",17-17 Oct. 1998,ieeexplore
10.1109/ROBOT.2010.5509238,A voice-commandable robotic forklift working alongside humans in minimally-prepared outdoor environments,IEEE,Conferences,"One long-standing challenge in robotics is the realization of mobile autonomous robots able to operate safely in existing human workplaces in a way that their presence is accepted by the human occupants. We describe the development of a multi-ton robotic forklift intended to operate alongside human personnel, handling palletized materials within existing, busy, semi-structured outdoor storage facilities. The system has three principal novel characteristics. The first is a multimodal tablet that enables human supervisors to use speech and pen-based gestures to assign tasks to the forklift, including manipulation, transport, and placement of palletized cargo. Second, the robot operates in minimally-prepared, semi-structured environments, in which the forklift handles variable palletized cargo using only local sensing (and no reliance on GPS), and transports it while interacting with other moving vehicles. Third, the robot operates in close proximity to people, including its human supervisor, other pedestrians who may cross or block its path, and forklift operators who may climb inside the robot and operate it manually. This is made possible by novel interaction mechanisms that facilitate safe, effective operation around people. We describe the architecture and implementation of the system, indicating how real-world operational requirements motivated the development of the key subsystems, and provide qualitative and quantitative descriptions of the robot operating in real settings.",https://ieeexplore.ieee.org/document/5509238/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/SMC.2019.8914201,A3C Based Motion Learning for an Autonomous Mobile Robot in Crowds,IEEE,Conferences,"The paper proposes a motion planning method using a deep reinforcement learning algorithm, Asynchronous Advantage Actor-Critic (A3C). For mobile robot navigation tasks in crowds, existing path planning based approaches are limited because the surrounding environments change dynamically. The correct motion in such a dynamic environment is underspecified, and a reinforcement learning approach is suitable for generating applicable motion. We propose an A3C based motion planning method for acquiring robot motion for a robot moving through crowds. The proposed method is evaluated in simulated crowds of pedestrians. The experiment section shows the basic performance depending on training parameters and some generated motion examples in the simulator. The learning results using real pedestrian motion are also shown.",https://ieeexplore.ieee.org/document/8914201/,"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)",6-9 Oct. 2019,ieeexplore
10.1109/FUZZ48607.2020.9177654,AI-FML Agent for Robotic Game of Go and AIoT Real-World Co-Learning Applications,IEEE,Conferences,"In this paper, we propose an AI-FML agent for robotic game of Go and AIoT real-world co-learning applications. The fuzzy machine learning mechanisms are adopted in the proposed model, including fuzzy markup language (FML)-based genetic learning (GFML), eXtreme Gradient Boost (XGBoost), and a seven-layered deep fuzzy neural network (DFNN) with backpropagation learning, to predict the win rate of the game of Go as Black or White. This paper uses Google AlphaGo Master sixty games as the dataset to evaluate the performance of the fuzzy machine learning, and the desired output dataset were predicted by Facebook AI Research (FAIR) ELF Open Go AI bot. In addition, we use IEEE 1855 standard for FML to describe the knowledge base and rule base of the Open Go Darkforest (OGD) prediction platform in order to infer the win rate of the game. Next, the proposed AI-FML agent publishes the inferred result to communicate with the robot Kebbi Air based on MQTT protocol to achieve the goal of human and smart machine co-learning. From Sept. 2019 to Jan. 2020, we introduced the AI-FML agent into the teaching and learning fields in Taiwan. The experimental results show the robots and students can co-learn AI tools and FML applications effectively. In addition, XGBoost outperforms the other machine learning methods but DFNN has the most obvious progress after learning. In the future, we hope to deploy the AI-FML agent to more available robot and human co-learning platforms through the established AI-FML International Academy in the world.",https://ieeexplore.ieee.org/document/9177654/,2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),19-24 July 2020,ieeexplore
10.1109/ROBIO.2009.5420410,AMF: A novel reactive approach for motion planning of mobile robots in unknown dynamic environments,IEEE,Conferences,"This paper presents a new approach based on Artificial Potential Fields (APF) which provides real-time and very effective methodology for practical motion planners in unknown dynamic environments. The Maxwell's equations are exploited to define Artificial Magnetoquasistatic Fields (AMF) as an extension of APF, which provides a predictive, intelligent, and natural behavior in contrast with other approaches. The essential aim of the AMF is dealing with moving obstacles, as well as static ones. The main idea is to consider an electrical current in the direction of each moving obstacle which induces magnetic field around it. These moving obstacles could be arbitrary in shape, size, and number. Neither the motion-trajectory of the moving obstacles nor the model of their motion is known. The only available information is their instantaneous velocity at each time step. In this method, the magnetoquasistatic approximation is used to obtain the electric and magnetic fields around robot. Next, using Lorentz equation, the necessary force can be calculated which should be applied to robot to avoid the collision with obstacles. A path planner based on this approach has been implemented and tested by various scenarios containing both static and moving obstacles. Simulations and experimental results illustrate the efficacy of the proposed method.",https://ieeexplore.ieee.org/document/5420410/,2009 IEEE International Conference on Robotics and Biomimetics (ROBIO),19-23 Dec. 2009,ieeexplore
10.1109/ISCAS.2019.8702353,AR-C3D: Action Recognition Accelerator for Human-Computer Interaction on FPGA,IEEE,Conferences,"In recent years, action recognition has been widely explored and attains significant performance improvement. In this paper, we propose a real-time action recognition specified convolutional 3D (AR-C3D) neural network for human-computer interaction. The CNN structure is optimized to decrease the complexity. Furthermore, Winograd algorithm is adopted to accelerate computation. It achieves 89.9% accuracy in the application which refers to the robot classifies the video captured by itself and would either imitate human's action or give verbal feedback. The Artix-7 FPGA implementation result outperforms previous work in terms of resource utilization and no external storage is consumed. One video can be processed in 6.6ms, and the power consumption is only 2.7W.",https://ieeexplore.ieee.org/document/8702353/,2019 IEEE International Symposium on Circuits and Systems (ISCAS),26-29 May 2019,ieeexplore
10.1109/WRCSARA53879.2021.9612673,ATFVO: An Attentive Tensor-compressed LSTM Model with Optical Flow Features for Monocular Visual Odometry,IEEE,Conferences,"This paper proposes a new framework called ATFVO which can be deployed on the edge device to resolve monocular visual odometry problem. The vast majority of visual odometry algorithms using deep learning are equivalent to or beyond the traditional visual odometry algorithms in performance, however they do not consider the computing capability of edge equipment. In this paper, convolution neural network (CNN) and attentive tensor-compressed compression LSTM (A-T-LSTM) are used, with optical flow feature as input and a 6-DoF absolute-scale pose as output. The framework is fused with the spatio-temporal feature and deal with the overfitting problem of over-parameterized LSTM with high-dimensional inputs, and utilizes attention mechanism to get poses from the sequence output of T-LSTM. The poses are estimated from the original RGB images sequence without depending on any prior knowledge. The experimental outcomes at the KITTI dataset display that, in compared with the performance of the most advanced methods, the single T-LSTM model is 141× smaller than the original LSTM model, and the entire model is nearly one-seventh of DeepVO with a speed 23× faster than Flowdometry. The proposed VO is deployed to the robot based on raspberry pi, which can achieve real-time inference and navigate a cruise.",https://ieeexplore.ieee.org/document/9612673/,2021 WRC Symposium on Advanced Robotics and Automation (WRC SARA),11-11 Sept. 2021,ieeexplore
10.1109/IEEECONF49454.2021.9382693,Accelerated Sim-to-Real Deep Reinforcement Learning: Learning Collision Avoidance from Human Player,IEEE,Conferences,"This paper presents a sensor-level mapless collision avoidance algorithm for use in mobile robots that map raw sensor data to linear and angular velocities and navigate in an unknown environment without a map. An efficient training strategy is proposed to allow a robot to learn from both human experience data and self-exploratory data. A game format simulation framework is designed to allow the human player to tele-operate the mobile robot to a goal and human action is also scored using the reward function. Both human player data and self-playing data are sampled using prioritized experience replay algorithm. The proposed algorithm and training strategy have been evaluated in two different experimental configurations: Environment 1, a simulated cluttered environment, and Environment 2, a simulated corridor environment, to investigate the performance. It was demonstrated that the proposed method achieved the same level of reward using only 16% of the training steps required by the standard Deep Deterministic Policy Gradient (DDPG) method in Environment 1 and 20% of that in Environment 2. In the evaluation of 20 random missions, the proposed method achieved no collision in less than 2 h and 2.5 h of training time in the two Gazebo environments respectively. The method also generated smoother trajectories than DDPG. The proposed method has also been implemented on a real robot in the real-world environment for performance evaluation. We can confirm that the trained model with the simulation software can be directly applied into the real-world scenario without further fine-tuning, further demonstrating its higher robustness than DDPG. The video and code are available: https://youtu.be/BmwxevgsdGc https://github.com/hanlinniu/turtlebot3_ddpg_collision_avoidance.",https://ieeexplore.ieee.org/document/9382693/,2021 IEEE/SICE International Symposium on System Integration (SII),11-14 Jan. 2021,ieeexplore
10.1109/ICTAI.2019.00249,Accurate and Robust RGB-D Dense Mapping with Inertial Fusion and Deformation-Graph Optimization,IEEE,Conferences,"RGB-D dense mapping has become more and more popular, however, when encountering rapid movement or shake, the robustness and accuracy of most RGB-D dense mapping methods are degraded and the generated maps are overlapped or distorted, due to the drift of pose estimation. In this paper, we present a novel RGB-D dense mapping method, which can obtain accurate, robust and global consistency map even in the above complex conditions. Firstly, the improved ORBSLAM method, which tightly-couples RGB-D information and inertial information to estimate the current pose of robot, is firstly introduced for accurate pose estimation rather than traditional frame-to-frame method in most RGB-D dense mapping methods. Besides, the TSDF (Truncated Signed Distance Function) method is used to effectively fuse depth frame into a global model, and to keep the global consistency of the generated map. Furthermore, since the drift error is inevitable, a deformation graph is constructed to minimize the consistent error in global model, to further improve the mapping performance. The performance of the proposed RGB-D dense mapping method was validated by extensive localization and mapping experiments on public datasets and real scene datasets, and it showed strongly accuracy and robustness over other state-of-the-art methods. What's more, the proposed method can achieve real-time performance implemented on GPU.",https://ieeexplore.ieee.org/document/8995400/,2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI),4-6 Nov. 2019,ieeexplore
10.1109/OCEANS.2000.882252,Acoustic-based position discrimination of a moving robot,IEEE,Conferences,"A real-world experiment is described, demonstrating the possibility of discriminating positions of a mobile robot moving through an unknown, unprepared office room, solely based on broadband audible acoustic signals. The average distance of distinguishable positions was found to be less than 15 cm. Maximum length sequence measurements are used to obtain the impulse response of the room at the present position, and a modified vector distance measure is used to cluster the data via the Neural Gas algorithm. No further interpretation of the data is performed. The data analysis method is independent of the environment or the recording system (the robot), therefore it is potentially applicable to other environments and vehicles. The method is especially interesting for the navigation of AUVs in unknown environments, as acoustic signals represent a major source of information in the underwater world, being available under the broadest range of circumstances.",https://ieeexplore.ieee.org/document/882252/,OCEANS 2000 MTS/IEEE Conference and Exhibition. Conference Proceedings (Cat. No.00CH37158),11-14 Sept. 2000,ieeexplore
10.1109/IROS.2004.1389844,Acquisition of human-robot joint attention through real-time natural interaction,IEEE,Conferences,"Joint attention, a process to attend to the object that the other attends to is supposed to be important for human-robot communication as well as for human-human communication. We propose an architecture for acquiring joint attention within a certain time period for realizing natural human-robot interaction. The architecture has two featured modules: a self-organizing map that makes the leaning time shorter and an automatic visual attention selector that let the agent communicate with a human synchronously. We implemented the proposed architecture in a real robot agent and found that 30 minutes was enough for acquiring joint attention with two objects. We can conclude from preliminary experiments that even if the gaze preference of the robot is different from that of the human caregiver, it can acquire joint attention.",https://ieeexplore.ieee.org/document/1389844/,2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),28 Sept.-2 Oct. 2004,ieeexplore
10.1109/IROS45743.2020.9341187,Active Improvement of Control Policies with Bayesian Gaussian Mixture Model,IEEE,Conferences,"Learning from demonstration (LfD) is an intuitive framework allowing non-expert users to easily (re-)program robots. However, the quality and quantity of demonstrations have a great influence on the generalization performances of LfD approaches. In this paper, we introduce a novel active learning framework in order to improve the generalization capabilities of control policies. The proposed approach is based on the epistemic uncertainties of Bayesian Gaussian mixture models (BGMMs). We determine the new query point location by optimizing a closed-form information-density cost based on the quadratic Rényi entropy. Furthermore, to better represent uncertain regions and to avoid local optima problem, we propose to approximate the active learning cost with a Gaussian mixture model (GMM). We demonstrate our active learning framework in the context of a reaching task in a cluttered environment with an illustrative toy example and a real experiment with a Panda robot.",https://ieeexplore.ieee.org/document/9341187/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ISCIS.2009.5291811,Active humanoid vision and object classification,IEEE,Conferences,"In this paper we study object learning and recognition on a humanoid robot with foveated vision. The developed approach is view-based and can learn viewpoint-independent representations for object recognition. The training data is collected statistically and in an interactive way where a human instructor freely shows the object from a number of different viewpoints. The proposed system was fully implemented and runs in real-time, which is essential for meaningful interaction with a humanoid robot.",https://ieeexplore.ieee.org/document/5291811/,2009 24th International Symposium on Computer and Information Sciences,14-16 Sept. 2009,ieeexplore
10.1109/FUZZ-IEEE.2014.6891705,Active interaction control of a rehabilitation robot based on motion recognition and adaptive impedance control,IEEE,Conferences,"Although electromyography (EMG) signals and interaction force have been widely used in patient cooperative or interactive training, the conventional EMG based control usually breaks the process into a patient-driven phase and a separate passive phase, which is not desirable. In this research, an active interaction controller based on motion recognition and adaptive impedance control is proposed and implemented on a six-DOFs parallel robot for lower limb rehabilitation. The root mean square (RMS) features of EMG signals integrating with the support vector machine (SVM) classifier were used to online predict the lower limb intention in advance and to trigger the robot assistance. The impedance control strategy was adopted to directly influence the robot assistance velocity and allow the exercise to follow a physiological trajectory. Moreover, an adaptive scheme learned the muscle activity level in real time and adapted the robot impedance in accordance with patient's voluntary participation efforts. Experimental results on several healthy subjects demonstrated that the lower limb motion intention can be precisely predicted in advance, and the robot assistance mode was also adjustable based on human-robot interaction and muscle activity level of subjects. Comparing with the conventional EMG-triggered assistance methods, such a strategy can increase patient's motivation because the subject's movement intention, active efforts as well as the muscle activity level changes can be directly reflected in the trajectory pattern and the robot assistance speeds.",https://ieeexplore.ieee.org/document/6891705/,2014 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),6-11 July 2014,ieeexplore
10.1109/FPA.1994.636089,"Active perception, navigation, homing, and grasping: an autonomous perspective",IEEE,Conferences,"Perception is needed for action, not for the pure sake of the construction of abstract representations, although it does not exclude the role of internal representations for mediating complex behaviours. We think that, for the purpose of building autonomous robots, active perception requires specific recipes for three related aspects: the design of the physical sensory system, the modality and type of information extracted, and the structure and functioning of the control system. We outline a set of solutions for these three aspects and describe their implementation on a real mobile robot through a set of three different experiments using a combination of neural networks and genetic algorithms. The results show that active perception is a useful feature that is exploited by autonomous agents. The experiments shout that the combination of genetic algorithms and neural networks is a feasible and fruitful technique for the development of active perception in autonomous agents.",https://ieeexplore.ieee.org/document/636089/,Proceedings of PerAc '94. From Perception to Action,7-9 Sept. 1994,ieeexplore
10.1109/ROBOT.2009.5152428,Active-learning assisted self-reconfigurable activity recognition in a dynamic environment,IEEE,Conferences,"It is desirable to know a resident's on-going activities before a robot or a smart system can provide attentive services to meet real human needs. This work addresses the problem of learning and recognizing human daily activities in a dynamic environment. Most currently available approaches learn offline activity models and recognize activities of interest on a real time basis. However, the activity models become outdated when human behaviors or device deployment have changed. It is a tedious and error-prone job to recollect data for retraining the activity models. In such a case, it is important to adapt the learnt activity models to the changes without much human supervision. In this work, we present a self-reconfigurable approach for activity recognition which reconfigures previously learnt activity models and infers multiple activities under a dynamic environment meanwhile pursuing minimal human efforts in relabeling training data by utilizing active-learning assistance.",https://ieeexplore.ieee.org/document/5152428/,2009 IEEE International Conference on Robotics and Automation,12-17 May 2009,ieeexplore
10.1109/ICARCV.2018.8581349,Activity Recognition Based on RGB-D and Thermal Sensors for Socially Assistive Robots,IEEE,Conferences,"For socially assistive robots, being able to recognize basic human actions is an important capability. The sensors, which are frequently mounted on most recent robots, such as RGB-D and thermal cameras, as well as the advances in deep learning have enabled the research on activity recognition to grow. In this paper, we collected our own dataset of actions in a home-like scenario, which contains thermal imagery in addition to RGB-D data and we proposed a method based on Long-term Recurrent Convolutional Networks (LRCN). We showed that our method has an accuracy comparable with the state-of-the-art. We also proved that thermal information can improve the recognition accuracy. Furthermore, we tested the real-time capability of our system and conducted a real-time experiment with a robot (Pepper robot from Softbank Robotics) so as to investigate the effect of a robot enabled with action recognition capability in a human-robot interaction.",https://ieeexplore.ieee.org/document/8581349/,"2018 15th International Conference on Control, Automation, Robotics and Vision (ICARCV)",18-21 Nov. 2018,ieeexplore
10.1109/RCAR47638.2019.9043958,Actor-Critic Method-Based Search Strategy for High Precision Peg-in-Hole Tasks,IEEE,Conferences,"In the field of 3C(Computer/Communication/Consumer Electronic) product assembly, Peg-in-hole task, such as fiber assembly, is widely used. However, it remains as a big challenge for robots to automatically execute peg-in-hole tasks. Building a contact model is the traditional idea, which requires lots of time and effort. However, the model suffers low accuracy in the situation with tighter clearance. Currently, the most learning-based methods do not take into account the particularity of such assembly tasks, which lead to slow convergence. In this paper, we propose a new search strategy based on reinforcement learning for high precision peg-in-hole assembly tasks. The assembly task is divided into two steps: search and insert. Afterwards, a Markov Decision Process (MDP) is designed for the two steps according to different assembly features and solved by an Actor-Critic method. The robot can learn how to choose the optimal action and accomplish peg-in-hole task with less training and execute steps, high success rate and smaller contact force. Moreover, the proposed method can be applied to the multi-hole task without retraining. The results of simulation and experiment demonstrate its fast and stable performance.",https://ieeexplore.ieee.org/document/9043958/,2019 IEEE International Conference on Real-time Computing and Robotics (RCAR),4-9 Aug. 2019,ieeexplore
10.1109/ICRoM.2014.6990997,Actor-critic neural network reinforcement learning for walking control of a 5-link bipedal robot,IEEE,Conferences,"Today, researches on adaptive control have focused on bio-inspired learning techniques to deal with real-life applications. Reinforcement Learning (RL) is one of these major techniques, which has been widely used in robot control tasks recently. On the other hand, artificial neural networks are an accurate approximation tool in nonlinear robotic dynamic control tasks. In this paper, our main goal was to combine the advantages of the artificial neural networks and the RL to reduce the learning time length and enhance the control accuracy. Therefore, we have implemented one of the promising RL approaches, actor-critic RL to control the actuation torques of a planar five-link bipedal robot and retain the passive torso in the vertical position. Our control agent consists of two three-layered neural network units, known as the critic and the actor for learning prediction and learning control tasks. These units are synchronized by the temporal difference error, which implements the eligibility trace vector to assign credit or blame for the error. Moreover, since the neural networks are implemented in both of the actor and the critic sections, we have added a learning database to reduce the probability of inaccurate approximation of the nonlinear functions. Results of our presented control method reveal its perfect performance in stable walking control of the bipedal robot.",https://ieeexplore.ieee.org/document/6990997/,2014 Second RSI/ISM International Conference on Robotics and Mechatronics (ICRoM),15-17 Oct. 2014,ieeexplore
10.1109/M2VIP.2017.8211476,Actuation planning and modeling of a soft swallowing robot,IEEE,Conferences,"The paper presents a new methodology to solve the actuation and modelling problems of a soft-bodied swallowing robot (SR), developed for human swallow evaluation. To solve the actuation problem, a central pattern generator (CPG) based novel actuation scheme is developed and implemented to generate peristalsis in the robot. Machine learning based technique is used to determine the governing dynamics of the robot because presently the robot does not have any differential equation to describe its actuation principle or its physics. To profile and sense the peristaltic waveform, a flat version of the robot containing pneumatic chambers for actuation has been proposed to approximate the deformation of the original SR and the CPG actuation scheme is used to command the flat SR so that the pneumatic chambers can be inflated. The logic of actuation is motivated from the swallowing phenomenon in humans, have been implemented in real time. An optical motion detection system (Vicon) is used to track the displacement of the air chambers of the robot and hence, to generate time-series data for determining the governing differential equations of the robot by using l<sub>1</sub> regularised machine learning technique. It is also concluded that the proposed method provides a promising new modelling technique for determining the governing dynamics of the robot where conventional modelling approaches are not applicable.",https://ieeexplore.ieee.org/document/8211476/,2017 24th International Conference on Mechatronics and Machine Vision in Practice (M2VIP),21-23 Nov. 2017,ieeexplore
10.1109/IJCNN.2015.7280835,Adaptive Parameterized AdaBoost Algorithm with application in EEG Motor Imagery Classification,IEEE,Conferences,"Among different machine learning algorithms AdaBoost is a classification technique, which improves the classification accuracy by increasing the weights of the misclassified data. To overcome the problem of misclassification in Real AdaBoost algorithm, of the already classified samples, concept of margin is employed in the Parameterized AdaBoost algorithm. The new parameter, introduced in Parameterized AdaBoost, corresponding to the margin is chosen randomly between 0 to 1. However, the margin value is different for different classification problem. Hence, in this paper, the parameter corresponding to the margin is adapted by learning the parameter value with the help of Differential Evolutionary algorithm corresponding to the optimal classification accuracy. Experiment for the support of the proposed Adaptive Parameterized AdaBoost Algorithm has been conducted with different standard database given by UCI Machine Learning Repository. In addition, an application of Adaptive Parameterized AdaBoost is performed in EEG Motor Imagery Classification. Finally the EEG Motor Imagery Classified data (Left/Right) is tested in a robot.",https://ieeexplore.ieee.org/document/7280835/,2015 International Joint Conference on Neural Networks (IJCNN),12-17 July 2015,ieeexplore
10.1109/ICCAR52225.2021.9463494,Adaptive Self-Localization System for Low-Cost Autonomous Robot,IEEE,Conferences,"Due to the massive growth in autonomous vehicles, mobile robots applications are more prevalent today. To implement intelligent behaviors, the robot must have the ability to locate itself and adapt to different environments. Despite the recent developments in self-localization, long-term navigation with low-cost robot is still an active area of research. This paper develops a new self-localization system based on Neural Network (NN) method that is fused into a fuzzy logic navigation system using low-cost encoders. The proposed system allows the autonomous mobile robot to adapt itself to different environments and improve its localization based on the trained model. In the experiment, the system is tested with PowerBot robot in different real environments, and compared with one of the most well-known self-localization method (i.e., dead-reckoning). The test is conducted in different set-up to confirm that the proposed system significantly improved the accuracy without the need for additional sensors other than the encoders. It was able to adapt to different environment and accumulatively improved the results.",https://ieeexplore.ieee.org/document/9463494/,"2021 7th International Conference on Control, Automation and Robotics (ICCAR)",23-26 April 2021,ieeexplore
10.1109/ROMAN.2006.314387,Adaptive Social Skills for Robots Interacting with Virtual Characters in Real Worlds,IEEE,Conferences,"We propose the implementation of a new interaction type that allows the creation of adaptive social relationships between robots and virtual characters in a real world environment, using reinforcement learning. We present the implementation of a storytelling scenario, which results in an immersion experience for the robot. The robot is able to interact and learn dynamically from the virtual character",https://ieeexplore.ieee.org/document/4107778/,ROMAN 2006 - The 15th IEEE International Symposium on Robot and Human Interactive Communication,6-8 Sept. 2006,ieeexplore
10.1109/IROS.1999.813009,Adaptive behavior acquisition for a distributed autonomous swimming robot based on real-world learning,IEEE,Conferences,"Proposes the construction of a ""strong"" autonomous mobile robot, which can acquire environment oriented behavior through learning, as a distributed autonomous system. It is thought that such a system has many advantages over other systems in terms of adaptability to the environment and so on. However, the potential of this type of system has yet to be demonstrated in experiments under real-world conditions. We conducted an experiment to determine whether a distributed autonomous swimming robot could acquire target-approaching behavior on a water surface which was set as the robot's work space. As a result, from a fairly simple coding, the robot acquired the reproducible target-approaching behavior using only local learning even in cases where a partial fault occurred, and the acquired actions also enabled the robot to approach the target in an environment with a narrow gate.",https://ieeexplore.ieee.org/document/813009/,Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289),17-21 Oct. 1999,ieeexplore
10.1109/IROS.2013.6696494,Adaptive collision-limitation behavior for an assistive manipulator,IEEE,Conferences,"An approach for adaptive shared control of an assistive manipulator is presented. A set of distributed collision and proximity sensors is used to aid in limiting collisions during direct control by the disabled user. Artificial neural networks adapt the use of the proximity sensors online, which limits movements in the direction of an obstacle before a collision occurs. The system learns by associating the different proximity sensors to the collision sensors where collisions are detected. This enables the user and the robot to adapt simultaneously and in real-time, with the objective of converging on a usage of the proximity sensors that increases performance for a given user, robot implementation and task-set. The system was tested in a controlled setting with a simulated 5 DOF assistive manipulator and showed promising reductions in the mean time on simplified manipulation tasks. It extends earlier work by showing that the approach can be applied to full multi-link manipulators.",https://ieeexplore.ieee.org/document/6696494/,2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,3-7 Nov. 2013,ieeexplore
10.1109/FUZZY.2008.4630629,Adaptive learning approach of integrating evolution fuzzy-neural networks and Q-learning for mobile robots,IEEE,Conferences,"In the paper, an adaptive learning approach of integrating evolution fuzzy-neural networks and Q-learning is developed so that a mobile robot can adapt itself to a real and complex environment. Specifically, based on Q-value and an evolution method that adjusts their parameter values of the fuzzy-neural networks, the mobile robot evolves better strategies to adapt to the environment. However, in most studies of evolution learning, the learning of mobile robots often requires a simulator and an enormous amount of evolution time so as to perform a task. Therefore, we are to integrate Q-learning into the evolution fuzzy-neural networks to avoid the requirement of the simulator. Experiment results of a mobile robot illustrate the performance of the proposed approach.",https://ieeexplore.ieee.org/document/4630629/,2008 IEEE International Conference on Fuzzy Systems (IEEE World Congress on Computational Intelligence),1-6 June 2008,ieeexplore
10.1109/IROS.2010.5650226,Adaptive motion control with visual feedback for a humanoid robot,IEEE,Conferences,"The performance of a soccer robot is highly dependent on its motion ability. The kicking motion is one of the most important motions in a soccer game. However, automatic, full body motion generation for humanoid robots presents a formidable computational challenge. At the current state the most common approaches of implementing this motion are based on key frame technique. Such solutions are inflexible, i.e., in order to adjust the aimed direction of the kick the robot has to walk around the ball. The adjustment costs a lot of time especially if some precise adjustments have to be done, e.g., for a penalty kick. In this paper we present an approach for adaptive control of the motions. We implemented our approach in order to solve the task of kicking the ball on a humanoid robot Nao. The approach was tested both in simulation and on a real robot.",https://ieeexplore.ieee.org/document/5650226/,2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,18-22 Oct. 2010,ieeexplore
10.1109/ICIT.1996.601644,Adaptive robust robot control using BP-SMENs,IEEE,Conferences,"This paper presents the development of a new adaptive recurrent neural network for the control of a nonlinear system represented by a two-link SCARA type planar robot manipulator. The standard backpropagation algorithm is used to adjust the weights of the networks. The proposed control system consists of an inverse neural model of robot (INNM), an INNM-based neural controller, a robust controller, a conventional PI controller, and a second order linear filter. To evaluate the performance of the proposed control scheme and neural network, a simulated SCARA type robot was studied and the results showed how well the proposed controller can minimise the error between an actual and desired end-effector trajectory. From simulation examples, the robot trajectory tracking showed superior performance that is very attractive for real-time implementation and application in complex industrial tasks. For comparison, the standard computed torque method is employed for controlling the robot.",https://ieeexplore.ieee.org/document/601644/,Proceedings of the IEEE International Conference on Industrial Technology (ICIT'96),2-6 Dec. 1996,ieeexplore
10.1109/RAAD.2010.5524575,Adaptive sliding mode controller design for mobile robot fault tolerant control. introducing ARTEMIC.,IEEE,Conferences,"Current real-time applications should timely deliver synchronized data-sets, minimize latency in their response and meet their performance specifications in the presence of disturbances and faults. The adaptive features of the designed controller are present at the lower control level using specific artificial intelligence techniques. Fuzzy inference system design is the fundamental element to generate an adaptive nonlinear controller for the robot operation in the presence of disturbances and modeling inaccuracies. This paper introduces an adaptive real-time distributed control application with fault tolerance capabilities for differential wheeled mobile robots, named ARTEMIC. Specific design, development and implementation details will be provided in this paper.",https://ieeexplore.ieee.org/document/5524575/,19th International Workshop on Robotics in Alpe-Adria-Danube Region (RAAD 2010),24-26 June 2010,ieeexplore
10.1109/ROMAN.2002.1045593,Advanced autonomous action elements in combination control of remote operation and autonomous control,IEEE,Conferences,"This paper examines the combination control in which remote operation is combined with autonomous behaviors with the aim to realize the remote operation of mobile robot which moves in human-coexisting environment. We consider the distance and direction to an obstacle and the speed of motion of the mobile robot for revolution, following, and slowdown, which we have proposed as the autonomous action element in combination control. Fuzzy reasoning and vector components are used. From the experiment by three subject persons, almost the same result has been obtained. When the distance and direction to an obstacle and the speed of motion of the mobile robot are considered, there doesn't seem to be a great difference in following, but mileage becomes shorter in revolution and transit time is reduced in slowdown.",https://ieeexplore.ieee.org/document/1045593/,Proceedings. 11th IEEE International Workshop on Robot and Human Interactive Communication,27-27 Sept. 2002,ieeexplore
10.1109/ETFA.1999.815411,Advanced control techniques based in artificial intelligence for robotics manipulators,IEEE,Conferences,"The performance quality in nonlinear model based control of mechanical manipulators is conditioned to the reliability of the mathematical model and precision in the knowledge of all the involved parameters. Control methods based on artificial intelligence techniques (learning algorithms, system identification and neural networks) can be applied to improve its performance. A neural control scheme is proposed, consisting basically of a neural network for learning the robot inverse dynamics and online generating the control signal. Also an online supervision based on optimisation techniques is designed and implemented for such neural control. Simulation results are provided to evaluate the alternative variations to the proposed central scheme.",https://ieeexplore.ieee.org/document/815411/,1999 7th IEEE International Conference on Emerging Technologies and Factory Automation. Proceedings ETFA '99 (Cat. No.99TH8467),18-21 Oct. 1999,ieeexplore
10.1109/ICRA48506.2021.9562117,Agile Robot Navigation through Hallucinated Learning and Sober Deployment,IEEE,Conferences,"Learning from Hallucination (LfH) is a recent machine learning paradigm for autonomous navigation, which uses training data collected in completely safe environments and adds numerous imaginary obstacles to make the environment densely constrained, to learn navigation planners that produce feasible navigation even in highly constrained (more dangerous) spaces. However, LfH requires hallucinating the robot perception during deployment to match with the hallucinated training data, which creates a need for sometimes-infeasible prior knowledge and tends to generate very conservative planning. In this work, we propose a new LfH paradigm that does not require runtime hallucination—a feature we call ""sober deployment""—and can therefore adapt to more realistic navigation scenarios. This novel Hallucinated Learning and Sober Deployment (HLSD) paradigm is tested in a benchmark testbed of 300 simulated navigation environments with a wide range of difficulty levels, and in the real-world. In most cases, HLSD outperforms both the original LfH method and a classical navigation planner.",https://ieeexplore.ieee.org/document/9562117/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ISCSIC.2017.28,An Adaptive 2D Tracking Approach for Person Following Robot,IEEE,Conferences,"In this paper, we present a 2D appearance vision based tracking approach for human following robot. Generally, existing methods have high cost of computing and requirements of hardware which makes the difficulty of employing the function on service robot. Hence, minimizing the cost of tracking with slight loss of precision can benefit this area. We focus on approach based on 2D image data which reduce tracking into two dimensions and can minimize the cost of computation. Our approach presents a corporate strategy which utilizes central consensus of correspondence for 2D feature points pairwise to track and employ a semi-supervised learning detector to update appearance change. To overcome difficulties from environment change, we set an enhancing process for feature points and background segmentation through depth information. We carefully evaluate our approach with common challenges of visual tracking in static view and deploy a dynamic view a real-world following task. The experiment results illustrate that our tracking approach works against common risks at 2D appearance tracking and properly follows the user obtaining 25 fps performance on mobile platform.",https://ieeexplore.ieee.org/document/8294176/,2017 International Symposium on Computer Science and Intelligent Controls (ISCSIC),20-22 Oct. 2017,ieeexplore
10.1109/ICIRCA48905.2020.9182995,An Approach for Digital Farming using Mobile Robot,IEEE,Conferences,"Farming is the backbone of the Indian economy and it has been unchartered territory for a technological solution. As of late developments in Artificial Intelligence technology combined with Robotics has paved the way for an option of digital farming. As a matter of fact, Indian farming has been facing various challenges that include abrupt change in climatic conditions, spoiling of yields, soil nutrient requirement, pests/weed control and so forth. Robotics and Artificial Intelligence (AI) along with the integration of various sensors ensures the possibility of better outcome. In this work the simulation of Mobile robot for the purpose of seed sowing along with its movement has been presented. The implementation comprises of the Motor schema for the navigation of robot and Gale Shapley (GS) algorithm for stable match of seed and yield combination. Such a robotic system combined with AI in real time will form excellent means of farming in terms of yield.",https://ieeexplore.ieee.org/document/9182995/,2020 Second International Conference on Inventive Research in Computing Applications (ICIRCA),15-17 July 2020,ieeexplore
10.1109/COINS51742.2021.9524186,An Edge AI based Robot System for Search and Rescue Applications,IEEE,Conferences,"In this work, we propose an edge AI based robot system that contains drones and multi-legged robots for search and rescue applications. To accurately search for survivors in real-time, we integrate Tiny-YOLO into the drone design. Instead of adopting a microprocessor usually used in a robot, the FPGA device is adopted as the main hardware computing architecture of the multi-legged robot. A resource-efficient quantized neural network is implemented as a hardware module and integrated into the multi-legged robot for real-time detection. When a survivor is detected from robots, the corresponding information about GPS and the triangulation localization is thus delivered to the edge server. Then, rescuers can receive the notification message from the edge server by using their mobile devices. For survivor detection, experiments show the drone and the multi-legged robot can achieve 2.164 fps and 2.404 fps, respectively.",https://ieeexplore.ieee.org/document/9524186/,2021 IEEE International Conference on Omni-Layer Intelligent Systems (COINS),23-25 Aug. 2021,ieeexplore
10.1109/ISCAS.2019.8702113,An Energy Efficient System for Touch Modality Classification in Electronic Skin Applications,IEEE,Conferences,"Electronic-skin aiming to mimic human skin is becoming a reality and systems able to process data close to the sensors are required to reduce latency and power consumption. This paper presents the design and implementation of an energy efficient smart system for tactile sensing based on a RISC-V parallel ultra-low power platform (PULP). The PULP processor, called Mr. Wolf, performs the on-board classification of different touch modalities. This demonstrates the promising use of on-board classification for emerging robot and prosthetic applications. Experimental results demonstrate the effectiveness of the platform on improving the energy efficiency of the online classification. In our experiments, Mr. Wolf runs 3.6 times faster than an ARM Cortex M4F (STM32F40), consuming only 28 mW. The proposed platform achieves 15× better energy efficiency, than the classification done on the STM32F40, consuming only 81mJ per classification.",https://ieeexplore.ieee.org/document/8702113/,2019 IEEE International Symposium on Circuits and Systems (ISCAS),26-29 May 2019,ieeexplore
10.1109/ICTAI50040.2020.00027,An Enhanced NSGA-II for Multiobjective UAV Path Planning in Urban Environments,IEEE,Conferences,"This paper considers multiobjective UAV path planning in a real 3D environment with the objective to find a safe energy-efficient path. An Enhanced Non-dominated Sorting Genetic Algorithm-II, called ENSGA-II, is proposed and combines several sorts of heuristic information to customize crossover and mutation operators. Furthermore, a local search and a ranking-based roulette wheel selection are incorporated for the mating procedure. Experiment results confirm that ENSGA-II has a better convergence rate and spread of solutions on several new real-world datasets. The effectiveness of the local search component is also validated on the CrazyS robot operating system (ROS) package which consists of a pelican quadcopter's modeling.",https://ieeexplore.ieee.org/document/9288281/,2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI),9-11 Nov. 2020,ieeexplore
10.1109/ICTAI.2015.111,An Environment Visual Awareness Approach in Cognitive Model ABGP,IEEE,Conferences,"ABGP is a special cognitive model, which consists of awareness, beliefs, goals and plans. As most agent architectures, ABGP agents obtain knowledge from the natural scenes only through single preestablished rules as well, don't directly capture the natural scenes information like human visual. Inspired by the biological visual cortex (V1) and the higher brain areas perceiving visual features, we propose a novel deep network model convolutional generative stochastic model (CGSM) used to visual feature representation, and firstly introduce it into the awareness module of the cognitive model ABGP to construct a state-of-the-art cognitive model ABGP-CGSM. For the novel cognitive model ABGP-CGSM, we construct a rat-robot maze search simulation platform to show the validity recognizing natural scenes. According to the simulation results on the noise and noiseless natural scenes, the rat-robot implemented by ABGP-CGSM has an excellent success rate when passing through the maze. The simulation shows that the ABGP-CGSM model proposed in our work can directly enhance the capability of communication between agent and natural scenes, improve the ability to cognize the real world as human being and conduct the agent to plan independently its path in terms of the visual information from the natural scenes.",https://ieeexplore.ieee.org/document/7372207/,2015 IEEE 27th International Conference on Tools with Artificial Intelligence (ICTAI),9-11 Nov. 2015,ieeexplore
10.1109/ROBIO.2006.340133,An Extension of the Distance-Propagating Dynamic System for Robot Path Planning to Safe Obstacle Clearance,IEEE,Conferences,"In this paper we extend our previously presented efficient distance-propagating dynamic system for real-time robot path planning in dynamic environments to the case where safety margins around obstacles are included. Inclusion of safety margins approximately triples the number of arithmetic operations, however, the distance-propagating dynamic system is still very computationally efficient. The algorithm uses a grid representation of the environment, which need not be regular, and is applicable to dynamic environments where both targets and obstacles are permitted to move. No prior knowledge of target or obstacle movement is assumed. Safety margins around obstacles are implemented as ""soft"" margins defined by local penalty functions around obstacles which represent the extra distance the robot is willing to travel in order to avoid passing through this margin. The path through which the robot travels minimizes the sum of the current known distance to a target and the cumulative local penalty functions along the path. The effectiveness of the algorithm is demonstrated through a number of simulations.",https://ieeexplore.ieee.org/document/4142070/,2006 IEEE International Conference on Robotics and Biomimetics,17-20 Dec. 2006,ieeexplore
10.1109/RCAR.2018.8621725,An Image Recognition Approach for Coal and Gangue Used in Pick-Up Robot,IEEE,Conferences,"Picking gangue from raw coal is a crucial step of coal production. Due to the potential for replacing manual workers, the study of pick-up robot is attracting much interest. Pick-up robots usually work in fixed working areas where the types of coals and gangues are unitary. Based on this fact, this paper proposes a simple, fast, and easily implemented approach for coal and gangue classification which is LS-SVM (Least Square Support Vector Machine) based using gray scale and texture as features. We firstly sampled the image dataset from Han City, Shaanxi province and Jizhong, Hebei province which are two main mining areas in China. The data of Han City consists of the images of lean coal and shale, and the data of Jizhong is coking coal and sandstone. By analyzing the gray scale and the texture of the sampled data, we discover that coal and gangue vary in the parameters including the mean and peak of gray scale, contrast ratio, and entropy. Therefore, these four parameters are chosen as features. We utilize LS-SVM as the machine learning model, and the model is trained with three groups of parameters separately. The first are the mean and peak of gray scale, the second are the contrast ratio and entropy which represents texture features, and the third are the peak of gray scale and the contrast ratio which integrates gray scale and texture features. After evaluation by using our sampled dataset, the model trained by the third group outperforms others. The classification results were 98.7% correct of coal and 96.6% correct of gangue for the data of Han city, and 98.6% correct of coal and 96.6% correct of gangue for the data of Jizhong.",https://ieeexplore.ieee.org/document/8621725/,2018 IEEE International Conference on Real-time Computing and Robotics (RCAR),1-5 Aug. 2018,ieeexplore
10.1109/RCAR47638.2019.9044034,An Improved ORB-SLAM2 With Refined Depth Estimation,IEEE,Conferences,"We present a novel VSLAM system based on ORB-SLAM2. Firstly, the uncertainties of the position estimate of the 3D feature points by triangulation are computed through the propagation of covariance matrix. Then, the value of the triangulated depth and the variance of depth are updated by an information refining method from multiple triangulations. In addition, the map points with large uncertainties are excluded. And, the uncertainties of map points are used to select keyframe. As a result, more accurate estimation of the map points and the robot poses at the keyframes can be obtained. We test the proposed algorithm on the TUM open source datasets and show that the proposed algorithm is superior to the ORB-SLAM2. A real-time experiment is executed using the Pioneer 3-AT robot in the indoor environment.",https://ieeexplore.ieee.org/document/9044034/,2019 IEEE International Conference on Real-time Computing and Robotics (RCAR),4-9 Aug. 2019,ieeexplore
10.1109/WCICA.2006.1713159,An Improved Q-learning Algorithm Based on Exploration Region Expansion Strategy,IEEE,Conferences,"In order to find a good solution to one of the key problems in Q-learning algorithm - keeping the balance between exploration and exploitation, an improved Q-learning algorithm based on exploration region expansion strategy is proposed on the base of Metropolis criterion-based Q-learning. With this strategy, the exploration blindness in the entire environment is eliminated, and the learning efficiency is increased. Meanwhile, other feasible path is sought where agent encounters obstacles, which makes the implementation of the algorithm on real robot easy. An automatic termination condition is also put forward, therefore, the redundant learning after finding optimal path is avoided, and the time of learning is reduced. The validity of the algorithm is proved by simulation experiments",https://ieeexplore.ieee.org/document/1713159/,2006 6th World Congress on Intelligent Control and Automation,21-23 June 2006,ieeexplore
10.1109/KCIC.2018.8628468,An Incremental Episodic Memory Framework for Topological Map Building,IEEE,Conferences,"In this paper, an episodic memory learning framework is proposed for categorizing and encoding sensory information that acquired from a robot for environment adaptation and sensorimotor map building. The proposed learning model termed as Incremental Episodic Memory Adaptive Resonance Theory (In-EMART), consists two layers of ART networks which used to detect novel event encountered by the robot and learn the spatio-temporal relationship by creating neurons incrementally. A set of connected episodes forms a sensorimotor map that can be used for path planning and goal navigation autonomously. The experimental results for a mobile robot show that: (i) In-EMART can learn sensory data in real time which is important for robot implementation; (ii) the model solves the perceptual aliasing issue by recalling the connected episode neurons; (iii) compared with previous works, the proposed method further generates a sensorimotor map for connecting episodes together to navigate from one place to another continuously.",https://ieeexplore.ieee.org/document/8628468/,2018 International Electronics Symposium on Knowledge Creation and Intelligent Computing (IES-KCIC),29-30 Oct. 2018,ieeexplore
10.1109/ROBOT.2010.5509310,An Inertia-Based Surface Identification System,IEEE,Conferences,"In many robotics applications, knowing the material properties around a robot is often critical for the robot's successful performance. For example, in mobility, knowledge about the ground surface may determine the success of a robot's gait. In manipulation, the physical properties of an object may dictate the results of a grasping strategy. Thus, a reliable surface identification system would be invaluable for these applications. This paper presents an Inertia-Based Surface Identification System (ISIS) based on accelerometer sensor data. Using this system, a robot actively “knocks” on a surface with an accelerometer-equipped device (e.g., hand or leg), collects the accelerometer data in real-time, and then analyzes and extracts three critical physical properties, the hardness, the elasticity, and the stiffness, of the surface. A lookup table and k-nearest neighbors techniques are used to classify the surface material based on a database of previously known materials. This technique is low-cost and efficient in computation. It has been implemented on the modular and self-reconfigurable SuperBot and has achieved high accuracy (95% and 85%) in several identification experiments with real-world material.",https://ieeexplore.ieee.org/document/5509310/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/CCDC49329.2020.9164059,An Integration-Enhanced Noise-Resistant RNN Model with Superior Performance Illustrated via Time-Varying Sylvester Equation Solving,IEEE,Conferences,"The Sylvester equation plays a fundamental role in the control system, e.g, which can be applied to inverse-kinematic motion control problem in robot manipulators through a certain conversion. Considering the incompatibility of most existing Sylvester equation solving schemes on noise and the inevitability of noise in real life, by defining a new matrix-valued error function, an integration-enhanced noise-resistant recurrent neural network (IENRRNN) is generalize to the time-varying Sylvester equation solving in this paper. The convergence of the IENRRNN model under both the model implementation error and differential error of coefficient matrices are investigated. What's more, from both convergence speed and convergence quality, effects of three activation functions on the computational errors achieved by the IENRRNN are evaluated. The influences of different design parameters on them are also discussed. Finally, with MATLAB, the effectiveness of the IENRRNN model for online solving the considered equation and its superiority compared to the traditional zeroing neural network (ZNN) model are demonstrated by simulative results.",https://ieeexplore.ieee.org/document/9164059/,2020 Chinese Control And Decision Conference (CCDC),22-24 Aug. 2020,ieeexplore
10.1109/ISSE46696.2019.8984462,An IoT Reconfigurable SoC Platform for Computer Vision Applications,IEEE,Conferences,"The field of Internet of Things (IoT) and smart sensors has expanded rapidly in various fields of research and industrial applications. The area of IoT robotics has become a critical component in the evolution of Industry 4.0 standard. In this paper, we developed an IoT based reconfigurable System on Chip (SoC) robot that is fast and efficient for computer vision applications. It can be deployed in other IoT robotics applications and achieve its intended function. A Terasic Hexapod Spider Robot (TSR) was used with its DE0-Nano SoC board to implement our IoT robotics system. The TSR was designed to provide a competent computer vision application to recognize different shapes using a machine learning classifier. The data processing for image detection was divided into two parts, the first part involves hardware implementation on the SoC board and to provide real-time interaction of the robot with the surrounding environment. The second part of implementation is based on the cloud processing technique, where further data analysis was performed. The image detection algorithm for the computer vision component was tested and successfully implemented to recognize shapes. The TSR moves or reacts based on the detected image. The Field Programmable Gate Array (FPGA) part is programmed to handle the movement of the robot and the Hard Processor System (HPS) handles the shape recognition, Wi-Fi connectivity, and Bluetooth communication. This design is implemented, tested and can be used in real-time applications in harsh environments where movements of other robots are restricted.",https://ieeexplore.ieee.org/document/8984462/,2019 International Symposium on Systems Engineering (ISSE),1-3 Oct. 2019,ieeexplore
10.1109/SoutheastCon42311.2019.9020532,An IoT-based Common Platform Integrating Robots and Virtual Characters for High Performance and Cybersecurity,IEEE,Conferences,"Two humanoid robots are developed. Both robots are human-like in appearance though one is more human-like than the other. A virtual human with human-like appearance is also developed. Various similar functionalities and interaction modalities for the robots and the virtual human are developed. Various technologies are incorporated with them to make them intelligent and autonomous. A common platform in the form of an internet of things (IoT) is developed that can integrate the robots and the virtual human for their real-world collaboration. Then, the collaboration between each robot and the virtual human is separately implemented via the common platform based on some control algorithms for finding a hidden object in a homely environment. The collaboration between the robot and the virtual human is evaluated. The status of cybersecurity in the IoT is briefly analyzed. The results show that the collaboration is satisfactory in various terms, which justify their social integration in the form of an IoT. Two robots with different appearance are actually used to investigate the effects of anthropomorphism on the interaction. The results can help employ artificial intelligent agents of heterogeneous realities to perform real-world tasks through their cooperation in the form of IoT that can provide high performance and cybersecurity.",https://ieeexplore.ieee.org/document/9020532/,2019 SoutheastCon,11-14 April 2019,ieeexplore
10.1109/ROMAN.2018.8525668,An Ontology-based Home Care Service Robot for Persons with Dementia,IEEE,Conferences,"In this paper, we introduce an ontology-based home care service robot that can provide personalized care for people who are in the early stage of dementia. The hardware and software framework encompassed in the proposed service robot was developed to carry out care services in their daily life at home. Specifically, to generate adaptive task plans in diverse caring situation, context reasoner and ontological model of dementia are included. Ontology includes various concepts that are related with the knowledge of caring dementia patient: dementia, dementia symptom, environment of around patient, and situation during patient's daily life. To evaluate if the proposed service robot could provide appropriate care service or not, experimental care scenario for helping a person with dementia take medicine was tried in the lab environment. Although tasks of the robot required for the experiment are rather simple, we have demonstrated that the robot could provide a personalized service that may be beneficial to dementia patient, family members and caregivers. In the future, we will add more care knowledge in the ontology and further develop a variety of care services. Additionally, we are going to test the care service robot in a real environment with actual dementia patient.",https://ieeexplore.ieee.org/document/8525668/,2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),27-31 Aug. 2018,ieeexplore
10.1109/ROMAN.2012.6343892,An active audition framework for auditory-driven HRI: Application to interactive robot dancing,IEEE,Conferences,"In this paper we propose a general active audition framework for auditory-driven Human-Robot Interaction (HRI). The proposed framework simultaneously processes speech and music on-the-fly, integrates perceptual models for robot audition, and supports verbal and non-verbal interactive communication by means of (pro)active behaviors. To ensure a reliable interaction, on top of the framework a behavior decision mechanism based on active audition policies the robot's actions according to the reliability of the acoustic signals for auditory processing. To validate the framework's application to general auditory-driven HRI, we propose the implementation of an interactive robot dancing system. This system integrates three preprocessing robot audition modules: sound source localization, sound source separation, and ego noise suppression; two modules for auditory perception: live audio beat tracking and automatic speech recognition; and multi-modal behaviors for verbal and non-verbal interaction: music-driven dancing and speech-driven dialoguing. To fully assess the system, we set up experimental and interactive real-world scenarios with highly dynamic acoustic conditions, and defined a set of evaluation criteria. The experimental tests revealed accurate and robust beat tracking and speech recognition, and convincing dance beat-synchrony. The interactive sessions confirmed the fundamental role of the behavior decision mechanism for actively maintaining a robust and natural human-robot interaction.",https://ieeexplore.ieee.org/document/6343892/,2012 IEEE RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication,9-13 Sept. 2012,ieeexplore
10.1109/ICIEV.2012.6317522,An adaptive Neuro-Fuzzy control approach for motion control of a robot arm,IEEE,Conferences,"This paper proposes an adaptive Neuro-Fuzzy control approach for controlling the link variables of a 4 degree-of-freedom Selective Compliant Assembly Robot Arm (SCARA) type robot arm / manipulator. In the real world environment, the mathematical models of many robots are often not accurate, due to the presence of continuous disturbances that effect their dynamic equations, in addition to errors in parameter knowledge. Consequently, method that rely less on precise mathematical models are often preferred. One such Adaptive Machine Learning Technique is proposed to be applied here, for motion control of the robot arm. The controller uses an inverse learning Adaptive Neuro-Fuzzy Inference System (ANFIS) model only to train itself from certain given robot trajectories. Ideally, these trajectories should be obtained by directly measuring the robot arm responses for given inputs to capture the actual dynamics in the presence of all uncertainties. However, for algorithm validation, trajectories generated through simulations based on mathematical models assumed to be reasonably accurate, can also be used for the training purpose. This approach is used for design and implementation of an ANFIS controller which is shown to act work satisfactorily. Further possible developments of this method are also outlined.",https://ieeexplore.ieee.org/document/6317522/,"2012 International Conference on Informatics, Electronics & Vision (ICIEV)",18-19 May 2012,ieeexplore
10.1109/INMIC.2004.1492904,An adaptive clustering method for model-free reinforcement learning,IEEE,Conferences,Machine learning for real world applications is a complex task due to the huge state and action sets they deal with and the a priori unknown dynamics of the environment involved. Reinforcement learning offers very efficient model-free methods which are often combined with approximation architectures to overcome these problems. We present a Q-learning implementation that uses a new adaptive clustering method to approximate state and actions sets. Experimental results for an obstacle avoidance behavior with the mobile robot Khepera are given.,https://ieeexplore.ieee.org/document/1492904/,"8th International Multitopic Conference, 2004. Proceedings of INMIC 2004.",24-26 Dec. 2004,ieeexplore
10.1109/CCECE.1993.332425,An adaptive control scheme for robots with unknown dynamics,IEEE,Conferences,"In this paper, a stable adaptive control scheme for robot manipulators with unknown dynamics is proposed. It consists of an off-line least-mean-square (LMS) type identifier to identify structured system dynamics and an online dynamic compensator to compensating for dynamic uncertainties. Taking advantage of the unique structure of the robot regressor dynamics, the former uses an LMS type algorithm to identify, using a set of trial data, the structured dynamic parameters of the robot while the latter uses an online stable parameter updating mechanism determined using Lyapunov theory to compensate for both unknown and uncertain dynamics. The off-line identified parameters we used as initial values for the online dynamic parameter estimation. Since both identifier and compensator are implemented using the regressor dynamics, the recursive formula, for the computation of robot regressor dynamics previously proposed can be used to achieve high computational efficiency in real-time implementations. An illustrative simulation example is included to show the proposed adaptive control algorithm.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/332425/,Proceedings of Canadian Conference on Electrical and Computer Engineering,14-17 Sept. 1993,ieeexplore
10.1109/RCAR.2017.8311855,An adaptive gait learning strategy for lower limb exoskeleton robot,IEEE,Conferences,"Adaptive gait tracking of lower limb exoskeleton robot is a significant research topic, The purpose of this paper is to help the wearer to find the most suitable gait from the exit gaits as soon as possible, A new method was presented to find and extract the characteristics of individual changes from the walking behavior to achieve automatic identification, In this paper, the lower limb joint angles were used as the gait feature, the joint angles of lower limb are important gait kinematics parameter, we got the joint angles of the lower limbs and the pressure distribution of the foot through the motion information acquisition system, and then we extracted the effective features of the signals. Finally we carried out the 2km/h, 3km/h, 4km/h walking experiment on a treadmill, and then the data was put into the Multilayer-layer perceptron neural networks for training, and the recognition rate is 93.85%. Accurate gait recognition is the basis for both the determination of the motion intention and the control strategy of the lower limb exoskeleton robot.",https://ieeexplore.ieee.org/document/8311855/,2017 IEEE International Conference on Real-time Computing and Robotics (RCAR),14-18 July 2017,ieeexplore
10.1109/ETFA46521.2020.9212163,An adaptive robotic grasping with a 2-finger gripper based on deep learning network,IEEE,Conferences,"In this paper, an adaptive and versatile robotic grasping system is presented that is able to manipulate manufactured objects in production factories with a 2-finger gripper. A pick and place scenario based on deep learning framework is implemented and is achieved based on the following main steps: detection of the manufactured objects in the global scene observed by a first RGB-D camera using a first deep learning network, estimation of the object pose using 2D bounding box coordinates and depth information, motion of the arm above the object in an approach pose using Kinematics and Dynamics Library (KDL), recognition of the object's face using a second deep learning network and information coming from a second RGB-D camera setup on the arm wrist, decision on the optimal grasping mode (opening or closing the fingers), execution of the grasping action. The developed system is validated practically by experiments in real world settings using a mobile manipulator platform consisting of 6 DoF robot arm with a 2-finger gripper setup on a mobile robot equipped by two RGB-D cameras.",https://ieeexplore.ieee.org/document/9212163/,2020 25th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA),8-11 Sept. 2020,ieeexplore
10.1109/INDIN.2005.1560420,An analogue recurrent neural network for trajectory learning and other industrial applications,IEEE,Conferences,"A real-time analogue recurrent neural network (RNN) can extract and learn the unknown dynamics (and features) of a typical control system such as a robot manipulator. The task at hand is a tracking problem in the presence of disturbances. With reference to the tasks assigned to an industrial robot, one important issue is to determine the motion of the joints and the effector of the robot. In order to model robot dynamics we use a neural network that can be implemented in hardware. The synaptic weights are modelled as variable gain cells that can be implemented with a few MOS transistors. The network output signals portray the periodicity and other characteristics of the input signal in unsupervised mode. For the specific purpose of demonstrating the trajectory learning capabilities, a periodic signal with varying characteristics is used. The developed architecture, however, allows for more general learning tasks typical in applications of identification and control. The periodicity of the input signal ensures convergence of the output to a limit cycle. Online versions of the synaptic update can be formulated using simple CMOS circuits. Because the architecture depends on the network generating a stable limit cycle, and consequently a periodic solution which is robust over an interval of parameter uncertainties, we currently place the restriction of a periodic format for the input signals. The simulated network contains interconnected recurrent neurons with continuous-time dynamics. The system emulates random-direction descent of the error as a multidimensional extension to the stochastic approximation. To achieve unsupervised learning in recurrent dynamical systems we propose a synapse circuit which has a very simple structure and is suitable for implementation in VLSI.",https://ieeexplore.ieee.org/document/1560420/,"INDIN '05. 2005 3rd IEEE International Conference on Industrial Informatics, 2005.",10-12 Aug. 2005,ieeexplore
10.1109/ICPHYS.2018.8390779,An approach for implementing key performance indicators of a discrete manufacturing simulator based on the ISO 22400 standard,IEEE,Conferences,"Performance measurement tools and techniques have become very significant in today's industries for increasing the efficiency of their processes in order to face the competitive market. The first step towards performance measurement is the real-time monitoring and gathering of the data from the manufacturing system. Applying these performance measurement techniques on real-world industry in a way that is more general and efficient is the next challenge. This paper presents a methodology for implementing the key performance indicators defined in the ISO 22400 standard-Automation systems and integration, Key performance indicators (KPIs) for manufacturing operations management. The proposed methodology is implemented on a multi robot line simulator for measuring its performance at runtime. The approach implements a knowledge-based system within an ontology model which describes the environment, the system and the KPIs. In fact, the KPIs semantic descriptions are based on the data models presented in the Key Performance Indicators Markup Language (KPIML), which is an XML implementation of models developed by the Manufacturing Enterprise Solutions Association (MESA) international organization.",https://ieeexplore.ieee.org/document/8390779/,2018 IEEE Industrial Cyber-Physical Systems (ICPS),15-18 May 2018,ieeexplore
10.1109/IROS.1991.174539,An approach to on-line obstacle avoidance for robot arms,IEEE,Conferences,"Presents an approach to on-line obstacle avoidance for fixed-base robot manipulators. It guarantees a collision-free path for the robot during real-time operations. This approach is based on analytic geometry and is suitable for continuous path control. Considering the potential collision with obstacles, the next trajectory point to move to is corrected. This strategy is direct formulated in the operational space in which the tasks are described and applicable for two-dimensional as well as for three-dimensional space. Because this algorithm requires no access to joint control, it can be also used for commercial robots given the desired path. One can assign it for various robots, here the implementation for the PUMA 560 is presented as an example.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174539/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/ICMA.2016.7558929,An artificial neural network based haptic rendering of contact with deformable bodies,IEEE,Conferences,"This paper presents an artificial neural network based 3-DOF haptic rendering scheme to render the contact force between a rigid object and a deformable body in a virtual environment. The finite-element method (FEM) technique is widely used for solving the deformation problem. However, this method has a heavy computational load to get accurate result, so it is difficult to apply this method to haptic simulating. To solve the challenging problem, in this paper, we presented a new motion control scheme to divide the motion of a rigid virtual object into three sub-movements along the three axes of a Cartesian-coordinate, based on which three single-input and single-output neural networks can be separately used to compute the three feedback force components along all the coordinate axes. The vector composition of the three force components is the feedback force exerted to a user through a haptic device. The proposed method can ensure the high accuracy and the high update rate of 3-DOF haptic rendering of deformable bodies. To testify the accuracy of the artificial neural network for haptic rendering, a medical robot is used to measure the data of the neural network training in the physical world, and a haptic device based experiment with a virtual environment validates the proposed algorithm for 3-DOF haptic rendering.",https://ieeexplore.ieee.org/document/7558929/,2016 IEEE International Conference on Mechatronics and Automation,7-10 Aug. 2016,ieeexplore
10.1109/FWC.2017.8368522,An auction based smart service robot implemented on a Fog Computing node,IEEE,Conferences,"Adopting AR/VR technology on smart retail services is gaining more momentum with the progress in indoor map scanning technology and the research on AI deep learning algorithms. In this paper we propose the use of a Fog computing node to generate an AR/VR view of the real store on a web page. The customers can then use the service robot to view the merchandise in the real store via the web and make purchases. Since the service robot is a precious resource on the AR/VR business model, we develop an auction method to optimize the customer satisfaction and the owner satisfaction in terms of customer waiting time and the average number of transactions that are assisted by the service robot respectively. We demonstrate that the auction method is a critical part in the AR/VR smart business services when the number of service robots is much less than the number of active customers from the web and that it performs better than the standard preemptive method.",https://ieeexplore.ieee.org/document/8368522/,2017 IEEE Fog World Congress (FWC),30 Oct.-1 Nov. 2017,ieeexplore
10.1109/IGARSS.2012.6350750,An autonomous robotic platform for ground penetrating radar surveys,IEEE,Conferences,"Detection of hidden surface crevasses on glaciers is a vital process involved in over-snow traverses for science and resupply missions in Polar regions. There are several areas warranting improvement in the current protocol for crevasse detection, which employs a human-operated ground penetrating radar (GPR) on a mid-weight tracked vehicle. In this fashion, a GPR scout team must plan an appropriate crevasse-free route by investigating paths across the glacier. This paper presents methods supporting a completely autonomous robotic system employing GPR probing of the glacier surface. We tested and evaluated three machine learning algorithms on post-processed Antarctic GPR data, collected by our robot and a Pisten Bully in 2009 and 2010 at McMurdo Station. We achieved 82% classification rate for a linear SVM, compared to 82% using logistic regression and 80% using a Bayes network for contrast. We also discuss independent versus sequential classification of GPR scans, and suggest improvements to or combinations of the most successful training models. Our experiment demonstrates the promise and reliability of real-time object detection with GPR.",https://ieeexplore.ieee.org/document/6350750/,2012 IEEE International Geoscience and Remote Sensing Symposium,22-27 July 2012,ieeexplore
10.1109/INDIN.2017.8104950,An autopilot system based on ROS distributed architecture and deep learning,IEEE,Conferences,"An autopilot system includes several modules, and the software architecture has a variety of programs. As we all know, it is necessary that there exists one brand with a compatible sensor system till now, owing to complexity and variety of sensors before. In this paper, we apply (Robot Operating System) ROS-based distributed architecture. Deep learning methods also adopted by perception modules. Experimental results demonstrate that the system can reduce the dependence on the hardware effectively, and the sensor involved is convenient to achieve well the expected functionalities. The system adapts well to some specific driving scenes, relatively fixed and simple driving environment, such as the inner factories, bus lines, parks, highways, etc. This paper presents the case study of autopilot system based on ROS and deep learning, especially convolution neural network (CNN), from the perspective of system implementation. And we also introduce the algorithm and realization process including the core module of perception, decision, control and system management emphatically.",https://ieeexplore.ieee.org/document/8104950/,2017 IEEE 15th International Conference on Industrial Informatics (INDIN),24-26 July 2017,ieeexplore
10.1109/ICRAE.2017.8291426,An educational robot system of visual question answering for preschoolers,IEEE,Conferences,"The educational robotics is a novel technology for preschooler's companion and can be used for lower level education. This paper presents an AI-based robot system for achieving educational aims, such as metacognition tutoring and geometrical thinking training, with characteristics of contextual teaching by mining knowledge from the real world directly. For metacognition tutoring in our system, objects in real world are detected and a set of learning materials associated with the objects is presented for learners. For example, when a cat is detected, the robot will teach learners to pronounce the “Cat” in different languages, and more knowledge about cat will be pushed to the learners. For geometrical thinking training, an automatic questioning-and-answering section is employed to engage the learner to think, which is carried by a voice interaction between learners and robots. In our experiment, a set of specific object images are captured to validate the feasibility and efficiency of the proposed system. Our study indicated that the proposed system succeeded in captivating the children and parents in maximizing the children's desire to explore.",https://ieeexplore.ieee.org/document/8291426/,2017 2nd International Conference on Robotics and Automation Engineering (ICRAE),29-31 Dec. 2017,ieeexplore
10.1109/ICSMC.2009.5346800,An embedded interval type-2 neuro-fuzzy controller for mobile robot navigation,IEEE,Conferences,"This paper describes intelligent navigation using an embedded interval type-2 neuro-fuzzy controller. Weightless neural network (WNNs) strategy is used because fast learning, easy hardware implementation and well suited to microcontroller-based-real-time systems. The WNNs utilizes previous sensor data and analyzes the situation of the current environment and classifies geometric feature such as U-shape, corridor and left or right corner. The behavior of mobile robot is implemented by means of interval type-2 fuzzy control rules can be generated directly from the WNNs classifier. This functionality is demonstrated on a mobile robot using modular platform and containing several microcontrollers implies the implementation of a robust architecture. The proposed architecture implemented using low cost range sensor and low cost microprocessor. The experiment results show, using that technique the source code is efficient. The mobile robot can recognize the current environment and to be able successfully avoid obstacle in real time and achieve smother motion compare than logic function and fuzzy type-1 controller.",https://ieeexplore.ieee.org/document/5346800/,"2009 IEEE International Conference on Systems, Man and Cybernetics",11-14 Oct. 2009,ieeexplore
10.1109/ICSMC.2002.1175718,An evolutionary visual landmark recognition system,IEEE,Conferences,A vision-based landmark recognition system by using the evolutionary principle for robot navigation tasks is implemented in this study. The research is aimed at using the GA to do pattern matching. The basic idea is to use genetic algorithms to find the best matching between nodes of the two patterns. The evaluation function can be defined in terms of total differences in magnitudes of nodes between the desired pattern and the real pattern. A search method based on genetic algorithms for pattern recognition in digital images is implemented as the vision layer for a behavior based mobile robot. The vision layer can recognize artificial landmarks by searching all the pro-defined patterns using the GA. Then it generates the desired behavior corresponding to various landmarks. The results of the algorithm is promising and has a high accuracy in classifying the input patterns. The effectiveness of the developed system is demonstrated by simulation and experimental studies.,https://ieeexplore.ieee.org/document/1175718/,"IEEE International Conference on Systems, Man and Cybernetics",6-9 Oct. 2002,ieeexplore
10.1109/IROS.2007.4399219,An extended policy gradient algorithm for robot task learning,IEEE,Conferences,"In real-world robotic applications, many factors, both at low-level (e.g., vision and motion control parameters) and at high-level (e.g., the behaviors) determine the quality of the robot performance. Thus, for many tasks, robots require fine tuning of the parameters, in the implementation of behaviors and basic control actions, as well as in strategic decisional processes. In recent years, machine learning techniques have been used to find optimal parameter sets for different behaviors. However, a drawback of learning techniques is time consumption: in practical applications, methods designed for physical robots must be effective with small amounts of data. In this paper, we present a method for concurrent learning of best strategy and optimal parameters, by extending the policy gradient reinforcement learning algorithm. The results of our experimental work in a simulated environment and on a real robot show a very high convergence rate.",https://ieeexplore.ieee.org/document/4399219/,2007 IEEE/RSJ International Conference on Intelligent Robots and Systems,29 Oct.-2 Nov. 2007,ieeexplore
10.1109/CIRA.2003.1222155,An incremental learning using schema extraction mechanism for autonomous mobile robot,IEEE,Conferences,"Recently, a number of skillful robots have been developed. One of them can walk and move upstairs just like human beings. However it can so far only demonstrate preprogrammed motions according to the external commands/situations. Therefore autonomous adaptation ability has been highly anticipated. Meanwhile, humans can learn new motions such as catching/kicking a ball, in spite of his/her high dimensional sensorimotor DOF (degree of freedom). In this learning process, it can be hypothesized that the learner actively constrains the DOF by him/her-self using learning skills, in this paper referred to as schema. In this study, a learning method for autonomous mobile robots operating in unknown environments is proposed, where not only a learning mechanism for sensorimotor mappings but also an extraction/re-use mechanism of the schema (i.e. constraint rules for learning) is implemented. Through the results of simulations and real experiments of mobile robot navigation, the validity of the proposed method is clarified.",https://ieeexplore.ieee.org/document/1222155/,Proceedings 2003 IEEE International Symposium on Computational Intelligence in Robotics and Automation. Computational Intelligence in Robotics and Automation for the New Millennium (Cat. No.03EX694),16-20 July 2003,ieeexplore
10.1109/URTC.2016.8284091,An indoor positioning system facilitated by computer vision,IEEE,Conferences,"The purpose of this paper is to present our work on a novel method which allows for previously unattainable accuracy in indoor positioning. Global positioning has changed the way in which we interact with our specific locations on a real time basis, as can be seen most prominently in mapping applications. However, global positioning is severely limited indoors where location is equally important, and further, requires greater accuracy. While there have been attempts to implement indoor positioning, these methods are severely lacking, prompting us to take a completely new approach. We use low cost webcams and a series of algorithms to detect people in a video frame, and then identify and position them. Accuracy for identification is upwards of 95% and positioning accuracy is within a half-meter for the majority of the frame of view, all while running in real time on mobile CPUs. Such a system can be implemented on large scales to allow for exciting new applications; indoor directions in malls and public transportation hubs, new forms of human-robot interactions and consumer habit analysis in stores are all now possible.",https://ieeexplore.ieee.org/document/8284091/,2016 IEEE MIT Undergraduate Research Technology Conference (URTC),4-6 Nov. 2016,ieeexplore
10.1109/IJCNN.2010.5596513,An insect brain computational model inspired by Drosophila melanogaster: Simulation results,IEEE,Conferences,"Since many years insects have been considered as a source of inspiration for robotic architectures. From this point of view the fly Drosophila melanogaster is more than likely a protagonist, because of the genetic techniques that allow neurobiologists to make deep studies and hypotheses about the brain of this fly. In this work a computational model of the Drosophila has been tested and implemented on a robot simulator. Moreover, the normal capabilities of the fly have been extended in order to have an useful robot-oriented model. Results about a possible application in a real-life scenario of the whole model of the Drosophila brain are reported.",https://ieeexplore.ieee.org/document/5596513/,The 2010 International Joint Conference on Neural Networks (IJCNN),18-23 July 2010,ieeexplore
10.1109/ICPR.1992.201634,An intelligent mobile robot golfing system using binocular stereo vision,IEEE,Conferences,"This paper describes a robot vision golfing system. The ARNIE P/sup tau / (Automated Robotic Navigational unit with Intelligent Eye and Putter) project was initiated to investigate the problems and develop software solutions for robotic tasks that require good hand-eye coordination and an intelligent feedback mechanism. This system has only one frame buffer and no specialized hardware, so quasi-real-time 3D tracking is accomplished in software using the unix spline facility. Golf is a difficult perceptory task which requires the integration of many complicated computational tasks. It is therefore a good platform to experiment with artificial intelligence techniques and robotics.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/201634/,[1992] Proceedings. 11th IAPR International Conference on Pattern Recognition,30 Aug.-3 Sept. 1992,ieeexplore
10.1109/ICMA.2013.6618173,An intelligent object manipulation framework for industrial tasks,IEEE,Conferences,"This paper presents an intelligent object manipulation framework for industrial tasks, which integrates a sensor-rich multi-fingered robot hand, an industrial robot manipulator, a conveyor belt and employs machine learning algorithms. The framework software architecture is implemented using a Windows 7 operating system with RTX real-time extension for synchronous handling of peripheral devices. The framework uses Scale Invariant Feature Transform (SIFT) image processing algorithm, Support Vector Machine (SVM) machine learning algorithm and 3D point cloud techniques for intelligent object recognition based on RGB camera and laser rangefinder information from the robot hand end effector. The objective is automated manipulation of objects with different shapes and poses with minimum programming effort applied by a user.",https://ieeexplore.ieee.org/document/6618173/,2013 IEEE International Conference on Mechatronics and Automation,4-7 Aug. 2013,ieeexplore
10.1109/ROBOT.1992.220085,An optimal scheduling of pick place operations of a robot-vision-tracking system by using back-propagation and Hamming networks,IEEE,Conferences,"The authors present a neural network approach to solve the dynamic scheduling problem for pick-place operations of a robot-vision-tracking system. An optimal scheduling problem is formulated to minimize robot processing time without constraint violations. This is a real-time optimization problem which must be repeated for each group of objects. A scheme which uses neural networks to learn the mapping from object pattern space to optimal order space offline and to recall online what has been learned is presented. The idea was implemented in a real system to solve a problem in large commercial dishwashing operations. Experimental results have been shown that with four different objects, time savings of up to 21% are possible over first-come, first-served schemes currently used in industry.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/220085/,Proceedings 1992 IEEE International Conference on Robotics and Automation,12-14 May 1992,ieeexplore
10.1109/ROBOT.1991.131636,Analogue computation of collision-free paths,IEEE,Conferences,"A method for robot path planning that uses a 2D scalar electric potential subject to Neumann boundary conditions is presented. Obstacles are modeled as nonconducting solids in a conducting medium. The starting point is modeled as a current source and the goal as an equal and opposite current sink. It is shown that this formulation is considerably more powerful than the recent potential-field algorithm of C.I. Connolly et al. (1990), particularly when navigating long, narrow corridors. Feasible paths for navigation are current streamlines, as demonstrated by the results of software simulations in a 2D Euclidean plane. One of the principal advantages of the method is that it can be implemented with parallel analog hardware in the form of a resistive grid. With analog VLSI chips, it will be possible to plan paths for realistic environments in real time.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/131636/,Proceedings. 1991 IEEE International Conference on Robotics and Automation,9-11 April 1991,ieeexplore
10.1109/ISESD.2017.8253306,Analysis of artificial intelligence application using back propagation neural network and fuzzy logic controller on wall-following autonomous mobile robot,IEEE,Conferences,"This paper presents a comparison of two methods of artificial intelligence which applied in Wall following Autonomous Mobile Robot; both of them are Neural Network Back propagation and Fuzzy Logic. The robot has three input variables and two output variables. The inputs are distance between the robot and the wall which is sensed by HC-SR04 ultrasonic sensors. The output variables are the speed of the two wheels which is driving by 12 Volt DC motor. In this case mobile robot is designed to avoid the collision with any obstacles like wall or other mobile robots. In this implementation mobile robot is designed with a numbers of ultrasonic sensors and placed on certain position like center front, left front and left back. The sensor will send the data in real time. After being processed, the input produces output in form of speed value governing motor rotation mounted on both wheels of the robot to find the optimum point. In this comparison, both methods Backpropagation Neural Network and Fuzzy Logic are treated the same. Wall following Autonomous Mobile Robot is using Atmega2560 microcontroller. The logic is uploaded to the microcontroller. The result of the comparison of these two methods when applied in Wall-following Autonomous Mobile Robot is the movement of the robot using Neural Network Back propagation is faster than using Fuzzy Logic Controller.",https://ieeexplore.ieee.org/document/8253306/,2017 International Symposium on Electronics and Smart Devices (ISESD),17-19 Oct. 2017,ieeexplore
10.1109/ICSMC.2004.1398386,Ant colony optimization based swarms: implementation for the mine detection application,IEEE,Conferences,"Mine detection is a sensitive task confronting the battlefield strategists. There is an ever-increasing demand for proper and sophisticated resources for many issues involved in the task. Traditional practices still involve human force directly in executing the tasks in spite of the advances in technology for tools and implements for the operation [GAO, 2001]. The problem includes various facets inherently: two of the prominent issues are location of mines over a minefield and secondly removal of the mines once located [GAO, 2001]. These two issues are not totally independent as technology used for one can directly or indirectly affect the other. Developments in artificial intelligence, natural heuristics, computational optimization and robotics have endowed us with the ability to realize unmanned robots (or robot like vehicles) that work intelligently on a real time basis in attempting at the problem of mine detection. In this paper we focus on the algorithms developed using ant colony optimization based approaches to the mine detection application and its implementation on a real-time basis. We focus on certain optimization techniques that could be used for effective realization of the algorithm. Generic groundscout robots had been already built at the MABL, RIT [Sahin F. et al., 2003]. These robots have been used to demonstrate the implementation",https://ieeexplore.ieee.org/document/1398386/,"2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)",10-13 Oct. 2004,ieeexplore
10.1109/ICACTE.2010.5579484,Applicability of feature selection on multivariate time series data for robotic discovery,IEEE,Conferences,"Open ended robotic discovery aims at enabling robots to autonomously design and execute sophisticated experiments for gaining conceptual insight about real world. Such experiments are planned activities rather than innate motor commands and thus each single experiment results in a multivariate time series. In such a scenario, reducing the number of features in order to allow a symbolic learner to build a correct conceptual model of underlying phenomena is a fundamental task. Only few feature selection approaches deal with finding relevant features in multivariate time series, which is just what the robot receives through its sensors. In this paper, we present results of applicability of a range of feature selection and time series analysis approaches on a novel real world scenario for autonomous robotic discovery. We found that even sophisticated representations and state of the art techniques, which perform very well on other benchmarks, do not show significant results in context of open ended discovery.",https://ieeexplore.ieee.org/document/5579484/,2010 3rd International Conference on Advanced Computer Theory and Engineering(ICACTE),20-22 Aug. 2010,ieeexplore
10.1109/ISIE.2007.4374936,Application of Fuzzy Neural Network in Parameter Optimization of Mobile Robot Path Planning Using Potential Field,IEEE,Conferences,"This paper discussed a new mobile robot path planning algorithm. It analyzed the traditional path planning algorithm that employs artificial potential field and fuzzy logic, and then develop a new method combing artificial potential field, neural network and fuzzy Logic, which realized real-time obstacle recognition and smooth motion in dynamic environment. This algorithm improves the traditional artificial potential field performance, while reducing its drawbacks' influence effectively. Experiment and simulation shows this method can make the robot avoid obstacles effectively and avoid being trapped in ""dead area"".",https://ieeexplore.ieee.org/document/4374936/,2007 IEEE International Symposium on Industrial Electronics,4-7 June 2007,ieeexplore
10.1109/ICEKIM52309.2021.00040,Application of Teaching Innovation Based on robotics engineering,IEEE,Conferences,"As the core major of “Internet + Industrial Intelligence”, robotics engineering is an upgrade and reconstruction of traditional engineering major. The industrial robot course is the professional core course of the Robotics Engineering. It is also a comprehensive course of multi-discipline integration, which involved mechanical engineering, automatic control, computer, sensor, electronic technology, artificial intelligence and other multi-disciplinary content. Robotics Engineering is characterized by broad foundation, great difficulty, emphasis on practice, rapid development and application of new knowledge. In the process of implementation of the teaching innovation, the new concept of engineering education was applied to propose a new form of curriculum system. Taking the projects of engineering as the study objects, disassemble the knowledge points involved in industrial robots, break the course boundaries, reshape the knowledge system, draw knowledge maps and then design teaching activities. In teaching innovation, teachers extend classroom through formation of subject competition teams, promote teaching and promote learning by competition, realize the integration of “teaching, class and competition”, build a bridge between theory and practice, then complete the transformation from knowledge learning to ability training. Besides, they also keep contact with intelligent manufacturing enterprises in Zhuhai and the Bay Area to obtain real-time new developments in enterprises. Thus, the latest information was introduced into classroom. Therefore, the meaning of “production, teaching, research and application” has been deepened. According to the characteristics of the knowledge points of the course, experts were invited to make special lectures for students which can bring them with international perspective and frontier knowledge.",https://ieeexplore.ieee.org/document/9479656/,"2021 2nd International Conference on Education, Knowledge and Information Management (ICEKIM)",29-31 Jan. 2021,ieeexplore
10.1109/CYBER53097.2021.9588269,Application of YOLO Object Detection Network In Weld Surface Defect Detection,IEEE,Conferences,"As industrial production becomes more modern and intelligent today, the inspection of product quality of the workshop is becoming more and more accustomed to replacing the old manual visual inspection methods with automated inspection systems. In the welding field, automated welding robots are not only used in traditional large-scale automobile assembly lines. In more general welding work, welding robots also plays an important role. The inspection of the welding quality of the welding robot is mainly to detect the four main types of weld defects. Compared to traditional defect classification based on support vector machines and defect detection based on template matching, this paper uses a welding surface defect detection system designed based on deep learning methods. By working with workshop welding experts, a large-scale image of nearly 5000 pictures is built. Large-scale weld defect datasets, while using the real-time and accuracy of the YOLO series of deep learning object detection frameworks, the weld defects detection model reaches 75.5% mean average precision(mAP) in constructed weld defect data set. In addition, the construction cost of the detection model and the deployment time of the detection system are greatly reduced. During the field test of the system in the workshop, among a batch of welding workpieces provided by the factory, the detection accuracy of weld defects reached 71%, which initially met the requirements of the workshop for an automated defect detection system.",https://ieeexplore.ieee.org/document/9588269/,"2021 IEEE 11th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)",27-31 July 2021,ieeexplore
10.1109/ROBOT.2000.844768,Application of automatic action planning for several work cells to the German ETS-VII space robotics experiments,IEEE,Conferences,"Experiences in space robotics show, that the user normally has to cope with a huge amount of data. So, only robot and mission specialists are able to control the robot arm directly in teleoperation mode. By means of an intelligent robot control in cooperation with virtual reality methods, it is possible for non-robot specialists to generate tasks for a robot or an automation component intuitively. Furthermore, the intelligent robot control improves the safety of the entire system. The on-ground robot control and command station for the robot arm ERA onboard the satellite ETS-VII builds on a new resource-based action planning approach to manage robot manipulators and other automation components. In the case of ERA, the action planning system also takes care of the ""real"" robot onboard the satellite and the ""virtual"" robot in the simulation system. By means of the simulation system, the user can plan tasks ahead as well as analyze and visualize different strategies. The paper describes the mechanism of resource-based action planning, its application to different work cells, the practical experiences gained from the implementation for the on-ground robot control and command station for the robot arm ERA developed in the GETEX project as well as the services it provides to support VR-based man machine interfaces.",https://ieeexplore.ieee.org/document/844768/,Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065),24-28 April 2000,ieeexplore
10.1109/IJCNN.1990.137866,Application of neural networks on robot grippers,IEEE,Conferences,"A new-generation general-purpose robot gripper system which applies an artificial neural network to guide a three-finger gripper has been designed. The simulation of the core part of the whole system, i.e. optimally placing three fingers for a stable grasp using the Hopfield net, has been conducted. The results obtained show that this scheme behaves in a promising fashion. The actual computation time is usually within several seconds if implemented in an analog neural net, making the real application attractive",https://ieeexplore.ieee.org/document/5726824/,1990 IJCNN International Joint Conference on Neural Networks,17-21 June 1990,ieeexplore
10.1109/ICINFA.2008.4608104,Application of reinforcement learning based on neural network to dynamic obstacle avoidance,IEEE,Conferences,"This paper focuses on the application of reinforcement learning to obstacle avoidance in dynamic environments. Behavior-based control architecture is more robust and better in real-time performance than conventional model based architecture in the control of mobile robot. An intelligent controller is proposed by integrating reinforcement learning with the behavior-based control architecture and applied to the obstacle avoidance. Neural network is used to approximate the Q-function to store the Q-value. By using the reinforcement learning, the mobile robot can learn to select proper behavior online without knowing the exact model of the system. In experiments, dynamic and static obstacles are placed in the environments separately. Experiment results show that the mobile robot can get to the target point without colliding with any obstacle after a period of learning.",https://ieeexplore.ieee.org/document/4608104/,2008 International Conference on Information and Automation,20-23 June 2008,ieeexplore
10.1109/CDC.1999.833361,Application of reinforcement learning control to a nonlinear dexterous robot,IEEE,Conferences,"In this paper, the effects of basic parameters in reinforcement learning control such as eligibility, action and critic network weights, system nonlinearities, gradient information, state-space partitioning, variance of exploration were studied in detail. We attempt to increase feasibility for practical applications, implementation, learning efficiency, and performance. Reinforcement learning is then applied for control of a nonlinear dexterous robot. This control problem dictates that the learning is performed online, based on binary and real valued reinforcement signal from a critic network, without knowing the system model nonlinearity. The learning algorithm consists of an action and critic networks that learn to keep the multifinger hand of the dexterous robot within desired limits.",https://ieeexplore.ieee.org/document/833361/,Proceedings of the 38th IEEE Conference on Decision and Control (Cat. No.99CH36304),7-10 Dec. 1999,ieeexplore
10.1109/IJCNN.2004.1380179,Applying KIV dynamic neural network model for real time navigation by mobile robot EMMA,IEEE,Conferences,"We use a biologically inspired dynamic neural network model to accomplish goal-oriented navigation by a mobile robot in a real environment with obstacles. This model is the KIV model of the brain. Real time navigation is a challenging task, especially when there is no a priori information about the environment. Our robot EMMA is designed to be autonomous using various sensory inputs, which are integrated to achieve an efficient navigation task. This paper focuses on the design, implementation, and evaluation of the performance of EMMA and gives a proof-of-principle in a real environment.",https://ieeexplore.ieee.org/document/1380179/,2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541),25-29 July 2004,ieeexplore
10.1109/SNPD.2007.118,Applying Multiple Classifier Systems to SoftMan's Perception System,IEEE,Conferences,"SoftMan, the virtual robot in network environment, is a kind of software Artificial Life living in computer networks. It has a humanoid structure, and simulating human, its perception system should be able to recognize perceptive objects. Enlightened by human's perception system and the ""disassemble-integration"" method in analyzing large systems, a cooperative classification model in SoftMan's perception system is proposed. In the model, different humanoid senses are simulated by multiple classifier systems (MCS). Consequently, SoftMan can perform multi-sense cooperative classification on its perceptive objects. A simulated experiment validates the basic feasibility of the model.",https://ieeexplore.ieee.org/document/4287524/,"Eighth ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing (SNPD 2007)",30 July-1 Aug. 2007,ieeexplore
10.1109/ICNN.1996.549172,Applying self-organizing networks to recognizing rooms with behavior sequences of a mobile robot,IEEE,Conferences,"We describe the application of a self-organizing network to the robot which learns to recognize rooms (enclosures) using behavior sequences. In robotics research, most studies on recognizing environments have tried to build the precise geometric map with highly sensitive sensors. However many natural agents like animals recognize the environments with low sensitivity sensors, and a geometric map may not be necessary. Thus we attempt to build a mobile robot using a self-organizing network to recognize the enclosures, in which it acts, with low sensitivity and local sensors. The mobile robot is behavior-based and does wall-following in an enclosure. Then the sequences of behaviors executed in each enclosure are obtained. The sequences are transformed into real-value vectors, and inputted to the Kohonen self-organizing network. Unsupervised learning is done and a mobile robot becomes able to distinguish and identify enclosures. We fully implemented the system using a real mobile robot and made experiments for evaluating the ability. Consequently we found out the recognition of enclosures was done well and our method was robust against small obstacles in an enclosure.",https://ieeexplore.ieee.org/document/549172/,Proceedings of International Conference on Neural Networks (ICNN'96),3-6 June 1996,ieeexplore
10.1109/HUMANOIDS.2012.6651500,Applying statistical generalization to determine search direction for reinforcement learning of movement primitives,IEEE,Conferences,"In this paper we present a new methodology for robot learning that combines ideas from statistical generalization and reinforcement learning. First we apply statistical generalization to compute an approximation for the optimal control policy as defined by training movements that solve the given task in a number of specific situations. This way we obtain a manifold of movements, which dimensionality is usually much smaller than the dimensionality of a full space of movement primitives. Next we refine the policy by means of reinforcement learning on the approximating manifold, which results in a learning problem constrained to the low dimensional manifold. We show that in some situations, learning on the low dimensional manifold can be implemented as an error learning algorithm. We apply golden section search to refine the control policy. Furthermore, we propose a reinforcement learning algorithm with an extended parameter set, which combines learning in constrained domain with learning in full space of parametric movement primitives, which makes it possible to explore actions outside of the initial approximating manifold. The proposed approach was tested for learning of pouring action both in simulation and on a real robot.",https://ieeexplore.ieee.org/document/6651500/,2012 12th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2012),29 Nov.-1 Dec. 2012,ieeexplore
10.1109/IJCNN.2015.7280807,Applying the canonical distributed Embodied Evolution algorithm in a collective indoor navigation task,IEEE,Conferences,"The automatic design of control systems for multi-robot teams that operate in real time is not affordable with traditional evolutionary algorithms mainly due to the huge computational requirements they imply. Embodied Evolution (EE) is an evolutionary paradigm that aims to address this problem through the embodiment of the individuals that make up the population in the physical robots. The interest for this type of evolutionary approach has been increasing steadily, leading to different algorithms and variations adapted to solve very specific practical cases. In a previous work, the authors started the implementation of a standard canonical EE algorithm that captures the more general principles of this paradigm and that can be applied to any distributed optimization problem. This canonical algorithm has been characterized already over a set of theoretical fitness landscapes corresponding to representative examples of the basic casuistry found in collective tasks. The current paper goes one step ahead in this research line, and the canonical algorithm is applied here in a collective navigation task in which a fleet of Micro Aerial Vehicles (MAVs) has to gather red rocks in an indoor scenario. The objective is to confirm that the characterization conclusions are generalizable to a practical case and to show that the canonical algorithm can be configured to operate as a specific algorithm easily.",https://ieeexplore.ieee.org/document/7280807/,2015 International Joint Conference on Neural Networks (IJCNN),12-17 July 2015,ieeexplore
10.1109/ICONIP.1999.845675,Artificial neural networks for autonomous robot control: reflective navigation and adaptive sensor calibration,IEEE,Conferences,"The authors present the application of artificial neural networks to the control of a mobile autonomous robot, which is acting in a totally unknown and-most importantly-dynamically changing environment. In particular, the employment of interacting 'simple', i.e. hand-designed, neural networks for navigation purposes is investigated as well as a variation of self-organizing maps for adaptive sensor calibration. We take a pragmatic point of view as the minimal condition imposed on the developed algorithms: that they do well on a real system acting in a real environment. Hence, the design of all of the implemented neural networks is clearly motivated by their applicability. In this context, special considerations are dedicated to ensure robustness, real-time capability and memory resourcefulness. In order to practically demonstrate the obtained results, the mini-robot Khepera is utilized as an experimentational platform, which is (due to its small size), a versatile tool for scientific investigation.",https://ieeexplore.ieee.org/document/845675/,ICONIP'99. ANZIIS'99 & ANNES'99 & ACNN'99. 6th International Conference on Neural Information Processing. Proceedings (Cat. No.99EX378),16-20 Nov. 1999,ieeexplore
10.1109/ICMLC.2004.1378596,Artificial neural networks for mobile robot acquiring heading angle,IEEE,Conferences,The RBF network is designed for the mobile robot to acquire the accurate and real-time heading angle that is significant for the successful localization. Several designs related to the network architecture and training has been made to construct the RBF network using the OLS algorithm. The results of the experiment show that the designed neural network can greatly improve the accuracy of the localization. The proposed localization system with combined sensors based on the RBF neural network is reliable to ensure the intelligent behaviors of the robot. The technical presentations in this paper can facilitate the application of artificial neural networks in the environmental robotics.,https://ieeexplore.ieee.org/document/1378596/,Proceedings of 2004 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.04EX826),26-29 Aug. 2004,ieeexplore
10.1109/SIBCON50419.2021.9438884,Assessment of Map Construction in vSLAM,IEEE,Conferences,"Vision-based Simultaneous Localization and Mapping (vSLAM) is a challenging task in modern computer vision. vSLAM is particularly important as mobile robotics application. It allows to localize the robot and build the map of unknown environment in 3D in real-time. During research and development of new methods, it needs extensive evaluation on trajectory and map quality compared to known methods. In this work we focus on map quality estimation. We develop the simulated ground-truth data in photo-realistic environment and introduce new metrics in order to estimate map quality. We evaluate neural network based vSLAM methods with our framework in order to show that it fits map quality estimation more than standard approaches. Open-source implementation of our map metrics is available at https://github.com/CnnDepth/slam_comparison.",https://ieeexplore.ieee.org/document/9438884/,2021 International Siberian Conference on Control and Communications (SIBCON),13-15 May 2021,ieeexplore
10.1109/IJCNN.2011.6033367,Attention driven computational model of the auditory midbrain for sound localization in reverberant environments,IEEE,Conferences,"In this paper, an auditory attention driven computational model of the auditory midbrain is proposed based on a spiking neural network [17] in order to localize attended sound sources in reverberant environments. Both bottom-up attention driven by sensors and top-down attention driven by the cortex are modeled at the level of an auditory midbrain nucleus - the inferior colliculus (IC). Improvements of the model in [17] is made to increase biological plausibility. First, inter-neuron inhibitions are modeled among the IC neurons which have the same characteristic frequency but different spatial response. This is designed to mimic the precedence effect [15] to produce localization results in reverberate environments. Secondly, descending projections from the auditory cortex (AC) to the IC are model to simulate the top-down attention so that focused sound sources can be better sensed in noise or multiple sound source situations. Our model is implemented on a mobile robot with a manikin head equipped with binaural microphones and tested in a real environment. The results shows that our attention driven model can give more accurate localization results than prior models.",https://ieeexplore.ieee.org/document/6033367/,The 2011 International Joint Conference on Neural Networks,31 July-5 Aug. 2011,ieeexplore
10.1109/RIOS.2015.7270741,Attitude control and trajectory tracking of an autonomous miniature aerial vehicle,IEEE,Conferences,"This paper introduces a Miniature Aerial Vehicle (MAV) which is Autonomous in outdoor environment. Main contributions of this research are both new trajectory tracking and attitude control scheme in real flight mode. This MAV is based on a traditional quadrotor. For stabilization of the quadrotor's attitude a PID controller is utilized. The proposed controller is designed such that to be able to attenuate effect of external wind disturbance and guarantee stability in this condition. For autonomous trajectory tracking, it is necessary to have a fixed altitude. Also an ARM cortex M4 microcontroller performs processing activities. Then, a trajectory is determined by a GPS in Mission Planner software for the outdoor environment. For real time communication between robot and ground station, HMTR module is used. Flight data is saved in Memory SD card and converts to MATLAB code for real time implementation. Experimental results of the proposed controller on the Autonomous Quadrotor in real conditions show the effectiveness of our approach.",https://ieeexplore.ieee.org/document/7270741/,2015 AI & Robotics (IRANOPEN),12-12 April 2015,ieeexplore
10.1109/ICRA.2018.8462967,Auctioning over Probabilistic Options for Temporal Logic-Based Multi-Robot Cooperation Under Uncertainty,IEEE,Conferences,"Coordinating a team of robots to fulfill a common task is still a demanding problem. This is even more the case when considering uncertainty in the environment, as well as temporal dependencies within the task specification. A multi-robot cooperation from a single goal specification requires mechanisms for decomposing the goal as well as an efficient planning for the team. However, planning action sequences offline is insufficient in real world applications. Rather, due to uncertainties, the robots also need to closely coordinate during execution and adjust their policies when additional observations are made. The framework presented in this paper enables the robot team to cooperatively fulfill tasks given as temporal logic specifications while explicitly considering uncertainty and incorporating observations during execution. We present the effectiveness of our ROS implementation of this approach in a case study scenario.",https://ieeexplore.ieee.org/document/8462967/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/SIU.2015.7130068,Audio-visual human tracking for active robot perception,IEEE,Conferences,"In this paper, a multimodal system is designed in the form of an active audio-vision in order to improve the perceptual capability of a robot in a noisy environment. The system running in real-time consists of 1) audition modality, 2) a complementary vision modality and 3) motion modality incorporating intelligent behaviors based on the data obtained from both modalities. The tasks of audition and vision are to detect, localize and track a speaker independently. The aim of motion modality is to enable a robot to have intelligent and human-like behaviors by using localization results from the sensor fusion. The system is implemented on a mobile robot platform in a real-time environment and the speaker tracking performance of the fusion is confirmed to be improved compared to each of sensory modalities.",https://ieeexplore.ieee.org/document/7130068/,2015 23nd Signal Processing and Communications Applications Conference (SIU),16-19 May 2015,ieeexplore
10.1109/ROBOT.2005.1570581,Auto-supervised learning in the Bayesian Programming Framework,IEEE,Conferences,"Domestic and real world robotics requires continuous learning of new skills and behaviors to interact with humans. Auto-supervised learning, a compromise between supervised and completely unsupervised learning, consist in relying on previous knowledge to acquire new skills. We propose here to realize auto-supervised learning by exploiting statistical regularities in the sensorimotor space of a robot. In our context, it corresponds to achieve feature selection in a Bayesian programming framework. We compare several feature selection algorithms and validate them on a real robotic experiment.",https://ieeexplore.ieee.org/document/1570581/,Proceedings of the 2005 IEEE International Conference on Robotics and Automation,18-22 April 2005,ieeexplore
10.23919/MIPRO52101.2021.9597142,Automated Robot Control for a Game of Chess in Unity Game Engine through Artificial Intelligence,IEEE,Conferences,"The topic of this paper is to study the possibility of using Unity game development engine for robot control. The aim of the work is to create a virtual environment in which the game of chess is simulated, through a duel of two robots controlled by artificial intelligence. As part of the work, real robot models were implemented in the Unity game engine. The simulated robots were ABB's IRB-120 arms with two joints. The movement of the robot is fully simulated within the physics simulation in the Unity system. The Forward and Backward Reaching Inverse Kinematics (FABRIK) algorithm was used for the inverse kinematics algorithm. For calculating the next move, external artificial intelligence library Stockfish was used and integrated with the Unity game engine. The final application has automated moves between the robots, has the option of a simple change of the viewpoint through camera movement, and is intended to be used in future work for the control of a real robot.",https://ieeexplore.ieee.org/document/9597142/,"2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO)",27 Sept.-1 Oct. 2021,ieeexplore
10.1109/ICICIC.2009.121,Automatic Path Search for Roving Robot Using Reinforcement Learning,IEEE,Conferences,"Rapid advances in robot technology have been made in recent years. In connection with these advances, robots are expected to be utilized in a variety of places and environments. This study describes, (1) a method which allows a robot to measure the location of its destination in the real world based on an image obtained from a single camera, and (2) a method of navigating a robot to a destination which is selected by a user on a display showing the forward robot view. Consideration is also given to cases in which there are obstacles between the robot and the destination. Through the use of reinforcement learning, which is considered a promising candidate among autonomous control techniques, the roving robot tries to find the shortest way to the destination based on information concerning the locations of obstacles and the destination. This study also describes an image-based method of measuring a selected location, the results from a simulation of path finding using reinforcement learning, and the results from an experiment of navigation in a real environment. Finally, a summary of the main conclusions is provided.",https://ieeexplore.ieee.org/document/5412489/,"2009 Fourth International Conference on Innovative Computing, Information and Control (ICICIC)",7-9 Dec. 2009,ieeexplore
10.1109/AHS.2007.37,Automatic Synthesis of Fault Detection Modules for Mobile Robots,IEEE,Conferences,"In this paper, we present a new approach for automatic synthesis of fault detection modules for autonomous mobile robots. The method relies on the fact that hardware faults typically change the flow of sensory perceptions received by the robot and the subsequent behavior of the control program. We collect data from three experiments with real robots. In each experiment, we record all sensory inputs from the robots while they are operating normally and after software-simulated faults have been injected. We use back- propagation neural networks to synthesize task-dependent fault detection modules. The performance of the modules is evaluated in terms of false positives and latency.",https://ieeexplore.ieee.org/document/4291986/,Second NASA/ESA Conference on Adaptive Hardware and Systems (AHS 2007),5-8 Aug. 2007,ieeexplore
10.1109/IJCNN.2003.1223997,Automatic language acquisition by an autonomous robot,IEEE,Conferences,"There is no such thing as a disembodied mind. We posit that cognitive development can only occur through interaction with the physical world. To this end, we are developing a robotic platform for the purpose of studying cognition. We suggest that the central component of cognition is a memory which is primarily associative, one where learning occurs as the correlation of events from diverse inputs. We also posit that human-like cognition requires a well-integrated sensory-motor system, to provide these diverse inputs. As implemented in our robot, this system includes binaural hearing, stereo vision, tactile sense, and basic proprioceptive control. On top of these abilities, we are implementing and studying various models of processing, learning and decision making. Our goal is to produce a robot that will learn to carry out simple tasks in response to natural language requests. The robot's understanding of language will be learned concurrently with its other cognitive abilities. We have already developed a robust system and conducted a number or experiments on the way to this goal, some details of which appear in this paper. This is a first progress report of what we believe will be a long term project with significant implications.",https://ieeexplore.ieee.org/document/1223997/,"Proceedings of the International Joint Conference on Neural Networks, 2003.",20-24 July 2003,ieeexplore
10.1109/ICIT.2018.8352157,Automatic parameter learning for easy instruction of industrial collaborative robots,IEEE,Conferences,"The manufacturing industry faces challenges in meeting requirements of flexibility, product variability and small batch sizes. Automation of high mix, low volume productions requires faster (re)configuration of manufacturing equipment. These demands are to some extend accommodated by collaborative robots. Certain actions can still be hard or impossible to manually adjust due to inherent process uncertainties. This paper proposes a generic iteratively learning approach based on Bayesian Optimisation to efficiently search for the optimal set of process parameters. The approach takes into account the process uncertainties by iteratively making a statistical founded choice on the next parameter-set to examine only based on the prior binomial outcomes. Moreover, our function estimator uses Wilson Score to make proper estimates on the success probability and the associated uncertain measure of sparsely sampled regions. The function estimator also generalises the experiment outcomes to the neighbour region through kernel smoothing by integrating Kernel Density Estimation. Our approach is applied to a real industrial task with significant process uncertainties, where sufficiently robust process parameters cannot intuitively be chosen. Using our approach, a collaborative robot automatically finds a reliable solution.",https://ieeexplore.ieee.org/document/8352157/,2018 IEEE International Conference on Industrial Technology (ICIT),20-22 Feb. 2018,ieeexplore
10.1109/ICAC.2004.1301379,Autonomic systems for mobile robots,IEEE,Conferences,"Mobile robots are an excellent testbed for autonomic computing research. The ultimate goal of robotics research is to develop a platform that can function autonomously in the face of hardware and software failures. This goal is becoming more important as robots are increasingly being deployed outside of controlled environments. In this paper, we discuss our work toward implementing an autonomic system for a mobile robot. This work is motivated by our experiences with existing mobile robot control software during real-world deployments.",https://ieeexplore.ieee.org/document/1301379/,"International Conference on Autonomic Computing, 2004. Proceedings.",17-18 May 2004,ieeexplore
10.1109/IROS45743.2020.9341657,Autonomous Exploration Under Uncertainty via Deep Reinforcement Learning on Graphs,IEEE,Conferences,"We consider an autonomous exploration problem in which a range-sensing mobile robot is tasked with accurately mapping the landmarks in an a priori unknown environment efficiently in real-time; it must choose sensing actions that both curb localization uncertainty and achieve information gain. For this problem, belief space planning methods that forward- simulate robot sensing and estimation may often fail in real-time implementation, scaling poorly with increasing size of the state, belief and action spaces. We propose a novel approach that uses graph neural networks (GNNs) in conjunction with deep reinforcement learning (DRL), enabling decision-making over graphs containing exploration information to predict a robot's optimal sensing action in belief space. The policy, which is trained in different random environments without human intervention, offers a real-time, scalable decision-making process whose high-performance exploratory sensing actions yield accurate maps and high rates of information gain.",https://ieeexplore.ieee.org/document/9341657/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ECMR.2019.8870908,Autonomous Robots as Actors in Robotics Theatre - Tribute to the Centenary of R.U.R.,IEEE,Conferences,"In the eyes of the roboticists, the play R.U.R. (Rossum's Universal Robots) of Czech writer Karel Čapek is seen as the messenger of the new robot age. R.U.R. is renown for the first mentioning of the word robot for a humanoid machine that looks, moves, feels, thinks and works like a human. Inspired by the 100th anniversary of R.U.R. in 2020, we have decided to make a performance with Pepper and NAO humanoid robots acting together with human actors. Performing in a theatrical performance is very demanding even for human actors, so we see the implementation of R.U.R. with robotic co-actors as a real challenge. For this purpose, we have analyzed human-robot and robot-robot interaction in the R.U.R. script to evaluate whether NAO and Pepper robots that we have are apt to act autonomously. Due to specific robot deficiencies that we found, we have made the robot casting first and then adapted the R.U.R. script to enable Pepper and NAO robots to perform their roles.",https://ieeexplore.ieee.org/document/8870908/,2019 European Conference on Mobile Robots (ECMR),4-6 Sept. 2019,ieeexplore
10.1109/AERO47225.2020.9172808,Autonomous UAV Navigation for Active Perception of Targets in Uncertain and Cluttered Environments,IEEE,Conferences,"The use of Small Unmanned Aerial Vehicles (sUAVs) has grown exponentially owing to an increasing number of autonomous capabilities. Automated functions include the return to home at critical energy levels, collision avoidance, take-off and landing, and target tracking. However, sUAVs applications in real-world and time-critical scenarios, such as Search and Rescue (SAR) is still limited. In SAR applications, the overarching aim of autonomous sUAV navigation is the quick localisation, identification and quantification of victims to prioritise emergency response in affected zones. Traditionally, sUAV pilots are exposed to prolonged use of visual systems to interact with the environment, which causes fatigue and sensory overloads. Nevertheless, the search for victims onboard a sUAV is challenging because of noise in the data, low image resolution, illumination conditions, and partial (or full) occlusion between the victims and surrounding structures. This paper presents an autonomous Sequential Decision Process (SDP) for sUAV navigation that incorporates target detection uncertainty from vision-based cameras. The SDP is modelled as a Partially Observable Markov Decision Process (POMDP) and solved online using the Adaptive Belief Tree (ABT) algorithm. In particular, a detailed model of target detection uncertainty from deep learning-based models is shown. The presented formulation is tested under Software in the Loop (SITL) through Gazebo, Robot Operating System (ROS), and PX4 firmware. A Hardware in the Loop (HITL) implementation is also presented using an Intel Myriad Vision Processing Unit (VPU) device and ROS. Tests are conducted in a simulated SAR GPS-denied scenario, aimed to find a person at different levels of location and pose uncertainty.",https://ieeexplore.ieee.org/document/9172808/,2020 IEEE Aerospace Conference,7-14 March 2020,ieeexplore
10.1109/SIMPAR.2016.7862403,Autonomous exploration by expected information gain from probabilistic occupancy grid mapping,IEEE,Conferences,"Occupancy grid maps are spatial representations of environments, where the space of interest is decomposed into a number of cells that are considered either occupied or free. This paper focuses on exploring occupancy grid maps by predicting the uncertainty of the map. Based on recent improvements in computing occupancy probability, this paper presents a novel approach for selecting robot poses designed to maximize expected map information gain represented by the change in entropy. This result is simplified with several approximations to develop an algorithm suitable for real-time implementation. The predicted information gain proposed in this paper governs an effective autonomous exploration strategy when applied in conjunction with an existing motion planner to avoid obstacles, which is illustrated by numerical examples.",https://ieeexplore.ieee.org/document/7862403/,"2016 IEEE International Conference on Simulation, Modeling, and Programming for Autonomous Robots (SIMPAR)",13-16 Dec. 2016,ieeexplore
10.1109/ICRA.2011.5980435,Autonomous learning of vision-based layered object models on mobile robots,IEEE,Conferences,"Although mobile robots are increasingly being used in real-world applications, the ability to robustly sense and interact with the environment is still missing. A key requirement for the widespread deployment of mobile robots is the ability to operate autonomously by learning desired environmental models and revising the learned models in response to environmental changes. This paper presents an approach that enables a mobile robot to autonomously learn layered models for environmental objects using temporal, local and global visual cues. A temporal assessment of image gradient features is used to detect candidate objects, which are then modeled using color distribution statistics and a spatial representation of gradient features. The robot incrementally revises the learned models and uses them for object recognition and tracking based on a matching scheme comprising a spatial similarity measure and second order distribution statistics. All algorithms are implemented and tested on a wheeled robot platform in dynamic indoor environments.",https://ieeexplore.ieee.org/document/5980435/,2011 IEEE International Conference on Robotics and Automation,9-13 May 2011,ieeexplore
10.1109/SYSOSE.2008.4724191,Autonomous navigation based on a Q-learning algorithm for a robot in a real environment,IEEE,Conferences,"This paper explores autonomous navigation and obstacle avoidance techniques based on Q-learning for a mobile robot in a real environment. The implemented algorithm focuses on simplicity and efficiency. The learning process takes place in both simulation and real world allowing the combination of a longer learning time in the simulator with a more accurate knowledge from the real world. After learning is completed in simulation and in the real world, the robot was able to navigate without hitting obstacles and able to generate control law for complex situations such as corners and small objects.",https://ieeexplore.ieee.org/document/4724191/,2008 IEEE International Conference on System of Systems Engineering,2-4 June 2008,ieeexplore
10.1109/IJCNN.2013.6706877,Autonomous reinforcement of behavioral sequences in neural dynamics,IEEE,Conferences,"We introduce a dynamic neural algorithm called Dynamic Neural (DN) SARSA(λ) for learning a behavioral sequence from delayed reward. DN-SARSA(λ) combines Dynamic Field Theory models of behavioral sequence representation, classical reinforcement learning, and a computational neuroscience model of working memory, called Item and Order working memory, which serves as an eligibility trace. DN-SARSA(λ) is implemented on both a simulated and real robot that must learn a specific rewarding sequence of elementary behaviors from exploration. Results show DN-SARSA(λ) performs on the level of the discrete SARSA(λ), validating the feasibility of general reinforcement learning without compromising neural dynamics.",https://ieeexplore.ieee.org/document/6706877/,The 2013 International Joint Conference on Neural Networks (IJCNN),4-9 Aug. 2013,ieeexplore
10.1109/ISIC.2002.1157759,Autonomous robot navigation based on fuzzy sensor fusion and reinforcement learning,IEEE,Conferences,"This paper presents the design and implementation of an autonomous robot navigation system for intelligent target collection in dynamic environments. A feature-based multi-stage fuzzy logic (MSFL) sensor fusion system is developed for target recognition, which is capable of mapping noisy sensor inputs into reliable decisions. The robot exploration and path planning are based on a grid map oriented reinforcement path learning system (GMRPL), which allows for long-term predictions and path adaptation via dynamic interactions with physical environments. In our implementation, the MSFL and GMRPL are integrated into a subsumption architecture for intelligent target-collecting applications. The subsumption architecture is a layered reactive agent structure that enables the robot to implement higher-layer functions including path learning and target recognition regardless of lower-layer functions such as obstacle detection and avoidance. Real-world application using a Khepera robot shows the robustness and flexibility of the developed system in dealing with robotic behavior such as target collecting in an ever-changing physical environment.",https://ieeexplore.ieee.org/document/1157759/,Proceedings of the IEEE Internatinal Symposium on Intelligent Control,30-30 Oct. 2002,ieeexplore
10.1109/CEC.2002.1004426,Autonomous robot navigation via intrinsic evolution,IEEE,Conferences,"This paper presents the design and implementation of an evolvable hardware based autonomous robot navigation system using intrinsic evolution. Distinguished from the traditional evolutionary approaches based on software simulation, an evolvable robot controller at the hardware gate-level that is capable of adapting dynamic changes in the environments is implemented. In our approach, the concept of Boolean function is used to construct the evolvable controller implemented on an FPGA-based robot turret, and evolutionary computing is applied as a learning tool to guide the artificial evolution at the hardware level. The effectiveness of the proposed evolvable autonomous robotic system is confirmed with the physical real-time implementation of robot navigation behaviors on light source following and obstacle avoidance using a robot with traction fault.",https://ieeexplore.ieee.org/document/1004426/,Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600),12-17 May 2002,ieeexplore
10.1109/IST.2012.6295593,Autonomous robotic ground penetrating radar surveys of ice sheets; Using machine learning to identify hidden crevasses,IEEE,Conferences,"This paper presents methods to continue development of a completely autonomous robotic system employing ground penetrating radar imaging of the glacier sub-surface. We use well established machine learning algorithms and appropriate un-biased processing, particularly those which are also suitable for real-time image analysis and detection. We tested and evaluated three processing schemes in conjunction with a Support Vector Machine (SVM) trained on 15 examples of Antarctic GPR imagery, collected by our robot and a Pisten Bully tractor in 2010 in the shear zone near McMurdo Station. Using a modified cross validation technique, we correctly classified all examples with a radial basis kernel SVM trained and evaluated on down-sampled and texture-mapped GPR images of crevasses, compared to 60% classification rate using raw data. We also test the most successful processing scheme on a larger dataset, comprised of 94 GPR images of crevasse crossings recorded in the same deployment. Our experiments demonstrate the promise and reliability of real-time object detection and classification with robotic GPR imaging surveys.",https://ieeexplore.ieee.org/document/6295593/,2012 IEEE International Conference on Imaging Systems and Techniques Proceedings,16-17 July 2012,ieeexplore
10.1109/ICRA.2013.6631235,Autonomous robotic valve turning: A hierarchical learning approach,IEEE,Conferences,"Autonomous valve turning is an extremely challenging task for an Autonomous Underwater Vehicle (AUV). To resolve this challenge, this paper proposes a set of different computational techniques integrated in a three-layer hierarchical scheme. Each layer realizes specific subtasks to improve the persistent autonomy of the system. In the first layer, the robot acquires the motor skills of approaching and grasping the valve by kinesthetic teaching. A Reactive Fuzzy Decision Maker (RFDM) is devised in the second layer which reacts to the relative movement between the valve and the AUV, and alters the robot's movement accordingly. Apprenticeship learning method, implemented in the third layer, performs tuning of the RFDM based on expert knowledge. Although the long-term goal is to perform the valve turning task on a real AUV, as a first step the proposed approach is tested in a laboratory environment.",https://ieeexplore.ieee.org/document/6631235/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/IROS.2017.8202143,Autonomous skill-centric testing using deep learning,IEEE,Conferences,Software testing is an important tool to ensure software quality. This is a hard task in robotics due to dynamic environments and the expensive development and time-consuming execution of test cases. Most testing approaches use model-based and/or simulation-based testing to overcome these problems. We propose model-free skill-centric testing in which a robot autonomously executes skills in the real world and compares it to previous experiences. The skills are selected by maximising the expected information gain on the distribution of erroneous software functions. We use deep learning to model the sensor data observed during previous successful skill executions and to detect irregularities. Sensor data is connected to function call profiles such that certain misbehaviour can be related to specific functions. We evaluate our approach in simulation and in experiments with a KUKA LWR 4+ robot by purposefully introducing bugs to the software. We demonstrate that these bugs can be detected with high accuracy and without the need for the implementation of specific tests or task-specific models.,https://ieeexplore.ieee.org/document/8202143/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/IEMBS.2008.4649235,BMI cyberworkstation: Enabling dynamic data-driven brain-machine interface research through cyberinfrastructure,IEEE,Conferences,"Dynamic data-driven brain-machine interfaces (DDDBMI) have great potential to advance the understanding of neural systems and improve the design of brain-inspired rehabilitative systems. This paper presents a novel cyberinfrastructure that couples in vivo neurophysiology experimentation with massive computational resources to provide seamless and efficient support of DDDBMI research. Closed-loop experiments can be conducted with in vivo data acquisition, reliable network transfer, parallel model computation, and real-time robot control. Behavioral experiments with live animals are supported with real-time guarantees. Offline studies can be performed with various configurations for extensive analysis and training. A Web-based portal is also provided to allow users to conveniently interact with the cyberinfrastructure, conducting both experimentation and analysis. New motor control models are developed based on this approach, which include recursive least square based (RLS) and reinforcement learning based (RLBMI) algorithms. The results from an online RLBMI experiment shows that the cyberinfrastructure can successfully support DDDBMI experiments and meet the desired real-time requirements.",https://ieeexplore.ieee.org/document/4649235/,2008 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society,20-25 Aug. 2008,ieeexplore
10.1109/IES53407.2021.9594013,Ball Position Transformation with Artificial Intelligence Based on Tensorflow Libraries,IEEE,Conferences,Research on wheeled soccer robots has been carried out by several researchers. This is due to the existence of national and international competitions. Previous research was to create a ball position transformation system with a modified method of neural network architecture. This research was developed by building an intelligent transformation system with the Tensorflow library. This transformation system aims to be able to directly measure the distance of objects in real terms without first changing the environmental image from an omni field to a flat plane with conventional camera calibration techniques. This process can replace manual calibration with a variety of field size changes The system can transform with mean error 0.0000026 on epoch 10000 using “conda-tensorflowneural network” libraries. It can transform the position of the ball from the omni space to the cartesian space. This system was implemented on wheeled soccer robot as keeper.,https://ieeexplore.ieee.org/document/9594013/,2021 International Electronics Symposium (IES),29-30 Sept. 2021,ieeexplore
10.1109/ROMAN.1995.531979,Basic study on avoidance motions for human behaviors,IEEE,Conferences,"The purpose of this study was propose the algorithm on the system including the mechanism to avoid a man. On basic study, this paper reports on the experiment of human avoidance motion, the experimental system for avoidance motions and experimental results. The human avoidance behavior occurs when passing each other. Many passings each of experimenter and subject have been recorded by VTR. Avoidance motions data are obtained through their loci by analyzing VTR. The experimental system for avoidance motions has three DC servo motors with encoders. One DC servo motor is used on human side. Two DC servo motors are used on robot side to realize X-Y axes avoidance. Personal computer controls all motors and realizes avoidance motion using human behavior data.",https://ieeexplore.ieee.org/document/531979/,Proceedings 4th IEEE International Workshop on Robot and Human Communication,5-7 July 1995,ieeexplore
10.1109/IJCNN.2016.7727848,Bayesian perception of touch for control of robot emotion,IEEE,Conferences,"In this paper, we present a Bayesian approach for perception of touch and control of robot emotion. Touch is an important sensing modality for the development of social robots, and it is used in this work as stimulus through a human-robot interaction. A Bayesian framework is proposed for perception of various types of touch. This method together with a sequential analysis approach allow the robot to accumulate evidence from the interaction with humans to achieve accurate touch perception for adaptable control of robot emotions. Facial expressions are used to represent the emotions of the iCub humanoid. Emotions in the robotic platform, based on facial expressions, are handled by a control architecture that works with the output from the touch perception process. We validate the accuracy of our system with simulated and real robot touch experiments. Results from this work show that our method is suitable and accurate for perception of touch to control robot emotions, which is essential for the development of sociable robots.",https://ieeexplore.ieee.org/document/7727848/,2016 International Joint Conference on Neural Networks (IJCNN),24-29 July 2016,ieeexplore
10.1109/FUZZY.2000.838648,Behavior based decision control in autonomous vehicles: a fuzzy approach using Khepera,IEEE,Conferences,"A fuzzy behavior based decision control architecture is introduced. Each behavior is composed by several fuzzy actions-a concept that constitutes the behavior building block, allowing the implementation of a single aspect of the desired competence. A fuzzy action itself is composed by action (fuzzy controller) and activity (fuzzy predicate) producing modules. The behavior performance is also dependent on the (simulated) available energy. The arbitration process is present at the levels of action and behavior. This architecture is tested on the Khepera robot, both in simulation and in reality. The results of the performed experiments are presented, encouraging the architecture use in long range autonomous vehicles.",https://ieeexplore.ieee.org/document/838648/,Ninth IEEE International Conference on Fuzzy Systems. FUZZ- IEEE 2000 (Cat. No.00CH37063),7-10 May 2000,ieeexplore
10.1109/ROMOCO.2001.973435,"Behavior learning to predict using neural networks (NN): Ttowards a fast, cooperative and adversarial robot team (RoboCup)",IEEE,Conferences,"To build a fast, cooperative and adversarial robot team (RoboCup), prediction behaviors became necessary. In the paper, a behavior learning method using neural networks (NN) is developed to enhance the behavior of GMD mobile robots. In fact, the suggested NN called NN-Prediction learns to predict successfulness of the elementary behavior ""Kick"" the ball towards the goal in order to act as consequence. The training is carried out by the supervised gradient back-propagation learning paradigm. This NN-Prediction has been specified on the Dual Dynamics Designer, to be thereafter implemented and tested on both the Dual Dynamics Simulator and GMD mobile robots, and analyzed on the Real-Time Trace Tool. NN-prediction demonstrated, during the 4/sup th/ World Championships RoboCup 2000, cooperative and adversarial behaviors especially face to situations where the successfulness of ""Kick"" is not guaranteed. Then, a discussion is given dealing with the suggested prediction behavior and how it relates to some other works.",https://ieeexplore.ieee.org/document/973435/,Proceedings of the Second International Workshop on Robot Motion and Control. RoMoCo'01 (IEEE Cat. No.01EX535),20-20 Oct. 2001,ieeexplore
10.1109/ROMAN.2012.6343774,Behavioral Turing test using two-axis actuators,IEEE,Conferences,"The Turing test is an imitation game for determining the intelligence of an agent. In spite of its simplified setting, the use of natural language between two agents in the test is still too high a hurdle for achieving fruitful results in the field of artificial intelligence. In this paper, the authors propose a variation of the Turing test with a restricted communication method. This modified test uses behaviors generated by two-axis actuators for communication instead of the natural language dialogue used in the normal Turing test. This reduction of scope reveals what kinds of features are essential for an imitation game, and broaden the application brought by Turing test. When we learn what sorts of communication become possible with restricted actuation, we can apply this knowledge to any kind of robot or device in the real world. First, we tried to determine what elements are critical for communication between a user and a robot through a preliminary experiment involving human-human communication. A human manipulator received a video image as input and controlled a ""robot box"" with two actuators in a way that would lead a user to put other objects into the box. The results indicated what kinds of behavior are required to show the intention of the manipulator to the user. Second, we analyzed the result of the preliminary experiment, organized a behavioral model from the result, and programmed the robot box to run the model. The behavior of the robot was programmed according to the user's head and hand locations as identified by a motion captures system. The robot automatically interact with a human without human manipulation with this program. Third, we conducted a behavioral Turing test in a communication task whereby the human collected items according to the instructions of the robot box. In this test, two actuators on the box is controlled both by human manipulator and our program. The answers of users suggests that the users could not identify which is controlled by a human manipulator or the program. This result indicates that the Turing test succeed in a restricted behavioral level.",https://ieeexplore.ieee.org/document/6343774/,2012 IEEE RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication,9-13 Sept. 2012,ieeexplore
10.1109/EMWRTS.1996.557846,Behaviour-oriented commands: from distributed knowledge representation to real-time implementation,IEEE,Conferences,"This paper presents a general methodology to model and implement real time control of complex systems with high reactivity. It is based on an original concept called ""behaviour oriented commands"" (BOCs). This methodology has been applied successfully in our mobile robot. BOCs incorporate mechanisms to model the set of rules (knowledge) which describes the restrictions and actions to achieve a goal. Basic rules are well encapsulated by entities called ""behaviours"", while global co-operating rules are explicited by the association link managed by the BOC's control unit. The model is easily translated into a real time implementation. This fusion between knowledge and real time is the main contribution of our work to the RT area.",https://ieeexplore.ieee.org/document/557846/,Proceedings of the Eighth Euromicro Workshop on Real-Time Systems,12-14 June 1996,ieeexplore
10.1109/ICRA40945.2020.9197470,"Benchmark for Skill Learning from Demonstration: Impact of User Experience, Task Complexity, and Start Configuration on Performance",IEEE,Conferences,"We contribute a study benchmarking the performance of multiple motion-based learning from demonstration approaches. Given the number and diversity of existing methods, it is critical that comprehensive empirical studies be performed comparing the relative strengths of these techniques. In particular, we evaluate four approaches based on properties an end user may desire for real-world tasks. To perform this evaluation, we collected data from nine participants, across four manipulation tasks. The resulting demonstrations were used to train 180 task models and evaluated on 720 task reproductions on a physical robot. Our results detail how i) complexity of the task, ii) the expertise of the human demonstrator, and iii) the starting configuration of the robot affect task performance. The collected dataset of demonstrations, robot executions, and evaluations are publicly available. Research insights and guidelines are also provided to guide future research and deployment choices about these approaches.",https://ieeexplore.ieee.org/document/9197470/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/IJCNN.2008.4633875,Bio-inspired stochastic chance-constrained multi-robot task allocation using WSN,IEEE,Conferences,"The multi-robot task allocation (MRTA) especially in unknown complex environment is one of the fundamental problems, a mostly important object in research of multi-robot. The MRTA problem is initially formulated as a chance-constrained optimization problem. Monte Carlo simulation is used to verify the accuracy of the solution provided by the algorithm. Ant colony optimization (ACO) algorithm based on bionic swarm intelligence was used. A hybrid intelligent algorithm combined Monte Carlo simulation and neural network is used for solving stochastic chance constrained models of MRTA. A practical implementation with real WSN and real mobile robots were carried out. In environment the successful implementation of tasks without collision validates the efficiency, stability and accuracy of the proposed algorithm. The convergence curve shows that as iterative generation grows, the utility increases and finally reaches a stable and optimal value. Results show that using sensor information fusion can greatly improve the efficiency. The algorithm is proved better than tradition algorithms without WSN for MRTA in real time.",https://ieeexplore.ieee.org/document/4633875/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/BIOROB.2018.8487202,Bioinspired Adaptive Spiking Neural Network to Control NAO Robot in a Pavlovian Conditioning Task,IEEE,Conferences,"The cerebellum has a central role in fine motor control and in various neural processes, as in associative paradigms. In this work, a bioinspired adaptive model, developed by means of a spiking neural network made of thousands of artificial neurons, has been leveraged to control a humanoid NAO robot in real-time. The learning properties of the system have been challenged in a classic cerebellum-driven paradigm, the Pavlovian timing association between two provided stimuli, here implemented as a laser-avoidance task. The neurophysiological principles used to develop the model, succeeded in driving an adaptive motor control protocol with acquisition and extinction phases. The spiking neural network model showed learning behaviors similar to the ones experimentally measured with human subjects in the same conditioning task. The model processed in real-time external inputs, encoded as spikes, and the generated spiking activity of its output neurons was decoded, in order to trigger the proper response with a correct timing. Three long-term plasticity rules have been embedded for different connections and with different time-scales. The plasticities shaped the firing activity of the output layer neurons of the network. In the Pavlovian protocol, the neurorobot successfully learned the correct timing association, generating appropriate responses. Therefore, the spiking cerebellar model was able to reproduce in the robotic platform how biological systems acquire and extinguish associative responses, dealing with noise and uncertainties of a real-world environment.",https://ieeexplore.ieee.org/document/8487202/,2018 7th IEEE International Conference on Biomedical Robotics and Biomechatronics (Biorob),26-29 Aug. 2018,ieeexplore
10.1109/IJCNN.2000.859467,Biologically inspired neural controllers for motor control in a quadruped robot,IEEE,Conferences,"This paper presents biologically inspired neural controllers for generating motor patterns in a quadruped robot. Sets of artificial neural networks are presented which provide 1) pattern generation and gait control, allowing continuous passage from walking to trotting to galloping, 2) control of sitting and lying down behaviors, and 3) control of scratching. The neural controllers consist of sets of oscillators composed of leaky-integrator neurons, which control pairs of flexor-extensor muscles attached to each joint. The networks receive sensory feedback proportional to the contraction of simulated muscles and to joint flexion. Similarly to what is observed in cats, locomotion can be initiated by either applying tonic (i.e. non-oscillating) input to the locomotion network or by sensory feedback from extending the legs. The networks are implemented in a quadruped robot. It is shown that computation can be carried out in real time and that the networks can generate the above mentioned motor behaviors.",https://ieeexplore.ieee.org/document/859467/,Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium,27-27 July 2000,ieeexplore
10.1109/IROS.2004.1389400,Biologically inspired optimal robot arm control with signal-dependent noise,IEEE,Conferences,"Progress in the field of humanoid robotics and the need to find simpler ways to program such robots has prompted research into computational models for robotic learning from human demonstration. To further investigate biologically inspired human-like robotic movement and imitation, we have constructed a framework based on three key features of human movement and planning: optimality, modularity and learning. In this paper we focus on the application of optimality principles to the production of human-like movement by a robot arm. Among computational theories of human movement, the signal-dependent noise, or minimum variance, model was chosen as a biologically realistic control scheme to produce human-like movement. A well known optimal control algorithm, the linear quadratic regulator, was adapted to implement this model. The scheme was applied both in simulation and on a real robot arm, which demonstrated human-like movement profiles in a point-to-point reaching experiment.",https://ieeexplore.ieee.org/document/1389400/,2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),28 Sept.-2 Oct. 2004,ieeexplore
10.1109/ROMAN.2017.8172296,Blame my telepresence robot joint effect of proxemics and attribution on interpersonal attraction,IEEE,Conferences,"When remote users share autonomy with a telepresence robot, questions arise as to how the behaviour of the robot is interpreted by local users. We investigated how a robot's violations of social norms under shared autonomy influence the local user's evaluation of the robot's remote users. Specifically, we examined how attribution of such violations to either the robot or the remote user influences social perception of the remote user. Using personal space invasion as a salient social norm violation, we conducted a within-subject experiment (n=20) to investigate these questions. Participants saw several people introducing themselves through a telepresence robot, personal space invasion and attribution were manipulated. We found a significant (p=0.007) joint effect of the manipulations on interpersonal attraction. After these first 20 participants our robot broke down, and we had to continue with another robot (n=20). We found a difference between the two robots, causing us to discard this data from our main analysis. Subsequent video annotation and comparison of the two robots suggests that accuracy of the followed trajectory modifies attribution. Our results offer insights into the mechanisms of attribution in interactions with a telepresence robot as a mediator.",https://ieeexplore.ieee.org/document/8172296/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/CSCS52396.2021.00073,Bluetooth Communications in Educational Robotics,IEEE,Conferences,"In a world in a continuous and rapid change, it is absolutely necessary for our students to keep up with the rapid progress of new technologies: Internet of Things (IoT), Robotics, Artificial Intelligence (AI), Virtual Reality (VR), Augmented Reality (AR) etc. The rapid evolution and diversification of these emerging technologies has recently led to their introduction into the educational offer of the school curriculum for the gymnasium. The discipline of Information and Communication Technology (ICT) has already been implemented, a discipline that involves both the formation of skills to use new technologies and the formation of computational thinking necessary for the efficient and intelligent use of these technologies. In order to teach and learn Physics from a STEM (Science, Technology, Engineering and Mathematics) educational perspective, we initiated optional school courses of IoT, Robotics and AI (approached through Machine Learning). These courses stimulate, at the level of students, computational thinking, creativity and innovation and lead, from an interdisciplinary perspective, to the development of emerging specializations such as Mathematics-Physics-Automation, Mathematics-Physics-Electronics, Mathematics-Physics-Informatics-Robotics etc. In this paper we presented a method of approaching, in the school educational space, the study of wireless communication technologies between smart devices, through an Educational Robotics project. The project consisted of creating a wireless controlled mobile robotic platform (robot car) via a Bluetooth module connected to an Arduino Uno board.",https://ieeexplore.ieee.org/document/9481012/,2021 23rd International Conference on Control Systems and Computer Science (CSCS),26-28 May 2021,ieeexplore
10.1109/ICRA.2019.8793510,Bonnet: An Open-Source Training and Deployment Framework for Semantic Segmentation in Robotics using CNNs,IEEE,Conferences,"The ability to interpret a scene is an important capability for a robot that is supposed to interact with its environment. The knowledge of what is in front of the robot is, for example, relevant for navigation, manipulation, or planning. Semantic segmentation labels each pixel of an image with a class label and thus provides a detailed semantic annotation of the surroundings to the robot. Convolutional neural networks (CNNs) are popular methods for addressing this type of problem. The available software for training and the integration of CNNs for real robots, however, is quite fragmented and often difficult to use for non-experts, despite the availability of several high-quality open-source frameworks for neural network implementation and training. In this paper, we propose a tool called Bonnet, which addresses this fragmentation problem by building a higher abstraction that is specific for the semantic segmentation task. It provides a modular approach to simplify the training of a semantic segmentation CNN independently of the used dataset and the intended task. Furthermore, we also address the deployment on a real robotic platform. Thus, we do not propose a new CNN approach in this paper. Instead, we provide a stable and easy-to-use tool to make this technology more approachable in the context of autonomous systems. In this sense, we aim at closing a gap between computer vision research and its use in robotics research. We provide an open-source codebase for training and deployment. The training interface is implemented in Python using TensorFlow and the deployment interface provides C++ library that can be easily integrated in an existing robotics codebase, a ROS node, and two standalone applications for label prediction in images and videos.",https://ieeexplore.ieee.org/document/8793510/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/DEVLRN.2014.6983026,Bootstrapping paired-object affordance learning with learned single-affordance features,IEEE,Conferences,"The aim of this paper is to propose a system where complex affordance learning is bootstrapped through using pre-learned basic-affordances as additional inputs of the complex affordance predictors or as cues in selecting the next objects to explore during learning. In the first stage, the robot learns affordances in the form of developing classifiers that predict effect categories given object features for different discrete actions applicable to single objects. These predictions are later added to robot's feature set as higher-level affordance features. In the second stage, the robot learns more complex multi-object affordances using object and affordance features. We first applied our idea in an artificial interaction database which includes discrete actions, several manually coded object categories, and actions effects. Finally, we validated our bootstrapping approach in a real robot with poke and stack actions. We expected to obtain higher performance with affordance-features especially in small training datasets as the object-robot-environment dynamics should have already been partially learned and encoded in affordances. The experiment results showed that complex affordance learning significantly speeds up with predictors that are bootstrapped with affordance-features compared to predictors that use low-level features such as shape descriptors. We also showed that by actively selecting the next objects and by increasing the diversity of the training set using a distance measure based on learned single-object affordances, the effect of bootstrapping can be further increased.",https://ieeexplore.ieee.org/document/6983026/,4th International Conference on Development and Learning and on Epigenetic Robotics,13-16 Oct. 2014,ieeexplore
10.1109/AIM.2019.8868855,Brain-robot Shared Control Based on Motor Imagery and Improved Bayes Filter<sup>*</sup>,IEEE,Conferences,"Brain-controlled robots are an innovative means of interacting and can also provide new solutions for disabled and stroke patients to communicate with the outside world. Since the poor real-time performance and poor accuracy of brain-computer interface (BCI) is not precise to control the robot directly, in order to avoid damage to the robot and humans in the process, this paper designs a brain-robot shared control system based on brain-computer interface. The motion direction of the robot controlled via four types of motor imagery (MI) signals. Feature extraction of MI signals is performed using common space pattern (CSP) combined with local characteristic-scale decomposition (LCD). The classification results are obtained with the appropriate features processed by the spectral regression discriminant analysis (SRDA) classifier. The Bayes filter algorithm is used to implement the robot shared control method, the belief of the robot's motion direction is calculated, and then the control ratio of the robot's autonomous motion and the BCI are assigned automatically. Considering that each control instruction given by BCI cost at least 1.5 seconds. To achieve better control effect at the interval between two instructions, the relationship with two steps of Bayes filter is redesigned, even if a new control data is not received, the robot will continuously update the measurement according to the previous control data, assign a new control ratio and execute the corresponding instruction, so that the robot can continuously adjust the movement intention and proportion during the instruction interval of BCI. The control effect was verified by online experiments. Using the improved Bayes filter algorithm, the success rate of the experiment is greatly improved, and the number of instructions used in single trial is reduced by 50%.",https://ieeexplore.ieee.org/document/8868855/,2019 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM),8-12 July 2019,ieeexplore
10.1109/IROS.2005.1545040,Broker: an interprocess communication solution for multi-robot systems,IEEE,Conferences,"We describe in this paper a novel implementation of the interprocess communication (IPC) technology, called Broker, in support of the development and the operation of a complex robot system. We view each robot system as a collection of processes that need to exchange information, e.g. motion commands and sensory data, in a flexible and convenient fashion, without affecting each other's operations in case of a process's scheduled termination or unexpected failure. We argue that the IPC technology provides an ideal framework for this purpose, and we carefully make our design decisions about its implementation based on the needs of robotics applications. Broker is programming language, operating system, and hardware platform independent and has served us well in a RoboCup project and collective robotics experiments, in both simulation and real-world environments.",https://ieeexplore.ieee.org/document/1545040/,2005 IEEE/RSJ International Conference on Intelligent Robots and Systems,2-6 Aug. 2005,ieeexplore
10.1109/CRV52889.2021.00009,Building Facades to Normal Maps: Adversarial Learning from Single View Images,IEEE,Conferences,"Surface normal estimation is an essential component of several computer and robot vision pipelines. While this problem has been extensively studied, most approaches are geared towards indoor scenes and often rely on multiple modalities (depth, multiple views) for accurate estimation of normal maps. Outdoor scenes pose a greater challenge as they exhibit significant lighting variation, often contain occluders, and structures like building facades are often ridden with numerous windows and protrusions. Conventional supervised learning schemes excel in indoor scenes, but do not exhibit competitive performance when trained and deployed in outdoor environments. Furthermore, they involve complex network architectures and require many more trainable parameters. To tackle these challenges, we present an adversarial learning scheme that regularizes the output normal maps from a neural network to appear more realistic, by using a small number of precisely annotated examples. Our method presents a lightweight and simpler architecture, while improving performance by at least 1.5x across most metrics. We evaluate our approaches against the state-of-the-art on normal map estimation, on a synthetic and a real outdoor dataset, and observe significant performance enhancements.",https://ieeexplore.ieee.org/document/9469450/,2021 18th Conference on Robots and Vision (CRV),26-28 May 2021,ieeexplore
10.1109/CASE49439.2021.9551562,Building Skill Learning Systems for Robotics,IEEE,Conferences,"Skill-generating policies have enabled robots to perform a wide range of applications as for example assembly tasks. However, the manual engineering effort for such policies is fairly high and the environment is frequently required to be rather deterministic. For expanding robot deployment to low-volume manufacturing two challenges need to be addressed. First, the robot should acquire the skill-generating policy not from a robot programmer but rather from an expert on the task and second, the robot needs to be able to operate in unstructured environments. In this paper we present a learning approach that combines imitation learning and reinforcement learning to provide a tool for intuitive task teaching followed by self-optimization of the system. The presented approach is applied to a dual-arm assembly task using a real robot and appropriate simulation models. Whereas pure imitation learning does not result in an acceptable success rate for the considered example, after 400 episodes of reinforcement learning the robot can successfully solve the assembly task.",https://ieeexplore.ieee.org/document/9551562/,2021 IEEE 17th International Conference on Automation Science and Engineering (CASE),23-27 Aug. 2021,ieeexplore
10.1109/IJCNN.2012.6252637,Building block of a programmable neuromorphic substrate: A digital neurosynaptic core,IEEE,Conferences,"The grand challenge of neuromorphic computation is to develop a flexible brain-inspired architecture capable of a wide array of real-time applications, while striving towards the ultra-low power consumption and compact size of biological neural systems. Toward this end, we fabricated a building block of a modular neuromorphic architecture, a neurosynaptic core. Our implementation consists of 256 integrate-and-fire neurons and a 1,024×256 SRAM crossbar memory for synapses that fits in 4.2mm<sup>2</sup> using a 45nm SOI process and consumes just 45pJ per spike. The core is fully configurable in terms of neuron parameters, axon types, and synapse states and its fully digital implementation achieves one-to-one correspondence with software simulation models. One-to-one correspondence allows us to introduce an abstract neural programming model for our chip, a contract guaranteeing that any application developed in software functions identically in hardware. This contract allows us to rapidly test and map applications from control, machine vision, and classification. To demonstrate, we present four test cases (i) a robot driving in a virtual environment, (ii) the classic game of pong, (iii) visual digit recognition and (iv) an autoassociative memory.",https://ieeexplore.ieee.org/document/6252637/,The 2012 International Joint Conference on Neural Networks (IJCNN),10-15 June 2012,ieeexplore
10.1109/ISDA.2010.5687045,Bézier curve based dynamic obstacle avoidance and trajectory learning for autonomous mobile robots,IEEE,Conferences,"This paper addresses the problem of avoiding dynamic obstacles while following the learned trajectory through non-point based maps directly through laser data. The geometric representation of free configuration area changes while a moving obstacle enters into the safety region of autonomous mobile robot. We have applied the Bézier curve properties to the free configuration eigenspaces to satisfy the dynamic obstacle avoidance path constraints. The algorithm is designed to accurately represent the mobile robot's characteristics while avoiding obstacle such as minimum turning radius. Moreover, we also discuss the obstacle avoided path feasibility as a vectorial combination of free configuration eigen-vectors at discrete time scan-frames to manifest a trajectory, which once followed and mapped onto the two control signals of mobile robot will enable it to build an efficient and accurate online environment map. Preliminary results in Matlab have been shown to validate the idea, while the same has been implemented in Player/stage (robotics real-time software) to analyze the performance of the proposed system.",https://ieeexplore.ieee.org/document/5687045/,2010 10th International Conference on Intelligent Systems Design and Applications,29 Nov.-1 Dec. 2010,ieeexplore
10.1109/ISCAS.2004.1329695,CNN wave based computation for robot navigation planning,IEEE,Conferences,"In this work a methodology for real-time robot navigation in a complex, dynamically changing environment, based on wave computation and implemented by cellular neural networks (CNNs) is introduced. The keypoint of the approach is to consider the environment in which the robot moves as an excitable medium. Obstacles and targets represent the source of autowave generation. The wavefronts propagating in the CNN medium provide to the robot all the information to achieve an adaptive motion avoiding the obstacles and directed to the target. In particular the paradigm of reaction-diffusion (RD) equations are used to implement a CNN-based wave computation for navigation control. Experimental results validating the approach are shown.",https://ieeexplore.ieee.org/document/1329695/,2004 IEEE International Symposium on Circuits and Systems (IEEE Cat. No.04CH37512),23-26 May 2004,ieeexplore
10.1109/ICICTA.2017.93,CNN-Based Model for Pose Detection of Industrial PCB,IEEE,Conferences,"For applications in robot manipulate with object, get the pose of objects is very important for controller's subsequent operations, especially in PCB feeding and blanking field, the grasp success rate will be enhanced if robot can get a exact pose of objects that relative to end manipulator. So in this paper we utilize the CNN model to build on a neural network for 3 tasks: object recognition, location and pose detection. This model treat pose detection as a classification problem and try to combine recognition, location at the same level. To validate the performance of the multi-task detection model, experiments and analysis of the model performance was carried out by the real-time PCB detection test. In the experiment, we use the PCB dataset comprised of 3 types which contains different poses made by ourselves as train/test samples. The number of object pose categories was divided into 8bins, 12bins and 36bins according to pose detection precision. We analysis the effect of the non-uniform datasets on training process and the final detect results shows that this CNN-based detection model can achieve high accuracy on PCB pose detection.",https://ieeexplore.ieee.org/document/8089976/,2017 10th International Conference on Intelligent Computation Technology and Automation (ICICTA),9-10 Oct. 2017,ieeexplore
10.1109/ROBOT.1990.126097,CSL: a cost-sensitive learning system for sensing and grasping objects,IEEE,Conferences,"The goal of the research reported is to build a learning robot which can survive in an unknown environment for a long time. Such a robot must learn which sensors to use, where to use them, and how to generate an inexpensive and reliable robot control procedure to accomplish its task. This is beyond machine learning methods because they usually ignore robot execution costs and are ill-prepared to handle failures. A cost-sensitive, noise-tolerant and inductive robot learning system, CSL, that represents the first steps toward achieving this goal is described, emphasizing the cost and noise issues in learning. CSL has been implemented in a real-world robot for sensing objects and selecting their grasping procedures.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/126097/,"Proceedings., IEEE International Conference on Robotics and Automation",13-18 May 1990,ieeexplore
10.1109/HUMANOIDS.2014.7041490,Can active impedance protect robots from landing impact?,IEEE,Conferences,"This paper studies the effect of passive and active impedance for protecting jumping robots from landing impacts. The theory of force transmissibility is used for selecting the passive impedance of the system to minimize the shock propagation. The active impedance is regulated online by a joint-level controller. On top of this controller, a reflex-based leg retraction scheme is implemented which is optimized using direct policy search reinforcement learning based on particle filtering. Experiments are conducted both in simulation and on a real-world hopping leg. We show that although the impact dynamics is fast, the addition of passive impedance provides enough time for the active impedance controller to react to the impact and protect the robot from damage.",https://ieeexplore.ieee.org/document/7041490/,2014 IEEE-RAS International Conference on Humanoid Robots,18-20 Nov. 2014,ieeexplore
10.1109/IJCNN52387.2021.9533738,CarSNN: An Efficient Spiking Neural Network for Event-Based Autonomous Cars on the Loihi Neuromorphic Research Processor,IEEE,Conferences,"Autonomous Driving (AD) related features provide new forms of mobility that are also beneficial for other kind of intelligent and autonomous systems like robots, smart transportation, and smart industries. For these applications, the decisions need to be made fast and in real-time. Moreover, in the quest for electric mobility, this task must follow low power policy, without affecting much the autonomy of the mean of transport or the robot. These two challenges can be tackled using the emerging Spiking Neural Networks (SNNs). When deployed on a specialized neuromorphic hardware, SNNs can achieve high performance with low latency and low power consumption. In this paper, we use an SNN connected to an event-based camera for facing one of the key problems for AD, i.e., the classification between cars and other objects. To consume less power than traditional frame-based cameras, we use a Dynamic Vision Sensor (DVS) [1]. The experiments are made following an offline supervised learning rule, followed by mapping the learnt SNN model on the Intel Loihi Neuromorphic Research Chip [2]. Our best experiment achieves an accuracy on offline implementation of 86%, that drops to 83% when it is ported onto the Loihi Chip. The Neuromorphic Hardware implementation has maximum 0.72 ms of latency for every sample, and consumes only 310 mW. To the best of our knowledge, this work is the first implementation of an event-based car classifier on a Neuromorphic Chip.",https://ieeexplore.ieee.org/document/9533738/,2021 International Joint Conference on Neural Networks (IJCNN),18-22 July 2021,ieeexplore
10.1109/IROS45743.2020.9341134,Catch the Ball: Accurate High-Speed Motions for Mobile Manipulators via Inverse Dynamics Learning,IEEE,Conferences,"Mobile manipulators consist of a mobile platform equipped with one or more robot arms and are of interest for a wide array of challenging tasks because of their extended workspace and dexterity. Typically, mobile manipulators are deployed in slow-motion collaborative robot scenarios. In this paper, we consider scenarios where accurate high-speed motions are required. We introduce a framework for this regime of tasks including two main components: (i) a bi-level motion optimization algorithm for real-time trajectory generation, which relies on Sequential Quadratic Programming (SQP) and Quadratic Programming (QP), respectively; and (ii) a learning-based controller optimized for precise tracking of high-speed motions via a learned inverse dynamics model. We evaluate our framework with a mobile manipulator platform through numerous high-speed ball catching experiments, where we show a success rate of 85.33%. To the best of our knowledge, this success rate exceeds the reported performance of existing related systems [1], [2] and sets a new state of the art.",https://ieeexplore.ieee.org/document/9341134/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ROBOT.1993.292250,Cellular robotics: simulation and HW implementation,IEEE,Conferences,"Aspects of self-organization are presented in this paper. Computer simulations as well as a real prototypical implementation are used to illustrate the proposed approach. Results of simulations are presented to compare different strategies of self-organization enabling a system of autonomous robots to form a chain between two landmarks in a completely unknown environment. This chain implicitly represents a path between any two points of the environment without an explicit representation of free space (no single robot has a global map of the environment). The experimental part, even if restricted to a few robots, demonstrates that the set of stimuli-action processes used in the simulations are indeed feasible on real systems.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/292250/,[1993] Proceedings IEEE International Conference on Robotics and Automation,2-6 May 1993,ieeexplore
10.1109/ICRA.2019.8793660,Chance Constrained Motion Planning for High-Dimensional Robots,IEEE,Conferences,"This paper introduces Probabilistic Chekov (p-Chekov), a chance-constrained motion planning system that can be applied to high degree-of-freedom (DOF) robots under motion uncertainty and imperfect state information. Given process and observation noise models, it can find feasible trajectories which satisfy a user-specified bound over the probability of collision. Leveraging our previous work in deterministic motion planning which integrated trajectory optimization into a sparse roadmap framework, p-Chekov shows superiority in its planning speed for high-dimensional tasks. P-Chekov incorporates a linear-quadratic Gaussian motion planning approach into the estimation of the robot state probability distribution, applies quadrature theories to waypoint collision risk estimation, and adapts risk allocation approaches to assign allowable probabilities of failure among waypoints. Unlike other existing risk-aware planners, p-Chekov can be applied to high-DOF robotic planning tasks without the convexification of the environment. The experiment results in this paper show that this p-Chekov system can effectively reduce collision risk and satisfy user-specified chance constraints in typical real-world planning scenarios for high-DOF robots.",https://ieeexplore.ieee.org/document/8793660/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/CIFEr.2019.8759121,Chatbot Application on Cryptocurrency,IEEE,Conferences,"Many chatbots have been developed that provide a multitude of services through a wide range of methods. A chatbot is a brand-new conversational agent in the highspeed changing technology world. With the advance of Artificial Intelligence and machine learning, chatbots are becoming more and more popular. A chatbot is the extension of human interface mediums such as the phone and social platforms. Similarly, Cryptocurrency is a new extension of digital or virtual currency designed to work as a medium of exchange. In the current digital exchanging world, investors and interested parties are eager to know more information about, and the capabilities of, this new type of currency. One of the potential paths to retrieve the info automatically and quickly is through a chatbot. We explored the open source python library, Chatterbot, to apply Itchat API (a WeChat interface) with the aim of building a robot chatting application, I&amp;C Chat, on the topic of cryptocurrency. First, we collected question and answer pairs datasets from Quora websites. Furthermore, we also created API calls to query the real time quote for the top 25 cryptocurrencies. Then we used the collected data to train our chatbot and implemented a logic adapter to receive the price quote of cryptocurrencies based on the incoming question. The Itchat API method will return the best matched answer to the asking party automatically. The response time of different questions has been investigated. The results imply that this application is quite useful, feasible and beneficial to the digital currency world.",https://ieeexplore.ieee.org/document/8759121/,2019 IEEE Conference on Computational Intelligence for Financial Engineering & Economics (CIFEr),4-5 May 2019,ieeexplore
10.1109/ICRA48506.2021.9561926,Circus ANYmal: A Quadruped Learning Dexterous Manipulation with Its Limbs,IEEE,Conferences,"Quadrupedal robots are skillful at locomotion tasks while lacking manipulation skills, not to mention dexterous manipulation abilities. Inspired by the animal behavior and the duality between multi-legged locomotion and multi-fingered manipulation, we showcase a circus ball challenge on a quadrupedal robot, ANYmal. We employ a model-free reinforcement learning approach to train a deep policy that enables the robot to balance and manipulate a light-weight ball robustly using its limbs without any contact measurement sensor. The policy is trained in the simulation, in which we randomize many physical properties with additive noise and inject random disturbance force during manipulation, and achieves zero-shot deployment on the real robot without any adjustment. In the hardware experiments, dynamic performance is achieved with a maximum rotation speed of 15 °/s, and robust recovery is showcased under external poking. To our best knowledge, it is the first work that demonstrates the dexterous dynamic manipulation on a real quadrupedal robot.",https://ieeexplore.ieee.org/document/9561926/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICCE46568.2020.9042997,Cliff-sensor-based Low-level Obstacle Detection for a Wheeled Robot in an Indoor Environment,IEEE,Conferences,"A ramp and uneven ground formed by a low-level obstacle - whose height is too low from the ground - often stalls a robot's navigation in an indoor environment. Few-centimeter differences between a low-level obstacle and a low-level non-obstacle are very difficult to be precisely measured in a constant distance at a mobile robot. In this paper, a wheeled mobile robot thus makes physical contact onto a low-level object, in order to measure such subtle differences. We use one or more cliff sensors typically in place for a mobile robot in order to avoid a drop-off. A wheeled robot climbs over a low-level object, classifies an obstacle vs. a non-obstacle using a cliff sensor's timeseries data, and rapidly backs up before getting stuck onto an obstacle. While adopting a simplified deep-learning architecture, we suggest a rapid and accurate obstacle detection technique in real-time. We implemented our technique on an embedded robot platform of LG Hom-Bot. The supplementary video on the physical robot experiment can be accessed at https://youtu.be/yK57S857_II.",https://ieeexplore.ieee.org/document/9042997/,2020 IEEE International Conference on Consumer Electronics (ICCE),4-6 Jan. 2020,ieeexplore
10.1109/IROS.2018.8594311,Cognition-enabled Framework for Mixed Human-Robot Rescue Teams,IEEE,Conferences,"With the advancements in robotic technology and the progress in human-robot interaction research, the interest in deploying mixed human-robot teams in rescue missions is increasing. Due to their complementary capabilities in terms of locomotion, visibility and reachability of areas, human-robot teams are considerably deployed in real-world settings, albeit the robotic agents in such scenarios are normally fully teleoperated. A major barrier to successful and efficient mission execution in those teams is the lack of cognitive skills in robotic systems. In this paper, we present a cognition-enabled framework and an implemented system where robotic agents are equipped with cognitive capabilities to naturally communicate with humans and autonomously perform tasks. The framework allows for natural tasking of robots, reasoning about robot behavior, capabilities and actions, and a common belief state representation for shared mission awareness of robots and human operators.",https://ieeexplore.ieee.org/document/8594311/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/IEEE.ICCC.2017.20,Cognitive Acoustic Analytics Service for Internet of Things,IEEE,Conferences,"The rapid development of the Internet of Things (IoT) has brought great changes for non-contact and non-destructive sensing and diagnosis. For every inanimate object can tell us something by the sound it makes, acoustic sensor demonstrates great advantages comparing to conventional electronic and mechanic sensors in such cases: overcoming environmental obstacles, mapping to existing use cases of detecting problems with human ears, low cost for deployment, etc. It could be widely applied to various domains, such as predictive maintenance of machinery, robot sensory, elderly and baby care in smart home, etc. Whether we can use the acoustic sensor data to understand what is happening and to predict what will happen relies heavily on the analytics capabilities we apply to the acoustic data, which has to overcome the obstacles of noise, disturbance and errors, and has to meet the requirement of real-time processing of high volume signals with large number of sensors. In this paper, we propose a scalable cognitive acoustics analytics service for IoT that provides the user an incremental learning approach to evolve their analytics capability on non-intuitive and unstructured acoustic data through the combination of acoustic signal processing and machine learning technology. It first performs acoustic signal processing and denoising, enables acoustic signal based abnormal detection based on sound intensity, spectral centroid, etc. Then based on the accumulated abnormal data, a supervised learning method is performed as baseline and a neural network based classifier is used to recognize acoustic events in different scenarios with various volume of sample data and requirement of accuracy. In addition, acoustic sensor arrays processing is supported for localization of moving acoustic source in more complex scenario. In this paper, we designed a hybrid computing structure. Finally, we conduct experiments on acoustic event recognition for machinery diagnosis, and show that the proposed system can achieve high accuracy.",https://ieeexplore.ieee.org/document/8029228/,2017 IEEE International Conference on Cognitive Computing (ICCC),25-30 June 2017,ieeexplore
10.1109/INDIN.2011.6034840,Cognitive decision unit applied to autonomous biped robot NAO,IEEE,Conferences,"The novel approach to use meta-psychology - the theoretic foundation of psychoanalysis - as archetype for a decision making framework for autonomous agents was realized in simulations recently. In addition, multiple studies showed the capability of a robot to sense and interact in its environment. This work fills the gap between sensing, environmental interaction and decision making by grounding these topics with an agents internal needs using the concepts of meta-psychology. The bodies of typical agents are equipped with internal systems which can generate bodily needs - for example the urgent need for food. As proof-of-concept we implemented this concept on a simulated agent as well as on a physical real humanoid biped robot to additionally proof the concept within a fully controlled simulated environment. The use of the common humanoid robot platform NAO, which has 25 degrees of freedom and biped locomotion, enforced us to deal with complex situations and disturbed sensor readings. NAO provides various internal sensors like engine temperature or battery level as well as external sensors like sonar or cameras. An implemented visual marker detecting system allowed us to detect objects in the surrounding environmental, representing food or energy sources. We show, how it is possible to use the psychoanalytically inspired framework ARS to control a real world application, the robot NAO.",https://ieeexplore.ieee.org/document/6034840/,2011 9th IEEE International Conference on Industrial Informatics,26-29 July 2011,ieeexplore
10.1109/CARE.2013.6733739,Cognitive learning enabled real time object search robot,IEEE,Conferences,"Object Tracking is usually performed in the context of higher-level applications that require the location and/or shape of the object in every frame. Most works are focused on a specific application, such as tracking human, car, or pre-learned objects. All these require database and considerable amount of training time to detect the current object and to track it. In this paper we propose a method to track objects where a pre-stored database is not a requirement. The proposed method uses a combination of Scale Invariant Feature Transform (SIFT) based feature extraction, Kalman filter and Cognitive learning. The algorithm has the ability to make its own database of the objects in the due course of time by interacting with the user through text based communication. This algorithm is deployed on a search robot which does the operation of searching an object in real time upon a command from the user. The search operation of robot is made more flexible using Bluetooth wireless communication protocol.",https://ieeexplore.ieee.org/document/6733739/,"2013 International Conference on Control, Automation, Robotics and Embedded Systems (CARE)",16-18 Dec. 2013,ieeexplore
10.1109/ROBIO49542.2019.8961823,Collaborative Object Transportation by Multiple Robots with Onboard Object Localization Algorithm,IEEE,Conferences,"Collaborative object transportation has become a popular study trend with its remarkable application foreground. In previous relevant studies, localization of the transported object has always been accomplished by additional devices rather than robot onboard equipments. This paper presents a generalized multi-robot leader-follower system for collaborative object transportation and an onboard object localization algorithm for trajectory tracking of the target object. In this system, the mobile robots can directly push a cubic object without extra gripping devices, when tracking the reference trajectory. During the control process, the object is regarded as an virtual leader, whose localization information is utilized as the feedback, while the mobile robots are considered as the followers. In absence of external localization systems, the proposed onboard localization algorithm provides the real-time position information of the object using scan data from lidars equipped on the robots. A performed measurement accuracy test shows high precision of this algorithm. Finally, a lane-changing experiment of object transportation is conducted, and it verifies this multi-robot leader-follower system.",https://ieeexplore.ieee.org/document/8961823/,2019 IEEE International Conference on Robotics and Biomimetics (ROBIO),6-8 Dec. 2019,ieeexplore
10.1109/MSM49833.2020.9202398,Collaborative Robot System for Playing Chess,IEEE,Conferences,"In recent years, number of collaborative robots industrial applications has made a significant increasment. Implementation of collaborative robots is a safe and effective way for designing robot-human cooperation systems. Combined with constantly developing artificial intelligence, collaborative systems are actually able to solve complex problems that require some sort of intelligence. For humans, board games are a good example of the visualization of robot intelligence. Such systems require estimation and detection of board and pieces in manipulator workspace, some kind of decision-making algorithms and robot control system to move pieces. The flagship of such systems are chess playing robots. The chess game has a defined and easy to understand set of rules which makes it interesting example of intelligent robotics systems application. In this paper, we present an implementation of collaborative robots for chess playing system which was designed to play against human or another robot. The system is able to track state of the game via camera, calculate the optimal move using implemented decision-making algorithm, detect illegal moves and execute pick-and-place task to physically move pieces. We test the developed system in a real-world setup and provide experimental results documenting the performance of proposed approach.",https://ieeexplore.ieee.org/document/9202398/,2020 International Conference Mechatronic Systems and Materials (MSM),1-3 July 2020,ieeexplore
10.1109/ICTAI.2019.00023,Collision-Free Path Finding for Dynamic Gaming and Real Time Robot Navigation,IEEE,Conferences,"Collision-free path finding is crucial for multi-agent traversing environments like gaming systems. An efficient and accurate technique is proposed for avoiding collisions with potential obstacles in virtual and real time environments. Potential field is a coherent technique but it eventuates with various problems like static map usage and pre-calculated potential field map of the environment. It is unsuitable for dynamically changing or unknown environments. Agents can get stuck inside a local minima incompetent in escaping without a workaround implementation. This paper presents efficient and accurate solutions to find collision free path using potential field for dynamic gaming and real time robot navigation. A surfing game in two testing environments with a Gamecar and a physical robot called Robocar is created with dynamic and solid obstacles. Sensor like proximity, line and ultrasonic are used along with the camera as different agents for path finding. The proposed intelligent agent (IA) technique is compared with other path planing algorithms and games in terms of time complexity, cost metrics, decision making complexity, action repertoire, interagent communication, reactivity and temporally continuous. It traverses for 135 meters(m) in 55.8 seconds(s) covering 20 goals and 419.3 m in 8.7 minutes while avoiding 10 local minimas successfully. Proposed technique shows comparable results to path finding with techniques using neural networks and A* algorithm. Experimental results prove the efficiency with run time overload, time complexity and resource consumption of the proposed technique.",https://ieeexplore.ieee.org/document/8995276/,2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI),4-6 Nov. 2019,ieeexplore
10.1109/IDAP.2017.8090332,Color based moving object tracking with an active camera using motion information,IEEE,Conferences,"In this study, a real-time system design, which can track (RGB) targets in dynamic environments with an active camera, was implemented. Object tracking applications are quite important for military, surveillance system and operational robot applications and getting more important day by day. This design allows us tracking an object using fewer cameras. The design consists of three main parts that are object detection, mapping, tracking the object. When the camera catches the object, first it detects the shape of the object and creates bounding box, according to bounding box information, the algorithm calculates the centroid of the object. Object coordinates are determined using centroid of the object then tracking process works by activating motors via Arduino-MATLAB communication. The motors placed on a platform called pan-tilt platform. The platform can turn 270 and 180 degrees on×and y-axis respectively.",https://ieeexplore.ieee.org/document/8090332/,2017 International Artificial Intelligence and Data Processing Symposium (IDAP),16-17 Sept. 2017,ieeexplore
10.1109/HUMANOIDS.2017.8246935,Combining deep learning for visuomotor coordination with object identification to realize a high-level interface for robot object-picking,IEEE,Conferences,"We present a proof of concept to show how a deep network for end-to-end visuomotor learning to grasp is coupled with an attention focus mechanism for state-of-the-art object detection with convolutional neural networks. The cognitively motivated integration of both methods in a single robotic system allows us to realize a high-level interface to use the visuomotor network in environments with several objects, which otherwise would only be usable in environments with a single object. The resulting system is deployed on a humanoid robot, and we perform several real-world grasping experiments that demonstrate the feasibility of our approach.",https://ieeexplore.ieee.org/document/8246935/,2017 IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids),15-17 Nov. 2017,ieeexplore
10.1109/IROS.1996.571056,Combining probabilistic map and dialog for robust life-long office navigation,IEEE,Conferences,A design of mobile robot for robust life-long navigation in office environment is proposed and evaluated. The key idea is combining probabilistic map and dialog with humans for reducing the location uncertainty. Bayesian inference with the map represented by probabilistic automata is used in order to reduce the number of queries and to evaluate the success rate of planned paths. We experimentally implemented the design using a simple Bayesian network with continuous nodes and demonstrated its effectiveness in a real environment.,https://ieeexplore.ieee.org/document/571056/,Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems. IROS '96,8-8 Nov. 1996,ieeexplore
10.1109/CYBER.2017.8446186,Comparative Study on Gesture Recognition Using Multiple Kernel Learning via Multi-mode Information Fusion,IEEE,Conferences,"An approach is introduced to the design of a multi-mode information fusion classifier to combine an inertial measurement unit with multichannel surface electromyography (sEMG) sensors to implement gesture control for a mobile robot movement, which can exceed the required control performance of vison-based methods in terms of portability, robustness, intuitiveness, and availability. A comparison of 4 groups of feature extraction project and multiple kernel relevance vector machine (MKRVM) based on multiple kernel expansion via kernel alignment were used to get better recognition performance. It was found that feature extraction method which combined time-domain analysis and time-frequency domain analysis can obtain better performance. Then, after comparing experiments, it was proved MKRVM based on multiple kernel expansion via kernel alignment not only achieved a higher recognition rate, its generalization ability was also significantly better than the traditional MKRVM. Genetic algorithms (GA) are used to optimize the best parameters for each kernel of the MKRVM algorithm. In the online robot control experiment, the gesture online identification system can accurately identify the operator gestures in real time and accurately control the youbot robot to move and do simple assembly operations.",https://ieeexplore.ieee.org/document/8446186/,"2017 IEEE 7th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)",31 July-4 Aug. 2017,ieeexplore
10.23919/ICCAS47443.2019.8971680,Comparison of Object Recognition Approaches using Traditional Machine Vision and Modern Deep Learning Techniques for Mobile Robot,IEEE,Conferences,"In this paper, we consider the problem of object recognition for a mobile robot in an indoor environment using two different vision approaches. Our first approach uses HOG descriptor with SVM classifier as traditional machine vision model while the second approach uses Tiny-YOLOv3 as modern deep learning model. The purpose of this study is to gain intuitive insight of both approaches for understanding the principles behind these techniques through their practical implementation in real world. We train both approaches with our own dataset for doors. The proposed work is assessed through the real-world implementation of both approaches using mobile robot with Zed camera in real world indoor environment and the robustness has been evaluated by comparing and analyzing the experimental results of both models on same dataset.",https://ieeexplore.ieee.org/document/8971680/,"2019 19th International Conference on Control, Automation and Systems (ICCAS)",15-18 Oct. 2019,ieeexplore
10.1109/ROBIO.2009.4913338,Complex robot training tasks through bootstrapping system identification,IEEE,Conferences,"Many sensor-motor competences in mobile robotics applications exhibit complex, non-linear characteristics. Previous research has shown that polynomial NARMAX models can learn such complex tasks. However as the complexity of the task under investigation increases, representing the whole relationship in one single model using only raw sensory inputs would lead to large models. Training such models is extremely difficult, and, furthermore, obtained models often exhibit poor performances. This paper presents a bootsrapping method of generating complex robot training tasks using simple NARMAX models. We model the desired task by combining predefined low level sensor motor controllers. The viability of the proposed method is demonstrated by teaching a Scitos GS autonomous robot to achieve complex route learning tasks in the real world robotics experiments.",https://ieeexplore.ieee.org/document/4913338/,2008 IEEE International Conference on Robotics and Biomimetics,22-25 Feb. 2009,ieeexplore
10.1109/ICIT.2002.1189341,Computer based robot training in a virtual environment,IEEE,Conferences,"As more market segments are welcoming automation, the robotic field continues to expand. With the accepted breadth of viable industrial robotic applications increasing, the need for flexible robotic training also grows. In the area of simulation and offline programming there have been innovative developments to Computer Aided Robotics (CAR) Systems. New and notable releases have been introduced to the public, especially among the small, affordable, and easy to use systems. These CAR-Systems are mainly aimed at system integrators in general industry business fields to whom the complex, powerful software tools used by the automotive industry (and its suppliers) are oversized. In general, CAR-Systems are used to design robot cells and to create the offline programs necessary to reduce start-up time and to achieve a considerable degree of planning reliability. Another potential yet to be fully considered, is the use of such CAR-Systems as an inexpensive and user-friendly tool for robotics training. This paper will show the educational potential and possibility inherent in simulation and introduce a successful example of this new method of training. Finally, this presentation should be seen as an attempt to outline novel methods for future education in an industrial environment characterized by the increased occurrence and implementation of the virtual factory.",https://ieeexplore.ieee.org/document/1189341/,"2002 IEEE International Conference on Industrial Technology, 2002. IEEE ICIT '02.",11-14 Dec. 2002,ieeexplore
10.1109/IROS.2006.282163,Conceptual Design and Implementation of Arm Wrestling Robot,IEEE,Conferences,"In this paper, we develop a novel robotic arm wrestling system integrated with mechanical arm, elbow/wrist force sensors, servo motor, encoder, 3-D MEMS accelerometer, and USB camera. The arm wrestling robot (AWR) is intended to play arm wrestling game with real human on a table for entertainment. The designing scenario of the prototype model's hardware is performed. Elbow/wrist force sensors, as a crucial device in the force sensing system, are described in details. Software is developed for device driven and interface. The surface electromyographic (EMG) signals from the upper limb are sampled when a real player competes with the force testing system. By using the method of wavelet packet transformation (WPT), the high-frequency noises can be eliminated effectively and the characteristics of EMG signals can be extracted. Artificial neural network is adopted to estimate the elbow joint torque. The effectiveness of the humanoid algorithm using torque control estimated via WRT and neural network is confirmed by experiments",https://ieeexplore.ieee.org/document/4059139/,2006 IEEE/RSJ International Conference on Intelligent Robots and Systems,9-15 Oct. 2006,ieeexplore
10.1109/IROS.2009.5354270,Consideration on robotic giant-swing motion generated by reinforcement learning,IEEE,Conferences,"This study attempts to make a compact humanoid robot acquire a giant-swing motion without any robotic models by using reinforcement learning; only the interaction with environment is available. Generally, it is widely said that this type of learning method is not appropriated to obtain dynamic motions because Markov property is not necessarily guaranteed during the dynamic task. However, in this study, we try to avoid this problem by embedding the dynamic information in the robotic state space; the applicability of the proposed method is considered using both the real robot and dynamic simulator. This paper, in particular, discusses how the robot with 5-DOF, in which the Q-Learning algorithm is implemented, acquires a giant-swing motion. Further, we describe the reward effects on the Q-Learning. Finally, this paper demonstrates that the application of the Q-Learning enable the robot to perform a very attractive giant-swing motion.",https://ieeexplore.ieee.org/document/5354270/,2009 IEEE/RSJ International Conference on Intelligent Robots and Systems,10-15 Oct. 2009,ieeexplore
10.1109/AITest.2019.00015,Constraint-Based Testing of An Industrial Multi-Robot Navigation System,IEEE,Conferences,"Intelligent multi-robot systems get more and more deployed in industrial settings to solve complex and repetitive tasks. Due to safety and economic reasons they need to operate dependably. To ensure a high degree of dependability, testing the deployed system has to be done in a rigorous way. Advanced multi-robot systems show a rich set of complex behaviors. Thus, these systems are difficult to test manually. Moreover, the space of potential environments and tasks for such systems is enormous. Therefore, methods that are able to explore this space in a structured way are needed. One way to address these issues is through model-based testing. In this paper we present an approach for testing the navigation system of a fleet of industrial transport robots. We show how all potential environments and navigation behaviors as well as requirements and restrictions can be represented in a formal constraint-based model. Moreover, we present the concept of coverage criteria in order to handle the potentially infinite space of test cases. Finally, we show how test cases can be derived from this model in an efficient way. In order to show the feasibility of the proposed approach we present an empirical evaluation of a prototype implementation using a real industrial use case.",https://ieeexplore.ieee.org/document/8718216/,2019 IEEE International Conference On Artificial Intelligence Testing (AITest),4-9 April 2019,ieeexplore
10.1109/IROS40897.2019.8967523,Contact Skill Imitation Learning for Robot-Independent Assembly Programming,IEEE,Conferences,"Robotic automation is a key driver for the advancement of technology. The skills of human workers, however, are difficult to program and seem currently unmatched by technical systems. In this work we present a data-driven approach to extract and learn robot-independent contact skills from human demonstrations in simulation environments, using a Long Short Term Memory (LSTM) network. Our model learns to generate error-correcting sequences of forces and torques in task space from object-relative motion, which industrial robots carry out through a Cartesian force control scheme on the real setup. This scheme uses forward dynamics computation of a virtually conditioned twin of the manipulator to solve the inverse kinematics problem. We evaluate our methods with an assembly experiment, in which our algorithm handles part tilting and jamming in order to succeed. The results show that the skill is robust towards localization uncertainty in task space and across different joint configurations of the robot. With our approach, non-experts can easily program force-sensitive assembly tasks in a robot-independent way.",https://ieeexplore.ieee.org/document/8967523/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/RO-MAN47096.2020.9223341,Context Dependent Trajectory Generation using Sequence-to-Sequence Models for Robotic Toilet Cleaning,IEEE,Conferences,"A robust, easy-to-deploy robot for service tasks in a real environment is difficult to construct. Record-and-playback (R&amp;P) is a method used to teach motor-skills to robots for performing service tasks. However, R&amp;P methods do not scale to challenging tasks where even slight changes in the environment, such as localization errors, would either require trajectory modification or a new demonstration. In this paper, we propose a Sequence-to-Sequence (Seq2Seq) based neural network model to generate robot trajectories in configuration space given a context variable based on real-world measurements in Cartesian space. We use the offset between a target pose and the actual pose after localization as the context variable. The model is trained using a few expert demonstrations collected using teleoperation. We apply our proposed method to the task of toilet cleaning where the robot has to clean the surface of a toilet bowl using a compliant end-effector in a constrained toilet setting. In the experiments, the model is given a novel offset context and it generates a modified robot trajectory for that context. We demonstrate that our proposed model is able to generate trajectories for unseen setups and the executed trajectory results in cleaning of the toilet bowl.",https://ieeexplore.ieee.org/document/9223341/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore
10.1109/SAUPEC/RobMech/PRASA48453.2020.9041114,Context-Aware Action with a Small Mobile Robot,IEEE,Conferences,"Simultaneous advances in mobile GPU computing and real-time object recognition now enable machines to make decisions and take actions based on the detection of objects of interest in the environment. An implementation of a mobile robot system that combines autonomous exploration and mapping capabilities with a real-time object recognition method based on a deep neural network running on a mobile GPU, is described. The system is able to detect objects of interest and then take real-time actions to interact with the objects, in this case, by moving to acquire inspection-style images of the object, from multiple angles. The robot system is small, self-contained and runs on battery power. The system shows the potential for the development of robotic systems with context awareness, permitting advanced autonomy.",https://ieeexplore.ieee.org/document/9041114/,2020 International SAUPEC/RobMech/PRASA Conference,29-31 Jan. 2020,ieeexplore
10.1109/ICARSC.2015.43,Contextual Policy Search for Generalizing a Parameterized Biped Walking Controller,IEEE,Conferences,"We investigate learning of flexible Robot locomotion controller, i.e., the controllers should be applicable for multiple contexts, for example different walking speeds, various slopes of the terrain or other physical properties of the robot. In our experiments, contexts are desired walking linear speed and the direction of the gait. Current approaches for learning control parameters of biped locomotion controllers are typically only applicable for a single context. They can be used for a particular context, for example to learn a gait with highest speed, lowest energy consumption or a combination of both. The question of our research is, how can we obtain a flexible walking controller that controls the robot (near) optimally for many different contexts? We achieve the desired flexibility of the controller by applying the recently developed contextual relative entropy policy search(REPS) method. With such a contextual policy search algorithm, we can generalize the robot walking controller for different contexts, where a context is described by a real valued vector. In this paper we also extend the contextual REPS algorithm to learn a non-linear policy instead of a linear one over the contexts. In order to validate our method, we perform a simulation experiment using a simulated NAO humanoid robot. The robot now learns a policy to choose the controller parameters for a continuous set of walking speeds and directions.",https://ieeexplore.ieee.org/document/7101605/,2015 IEEE International Conference on Autonomous Robot Systems and Competitions,8-10 April 2015,ieeexplore
10.1109/CIMCA.2005.1631373,Continuous Curvature Trajectory Generation with Obstacle Avoidance for Car-Like Robots,IEEE,Conferences,"This paper presents an extension of cubic curvature polynomial trajectory planning to include a mechanism for obstacle avoidance. Cubic polynomials have been used to describe curvature continuous trajectories for car like robots. From known start and end robot postures, (position, orientation and curvature) a continuous trajectory can be decided. We extend cubic polynomial trajectories to fourth order polynomials, and introduce a cost function, describing accumulated distance to obstacles along a trajectory, to the robot posture vector. Such trajectories, generated by a gradient descent method, satisfy continuity constraints and avoid obstacles. The method is implemented on a mobile robot system and experiments in real time trajectory planning and execution are conducted",https://ieeexplore.ieee.org/document/1631373/,"International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC'06)",28-30 Nov. 2005,ieeexplore
10.1109/ICEEE.2011.6106626,Continuous-time neural control for a 2 DOF vertical robot manipulator,IEEE,Conferences,"This paper presents a continuous-time neural control scheme for identification and control of a two degrees of freedom (DOF) direct drive vertical robot manipulator model, on which effects due to friction and gravitational forces are both considered. A recurrent high-order neural network (RHONN) structure is proposed in order to identify the plant model to then, based on this neural structure, derive a neural controller using the backstepping design methodology. The trajectory tracking performance of the neural controller is illustrated via simulations results, which suggest the validity of the proposed approach for its implementation in real-time.",https://ieeexplore.ieee.org/document/6106626/,"2011 8th International Conference on Electrical Engineering, Computing Science and Automatic Control",26-28 Oct. 2011,ieeexplore
10.1109/WHC.2011.5945522,Control of a desktop mobile haptic interface,IEEE,Conferences,"Most haptic devices share two main limits: they are grounded and they have limited workspace. A possible solution is to create haptic interfaces by combining mobile robots and standard grounded force-feedback devices, the so called Mobile Haptic Interfaces (MHIs). However, MHIs are characterized by dynamical limitations due to performance of the employed devices. This paper focuses on basic design issues and presents a novel (prototype) Mobile Haptics Platform that employs the coordination of numerically controlled wheel torques to render forces to a user handle placed on the top of the device. The interface, consisting in a small omni-directional robot, is link-less, fully portable and it has been designed to support home-rehabilitation exercises. In the present paper we shall review relevant choices concerning the functional aspects and the control design. In particular a specific embedded sensor fusion was implemented to allow the device to move on a desk without drifting. The sensor fusion algorithm has been optimized to provide users with a quality force feedback while ensuring accurate position tracking. The two requirements are in contrast each other and a specific variant of the Extended Kalman Filter (EKF) was required to allow the device working.",https://ieeexplore.ieee.org/document/5945522/,2011 IEEE World Haptics Conference,21-24 June 2011,ieeexplore
10.1109/IROS.2012.6385803,Control of contact forces: The role of tactile feedback for contact localization,IEEE,Conferences,"This paper investigates the role of precise estimation of contact points in force control. This analysis is motivated by scenarios in which robots make contacts, either voluntarily or accidentally, with different parts of their body. Control paradigms that are usually implemented in robots with no tactile system, make the hypothesis that contacts occur at the end-effectors only. In this paper we try to investigate what happens when this assumption is not verified. First we consider a simple feedforward force control law, and then we extend it by introducing a proportional feedback term. For both controllers we find the error in the resulting contact force, that is induced by a hypothetic error in the estimation of the contact point. We show that, depending on the geometry of the contact, incorrect estimation of contact points can induce undesired joint accelerations. We validate the presented analysis with tests on a simulated robot arm. Moreover we consider a complex real world scenario, where most of the assumptions that we make in our analytical derivation do not hold. Through tests on the iCub humanoid robot we see how errors in contact localization affect the performance of a parallel force/position controller. In order to estimate contact points and contact forces on the forearm of the iCub we do not use any model of the environment, but we exploit its 6-axis force/torque sensor and its sensorized skin.",https://ieeexplore.ieee.org/document/6385803/,2012 IEEE/RSJ International Conference on Intelligent Robots and Systems,7-12 Oct. 2012,ieeexplore
10.1109/AUV.2016.7778702,Convolutional neural network-based real-time ROV detection using forward-looking sonar image,IEEE,Conferences,"Agent system is strategy to enhance the underwater manipulation. The conventional manipulation is generally robot arm-based configuration which has singular points. On the other hand, the agent system is an armless manipulation that the agent vehicle works as the end-effector. If the location of the agent can be measured, the end effector is able to be place to any position. To implement this system, the method of an agent vehicle localization is proposed. The method uses the sonar images of moving agent obtained by forward-looking sonar. To detect the location of the agent in the sonar images, the convolutional neural network is applied. We applied the state-of-art object-detection algorithm to the agent vehicle system. The fast object-detection algorithm based on neural network can fulfil the real-time detection and show the remarkable validity. It means the underwater robot can begin navigation under its feed-back. Through field experiment, we confirm the proposed method can detect and track the agent in the successive sonar images.",https://ieeexplore.ieee.org/document/7778702/,2016 IEEE/OES Autonomous Underwater Vehicles (AUV),6-9 Nov. 2016,ieeexplore
10.1109/ICRA40945.2020.9197209,Cooperative Multi-Robot Navigation in Dynamic Environment with Deep Reinforcement Learning,IEEE,Conferences,"The challenges of multi-robot navigation in dynamic environments lie in uncertainties in obstacle complexities, partially observation of robots, and policy implementation from simulations to the real world. This paper presents a cooperative approach to address the multi-robot navigation problem (MRNP) under dynamic environments using a deep reinforcement learning (DRL) framework, which can help multiple robots jointly achieve optimal paths despite a certain degree of obstacle complexities. The novelty of this work includes threefold: (1) developing a cooperative architecture that robots can exchange information with each other to select the optimal target locations; (2) developing a DRL based framework which can learn a navigation policy to generate the optimal paths for multiple robots; (3) developing a training mechanism based on dynamics randomization which can make the policy generalized and achieve the maximum performance in the real world. The method is tested with Gazebo simulations and 4 differential drive robots. Both simulation and experiment results validate the superior performance of the proposed method in terms of success rate and travel time when compared with the other state-of-art technologies.",https://ieeexplore.ieee.org/document/9197209/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ICCAS.2007.4407004,Cooperative behavior acquisition of multiple autonomous mobile robots by an objective-based reinforcement learning system,IEEE,Conferences,"The present paper proposes an objective-based reinforcement learning system for multiple autonomous mobile robots to acquire cooperative behavior. The proposed system employs profit sharing (PS) as a learning method. A major characteristic of the system is using two kinds of PS tables. One is to learn cooperative behavior using information on other agents' positions and the other is to learn how to control basic movements. Through computer simulation and real robot experiment using a garbage-collection problem, the performance of the proposed system is evaluated. As a result, it is verified that agents select the most available garbage for cooperative behavior using visual information in an unknown environment and move to the target avoiding obstacles.",https://ieeexplore.ieee.org/document/4407004/,"2007 International Conference on Control, Automation and Systems",17-20 Oct. 2007,ieeexplore
10.1109/IROS.2012.6385982,Cooperative sensing and recognition by a swarm of mobile robots,IEEE,Conferences,"We present an approach for distributed real-time recognition tasks using a swarm of mobile robots. We focus on the visual recognition of hand gestures, but the solutions that we provide have general applicability and address a number of challenges common to many distributed sensing and classification problems. In our approach, robots acquire and process hand images from multiple points of view, most of which do not allow for a satisfactory classification. Each robot is equipped with a statistical classifier, which is used to generate an opinion for the sensed gesture. Using a low-bandwidth wireless channel, the robots locally exchange their opinions. They also exploit mobility to adapt their positions to maximize the mutual information collectively gathered by the swarm. A distributed consensus protocol is implemented, to allow to rapidly settle on a decision once enough evidence is available. The system is implemented and demonstrated on real robots. In addition, extensive quantitative results of emulation experiments, based on a real image dataset, are reported. We consider different scenarios and study the scalability and the robustness of the swarm performance for distributed recognition.",https://ieeexplore.ieee.org/document/6385982/,2012 IEEE/RSJ International Conference on Intelligent Robots and Systems,7-12 Oct. 2012,ieeexplore
10.1109/RCAR.2016.7784079,Coordination control of dual-arm robot based on modeled predictive control,IEEE,Conferences,"This paper presents a master-slave force hybrid coordinated motion control method which is based on the model predictive control (MPC) algorithm. In the paper, the kinematics model of the dual 6-DOF arms is build. Six axis force sensors are installed at the ends of the two arms, the master arm adopts the position control method and the based on the model predictive control algorithm DMC theory force/position hybrid control method is adopted in the slave arm. According to the kinematic model of the dual-arms, the end pose and joint angle rule conversion library is established, and the motion prediction model of the manipulator also is established. By using these models, the slave arm can acquire the position and direction of the master arm synchronously, and the current end position of the master arm is also used as the reference input value of the end position of the slave arm. The rotation operation sequence of the joint angle rule conversion library predicted model and end pose apply to the joint motor, drive the end of the robot arm to move to the target position. After doing these we could synchronously realize position tracking. In our experiment the current position tracking could be realized through the simulation analysis of six degree of freedom dual arm robot.",https://ieeexplore.ieee.org/document/7784079/,2016 IEEE International Conference on Real-time Computing and Robotics (RCAR),6-10 June 2016,ieeexplore
10.1109/IROS.2014.6942970,Coordination in human-robot teams using mental modeling and plan recognition,IEEE,Conferences,"Beliefs play an important role in human-robot teaming scenarios, where the robots must reason about other agents' intentions and beliefs in order to inform their own plan generation process, and to successfully coordinate plans with the other agents. In this paper, we cast the evolving and complex structure of beliefs, and inference over them, as a planning and plan recognition problem. We use agent beliefs and intentions modeled in terms of predicates in order to create an automated planning problem instance, which is then used along with a known and complete domain model in order to predict the plan of the agent whose beliefs are being modeled. Information extracted from this predicted plan is used to inform the planning process of the modeling agent, to enable coordination. We also look at an extension of this problem to a plan recognition problem. We conclude by presenting an evaluation of our technique through a case study implemented on a real robot.",https://ieeexplore.ieee.org/document/6942970/,2014 IEEE/RSJ International Conference on Intelligent Robots and Systems,14-18 Sept. 2014,ieeexplore
10.1109/IROS.2018.8593374,Cost of Transport Estimation for Legged Robot Based on Terrain Features Inference from Aerial Scan,IEEE,Conferences,"The effectiveness of the robot locomotion can be measured using the cost of transport (CoT) which represents the amount of energy that is needed for traversing from one place to another. Terrains excerpt different mechanical properties when crawled by a multi-legged robot, and thus different values of the CoT. It is therefore desirable to estimate the CoT in advance and plan the robot motion accordingly. However, the CoT might not be known prior the robot deployment, e.g., in extraterrestrial missions; hence, a robot has to learn different terrains as it crawls through the environment incrementally. In this work, we focus on estimating the CoT from visual and geometrical data of the crawled terrain. A thorough analysis of different terrain descriptors within the context of incremental learning is presented to select the best performing approach. We report on the achieved results and experimental verification of the selected approaches with a real hexapod robot crawling over six different terrains.",https://ieeexplore.ieee.org/document/8593374/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/IROS.2014.6942768,Crowdsourcing as a methodology to obtain large and varied robotic data sets,IEEE,Conferences,"For autonomous robots to operate successfully in unknown environments, their computer vision algorithms need to generalize over many different environments. However, due to practical considerations robotic vision experiments are typically limited to a single robot and a few (laboratory) environments. We propose crowdsourcing as a methodology for gathering large and varied robotic data sets. We evaluate the methodology by performing the first crowdsourcing experiment involving actual robots. In particular, we have made a space-game called `Astro Drone' for a toy quad rotor, the Parrot AR drone. Nine months after the game's release, there are 14,628 downloads and 840 contributions, consisting of visual features and drone state estimates. Data mining shows the methodology's potential, providing insights such as the relation between the number of visual features and obstacle distances.",https://ieeexplore.ieee.org/document/6942768/,2014 IEEE/RSJ International Conference on Intelligent Robots and Systems,14-18 Sept. 2014,ieeexplore
10.1109/ROMAN.2018.8525717,Data-driven development of Virtual Sign Language Communication Agents,IEEE,Conferences,"Engaging deaf and hearing people in common discussions requires interfaces to help them understand each other, such as robot agents that translate spoken language into Sign Language (SL) expressions and vice-versa. However, the recognition and generation of signed sentences is a complex task of high dimensionality that cannot be solved in sufficient quality yet. Thus, it is necessary to develop new technologies of improved performances. The sequence to sequence neural network model, traditionally used for machine translation, is adapted to the above two tasks by treating a SL sequence as a multi-dimensional sentence. We defined an encoding of the SL annotations and conducted experiments on the network structure to define a most accurate translation model. This study proves the network trainable and possibly applicable in real-life with an extended dataset, which shall be tested for deployment in virtual translation assistants in the following.",https://ieeexplore.ieee.org/document/8525717/,2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),27-31 Aug. 2018,ieeexplore
10.1109/ICRA48506.2021.9561066,Decentralized Connectivity Maintenance with Time Delays using Control Barrier Functions,IEEE,Conferences,"Connectivity maintenance is crucial for the real world deployment of multi-robot systems, as it ultimately allows the robots to communicate, coordinate and perform tasks in a collaborative way. A connectivity maintenance controller must keep the multi-robot system connected independently from the system’s mission and in the presence of undesired real world effects such as communication delays, model errors, and computational time delays, among others. In this paper we present the implementation, on a real robotic setup, of a connectivity maintenance control strategy based on Control Barrier Functions. During experimentation, we found that the presence of communication delays has a significant impact on the performance of the controlled system, with respect to the ideal case. We propose a heuristic to counteract the effects of communication delays, and we verify its efficacy both in simulation and with physical robot experiments.",https://ieeexplore.ieee.org/document/9561066/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICRA.2016.7487617,Decentralized multi-agent exploration with online-learning of Gaussian processes,IEEE,Conferences,"Exploration is a crucial problem in safety of life applications, such as search and rescue missions. Gaussian processes constitute an interesting underlying data model that leverages the spatial correlations of the process to be explored to reduce the required sampling of data. Furthermore, multi-agent approaches offer well known advantages for exploration. Previous decentralized multi-agent exploration algorithms that use Gaussian processes as underlying data model, have only been validated through simulations. However, the implementation of an exploration algorithm brings difficulties that were not tackle yet. In this work, we propose an exploration algorithm that deals with the following challenges: (i) which information to transmit to achieve multi-agent coordination; (ii) how to implement a light-weight collision avoidance; (iii) how to learn the data's model without prior information. We validate our algorithm with two experiments employing real robots. First, we explore the magnetic field intensity with a ground-based robot. Second, two quadcopters equipped with an ultrasound sensor explore a terrain profile. We show that our algorithm outperforms a meander and a random trajectory, as well as we are able to learn the data's model online while exploring.",https://ieeexplore.ieee.org/document/7487617/,2016 IEEE International Conference on Robotics and Automation (ICRA),16-21 May 2016,ieeexplore
10.1109/Humanoids43949.2019.9035031,Deep Correspondence Learning for Effective Robotic Teleoperation using Virtual Reality,IEEE,Conferences,"By projecting into a 3-D workspace, robotic teleoperation using virtual reality allows for a more intuitive method of control for the operator than using a 2-D view from the robot's visual sensors. This paper investigates a setup that places the teleoperator in a virtual representation of the robot's environment and develops a deep learning based architecture modeling the correspondence between the operator's movements in the virtual space and joint angles for a humanoid robot using data collected from a series of demonstrations. We evaluate the correspondence model's performance in a pick-and - place teleoperation experiment.",https://ieeexplore.ieee.org/document/9035031/,2019 IEEE-RAS 19th International Conference on Humanoid Robots (Humanoids),15-17 Oct. 2019,ieeexplore
10.1109/IROS40897.2019.8967874,Deep Dive into Faces: Pose &amp; Illumination Invariant Multi-Face Emotion Recognition System,IEEE,Conferences,"One of the advancements in humanization of robots is its ability to recognize human emotions. Facial expression plays a key role in identifying human emotions relative to other cues. In this research, an intelligent network capable of real-time emotion recognition from multiple faces using deep learning technique is presented. The proposed network is based on Convolution Neural Network (CNN) in which three blocks of Convolution layers for feature extraction and two blocks of Dense layers for classification are used. The novelty of this method lies in recognizing emotions from multiple faces simultaneously in real time and its invariance to head pose, illumination and age factor. Most of reported work in literature for multiple faces is for frontal face without illumination variation. The proposed emotion recognition system is deployed on Raspberry Pi3 B+ for human robot interaction applications and achieved an average accuracy of 95.8% in real time.",https://ieeexplore.ieee.org/document/8967874/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.23919/ChiCC.2018.8483142,Deep Generative Network and Regression Network for Fishing Nets Detection in Real-time,IEEE,Conferences,"The problem that the underwater robot is winded by fishing nets is the most concerned. At present, there are still no effective methods which can detect fishing nets in real time to avoid obstacles. As fishing net images taken with traditional detection technique are blurry and have low definition, it is hard to identify fishing nets. In view of this phenomenon, we proposed a new underwater detection method in this paper and used underwater laser scanning system to collect clear fishing net images. Due to the high cost of data acquisition and the single amount of experiment data, we took advantage of a deep generative network to amplify original data. In fishing nets detection network, we used a residual network as new base net to deepen the network layers, then combined the method of regression with some region suggestion to detect fishing nets, which can improve the accuracy of fishing nets detection without affecting the real-time performance. Finally, the contrast experiment of laser fishing net images is carried out to verify the effectiveness of the proposed method.",https://ieeexplore.ieee.org/document/8483142/,2018 37th Chinese Control Conference (CCC),25-27 July 2018,ieeexplore
10.1109/ICRoM48714.2019.9071857,Deep Learning Approach For Object Tracking Of RoboEye,IEEE,Conferences,"RoboEye is a spherical 3RRR parallel robot which has been developed for its high precision. It can provide high speeds, so can be used for fast tracking tasks. To this end, in this paper proper deep learning approaches are combined with classical control methods. Deep learning algorithms are employed to detect an object of interest among various ones in a monocular image, and then obtain an estimatation of the distance to the camera. So, simultaneous depth estimation, and object detection with a monocular camera for real time implementation is proposed here. For fast calculations, also to overcome manufacturing uncertainties, inverse kinematic equations are computed by a multi-layer perceptron (MLP) network based on real data. Finally, a classical PID controller can perform a fast tracking of the object.",https://ieeexplore.ieee.org/document/9071857/,2019 7th International Conference on Robotics and Mechatronics (ICRoM),20-21 Nov. 2019,ieeexplore
10.1109/ICRA.2019.8794187,Deep Learning based Motion Prediction for Exoskeleton Robot Control in Upper Limb Rehabilitation,IEEE,Conferences,"The synchronization of the movement between exoskeleton robot and human arm is crucial for Robot-assisted training (RAT) in upper limb rehabilitation. In this paper, we propose a deep learning based motion prediction model which is applied to our recently developed 8 degrees-of-freedom (DoFs) upper limb rehabilitation exoskeleton, named NTUH-II. The human arm dynamics and surface electromyography (sEMG) can be first measured by two wireless sensors and used as input of deep learning model to predict user's motion. Then, the prediction can be used as desired motion trajectory of the exoskeleton. As a result, the robot arm can follow the movement on either side of the user's arm in real-time. Various experiments have been conducted to verify the performance of the proposed motion prediction model, and the results show that the proposed motion prediction implementation can reduce the mean absolute error and the average delay time of movement between human arm and robot arm.",https://ieeexplore.ieee.org/document/8794187/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/BioRob49111.2020.9224272,Deep Learning of Movement Intent and Reaction Time for EEG-informed Adaptation of Rehabilitation Robots,IEEE,Conferences,"Mounting evidence suggests that adaptation is a crucial mechanism for rehabilitation robots in promoting motor learning. Yet, it is commonly based on robot-derived movement kinematics, which is a rather subjective measurement of performance, especially in the presence of a sensorimotor impairment. Here, we propose a deep convolutional neural network (CNN) that uses electroencephalography (EEG) as an objective measurement of two kinematics components that are typically used to assess motor learning and thereby adaptation: i) the intent to initiate a goal-directed movement, and ii) the reaction time (RT) for that movement. We evaluated our CNN on data acquired from an in-house experiment where 12 healthy subjects moved a rehabilitation robotic arm in four directions on a plane, in response to visual stimuli. Our CNN achieved average test accuracies of 80.08% and 79.82% in a binary classification of the intent (intent vs. no intent) and RT (slow vs. fast), respectively. Our results demonstrate how individual movement components implicated in distinct types of motor learning can be predicted from synchronized EEG data acquired before the start of the movement. Our approach can, therefore, inform robotic adaptation in real-time and has the potential to further improve one's ability to perform the rehabilitation task.",https://ieeexplore.ieee.org/document/9224272/,2020 8th IEEE RAS/EMBS International Conference for Biomedical Robotics and Biomechatronics (BioRob),29 Nov.-1 Dec. 2020,ieeexplore
10.1109/R10-HTC.2018.8629836,Deep Learning-Based Eye Gaze Controlled Robotic Car,IEEE,Conferences,"In recent years Eye gaze tracking (EGT) has emerged as an attractive alternative to conventional communication modes. Gaze estimation can be effectively used in human-computer interaction, assistive devices for motor-disabled persons, autonomous robot control systems, safe car driving, diagnosis of diseases and even in human sentiment assessment. Implementation in any of these areas however mostly depends on the efficiency of detection algorithm along with usability and robustness of detection process. In this context we have proposed a Convolutional Neural Network (CNN) architecture to estimate the eye gaze direction from detected eyes which outperforms all other state of the art results for Eye-Chimera dataset. The overall accuracies are 90.21% and 99.19% for Eye-Chimera and HPEG datasets respectively. This paper also introduces a new dataset EGDC for which proposed algorithm finds 86.93% accuracy. We have developed a real-time eye gaze controlled robotic car as a prototype for possible implementations of our algorithm.",https://ieeexplore.ieee.org/document/8629836/,2018 IEEE Region 10 Humanitarian Technology Conference (R10-HTC),6-8 Dec. 2018,ieeexplore
10.1109/MSM49833.2020.9201666,Deep Learning-based Algorithm for Mobile Robot Control in Textureless Environment,IEEE,Conferences,"For the implementation of stereo image-based visual servoing algorithm in the eye-in-hand robotics applications, one of the main concerns is the accurate point feature detection and matching algorithm. Since the visual servoing is carried out in the textureless environment, the feature detection process is even more challenging. To fulfill the requirement of a robust and reliable point feature detection process, in this paper we present the novel deep learning-based algorithm. The approach based on convolutional neural networks and algorithm for detection of manufacturing entities is proposed and detected regions of interest are utilized for the improvement of the point feature detection algorithm. The proposed algorithm is experimentally evaluated in real-world settings by using wheeled nonholonomic mobile robot RAICO equipped with stereo vision system. The experimental results show the improvement of 58% in the accuracy of matched point features in the images obtained during the visual servoing process. Moreover, with the implementation of the proposed deep learning-based approach, the number of successful experimental runs has increased by 80%.",https://ieeexplore.ieee.org/document/9201666/,2020 International Conference Mechatronic Systems and Materials (MSM),1-3 July 2020,ieeexplore
10.1109/ICRA48506.2021.9561729,Deep Neuromorphic Controller with Dynamic Topology for Aerial Robots,IEEE,Conferences,"Current aerial robots are increasingly adaptive; they can morph to enable operation in changing conditions to complete diverse missions. Each mission may require the robot to conduct a different task. A conventional learning approach can handle these variations when the system is trained for similar tasks in a representative environment. However, it may result in overfitting to the new data stream or the failure to adapt, leading to degradation or a potential crash. These problems can be mitigated with an excessive amount of data and embedded model, but the computational power and the memory of the aerial robots are limited. In order to address the variations in the model, environment as well as the tasks within onboard computation limitations, we propose a deep neuromorphic controller approach with variable topologies to handle each different condition and the data stream with a feasible computation and memory allocation. The proposed approach is based on a deep neuromorphic (multi and variable layered neural network) controller with dynamic depth and progressive layer adaptation for each new data stream. This adaptive structure is combined with a switching function to form a sliding mode controller. The network parameter update rule guarantees the stability of the closed loop system by the convergence of the error dynamics to the sliding surface. Being the first implementation on an aerial robot in this context, the results illustrate the adaptation capability, stability, computational efficiency as well as the real-time validation.",https://ieeexplore.ieee.org/document/9561729/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ROBIO.2018.8665274,Deep Reinforcement Learning Based Brachiation Control for Two-Link Bio-Primate Robot,IEEE,Conferences,"Manually designing an effective and efficient controller for complex mechanics, such as bio-inspired robots or underactuated mechanical system, typically are very difficult. It requires precise motion planning and dynamic control. Reinforcement learning or genetic algorithm based learning methods suffers from representing the high dimensional models. The combination of deep learning and reinforcement learning provide a feasible way to handle such difficulties. However, priori-less searching sometimes tends to be low efficient and usually finds the “mechanic” solution instead of the “natural” one. In this paper, the traditional nonlinear control concept is integrated into the deep reinforcement learning (DRL) framework. The whole process is implemented on the brachiation control problem of a two link bio-primate robot. Deep Deterministic Policy Gradient (DDPG) is used to search for the optimal control policy. The searching process is realized by interacting with the dynamic model instead of real robot. The energy based planning and control concept is adopted, which utilize the fact that when the shoulder joint angle is fixed, energy of the whole system keeps constant. By regulating the angle and energy, the robot can be restricted on a particular trajectory. The energy concept is encoded within the reward function and trained in the Gym environment. For varying targets point-to-point control, the network structure is also modified to accept the target coordinates. Effectiveness of the proposed methods are verified by simulation and experimental results.",https://ieeexplore.ieee.org/document/8665274/,2018 IEEE International Conference on Robotics and Biomimetics (ROBIO),12-15 Dec. 2018,ieeexplore
10.23919/ICCAS47443.2019.8971637,Deep Reinforcement Learning Based Robot Arm Manipulation with Efficient Training Data through Simulation,IEEE,Conferences,"Deep reinforcement learning trains neural networks using experiences sampled from the replay buffer, which is commonly updated at each time step. In this paper, we propose a method to update the replay buffer adaptively and selectively to train a robot arm to accomplish a suction task in simulation. The response time of the agent is thoroughly taken into account. The state transitions that remain stuck at the boundary of constraint are not stored. The policy trained with our method works better than the one with the common replay buffer update method. The result is demonstrated both by simulation and by experiment with a real robot arm.",https://ieeexplore.ieee.org/document/8971637/,"2019 19th International Conference on Control, Automation and Systems (ICCAS)",15-18 Oct. 2019,ieeexplore
10.1109/SoutheastCon44009.2020.9249654,Deep Reinforcement Learning For Visual Navigation of Wheeled Mobile Robots,IEEE,Conferences,"A study is presented on applying deep reinforcement learning (DRL) for visual navigation of wheeled mobile robots (WMR) in dynamic and unknown environments. Two DRL algorithms, namely, value-learning deep Q-network (DQN) and policy gradient based asynchronous advantage actor critic ( A 3C), have been considered. RGB (red, green and blue) and depth images have been used as inputs in implementation of both DRL algorithms to generate control commands for autonomous navigation of WMR in simulation environments. The initial DRL networks were generated and trained progressively in OpenAI Gym Gazebo based simulation environments within robot operating system (ROS) framework for a popular target WMR, Kobuki TurtleBot2. A pre-trained deep neural network ResNet50 was used after further training with regrouped objects commonly found in laboratory setting for target-driven mapless visual navigation of Turlebot2 through DRL. The performance of A 3C with multiple computation threads (4, 6, and 8) was simulated on a desktop. The navigation performance of DQN and A 3C networks, in terms of reward statistics and completion time, was compared in three simulation environments. As expected, A 3C with multiple threads (4, 6, and 8) performed better than DQN and the performance of A 3C improved with number of threads. Details of the methodology, simulation results are presented and recommendations for future work towards real-time implementation through transfer learning of the DRL models are outlined.",https://ieeexplore.ieee.org/document/9249654/,2020 SoutheastCon,28-29 March 2020,ieeexplore
10.1109/ICRA48506.2021.9561145,Deep Reinforcement Learning Framework for Underwater Locomotion of Soft Robot,IEEE,Conferences,"Soft robotics is an emerging technology with excellent application prospects. However, due to the inherent compliance of the materials used to build soft robots, it is extremely complicated to control soft robots accurately. In this paper, we introduce a data-based control framework for solving the soft robot underwater locomotion problem using deep reinforcement learning (DRL). We first built a soft robot that can swim based on the dielectric elastomer actuator (DEA). We then modeled it in a simulation for the purpose of training the neural network and tested the performance of the control framework through real experiments on the robot. The framework includes the following: a simulation method for the soft robot that can be used to collect data for training the neural network, the neural network controller of the swimming robot trained in the simulation environment, and the computer vision method to collect the observation space from the real robot using a camera. We confirmed the effectiveness of the learning method for the soft swimming robot in the simulation environment by allowing the robot to learn how to move from a random initial state to a specific direction. After obtaining the trained neural network through the simulation, we deployed it on the real robot and tested the performance of the control framework. The soft robot successfully achieved the goal of moving in a straight line in disturbed water. The experimental results suggest the potential of using deep reinforcement learning to improve the locomotion ability of mobile soft robots.",https://ieeexplore.ieee.org/document/9561145/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/WCNC45663.2020.9120611,Deep Reinforcement Learning based Indoor Air Quality Sensing by Cooperative Mobile Robots,IEEE,Conferences,"Confronted with the severe indoor air pollution nowadays, we propose the usage of multiple robots to detect the indoor air quality (IAQ) cooperatively for fewer sensors and larger sensing area. To acquire the complete real-time IAQ distribution map, we exploit the real statistical data to construct the IAQ data model and adopt Kalman Filter to obtain the estimation of the unmeasured area. Since the movement of the robots affects the estimation accuracy, a proper movement strategy should be planned to minimize the total estimation error. To solve this optimization problem, we design a deep Q-learning approach, which provides sub-optimal movement strategies for real-time robot sensing. By simulations, we verify the adopted IAQ data model and testify the effectiveness of the proposed solution. For application considerations, we have deployed this system in Peking University since Dec. 2018 and developed a website to visualize the IAQ distribution.",https://ieeexplore.ieee.org/document/9120611/,2020 IEEE Wireless Communications and Networking Conference (WCNC),25-28 May 2020,ieeexplore
10.1109/IROS.2018.8594327,Deep Reinforcement Learning for Audio-Visual Gaze Control,IEEE,Conferences,"We address the problem of audio-visual gaze control in the specific context of human-robot interaction, namely how controlled robot motions are combined with visual and acoustic observations in order to direct the robot head towards targets of interest. The paper has the following contributions: (i) a novel audio-visual fusion framework that is well suited for controlling the gaze of a robotic head; (ii) a reinforcement learning (RL) formulation for the gaze control problem, using a reward function based on the available temporal sequence of camera and microphone observations; and (iii) several deep architectures that allow to experiment with early and late fusion of audio and visual data. We introduce a simulated environment that enables us to learn the proposed deep RL model without the need of spending hours of tedious interaction. By thoroughly experimenting on a publicly available dataset and on a real robot, we provide empirical evidence that our method achieves state-of-the-art performance.",https://ieeexplore.ieee.org/document/8594327/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ASCC.2017.8287420,Deep learning for picking point detection in dense cluster,IEEE,Conferences,"This paper considers the problem of picking objects in cluster. This requires the robot to reliably detect the picking point for the known or unseen objects under the environment with occlusion, disorder and a variety of objects. We present a novel pipeline to detect picking point based on deep convolutional neural network (CNN). A two-dimensional picking configuration is proposed, thus an extensive data augmentation strategy is enabled and a labeled dataset is established quickly and easily. At last, we demonstrate the implementation of our method on a real robot and show that our method can accurately detect picking point of unseen objects and achieve a pick success of 91% in cluster bin-picking scenario.",https://ieeexplore.ieee.org/document/8287420/,2017 11th Asian Control Conference (ASCC),17-20 Dec. 2017,ieeexplore
10.1109/IROS.2017.8206046,Deep predictive policy training using reinforcement learning,IEEE,Conferences,"Skilled robot task learning is best implemented by predictive action policies due to the inherent latency of sensorimotor processes. However, training such predictive policies is challenging as it involves finding a trajectory of motor activations for the full duration of the action. We propose a data-efficient deep predictive policy training (DPPT) framework with a deep neural network policy architecture which maps an image observation to a sequence of motor activations. The architecture consists of three sub-networks referred to as the perception, policy and behavior super-layers. The perception and behavior super-layers force an abstraction of visual and motor data trained with synthetic and simulated training samples, respectively. The policy super-layer is a small subnetwork with fewer parameters that maps data in-between the abstracted manifolds. It is trained for each task using methods for policy search reinforcement learning. We demonstrate the suitability of the proposed architecture and learning framework by training predictive policies for skilled object grasping and ball throwing on a PR2 robot. The effectiveness of the method is illustrated by the fact that these tasks are trained using only about 180 real robot attempts with qualitative terminal rewards.",https://ieeexplore.ieee.org/document/8206046/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/ROMAN.2017.8172429,Deep recurrent Q-learning of behavioral intervention delivery by a robot from demonstration data,IEEE,Conferences,"We present a learning from demonstration (LfD) framework that uses a deep recurrent Q-network (DRQN) to learn how to deliver a behavioral intervention (BI) from demonstrations performed by a human. The trained DRQN enables a robot to deliver a similar BI in an autonomous manner. BIs are highly structured procedures wherein children with developmental delays/disorders (e.g. autism, ADHD, etc.) are trained to perform new behaviors and life-skills. Mounting anecdotal evidence from human-robot interaction (HRI) research has shown that BI benefits from the use of robots as a delivery tool. Most of the HRI research on robot-based intervention relies on tele-operated robots. However, the need for autonomy has become increasingly evident, especially when it comes to the real-world deployment of these systems. The few studies that have used autonomy in robot-based BI relied on hand-picked features of the environment in order to trigger correct robot actions. Additionally, none of these automated architectures attempted to learn the BI from human demonstrations, though this appears to be the most natural way of learning. This paper represents the first attempt to design a robot that uses LfD to learn BI. We generate a model then correctly predict appropriate actions with greater than 80% accuracy. To the best of our knowledge, this is the first attempt to employ DRQN within an LfD framework to learn high level reasoning embedded in human actions and behaviors simply from observations.",https://ieeexplore.ieee.org/document/8172429/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/RCAR49640.2020.9303294,Deep-Learning Based Robotic Manipulation of Flexible PCBs,IEEE,Conferences,"In the past 10 years, due to the fast development of 3C industries such as mobile phones and computers, people have higher requirements for the automatic soldering technology of flexible PCBs. However, the deformation and the small size of flexible PCBs open up significant challenges to robotic soldering. This paper proposes a deep-learning based manipulation scheme for automatic soldering of flexible PCBs. The proposed controller can enable the robot to automatically contact the flexible PCB first, then actively control the flexible PCB to the desired position with the visual feedback, and finally, the soldering machine will solder the flexible PCBs smoothly. First, the approach of deep learning is used to detect the position of the solder pad (feature). Then, the vision-based controller drives the robot to manipulate the solder pad to the desired position, such that the soldering machine can work to solder two pieces of flexible PCBs together. The use of a deep learning approach can explore the human's experience to improve the accuracy of detection and hence deals with the issues of clustered environment, change of illumination, and different initial position, etc. The proposed detection approach and control scheme is implemented in a soldering robot for flexible PCBs and the results validate the performance of the proposed methods.",https://ieeexplore.ieee.org/document/9303294/,2020 IEEE International Conference on Real-time Computing and Robotics (RCAR),28-29 Sept. 2020,ieeexplore
10.1109/CVPR.2019.00346,DenseFusion: 6D Object Pose Estimation by Iterative Dense Fusion,IEEE,Conferences,"A key technical challenge in performing 6D object pose estimation from RGB-D image is to fully leverage the two complementary data sources. Prior works either extract information from the RGB image and depth separately or use costly post-processing steps, limiting their performances in highly cluttered scenes and real-time applications. In this work, we present DenseFusion, a generic framework for estimating 6D pose of a set of known objects from RGB-D images. DenseFusion is a heterogeneous architecture that processes the two data sources individually and uses a novel dense fusion network to extract pixel-wise dense feature embedding, from which the pose is estimated. Furthermore, we integrate an end-to-end iterative pose refinement procedure that further improves the pose estimation while achieving near real-time inference. Our experiments show that our method outperforms state-of-the-art approaches in two datasets, YCB-Video and LineMOD. We also deploy our proposed method to a real robot to grasp and manipulate objects based on the estimated pose.",https://ieeexplore.ieee.org/document/8953386/,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),15-20 June 2019,ieeexplore
10.1109/ICRA.2013.6631325,Deploying artificial landmarks to foster data association in simultaneous localization and mapping,IEEE,Conferences,"Data association is an essential problem in simultaneous localization and mapping. It is hard to solve correctly, especially in ambiguous environments. We consider a scenario where the robot can ease the data association problem by deploying a limited number of uniquely identifiable artificial landmarks along its path and use them afterwards as fixed anchors. Obviously, the choice of the positions where the robot should drop these markers is crucial as poor choices might prevent the robot from establishing accurate data associations. In this paper, we present a novel approach for learning when to drop the landmarks so as to optimize the data association performance. We use Monte Carlo reinforcement learning for computing an optimal policy and apply a statistical convergence test to decide if the policy is converged and the learning process can be stopped. Extensive experiments also carried out with a real robot demonstrate that the data association performance using landmarks deployed according to our learned policies is significantly higher compared to other strategies.",https://ieeexplore.ieee.org/document/6631325/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/SIU.2010.5652736,Derivation of gaze direction from head pose estimates,IEEE,Conferences,"Automatic estimation of gaze direction information is important for certain applications of human-robot and human-computer interaction. Depending on the properties of the specific application, it may be required to derive this information in real time from low resolution visual inputs, with as much precision as possible. In this paper we present an algorithm for transforming head pose estimates to gaze direction estimates. The main contribution of this study lies in the fact that it makes a clear distinction between head pose and gaze direction. Unlike some of the previous works in this field, we do not correct the head pose to correspond to a possible attention fixation point in accordance with the experiment scenario. Instead we propose using a concrete and environment-independent method for this purpose. To transform the head pose estimates into gaze direction, a Gaussian process regression model is proposed and the reasons validating this choice are discussed in detail.",https://ieeexplore.ieee.org/document/5652736/,2010 IEEE 18th Signal Processing and Communications Applications Conference,22-24 April 2010,ieeexplore
10.1109/FPL.2005.1515790,Design and FPGA implementation of an embedded real-time biologically plausible spiking neural network processor,IEEE,Conferences,"The implementation of a large scale, leaky-integrate-and-fire neural network processor using the Xilinx Virtex-II family of field programmable gate array (FPGA) is presented. The processor has been designed to model biologically plausible networks of spiking neurons in real-time to assist with the control of a mobile robot. The real-time constraint has led to a re-evaluation of some of the established architectural and algorithmic features of previous spiking neural network based hardware. The design was coded and simulated using Handel-C hardware description language (HDL) and the DK3 design suite from Celoxica. The processor has been physically implemented and tested on a RC200 development board, also from Celoxica.",https://ieeexplore.ieee.org/document/1515790/,"International Conference on Field Programmable Logic and Applications, 2005.",24-26 Aug. 2005,ieeexplore
10.1109/AINL-ISMW-FRUCT.2015.7382967,Design and implementation Raspberry Pi-based omni-wheel mobile robot,IEEE,Conferences,Nowadays simultaneous localization and mapping (SLAM) algorithms are being tested at least in two phases: software simulation and real hardware platform testing. This paper describes hardware design and control software for small size omni-directional wheels robot implemented for indoor testing SLAM algorithms.,https://ieeexplore.ieee.org/document/7382967/,"2015 Artificial Intelligence and Natural Language and Information Extraction, Social Media and Web Search FRUCT Conference (AINL-ISMW FRUCT)",9-14 Nov. 2015,ieeexplore
10.1109/ETFA.2015.7301549,Design and implementation for multiple-robot deployment in intelligent space,IEEE,Conferences,"This paper presents the problem of robot deployment for a number of scattered tasks. We aim to minimize the duration it takes for all robots to reach their assigned task locations. In previous work, we have proposed a team composed of one carrier robot (CR) and several servant robots to accomplish the mission. Then we have suggested an algorithm that determines a path of the CR for an efficient deployment under a few constraints, which is verified by simulations. Assuming that the servant robots are unmanned aerial vehicles (UAVs), the present paper extends the discussion to a real robot experiment. We design and implement a deployment system in intelligent space. The feasibility of the study is demonstrated through an experiment.",https://ieeexplore.ieee.org/document/7301549/,2015 IEEE 20th Conference on Emerging Technologies & Factory Automation (ETFA),8-11 Sept. 2015,ieeexplore
10.1109/ITAIC.2019.8785457,Design and implementation of a cooperative dual body vehicle,IEEE,Conferences,"In order to reduce the over-dependence of low-cost underwater vehicles on cables, and considering that it is difficult to transmit radio signals underwater, proposeding a design scheme of vehicle combining unmanned ship with underwater vehicles on the basis of the ROS platform (robot operating system).The work shows that under the condition of reasonable utilization of ROS compatibility, advantages of USV (unmanned surface vessel) and ROV (remote operating vehicle) can be complemented greatly. The USV shares part of the functions of the underwater working module, while providing auxiliary means for inertial navigation devices, it maintains better endurance and maneuverability. ROV which focuses on underwater operation has practical functions and low volume, thus saving production costs. This system has navigation performance, intelligent level, remote control ability and expansion ability, which can provide reference for the design of some low cost underwater vehicles in a way.",https://ieeexplore.ieee.org/document/8785457/,2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC),24-26 May 2019,ieeexplore
10.1109/ICMLC.2009.5212155,Design and implementation of a visual servo system,IEEE,Conferences,"Robot visual servo system has an important status in robotic research and application, also has a decisive influence on robot intelligence. According to robotic kinematics and dynamics, the method of visual servo controller based on position is adopted in this paper. Binocular camera stereo vision technology and a kind of real-time control card Q8 based on MATLAB are used in motion control. The paper describes the control structure, hardware, software, designs a visual servo system platform and implements the real-time mission that track, capture or access moving targets on the platform.",https://ieeexplore.ieee.org/document/5212155/,2009 International Conference on Machine Learning and Cybernetics,12-15 July 2009,ieeexplore
10.1109/ICMA.2017.8015890,Design and implementation of self-tuning control method for the underwater spherical robot,IEEE,Conferences,"Considering the complicated disturbance in underwater circumstance, usually it is difficult to solve the control problem when the robot changes its motion state or it is subject to ocean currents, its performance deteriorates since the fixed set of parameters is no longer valid for the new conditions. Thus, in this paper, an auto-tune PID (Proportional + Integral + Derivative)-like controller based on Neural Networks is applied to our amphibious spherical underwater robot, which has a great advantage on processing online for the robot due to their nonlinear dynamics. The Neural Networks (NN) plays the role of automatically estimating the suitable set of PID gains that achieves stability of the system. The NN adjusts online the controller gains that attain the smaller position tracking error. The performance of the NN-based controller is investigated in ADAMS and MATLAB cooperative simulation. The velocity of the spherical robot can be controlled to precisely track desired trajectory in body-fixed coordinate system. Additionally, real time experiments on our underwater spherical robot are conducted to show the effectiveness of the algorithm.",https://ieeexplore.ieee.org/document/8015890/,2017 IEEE International Conference on Mechatronics and Automation (ICMA),6-9 Aug. 2017,ieeexplore
10.1109/AIEA53260.2021.00013,Design of a Real-time Robot Control System oriented for Human-Robot Cooperation,IEEE,Conferences,"An open real-time control system based on the EtherCAT fieldbus communication technology is proposed to fulfill the high real-time requirement of the human-robot cooperation controller in this paper. An open source real-time kernel of Xenomai is employed as the real-time software platform of the robot control system. Based on this, four-layer interfaces architecture are accomplished, which are human-machine cooperation control layer, motion control layer, robot axis control layer and hardware abstraction layer, through the corresponding four real-time tasks to meet the demand of human-robot cooperation operations. In addition, the scheduling task is developed to manage the 4 real-time tasks. The dual buffer communication mechanisms and priority-based scheduling strategy between layers was exploited to synchronize these real-time tasks. The underlying hardware abstract interface and the human-robot collaborative control algorithm interface are opened in the control system as the quadric exploitation interfaces to meet the need of developing application tasks in real-time space. Experiment results which are conducted on a self-developed 6-DOF collaborative robot show that the proposed control system is effective in real-time control applications of human-robot cooperative control at the control cycle of 5 milliseconds.",https://ieeexplore.ieee.org/document/9525600/,2021 International Conference on Artificial Intelligence and Electromechanical Automation (AIEA),14-16 May 2021,ieeexplore
10.1049/cp.2012.1101,Design of a real-time tracking robot based on simplified binocular positioning model,IET,Conferences,"A real-time-tracking robot based on binocular positioning is proposed in this essay. This system synthetically evaluates both color and morphological property of the target, realizing fast positioning with a simplified binocular positioning model. With the use of Kalman filter to predict the movement of the target, the system promptly adjusts the direction of the PTZ which carries the cameras, making it possible for the real time tracking of the target. Besides, the essay introduces an edge detection algorithm based on brightness equalization to eliminate possible false boundary lines caused by shadows or illumination. Finally, experiment results demonstrate the realtime performance and accuracy of the system.",https://ieeexplore.ieee.org/document/6492708/,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),3-5 March 2012,ieeexplore
10.1109/SECON.2008.4494306,Design of an integrated environment for operation and control of robotic arms (non-reviewed),IEEE,Conferences,"As more advanced control algorithms are becoming available for the control of robotic arms, traditional fixed controller boards and associated code generators are becoming less convenient way to test such control algorithms in real-time. The process of using such boards is complex, time consuming, and inflexible. In this work, an integrated hardware-software environment was developed and presented where researchers can simply use any Matlab/Simulink basic function block and/or toolbox, such as fuzzy logic or neural network, to design, implement, and test different controller algorithms in realtime for robotic arm operations. The hardware includes a computer, the dSPACE-ds1103 digital processing board, an amplifier board, and the Zebra-ZERO robotics arm as a test-bed. Also, Matlab GUI, m-file, Matlab/Simulink blocks, and dSPACE interface functions are combined together to form the software environment. Control algorithms can be designed in the Matlab/Simulink then converted to c-code and download to the dSPACE processing board. The Matlab m-file are used to code the arm inverse kinematics model and the path planning to calculate the joint angles then send them to the dSPACE processing board using the dSPACE interface functions. Finally, the dSPACE processing board generates physical signal to control the robot arm in real-time. The proposed hardware-software components are developed and integrated together, and several control algorithms can be tested on it. The development steps and some of the realtime testing results conducted on the hardware are explained next in this extended abstract. Typically, controllers are designed to run on dedicated hardware and researchers need different hardware to test different control strategies. This can be costly and time consuming where one has to develop different control environment for every control strategy to be tested. In this work, an integrated hardware-software environment was developed for implementation and testing of different control algorithms in real-time. The integrated system is composed of a computer, a power supply, the DS1103 dSPACE controller board, an amplifier, and the Zebra- Zero force robotics arm. The computer is used to send commands to the DS1103 dSPACE controller board.Inside the DS1103 dSPACE controller board, a Texas instruments DSP micro-controller performs the necessary calculation to determine the PWM signal to be generated and sent to the amplifier. The amplifier then generates the control signals that are applied to dc-motors that drive the links. The motor encoders provide feedback position signals as output. To develop the software environment, the Matlab programming environment (m-file), Matlab's graphical user interface, Simulink, and the toolbox are all employed. A user graphical interface (GUI) was designed for user convenience. The robot can be moved to the ready position then, the forward or inverse kinematical model is chosen according to the type of input data. The links begin to move when the Move button is pressed. The user can also select different movement speed for each link. Finally, when link movement has ceased, the joint trajectories are displayed on the GUI. Trajectory planning files for position, velocity and acceleration references are also developed and implemented in the environment. Two types of trajectories are made available according to different requirements; second order polynomial and third-order polynomial trajectory. The second order polynomial trajectory is recommended for links with large angular position difference. For purpose of testing and verification, the Zebra-Zero robotics arm was used. The Lagrangian mechanics is used to develop the dynamic equations for the Zebra-Zero robotic arm. Some of the arm parameters are calculated while others are determined experimentally, e.g., the link inertias and masses. A Simulink model of the robotic arm dynamic was developed. To test the environment a control algorithm was also designed then automatically converted to C programming language and downloaded to the DS1103 dSPACE controller board. The user enters commands using the Matlab GUI. Based on input, positions or final location and orientation, the forward or inverse kinematical model is selected. In this work a PID control algorithm was designed and tested on the Zebra- Zero robotics arm. To verify the controller performance, Matlab toolbox was used to simulate the Zebra-Zero robotic arm dynamics model. The results were very comparable with the actual Zebra-Zero robotic arm hardware performance.",https://ieeexplore.ieee.org/document/4494306/,IEEE SoutheastCon 2008,3-6 April 2008,ieeexplore
10.1109/TENCON.2016.7848000,Design of hardware circuit based on a neural network model for rapid detection of center of gravity position,IEEE,Conferences,"This paper proposes a rapid detection method for the center of gravity based on a neural network model. It is suitable for the rapid response requirement such as attitude control of a gait robot or real time torque control of a running car. The proposed method detects the center of gravity position on a straight line by using only the hardware circuit composing of common electronic devices instead of software, microprocessor and AD converter. The circuit employs some neural based comparators without the learning function to simplify the circuit structure. The detection circuit using some parallel processing neural comparators rapidly detects the center of gravity position on a straight line. In this paper, the circuit is designed and fabricated with electronic devices, and the circuit experiment shows the performance of the position detection.",https://ieeexplore.ieee.org/document/7848000/,2016 IEEE Region 10 Conference (TENCON),22-25 Nov. 2016,ieeexplore
10.1109/CMCE.2010.5609659,Design of mobile robot system with remote control based on CAN-bus,IEEE,Conferences,"In order to realizing remote control and information collection quickly and reliably, the mobile robot with remote control is designed. In the paper, according to analysis of the overall structure, hardware circuit of the robot system is designed. Because the CAN2.0 standard only makes physical layer protocol and data link layer protocol, application layer protocol is ruled according to robot control system. In the last part of this paper, the software of master/slave computer is introduced in detail. The experiment shows that running performance of robot control system is balanced, efficient and has satisfied the practical demand.",https://ieeexplore.ieee.org/document/5609659/,"2010 International Conference on Computer, Mechatronics, Control and Electronic Engineering",24-26 Aug. 2010,ieeexplore
10.1109/ICMA.2006.257524,"Design, Fabrication and Application of ARm Wrestling Robot",IEEE,Conferences,"This paper presents a novel 2 DOF robotic arm wrestling system integrated with mechanical arm, elbow/wrist force sensors, servo motor, encoder, 3-D MEMS accelerometer, and USB camera. The arm wrestling robot (AWR) is used to play arm wrestling game with human for entertainment. Based on the force testing equipment, we acquire the data of surface electromyographic (EMG) signals form target muscle when a real player competes with the robot. Wavelet transform and neural network are applied to extract the characteristics of EMG signals and estimate the joint torque. Experiment results have proved the validation of the wavelet neural network method",https://ieeexplore.ieee.org/document/4026383/,2006 International Conference on Mechatronics and Automation,25-28 June 2006,ieeexplore
10.1109/IROS.1999.813052,Designing rhythmic motions using neural oscillators,IEEE,Conferences,"Neural oscillators offer simple and robust solutions to problems such as locomotion and dynamic manipulation. However, the parameters of these systems are notoriously difficult to tune. This paper presents an analysis technique which alleviates the difficulty of tuning. The method is based on describing function analysis, and can predict the steady state motion of the system, analyze stability, and be used to determine robustness to system changes. The method is illustrated using a number of design examples including an implementation of juggling on a real robot.",https://ieeexplore.ieee.org/document/813052/,Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289),17-21 Oct. 1999,ieeexplore
10.1109/ICSMC.1998.726514,"Designing, making, and using a mobile robot",IEEE,Conferences,"Describes the building and control of a mobile robot which is capable of navigating in a well defined workspace by means of generating an optimal trajectory. The basic control architecture of the mobile robot is implemented with a combination of an MC68HC11 microcontroller and a personal computer. The kinematics of the proposed differential impulse is analyzed which allow us to select the appropriate steering DC motors and speed measurement requirements of the system. The motor control is performed by a PWM scheme and PI controllers. A path planning stage finds the optimal trajectory, taking a graphical description of the workspace and using potential fields and dynamic programming to solve the optimization problem and avoid the obstacles. Clearly there are two specific problems: building a complete device that will allow having an electric powered robot and the use of these resources to obtain controlled and collision-free movement in a real workspace.",https://ieeexplore.ieee.org/document/726514/,"SMC'98 Conference Proceedings. 1998 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.98CH36218)",14-14 Oct. 1998,ieeexplore
10.1109/ICoSTA48221.2020.1570615971,Detecting Features of Middle Size Soccer Field using Omnidirectional Camera for Robot Soccer ERSOW,IEEE,Conferences,"ERSOW (EEPIS Robot Soccer on Wheeled) is robot soccer developed by Politeknik Elektronika Negeri Surabaya that is designed and implemented on a Middle Size League division by following the rules of RoboCup, an international robot competition. One of the most famous division is a soccer robot, that is divided into two divisions: (1) SSL (Small Size League) and (2) MSL (Middle Size League). There are many research fields related to soccer robot which must be developed in robot ERSOW such as Artificial Intelligence (AI), Computer Vision, Embedded System, Mechanic Systems, and Hardware. This paper focuses on computer vision research for robot ERSOW, especially detecting features of the middle size soccer field, so that specific features of the field like X-junction, T-junction and L-junction can be detected to help robot positioning task where the result is represented into x and y in real-world coordinate. By knowing the position of the features, the robot position can be calculated. The localization system at robot ERSOW uses odometry, which has a large percentage of data errors. Therefore, we attempt to extract the feature of X-junction that is done to find its x and y coordinates and then the obtained coordinate can be used as a reference for correcting odometry data by AI.",https://ieeexplore.ieee.org/document/9079260/,2020 International Conference on Smart Technology and Applications (ICoSTA),20-20 Feb. 2020,ieeexplore
10.1109/CONIELECOMP.2017.7891823,Detecting falling people by autonomous service robots: A ROS module integration approach,IEEE,Conferences,"In this paper is presented the integration of diverse modules for people fallen detection by a mobile service robot. This integration has been achieved in the middleware ROS (Robotics Operation System). The proposed implementation are arranged over an modular architecture of three layers: Hardware, Processing and Decision. The modules implemented are on the processing layer. The first module uses an RGB-D camera to detect and track a person in the environment. This module calculate features to detect the fallen pose. In the second module, a PID controller in a pan/tilt unit is used, in order to track the person with a minimum error and soft movement. For this purpose the centroid of the person is located at the center of the plane image. The main characteristics in our architecture are: 1) Segmentation in depth is used, because 3D information is required for detecting the fallen pose; 2) The parameters of PID control are tuned using a manual method and a genetic algorithm, to compare and improve the performance of the tracking person module. Once the PID controller was optimized, the architecture to follow the person and detect the fallen pose, is probed in real time.",https://ieeexplore.ieee.org/document/7891823/,"2017 International Conference on Electronics, Communications and Computers (CONIELECOMP)",22-24 Feb. 2017,ieeexplore
10.1109/IROS.2018.8594335,Detection- Tracking for Efficient Person Analysis: The DetTA Pipeline,IEEE,Conferences,"In the past decade many robots were deployed in the wild, and people detection and tracking is an important component of such deployments. On top of that, one often needs to run modules which analyze persons and extract higher level attributes such as age and gender, or dynamic information like gaze and pose. The latter ones are especially necessary for building a reactive, social robot-person interaction. In this paper, we combine those components in a fully modular detection-tracking-analysis pipeline, called DetTA. We investigate the benefits of such an integration on the example of head and skeleton pose, by using the consistent track ID for a temporal filtering of the analysis modules' observations, showing a slight improvement in a challenging real-world scenario. We also study the potential of a so-called “free-flight” mode, where the analysis of a person attribute only relies on the filter's predictions for certain frames. Here, our study shows that this boosts the runtime dramatically, while the prediction quality remains stable. This insight is especially important for reducing power consumption and sharing precious (GPU-)memory when running many analysis components on a mobile platform, especially so in the era of expensive deep learning methods.",https://ieeexplore.ieee.org/document/8594335/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/IJCNN.2003.1223996,"Developing early senses about the world: ""Object Permanence"" and visuoauditory real-time learning",IEEE,Conferences,"What ""constraints"" are exactly wired into the human developmental program? What ""constraints"" are minimally necessary for a developmental robot? These are open questions. In this paper, we propose a mechanism of developing experience-based priming - predicting the future contexts including sensation and action based on the previous experience - as a powerful ""constraint"" for developmental robots. We present an architecture that develops this priming capability through realtime online interactions with the environment. We report how our SAIL robot developed a sense of novelty in a well-known ""drawbridge"" experiment which sheds light on the controversial issue of ""object permanence"" in psychology. We further show how the proposed priming mechanism enabled SAIL to deal with a very challenging online learning setting: learning the name and property (e.g., size) of dynamically rotating objects through verbal dialogues.",https://ieeexplore.ieee.org/document/1223996/,"Proceedings of the International Joint Conference on Neural Networks, 2003.",20-24 July 2003,ieeexplore
10.1109/IEEECONF49454.2021.9382646,Development and Testing of Garbage Detection for Autonomous Robots in Outdoor Environments,IEEE,Conferences,"In Japan, there is a growing concern about labor shortages due to the declining birthrate and aging population, and there are high expectations for robots to help solve such social problems and create industries. However, due to the prohibition of public road tests in Japan, there are few examples of actual applications of robots. Therefore, considerations and problems in the practical application of robots are still unclear. In this paper, by focusing on the implementation of garbage collection technology, we have developed an autonomous garbage collection robot using deep learning. In addition, we have verified the usefulness of our garbage detection technology in outdoor environments by conducting actual demonstrations at HANEDA INNOVATION CITY, which is a large-scale commercial and business complex belonged private property, Utsunomiya University, and Nakanoshima Challenge 2019, which is a field of demonstration experiment in the outdoor environment. Our garbage detector was designed to detect cans, plastic bottles, and lunch boxes automatically. Through experiments on test data and outdoor experiments in the real-world, we have confirmed that our detector has a 95.6% Precision and 96.8% Recall. Conparisons to other state-of-the-art detectors are also presented.",https://ieeexplore.ieee.org/document/9382646/,2021 IEEE/SICE International Symposium on System Integration (SII),11-14 Jan. 2021,ieeexplore
10.1109/ICBDIE52740.2021.00087,Development and application of virtual simulation and real arm combination system based on teleoperation Technology,IEEE,Conferences,"Teleoperation robot is an artificial intelligence system that expands human perception and operation ability through the interaction between operator and remote robot. With the help of the teleoperation robot system, people can work in all kinds of dangerous, harsh, and inaccessible environments, such as disaster relief, marine development, telemedicine, and aerospace. Combining computer programming technology, virtual simulation technology, chip technology, and remote control technology, a set of basic virtual simulation arm systems (two-fingered hand) is designed and developed. Through the motion analysis of the manipulator, human-computer interaction remote control, and chemical experiment design, the real-time simulation interaction of the manipulator operating chemical experiment is realized. It creates a real situation, which enables the operators to feel the chemical experiment more deeply, vividly, and intuitively.",https://ieeexplore.ieee.org/document/9457452/,2021 2nd International Conference on Big Data and Informatization Education (ICBDIE),2-4 April 2021,ieeexplore
10.1109/ROBOT.2004.1307521,Development and deployment of a line of sight virtual sensor for heterogeneous teams,IEEE,Conferences,"For a team of cooperating robots, geometry plays a vital role in operation. Knowledge of line of sight to local obstacles and adjacent teammates is critical in both the movement and planning stages to avoid collisions, maintain formation and localize the team. However, determining if other robots are within the line of sight of one another is difficult with existing sensor platforms - especially as the scale of the robot is reduced. We describe a method of exploiting collective team information to generate a virtual sensor that provides line of sight determination, greater range and resolution and the ability to generalize local sensing. We develop this sensor and apply it to the control of a tightly coupled, resource-limited robot team called Millibots.",https://ieeexplore.ieee.org/document/1307521/,"IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004",26 April-1 May 2004,ieeexplore
10.1109/IECON48115.2021.9589075,Development of Agricultural Robot Platform with Virtual Laboratory Capabilities,IEEE,Conferences,"Agricultural robots are called to help in many tasks in emerging clean and sustainable agriculture. These complex electro-mechanical systems can actually integrate artificial intelligence (AI), the Internet of Things (IoT), sensors, actuators, and advanced control methods to accomplish functions in autonomous or in collaborative ways. Before the deployment of such techniques in the field, it is convenient to carry out laboratory validations. These last could be at the sub-system, e.g., sensors or servos operation, or the whole system level. This paper proposes the development of the hardware and software parts of a platform of agricultural robot. The proposed system, highly motivated by the restrictions imposed by COVID-19 context, enables laboratory tests virtualization while keeping real-time functionalities",https://ieeexplore.ieee.org/document/9589075/,IECON 2021 – 47th Annual Conference of the IEEE Industrial Electronics Society,13-16 Oct. 2021,ieeexplore
10.1109/ICCAS.2008.4694375,Development of Automatic Process Control system with simulation in PECVD system,IEEE,Conferences,"We develop the automatic process control system to maximize the number of available process chambers by controlling the time to start cleaning each chamber. Firstly, to achieve the purpose we build the controller model which creates and changes the pseudo RPSC counter properly by controlling other factors: unit priority, robot sequence etc. Secondly, for testing the control system we design one of the representative PECVD systems, and experiment the simulated system with the APC system and without it under various conditions. Finally, we optimize the system with the evolution strategy. As a result, not only major performance indicators; cycle time and throughput but also the variations of them have improved than before adapting the system. The contribution of this research is to present the practical solution concerned with various and complex issues in the real world.",https://ieeexplore.ieee.org/document/4694375/,"2008 International Conference on Control, Automation and Systems",14-17 Oct. 2008,ieeexplore
10.1109/EMS.2017.12,Development of Components of Multi-agent CASE-System for Describing the Logic of Behavior of Mobile Robots,IEEE,Conferences,"In the article there are substantiation of architectural and technical solutions, with the basis of the universal CASE-tool for describing (""programming"") the behavior of mobile robots. The development tool intended for carrying out experiments in the field of artificial intelligence and it is based on multi-agent technology. In addition, the toolkit will be the maximum possible reuse of elements (tasks, processes, etc.). The basis for the development is the idea of combining, within the framework of one tool, both the real execution of the algorithm by the robot, and its simulation. It allows talking about testing partially implemented hardware (sensors and actuators). Development is carried out based on open source technology; all texts of programs are available at web source: https://github.com/unclesal/tenguai.",https://ieeexplore.ieee.org/document/8356782/,2017 European Modelling Symposium (EMS),20-21 Nov. 2017,ieeexplore
10.1109/ICIS.2018.8466473,Development of a GPU-Based Human Emotion Recognition Robot Eye for Service Robot by Using Convolutional Neural Network,IEEE,Conferences,"Service robots can be used widely to assist elderly and disable population due to the lack of caregivers in future. Real-time human tracking, detection, focusing and implementing various algorithms are a wide range of application in emotion recognition service robots. Therefore service robots must have a properly designed robot eye model to be human-friendly with accurate human-robot interaction. Developed robot eye can be recognized the human emotional states by using well trained deep convolutional neural networks (ConvNet). This paper describes graphics processing units (GPUs) based human emotion recognition robot eye by using ConvNet. Mainly, the robot eye performs two processes in the intelligent systems. They are the robot eye focus to the human face and head by using pre-trained haar cascade classifier and recognizes the human emotional states probability with percentages as happy, sad or relaxes by using pre-trained ConvNet. The developed robot eye was implemented and tested by using different people successfully and the results of them are presented. According to the results, the emotions are detected more than 85% of overall accuracy for each person.",https://ieeexplore.ieee.org/document/8466473/,2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS),6-8 June 2018,ieeexplore
10.1109/SII46433.2020.9025980,Development of a Web-Based Education System for Deep Reinforcement Learning-Based Autonomous Mobile Robot Navigation in Real World,IEEE,Conferences,"The technology that combined deep reinforcement learning and robotics is increasing interests in recent years. Although several online tools for studying this technology can be found, it is difficult for beginners to develop actual robot systems for autonomous navigation in the real world. In this study, we developed a web-based educational system that is able to help users to study mobile robot navigation based on deep reinforcement learning and develop actual robot systems. The proposed web system provides the following functions: setting the parameters of reinforcement learning for autonomous robot navigation, running learning scripts and monitoring status of the learning. The first experiment that a user develops an actual robot system was performed. In the experiment, the user tuned parameters on the web page started the training and obtained action policy models. The experimental results indicate the proposed system can be applied to develop an actual autonomous navigation system. Also, the user could decide better parameters through the trial and error process using the proposed system.",https://ieeexplore.ieee.org/document/9025980/,2020 IEEE/SICE International Symposium on System Integration (SII),12-15 Jan. 2020,ieeexplore
10.1109/ROBIO.2010.5723534,Development of a cognition system for analyzing rat's behaviors,IEEE,Conferences,"The interaction experiment, between a robot and a rat, will benefit significantly when the rat's actions can be recognized automatically in real time. Regarding quantitative behavior analysis, the number and duration of a rat's actions should be measured efficiently and accurately. Therefore, aiming at the above-mentioned objectives, a novel cognition system capable of detecting rats' actions has been proposed in this paper. The main function of this cognition system lies on the real-time recognition and offline analysis of rats' behaviors. Basic image processing algorithm as Labeling and Contour Finding were employed to extract feature parameters (body length, body area, body radius, rotational angle, and ellipticity) of rat's actions. These parameters are integrated as the input feature vector of NN (Neural Network) and SVM (Support Vector Machine) training system respectively. Preliminary experiments reveal that the grooming, rotating and rearing actions could be recognized with extremely high rate (more than 90%) by both NN and SVM. Compared to NN, SVM provides better recognition rate and less computational cost.",https://ieeexplore.ieee.org/document/5723534/,2010 IEEE International Conference on Robotics and Biomimetics,14-18 Dec. 2010,ieeexplore
10.1109/ROBIO.2012.6491198,Development of a cricket interaction system utilizing mobile robot for behavioral data collection,IEEE,Conferences,"This paper describes about a prototype of active interaction experiment system between a cricket and an operated micro mobile robot and measured/collected data in real-time by using the system. The behavior selection of the cricket (Gyllus bimaculatus) is influenced by the experience or the context in living environment. Therefore, we are trying to investigate neuronal mechanisms underlying micro brain of the cricket. For gathering behavioral data, we are developing a control/measurement system for realizing active interaction experiment. The prototype is composed of a micro mobile robot as a physical interaction agent, a camera and a microphone and a computer commands to the micro mobile robot and record the data of video sequence, motion tracking and the audio. Experimental trial using the prototype was done and reported.",https://ieeexplore.ieee.org/document/6491198/,2012 IEEE International Conference on Robotics and Biomimetics (ROBIO),11-14 Dec. 2012,ieeexplore
10.1109/ISSNIP.2008.4761994,Development of a social learning mechanism for a humanoid robot,IEEE,Conferences,"A main purpose of humanoid robotic research is to develop a socially interactive robot by providing for a certain degree adaptability and flexibility in order to endow the robot with natural interactions with humans. In this paper, a social learning mechanism is proposed for enabling a humanoid robot to learn social behaviors through imitation. To achieve this goal, a novel imitation algorithm is proposed for transferring human social behaviors into a robot in real time. This approach considers the characteristic of motions for extracting symbolic postures, which consists of changing the points of motion directions. Reinforcement learning is utilized for extracting optimal symbolic postures and for incorporating the divisional cubic spline interpolation for generating a robotpsilas social behaviors through symbolic postures. In our experiment, we attempt to transfer three social cues: a ldquopointing gesture,rdquo a gesture for ldquoexplaining something attractively,rdquo and a gesture for expressing ldquoI donpsilat know.rdquo The experimental results confirmed the accuracy of the robot motion generation through the proposed mechanism for transferring natural social behaviors.",https://ieeexplore.ieee.org/document/4761994/,"2008 International Conference on Intelligent Sensors, Sensor Networks and Information Processing",15-18 Dec. 2008,ieeexplore
10.1109/IJCNN48605.2020.9206931,Developmental Learning of Value Functions in a Motivational System for Cognitive Robotics,IEEE,Conferences,"Motivation is quite an important topic when addressing continual open-ended learning processes in autonomous robots. The three main issues that need to be considered are, firstly, how does a designer define what the robot strives for in a manner that is independent from any particular domain it may find itself in. Secondly, once that robot is in a domain, how does it go about finding and relating goals in that particular domain on its own. Finally, the third issue is, once a goal is found, how does a robot establish a representation, usually in the form of a Value Function, that will allow it to exploit that goal. This paper deals with the third issue in the framework of the motivational engine we have designed for cognitive architectures. It addresses the problem of efficiently and appropriately learning complex Value Functions starting from intrinsically motivated traces of valuated robot actions that are often ambiguous and multivalued. To this end, a developmental learning mechanism is proposed that relies on the concurrent application of a real time ANN learning procedure over the traces of the valuated robot actions, and a simpler sensor correlation-based approach to allow for the production of better configured data traces for the learning process. The mechanism is analyzed and discussed over an experiment considering a real Baxter robot.",https://ieeexplore.ieee.org/document/9206931/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/ICRA48506.2021.9562061,Dexterous Manoeuvre through Touch in a Cluttered Scene,IEEE,Conferences,"Manipulation in a densely cluttered environment creates complex challenges in perception to close the control loop, many of which are due to the sophisticated physical interaction between the environment and the manipulator. Drawing from biological sensory-motor control, to handle the task in such a scenario, tactile sensing can be used to provide an additional dimension of the rich contact information from the interaction for decision making and action selection to manoeuvre towards a target. In this paper, a new tactile-based motion planning and control framework based on bioinspiration is proposed and developed for a robot manipulator to manoeuvre in a cluttered environment. An iterative two-stage machine learning approach is used in this framework: an autoencoder is used to extract important cues from tactile sensory readings while a reinforcement learning technique is used to generate optimal motion sequence to efficiently reach the given target. The framework is implemented on a KUKA LBR iiwa robot mounted with a SynTouch BioTac tactile sensor and tested with real-life experiments. The results show that the system is able to move the end-effector through the cluttered environment to reach the target effectively.",https://ieeexplore.ieee.org/document/9562061/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/CCTA41146.2020.9206279,Direct Force Feedback using Gaussian Process based Model Predictive Control,IEEE,Conferences,"Many robotic applications require control of the applied forces or moments. Model predictive control allows for the direct or indirect control of forces, while taking constraints into account. However, challenges arise when the robot environment that affects the force is highly variable, uncertain and difficult to model. Learning supported model predictive control makes it possible to combine the advantages of optimal control, such as the explicit consideration of constraints, with the advantages of machine learning, such as adaptive data-based modeling. In this paper Gaussian processes are used to model the contact forces that are applied in model predictive force control. The Gaussian process learns the static output mapping describing the interaction of the robot with the environment. It is shown that stability guarantees can be derived in a similar way as in classical predictive control. A proof-of-concept experimental implementation of a direct hybrid position force controller for a lightweight robot shows real-time feasibility.",https://ieeexplore.ieee.org/document/9206279/,2020 IEEE Conference on Control Technology and Applications (CCTA),24-26 Aug. 2020,ieeexplore
10.1109/IJCNN48605.2020.9207522,Discrete-Time Lyapunov based Kinematic Control of Robot Manipulator using Actor-Critic Framework,IEEE,Conferences,"Stability and optimality are the two foremost re-quirements for robotic systems that are deployed in critical operations and are to work for long hours or under limited energy resources. To address these, in this work we present a novel Lyapunov stability based discrete-time optimal kinematic control of a robot manipulator using actor-critic (AC) framework. The robot is actuated using optimal joint-space velocity control input to track a time-varying end-effector trajectory in its task space. In comparison to the existing near-optimal kinematic control solutions for robot manipulator under AC framework, proposed controller exhibits guaranteed analytical stability. We derive a novel critic weight update law based on Lyapunov stability, thus ensuring that the weights are updated along the negative gradient of Lyapunov function. This eventually ensures closed-loop system stability and convergence to the optimal control in discrete-time. Extensive simulations are performed on a 3D model of 6-DoF Universal Robot (UR) 10 in Gazebo, followed by implementation on real UR 10 robot manipulator to show the efficacy of the proposed scheme.",https://ieeexplore.ieee.org/document/9207522/,2020 International Joint Conference on Neural Networks (IJCNN),19-24 July 2020,ieeexplore
10.1109/Agro-Geoinformatics.2017.8047016,Disease detection on the leaves of the tomato plants by using deep learning,IEEE,Conferences,"The aim of this work is to detect diseases that occur on plants in tomato fields or in their greenhouses. For this purpose, deep learning was used to detect the various diseases on the leaves of tomato plants. In the study, it was aimed that the deep learning algorithm should be run in real time on the robot. So the robot will be able to detect the diseases of the plants while wandering manually or autonomously on the field or in the greenhouse. Likewise, diseases can also be detected from close-up photographs taken from plants by sensors built in fabricated greenhouses. The examined diseases in this study cause physical changes in the leaves of the tomato plant. These changes on the leaves can be seen with RGB cameras. In the previous studies, standard feature extraction methods on plant leaf images to detect diseases have been used. In this study, deep learning methods were used to detect diseases. Deep learning architecture selection was the key issue for the implementation. So that, two different deep learning network architectures were tested first AlexNet and then SqueezeNet. For both of these deep learning networks training and validation were done on the Nvidia Jetson TX1. Tomato leaf images from the PlantVillage dataset has been used for the training. Ten different classes including healthy images are used. Trained networks are also tested on the images from the internet.",https://ieeexplore.ieee.org/document/8047016/,2017 6th International Conference on Agro-Geoinformatics,7-10 Aug. 2017,ieeexplore
10.1109/NCA.2013.21,Distributed and Dynamic Map-less Self-reconfiguration for Microrobot Networks,IEEE,Conferences,"MEMS micro robots are low-power and low memory capacity devices that can sense and act. One of the most challenges in MEMS micro robot applications is the self-reconfiguration, especially when the efficiency and the scalability of the algorithm are required. In the literature, if we want a self-reconfiguration of micro robots to a target shape consisting of P positions, each micro robot should have a memory capacity of P positions. Therefore, if P equals to millions, each node should have a memory capacity of millions of positions. Therefore, this is not scalable. In this paper, nodes do not record any position, we present a self-reconfiguration method where a set of micro robots are unaware of their current position and do not have the map of the target shape. In other words, nodes do not store the positions that build the target shape. Consequently, memory usage for each node is reduced to O(1). An algorithm of self-reconfiguration to optimize the communication is deeply studied showing how to manage the dynamicity (wake up and sleep of micro robots) of the network to save energy. Our algorithm is implemented in Meld, a declarative language, and executed in a real environment simulator called DPRSim.",https://ieeexplore.ieee.org/document/6623641/,2013 IEEE 12th International Symposium on Network Computing and Applications,22-24 Aug. 2013,ieeexplore
10.1049/cp.2012.1127,Distributed parallel processing of mobile robot PF-SLAM,IET,Conferences,"Real-time property is a fundamental requirement for a practical robot system. For this purpose, this article proposes an implementation architecture of robot SLAM by adopting two parallel threads processing. Since the dominant factor which determines the computational complexity is the employed particle number, two distributed threads with different particle set size are executed simultaneously. Conventional PF-SLAM algorithm occupies one of threads, and the other thread which hires more particles is activated whenever robot has significant motion changes. Advantages of this presented idea are validated by experiment carried on Pioneer robot.",https://ieeexplore.ieee.org/document/6492734/,International Conference on Automatic Control and Artificial Intelligence (ACAI 2012),3-5 March 2012,ieeexplore
10.1109/ICAR.2017.8023522,Door opening by joining reinforcement learning and intelligent control,IEEE,Conferences,"In this paper we address a problem of how to open the doors with an articulated robot. We propose a novel algorithm, that combines widely used reinforcement learning approach with intelligent control algorithms. In order to speed up learning, we formed more structured search, which exploits physical constraints of the problem to be solved. The underlying controller, which acts as a policy search agent, generates movements along the admissible directions defined by physical constraints of the task. This way we can efficiently solve many practical problems such as door opening without almost any previous knowledge of the environment. The approach was verified in simulation as well as with real robot experiment.",https://ieeexplore.ieee.org/document/8023522/,2017 18th International Conference on Advanced Robotics (ICAR),10-12 July 2017,ieeexplore
10.1109/RoboSoft51838.2021.9479353,DroneTrap: Drone Catching in Midair by Soft Robotic Hand with Color-Based Force Detection and Hand Gesture Recognition,IEEE,Conferences,"The paper proposes a novel concept of docking drones to make this process as safe and fast as possible. The idea behind the project is that a robot with a soft gripper grasps the drone in midair. The human operator navigates the robotic arm with the ML-based gesture recognition interface. The 3-finger robot hand with soft fingers is equipped with touch sensors, making it possible to achieve safe drone catching and avoid inadvertent damage to the drone's propellers and motors. Additionally, the soft hand is featured with a unique color-based force estimation technology based on a computer vision (CV) system. Moreover, the visual color-changing system makes it easier for the human operator to interpret the applied forces.Without any additional programming, the operator has full real-time control of robot's motion and task execution by wearing a mocap glove with gesture recognition, which was developed and applied for the high-level control of DroneTrap.The experimental results revealed that the developed color-based force estimation can be applied for rigid object capturing with high precision (95.3%). The proposed technology can potentially revolutionize the landing and deployment of drones for parcel delivery on uneven ground, structure maintenance and inspection, risque operations, and etc.",https://ieeexplore.ieee.org/document/9479353/,2021 IEEE 4th International Conference on Soft Robotics (RoboSoft),12-16 April 2021,ieeexplore
10.1109/ICAR46387.2019.8981552,Dynamic Movement Primitives: Volumetric Obstacle Avoidance,IEEE,Conferences,"Dynamic Movement Primitives (DMPs) are a framework for learning a trajectory from a demonstration. The trajectory can be learned efficiently after only one demonstration, and it is immediate to adapt it to new goal positions and time duration. Moreover, the trajectory is also robust against perturbations. However, obstacle avoidance for DMPs is still an open problem. In this work, we propose an extension of DMPs to support volumetric obstacle avoidance based on the use of superquadric potentials. We show the advantages of this approach when obstacles have known shape, and we extend it to unknown objects using minimal enclosing ellipsoids. A simulation and experiments with a real robot validate the framework, and we make freely available our implementation.",https://ieeexplore.ieee.org/document/8981552/,2019 19th International Conference on Advanced Robotics (ICAR),2-6 Dec. 2019,ieeexplore
10.1109/DEVLRN.2008.4640818,Dynamic field theory of sequential action: A model and its implementation on an embodied agent,IEEE,Conferences,"How sequences of actions are learned, remembered, and generated is a core problem of cognition. Despite considerable theoretical work on serial order, it typically remains unexamined how physical agents may direct sequential actions at the environment within which they are embedded. Situated physical agents face a key problem - the need to accommodate variable amounts of time it takes to terminate each individual action within the sequence. Here we examine how Dynamic Field Theory (DFT), a neuronally grounded dynamical systems approach to embodied cognition, may address sequence learning and sequence generation. To demonstrate that the proposed DFT solution works with real and potentially noisy sensory systems as well as with real physical action systems, we implement the approach on a simple autonomous robot. We demonstrate how the robot acquires sequences from experiencing the associated sensory information and how the robot generates sequences based on visual information from its environment using low-level visual features.",https://ieeexplore.ieee.org/document/4640818/,2008 7th IEEE International Conference on Development and Learning,9-12 Aug. 2008,ieeexplore
10.1109/ISIC.2003.1254674,Dynamic neuro-fuzzy adaptive control for flexible-link manipulators based on dynamic inversion,IEEE,Conferences,"A dynamic neuro-fuzzy (DNF) adaptive control system is presented in this paper for the trajectory tracking of a flexible-link manipulator with poorly known dynamics, where the robot tip vibration is measured by position sensitive detectors (PSDs). Based on the singular perturbation method and two time-scale decompositions, the robot dynamics is approximated by a slow subsystem of an equivalent rigid arm and a fast subsystem of flexible mode. Then, the DNF adaptive controller based on dynamic inversion is designed for the tracking control of the equivalent rigid arm, while a fuzzy proportional derivative (PD) type controller is used to stabilize the elastic dynamics using PSDs measurement feedback. The NF learning algorithm and the stability proof of the closed-loop system are given, and an upper bound for the singular perturbation parameter is also obtained. Finally, the real-time experiment is conducted to show the viability and effectiveness of the proposed control approach.",https://ieeexplore.ieee.org/document/1254674/,Proceedings of the 2003 IEEE International Symposium on Intelligent Control,8-8 Oct. 2003,ieeexplore
10.1109/ICSMC.1995.537949,Dynamic path planning,IEEE,Conferences,"Path planning is dynamic when the path is continually recomputed as more information becomes available. A computational framework for dynamic path planning is proposed which has the ability to provide navigational directions during the computation of the plan. Path planning is performed using a potential field approach. We use a specific type of potential function-a harmonic function-which has no local minima. The implementation is parallel and consists of a collection of communicating processes, across a network of SPARC &amp; SGI workstations using a message passing software package called PVM. The computation of the plan is performed independently of the execution of the plan. A hierarchical coarse-to-fine procedure is used to guarantee a correct control strategy at the expense of accuracy. We have successfully navigated a Nomad robot around our lab space with no a priori map in real-time. The result of the described approach is a parallel implementation which permits dynamic path planning using available processor resources.",https://ieeexplore.ieee.org/document/537949/,"1995 IEEE International Conference on Systems, Man and Cybernetics. Intelligent Systems for the 21st Century",22-25 Oct. 1995,ieeexplore
10.1109/EMBC.2015.7318719,EEG error potentials detection and classification using time-frequency features for robot reinforcement learning,IEEE,Conferences,"In thought-based steering of robots, error potentials (ErrP) can appear when the action resulting from the brain-machine interface (BMI) classifier/controller does not correspond to the user's thought. Using the Steady State Visual Evoked Potentials (SSVEP) techniques, ErrP, which appear when a classification error occurs, are not easily recognizable by only examining the temporal or frequency characteristics of EEG signals. A supplementary classification process is therefore needed to identify them in order to stop the course of the action and back up to a recovery state. This paper presents a set of time-frequency (t-f) features for the detection and classification of EEG ErrP in extra-brain activities due to misclassification observed by a user exploiting non-invasive BMI and robot control in the task space. The proposed features are able to characterize and detect ErrP activities in the t-f domain. These features are derived from the information embedded in the t-f representation of EEG signals, and include the Instantaneous Frequency (IF), t-f information complexity, SVD information, energy concentration and sub-bands' energies. The experiment results on real EEG data show that the use of the proposed t-f features for detecting and classifying EEG ErrP achieved an overall classification accuracy up to 97% for 50 EEG segments using 2-class SVM classifier.",https://ieeexplore.ieee.org/document/7318719/,2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),25-29 Aug. 2015,ieeexplore
10.1109/MWSCAS.2018.8624056,EMG-based hand gesture control system for robotics,IEEE,Conferences,"In this paper, a Electromyogram (EMG) based hand gesture control system is developed. A wearable human machine interface (HMI) device is designed for an in-home assistance service robot. An EMG-based control system utilizes MyoWave muscle sensor to acquire and amplify EMG signal. A microcontroller system is used to an artificial neural network (ANN) to classify the EMG signal. Based on different hand movements, commands are sent through WiFi to control the motor in a service robot. The on-board Camera system mounted the robot can capture video real-time. In addition, a web server is implemented to provide live video feedback for robot navigation and user instructions.",https://ieeexplore.ieee.org/document/8624056/,2018 IEEE 61st International Midwest Symposium on Circuits and Systems (MWSCAS),5-8 Aug. 2018,ieeexplore
10.1109/CSCloud-EdgeCom49738.2020.00050,Edge Computing-based 3D Pose Estimation and Calibration for Robot Arms,IEEE,Conferences,"Industrial robots are widely used in current production lines, and complex pipeline processes, especially those with different assembly requirements, are designed for intelligent manufacturing in the era of industry 4.0. During the new crown epidemic, a large number of car companies used the production line to transform production of medical materials such as masks and protective clothing, which provided a strong guarantee for fighting the epidemic. In this scenario, a pipeline is often assembled from robotic arms from multiple suppliers. The traditional methods is complex and takes a lot of time. In this paper, we propose a novel deep learning based robot arm 3D pose estimation and calibration model with simple Kinect stereo cameras which can be deployed on light-weight edge computing systems. The light-weight deep CNN model can detection 5 predefined key points based on RGB-D data. In this way, when the assembly line composed of different robot arms needs to be reassembled, our model can quickly provide the robot's pose information without additional tuning processes. Testing in Webots with Rokae xb4 robot arm model shows that our model can quickly estimate the key point of the robot arm.",https://ieeexplore.ieee.org/document/9170983/,2020 7th IEEE International Conference on Cyber Security and Cloud Computing (CSCloud)/2020 6th IEEE International Conference on Edge Computing and Scalable Cloud (EdgeCom),1-3 Aug. 2020,ieeexplore
10.1109/RCAR.2018.8621810,Efficient and Low-Cost Deep-Learning Based Gaze Estimator for Surgical Robot Control,IEEE,Conferences,"Surgical robots are playing more and more important role in modern operating room. However, operations by using surgical robot are not easy to handle by doctors. Vision based human-computer interaction (HCI) is a way to ease the difficulty to control surgical robots. While the problem of this method is that eyes tracking devices are expensive. In this paper, a low cost and robust deep-learning based on gaze estimator is proposed to control surgical robots. By this method, doctors can easily control the robot by specifying the starting point and ending point of the surgical robot using eye gazing. Surgical robots can also be controlled to move in 9 directions using controllers' eyes gazing information. A Densely Connected convolutional Neural Networks (Dense CNN) model for 9-direction/36-direction gaze estimation is built. The Dense CNN architecture has much more less trainable parameters compared to traditional CNN network architecture (AlexNet like/VGG like) which is more feasible to deploy on the Field-Programmable Gate Array (FPGA) and other hardware with limited memories.",https://ieeexplore.ieee.org/document/8621810/,2018 IEEE International Conference on Real-time Computing and Robotics (RCAR),1-5 Aug. 2018,ieeexplore
10.1109/IROS.2016.7759250,Efficient learning of stand-up motion for humanoid robots with bilateral symmetry,IEEE,Conferences,"Standing up after falling is an essential ability for humanoid robots in order to resume their tasks without help from humans. Although many humanoid robots, especially small-size humanoid robots, have their own stand-up motions, there has not been a generalized method to automatically learn flexible stand-up motions for humanoid robots which can be applied to various fallen positions. In this research, we propose a method for learning stand-up motions for humanoid robots using Q-learning making use of their bilateral symmetry. We implemented this method on DarwIn-OP humanoid robots and learned an optimal policy in simulation. We compared the resulting stand-up motion with manually designed stand-up motions and with stand-up motions learned without considering bilateral symmetry. Both in simulation and on the real robot, the new stand-up motion was successful in most trials while other motions took longer or were not as robust.",https://ieeexplore.ieee.org/document/7759250/,2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),9-14 Oct. 2016,ieeexplore
10.1109/ROMAN.2009.5326159,Efficient parsing of spoken inputs for human-robot interaction,IEEE,Conferences,"The use of deep parsers in spoken dialogue systems is usually subject to strong performance requirements. This is particularly the case in human-robot interaction, where the computing resources are limited and must be shared by many components in parallel. A real-time dialogue system must be capable of responding quickly to any given utterance, even in the presence of noisy, ambiguous or distorted input. The parser must therefore ensure that the number of analyses remains bounded at every processing step. The paper presents a practical approach to addressing this issue in the context of deep parsers designed for spoken dialogue. The approach is based on a word lattice parser combined with a statistical model for parse selection. Each word lattice is parsed incrementally, word by word, and a discriminative model is applied at each incremental step to prune the set of resulting partial analyses. The model incorporates a wide range of linguistic and contextual features and can be trained with a simple perceptron. The approach is fully implemented as part of a spoken dialogue system for human-robot interaction. Evaluation results on a Wizard-of-Oz test suite demonstrate significant improvements in parsing time.",https://ieeexplore.ieee.org/document/5326159/,RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication,27 Sept.-2 Oct. 2009,ieeexplore
10.1109/IROS.2012.6385832,Elastic strips: Implementation on a physical humanoid robot,IEEE,Conferences,"For robots to operate in human environments, they are required to react safely to unexpected changes in the work area. However, existing manipulation task planning methods take more than several seconds or minutes to update their solutions when environmental changes are recognized. Furthermore, the computation time exponentially increases in case of highly complex structures such as humanoid robots. Therefore, we propose a reactive system for high d.o.f. robots to perform interactive manipulation tasks under real-time conditions. The paper describes the implementation of the Elastic Strip Framework, a plan modification approach to update initial motion plans. To improve its real-time performance and reliability, the previous geometric approximation is replaced by an implicit method that constructs an elastic tunnel for collision checking. Additionally, in order to maintain a robust system even in exceptional situations, such as undetected obstacles, the force transformer module executes compliant motions, and the current elastic strip adapts the path tracking motion by monitoring tracking errors of the actual motion. The proposed system is applied to a Honda humanoid robot. Real-time performance is successfully demonstrated in real-world experiments.",https://ieeexplore.ieee.org/document/6385832/,2012 IEEE/RSJ International Conference on Intelligent Robots and Systems,7-12 Oct. 2012,ieeexplore
10.1109/ICE2T.2017.8215992,Elevator button and floor number recognition through hybrid image classification approach for navigation of service robot in buildings,IEEE,Conferences,"To successfully move a robot into the building, the elevator button and elevator floor number detection and recognition can play an important role. It can help a robot move in the building, just as it also can help a visually impaired person who wants to move another floor in the building. Due to vision-based approach, the difference in lighting condition and the complex background are the main obstacles in this research. A hybrid image classification model is presented in this research to overcome all these difficulties. This hybrid model is the combination of histogram of oriented gradients and bag of words models, which later reduces the dimension of image features by using the feature selection algorithm. An artificial neural network has been implemented to get the experimental result by training and testing. In order to get training performance, 1000 training image samples have been used and additional 1000 image samples also been used to get the testing performance. The experimental results of this research indicate that this proposed framework is important for real-time implementation to implement the elevator button and elevator floor number recognition framework.",https://ieeexplore.ieee.org/document/8215992/,2017 International Conference on Engineering Technology and Technopreneurship (ICE2T),18-20 Sept. 2017,ieeexplore
10.1109/IHMSC.2013.225,Embedded Motion Controller Design Based on RTEX Network,IEEE,Conferences,"Adopting embedded framework and network communication mode, a kind of multi-axis embedded motion controller hardware platform design for the Panasonic A5N drive is proposed, which is Based on the modular control core (ARM + FPGA) and can adapt to the new real-time network RTEX. The processes of controller's functional design, hardware design and software design are explained in detail. Up to now, the motion controller's hardware platform have been completed and verified by communication experiments, position and velocity control experiments, and the results of which show that the controller have good scalability, reliability, flexibility and openness and could well meet the needs of the multi-axis robot's motion control.",https://ieeexplore.ieee.org/document/6642753/,2013 5th International Conference on Intelligent Human-Machine Systems and Cybernetics,26-27 Aug. 2013,ieeexplore
10.1109/ICIEV.2018.8641023,Embedded System based Bangla Intelligent Social Virtual Robot with Sentiment Analysis,IEEE,Conferences,"Bangla is the mother tongue of millions of people all over the world. Despite being a very popular language, any social virtual robot that can intelligently communicate in Bangla is a fairytale till now. One of the main reason of this is lack of rich text corpus and previous research on Bangla language. The proposed Bangla Intelligent Social Virtual Robot can communicate in Bangla intelligently and can express its reflective emotion virtually with the help of machine learning algorithms and sentiment analysis. In this paper, we discuss the approached system, design methodology and implementation details of first ever Bangla virtual embedded robot followed by the methodology of building a rich Bangla text corpus. The proposed embedded virtual robot turns out better performer when compared with only known Bangla intelligent chatbot named `Golpo' and the embedded system performance efficiency has been upgraded with the help CPU over-clocking technique.",https://ieeexplore.ieee.org/document/8641023/,"2018 Joint 7th International Conference on Informatics, Electronics & Vision (ICIEV) and 2018 2nd International Conference on Imaging, Vision & Pattern Recognition (icIVPR)",25-29 June 2018,ieeexplore
10.1109/IROS.2001.976268,Embedding cooperation in robots to play soccer game,IEEE,Conferences,"Robotic soccer provides an opportunity to explore such a challenging research topic that multiple agents (physical robots or sofbots) work together in a realtime, noisy and adversarial environment to obtain specific objectives. It requires each agent can not only deal with infinite unpredictable situations, but also present cooperation with others. The previous researches about cooperation often put emphasis on task decomposition and conflict avoidance among team members. In this paper, we describe a robot architecture, which addresses ""scaling cooperation"" among robots, and meanwhile keeps each robot making decision independently. The architecture is based on ""ideal cooperation"" principle and implemented for Small Robot League in RoboCup Experimental results prove its effectiveness and reveal several primary characteristics of behaviors in robotic soccer. Finally, some important problems of future work are discussed.",https://ieeexplore.ieee.org/document/976268/,Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180),29 Oct.-3 Nov. 2001,ieeexplore
10.1109/ACIIAsia.2018.8470388,Emotional Human Machine Conversation Generation Based on SeqGAN,IEEE,Conferences,"In recent years, artificial intelligence has made a significant breakthrough and progress in the field of humanmachine conversation. However, how to generate high-quality, emotional and subhuman conversation still a troublesome work. The key factor of man-machine dialogue is whether the chatbot can give a good response in content and emotional level. How to ensure that the robot understands the user's emotions, and consider the user's emotions then give a satisfactory response. In this paper, we add the emotional tags to the post and response from the dataset respectively. The emotional tags, as the emotional tags of post and response, represent the emotions expressed by this sentence. The purpose of our emotional tags is to make the chatbot understood the emotion of the input sequence more directly so that it has a recognition of the emotional dimension. In this paper, we apply the mechanism of GAN network on our conversation model. For the generator: We make full use of Encoder-Decoder structure form a seq2seq model, which is used to generate a sentence's response. For the discriminator: distinguish between the human-generated dialogues and the machine-generated ones.The outputs from the discriminator are used as rewards for the generative model, pushing the system to generate dialogues that mostly resemble human dialogues. We cast our task as an RL(Reinforcement Learning) problem, using a policy gradient method to reward more subhuman conversational sequences, and in addition we have added an emotion tags to represent the response we want to get, which we will use as a rewarding part of it, so that the emotions of real responses can be closer to the emotions we specify. Our experiment shows that through the introduction of emotional intelligence, our model can generate responses appropriate not only in content but also in emotion, which can be used to control and adjust users emotion. Compared with our previous work, we get a better performance on the same data set, and we get less ''safe'' response than before, but there will be a certain degree of existence.",https://ieeexplore.ieee.org/document/8470388/,2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia),20-22 May 2018,ieeexplore
10.1109/RO-MAN46459.2019.8956327,End-User Programming of Low-and High-Level Actions for Robotic Task Planning,IEEE,Conferences,"Programming robots for general purpose applications is extremely challenging due to the great diversity of end-user tasks ranging from manufacturing environments to personal homes. Recent work has focused on enabling end-users to program robots using Programming by Demonstration. However, teaching robots new actions from scratch that can be reused for unseen tasks remains a difficult challenge and is generally left up to robotic experts. We propose iRoPro, an interactive Robot Programming framework that allows end-users to teach robots new actions from scratch and reuse them with a task planner. In this work we provide a system implementation on a two-armed Baxter robot that (i) allows simultaneous teaching of low-and high-level actions by demonstration, (ii) includes a user interface for action creation with condition inference and modification, and (iii) allows creating and solving previously unseen problems using a task planner for the robot to execute in real-time. We evaluate the generalisation power of the system on six benchmark tasks and show how taught actions can be easily reused for complex tasks. We further demonstrate its usability with a user study (N=21), where users completed eight tasks to teach the robot new actions that are reused with a task planner. The study demonstrates that users with any programming level and educational background can easily learn and use the system.",https://ieeexplore.ieee.org/document/8956327/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/ICCE.2018.8326229,End-to-end deep learning for autonomous navigation of mobile robot,IEEE,Conferences,"This paper proposes an end-to-end method for training convolutional neural networks for autonomous navigation of a mobile robot. Traditional approach for robot navigation consists of three steps. The first step is extracting visual features from the scene using the camera input. The second step is to figure out the current position by using a classifier on the extracted visual features. The last step is making a rule for moving the direction manually or training a model to handle the direction. In contrast to the traditional multi-step method, the proposed visuo-motor navigation system can directly output the linear and angular velocities of the robot from an input image in a single step. The trained model gives wheel velocities for navigation as outputs in real-time making it possible to be implanted on mobile robots such as robotic vacuum cleaner. The experimental results show an average linear velocity error of 2.2 cm/s and average angular velocity error of 3.03 degree/s. The robot deployed with the proposed model can navigate in a real-world environment by only using the camera without relying on any other sensors such as LiDAR, Radar, IR, GPS, IMU.",https://ieeexplore.ieee.org/document/8326229/,2018 IEEE International Conference on Consumer Electronics (ICCE),12-14 Jan. 2018,ieeexplore
10.1109/SEAMS51251.2021.00015,Enhancing Human-in-the-Loop Adaptive Systems through Digital Twins and VR Interfaces,IEEE,Conferences,"Self-adaptation approaches usually rely on closed-loop controllers that avoid human intervention from adaptation. While such fully automated approaches have proven successful in many application domains, there are situations where human involvement in the adaptation process is beneficial or even necessary. For such “human-in-the-loop” adaptive systems, two major challenges, namely transparency and controllability, have to be addressed to include the human in the self-adaptation loop. Transparency means that relevant context information about the adaptive systems and its context is represented based on a digital twin enabling the human an immersive and realistic view. Concerning controllability, the decision-making and adaptation operations should be managed in a natural and interactive way. As existing human-in-the-loop adaptation approaches do not fully cover these aspects, we investigate alternative human-in-the-loop strategies by using a combination of digital twins and virtual reality (VR) interfaces. Based on the concept of the digital twin, we represent a self-adaptive system and its respective context in a virtual environment. With the help of a VR interface, we support an immersive and realistic human involvement in the self-adaptation loop by mirroring the physical entities of the real world to the VR interface. For integrating the human in the decision-making and adaptation process, we have implemented and analyzed two different human-in-the-loop strategies in VR: a procedural control where the human can control the decision making-process and adaptations through VR interactions (human-controlled) and a declarative control where the human specifies the goal state and the configuration is delegated to an AI planner (mixed-initiative). We illustrate and evaluate our approach based on an autonomic robot system that is accessible and controlled through a VR interface.",https://ieeexplore.ieee.org/document/9462035/,2021 International Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS),18-24 May 2021,ieeexplore
10.1109/ICRA48506.2021.9562114,Enhancing Robot Perception in Grasping and Dexterous Manipulation through Crowdsourcing and Gamification,IEEE,Conferences,"Robot grasping and manipulation planning in unstructured and dynamic environments is heavily dependent on the attributes of manipulated objects. Although deep learning approaches have delivered exceptional performance in robot perception, human perception and reasoning are still superior in processing novel object classes. Moreover, training such models requires large datasets that are generally expensive to obtain. This work combines crowdsourcing and gamification to leverage human intelligence, enhancing the object recognition and attribute estimation aspects of robot perception. The framework employs an attribute matching system that encodes visual information into an online puzzle game, utilizing the collective intelligence of players to expand an initial attribute database and react to real-time perception conflicts. The framework is deployed and evaluated in a proof-of-concept application for enhancing object recognition in autonomous robot grasping and a model for estimating the response time is proposed. The obtained results demonstrate that given enough players, the framework can offer near real-time labeling of novel objects, based purely on visual information and human experience.",https://ieeexplore.ieee.org/document/9562114/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ISIC.2001.971506,Enhancing control architectures using CORBA,IEEE,Conferences,"The nature of applied research in intelligent robot controllers makes having a versatile software architecture a real need for exploring alternative designs in robotic minds construction. The paper presents an experiment in the adaptation of a multi-robot cooperation architecture to a CORBA-based schema. The paper demonstrates not only the feasibility but the convenience of using, state-of-the-art, modular software technologies for the construction of advanced intelligent controllers.",https://ieeexplore.ieee.org/document/971506/,Proceeding of the 2001 IEEE International Symposium on Intelligent Control (ISIC '01) (Cat. No.01CH37206),5-7 Sept. 2001,ieeexplore
10.1109/IECON.2017.8217492,Enhancing the familiarity for humanoid robot pepper by adopting customizable motion,IEEE,Conferences,"Most of the works use sensor to recognize human gesture and teleoperate robot in real time for different usage. One of the purpose is social learning which human learn behavior and take place in the social context. Our research aims to let user create customizable gesture and motion for proper condition. This paper presented the method to replicates human gesture for robot imitation. If robot can adapt human like behavior to interact with human, it is potentially helpful to build intimate between human and robot. Human gesture were recorded and unnecessary noise was removed to smooth robot's motion. Furthermore, by changing motion speed it is possible to create different feeling so that it might be arouse human's interest and spice up the interaction. The experiment results show the parameter pair to implement motion on robot.",https://ieeexplore.ieee.org/document/8217492/,IECON 2017 - 43rd Annual Conference of the IEEE Industrial Electronics Society,29 Oct.-1 Nov. 2017,ieeexplore
10.1109/ICIA.2006.306024,Environmental Perception of Mobile Robot,IEEE,Conferences,"This paper builds a system to perceive the unknown environment based on multi-sensor data fusion. It enables the self-determined mobile robot to identify the type of the obstacles around it timely in the process of travel, and the mobile robot achieves more intelligent operations. First, the paper introduces the theory of the mobile robot's environmental perception and the configuration of the multi-sensor data fusion technology. Second, it combines the characteristics of neural network (NN) and brings forward that apply the MLP (multi-layer perception), which based on the improved back propagation (BP) arithmetic and four mature items of fusion rules, to perceive the real surroundings aiming at simplifying the former solving projects. Third, the paper presents a structure of multi-sensor data fusion, which two sub-networks for barrier recognition are separately built and incorporates with each other by parallel connection to form a high-powered recognition system. Finally, the results of experiment present that the method given by the paper are very pleasant",https://ieeexplore.ieee.org/document/4097957/,2006 IEEE International Conference on Information Acquisition,20-23 Aug. 2006,ieeexplore
10.1109/ICCAE.2009.52,Environmental Recognition Using RAM-Network Based Type-2 Fuzzy Neural for Navigation of Mobile Robot,IEEE,Conferences,"Reactive autonomous mobile robot navigating in real time environment is one of the most important requirements. Most of the systems have some common drawbacks such as, large computation, expensive equipment, hard implementation, and the complexity of the system. The work presented in this paper deals with a type-2 fuzzy-neural controller using RAM-based network to make navigation decisions. The proposed architecture can be implemented easily with low cost range sensor and low cost microprocessor. To minimize the execution time, we used a look-up table and that output stored into the robot RAM memory and becomes the current controller that drives the robot. This functionality is demonstrated on a mobile robot using a simple, 8 bit microcontroller with 512 bytes of RAM. The experiment results show that source code is efficient, works well, and the robot was able to successfully avoid obstacle in real time.",https://ieeexplore.ieee.org/document/4804536/,2009 International Conference on Computer and Automation Engineering,8-10 March 2009,ieeexplore
10.1109/ICRA40945.2020.9197510,Episodic Koopman Learning of Nonlinear Robot Dynamics with Application to Fast Multirotor Landing,IEEE,Conferences,"This paper presents a novel episodic method to learn a robot's nonlinear dynamics model and an increasingly optimal control sequence for a set of tasks. The method is based on the Koopman operator approach to nonlinear dynamical systems analysis, which models the flow of observables in a function space, rather than a flow in a state space. Practically, this method estimates a nonlinear diffeomorphism that lifts the dynamics to a higher dimensional space where they are linear. Efficient Model Predictive Control methods can then be applied to the lifted model. This approach allows for real time implementation in on-board hardware, with rigorous incorporation of both input and state constraints during learning. We demonstrate the method in a real-time implementation of fast multirotor landing, where the nonlinear ground effect is learned and used to improve landing speed and quality.",https://ieeexplore.ieee.org/document/9197510/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/WCICA.2000.863468,Estimated force emulation for space robot using neural networks,IEEE,Conferences,"This paper introduces the telerobotic system estimated force emulation using neural networks. A delay-compensating 3D stereo-graphic simulator is implemented in SGI ONYX/4 RE/sup 2/. The estimated force emulation can protect the real robot in time from being damaged in collision. The neural network is used to learn the mapping between the contact force error and the accommodated position command to the controller of the space robot. Finally, the controller can feel the emulated force with a two-hand 6-DOF master arm using the force feedback interface.",https://ieeexplore.ieee.org/document/863468/,Proceedings of the 3rd World Congress on Intelligent Control and Automation (Cat. No.00EX393),26 June-2 July 2000,ieeexplore
10.1109/IJCNN.2015.7280802,Estimating multimodal attributes for unknown objects,IEEE,Conferences,"If a robot is expected to perform in the real-world, the robot should recognize objects in such environment using its multimodal sensors in real-time. Traditional multimodal object classification methods focus on recognizing known objects; however, it is impossible to learn all objects that we use. On the other hand, the classification of unknown objects has become a popular topic in image processing. However popular methods have batch algorithms, and there is no method to integrate multimodal classification results with an online algorithm. This study proposes a novel method that estimates multimodal attributes of an unknown object. The method uses an ultra-fast and online learning method based on a STAR-SOINN, which stands for STAtistical Recognition on Self-Organizing and Incremental Neural Network. The results from a comparative experiment show that the recognition accuracy for known objects is higher than a method that naïvely integrates the modalities and a previous method. And this method works very quickly: approximately 1 second to learn one object, and 25 millisecond for a single estimation. We also conducted an experiment to estimate attributes of unknown objects, it could estimate approximately 90% of the attributes for these objects.",https://ieeexplore.ieee.org/document/7280802/,2015 International Joint Conference on Neural Networks (IJCNN),12-17 July 2015,ieeexplore
10.1109/ROBIO.2015.7418768,Evolving hidden Markov model based human intention learning and inference,IEEE,Conferences,"To effectively facilitate human robot cooperation, human intention should be recognized by robot accurately and effectively. Teaching the robot human intentions in advance could be well suitable for a static environment with limited tasks. Nevertheless, in an dynamic environment that requires task update, the pre-teaching approach cannot satisfy the evolving knowledge of human intention. The unknown human intentions which have not been taught in advance, will not be understood by robot. This problem limits the human robot cooperation in a real dynamic environment. In this paper, we proposed a human intention learning and inference method to improve the intuitive cooperative capability of the robot. An evolving hidden Markov model (EHMM) approach has been developed to learn and infer human intentions according to the observation. Assembly tasks with ten different configurations have been designed and simulation experiments were carried out. Four assembly configurations have been used for known human intention recognition experiment and six configurations have been used for unknown human intention learning and inference experiment. The accurate and robust results obtained from the experiments have shown the feasibility of the proposed EHMM for human intention learning and inference.",https://ieeexplore.ieee.org/document/7418768/,2015 IEEE International Conference on Robotics and Biomimetics (ROBIO),6-9 Dec. 2015,ieeexplore
10.1109/ICITA.2005.135,Experiences with simulated robot soccer as a teaching tool,IEEE,Conferences,"The development of assignments for undergraduate teaching typically requires a compromise between what is achievable by an average student and what engages the interest of a more advanced member of the class. Selecting a suitable compromise is particularly problematic for undergraduate artificial intelligence (AI) courses which typically attempt to cover a very broad range of topics, without delving too deeply into the details. Ideally, a single problem would be selected whose solution could be approached with more than one technique covered in the course, enabling students to carry out a comparative analysis of performance. Robot soccer simulation has provided an interesting platform for artificial intelligence research and is increasingly being used as a teaching apparatus. There are a number of limitations with existing simulation methodologies for this purpose. Current robot soccer simulators are aimed at research groups where accuracy is paramount and all facets of the real system must be emulated. However, many of the intricacies of a real robot soccer player are inappropriate for a teaching environment, as they detract from desired learning outcomes. Consequently, there is a need for a simulation that employs a simplified set of game rules and dynamics. This paper describes the design and implementation of such a framework and presents experiences gained from its use as a third year practical.",https://ieeexplore.ieee.org/document/1488833/,Third International Conference on Information Technology and Applications (ICITA'05),4-7 July 2005,ieeexplore
10.1109/ICA-SYMP.2019.8646199,Experiment on Real-Time Image Processing in the Controlling of Mecanum Wheel Robotic Car,IEEE,Conferences,"The control method of the mecanum wheel robotic car is accomplished by computer vision. The camera attached to the computer is for the purpose of image processing with open source computer vision (OpenCV). It can capture the locations of the wheel robot and the target by the use of open source computer vision as pattern recognition scheme. By using the Oriented FAST and Rotated Brief (ORB) feature, the program finds the patterns. The locations of the target and the robot are obtained by K-Mean Clustering method. And then, the programming method is used to calculate their location difference to generate a movement command. The movement command is then sent to the microcontroller of wheel robot system by means of wireless communication using NRF radio modules. By doing so, the robotic car goes to target with the command of computer vision program. The experimental results confirmed that the performance of the control algorithm could be utilized for the real-time condition.",https://ieeexplore.ieee.org/document/8646199/,"2019 First International Symposium on Instrumentation, Control, Artificial Intelligence, and Robotics (ICA-SYMP)",16-18 Jan. 2019,ieeexplore
10.1109/RIOS.2016.7529488,Experimental stability study of an Octorotor using an intelligent controller,IEEE,Conferences,"In this paper, the attitude stabilization problem of an Octorotor with coaxial motors is studied. To this end, the new method of intelligent adaptive control is presented. The designed controller which includes fuzzy and PID controllers, is completed by resistant adaptive function of approximate external disturbance and changing in the dynamic model. In fact, the regulation factor of PID controller is done by the fuzzy logic system. At first, the Fuzzy-PID and PID controllers are simulated in MATLAB/Simulink. Then, the Fuzzy-PID controller is implemented on the Octorotor with coaxial motors as online auto-tuning. Also, LabVIEW software has been used for tests and the performance analysis of the controllers. All of this experimental operation is done in indoor environment in the presence of wind as disturbance in the hovering operation. All of these operations are real-time and telemetry wireless is done by network connection between the robot and ground station in the LABVIEW software. Finally, the controller efficiency and results are studied.",https://ieeexplore.ieee.org/document/7529488/,2016 Artificial Intelligence and Robotics (IRANOPEN),9-9 April 2016,ieeexplore
10.1109/ICRA.2019.8793829,Exploiting Trademark Databases for Robotic Object Fetching,IEEE,Conferences,"Service robots require the ability to recognize various household objects in order to carry out certain tasks, such as fetching an object for a person. Manually collecting information on all the objects a robot may encounter in a household is tedious and time-consuming; therefore this paper proposes the use of large-scale data from existing trademark databases. These databases contain logo images and a description of the goods and services the logo was registered under. For example, Pepsi is registered under soft drinks. We extend domain randomization in order to generate synthetic data to train a convolutional neural network logo detector, which outperformed previous logo detectors trained on synthetic data. We also provide a practical implementation for object fetching on a robot, which uses a Kinect and the logo detector to identify the object the human user requested. Tests on this robot indicate promising results, despite not using any real world photos for training.",https://ieeexplore.ieee.org/document/8793829/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/Humanoids.2011.6100913,Exploiting previous experience to constrain robot sensorimotor learning,IEEE,Conferences,"A truly autonomous robot should be able to generalize known actions to new situations and to autonomously refine its knowledge base. In this paper we present a three stage approach to the problem of expanding and refining the database of sensorimotor knowledge. The first stage is based on the generalization of previously trained movements associated with a specific task, which results in a first approximation of a suitable control policy in a new situation. The second stage applies learning on the manifold defined by the previously acquired training data, which results in a learning problem of reduced dimensionality. The final tuning of the desired control policy is accomplished by learning in the full state space, where the dimensionality of the problem is much higher. The assumption is that the first two steps already provide a good initial estimate for the optimal control policy so that this final step only locally refines the parameters learned in the first two steps. This significantly reduces the number of test trials needed by standard reinforcement learning techniques. The proposed approach was evaluated in simulation as well as on the real robot in a ball throwing experiment.",https://ieeexplore.ieee.org/document/6100913/,2011 11th IEEE-RAS International Conference on Humanoid Robots,26-28 Oct. 2011,ieeexplore
10.1109/AIM.2019.8868536,Exploiting the ACCuracy-ACCeleration tradeoff: VINS-assisted real-time object detection on moving systems,IEEE,Conferences,"In recent years, Convolutional Neural Networks (CNNs) have repeatedly shown state-of-the-art performance for their accuracy in the task of object detection, but their heavy computational costs impede their ability for real-time detection when the supporting system is moving, particularly when it is accelerating. At the same time, recent progress on visual inertial systems takes great advantage of movement information to robustly estimate the robot state and its surrounding. This paper proposes to exploit the advantages of inertial odometry research for the purpose of real-time object detection system on mobile robots. We combine a CNN detector with VINS-Mono, a moving visual odometry system, and show reliable improvement in the detection process, especially when the robot accelerates or decelerates. Our system is ready-to-use in that it has very low deployment cost and requires no calibration. The resulting system allows for simultaneous robot state estimation and object detection, as well as object tracking. Lastly, this architecture proves to be flexible because not restrained to a specific object type or detector.",https://ieeexplore.ieee.org/document/8868536/,2019 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM),8-12 July 2019,ieeexplore
10.1109/ICAIE50891.2020.00028,Exploration and Practice on Industrial Robot Experimental Teaching Based on Virtuality and Reality Combination,IEEE,Conferences,"In view of the common problems currently existing in the industrial robot experimental teaching in the higher vocational colleges, this paper, through deep integration of the traditional experimental teaching and the virtual simulation technology, proposes the industrial robot experimental teaching mode based on the combination of virtuality and reality. The teaching process is divided into three parts: pre-class, in-class and post-class, and the experimental teaching design is elaborated in details by taking the “material blocks handling experiment” as an example. Practices proved that the experimental teaching mode based on the virtuality and reality combination has improved the efficiency and quality of classroom teaching, enriched the after-school time of students and improved the depth and scope of learning, which played a positive role in promoting the specialty construction and talent cultivation, and could provide reference for the experimental teaching of related specialties in similar colleges and universities.",https://ieeexplore.ieee.org/document/9262587/,2020 International Conference on Artificial Intelligence and Education (ICAIE),26-28 June 2020,ieeexplore
10.1109/ICVRIS.2018.00078,Exploration of Computer Emotion Decision Based on Artificial Intelligence,IEEE,Conferences,"To carry out the discussion of computer emotion decision based on artificial intelligence, first of all, based on the psychological experiment paradigm of children's game task, and the test process of the artificial emotion generating engine was completed on the emotional spontaneous transfer and the stimulus transfer model. Secondly, the reasoning method and analytic hierarchy process (AHP) were introduced into the multi system, and a kind of multi emotion decision model based on the emotion reasoning was constructed. The hierarchical structure method was used to solve the complex decision problem of the humanoid robot in the intelligent home environment. Then, based on the emotion energy theory, a mood state regulation algorithm based on the combination of HMM-based spontaneous transfer and stimulus transfer was established. In addition, on this basis, the design and implementation of humanoid robot associative memory model was realized. Finally, the theory and algorithm were integrated into the interactive platform of human-computer expression, and the validity of the model was analysed and verified. The results showed that, on this robot platform, the process of human-computer interaction and cooperation which integrated emotion evaluation, emotional decision, associative memory and emotion regulation was realized. As a result, the computer emotion decision based on artificial intelligence can be well applied in many fields.",https://ieeexplore.ieee.org/document/8531405/,2018 International Conference on Virtual Reality and Intelligent Systems (ICVRIS),10-11 Aug. 2018,ieeexplore
10.1109/SIEDS49339.2020.9106581,"Explorer51 – Indoor Mapping, Discovery, and Navigation for an Autonomous Mobile Robot",IEEE,Conferences,"The nexus of robotics, autonomous systems, and artificial intelligence (AI) has the potential to change the nature of human guided exploration of indoor and outdoor spaces. Such autonomous mobile robots can be incorporated into a variety of applications, ranging from logistics and maintenance, to intelligence gathering, surveillance, and reconnaissance (ISR). One such example is that of a tele-operator using the robot to generate a map of the inside of a building while discovering and tagging the objects of interest. During this process, the tele-operator can also assign an area for the robot to navigate autonomously or return to a previously marked area/object of interest. Search and rescue and ISR abilities could be immensely improved with such capabilities. The goal of this research is to prototype and demonstrate the above autonomous capabilities in a mobile ground robot called Explorer51. Objectives include: (i) enabling an operator to drive the robot non-line of sight to explore a space by incorporating a first-person view (FPV) system to stream data from the robot to the base station; (ii) implementing automatic collision avoidance to prevent the operator from running the robot into obstacles; (iii) creating and saving 2D and 3D maps of the space in real time by using a 2D laser scanner, tracking, and depth/RGB cameras; (iv) locating and tagging objects of interest as waypoints within the map; (v) autonomously navigate within the map to reach a chosen waypoint. To accomplish these goals, we are using the AION Robotics R1 Unmanned Ground Vehicle (UGV) rover as the platform for Explorer51 to demonstrate the autonomous features. The rover runs the Robot Operating System (ROS) onboard an NVIDIA Jetson TX2 board, connected to a Pixhawk controller. Sensors include a 2D scanning LiDAR, depth camera, tracking camera, and an IMU. Using existing ROS packages such as Cartographer and TEB planner, we plan to implement ROS nodes for accomplishing these tasks. We plan to extend the mapping ability of the rover using Visual Inertial Odometry (VIO) using the cameras. In addition, we will explore the implementation of additional features such as autonomous target identification, waypoint marking, collision avoidance, and iterative trajectory optimization. The project will culminate in a series of demonstrations to showcase the autonomous navigation, and tele-operation abilities of the robot. Success will be evaluated based on ease of use by the tele-operator, collision avoidance ability, autonomous waypoint navigation accuracy, and robust map creation at high driving speeds.",https://ieeexplore.ieee.org/document/9106581/,2020 Systems and Information Engineering Design Symposium (SIEDS),24-24 April 2020,ieeexplore
10.1109/IJCNN.2019.8852425,Exploring Deep Models for Comprehension of Deictic Gesture-Word Combinations in Cognitive Robotics,IEEE,Conferences,"In the early stages of infant development, gestures and speech are integrated during language acquisition. Such a natural combination is therefore a desirable, yet challenging, goal for fluid human-robot interaction. To achieve this, we propose a multimodal deep learning architecture, for comprehension of complementary gesture-word combinations, implemented on an iCub humanoid robot. This enables human-assisted language learning, with interactions like pointing at a cup and labelling it with a vocal utterance. We evaluate various depths of the Mask Regional Convolutional Neural Network (for object and wrist detection) and the Residual Network (for gesture classification). Validation is carried out with two deictic gestures across ten real-world objects on frames recorded directly from the iCub's cameras. Results further strengthen the potential of gesture-word combinations for robot language acquisition.",https://ieeexplore.ieee.org/document/8852425/,2019 International Joint Conference on Neural Networks (IJCNN),14-19 July 2019,ieeexplore
10.1109/ROMAN.2017.8172449,Exploring data augmentation methods in reverberant human-robot voice communication,IEEE,Conferences,"Collecting training data is not an easy task especially in situation involving robots that require tremendous physical effort. The ability to augment data through synthetic means is a convenient tool to solve this problem. Therefore it is important to evaluate the extent of the usefulness of augmented data. In this paper, we will explore data augmentation schemes in reverberant environment and investigate a method to effectively select data. We experiment in a real reverberant environment condition and investigate both the traditional automatic speech recognition (ASR) system based on gaussian mixture model-hidden markov model (GMM-HMM) and the most current system based on Deep Neural Networks (i.e, HMM-DNN). Our results show that the combination of data augmentation and data selection, further improves system performance. In our experiments, we used real test data in a reverberant hands-free human-robot communication scenario.",https://ieeexplore.ieee.org/document/8172449/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/ICORR.2019.8779424,Exploring the Impact of Machine-Learned Predictions on Feedback from an Artificial Limb,IEEE,Conferences,"Learning to get by without an arm or hand can be very challenging, and existing prostheses do not yet fill the needs of individuals with amputations. One promising solution is to improve the feedback from the device to the user. Towards this end, we present a simple machine learning interface to supplement the control of a robotic limb with feedback to the user about what the limb will be experiencing in the near future. A real-time prediction learner was implemented to predict impact-related electrical load experienced by a robot limb; the learning system's predictions were then communicated to the device's user to aid in their interactions with a workspace. We tested this system with five able-bodied subjects. Each subject manipulated the robot arm while receiving different forms of vibrotactile feedback regarding the arm's contact with its workspace. Our trials showed that using machine-learned predictions as a basis for feedback led to a statistically significant improvement in task performance when compared to purely reactive feedback from the device. Our study therefore contributes initial evidence that prediction learning and machine intelligence can benefit not just control, but also feedback from an artificial limb. We expect that a greater level of acceptance and ownership can be achieved if the prosthesis itself takes an active role in transmitting learned knowledge about its state and its situation of use.",https://ieeexplore.ieee.org/document/8779424/,2019 IEEE 16th International Conference on Rehabilitation Robotics (ICORR),24-28 June 2019,ieeexplore
10.1109/ICRA48506.2021.9561040,Extendable Navigation Network based Reinforcement Learning for Indoor Robot Exploration,IEEE,Conferences,This paper presents a navigation network based deep reinforcement learning framework for autonomous indoor robot exploration. The presented method features a pattern cognitive non-myopic exploration strategy that can better reflect universal preferences for structure. We propose the Extendable Navigation Network (ENN) to encode the partially observed high-dimensional indoor Euclidean space to a sparse graph representation. The robot’s motion is generated by a learned Q-network whose input is the ENN. The proposed framework is applied to a robot equipped with a 2D LIDAR sensor in the GAZEBO simulation where floor plans of real buildings are implemented. The experiments demonstrate the efficiency of the framework in terms of exploration time.,https://ieeexplore.ieee.org/document/9561040/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ROBOT.2003.1241690,Extended QDSEGA for controlling real robots - acquisition of locomotion patterns for snake-like robot,IEEE,Conferences,"Reinforcement learning is very effective for robot learning. It is because it does not need prior knowledge and has higher capability of reactive and adaptive behaviors. In our previous works, we proposed new reinforce learning algorithm: ""Q-learning with dynamic structuring of exploration space based on genetic algorithm (QDSEGA)"". It is designed for complicated systems with large action-state space like a robot with many redundant degrees of freedom. However the application of QDSEGA is restricted to static systems. A snake-like robot has many redundant degrees of freedom and the dynamics of the system are very important to complete the locomotion task. So application of usual reinforcement learning is very difficult. In this paper, we extend layered structure of QDSEGA so that it becomes possible to apply it to real robots that have complexities and dynamics. We apply it to acquisition of locomotion pattern of the snake-like robot and demonstrate the effectiveness and the validity of QDSEGA with the extended layered structure by simulation and experiment.",https://ieeexplore.ieee.org/document/1241690/,2003 IEEE International Conference on Robotics and Automation (Cat. No.03CH37422),14-19 Sept. 2003,ieeexplore
10.1109/AMC.2019.8371065,"Extending the life of legacy robots: MDS-Ach, a real-time, process based, networked, secure middleware based on the x-Ach methodology",IEEE,Conferences,"This work shows how to add modern tools to legacy robots while retaining the original tools and original calibration procedures/utilities through the use of a lightweight middleware connected to the communications level of the robot. MDS-Ach is a middleware made for the Xitome Mobile Dexterous Social (MDS) Robot originally released in 2008. The robot is being actively used at multiple locations including the U.S. Naval Research Laboratory's Laboratory for Autonomous Systems Research (NRL-LASR). The MDS-Ach middleware gives the MDS Robot the software capabilities of modern robot systems using the x- Ach real-time processes based architecture. It controls the MDS Robot directly over the controller area network (CAN) bus via a dedicated real-time daemon. Each process communicates with the others over a network capable shared memory. The shared memory is a ""first-in-last-out"" (i.e. reads the newest data first) non-head-of-line blocking ring buffer which ensures readability of latest data first while retaining the ability to retrieve the older data. When running over a network, UDP or TCP protocol can be utilized depending on the timing and reliability requirements. SSH tunneling is used when secure connections between networked controllers are required. The MDS-Ach middleware is designed to allow for simple and easy development with modern robotic tools while adding accessibility and usability to our non-hardware-focused partners. Real-time collision avoidance and a robust inverse kinematics solution are implemented within the MDS-Ach system. Examples of collision avoidance, inverse kinematics implementation, and the software architecture are given.",https://ieeexplore.ieee.org/document/8371065/,2018 IEEE 15th International Workshop on Advanced Motion Control (AMC),9-11 March 2018,ieeexplore
10.1109/ICUSAI47366.2019.9124850,FD-SLAM: Real-time Tracking and Mapping in Dynamic Environments,IEEE,Conferences,"A robot needs the ability of Simultaneous Localization and Mapping(SLAM) in an unknown environment. It can help the robot navigation and tracking. The traditional method only considers that the robot works in a static environment. But in most cases, the robot should work in a highly dynamic environment like people. This paper presents a novel SLAM system named FD-SLAM, building on ORB-SLAM2 [1], which adds the abilities of dynamic object detection and fusion of depth image and semantic image to better estimate the position of people in an image. To improve the real-time performance of FD-SLAM, it has five threads that run simultaneously in FD-SLAM: tracking, semantic segmentation, local mapping, loop closing, and point cloud mapping. FD-SLAM uses the deep neural network algorithm to detect the dynamic object and combine the depth image with the corresponding semantic image to obtain a more accurate position of a dynamic object thus reducing the impact of dynamic objects to more accurately estimate the pose of the camera. Finally, the point cloud thread uses each keyframe to create a point cloud map. We experiment with a public dataset. The results show that the absolute trajectory error of FD-SLAM is smaller than that of ORB-SLAM and DS-SLAM, and it has better real-time performance than other SLAM systems for a dynamic environment.",https://ieeexplore.ieee.org/document/9124850/,2019 IEEE International Conference on Unmanned Systems and Artificial Intelligence (ICUSAI),22-24 Nov. 2019,ieeexplore
10.1109/FPT.2009.5377635,FPGA implementation of mixed integer quadratic programming solver for mobile robot control,IEEE,Conferences,"We propose a high-speed mixed integer quadratic programming (MIQP) solver on an FPGA. The MIQP solver can be applied to various optimizing applications including real-time robot control. In order to rapidly solve the MIQP problem, we implement reusing a first solution (first point), pipeline architecture, and multi-core architecture on the single FPGA. By making use of them, we confirmed that 79.5% of the cycle times are reduced, compared with straightforward sequential processing. The operating frequency is 67 MHz, although a core 2 duo PC requires 3.16 GHz in processing the same size problem. The power consumption of the MIQP solver is 4.2 W.",https://ieeexplore.ieee.org/document/5377635/,2009 International Conference on Field-Programmable Technology,9-11 Dec. 2009,ieeexplore
10.1109/RCAR52367.2021.9517666,FPGA-based Deep Learning Acceleration for Visual Grasping Control of Manipulator,IEEE,Conferences,"The vision-based robotic arm control system is an important solution for intelligent production, and the robotic arm visual grasping system based on deep learning is an important branch. Aiming at the requirements of fast visual recognition speed, low power consumption and high precision of mobile visual grasping robot, a deep learning target detection scheme based on FPGA hardware acceleration is proposed. Use Vivado and Petalinux development kit to build the software and hardware system, then deploy YOLOv3 model in the system. Experiments show that the solution meets the demand of robotic arm visual grasping, and the real-time performance is better. The recognition speed is 18 times that of the CPU, the power consumption is 1/13 of the GPU, and the cost is lower.",https://ieeexplore.ieee.org/document/9517666/,2021 IEEE International Conference on Real-time Computing and Robotics (RCAR),15-19 July 2021,ieeexplore
10.1109/CECNET.2011.5768500,Face detection and recognition method based on skin color and depth information,IEEE,Conferences,"An improved face detection and recognition method based on information of skin color and depth obtained by binocular vision system was proposed in this paper. With this method, the face area was detected firstly by using Adaboost algorithm. Afterwards, the real face was distinguished from fake one by using the skin color information and the depth data. Then, by using PCA algorithm, a specific face can be recognized by comparing the principal components of the current face to those of the known individuals in a facial database built in advance. This method was applied to a service robot equipped with a binocular camera system for real-time face detection and recognition experiment, and satisfactory results were obtained.",https://ieeexplore.ieee.org/document/5768500/,"2011 International Conference on Consumer Electronics, Communications and Networks (CECNet)",16-18 April 2011,ieeexplore
10.1109/MMSP.2002.1203300,Face recognition by incremental learning for robotic interaction,IEEE,Conferences,"One of the important features for human-robot interaction is its ability to recognize human faces. This paper presents a novel architecture suitable for real time robotic face recognition by learning a person's face incrementally. The Gabor features at respective feature locations of a face are used to derive a similarity measurement. A face tracking followed by a clustering technique is used to learn a person's face appearance variance when the system interacts with the person. The recognition by learning proposed in this paper is similar to the partial memory incremental learning method, where we proposed a novel approach to the learning and updating process. Experiment shows significant improvement in the face recognition performance after learning over the time and with more interaction between a person and the system.",https://ieeexplore.ieee.org/document/1203300/,2002 IEEE Workshop on Multimedia Signal Processing.,9-11 Dec. 2002,ieeexplore
10.1109/ICSMC.1997.633250,Facial interaction between animated 3D face robot and human beings,IEEE,Conferences,"We study the realization of a realistic human-like response of an animated 3D face robot in communicative interaction with human beings. The face robot can produce human-like facial expressions and recognize human facial expressions using facial image data obtained by a CCD camera mounted inside the left eyeball. We developed the real time machine recognition of facial expressions by using a layered neural network and achieved a high correct recognition ratio of 85% with respect to 6 typical facial expressions of 15 subjects in 55 ms. We also developed a new small-size actuator for display of facial expressions on the face robot, giving the same speed in dynamic facial expressions as in human even in the case of a high-speed expression of ""surprise"". For facial interactive communication between the face robot and human beings, we integrated these two technologies to produce the facial expression in respond to the recognition result of the human facial expression in real time. This implies a high technological potential for the animated face robot to undertake interactive communication with human when an artificial emotion being implemented.",https://ieeexplore.ieee.org/document/633250/,"1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation",12-15 Oct. 1997,ieeexplore
10.1109/UR49135.2020.9144836,Fall detection based on CNN models implemented on a mobile robot,IEEE,Conferences,"Fall accidents are serious events that need to be addressed. Generally, elderly people could suffer these accidents that may lead injures or even death. The use of Convolutional Neural Networks (CNN) has achieved the state of the art for fall detection, but it requires a high computational cost. In this work, we propose an efficient CNN architecture with a reduced number of parameters, which is applied to fall detection in a service with a mobile robot, equipped with a resource-constrained hardware (Nvidia Jetson TX2 platform). Also, different pre-trained CNN models are compared to measure their performances in real scenarios, in addition with other functions like following people and navigation. Furthermore, fall detection is carried out by extraction of temporal features obtained with an Optical Flow extraction from two consecutive RGB images. The proposed network is confirmed by our results to be faster and more suitable for running on resource-constrained Hardware. Our model achieves 88.55% of accuracy using the proposed architecture and it works at 23.16 FPS on GPU and 10.23 FPS on CPU.",https://ieeexplore.ieee.org/document/9144836/,2020 17th International Conference on Ubiquitous Robots (UR),22-26 June 2020,ieeexplore
10.1109/ICRA40945.2020.9197159,Fast Adaptation of Deep Reinforcement Learning-Based Navigation Skills to Human Preference,IEEE,Conferences,"Deep reinforcement learning (RL) is being actively studied for robot navigation due to its promise of superior performance and robustness. However, most existing deep RL navigation agents are trained using fixed parameters, such as maximum velocities and weightings of reward components. Since the optimal choice of parameters depends on the use-case, it can be difficult to deploy such existing methods in a variety of real-world service scenarios. In this paper, we propose a novel deep RL navigation method that can adapt its policy to a wide range of parameters and reward functions without expensive retraining. Additionally, we explore a Bayesian deep learning method to optimize these parameters that requires only a small amount of preference data. We empirically show that our method can learn diverse navigation skills and quickly adapt its policy to a given performance metric or to human preference. We also demonstrate our method in real-world scenarios.",https://ieeexplore.ieee.org/document/9197159/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ISPACS.2018.8923369,Fast Recognition and Control of Walking Mode for Humanoid Robot Based on Pressure Sensors and Nearest Neighbor Search,IEEE,Conferences,"In this paper, we propose a nearest-neighbor multi-reference learning system for control of humanoid-robot movements, using real-time data from pressure sensors embedded in the robot feet, which is processed with parallelized pipeline architecture for high-speed recognition of actual surface conditions. A first nearest-neighbor (1-NN) classifier is used to recognize the most similar reference pattern in terms of the smallest Euclidean distance. Our proposed architecture achieves a classification time of about 2.4μ s with a total power consumption of 8.53mW at 100 MHz operating frequency when implemented on a low-cost FPGA (Cyclone-V GX-Series). The analysis results are further useful for a next-generation-ASIC-based AI-chip design for a robust real-time robot-learning system.",https://ieeexplore.ieee.org/document/8923369/,2018 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS),27-30 Nov. 2018,ieeexplore
10.1109/IROS40897.2019.8967966,Fast and Safe Policy Adaptation via Alignment-based Transfer,IEEE,Conferences,"Applying deep reinforcement learning to physical systems, as opposed to learning in simulation, presents additional challenges in terms of sample efficiency and safety. Collecting large amounts of hardware demonstration data is time-consuming and the exploratory behavior of reinforcement learning algorithms may lead the system into dangerous states, especially during the early stages of training. To address these challenges, we apply transfer learning to reuse a previously learned policy instead of learning from scratch. In this paper, we propose a method where given a source policy, policy adaptation is performed via transfer learning to produce a target policy suitable for real-world deployment. For policy adaptation, alignment-based transfer learning is applied to trajectories generated by the source policy and their corresponding safe target trajectories. We apply this method to manipulators and show that the proposed method is applicable to both inter-task and inter-robot transfer whilst considering safety. We also show that the resulting target policy is robust and can be further improved with reinforcement learning.",https://ieeexplore.ieee.org/document/8967966/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/IROS.2004.1389583,"Fast, reliable, adaptive, bimodal people tracking for indoor environments",IEEE,Conferences,"We present a real-time system for a mobile robot that can reliably detect and track people in uncontrolled indoor environments. The system uses a combination of leg detection based on distance information from a laser range sensor and visual face detection based on an analogical algorithm implemented on specialized hardware (the CNN universal machine). Results from tests in a variety of environments with different lighting conditions, a different number of appearing and disappearing people, and different obstacles are reported to demonstrate that the system can find and subsequently track several, possibly people simultaneously in indoor environments. Applications of the system include in particular service robots for social events.",https://ieeexplore.ieee.org/document/1389583/,2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),28 Sept.-2 Oct. 2004,ieeexplore
10.1109/CIRA.2005.1554338,Faster learning in embodied systems through characteristic attitudes,IEEE,Conferences,"Classical reinforcement learning is a general learning paradigm with wide applicability in many problem domains. Where embodied agents are concerned, however, it is unable to take advantage of the structured, regular nature of the physical world to maximise learning efficiency. Here, using a model of a three joint robot arm, we show initial learning accelerated by an order of magnitude using simple constraints to produce characteristic attitudes, implemented as part of the learning algorithm. We point out possible parallels with constraints on the movement of natural organisms owing to their detailed mechanical structure. The work forms part of our EMBER framework for reinforcement learning in embodied agents introduced and developed in 2004.",https://ieeexplore.ieee.org/document/1554338/,2005 International Symposium on Computational Intelligence in Robotics and Automation,27-30 June 2005,ieeexplore
10.1109/CYBER53097.2021.9588329,Fault-Aware Robust Control via Adversarial Reinforcement Learning,IEEE,Conferences,"Robots have limited adaptation ability compared to humans and animals in the case of damage. However, robot damages are prevalent in realworld applications, especially for robots deployed in extreme environments. The fragility of robots greatly limits their widespread application. We propose an adversarial reinforcement learning framework, which significantly increases robot robustness over joint damage cases in both manipulation tasks and locomotion tasks. The agent is trained iteratively under the joint damage cases where it has poor performance. We validate our algorithm on a three-fingered robot hand and a quadruped robot. Our algorithm can be trained only in simulation and directly deployed on a real robot without any fine-tuning. It also demonstrates exceeding success rates over arbitrary joint damage cases.",https://ieeexplore.ieee.org/document/9588329/,"2021 IEEE 11th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)",27-31 July 2021,ieeexplore
10.1109/RCAR.2018.8621723,Fault-Tolerant and Self-Adaptive Market-Based Coordination Using Hoplites Framework for Multi-Robot Patrolling Tasks,IEEE,Conferences,"An autonomous robot team can be employed for continuous coverage of a dynamic environment. In this paper, we propose a novel approach for creating multi-robot patrolling policies, which is fault-tolerant and self-adaptive. A dynamic priority queue and time-out replanning mechanism are maintained by each robot to schedule the tasks fault-tolerantly in the context of the market-based method. Hoplites framework is adapted by introducing a self-adaptive threshold adjustment and sharing mechanism to provide a high-level coordination. This work is demonstrated by a multi-robot patrolling task implemented on Robot Operating System (ROS). A flexible tool, Stage, is leveraged to provide the simulated environment. The experimental results validate the effectiveness and availability.",https://ieeexplore.ieee.org/document/8621723/,2018 IEEE International Conference on Real-time Computing and Robotics (RCAR),1-5 Aug. 2018,ieeexplore
10.1109/SICE.2002.1195372,Fish catching using gazing-GA visual servoing - verification of robustness for lighting condition varieties,IEEE,Conferences,"The purpose of this research is to propose a scene recognition method for real-time visual servoing of a manipulator, which has robustness for lighting environments. We have verified the robustness of the proposed method against lighting condition variations and the effectiveness of the method for real-time recognition using a fish catching experiment by visual servoing of a hand-eye robot.",https://ieeexplore.ieee.org/document/1195372/,Proceedings of the 41st SICE Annual Conference. SICE 2002.,5-7 Aug. 2002,ieeexplore
10.1109/ROBOT.1993.292135,Fixed computation real-time sonar fusion for local navigation,IEEE,Conferences,"A system is described for the spatial and temporal fusion of multiple sonars into a dynamic model which serves as a basis for local navigation. In order to guarantee that the robot's actions remain in synchrony with the changing state of the world, there is a continuous mapping from sonar readings to local model to navigation plan and, finally, to actuator commands. Because of this tight coupling of sensing and action, the responsiveness of the system is limited by the computational power of the processor and the required fidelity of the fused model. To address this tradeoff, the system is implemented using the GAPPS/REX circuit-based language. Analysis of the resulting fixed sized circuits allows computation tradeoffs to be made between the system fidelity and the responsiveness required by the operating environment. A description is presented of the sensor fusion and navigation algorithms, as well as the results of the system controlling MITRE's mobile robot Uncle Bob.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/292135/,[1993] Proceedings IEEE International Conference on Robotics and Automation,2-6 May 1993,ieeexplore
10.1109/RIOS.2013.6595317,Flexible snake robot: Design and implementation,IEEE,Conferences,"This paper presents a snake robot able to pass different and difficult paths because of special physical form and movement joints mechanism. These snake robots have no passive wheels. The robot moves by friction between the robot body and the surface on which it is. The joints have been designed and fabricated in a way that each joint has two freedom grades and it may move 228 degrees in every direction. Each joint has two DC servo motors and the power is transferred from the motors output to the joint shaft through bevel gear. The flexibility of the robot makes possible to move forward, back and laterally by imitating real snake's moves. In this paper different measures have been presented in order to design and assemble the joints, motors driver, different ways to guide the robot and its vision.",https://ieeexplore.ieee.org/document/6595317/,2013 3rd Joint Conference of AI & Robotics and 5th RoboCup Iran Open International Symposium,8-8 April 2013,ieeexplore
10.1109/VR.2015.7223421,Flying robot manipulation system using a virtual plane,IEEE,Conferences,"The flexible movements of flying robots make it difficult for novices to manipulate them precisely with controllers such as a joystick and a proportional radio system. Moreover, the mapping of instructions between a robot and its reactions is not necessarily intuitive for users. We propose manipulation methods for flying robots using augmented reality technologies. In the proposed system, a virtual plane is superimposed on a flying robot and users control the robot by manipulating the virtual plane and drawing a moving path on it. We present the design and implementation of our system and describe experiments conducted to evaluate our methods.",https://ieeexplore.ieee.org/document/7223421/,2015 IEEE Virtual Reality (VR),23-27 March 2015,ieeexplore
10.1109/HUMANOIDS.2014.7041373,Footstep planning on uneven terrain with mixed-integer convex optimization,IEEE,Conferences,"We present a new method for planning footstep placements for a robot walking on uneven terrain with obstacles, using a mixed-integer quadratically-constrained quadratic program (MIQCQP). Our approach is unique in that it handles obstacle avoidance, kinematic reachability, and rotation of footstep placements, which typically have required non-convex constraints, in a single mixed-integer optimization that can be efficiently solved to its global optimum. Reachability is enforced through a convex inner approximation of the reachable space for the robot's feet. Rotation of the footsteps is handled by a piecewise linear approximation of sine and cosine, designed to ensure that the approximation never overestimates the robot's reachability. Obstacle avoidance is ensured by decomposing the environment into convex regions of obstacle-free configuration space and assigning each footstep to one such safe region. We demonstrate this technique in simple 2D and 3D environments and with real environments sensed by a humanoid robot. We also discuss computational performance of the algorithm, which is currently capable of planning short sequences of a few steps in under one second or longer sequences of 10-30 footsteps in tens of seconds to minutes on common laptop computer hardware. Our implementation is available within the Drake MATLAB toolbox [1].",https://ieeexplore.ieee.org/document/7041373/,2014 IEEE-RAS International Conference on Humanoid Robots,18-20 Nov. 2014,ieeexplore
10.1109/SMC.2019.8914009,Force Reference Extraction via Human Interaction for a Robotic Polishing Task: Force-Induced Motion,IEEE,Conferences,"In this paper, a method to control a manipulator using force-induced trajectory is proposed. The trajectory is learned from an operator doing the polishing task using a tool attached to the robot's end effector. The learning process is performed by a deep neural network which is designed and trained to generate a force profile according to the states (joints' positions and velocities). The admittance control technique is utilized to make the manipulator compliant to the operator movements in the teaching mode. Spring-Damper system along with Inertia-Damper system have been studied to impose the relationship between the operator's applied force and the reaction of the manipulator. The universal robot (UR5) aside with a force sensor (OptoForce) are used to run the experiment. Robot Operation System (ROS) is used to accomplish the task in real time. The polishing task is learned and achieved by the robot itself, and the force trajectories are better followed using the Inertia-Damper system as the admittance controlling scheme.",https://ieeexplore.ieee.org/document/8914009/,"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)",6-9 Oct. 2019,ieeexplore
10.1109/IECON.2000.973216,Force control in robotic assembly under extreme uncertainty using ANN,IEEE,Conferences,"Robotic assembly operations can be performed by specifying an exact model of the operation. However, the uncertainties involved during assembly make it difficult to conceive such a model In these cases, the use of a connectionist model may be advantageous. In this paper, the design of a robotic cell based on the adaptive resonance theory artificial neural network and a PC host-slave architecture that overcame these uncertainties is presented. Different sources of uncertainty under real conditions are identified and their contribution in a typical assembly operation evaluated. The robotic system is implemented using a PUMA 761 industrial robot with six degrees of freedom (DOF) and a force/torque (F/T) sensor attached to its wrist which conveys force information to the neural network controller (NNC). Results during assembly operations are presented which validate the approach. Furthermore, the method is generic and can be implemented onto other manipulators.",https://ieeexplore.ieee.org/document/973216/,"2000 26th Annual Conference of the IEEE Industrial Electronics Society. IECON 2000. 2000 IEEE International Conference on Industrial Electronics, Control and Instrumentation. 21st Century Technologies",22-28 Oct. 2000,ieeexplore
10.1109/SII.2011.6147520,Forming an artificial pheromone potential field using mobile robot and RFID tags,IEEE,Conferences,"In the biological world, social insects such as ants and bees use a volatile substance called pheromone for their foraging or homing tasks. This study deals with how to utilize the concept of the chemical pheromone as an artificial potential field for robotic purposes. This paper first models a pheromone-based potential field, which is constructed through the interaction between mobile robot and RFID tags. The emphasis in the modeling of the system is on the possibility of the practical implementable ideas. The stability analysis of the pheromone potential field is carried out with the aim of implementing the model on a real robotic system. The comprehensive analysis on stability provides the criteria for how the parameters are to be set for the proper potential field, and has also led to a new filter design scheme called pheromone filter. The designed filter satisfies both the stability and accuracy of the field, and facilitates a more straightforward and practical implementation for building and shaping the potential field. The effectiveness of the proposed algorithm is validated through both computer simulation and real experiment.",https://ieeexplore.ieee.org/document/6147520/,2011 IEEE/SICE International Symposium on System Integration (SII),20-22 Dec. 2011,ieeexplore
10.1109/IROS40897.2019.8967568,From Pixels to Buildings: End-to-end Probabilistic Deep Networks for Large-scale Semantic Mapping,IEEE,Conferences,"We introduce TopoNets, end-to-end probabilistic deep networks for modeling semantic maps with structure reflecting the topology of large-scale environments. TopoNets build a unified deep network spanning multiple levels of abstraction and spatial scales, from pixels representing geometry of local places to high-level descriptions of semantics of buildings. To this end, TopoNets leverage complex spatial relations expressed in terms of arbitrary, dynamic graphs. We demonstrate how TopoNets can be used to perform end-to-end semantic mapping from partial sensory observations and noisy topological relations discovered by a robot exploring large-scale office spaces. Thanks to their probabilistic nature and generative properties, TopoNets extend the problem of semantic mapping beyond classification. We show that TopoNets successfully perform uncertain reasoning about yet unexplored space and detect novel and incongruent environment configurations unknown to the robot. Our implementation of TopoNets achieves real-time, tractable and exact inference, which makes these new deep models a promising, practical solution to mobile robot spatial understanding at scale.",https://ieeexplore.ieee.org/document/8967568/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/DEVLRN.2005.1490934,From Unknown Sensors and Actuators to Visually Guided Movement,IEEE,Conferences,"This paper describes a developmental system implemented on a real robot that learns a model of its own sensory and actuator apparatuses. There is no innate knowledge regarding the modality or representation of the sensoric input and the actuators, and the system relies on generic properties of the robot's world such as piecewise smooth effects of movement on sensory changes. The robot develops the model of its sensorimotor system by first performing random movements to create an informational map of the sensors. Using this map the robot then learns what effects the different possible actions have on the sensors. After this developmental process the robot can perform simple motion tracking",https://ieeexplore.ieee.org/document/1490934/,"Proceedings. The 4th International Conference on Development and Learning, 2005",19-21 July 2005,ieeexplore
10.1109/COASE.2017.8256157,Full automatic path planning of cooperating robots in industrial applications,IEEE,Conferences,"Parts made of carbon fiber reinforced plastics (CFRP) for airplane components can be so huge that a single industrial robot is no longer able to handle them, and cooperating robots are required. Manual programming of cooperating robots is difficult, but with large numbers of different sized and shaped cut-pieces, it is almost impossible. This paper presents an automated production system consisting of a camera for the precise detection of the position of each cut-piece and a collision-free path planner which can dynamically react to different positions for the transfer motions. The path is planned for multiple robots adhering to motion constrains, such as the requirement that the textile cut-piece must form a catenary which can change during transport. Additionally a technique based on machine learning has been implemented which correctly resolves redundancy for a linear axis during planning. Finally, all components are tested on a real robot system in industrial scale.",https://ieeexplore.ieee.org/document/8256157/,2017 13th IEEE Conference on Automation Science and Engineering (CASE),20-23 Aug. 2017,ieeexplore
10.1109/ISSE.2015.7248059,Fully integrated artificial intelligence solution for real time route tracking,IEEE,Conferences,"In this paper the authors propose a solution in which an intelligent algorithm - genetic algorithm in our case - is used to generate commands for a robot in real time, so that the robot can determine the optimal moves considering several aspects: route tracking and low power consumption. Genetic algorithms are intelligent solutions for multi-criteria optimization and using them to find solutions to the optimization problems containing constrictions. However, they were designed as algorithms running on computer and therefore cannot ensure rapid generation of the solutions. On the other hand, the problem of determining the optimal response to command a robot requires real time response. The paper presents a method for hardware implementation and integration in a FPGA circuit of a genetic algorithm, in order to accelerate the convergence and to generate solutions in real time.",https://ieeexplore.ieee.org/document/7248059/,2015 38th International Spring Seminar on Electronics Technology (ISSE),6-10 May 2015,ieeexplore
10.1109/ROMAN.2017.8172498,Functional imitation task in the context of robot-assisted Autism Spectrum Disorder diagnostics: Preliminary investigations,IEEE,Conferences,"This paper presents a functional imitation task aimed at facilitating Autism Spectrum Disorder (ASD) diagnostics in children. Imitation plays a key role in the development of social skills at a young age, and studies have shown that the ability to imitate is impaired in children with ASD. Therefore, we expect imitation-based tasks to have diagnostic value. In this paper, we introduce two novel elements of human-robot interaction in the context of autism diagnostics. Instead of pure motoric imitation, we propose imitation tasks involving real objects in the environment. The introduction of physical objects strongly emphasizes joint attention skills, another area that is typically impaired in children with ASD. Furthermore, we present simple object detection, manipulation, tracking and gesture recognition algorithms, suitable for real-time, onboard execution on the small-scale humanoid robot NAO. The proposed system paves the way for fully autonomous execution of diagnostic tasks, which would simplify the deployment of robotic assistants in clinical settings. The source code for all described functionalities has been made publicly available as open-source software. We present a preliminary evaluation of the proposed system with a control group of typically developing preschool children and a group of seven children diagnosed with ASD.",https://ieeexplore.ieee.org/document/8172498/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/MMAR.2019.8864671,Fusion of Gesture and Speech for Increased Accuracy in Human Robot Interaction,IEEE,Conferences,"An approach for decision-level fusion for gesture and speech based human-robot interaction (HRI) is proposed. A rule-based method is compared with several machine learning approaches. Gestures and speech signals are initially classified using hidden Markov models, reaching accuracies of 89.6% and 84% respectively. The rule-based approach reached 91.6% while SVM, which was the best of all evaluated machine learning algorithms, reached an accuracy of 98.2% on the test data. A complete framework is deployed in real time humanoid robot (NAO) which proves the efficacy of the system.",https://ieeexplore.ieee.org/document/8864671/,2019 24th International Conference on Methods and Models in Automation and Robotics (MMAR),26-29 Aug. 2019,ieeexplore
10.1109/HRI.2010.5453172,FusionBot: A barista robot: Fusionbot serving coffees to visitors during technology exhibition event,IEEE,Conferences,"Summary form of only given: This video shows a service robot named FusionBot autonomously serving coffees to visitors on their request, which occurred during two days-long experiment in TechFest 2008 event. The coffee serving task involves taking coffee order from a visitor, identifying a cup and smart coffee machine, moving towards the coffee machine, communicating with the coffee machine and fetching the coffee cup to the visitor. The main purpose of this experiment is to explore and demonstrate the utility of an interactive service robot in smart home environment, thereby improving the quality of human life. Before conducting the experiments, visitors were given general procedural instructions and simple introduction on how the FusionBot works. Visitors then performed experiment tasks, i.e., ordering a cup of coffee. Thereafter, the visitors were asked to fill out the satisfaction questionnaires to find out their reaction and perception on the FusionBot. Of just over 100 survey questionnaires handed out, sixty eight (68) valid responses (i.e. 68%) were received. Over all, with regards to the FusionBot task satisfaction, more than half of respondents were satisfied with what the FusionBot can do. Nearly one quarter of the respondents indicated that it was not easy to communicate with the FusionBot. This could be due to occurrence of various background noises, which were falsely picked up by the FusionBot as speech input from the visitor. Similarly, less than one quarter indicated that it was not easy to learn how to use the FusionBot. This could be due to the not knowing what to do with the FusionBot and not knowing what the FusionBot does. The experiment was successful in two main dimensions; (1) the robot demonstrated the ability to interact with visitors and perform challenging real-world task autonomously, and (2) It provided some evidence towards the feasibility of using autonomous service robot and smart coffee machine to serve drink in a reception/home or acting as a host in an organization. While preliminary, the experiment also suggests that while developing a service robot; (1) static appearance is very important, (2) requires robust speech recognition and vision understanding, and finally (3) requires comprehensive training on speech and vision with respective data.",https://ieeexplore.ieee.org/document/5453172/,2010 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI),2-5 March 2010,ieeexplore
10.1109/FUZZY.2006.1681996,Fuzzy Logic based Active Map Learning for Autonomous Robot,IEEE,Conferences,"The paper proposes a fast map learning approach for real-time map building and active exploration in unknown indoor environments. This approach includes a map model, a map update method, an exploration method, and a map postprocessing method. The map adopts a grid-based representation and uses frequency value to measure the confidence that a cell is occupied by an obstacle. The exploration method is implemented by coordinating two novel behaviors: path-exploring behavior and environment-detection behavior. Fuzzy logic is used to implement the behavior design and coordination. The fast map update and path planning (i.e. the exploration method) make our approach a candidate for real-time implementation on mobile robots. The results are demonstrated by simulated experiments based on a Pioneer robot with eight forward sonar sensors.",https://ieeexplore.ieee.org/document/1681996/,2006 IEEE International Conference on Fuzzy Systems,16-21 July 2006,ieeexplore
10.1109/AIM.2009.5229761,Fuzzy and Neural controllers for acute obstacle avoidance in mobile robot navigation,IEEE,Conferences,"Robot navigation is the technique to guide the mobile robot move towards the desired goal where dynamic and unknown environment is involved. The environment is distinguished by variable terrain and also certain objects which are known as obstacles that may block the movement of the robot in reaching the desired destination. Fuzzy Logic (FL) and Artificial Neural Network (ANN) are used to assist autonomous mobile robot move, learn the environment and reach the desired goal. This research study is focused on exploring the four combinations of training algorithms composed of FL and ANN that avoid acute obstacles in the environment. Path Remembering algorithm proposed in this paper will assist the mobile robot to come out from acute obstacles. Virtual wall building method also is proposed in order to prevent the mobile robot reentering the same acute obstacle once it has been turned away from the wall. MATLAB simulation is developed to verify and validate the algorithms before they are implemented in real time on Team AmigoBottrade robot. The results obtained from both simulation and actual application confirmed the flexibility and robustness of the controllers designed in avoiding acute obstacles and a comparison of all the four combinations of algorithms is done to find the best combination of algorithms to perform the required navigation to avoid acute obstacles.",https://ieeexplore.ieee.org/document/5229761/,2009 IEEE/ASME International Conference on Advanced Intelligent Mechatronics,14-17 July 2009,ieeexplore
10.1109/FUZZY.1997.619465,Fuzzy behaviors combination to control a nonholonomic mobile robot using virtual perception memory,IEEE,Conferences,This paper presents the implementation of the combination of fuzzy reactive navigation behaviors using virtual perception memory. Robot control actions are generated by different fuzzy behavior components which cooperate to determine the motion of the vehicle. This approach differs from other methods in the use of a virtual perception memory to make a robot controller more robust with respect to temporary loss of sensorial information. Experimental results of an application to a real robot demonstrate the robustness of the proposed method.,https://ieeexplore.ieee.org/document/619465/,Proceedings of 6th International Fuzzy Systems Conference,5-5 July 1997,ieeexplore
10.1109/FUZZY.1996.551714,Fuzzy logic control of an obstacle avoidance robot,IEEE,Conferences,"A fuzzy controller is used to control an obstacle avoidance mobile robot. In this classical problem, the aim is to guide a mobile robot along its path to avoid any static obstacles in front of it. Obstacle avoidance in real-time is a mandatory feature for mobile robots in a dynamically unknown environment. The controller presented here uses three sub-controllers. The outputs are summed to produce a concerted effort to control the motors steering the robot away from obstacles. This fuzzy controller was implemented on a miniature robot. This robot is able to overcome its limitation on range accuracy to follow a left wall, maintaining a short distance from it, to avoid obstacles in front of it, and to decide whether a gap is wide enough for a ""side-step"" manoeuvre.",https://ieeexplore.ieee.org/document/551714/,Proceedings of IEEE 5th International Fuzzy Systems,11-11 Sept. 1996,ieeexplore
10.1109/ISMA.2009.5164850,Fuzzy motion-based control for a bi-steerable mobile robot navigation,IEEE,Conferences,"This paper presents an implementation of a Fuzzy Motion Controller (FMC) to endow the mobile robot Robucar with capability to achieve the action behavior allowing smooth motion generation with intelligence in real-time. The robot state space (velocity and distances) is modeled in discrete intervals leading to linguistic variables. The fuzzy motion control rules are derived and used in a fuzzy inference mechanism to give the final control command to the robot actuators. Simulation and experimental results show FMC capabilities in generating smooth motions, illustrating then its adaptivity and intelligence.",https://ieeexplore.ieee.org/document/5164850/,2009 6th International Symposium on Mechatronics and its Applications,23-26 March 2009,ieeexplore
10.1109/ISIC.1994.367848,Fuzzy neural network implementation of self tuning PID control systems,IEEE,Conferences,"The fuzzy cognitive map (FCM) is a powerful universal method for representation of knowledge in various domains. The fuzzy inference engine can be implemented in the form of a network of FCMs. FCM implementation of the inference engine provides a suitable mechanism for expert control systems and information engineers to embed acquired human expertise, which is often imprecise, vague, or incomplete. The exploitation of an online learning algorithm empowers the fuzzy inference engine with the ability to modify its incomplete or possibly inconsistent knowledge base resulting in continuous improvement of the embedded knowledge. The fact that learning is an inherent feature of neural networks has inspired several researchers with the idea of using neural networks to implement fuzzy inference engines capable of learning. This paper presents a method for neural network FCM implementation of the fuzzy inference engine using the fuzzy columnar neural network architecture (FCNA). In this method the available human expertise is mapped first into an initial set of weights for the neurons. A new learning algorithm is then used to enhance the embedded knowledge in the neural network as a result of real time experience. The fuzzy inference engine (the neural network FCM) is used in computer simulations to control the speed of an underwater autonomous mobile robot. Results and computer simulation experiments are presented along with an evaluation of the new approach.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/367848/,Proceedings of 1994 9th IEEE International Symposium on Intelligent Control,16-18 Aug. 1994,ieeexplore
10.1109/ICMLC.2004.1380726,Fuzzy predictive control of wheeled mobile robot based on multi-sensors,IEEE,Conferences,"During the wheeled mobile robot (WMR) navigation, the position estimation obtained by one sensor is unrealistic and useless. The composite navigation method based on multi-sensor is proposed, which provides redundancy and assures reliability and precision of the observed features. Considering the non-holonomic constraint between the ground and WMR, a fuzzy predictive control is presented where the weight matrix of the pose error is chosen by the real-time fuzzy algorithm. Here, the fuzzy predictive controller based on composite navigation is used on XUAT.AGV, which is a kind of WMR. It has been proved that the controller can improve the control reliability and precision of WMR through theory analysis and experiment.",https://ieeexplore.ieee.org/document/1380726/,Proceedings of 2004 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.04EX826),26-29 Aug. 2004,ieeexplore
10.1109/ROMAN.2004.1374845,Fuzzy reinforcement learning for an evolving virtual servant robot,IEEE,Conferences,"This work presents our research in the application of reinforcement learning algorithms for the generation of autonomous intelligent virtual robots, that can learn and enhance their task performance in assisting humans in housekeeping. For the control system architecture of the virtual agents, two algorithms, based on Watkins' Q(/spl lambda/) learning and the zeroth-level classifier system (ZLCS), are incorporated with fuzzy inference systems(FlS). Performance of these algorithms is evaluated and compared. A 3D application of a virtual robot whose task is to interact with virtual humans and offer optimal services on everyday in-house needs is designed and implemented. The learning systems are incorporated in the decision-making process of the virtual robot servant to allow itself to understand and evaluate the fuzzy value requirements and enhance its performance.",https://ieeexplore.ieee.org/document/1374845/,RO-MAN 2004. 13th IEEE International Workshop on Robot and Human Interactive Communication (IEEE Catalog No.04TH8759),22-22 Sept. 2004,ieeexplore
10.1109/INDIN.2009.5195905,GPS and sonar based area mapping and navigation by mobile robots,IEEE,Conferences,"In this paper, we have presented a GPS and sonar based area mapping and navigation scheme for a mobile robot. A mapping is achieved between the GPS space and the world coordinates of the mobile robot which enables us to generate direct motion commands for it. This mapping enables the robot to navigate among different GPS locations within the mapped area. The GPS data is extracted online to get the latitude and longitude information of a particular location. In the training phase, a 2-D axis transformation is used to relate local robot frame with the robot world coordinates and then the actual world coordinates are mapped from the GPS data using a RBFN (radial basis function network) based Neural Network. In the second phase, direct GPS data is used to get the mapping into the world coordinates of mobile robot using the trained network and the motion commands are generated accordingly. The physical placement of sonar devices, their ranging limits and beam opening angles are considered during navigation for possible collision detection and obstacle avoidance. This scheme is successfully implemented in real time with Pioneer mobile robot from ActivMedia Robotics and GPS receiver. The scheme is also tested in the simulation to justify its application in the real world.",https://ieeexplore.ieee.org/document/5195905/,2009 7th IEEE International Conference on Industrial Informatics,23-26 June 2009,ieeexplore
10.1109/ROBIO.2017.8324476,Generalized framework for the parallel semantic segmentation of multiple objects and posterior manipulation,IEEE,Conferences,"The end-to-end approach presented in this paper deals with the recognition, detection, segmentation and grasping of objects, assuming no prior knowledge of the environment nor objects. The proposed pipeline is as follows: 1) Usage of a trained Convolutional Neural Net (CNN) that recognizes up to 80 different classes of objects in real time and generates bounding boxes around them. 2) An algorithm to derive in parallel the pointclouds of said regions of interest (ROI). 3) Eight different segmentation methods to remove background data and noise from the pointclouds and obtain a precise result of the semantically segmented objects. 4) Registration of the object's pointclouds over time to generate the best possible model. 5) Utilization of an algorithm to detect an array of grasping positions and orientations based mainly on the geometry of the object's model. 6) Implementation of the system on the humanoid robot MyBot, developed in the RIT Lab at KAIST. 7) An algorithm to find the bounding box of the object's model in 3D to then create a collision object and add it to the octomap. The collision checking between robot's hand and the object is removed to allow grasping using the MoveIt libraries. 8) Selection of the best grasping pose for a certain object, plus execution of the grasping movement. 9) Retrieval of the object and moving it to a desired final position.",https://ieeexplore.ieee.org/document/8324476/,2017 IEEE International Conference on Robotics and Biomimetics (ROBIO),5-8 Dec. 2017,ieeexplore
10.1109/IROS.1994.407570,Generation of optimal configuration for a redundant manipulator with a trained neural network,IEEE,Conferences,"Redundant manipulators have more degrees of freedom than what is absolutely necessary for performing a task. The extra degrees of freedom can be used for avoiding obstacles or to optimize certain performance indices like manipulability or task compatibility. Maximizing manipulability keeps the manipulator away from singularities and provides more velocity transmission ratios in all directions. Optimizing task compatibility improves the force/velocity transmission ratios in the specified directions. However, the real time implementation of various optimizing algorithms is difficult because of the need of large computing time. In the present work, robot configurations for an optimum performance index are computed throughout the workspace. These configurations are then used to train a layered feed forward neural network (FFNN). During operation of the robot, the trained neural net outputs optimal configurations in real-time. The neural net captures the gross behaviour of the training data rather than memorizing the individual data, as in a lookup table. Thus its output is smooth and ideally suited for control purposes. We have simulated this approach on a 3-DOF redundant planar manipulator and the results are discussed in this paper.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/407570/,Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS'94),12-16 Sept. 1994,ieeexplore
10.1109/ROBOT.2001.933128,Generation of optimal trajectory for real system of an underactuated manipulator,IEEE,Conferences,"Trajectory of an underactuated manipulator is usually generated according to both kinematics and dynamics of the manipulator, different to that of conventional manipulator. The real trajectory by a real system may differ greatly from the trajectory generated from the dynamics model because there always exist errors in the dynamic model, and the feedback control is less effective in an underactuated manipulator. A method for generation of optimal trajectory for the real system of an underactuated manipulator with nonholonomic constraints is proposed. By using this method, the dynamics model of a real system can be improved by learning, and an optimal trajectory is generated according to the model improved sequentially. The effectiveness of the method is confirmed by experiment with a golf swinging robot. The implementation and experimental results obtained of the control method are described.",https://ieeexplore.ieee.org/document/933128/,Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164),21-26 May 2001,ieeexplore
10.1109/ISKE47853.2019.9170343,Genetic Algorithm Integrated with Neural-Network for Tolman Mouse Robot Navigation,IEEE,Conferences,"Mapping building plays an important role in robot navigation, in order to facility agent with high level intelligence and mimic the major function of rat's space cell, a new mechanism of Genetic Algorithm Integrated with Neuralnetwork(GAIN) was proposed in this paper. Considering the scenario of unknown environment when agent explores the map, weights in neural network remain the same during agent's lifecycle and will be optimized by genetic algorithm. Several simulation was performed on Unity platform, especial the Tolman mouse maze experiment, including cross position learning experiment, spatial orientation experiment and roundabout experiment, had been reproduced by agent other than real rat. Furthermore, some extension of experiment has also done to further prove the feasibility of the algorithm. Simulation results verified the proposed GAIN algorithm can endow agent with cognitive map function.",https://ieeexplore.ieee.org/document/9170343/,2019 IEEE 14th International Conference on Intelligent Systems and Knowledge Engineering (ISKE),14-16 Nov. 2019,ieeexplore
10.1109/ROMAN.2009.5326235,Gestural teleoperation of a mobile robot based on visual recognition of sign language static handshapes,IEEE,Conferences,"This paper presents results achieved in the frames of a national research project (titled ldquoDIANOEMArdquo), where visual analysis and sign recognition techniques have been explored on Greek Sign Language (GSL) data. Besides GSL modelling, the aim was to develop a pilot application for teleoperating a mobile robot using natural hand signs. A small vocabulary of hand signs has been designed to enable desktopbased teleoperation at a high-level of supervisory telerobotic control. Real-time visual recognition of the hand images is performed by training a multi-layer perceptron (MLP) neural network. Various shape descriptors of the segmented hand posture images have been explored as inputs to the MLP network. These include Fourier shape descriptors on the contour of the segmented hand sign images, moments, compactness, eccentricity, and histogram of the curvature. We have examined which of these shape descriptors are best suited for real-time recognition of hand signs, in relation to the number and choice of hand postures, in order to achieve maximum recognition performance. The hand-sign recognizer has been integrated in a graphical user interface, and has been implemented with success on a pilot application for real-time desktop-based gestural teleoperation of a mobile robot vehicle.",https://ieeexplore.ieee.org/document/5326235/,RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication,27 Sept.-2 Oct. 2009,ieeexplore
10.1109/IJCNN.2015.7280540,Gesture based human multi-robot interaction,IEEE,Conferences,"The emergence of robot applications for non-technical users implies designing new ways of interaction between robotic platforms and users. The main goal of this work is the development of a gestural interface to interact with robots in a similar way as humans do, allowing the user to provide information of the task with non-verbal communication. The gesture recognition application has been implemented using the Microsoft's Kinect<sup>™</sup> v2 sensor. Hence, a real-time algorithm based on skeletal features is described to deal with both, static gestures and dynamic ones, being the latter recognized using a weighted Dynamic Time Warping method. The gesture recognition application has been implemented in a multi-robot case. A NAO humanoid robot is in charge of interacting with the users and respond to the visual signals they produce. Moreover, a wheeled Wifibot robot carries both the sensor and the NAO robot, easing navigation when necessary. A broad set of user tests have been carried out demonstrating that the system is, indeed, a natural approach to human robot interaction, with a fast response and easy to use, showing high gesture recognition rates.",https://ieeexplore.ieee.org/document/7280540/,2015 International Joint Conference on Neural Networks (IJCNN),12-17 July 2015,ieeexplore
10.1109/IRIS.2016.8066077,Gesture based robotic arm control for meal time care using a wearable sensory jacket,IEEE,Conferences,"This work presents the development of a wireless, low cost, wearable sensor jacket for the purpose of controlling a robot arm by mimicking the motion and behaviour of a humans arm. The intended use of our system is to provide remote daily nursing care by using our system from a distant place such as a nursing home or hospital, to control a stationed robotic arm placed in an elderly or patient's home. The final system is comprised of a wearable jacket which is embedded with IMU and flex sensors to detect and track the wearers arm movements and behaviour. The system is capable of detecting up to 5 degrees of freedom of the human arm and replicate these motions using a 6 DOF robot arm. The usability, accuracy and precision of our jacket system is evaluated through a user study and the results demonstrated that our system was more accurate and easier to use for operators than a conventional robotic arm joystick controller. In a water bottle transfer task our developed wearable jacket system demonstrated an average error distance of 29.36mm from the target point, while the results using the conventional joystick demonstrated an average error distance of 37.48mm. Furthermore subjects using our system were able to complete the transfer task in an average time of 44.1s per trial which was more efficient than the joystick method in which subjects averaged 55.55s per trial. Finally, we report a feasibility study with the jacket and a subject to demonstrate the capability of this system of giving a patient water to drink. The feasibility experiment showed an 86.66% success rate in giving a patient water via video stream teleoperation control.",https://ieeexplore.ieee.org/document/8066077/,2016 IEEE International Symposium on Robotics and Intelligent Sensors (IRIS),17-20 Dec. 2016,ieeexplore
10.1109/CACRE52464.2021.9501291,Give Me a Wrench!: Finding Tools for Human Partners in Human-Robot Collaborative Manufacturing Contexts,IEEE,Conferences,"Manufacturing processes can be optimized by enabling human-robot collaboration. A relevant goal in this area is to create a collaborative solution in which robots can provide assisting actions to humans, thereby, reducing menial labor as well as increasing productivity. The solution is based on implementing efficient hand-over of mechanical tools from robots to humans. Hand-over tasks are inevitable in human-robot collaborative manufacturing contexts. These tasks need three-step mechanism: object identification, object grasping, and the actual hand-over. This paper presents an approach for robots to find tools for human partners in human-robot collaboration via deep learning. This is achieved using the object detection system YOLOv3 for identification of commonly used mechanical tools. By training on a custom dataset of 800 images of mechanical tools created for the study, the tool recognition is implemented in realworld human-robot hand-over tasks. Experimental results show that the proposed approach achieves a high accuracy for identification of tools in real-world human-robot collaboration. Future work of this study is also discussed.",https://ieeexplore.ieee.org/document/9501291/,"2021 6th International Conference on Automation, Control and Robotics Engineering (CACRE)",15-17 July 2021,ieeexplore
10.1109/ICRA.2019.8793810,Goal-Driven Navigation for Non-holonomic Multi-Robot System by Learning Collision,IEEE,Conferences,"In this paper, we propose the reinforcement learning based multi-robot collision avoidance approach by learning collision. Dynamical path re-planning, which is massively used in classical collision avoidance methods, needs overall information of the environment. Also, training agent robots to avoid the collision and pursue a goal point simultaneously is inefficient since the agent should learn two tasks. As the number of tasks that the agent should learn increases, it is difficult to make the performance of an algorithm consistent, which is known as reproducibility issue. To overcome these limitations, Collision Avoidance by Learning Collision (CALC), which learns collision instead of avoiding an obstacle robot is suggested. To solve the collision avoidance problem efficiently, the proposed method divides the problem into training and planning. In the training algorithm, an agent robot learns how to collide with a single obstacle robot and then generates a trained policy. With the trained policy, the agent can pursue a goal point since the policy leads the agent to `collide' with the goal. Furthermore, by taking action in a reverse way from the trained policy, the agent can avoid multiple obstacle robots in the planning algorithm at once. The proposed method is validated both in the robot simulation and real robot experiment, and compared with the existing collision avoidance method.",https://ieeexplore.ieee.org/document/8793810/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/IROS.2018.8594070,HARK-Bird-Box: A Portable Real-time Bird Song Scene Analysis System,IEEE,Conferences,"This paper addresses real-time bird song scene analysis. Observation of animal behavior such as communication of wild birds would be aided by a portable device implementing a real-time system that can localize sound sources, measure their timing, classify their sources, and visualize these factors of sources. The difficulty of such a system is an integration of these functions considering the real-time requirement. To realize such a system, we propose a cascaded approach, cascading sound source detection, localization, separation, feature extraction, classification, and visualization for bird song analysis. Our system is constructed by combining an open source software for robot audition called HARK and a deep learning library to implement a bird song classifier based on a convolutional neural network (CNN). Considering portability, we implemented this system on a single-board computer, Jetson TX2, with a microphone array and developed a prototype device for bird song scene analysis. A preliminary experiment confirms a computational time for the whole system to realize a real-time system. Also, an additional experiment with a bird song dataset revealed a trade-off relationship between classification accuracy and time consuming and the effectiveness of our classifier.",https://ieeexplore.ieee.org/document/8594070/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/RO-MAN47096.2020.9223558,HATSUKI : An anime character like robot figure platform with anime-style expressions and imitation learning based action generation,IEEE,Conferences,"Japanese character figurines are popular and have a pivot position in Otaku culture. Although numerous robots have been developed, few have focused on otaku-culture or on embodying anime character figurines. Therefore, we take the first steps to bridge this gap by developing Hatsuki, which is a humanoid robot platform with anime based design. Hatsuki's novelty lies in its aesthetic design, 2D facial expressions, and anime-style behaviors that allows Hatsuki to deliver rich interaction experiences resembling anime-characters. We explain our design implementation process of Hatsuki, followed by our evaluations. In order to explore user impressions and opinions towards Hatsuki, we conducted a questionnaire in the world's largest anime-figurine event. The results indicate that participants were generally very satisfied with Hatsuki's design, and proposed various use case scenarios and deployment contexts for Hatsuki. The second evaluation focused on imitation learning, as such a method can provide better interaction ability in the real world and generate rich, context-adaptive behaviors in different situations. We made Hatsuki learn 11 actions, combining voice, facial expressions and motions, through the neural network based policy model with our proposed interface. Results show our approach was successfully able to generate the actions through self-organized contexts, which shows the potential for generalizing our approach in further actions under different contexts. Lastly, we present our future research direction for Hatsuki and provide our conclusion.",https://ieeexplore.ieee.org/document/9223558/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore
10.1109/ITSC.2014.6958165,HOG based multi-object detection for urban navigation,IEEE,Conferences,"A necessary condition to perform a fully autonomous driving system in urban environment is to detect object types in real scenes. Visual object recognition is a key solution, but multi-object detection still remain unsolved. In this paper, we present a fast and efficient multi-object detection system built to recognize, at the same time, pedestrians cars and bicycles. For each target type, we construct a holistic detector in a cascade manner, using a dense overlapping grid based on histograms of oriented gradients (HOG). The selection of HOG features is obtained through a learning process using AdaBoost algorithm. Experiments have been conducted on the car-like robot Robucar, where the single detectors are combined and implemented on its embedded computer, which is endowed with a modular software platform. Results are promising as the system can process up to 20 fps with VGA images.",https://ieeexplore.ieee.org/document/6958165/,17th International IEEE Conference on Intelligent Transportation Systems (ITSC),8-11 Oct. 2014,ieeexplore
10.1109/ICIEA.2006.257252,Hand Posture Recognition in Gesture-Based Human-Robot Interaction,IEEE,Conferences,"Natural and friendly interface is critical for the development of service robots. Gesture-based interface offers a way to enable untrained users to interact with robots more easily and efficiently. In this paper, we present a posture recognition system implemented on a real humanoid service robot. The system applies the RCE neural network based color segmentation algorithm to separate hand images from complex backgrounds. The topological features of the hand are then extracted from the silhouette of the segmented hand region. Based on the analysis of these simple but distinctive features, hand postures are identified accurately. Experimental results on gesture-based robot programming demonstrated the effectiveness and robustness of the system",https://ieeexplore.ieee.org/document/4025853/,2006 1ST IEEE Conference on Industrial Electronics and Applications,24-26 May 2006,ieeexplore
10.1109/EMBC44109.2020.9176261,Haptic Coupling in Dyads Improves Motor Learning in a Simple Force Field,IEEE,Conferences,"In dyadic motor learning, pairs of people learn the same motion while their limbs are loosely coupled together using haptic devices. Such coupled learning has been shown to outperform solo learning (including robot-guided learning) for simple one-degree-of-freedom tasks. However, results from more complex tasks are limited and sometimes conflicting. We thus evaluated coupled learning in a two-degree-of-freedom tracking task where participants also had to compensate for a simple force field. Participant pairs were split into two groups: an experiment group that experienced a compliant haptic coupling between participants' hands and a control group that did not. The study protocol consisted of 70 repetitions of 18.9-second tracking trials: 10 initial solo trials with no coupling, 50 ""learning"" trials (where participants in the experiment group were coupled), and 10 final solo trials with no coupling. The experiment group (coupled) improved their solo tracking performance both in the presence (p = 0.008) and absence (p &lt;; 0.001) of the force field; however, the control group (no coupling) only improved their solo performance in the absence of the force field (p &lt;; 0.001) but not in the presence of the field (p = 0.81). This suggests that dyadic motor learning can outperform solo learning for two-dimensional tracking motions in the presence of a simple force field, though the mechanism by which learning is improved is not yet clear.Clinical Relevance-As motor learning is critical for applications such as motor rehabilitation, dyadic training could be used to achieve a better overall outcome and a faster learning speed in these applications compared to solo training.",https://ieeexplore.ieee.org/document/9176261/,2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),20-24 July 2020,ieeexplore
10.1109/ISVLSI.2016.101,Hardware Design Automation of Convolutional Neural Networks,IEEE,Conferences,"Convolutional Neural Networks (CNNs) are a variation of feed-forward Neural Networks inspired by the biological process in the visual cortex of animals. The interest in this supervised learning algorithm has rapidly grown in many fields like image and video recognition and natural language processing. Nowadays they have become the state of the art in various applications like mobile robot vision, video surveillance and Big Data analytics. The specific computation pattern of CNNs results to be highly suitable for hardware acceleration, in fact different types of accelerators have been proposed based on GPU, Field Programmable Gate Array (FPGA) and ASIC. In particular, in the embedded systems context, due to real time and power consumption challenges, it is crucial to find the right tradeoff between performance, energy efficiency, fast development round and cost. This work proposes a framework meant as a tool for the user to accelerate and simplify the design and the implementation of CNNs on FPGAs by leveraging High Level Synthesis, still providing a certain level of customization of the hardware design.",https://ieeexplore.ieee.org/document/7560201/,2016 IEEE Computer Society Annual Symposium on VLSI (ISVLSI),11-13 July 2016,ieeexplore
10.1109/ICAEE.2017.8255341,Hardware and software implementation of real time electrooculogram (EOG) acquisition system to control computer cursor with eyeball movement,IEEE,Conferences,"Human computer interface (HCI) is an emerging technology of neuroscience and artificial intelligence. Development of HCI system using bio signal e.g. Electrooculogram (EOG), Electromyogram (EMG), Electroencephalogram (EEG), Functional near-infrared spectroscopy (fNIRS) etc. are attracted more and more attention of researchers all over the world in recent years because through this it is possible to get acquainted with advanced technologies of artificial intelligence. This paper presents the design and implementation of a fully functional Electrooculogram (EOG) based human computer interface. In this work we have designed and implemented necessary hardware and software for EOG signal acquisition along with controlling hardware such as wheelchair, robotic arm, mobile robot etc., and move computer mouse cursor simultaneously using EOG signal. This interface has three portion: EOG signal acquisition and amplification, analog to digital conversion, and real time hardware and mouse cursor movement. Eye movement is detected by measuring potential difference between cornea and retina using five Ag-Agcl disposable electrodes. Frequency range of EOG signal is considered as 0.3 to 15Hz, so this frequency range is taken using an active high and low pass filter so that accurate EOG signal can be achieved. The analog output of the EOG signal from filter is converted into digital signal by using an Arduino. Arduino serialize the EOG data for calibration and provides a threshold reference point which is used for controlling Hardware. The Classification module e.g. Support Vector machine (SVM) and Linear Discriminant Analysis (LDA) classify live data with respect to the horizontal and vertical data. This works as a binary classifier and choose optimal hyper-plane between two variables. According to each update on the eye position, cursor automatically accelerated in particular direction. PyMouse module in python is used for this task. Eye gesture based Hardware like robot, wheelchair etc. control and mouse cursor movement are the principle outcome of this research work.",https://ieeexplore.ieee.org/document/8255341/,2017 4th International Conference on Advances in Electrical Engineering (ICAEE),28-30 Sept. 2017,ieeexplore
10.1109/ROBOT.1993.292013,Hidden Markov model approach to skill learning and its application in telerobotics,IEEE,Conferences,"The problem of how human skill can be represented as a parametric model using a hidden Markov (HMM), and how an HMM-based skill model can be used to learn human skill, is discussed. The HMM is feasible for characterizing two stochastic processes, measurable action and immeasurable mental states that are involved in the skill learning. Based on the most likely performance criterion, the best action sequence can be selected from previously measured action data by modeling the skill as an HMM. This selection process can be updated in real-time by feeding new action data and modifying HMM parameters. The implementation of the proposed method in a teleoperation-controlled space robot is discussed. The results demonstrate the feasibility of the method.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/292013/,[1993] Proceedings IEEE International Conference on Robotics and Automation,2-6 May 1993,ieeexplore
10.1109/SMC.2018.00176,Hierarchical Control Architecture Regulating Competition between Model-Based and Context-Dependent Model-Free Reinforcement Learning Strategies,IEEE,Conferences,"Recent evidence in neuroscience and psychology suggests that a single reinforcement learning (RL) algorithm only accounts for less than 60% of the variance of human choice behavior in an uncertain and dynamic environment, where the amount of uncertainty in state-action-state transitions drift over time. The prediction performance further decreases when the size of the state space increases. We proposed a hierarchical context-dependent RL control framework that dynamically exerted control weights on model-based (MB) and multiple model-free (MF) RL strategies associated with different task goals. To properly assess the validity of the proposed method, we considered a two-stage Markov decision task (MDT) in which the three different types of context changed over time. We trained 57 different RL control models on a Caltech MDT data set; then, we assessed their prediction performance using a Bayesian model comparison. This large-scale computer simulation analysis revealed that the model providing the most accurate prediction was the version that implemented the competition between the MB and multiple goal-dependent MF RL strategies. The present study demonstrates the applicability of the goal-driven RL control to a variety of real-world human-robot interaction scenarios.",https://ieeexplore.ieee.org/document/8616172/,"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",7-10 Oct. 2018,ieeexplore
10.1109/IJCNN.2007.4371289,Hierarchical MMC Networks as a manipulable body model,IEEE,Conferences,"A cognitive control system for a walking robot should be able to solve from simple reactive tasks up to complex tasks, including tasks which need cognitive capabilities and setting up plans. Planning ahead involves some kind of internal representation: most important a model of the own body. Considering planning as mental simulation, this model must be fully functional: it is constrained in the same way as the body itself and it can move and be used in the same way as the body. This model can then be used to try out movements mentally without doing the action in reality. For this purpose it must be possible to decouple the body itself from the action controlling modules to use the original controllers for control of the internal representations. In this publication we introduce a hierarchical model, implemented as an recurrent neural network based on the MMC principle.",https://ieeexplore.ieee.org/document/4371289/,2007 International Joint Conference on Neural Networks,12-17 Aug. 2007,ieeexplore
10.1109/IRC.2020.00029,Hierarchical Planner with Composable Action Models for Asynchronous Parallelization of Tasks and Motions,IEEE,Conferences,"Task and motion planning is a relevant yet hard to solve problem in robotic manipulation. Large number of degrees of freedom with multiple manipulators and several objects require specialized algorithms, which can deal with the hybrid planning and optimization problem. An additional challenge is the asynchronous parallelization of single robot actions on interacting manipulators. In this paper we propose a system with a hierarchical planner, which solves the task and motion problem and optimizes for a subsequent parallelization. We use action models based on a constraint formulation; thus, the execution engine can parallelize the sequential plan without synchronization between different tasks. In the experiment, we solve a task and motion problem with difficult geometric constraints and combinatorial complexity. The asynchronously parallel execution of that plan is demonstrated on a real world dual-arm robot.",https://ieeexplore.ieee.org/document/9287975/,2020 Fourth IEEE International Conference on Robotic Computing (IRC),9-11 Nov. 2020,ieeexplore
10.1109/ROBOT.1995.525442,Hierarchical control architecture for Cellular Robotic System-simulations and experiments,IEEE,Conferences,"Describes the hierarchical control architecture of real mobile robots for Cellular Robotic System Mark-V (CEBOT Mark-V). A parallel processing control system has been adopted, and by adjusting the role of parallel processes standing for the states of independent primitive behaviors, the change of system organization is realized to adapt the redefinition of plural tasks and the variation of environments. The authors propose a method for decision making of a mobile robot's behavior through integrating multiple behavioral processes. The authors define two relation matrices denoting the relationship among the processes: the priority matrix and the interest relation matrix. The matrices are used to adjust the outputs of behavioral processes and optimize the behavior of mobile robots. To obtain the most suitable priority matrix, the authors introduce a learning-adapting algorithm. The results of simulation and experiment with a real CEBOT Mark-V showed the effectiveness of the proposed matrices and learning-adapting algorithm. On the other hand, instead of simply selecting processes for decision making of the robot's behavior, the integration of multiple processes based on the proposed matrices enhanced the control robustness of robot system.",https://ieeexplore.ieee.org/document/525442/,Proceedings of 1995 IEEE International Conference on Robotics and Automation,21-27 May 1995,ieeexplore
10.1109/ICSMC.1996.565422,High speed neural control for robot navigation,IEEE,Conferences,"This paper addresses the real time control of the Khepera mobile robot navigation in a maze with reflector walls. Boolean neural networks such as RAM and GSN models are applied to drive the vehicle, following a light source, while avoiding obstacles. Both neural networks are implemented with simple logic and arithmetic functions (NOT, AND, OR, Addition, and Comparison), aiming to improve the system speed. The results obtained are compared with two other control strategies: multilayer perceptron and fuzzy logic.",https://ieeexplore.ieee.org/document/565422/,"1996 IEEE International Conference on Systems, Man and Cybernetics. Information Intelligence and Systems (Cat. No.96CH35929)",14-17 Oct. 1996,ieeexplore
10.1109/ICRA48506.2021.9561034,High-Speed Robot Navigation using Predicted Occupancy Maps,IEEE,Conferences,"Safe and high-speed navigation is a key enabling capability for real world deployment of robotic systems. A significant limitation of existing approaches is the computational bottleneck associated with explicit mapping and the limited field of view (FOV) of existing sensor technologies. In this paper, we study algorithmic approaches that allow the robot to predict spaces extending beyond the sensor horizon for robust planning at high speeds. We accomplish this using a generative neural network trained from real-world data without requiring human annotated labels. Further, we extend our existing control algorithms to support leveraging the predicted spaces to improve collision-free planning and navigation at high speeds. Our experiments are conducted on a physical robot based on the MIT race car using an RGBD sensor where were able to demonstrate improved performance at 4 m/s compared to a controller not operating on predicted regions of the map.",https://ieeexplore.ieee.org/document/9561034/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/IROS.2008.4651150,High-dimensional underactuated motion planning via task space control,IEEE,Conferences,"Kinodynamic planning algorithms have the potential to find feasible control trajectories which accomplish a task even in very nonlinear or constrained dynamical systems. Underactuation represents a particular form of a dynamic constraint, inherently present in many machines of interest (e.g., walking robots), and necessitates planning for long-term control solutions. A major limitation in motion planning techniques, especially for real-time implementation, is that they are only practical for relatively low degree-of-freedom problems. Here we present a model-based dimensionality reduction technique based on an extension of partial feedback linearization control into a task-space framework. This allows one to plan motions for a complex underactuated robot directly in a low-dimensional task-space, and to resolve redundancy with lower-priority tasks. We illustrate the potential of this approach with an extremely simple motion planning system which solves the swing-up problem for multi-link underactuated pendula, and discuss extensions to the control of walking.",https://ieeexplore.ieee.org/document/4651150/,2008 IEEE/RSJ International Conference on Intelligent Robots and Systems,22-26 Sept. 2008,ieeexplore
10.1109/TAI.2000.889888,History checking of temporal fuzzy logic formulas for monitoring behavior-based mobile robots,IEEE,Conferences,"Behavior-based robot control systems have shown remarkable success for controlling robots evolving in real world environments. However, they can fail in different manners due to their distributed control and their local decision making. In this case, monitoring can be used to detect failures and help to recover from them. In this work, we present an approach for specifying monitoring knowledge and a method for using this knowledge to detect failures. In particular we show how temporal fuzzy logic can be used to represent monitoring knowledge and then utilized to effectively detect runtime failures. New semantics are introduced to take into consideration uncertainty and noisy information. There are numbers of advantages to our approach including a declarative semantics for the monitoring knowledge and an independence of this knowledge from the implementation details of the control system. Moreover we show how our system can deal effectively with noisy information and sensor readings. Experiments with two real world robots and the simulator are used to illustrate failure examples and the benefits of failure detection and noise elimination.",https://ieeexplore.ieee.org/document/889888/,Proceedings 12th IEEE Internationals Conference on Tools with Artificial Intelligence. ICTAI 2000,15-15 Nov. 2000,ieeexplore
10.1109/ETFA.2018.8502527,Holo Pick'n'Place,IEEE,Conferences,"In this paper we contribute to the research on facilitating industrial robot programming by presenting a concept for intuitive drag and drop like programming of pick and place tasks with Augmented Reality (AR). We propose a service-oriented architecture to achieve easy exchangeability of components and scalability with respect to AR devices and robot workplaces. Our implementation uses a HoloLens and a UR5 robot, which are integrated into a framework of RESTful web services. The user can drag recognized objects and drop them at a desired position to initiate a pick and place task. Although the positioning accuracy is unsatisfactory yet, our implemented prototype achieves most of the desired advantages to proof the concept.",https://ieeexplore.ieee.org/document/8502527/,2018 IEEE 23rd International Conference on Emerging Technologies and Factory Automation (ETFA),4-7 Sept. 2018,ieeexplore
10.1109/IROS.2006.282590,How can humanoid acquire lexicon? -active approach by attention and learning biases based on curiosity-,IEEE,Conferences,"Observation study of human infants tells us that they can successfully acquire lexicon; understanding the relationship between the meaning and the uttered word from only one teaching by caregiver, even though there are many other possible mappings. This paper proposes a lexical acquisition model which makes use of curiosity to associate visual features of observed objects with the labels that are uttered by a caregiver. A robot changes its attention and learning rate based on curiosity. In the experiment with a real humanoid robot, the visual features are represented with self-organizing maps which adaptively represents the shape of observed objects independent of the viewpoints",https://ieeexplore.ieee.org/document/4058940/,2006 IEEE/RSJ International Conference on Intelligent Robots and Systems,9-15 Oct. 2006,ieeexplore
10.1109/ACSOS49614.2020.00036,How far should I watch? Quantifying the effect of various observational capabilities on long-range situational awareness in multi-robot teams,IEEE,Conferences,"In our previous work, we showed that individual robots within a multi-robot team can gain long-distance situational awareness from passive observations of a single nearby neighbor without any explicit robot-to-robot communication. However, that prior work was developed only in simulation, and performance was not measured for real robot teams in physical space with realistic hardware limitations. Toward this end, we studied the performance of these methods in real robot scenarios with methods using more sophisticated techniques in machine learning to mitigate practical implementation problems. In this study, we further extend that work by characterizing the effects of changing history length and sensor range. Rather than finding that increasing history length and sensor range always yield better estimation performance, we find that the optimal history length and sensor range varies depending on the distance between the estimating robot and the robot being estimated. For estimation problems where the estimation target is nearby, longer histories actually degrade performance, and so sensor ranges could be increased instead. Conversely, for farther targets, history length is as valuable or more valuable than sensor range. Thus, just as optimal shutter speed varies with light availability and speed of the subject, passive situational awareness in multi-robot teams is best achieved with different strategies depending on proximity to locations of interest. All studies use the teams of Thymio II physical, two-wheeled robots in laboratory environments <sup>1</sup>.<sup>1</sup>Data and models used are available at https://github.com/PavlicLab/ACSOS2020_ReTLo_Extension.git.",https://ieeexplore.ieee.org/document/9196255/,2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS),17-21 Aug. 2020,ieeexplore
10.1109/CRV.2010.55,Human Upper Body Pose Recognition Using Adaboost Template for Natural Human Robot Interaction,IEEE,Conferences,"In this paper, we propose a novel Adaboost template to recognize human upper body poses from disparity images for natural human robot interaction (HRI). First, the upper body poses of standing persons are classified into seven categories of views. For each category, a mean template, variance template, and percentage template are generated. Then, the template region is divided into positive and negative regions, corresponding to the region of bodies and surrounding open space. A weak classifier is designed for each pixel in the template. A new EM-like Adaboost learning algorithm is designed to learn the Adaboost template. Different from existing Adaboost classifiers, we show that the Adaboost template can be used not only for recognition but also for adaptive top-down segmentation. By using Adaboost template, only a few positive samples for each category are required for learning. Comparison with conventional template matching techniques has been made. Experimental results show that significant improvements can be achieved in both cases. The method has been deployed in a social robot to estimate human attentions to the robot in real-time human robot interaction.",https://ieeexplore.ieee.org/document/5479162/,2010 Canadian Conference on Computer and Robot Vision,31 May-2 June 2010,ieeexplore
10.1109/SCISISIS50064.2020.9322719,Human-Robot Interaction Based on Facial Expression Recognition Using Deep Learning,IEEE,Conferences,"In recent years, many robots for the purpose of communicating with people have been developed. Such a robot is required to have human interaction and communication ability. In order to perform the interaction naturally, the nonverbal communication such as human facial expression and body movement is important. In this research, we propose a method to classify emotions from human face images by deep learning and generate a robot emotional reaction by Markovian emotional model. Here, we perform to learn human facial images with various emotions using CNN (Convolutional Neural Network) which is a kind of deep learning, and recognize human emotions from facial images in the human interaction. Based on the human emotion obtained by deep learning, the robot returns its emotional behavior to the human. In this research, we executed the interaction experiment using an real communication robot and this result is also reported in this paper.",https://ieeexplore.ieee.org/document/9322719/,2020 Joint 11th International Conference on Soft Computing and Intelligent Systems and 21st International Symposium on Advanced Intelligent Systems (SCIS-ISIS),5-8 Dec. 2020,ieeexplore
10.1109/YAC53711.2021.9486647,Human-Robot Interaction System Design for Manipulator Control Using Reinforcement Learning,IEEE,Conferences,"In this article, a novel human-robot interaction (HRI) system is presented and applied in the robotic arm coordinated operation control task. The presented HRI system includes two parts, the impedance model controller and the robotic arm controller, which allows the operator to manipulate the robotic arm to accomplish the given task with minimal human effort. First, the model-based reinforcement learning (RL) method is applied in the impedance model for operator adaptation. The impedance model controller can transform human input into the specific signal for the manipulator. Second, a novel adaptive manipulator controller is designed. In contrast to existing controllers, a velocity-free filter is implemented in our controller, which is developed to replace the manipulator actuator's speed signal. The effectiveness of the presented HRI system is verified by the simulation based on real manipulator parameters.",https://ieeexplore.ieee.org/document/9486647/,2021 36th Youth Academic Annual Conference of Chinese Association of Automation (YAC),28-30 May 2021,ieeexplore
10.1109/ICRA.2013.6630610,Human-friendly robot navigation in dynamic environments,IEEE,Conferences,"The vision-based mechanisms that pedestrians in social groups use to navigate in dynamic environments, avoiding obstacles and each others, have been subject to a large amount of research in social anthropology and biological sciences. We build on recent results in these fields to develop a novel fully-distributed algorithm for robot local navigation, which implements the same heuristics for mutual avoidance adopted by humans. The resulting trajectories are human-friendly, because they can intuitively be predicted and interpreted by humans, making the algorithm suitable for the use on robots sharing navigation spaces with humans. The algorithm is computationally light and simple to implement. We study its efficiency and safety in presence of sensing uncertainty, and demonstrate its implementation on real robots. Through extensive quantitative simulations we explore various parameters of the system and demonstrate its good properties in scenarios of different complexity. When the algorithm is implemented on robot swarms, we could observe emergent collective behaviors similar to those observed in human crowds.",https://ieeexplore.ieee.org/document/6630610/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/ROBIO.2011.6181717,Human-like gradual multi-agent Q-learning using the concept of behavior-based robotics for autonomous exploration,IEEE,Conferences,"In the last few years, the field of mobile robotics has made lots of advancements. These advancements are due to the extensive application of mobile robots for autonomous exploration. Mobile robots are being popularly used for applications in space, underwater explorations, underground coal mines monitoring, inspection in chemical/toxic/ nuclear factories etc. But if these environments are unknown/unpredictable, conventional/ classical robotics may not serve the purpose. In such cases robot learning is the best option. Learning from the past experiences, is one such way for real time application of robots for completely unknown environments. Reinforcement learning is one of the best learning methods for robots using a constant system-environment interaction. Both single and multi-agent concepts are available for implementation of learning. The current research work describes a multi-agent based reinforcement learning using the concept of behaviour-based robotics for autonomous exploration of mobile robots. The concept has also been tested both in indoor and outdoor environments using real-time robots.",https://ieeexplore.ieee.org/document/6181717/,2011 IEEE International Conference on Robotics and Biomimetics,7-11 Dec. 2011,ieeexplore
10.1109/HUMANOIDS.2017.8246941,Human-robot interaction assessment using dynamic engagement profiles,IEEE,Conferences,"This paper addresses the use of convolutional neural networks for image analysis resulting in an engagement metric that can be used to assess the quality of human robot interactions. We propose a method based on a pretrained convolutional network able to map emotions onto a continuous [0-1] interval, where 0 represents disengaged and 1 fully engaged. The network shows a good accuracy at recognizing the engagement state of humans given positive emotions. A time based analysis of interaction experiments between small humanoid robots and humans provides time series of engagement estimates, which are further used to understand the nature of the interaction as well as the overall mood and interest of the participant during the experiment. The method allows a real-time implementation and supports a quantitative and qualitative assessment of a human robot interaction with respect to a positive engagement and is applicable to humanoid robotics as well as other related contexts.",https://ieeexplore.ieee.org/document/8246941/,2017 IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids),15-17 Nov. 2017,ieeexplore
10.1109/CSPA.2014.6805724,Humanoid localisation in a robot soccer competition using a single camera,IEEE,Conferences,"One of the main challenges in a humanoid robot soccer competition is registering robots on the field so that they can estimate their best possible positions. This paper proposes an initial self-localisation algorithm to estimate the distance between a robot and a goal post, which is used as a landmark. By manipulating a single camera, we can apply analytic geometry to determine the real world coordinates of a robot from the transformation image plane. An experiment was conducted from the perspective of a robot in a soccer competition. The robot was able to locate itself with a minimum mean square error rate. This technology has great potential for boosting attacking and defensive performance.",https://ieeexplore.ieee.org/document/6805724/,2014 IEEE 10th International Colloquium on Signal Processing and its Applications,7-9 March 2014,ieeexplore
10.1109/ICRA.2013.6631340,Humanoid robot posture-control learning in real-time based on human sensorimotor learning ability,IEEE,Conferences,"In this paper we propose a system capable of teaching humanoid robots new skills in real-time. The system aims to simplify the robot control and to provide a natural and intuitive interaction between the human and the robot. The key element of the system is exploitation of the human sensorimotor learning ability where a human demonstrator learns how to operate a robot in the same fashion as humans adapt to various everyday tasks. Another key aspect of the proposed system is that the robot learns the task simultaneously while the human is operating the robot. This enables the control of the robot to be gradually transferred from the human to the robot during the demonstration. The control is transferred based on the accuracy of the imitated task. We demonstrated our approach using an experiment where a human demonstrator taught a humanoid robot how to maintain the postural stability in the presence of the perturbations. To provide the appropriate feedback information of the robot's postural stability to the human sensorimotor system, we utilized a custom-built haptic interface. To absorb the demonstrated skill by the robot, we used Locally Weighted Projection Regression machine learning method. A novel approach was implemented to gradually transfer the control responsibility from the human to the incrementally built autonomous robot controller.",https://ieeexplore.ieee.org/document/6631340/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/ICBAIE52039.2021.9390048,Hybrid Path Planning Algorithm Based on Improved Dynamic Window Approach,IEEE,Conferences,"Path planning is the hot topic in the autonomous robot navigation research area. Different from the former researchers, namely using the static obstacle environments, in this paper, we propose a hybrid path planning algorithm based on improved dynamic windows approach. The proposed algorithm can be shown as 1 Use the Astar algorithm to plan the path to avoid static obstacles in the operating environment, 2 Design a stage target selection strategy to guide the mobile robot to move on the global optimal planning path, 3 Propose an improved dynamic window approach that integrates the speed obstacle method, and the mobile robot is facing When moving obstacles, it can flexibly avoid, and maintain the smoothness of the path and the executable of speed control commands. Finally, the feasibility and effectiveness of the algorithm proposed in this paper are verified through the design algorithm simulation experiment, and the simulation result analysis verifies the obstacle avoidance of the improved algorithm Effect and real-time path optimality.",https://ieeexplore.ieee.org/document/9390048/,"2021 IEEE 2nd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)",26-28 March 2021,ieeexplore
10.1109/EPIA.2005.341221,Hybrid State Machines with Timed Synchronization for Multi-Robot System Specification,IEEE,Conferences,"In multi-robot systems, the need for precise modeling or specification of agent behaviors arises due to the high complexity of the robot agent interactions and the dynamics of the environment. Since the behavior of agents usually can be understood as driven by external events and internal states, it is obvious to model multiagent systems by state transition diagrams. The corresponding formalisms come equipped with a formal semantics which is advantageous. In this paper, a combination of UML statecharts and hybrid automata is proposed, allowing formal system specification on different levels on abstraction on the one hand, and expressing real-time system behavior with continuous variables on the other hand. One important aspect of multi-robot systems is the need of coordination and hence synchronization of behavior. For both, statecharts and hybrid automata, it is assumed that synchronization takes zero time. This is sometimes unrealistic. Therefore, a new notation and implementation of synchronization is proposed here, which overcomes this problem. The proposed method is illustrated with a case study from the robotic soccer domain",https://ieeexplore.ieee.org/document/4145962/,2005 portuguese conference on artificial intelligence,5-8 Dec. 2005,ieeexplore
10.1109/MHS.1995.494218,Hybrid system of mechanical parts and living organisms for microrobots,IEEE,Conferences,"Summary form only given. Fundamental attempts to make hybrid robots, in which some artificial sensors and actuators are replaced with natural antennas and muscles, are discussed. First, it is shown that signals from an antenna are easily obtained with electrodes connected to both ends of the antenna. In our experiment, antennas of silkworm moth (Bombyx mori) are used as sensors which can detect a few molecules of pheromone. As for actuators, electrical stimulation can generate the desired smooth movement of muscles. Finally, intelligence of microrobots is considered. Currently, it is impossible to use a real nervous system for hybrid robots because a nervous system cannot be taken out from the body without damage. In addition, a nervous system cannot be connected with artificial sensors and actuators. Instead, recurrent artificial neural networks are applied. The connections of the neural networks are obtained by genetic algorithms. As a result, a mobile robot with antennas follows a stream of pheromone.",https://ieeexplore.ieee.org/document/494218/,MHS'95. Proceedings of the Sixth International Symposium on Micro Machine and Human Science,4-6 Oct. 1995,ieeexplore
10.1109/ETFA.2005.1612680,Hyper-redundant robotic micro-grippers with neural control,IEEE,Conferences,"The paper introduces a novel approach for the kinematic coordination of mechanical robot micro-grippers on the basis of neural networks. Conventional robot systems use specialized grippers for specific tasks. For objects with an amorphous structure, variable shape or small dimensions, conventional grippers become unreliable due to several reasons. The present paper presents an approach on the basis of a tentacle shaped micro-gripper with a high number of links and rotational articulated joints. The proposed method for gripping an object is based on wrapping the manipulator's links around the object in order to establish a firm grip. Sensors located near the joints of the micro-manipulator detect the corresponding distances to the object. Since the multi-link manipulator has a high degree of kinematic redundancy (consider up to several hundred links in a chain), the implementation of an effective trajectory control unit is a challenging task, especially if sensor-based real-time coordination is required. In this paper, we use an optimized geometrical path generator in order to teach dynamic neural nets a certain motion behavior, dependent on distance sensor signals. We show that the neural net is able to learn the procedural knowledge for the gripping process with ability of generalization and discuss the results",https://ieeexplore.ieee.org/document/1612680/,2005 IEEE Conference on Emerging Technologies and Factory Automation,19-22 Sept. 2005,ieeexplore
10.1109/HAPTIC.2010.5444617,IN-HAPTICS: Interactive navigation using haptics,IEEE,Conferences,"We present a computational framework and experimental platform for robot navigation that allows for a user-friendly, graphical and haptic interaction with the human operator during the deployment process. The operator can see, feel, and manipulate the artificial potential field that drives the robot through an environment cluttered with obstacles. We present a case study in which the operator rescues a robot trapped in a local minimum of a navigation potential field.",https://ieeexplore.ieee.org/document/5444617/,2010 IEEE Haptics Symposium,25-26 March 2010,ieeexplore
10.1109/ELECTR.1991.718282,Imaging And Controls For Mars Robots With Neural Networks,IEEE,Conferences,"Two aspects of the design of space robots is covered implemented by neural networks and by hybrid approach with artificial intelligence. One is a neurocontroller for a real-time autonomous system. An optical control system developed saves the time for the image processing that analyzes an image sensor through the environment and induces a transformation over the sensor array. A prototype of the neurocontroller is able to learn and control by itself. The second aspect deals with the design of a Servo Control System for a Robot with the capability of ""learning in Unanticipated Situations"" incorporated in the system. The robot is assumed to be employed to perform useful tasks in an alien evironment. The model developed is shown to provide the robot with the capability to recover from unanticipated situations that can lead to the disruption of its normal operation, and to learn to avoid such situations in the future. These two aspects will be integrated for a design of a very intelligent autonomous space robot.",https://ieeexplore.ieee.org/document/718282/,"Electro International, 1991",16-18 April 1991,ieeexplore
10.1109/IROS45743.2020.9341035,ImitationFlow: Learning Deep Stable Stochastic Dynamic Systems by Normalizing Flows,IEEE,Conferences,"We introduce ImitationFlow, a novel Deep generative model that allows learning complex globally stable, stochastic, nonlinear dynamics. Our approach extends the Normalizing Flows framework to learn stable Stochastic Differential Equations. We prove the Lyapunov stability for a class of Stochastic Differential Equations and we propose a learning algorithm to learn them from a set of demonstrated trajectories. Our model extends the set of stable dynamical systems that can be represented by state-of-the-art approaches, eliminates the Gaussian assumption on the demonstrations, and outperforms the previous algorithms in terms of representation accuracy. We show the effectiveness of our method with both standard datasets and a real robot experiment.",https://ieeexplore.ieee.org/document/9341035/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/CISP-BMEI48845.2019.8965907,Implementation and Verification of a Virtual Testing System Based on ROS and Unity for Computer Vision Algorithms,IEEE,Conferences,"With the development of artificial intelligence technology, Computer vision algorithm is playing an increasingly important role. Computer vision algorithm testing is a vital link to ensure the safe and reliable operation of agents. However, the traditional testing methods based on real scenes provide single samples and are challenging to obtain ground truth, which makes it inefficient to test computer vision algorithms. To solve this problem, the testing method of computer vision algorithms using virtual scenes instead of real scenes has been applied. In this paper, Unity and robot operating system (ROS) are selected to build a virtual testing system named URCV for computer vision algorithms. The feasibility of the system and the influence of virtual scene elements on the testing of the monocular ORB_SLAM2 algorithm are verified, including the rendering path of Unity's RGB camera, texture accuracy, and illumination model.",https://ieeexplore.ieee.org/document/8965907/,"2019 12th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)",19-21 Oct. 2019,ieeexplore
10.1109/ISCAS.2003.1205151,Implementation of Turing patterns for bio-inspired motion control,IEEE,Conferences,"In this paper a CNN controlling the reactive behavior of a roving robot by means of Turing patterns is introduced. The Turing pattern represents the fixed-action pattern of the robot, while the initial conditions of the CNN are given by the sensor status. The approach is still valid when the number of sensors is high, being able to perform data fusion in real-time through analog parallel processing. An experiment using a small roving robot is presented to validate the approach.",https://ieeexplore.ieee.org/document/1205151/,"Proceedings of the 2003 International Symposium on Circuits and Systems, 2003. ISCAS '03.",25-28 May 2003,ieeexplore
10.1109/ELECSYM.2018.8615503,Implementation of Victims Detection Framework on Post Disaster Scenario,IEEE,Conferences,"Disasters are prone to occur in Indonesia due to geographical factors, such as tectonic plate movements, which can cause an earthquake. Earthquakes are one of the most frequent disasters, they have broad impacts in a short time and are unpredictable. Thus, an extensive search process in a short time is highly critical to determine the victims location. In this paper, a victims detection framework is developed starting from acquiring images using an unmanned aerial vehicle and further processing using convolutional neural network (CNN) to locate victims robustly on post-disaster. Input images are then sent to victim detector dedicated ground station server for further high processing robustly locating the possibility of victims. A simulation system mimicking a real environment is developed to test our framework in real time. A transmission protocol is also developed for effectively transmitting data between the robot and the server. The treatment on the detection process of the victim is different from the normal human detection, some pre-processing stages are applied to increase the variation of the given dataset. An embedded system is used for taking images and additional sensors data, such as location and time using Global Navigation Satellite System.",https://ieeexplore.ieee.org/document/8615503/,2018 International Electronics Symposium on Engineering Technology and Applications (IES-ETA),29-30 Oct. 2018,ieeexplore
10.1109/SSST.1998.660084,Implementation of a navigational neural network on a parallel DSP board,IEEE,Conferences,"This work presents a neural network architecture that is motivated by the learning and memory characteristics of a part of the brain known as hippocampus, which is important in navigational behavior in humans and animals. Neural networks perform nonlinear transformations on data to yield suitable classification or control actions. In our case, the navigation network takes the distance information as data and maps it to control actions by the mobile robot. Navigation is a very important engineering problem for unknown or hazardous environments to ensure the safety of equipment and human life. Hardware implementation can benefit applications in real time where speed is the major concern. Our objective is to implement such a navigational neural network in parallel so that real time performance can be achieved by using a parallel DSP board system. Supplementary studies are also being carried out on the IBM SP2 supercomputer to understand the design and scaling properties of the parallel algorithm.",https://ieeexplore.ieee.org/document/660084/,Proceedings of Thirtieth Southeastern Symposium on System Theory,10-10 March 1998,ieeexplore
10.1109/IJCNN.2008.4633972,Implementation of a neural network based visual motor control algorithm for A 7 DOF redundant manipulator,IEEE,Conferences,"This paper deals with visual-motor coordination of a 7 dof robot manipulator for pick and place applications. Three issues are dealt with in this paper - finding a feasible inverse kinematic solution without using any orientation information, resolving redundancy at position level and finally maintaining the fidelity of information during clustering process thereby increasing accuracy of inverse kinematic solution. A 3-dimensional KSOM lattice is used to locally linearize the inverse kinematic relationship. The joint angle vector is divided into two groups and their effect on end-effector position is decoupled using a concept called function decomposition. It is shown that function decomposition leads to significant improvement in accuracy of inverse kinematic solution. However, this method yields a unique inverse kinematic solution for a given target point. A concept called sub-clustering in configuration space is suggested to preserve redundancy during learning process and redundancy is resolved at position level using several criteria. Even though the training is carried out off-line, the trained network is used online to compute the required joint angle vector in only one step. The accuracy attained is better than the current state of art. The experiment is implemented in real-time and the results are found to corroborate theoretical findings.",https://ieeexplore.ieee.org/document/4633972/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/IROS.1991.174485,Implementation of an active optical range sensor using laser slit for in-door intelligent mobile robot,IEEE,Conferences,"The sensor with real-time environment recognition ability is one of the key technologies for autonomous robots. The authors have designed and implemented a small size optical range sensor for their experimental mobile robot. The sensor consists of a laser slit generator, a CCD image sensor and a processing unit. Using this sensor, the real-time obstacle avoiding function is realized and added to the autonomous navigation aspect of the robot.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174485/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/ACC.2014.6859431,"Implementation of an adaptive, model free, learning controller on the Atlas robot",IEEE,Conferences,"Recent events in natural and man-made disasters have highlighted the limitation in man's ability to confine and mitigate damage in such scenarios. Therefore, there is an urgent need for robotic technology that can function in all environments and serve as a substitute to humans in disaster scenarios. This paper presents research efforts to advance walking technology of humanoid robots with application to the Boston Dynamics Atlas robot. The Atlas was designed as part of the DARPA Robotics Challenge (DRC). The paper contribution is in a model free, walking trajectory tracking controller that is tested using GAZEBO robotics simulator. Artificial neural networks are used to learn the robot's nonlinear dynamics on the fly using a neuroadaptive control algorithm. The learned nonlinear dynamics are utilized along with a filtered error signal to generate input torques to control the system. Results show that the ability to approximate the robot nonlinear dynamics allows for full-body control without the need of modeling such a complex system. This ability is what makes the control scheme utilized appealing for complex, real-life, robotic applications that occur in a non-laboratory setting.",https://ieeexplore.ieee.org/document/6859431/,2014 American Control Conference,4-6 June 2014,ieeexplore
10.1109/CONIELECOMP.2014.6808580,Implementation of an embedded system on a TS7800 board for robot control,IEEE,Conferences,"Growing Functional Modules (GFM) learning based controllers need to be experimented on real robots. In 2009, looking to develop a flexible and generic embedded interface for such robots, we decided to use a TS-7800 single board computer (SBC) with a Debian Linux operating system. Despite the many advantages of this board, implementing the embedded system has been a complex task. This paper describes the implementation of protocols through the TS-7800 different ports (RS232, TCP/IP, USB, analog and digital pins) as well as the connection of external boards (TS-ADC24, TS-DIO64, SSC-32 and LCD display). This implementation was required to connect a large range of actuators, sensors and other peripherals. Furthermore, the architecture of the embedded system is exposed in detail, including topics such as the XML configuration file that specifies the peripherals connected to the SBC, the concept of virtual sensors, the implementation of parallelism and the embedded system interface launcher. Technical aspects such as the optimization of video capture and processing are detailed because their execution required specific compilers versions, EABI emulation and extra libraries (openCV libjpg and libpngand libv4l). The final embedded system was implemented in a humanoid robot and connected to the GFM controller in charge of developing its equilibrium subsystem.",https://ieeexplore.ieee.org/document/6808580/,"2014 International Conference on Electronics, Communications and Computers (CONIELECOMP)",26-28 Feb. 2014,ieeexplore
10.1109/CEC.2003.1299606,Implementation of an immuno-genetic network on a real Khepera II robot,IEEE,Conferences,"The design of autonomous navigation systems for mobile robots, with simultaneous objectives to be satisfied such as garbage collection with integrity maintenance, requires refined coordination mechanisms to deal with modules of elementary behaviour. This paper shows the implementation on a real Khepera II robot of an immuno-genetic network for autonomous navigation that combines an evolutionary algorithm with a continuous immune network model. The proposed immuno-genetic system has the immune network implementing a dynamic process of decision-making, and the evolutionary algorithm defining the network structure. To be able to evaluate the controllers (immune networks) on the evolutionary process, a virtual environment was used for computer simulation, based on the characteristics of the navigation problem. The immune networks obtained by evolution were then analyzed and tested on new situations, presenting coordination capability in simple and more complex tasks. Some preliminary experiments on a real Khepera II robot demonstrate the feasibility of the evolved immune networks.",https://ieeexplore.ieee.org/document/1299606/,"The 2003 Congress on Evolutionary Computation, 2003. CEC '03.",8-12 Dec. 2003,ieeexplore
10.1109/iFuzzy.2013.6825409,Implementation of human following mission by using fuzzy head motion control and Q-learning wheel motion control for home service robot,IEEE,Conferences,"This paper mainly implements human following function for home service robot, May, developed in our laboratory. In order to follow the operator accurately, visual tracking is composed by Tracing-Learning-Detection (TLD) and Kinect skeleton, where TLD plays the role as re-detecting the situation that operator is occluded or disappeared, and Kinect skeleton is adopted to track all other situations while TLD is learning how to enlarge operator image patterns in order to enhance recognition rates. For the sake of improving tracking capability, fuzzy head motion control is added in the visual tracking system to compensate the constraints that the mobile platform of May cannot react rapidly. Every instant movement of the operator can be captured by fuzzy head motion control in real time. Q-learning is applied to discover the pose switching of the mobile platform such that May possesses more robust following ability. By Q-learning, states setting are based on three dimensional position, actions are created by the pose of four wheel independent steering and four wheel independent driven (4WIS4WID) platform, and rewards are established on state transitions. Finally, both the experimental results in the laboratory and competition consequents of Follow Me Mission in robot@home league at RoboCup Japan Open 2013 Tokyo demonstrate that our robot May can fluently switch its poses to follow operator by utilizing the proposed schemes.",https://ieeexplore.ieee.org/document/6825409/,2013 International Conference on Fuzzy Theory and Its Applications (iFUZZY),6-8 Dec. 2013,ieeexplore
10.1109/SMC.2017.8122654,Implementation of human-robot VQA interaction system with dynamic memory networks,IEEE,Conferences,"One of the major functions of intelligent robots such as social or home service robots is to interact with users in natural language. Moving on from simple conversation or retrieval of data stored in computer memory, we present a new Human-Robot Interaction (HRI) system which can understand and reason over environment around the user and provide information about it in a natural language. For its intelligent interaction, we integrated Dynamic Memory Networks (DMN), a deep learning network for Visual Question Answering (VQA). For its hardware, we built a robotic head platform with a tablet PC and a 3 DOF neck. Through an experiment where the user and the robot had question answering interaction in our customized environment and in real time, the feasibility our proposed system was validated, and the effectiveness of deep learning application in real world as well as a new insight on human robot interaction was demonstrated.",https://ieeexplore.ieee.org/document/8122654/,"2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",5-8 Oct. 2017,ieeexplore
10.1109/INES.1997.632397,Implementation of neural network sliding-mode controller for DD robot,IEEE,Conferences,"The experimental development of a trajectory tracking neural network controller based on the theory of continuous sliding-mode controllers is shown in the paper. The neural network control law was verified on a real direct drive 3 DOF PUMA mechanism. The new neural network sliding-mode controller was successfully tested for trajectory tracking sudden changes in the manipulator dynamics (load). The comparision between the neural network sliding mode controller, a computer torque method controller and a continuous sliding mode controller with PI-estimator for sudden load changes on the real robot mechanism is shown.",https://ieeexplore.ieee.org/document/632397/,Proceedings of IEEE International Conference on Intelligent Engineering Systems,17-17 Sept. 1997,ieeexplore
10.1109/IROS.1995.525808,Implementation of real time spatial mapping in robotic systems through self-organizing neural networks,IEEE,Conferences,"Presents a methodology which allows an autonomous agent i.e., a mobile robot, to learn and build maps of its operating environment by relying only on its range sensors. The maps, described with respect to the robot's inertial frame, are developed in real time by correlating robot position and sensory data. This latter feature characterizes part of the uniqueness of the authors' approach. These maps are topologically isomorphic to the maps created for the same room(s) by humans. The methodology exploits the principle of self-organization, implemented as an artificial neural network module which processes incoming sensor range data. The generation of environmental maps can be visualized as an elastic string of neurons whereby every neuron represents a finite portion of the physical world. This elastic string stretches dynamically so as to take on the shape of the environment, a unique characteristic of the authors' methodology. In this respect, the neural net provides a discretized representation of the ""continuous"" physical environment as the latter is seen through the robot's own sensors. Experiments, focused on indoor applications, have successfully demonstrated the ability of a robot to build maps of geometrically complex environments. The results presented in this paper, compared with the authors' earlier efforts, show significant improvement in that every single sensor data point contributes equally to the location of the neurons of the spatial map at the end of the learning process. This is important because the authors wish to minimize the effect of the order in which data points are processed.",https://ieeexplore.ieee.org/document/525808/,Proceedings 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human Robot Interaction and Cooperative Robots,5-9 Aug. 1995,ieeexplore
10.1109/I2CT.2014.7092212,Implementation of synthetic brain concept in humanoid robot,IEEE,Conferences,"This paper is elaborate the model of humanoid robot interacts with human being and perform various operation as per the command given by the human being. A humanoid robot having Synthetic brain can able to do Interaction, communication, Object detection, information acquisition about any object, response to voice command, chatting logically with human beings. Object detection will be done by this robot for that purpose there is use image processing concept (HAAR Technique), And to make the system intelligent that is whenever system interact, communicate, chat with human it gives proper response, question / answers there is integrates artificial intelligence and DFA / NFA automata and Prolog language concept for answering logically over the complex and relevant strings or data.",https://ieeexplore.ieee.org/document/7092212/,International Conference for Convergence for Technology-2014,6-8 April 2014,ieeexplore
10.1109/CIMSA.2003.1227232,Improve the position measurement accuracy using a dynamic on-line fuzzy interpolation technique,IEEE,Conferences,"Traditional robot calibration implements model and modeless methods. The compensation of position error in modeless method is to move the end-effector of robot to the target position in the workspace, and to find the position error of that target position by using a bilinear interpolation method based on the neighboring 4-point's errors around the target position. A camera or other measurement devices can be utilized to find or measure this position error, and compensate this error with the interpolation result. This paper provides a novel fuzzy interpolation method to improve the compensation accuracy obtained by using a bilinear interpolation method. A dynamic online fuzzy inference system is implemented to meet the needs of a fast real-time control system and calibration environment. The simulated results show that the compensation accuracy can be greatly improved by using this fuzzy interpolation method compared with the bilinear interpolation method.",https://ieeexplore.ieee.org/document/1227232/,"The 3rd International Workshop on Scientific Use of Submarine Cables and Related Technologies, 2003.",31-31 July 2003,ieeexplore
10.1109/ELECSYM.2018.8615506,Improving Field and Ball Detector for Humanoid Robot Soccer EROS Platform,IEEE,Conferences,"Humanoid robot soccer perceives environment mostly through cameras. The performance decrement in our humanoid soccer platform (EROS) is primarily due to the visual perception that is less robust to the RoboCup new rule which specifically reducing color coding in the field. Notable works favorably employ simple color segmentation, image morphology, and blob detector due to simplicity in the implementation and run in real-time for most embedded hardware, while some employ a more advanced supervised learning running in sophisticated hardware to boost detection accuracy. In this paper, a visual perception system consisting of field and ball detection is developed in our platform EROS to address the RoboCup new rule. Color segmentation and image morphology are stacked with a more advanced supervised learning cascade classifier. In this way, the favorable color segmentation and image morphology help to reduce the number of object candidates while the cascade classifier helps to boost the accuracy of detection. Experiments show encouraging result for detecting field and ball position. Our approach has successfully been implemented in practice and achieves remarkably result in Indonesian humanoid robot soccer competition.",https://ieeexplore.ieee.org/document/8615506/,2018 International Electronics Symposium on Engineering Technology and Applications (IES-ETA),29-30 Oct. 2018,ieeexplore
10.1109/IROS45743.2020.9341029,Improving Unimodal Object Recognition with Multimodal Contrastive Learning,IEEE,Conferences,"Robots perceive their environment using various sensor modalities, e.g., vision, depth, sound or touch. Each modality provides complementary information for perception. However, while it can be assumed that all modalities are available for training, when deploying the robot in real-world scenarios the sensor setup often varies. In order to gain flexibility with respect to the deployed sensor setup we propose a new multimodal approach within the framework of contrastive learning. In particular, we consider the case of learning from RGB-D images while testing with one modality available, i.e., exclusively RGB or depth. We leverage contrastive learning to capture high-level information between different modalities in a compact feature embedding. We extensively evaluate our multimodal contrastive learning method on the Falling Things dataset and learn representations that outperform prior methods for RGB-D object recognition on the NYU-D dataset. Our code and details on the used datasets are available at: https://github.com/meyerjo/MultiModalContrastiveLearning.",https://ieeexplore.ieee.org/document/9341029/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ROMAN.2017.8172491,Improving robot transparency: Real-time visualisation of robot AI substantially improves understanding in naive observers,IEEE,Conferences,"Deciphering the behaviour of intelligent others is a fundamental characteristic of our own intelligence. As we interact with complex intelligent artefacts, humans inevitably construct mental models to understand and predict their behaviour. If these models are incorrect or inadequate, we run the risk of self deception or even harm. Here we demonstrate that providing even a simple, abstracted real-time visualisation of a robot's AI can radically improve the transparency of machine cognition. Findings from both an online experiment using a video recording of a robot, and from direct observation of a robot show substantial improvements in observers' understanding of the robot's behaviour. Unexpectedly, this improved understanding was correlated in one condition with an increased perception that the robot was `thinking', but in no conditions was the robot's assessed intelligence impacted. In addition to our results, we describe our approach, tools used, implications, and potential future research directions.",https://ieeexplore.ieee.org/document/8172491/,2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),28 Aug.-1 Sept. 2017,ieeexplore
10.1109/ICPR.1996.547231,Incremental learning for vision-based navigation,IEEE,Conferences,"In this paper, we explore the issue of incremental learning for autonomous navigation of a mobile robot. The autonomous navigation problem is regarded as a content-based retrieval problem where the robot learns the navigation experience using a hierarchical recursive partition tree (RPT). During real navigation, each time a new image is grabbed to retrieve the learned tree. The associated control signals of the retrieved are used to control the new action of the robot. Use of RPT can achieve efficient retrieval. In the proposed incremental learning scheme, a new image with the associated control signals is learned or rejected according to whether its retrieved output control signals are within tolerance of the desired control signals of the input query image. We use the eigen-subspace method for feature extraction in our incremental learning. The proposed algorithm has a real-time implementation for both learning and performance phases. Experimental results are shown to confirm the effectiveness of proposed method.",https://ieeexplore.ieee.org/document/547231/,Proceedings of 13th International Conference on Pattern Recognition,25-29 Aug. 1996,ieeexplore
10.1109/IROS.2010.5650519,Incremental motion primitive learning by physical coaching using impedance control,IEEE,Conferences,"We present an approach for kinesthetic teaching of motion primitives for a humanoid robot. The proposed teaching method allows for iterative execution and motion refinement using a forgetting factor. During the iterative motion refinement, a confidence value specifies an area of allowed refinement around the nominal trajectory. A novel method for continuous generation of motions from a hidden Markov model (HMM) representation of motion primitives is proposed, which incorporates relative time information for each state. On the real-time control level, the kinesthetic teaching is handled by a customized impedance controller, which combines tracking performance with soft physical interaction and allows to implement soft boundaries for the motion refinement. The proposed methods were implemented and tested using DLR's humanoid upper-body robot Justin.",https://ieeexplore.ieee.org/document/5650519/,2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,18-22 Oct. 2010,ieeexplore
10.1109/DEVLRN.2014.6983001,Incremental training of Restricted Boltzmann Machines using information driven saccades,IEEE,Conferences,"In the context of developmental robotics, a robot has to cope with complex sensorimotor spaces by reducing their dimensionality. In the case of sensor space reduction, classical approaches for pattern recognition use either hardcoded feature detection or supervised learning. We believe supervised learning and hard-coded feature extraction must be extended with unsupervised learning of feature representations. In this paper, we present an approach to learn representations using space-variant images and saccades. The saccades are driven by a measure of quantity of information in the visual scene, emerging from the activations of Restricted Boltzmann Machines (RBMs). The RBM, a generative model, is trained incrementally on locations where the system saccades. Our approach is implemented using real data captured by a NAO robot in indoor conditions.",https://ieeexplore.ieee.org/document/6983001/,4th International Conference on Development and Learning and on Epigenetic Robotics,13-16 Oct. 2014,ieeexplore
10.1109/ICEE50131.2020.9260698,"Indoor and Outdoor Face Recognition for Social Robot, Sanbot Robot as Case Study",IEEE,Conferences,"The interaction between human and robots is of paramount importance in comforting robot and human in the context of social demand. For the purpose of human-robot interaction, the robot should have the ability to perform a variety of actions including face recognition, path planning, etc. In this paper, face recognition has been implemented on the Sanbot robot. Since the Sanbot robot is intended to work in real environment, therefore indoor and outdoor environment is taken into account in proposing the corresponding face recognition algorithm. For each case a robust pre-processing algorithm should be designed and which can circumvent a challenging problem in face recognition, namely, different lighting conditions (light intensity, angle of radiation, etc.). In case of indoor environment, faces in an captured image by the robot HD camera are found using a Haar-cascade algorithm. Afterwards, a histogram equalization is applied to face images in order to standardize them. Then commonly practiced Deep convolutional neural network structures such as Inception and ResNet are used to design a model and trained end-to-end on a customized dataset with strong augmentation. Finally, by using a voting method, proper prediction is carried out on each face. In what concerns the outdoor environment, which has more challenges, upon applying histogram Equalization on the captured image, faces are found using a MultiTask Cascaded Convolutional Neural Network. Then face images are aligned as head orientation are corrected. Finally, cropped face image is fed to Siamese Network in order to extract face features and verifying individuals. From several practical results it has been inferred that the accuracy of the indoor method is nearly 93% without voting and with voting 97%, and the outdoor method is about 95%.",https://ieeexplore.ieee.org/document/9260698/,2020 28th Iranian Conference on Electrical Engineering (ICEE),4-6 Aug. 2020,ieeexplore
10.1109/ROBOT.2010.5509682,Indoor scene recognition through object detection,IEEE,Conferences,"Scene recognition is a highly valuable perceptual ability for an indoor mobile robot, however, current approaches for scene recognition present a significant drop in performance for the case of indoor scenes. We believe that this can be explained by the high appearance variability of indoor environments. This stresses the need to include high-level semantic information in the recognition process. In this work we propose a new approach for indoor scene recognition based on a generative probabilistic hierarchical model that uses common objects as an intermediate semantic representation. Under this model, we use object classifiers to associate low-level visual features to objects, and at the same time, we use contextual relations to associate objects to scenes. As a further contribution, we improve the performance of current state-of-the-art category-level object classifiers by including geometrical information obtained from a 3D range sensor that facilitates the implementation of a focus of attention mechanism within a Monte Carlo sampling scheme. We test our approach using real data, showing significant advantages with respect to previous state-of-the-art methods.",https://ieeexplore.ieee.org/document/5509682/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/ROBOT.1991.131908,Instinctive behaviors and personalities in societies of cellular robots,IEEE,Conferences,"A description is presented of the social organization of societies of cellular mobile units featuring instinctive behavior. Each robotic unit has its own personality and lives independently from the others. Useful tasks are carried out through collaboration rather than by individual effort. The behavior of each unit derives from a subsumption-like control structure, which emphasizes the roles of innate personality, external stimuli, and communication. A number of different robotic personalities are described and techniques of implementing them in real robot units are outlined. The implementation of instinctive behavior is described for the case of a robotic vehicle system (ROBBIE).&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/131908/,Proceedings. 1991 IEEE International Conference on Robotics and Automation,9-11 April 1991,ieeexplore
10.1109/ROBOT.1992.219999,Integrated planning and execution control of autonomous robot actions,IEEE,Conferences,"The authors describe an implemented integrated system allowing a mobile robot to plan its actions, taking into account temporal constraints, and to control their execution in real time. The general architecture has three levels, and the approach is related to hierarchical planning: the plan produced by the temporal planner is further refined at the control level, which in turn supervises its execution by a functional level. The framework of the French Mars Rover project VAP is used as an illustration of the various aspects discussed.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/219999/,Proceedings 1992 IEEE International Conference on Robotics and Automation,12-14 May 1992,ieeexplore
10.1109/ISCAS.2007.378811,Integrating high-level sensor features via STDP for bio-inspired navigation,IEEE,Conferences,"Correlation based algorithms have been found to explain many basic behaviors in simple animals. In this paper the authors investigate the problem of navigation control of a robot from the viewpoint of bio-inspired perception. In this paper the authors study how to go up, through learning, from the implementation of a reactive system, towards behaviors of increasing complexity. The whole control system is based on networks of spiking neurons. A correlation based rule, namely the spike timing dependent plasticity (STDP), is implemented for an efficient learning. The main interesting consequence is that the system is able to learn high-level sensor features, based on a set of basic reflexes, depending on some low-level sensor inputs. The whole methodology is presented through simulation results and also through its implementation on an FPGA based system for real time working on a roving robot.",https://ieeexplore.ieee.org/document/4252708/,2007 IEEE International Symposium on Circuits and Systems,27-30 May 2007,ieeexplore
10.1109/LARS-SBR.2016.49,Integration of People Detection and Simultaneous Localization and Mapping Systems for an Autonomous Robotic Platform,IEEE,Conferences,"This paper presents the implementation of a people detection system for a robotic platform able to perform Simultaneous Localization and Mapping (SLAM), allowing the exploration and navigation of the robot considering people detection interaction. The robotic platform consists of a Pioneer 3DX robot equipped with an RGB-D camera, a Sick Lms200 sensor laser and a computer using the robot operating system ROS. The idea is to integrate the people detection system to the simultaneous localization and mapping (SLAM) system of the robot using ROS. Furthermore, this paper presents an evaluation of two different approaches for the people detection system. The first one uses a manual feature extraction technique, and the other one is based on deep learning methods. The manual feature extraction method in the first approach is based on HOG (Histogram of Oriented Gradients) detectors. The accuracy of the techniques was evaluated using two different libraries. The PCL library (Point Cloud Library) implemented in C ++ and the VLFeat MatLab library with two HOG variants, the original one, and the DPM (Deformable Part Model) variant. The second approaches are based on a Deep Convolutional Neural Network (CNN), and it was implemented using the MatLab MatConvNet library. Tests were made objecting the evaluation of losses and false positives in the people's detection process in both approaches. It allowed us to evaluate the people detection system during the navigation and exploration of the robot, considering the real time interaction of people recognition in a semi-structured environment.",https://ieeexplore.ieee.org/document/7783535/,2016 XIII Latin American Robotics Symposium and IV Brazilian Robotics Symposium (LARS/SBR),8-12 Oct. 2016,ieeexplore
10.1109/IECON.2011.6119682,Integration of grey model and neural network for robotic application,IEEE,Conferences,"This paper proposes an intelligent forecasting system based on a feedforward neural network aided grey model (FNAGM), integrating a first-order single variable grey model (GM(1,1)) and a feedforward neural network. The system includes three phases: initialization phase, GM(1,1) prediction phase, and FNAGM prediction phase. A number of parameters required for the FNAGM are selected in the initialization phase. A one-step ahead predictive value is generated in the GM(1,1) prediction phase, followed by the implementation of a feedforward neural network used to determine the prediction error of the GM(1,1) and compensate for it in the FNAGM prediction phase. We also adopted on-line batch training to adjust the network according to the Levenberg-Marquardt algorithm in real-time. According to the experimental results of a robot, the proposed intelligent forecasting system can provide high accuracy for both trajectory prediction and target tracking.",https://ieeexplore.ieee.org/document/6119682/,IECON 2011 - 37th Annual Conference of the IEEE Industrial Electronics Society,7-10 Nov. 2011,ieeexplore
10.1109/IJCNN.2014.6889647,Intelligent Facial Action and emotion recognition for humanoid robots,IEEE,Conferences,"This research focuses on the development of a realtime intelligent facial emotion recognition system for a humanoid robot. In our system, Facial Action Coding System is used to guide the automatic analysis of emotional facial behaviours. The work includes both an upper and a lower facial Action Units (AU) analyser. The upper facial analyser is able to recognise six AUs including Inner and Outer Brow Raiser, Upper Lid Raiser etc, while the lower facial analyser is able to detect eleven AUs including Upper Lip Raiser, Lip Corner Puller, Chin Raiser, etc. Both of the upper and lower analysers are implemented using feedforward Neural Networks (NN). The work also further decodes six basic emotions from the recognised AUs. Two types of facial emotion recognisers are implemented, NN-based and multi-class Support Vector Machine (SVM) based. The NN-based facial emotion recogniser with the above recognised AUs as inputs performs robustly and efficiently. The Multi-class SVM with the radial basis function kernel enables the robot to outperform the NN-based emotion recogniser in real-time posed facial emotion detection tasks for diverse testing subjects.",https://ieeexplore.ieee.org/document/6889647/,2014 International Joint Conference on Neural Networks (IJCNN),6-11 July 2014,ieeexplore
10.1109/ARIS50834.2020.9205772,Intelligent Robot for Worker Safety Surveillance: Deep Learning Perception and Visual Navigation,IEEE,Conferences,"The fatal injury rate for the construction industry is higher than the average for all industries. Recently, researchers have shown an increased interest in occupational safety in the construction industry. However, all the current methods using conventional machine learning with stationary cameras suffer from some severe limitations, perceptual aliasing (e.g., different places/objects can appear identical), occlusion (e.g., place/object appearance changes between visits), seasonal / illumination changes, significant viewpoint changes, etc. This paper proposes a perception module using end-to-end deep-learning and visual SLAM (Simultaneous Localization and Mapping) for an effective and efficient object recognition and navigation using a differential-drive mobile robot. Various deep-learning frameworks and visual navigation strategies with evaluation metrics are implemented and validated for the selection of the best model. The deep-learning model's predictions are evaluated via the metrics (model speed, accuracy, complexity, precision, recall, P-R curve, F1 score). The YOLOv3 shows the best trade-off among all algorithms, 57.9% mean average precision (mAP), in real-world settings, and can process 45 frames per second (FPS) on NVIDIA Jetson TX2 which makes it suitable for real-time detection, as well as a right candidate for deploying the neural network on a mobile robot. The evaluation metrics used for the comparison of laser SLAM are Root Mean Square Error (RMSE). The Google Cartographer SLAM shows the lowest RMSE and acceptable processing time. The experimental results demonstrate that the perception module can meet the requirements of head protection criteria in Occupational Safety and Health Administration (OSHA) standards for construction. To be more precise, this module can effectively detect construction worker's non-hardhat-use in different construction site conditions and can facilitate improved safety inspection and supervision.",https://ieeexplore.ieee.org/document/9205772/,2020 International Conference on Advanced Robotics and Intelligent Systems (ARIS),19-21 Aug. 2020,ieeexplore
10.1109/ICAMechS.2016.7813486,Intelligent adaptive precrash control for autonmous vehicle agents (CBR Engine &amp; hybrid A∗ path planner),IEEE,Conferences,"PreCrash problem of Intelligent Control of autonomous vehicles robot is a very complex problem, especially vehicle pre-crash scenariws and at points of intersections in real-time environmenta. This Paper presents a novel architecture of Intelligent adaptive control for autonomous vehicle agent that depends on Artificial Intelligence Techniques that applies case-based reasoning techniques, where Parallel CBR Engines are implemented for different scenarios' of PreCrash problem and sub-problems of intersection safety and collision avoidance, in the higher level of the controller and A* path planner for path planning and at lower-levels it also uses some features of autonomous vehicle dynamics. Moreover, the planner is enhanced by combination of Case-Based Planner. All modules are presented and discussed. Experimental results are conducted in the framework of Webots autonomous vehicle tool and overall results are good for the CBR Engine for Adaptive control and also for the hybrid Case-Based Planner, A* and D* motion planner along with conclusion and future work.",https://ieeexplore.ieee.org/document/7813486/,2016 International Conference on Advanced Mechatronic Systems (ICAMechS),30 Nov.-3 Dec. 2016,ieeexplore
10.1109/ICIT.2010.5472498,Intelligent control and evolutionary strategies applied to multirobotic systems,IEEE,Conferences,"This paper describes the modeling, implementation, and evaluation of RoBombeiros multirobotic system. The robotic task in this paper is performed over a natural disaster, simulated as a forest fire. The simulator supports several features to allow realistic simulation, like irregular terrains, natural processes (e.g. fire, wind) and physical constraint in the creation and application of mobile robots. The proposed system relies on two steps: (i) group formation planning and (ii) intelligent techniques to perform robots navigation for fire fighting. For planning, we used genetic algorithms to evolve positioning strategies for firefighting robots performance. For robots operation, physically simulated fire-fighting robots were built, and the sensory information of each robot (e.g. GPS, compass, sonar) was used in the input of an artificial neural network (ANN). The ANN controls the vehicle (robot) actuators and allows navigation with obstacle avoidance. Simulation results show that the ANN satisfactorily controls the mobile robots; the genetic algorithm adequately configures the fire fighting strategy and the proposed multi-robotic system can have an essential hole in the planning and execution of fire fighting in real forests.",https://ieeexplore.ieee.org/document/5472498/,2010 IEEE International Conference on Industrial Technology,14-17 March 2010,ieeexplore
10.1109/ICNN.1988.23981,Intelligent control of the Intelledex 605T robot manipulator,IEEE,Conferences,"The authors present the results of the experiments which indicate how controlled robotic motion might be achieved through pattern-based paradigms, implemented for real-time operation on the Intelledex 605T robot manipulator with artificial neural nets (ANN). Previous attempts at pattern-based control have often failed, primarily because of the need for storage of an enormous number of training-set patterns and the long times required for pattern processing. It is demonstrated that these problems can be overcome through use of artificial neural networks implemented by parallel distributed processing. The feedforward Rumelhart net is investigated for the constrained robot manipulator. The robot arm, with two degrees of freedom, must move its end effector toward an observed target in the presence of disturbances. Such a control action need not be programmed in detail. Presented with a small number of training situations, the ANN can generalize and perform in many different situations. Preliminary results obtained using an Intelledex 605T and an IBM PC/AT are described.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/23981/,IEEE 1988 International Conference on Neural Networks,24-27 July 1988,ieeexplore
10.1109/IROS.2005.1545188,Interactive evolution of human-robot communication in real world,IEEE,Conferences,"This paper describes how to implement interactive evolutionary computation (IEC) into a human-robot communication system. IEC is an evolutionary computation (EC) in which the fitness function is performed by human assessors. We used IEC to configure the human-robot communication system. We have already simulated IEC's application. In this paper, we implemented IEC into a real robot. Since this experiment leads considerable burdens on both the robot and experimental subjects, we propose the human-machine hybrid evaluation (HMHE) to increase the diversity within the genetic pool without increasing the number of interactions. We used a communication robot, WAMOEBA-3 (Waseda artificial mind on emotion base), which is appropriate for this experiment. In the experiment, human assessors interacted with WAMOEBA-3 in various ways. The fitness values increased gradually, and assessors felt the robot learnt the motions they desired. Therefore, it was confirmed that the IEC is most suitable as the communication learning system.",https://ieeexplore.ieee.org/document/1545188/,2005 IEEE/RSJ International Conference on Intelligent Robots and Systems,2-6 Aug. 2005,ieeexplore
10.1109/ISIC.2003.1253948,Internet-based remote control by using Adaline neural networks,IEEE,Conferences,"In this paper, we present a remote control scheme for Internet-based teleoperation. This control scheme relies on the real-time estimation of concurrent roundtrip delays in order to optimally assign tasks between the user and the robot. For this purpose, we employ an adaptive linear (Adaline) neural network for which most conventional learning algorithms are infeasible since the computation is usually too intensive to be practical. To get around this problem, we introduce a novel learning algorithm that is based on the maximum entropy principle. Compared to traditional learning algorithms, the computing cost of this algorithm is very low, which makes it possible for the proposed neural network to be implemented on-line in real-time.",https://ieeexplore.ieee.org/document/1253948/,Proceedings of the 2003 IEEE International Symposium on Intelligent Control,8-8 Oct. 2003,ieeexplore
10.1109/ISSCS52333.2021.9497411,Inverted Pendulum Control with a Robotic Arm using Deep Reinforcement Learning,IEEE,Conferences,"Inverted pendulum control is a benchmark control problem that researchers have used to test the new control strategies over the past 50 years. Deep Reinforcement Learning Algorithm is used recently on the inverted pendulum on a straightforward form. The inverted pendulum had only one degree of freedom and was moving on a plane. This paper demonstrates a successful implementation of a deep reinforcement learning algorithm on an inverted pendulum that rotates freely on a spherical joint with an industrial 6 degrees freedom robot arm. This research used the Deep Reinforcement Learning algorithm in Robot Operating System (ROS) and Gazebo Simulation. Experimental results show that the proposed method achieved promising outputs and reaches the control objectives. We were able to control the inverted pendulum upward for 30 and 20 seconds in two case studies. Two other significant novelties in this research are using an inertial measurement unit (IMU) on the tip of the pendulum, that will facilitate implementation on the real robot for future work and different reward functions in comparing to past publications that enable continuous learning and mastering control in a vertical position",https://ieeexplore.ieee.org/document/9497411/,"2021 International Symposium on Signals, Circuits and Systems (ISSCS)",15-16 July 2021,ieeexplore
10.1109/ICRAI47710.2019.8967365,Investigating Series-Parallel Actuation Arrangement in a Bioinspired Biped Robot,IEEE,Conferences,A bipedal robot with serial linkage legs having passive energy storage elements distal to the knee in a Series Parallel Elastic Actuation (SPEA) arrangement is presented to demonstrate and experiment on energy input and recovery during energy-intensive low frequency squatting. The robot is based on the hind legs of the Felidae family with bio-inspired linkage ratios and spring locations. The design places special emphasis on reduction of leg inertia by qualitative assessment of placement of heavier components including motors. Natural dynamics of the system are explored by allowing the assembly to fall from a height and observing its passive spring-damping characteristics and oscillatory frequency. The same is also investigated through computational simulations in the absence of real-world constraints such as joint friction. The effects of SPEA at the knee and ankle joint is observed on the ground-reaction force through the simulation environment. An interesting proposal of incorporating an engage-disengage spring at the knee joint is discussed.,https://ieeexplore.ieee.org/document/8967365/,2019 International Conference on Robotics and Automation in Industry (ICRAI),21-22 Oct. 2019,ieeexplore
10.1109/IJCNN.2003.1223995,Investigating models of social development using a humanoid robot,IEEE,Conferences,"Human social dynamics rely upon the ability to correctly attribute beliefs, goals, and percepts to other people. The set of abilities that allow an individual to infer these hidden mental states based on observed actions and behavior has been called a ""theory of mind"". Drawing from the models of Baron-Cohen (1995) and Leslie (1994), a novel architecture called embodied theory of mind was developed to link high-level cognitive skills to the low-level perceptual abilities of a humanoid robot. The implemented system determines visual saliency based on inherent object attributes, high-level task constraints, and the attentional states of others. Objects of interest are tracked in real-time to produce motion trajectories which are analyzed by a set of naive physical laws designed to discriminate animate from inanimate movement. Animate objects can be the source of attentional states (detected by finding faces and head orientation) as well as intentional states (determined by motion trajectories between objects). Individual components are evaluated by comparisons to human performance on similar tasks, and the complete system is evaluated in the context of a basic social learning mechanism that allows the robot to mimic observed movements.",https://ieeexplore.ieee.org/document/1223995/,"Proceedings of the International Joint Conference on Neural Networks, 2003.",20-24 July 2003,ieeexplore
10.1109/ACC.1994.735001,Investigation of kinematics and inverse dynamics algorithm with a DSP implementation of a neural network,IEEE,Conferences,"An investigation is described to demonstrate the benefits which can be gained by using a digital signal processor (DSP) to implement robot related control schemes, kinematics, and inverse dynamics with a neural network. A neural network adaptive controller is given and applied to a robot manipulator having a closed kinematic chain, a configuration which is not well suited to the popular serial link algorithms. The Lyapunov's stability approach is used to develop a learning rule for the neural network controller that would guarantee the stability of the training process under mild conditions. The controller hardware consists of a PC-386, a fixed point DSP, and a floating point DSP. The software installed on each of these processors has the requirements of satisfying the specific responsibility assigned to that processor and of communicating with other processors so that necessary data is passed on in a timely manner. A computational software package has been built to further enhance the speed of the general control scheme and the neural network algorithm. The techniques used in the DSP implementation of the adaptive control algorithm in real-time are also discussed.",https://ieeexplore.ieee.org/document/735001/,Proceedings of 1994 American Control Conference - ACC '94,29 June-1 July 1994,ieeexplore
10.1109/ICETIETR.2018.8529028,IoT Enabled Robots with QR Code Based Localization,IEEE,Conferences,"Robots are sophisticated form of IoT devices as they are smart devices that scrutinize sensor data from multiple sources and observe events to decide the best procedural actions to supervise and manoeuvre objects in the physical world. In this paper, localization of the robot is addressed by QR code Detection and path optimization is accomplished by Dijkstras algorithm. The robot can navigate automatically in its environment with sensors and shortest path is computed whenever heading measurements are updated with QR code landmark recognition. The proposed approach highly reduces computational burden and deployment complexity as it reflects the use of artificial intelligence to self-correct its course when required. An Encrypted communication channel is established over wireless local area network using SSHv2 protocol to transfer or receive sensor data(or commands) making it an IoT enabled Robot.",https://ieeexplore.ieee.org/document/8529028/,2018 International Conference on Emerging Trends and Innovations In Engineering And Technological Research (ICETIETR),11-13 July 2018,ieeexplore
10.1109/ISIE.2009.5221750,Joint control of ROBOKER arm using a neural chip embedded on FPGA,IEEE,Conferences,"This paper presents implementation of a neural chip to proceed neural processing of the radial basis function (RBF) network. RBF network along with a primary PD controller is trained in on-line fashion. Radial basis function network processing is embedded on a field programmable gate array(FPGA) chip to achieve real-time control. To enable nonlinear function calculation, a floating point processor is designed to allow assembly programming for learning algorithm. Other necessary hardware modules for control purposes are also designed and implemented. A humanoid robot called the ROBOKER with two arms of 6 degrees-of-freedom each is controlled. Joint angles of the ROBOKER arms are controlled and tracking performances by the neural chip are compared with those by PD controllers.",https://ieeexplore.ieee.org/document/5221750/,2009 IEEE International Symposium on Industrial Electronics,5-8 July 2009,ieeexplore
10.1109/GCIS.2009.206,Layered Task Allocation in Multi-robot Systems,IEEE,Conferences,"A layered task allocation method is presented for multi-robot systems in a collaboration and adversarial, dynamic, real-time environment with unreliable communication in this paper. The process of task allocation is divided into three layers: task decomposition layer, task evaluation layer and task selection layer. In task decomposition layer, robots categorize their environments into corresponding modes, and fix subtasks in every mode as experts do, in order to reduce candidate tasks and decrease the complexity of task allocation. Q-Learning based on Adaptive Neuro Fuzzy Inference System (ANFIS) is adopted to compute utilities of candidate tasks in task evaluation layer. This can not only avoid the complicated opponent modeling but also make the learning more efficient. In task selection layer, task with the maximum utility is selected in application, but in learning, task is selected according to randomized Boltzmann exploration tactics in order to get more information for optimization. Simulation experiments implemented on simulated robotic soccer show that this approach improves performances of multi-robot systems greatly.",https://ieeexplore.ieee.org/document/5209028/,2009 WRI Global Congress on Intelligent Systems,19-21 May 2009,ieeexplore
10.1109/ROBIO.2007.4522258,Layered omnidirectional walking controller for the humanoid soccer robot,IEEE,Conferences,"This paper proposes the layered omnidirectional walking controller for the humanoid soccer robot. The gait of the robot can be parameterized using the destination posititon and the desired direction while reaching the destination. Its implementation in our RoboCup simulation team - SEU-3D is detailed in this paper. Our approach generates smooth robot trajectories without stop before changing direction or turning, and is fast enough to meet the real-time requirements. The proposed approach has been tested in the RoboCup soccer 3D server platform. The results showed that omnidirectional walking has advantages in dynamic environments.",https://ieeexplore.ieee.org/document/4522258/,2007 IEEE International Conference on Robotics and Biomimetics (ROBIO),15-18 Dec. 2007,ieeexplore
10.1109/OCEANS.2018.8604686,Learned Anticipation Strategy on Complex Behaviors and as an Approach to Generalization Behavior for the Coordination of an AUV Fleet,IEEE,Conferences,"Anticipation is natural behavior seen in certain organisms when they try to adapt their behavior to create an accurate reaction to an event that will happen in the future based on sequential information that extracted from the environment and other organisms. Anticipation has been studied from both the human and the animal perspectives and science has been taking some of these ideas to implement this behavior in machines. Research and studies of anticipation using Artificial Intelligence (AI) methods has been growing during the past years within different fields, including Robotics, Stock Market, Weather Forecast, Social Media, among others. At the University of Idaho, we have been focusing on studying Anticipation using Autonomous Underwater Vehicles (AUV). This paper analyzes the impact on coordination of including an anticipation module to adapt to complex behaviors and to make decisions based on generalization while running as part of a simulation of a fleet of AUVs following a magnetic signature assessment (MSA) task. During this task, a moving Target Ship (TS) shares information about its behavior with the fleet of AUVs while the fleet tries to maintain formation and reach a designated meeting point at the same time as the TS. The TS behaviors include sudden and/or complex changes in movement during the experiment. These changes in the TS's movement make it difficult for the AUVs to reach the meeting point at the same time as the TS without additional information. Progress messages from the TS are used by the AUVs to adjust their behavior, but the messages may be sparse. A portion of the data that represents the TS's behavior was used as training data for the anticipation module in the AUVs. The remaining data was used as brand new cases that the anticipation module would try to solve to encourage generalization. Generalization occurs when the robot can solve a task that it was not trained for, but there was sufficient training data to result in reasonable solutions. For these experiments, the messages that are sent by the TS to the AUVs report the TS's progress to the goal. The TS reports its progress using Fuzzy set membership values. This strategy is used to model real-world situations where progress cannot be defined with exact values. The membership values are represented by fuzzy sets including On Schedule, Behind Schedule, Ahead of Schedule, etc. This strategy gives a more human-like approach to the AUVs for decision making because humans often say things like “I'm a little behind schedule”. The anticipation module works as an aid for the communication between the TS and the fleet of AUVs. It tries to keep the fleet running on track and synchronized with the TS behavior by filling in missing messages with an anticipated message. In this research it is assumed that missing and corrupt messages occur because of a noisy or low-bandwidth communications. The experiments simulate this condition by sending messages more infrequently. The TS stops broadcasting messages for a specific time period that has been selected before starting the test. Versions of the anticipation module, using a Neural Network model and a Fuzzy Logic model were tested. To have comparable results, the position of the meeting point is constant during each experiment and is used as a point of reference. The effectiveness of the anticipation module was evaluated by measuring the distance between the actual meeting point of the fleet of AUVs and the TS and the desired meeting point. In general the anticipation module reduced the error significantly. This included the tests using the novel behaviors that were not part of the training set. These last results lead to the idea that, with the right training data, the AUVs are displaying generalization behavior. In general, the anticipation module helps the fleet of AUVs to infer the behavior of the TS and they synchronize to the TS even when there was a lack of information, caused by missing messages.",https://ieeexplore.ieee.org/document/8604686/,OCEANS 2018 MTS/IEEE Charleston,22-25 Oct. 2018,ieeexplore
10.1109/ICTC49870.2020.9289214,Learning Control Policy with Previous Experiences from Robot Simulator,IEEE,Conferences,"Advances in deep reinforcement learning enabled cost-efficient training of control policy of physical robot actions from robot simulators. Learning control policy in a simulated environment is cost-efficient over learning in a real environment. Reward engineering is one of the key components to train efficient control policy. For tasks with long horizons such as navigation and manipulation, a sparse reward is providing limited information. The robot simulator for a physical engine of physical robot manipulation has made it easy for researchers in the field of deep reinforcement learning to simulate complicated robot manipulation environments. In this paper, A robot manipulation simulator and a deep RL framework are utilized for implement a training control policy by utilizing previous experiences. For implementation, Recent innovation Hindsight Experience Replay (HER) algorithms with previous experiences to calculate dense rewards from a sparse reward is leveraged . Proposed implementation showed an approach to investigate the reward engineering method to formulate dense reward in robot manipulator tasks.",https://ieeexplore.ieee.org/document/9289214/,2020 International Conference on Information and Communication Technology Convergence (ICTC),21-23 Oct. 2020,ieeexplore
10.1109/IROS45743.2020.9340865,Learning Human-Aware Robot Navigation from Physical Interaction via Inverse Reinforcement Learning,IEEE,Conferences,"Autonomous systems, such as delivery robots, are increasingly employed in indoor spaces to carry out activities alongside humans. This development poses the question of how robots can carry out their tasks while, at the same time, behaving in a socially compliant manner. Further, humans need to be able to communicate their preferences in a simple and intuitive way, and robots should adapt their behavior accordingly. This paper investigates force control as a natural means to interact with a mobile robot by pushing it along the desired trajectory. We employ inverse reinforcement learning (IRL) to learn from human interaction and adapt the robot behavior to its users' preferences, thereby eliminating the need to program the desired behavior manually. We evaluate our approach in a real-world experiment where test subjects interact with an autonomously navigating robot in close proximity. The results suggest that force control presents an intuitive means to interact with a mobile robot and show that our robot can quickly adapt to the test subjects' personal preferences.",https://ieeexplore.ieee.org/document/9340865/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/SMC.2019.8914406,Learning Locomotion Skills via Model-based Proximal Meta-Reinforcement Learning,IEEE,Conferences,"Model-based reinforcement learning methods provide a promising direction for a range of automated applications, such as autonomous vehicles and legged robots, due to their sample-efficiency. However, their asymptotic performance is usually inferior compared to the state-of-the-art model-free reinforcement learning methods in locomotion control domains. One main challenge of model-based reinforcement learning is learning a dynamics model that is accurate enough for planning. This paper mitigates this issue by meta-reinforcement learning from an ensemble of dynamics models. A policy learns from dynamics models that hold different beliefs of a real environment. This procedure improves its adaptability and inaccuracy-tolerance ability. A proximal meta-reinforcement learning algorithm is introduced to improve computational efficiency and reduces variance of higher-order gradient estimation. A heteroscedastic noise is added to the training dataset, thus leading to a robust and efficient model learning. Subsequently, proximal meta-reinforcement learning maximizes the expected returns by sampling “imaginary” trajectories from the learned dynamics, which does not require real environment data and can be deployed on many servers in parallel to speed up the whole learning process. The aim of this work is to reduce the sample-complexity and computational cost of reinforcement learning in robot locomotion tasks. Simulation experiments show that the proposed algorithm achieves an asymptotic performance compared with the state-of-the-art model-free reinforcement learning methods with significantly fewer samples, which confirm our theoretical results.",https://ieeexplore.ieee.org/document/8914406/,"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)",6-9 Oct. 2019,ieeexplore
10.1109/IROS45743.2020.9341458,Learning Motion Parameterizations of Mobile Pick and Place Actions from Observing Humans in Virtual Environments,IEEE,Conferences,"In this paper, we present an approach and an implemented pipeline for transferring data acquired from observing humans in virtual environments onto robots acting in the real world, and adapting the data accordingly to achieve successful task execution. We demonstrate our pipeline by inferring seven different symbolic and subsymbolic motion parameters of mobile pick and place actions, which allows the robot to set a simple breakfast table. We propose an approach to learn general motion parameter models and discuss, which parameters can be learned at which abstraction level.",https://ieeexplore.ieee.org/document/9341458/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ICRA40945.2020.9196785,Learning Resilient Behaviors for Navigation Under Uncertainty,IEEE,Conferences,"Deep reinforcement learning has great potential to acquire complex, adaptive behaviors for autonomous agents automatically. However, the underlying neural network polices have not been widely deployed in real-world applications, especially in these safety-critical tasks (e.g., autonomous driving). One of the reasons is that the learned policy cannot perform flexible and resilient behaviors as traditional methods to adapt to diverse environments. In this paper, we consider the problem that a mobile robot learns adaptive and resilient behaviors for navigating in unseen uncertain environments while avoiding collisions. We present a novel approach for uncertainty-aware navigation by introducing an uncertainty-aware predictor to model the environmental uncertainty, and we propose a novel uncertainty-aware navigation network to learn resilient behaviors in the prior unknown environments. To train the proposed uncertainty-aware network more stably and efficiently, we present the temperature decay training paradigm, which balances exploration and exploitation during the training process. Our experimental evaluation demonstrates that our approach can learn resilient behaviors in diverse environments and generate adaptive trajectories according to environmental uncertainties.",https://ieeexplore.ieee.org/document/9196785/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ISIE.2007.4374932,Learning Wall Following Behaviour in Robotics through Reinforcement and Image-based States,IEEE,Conferences,"In this work, a visual and reactive wall following behaviour is learned by reinforcement. With artificial vision the environment is perceived in 3D, and it is possible to avoid obstacles that are invisible to other sensors that are more common in mobile robotics. Reinforcement learning reduces the need for intervention in behaviour design, and simplifies its adjustment to the environment, the robot and the task. In order to facilitate its generalization to other behaviours and to reduce the role of the designer, we propose a regular image-based codification of states. Even though this is much more difficult, our implementation converges and is robust. Results are presented with a Pioneer 2 AT. Learning phase has been realized on the Gazebo 3D simulator and the test phase has been proved in simulated and real environments to demonstrate the correct design and robustness of our algorithms.",https://ieeexplore.ieee.org/document/4374932/,2007 IEEE International Symposium on Industrial Electronics,4-7 June 2007,ieeexplore
10.1109/IIAI-AAI.2013.74,Learning Which Features to Imitate in a Painting Task,IEEE,Conferences,"Learning is essential for an autonomous agent to adapt to an environment. One method of learning is through trial and error, however, this method is impractical in a complex environment because of the long learning time required by the agent. Therefore, guidelines are necessary in order to expedite the learning process in such environments, and imitation is one such guideline. Sakato, Ozeki, and Oka (2012) recently proposed a computational model of imitation and autonomous behavior by which an agent can reduce its learning time through imitation. In this paper, we apply the model to a real robot, Nao, and evaluate the model using simple features in a simple environment. We also report on the progress of implementation of the model, and evaluations of the performance of imitation using the implemented model. Our experimental results indicate that the model adapted to the experimental environment by imitation.",https://ieeexplore.ieee.org/document/6630378/,2013 Second IIAI International Conference on Advanced Applied Informatics,31 Aug.-4 Sept. 2013,ieeexplore
10.1109/IJCNN.2005.1556414,Learning a hierarchical fuzzy system with autonomous navigation as an example,IEEE,Conferences,"In this paper, a hierarchical fuzzy system for high-dimensional dataset is proposed. The sequential least-squares method is introduced to estimate Takagi-Sugeno rules. A hierarchical clustering takes place in the product space of input and output, and each path from the root to a leaf corresponds to a fuzzy if-then rule. Only a subset of the rules is considered, based on the location of the input query data. At each level of the hierarchy, a discriminating subspace is generated automatically from the high-dimensional input space for a good generalization capability. Both a synthetic data set and a real robot autonomous navigation experiment are considered to illustrate how effective the system is.",https://ieeexplore.ieee.org/document/1556414/,"Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005.",31 July-4 Aug. 2005,ieeexplore
10.1109/ICRA.2016.7487509,Learning assistive strategies from a few user-robot interactions: Model-based reinforcement learning approach,IEEE,Conferences,"Designing an assistive strategy for exoskeletons is a key ingredient in movement assistance and rehabilitation. While several approaches have been explored, most studies are based on mechanical models of the human user, i.e., rigid-body dynamics or Center of Mass (CoM)-Zero Moment Point (ZMP) inverted pendulum moECenter of Massdel, or only focus on periodic movements with using oscillator models. On the other hand, the interactions between the user and the robot are often not considered explicitly because of its difficulty in modeling. In this paper, we propose to learn the assistive strategies directly from interactions between the user and the robot. We formulate the learning problem of assistive strategies as a policy search problem. To alleviate heavy burdens to the user for data acquisition, we exploit a data-efficient model-based reinforcement learning framework. To validate the effectiveness of our approach, an experimental platform composed of a real subject, an electromyography (EMG)-measurement system, and a simulated robot arm is developed. Then, a learning experiment with the assistive control task of the robot arm is conducted. As a result, proper assistive strategies that can achieve the robot control task and reduce EMG signals of the user are acquired only by 30 seconds interactions.",https://ieeexplore.ieee.org/document/7487509/,2016 IEEE International Conference on Robotics and Automation (ICRA),16-21 May 2016,ieeexplore
10.1109/IECON.1993.339280,Learning behavioral control by reinforcement for an autonomous mobile robot,IEEE,Conferences,"We present an implementation of a reinforcement learning algorithm through the use of a special neural network topology, the AHC (adaptive heuristic critic). The AHC constitutes a fusion supervisor of primitive behaviours in order to execute more complex robot behaviours as for example go to goal. This fusion supervisor is part of an architecture for the execution of mobile robot tasks which are composed of several primitive behaviours which act in a simultaneous or concurrent fashion. The architecture allows for learning to take place at the execution level, it incorporates the experience gained in executing primitive behaviours as well as the overall task. The implementation of the autonomous learning approach has been tested within OPMOR, a simulation environment for mobile robots and with our mobile platform UPM Robuter. Both simulated and real results are presented. The performance of the AHC neural network is adequate. Portions of this work have been implemented in the EEC ESPRIT 2483 PANORAMA Project.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/339280/,Proceedings of IECON '93 - 19th Annual Conference of IEEE Industrial Electronics,15-19 Nov. 1993,ieeexplore
10.1109/ROBIO.2017.8324818,Learning complex assembly skills from kinect based human robot interaction,IEEE,Conferences,"Acquiring complex assembly skills is still a challenging task for robot programming. Because of the sensory and body structure differences, the human knowledge has to be demonstrated, recorded, converted and finally learned by the robot, in an inexplicit and indirect way. During this process, “how to demonstrate”, “how to convert” and “how to learn” are the key problems. In this paper, Kinect sensor is utilized to provide the behavior information of the human demonstrator. Through natural human robot interaction, body skeleton and joint 3D coordinates are provided in real-time, which can fully describe the human intension and task related skills. To overcome the structural and individual differences, a Cartesian level unified mapping method is proposed to convert the human motion and match the specified robot. The recorded data set are modeled using Gaussian mixture model(GMM) and Gaussian mixture regression(GMR), which can extract redundancies across multiple demonstrations and build robust models to regenerate the dynamics of the recorded movements. The proposed methodologies are implemented in the imNEU humanoid robot platform. Experimental results verify the effectiveness.",https://ieeexplore.ieee.org/document/8324818/,2017 IEEE International Conference on Robotics and Biomimetics (ROBIO),5-8 Dec. 2017,ieeexplore
10.1109/IS.2018.8710525,Learning from Virtual Experience: Mapless Navigation with Neuro-Fuzzy Intelligence,IEEE,Conferences,"Traditional robot navigation approaches normally rely on creating a precise map of the environment which is a computationally expensive procedure and highly depends on an accurate sensory system. Even for motion planning in similar terrains, the planner needs to prepare or obtain a map beforehand. In this paper, this issue is addressed, and a neurofuzzy motion planner is presented for mobile robot navigation without a map. We show that, by means of a virtual experience model and a neuro-fuzzy system, a mapless motion planning approach can learn basic navigation primitives in simple obstacle arrangements without any prior demonstration. The virtual experience model creates a large number of test environments with a random set of arbitrarily shaped obstacles and places the robot in a random pose with different start and goal positions in different instances. Then, based on the readings of the robot's sensors and a collection of predefined general linguistic rules, a set of control commands including the robot's linear and angular velocity is calculated as the outputs of the virtual experience. The resulting dataset is then loaded into an adaptive neuro-fuzzy inference system to create and optimize a fuzzy motion planner using the subtractive clustering method and a hybrid technique combining the back-propagation algorithm and the least square adaptation method respectively, which guides the robot in simple unknown environments without requiring a global obstacle map. To validate the effectiveness of the proposed model, the motion planner was implemented on a nonholonomic differential drive robot to test its performance in two real navigation tasks. Experimental studies show that the proposed mapless motion planner can efficiently guide the robot in similar arrangements of convex obstacles.",https://ieeexplore.ieee.org/document/8710525/,2018 International Conference on Intelligent Systems (IS),25-27 Sept. 2018,ieeexplore
10.1109/ICSMC.1999.816636,Learning from conceptual aliasing caused by direct teaching,IEEE,Conferences,"Perceptual and action aliasing caused by the state and action space differences between the learner and the teacher (hereafter, we call these two problems conceptual aliasing) is a serious problem for direct teaching methods because the instructions given by the teacher might not be consistent with the learner's view. This paper proposes a method that resolves conceptual aliasing by two-mode frequent instructions on the teacher's side and self-learning mechanism on the learner's side. The experiment with a real robot is shown and a discussion is given.",https://ieeexplore.ieee.org/document/816636/,"IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028)",12-15 Oct. 1999,ieeexplore
10.1109/ICSMC.2010.5641727,Learning from conflicts in real world environments for the realization of Cognitive Technical Systems,IEEE,Conferences,"In this contribution, a novel learning method realizing the refinement of a Cognitive Technical System's pattern recognition and attention capabilities is presented. The method is implemented within a cognitive architecture with a representational level based on Situation-Operator-Modeling and high-level Petri Nets. Through the representational level, it is possible to realize a mental model mapping the complex structure of the real world internally in a compact format reduced to the relevant aspects. The mental model can be created and modified automatically by learning from interaction. If the perceived real world does not correspond to the system's mental model, the system detects ambiguities (or conflicts) inevitably. Then, the system tries to solve the conflicts by a more detailed view to the measured sensor inputs. Thus, new significant features (on a high abstraction level) can be derived from the measurements and taken into account to distinguish different (before apparently equal) situations. The contribution describes the proposed method and its fundamentals in detail. Furthermore, the realization of a cognitive mobile robot is presented as an application example illustrating the proposed method.",https://ieeexplore.ieee.org/document/5641727/,"2010 IEEE International Conference on Systems, Man and Cybernetics",10-13 Oct. 2010,ieeexplore
10.1109/IJCNN.1993.716991,Learning goal-directed navigation as attractor dynamics for a sensory motor system. (An experiment by the mobile robot YAMABICO),IEEE,Conferences,"This paper describes experimental results based on the authors' prior-proposed scheme: learning of sensory-based, goal-directed behavior. The scheme was implemented on the mobile robot ""YAMABICO"" and learning of a set of goal-directed navigations were conducted. The experiment assumed that the robot receives no global information such as position nor prior environment model. Instead, the robot was trained to learn adequate maneuvering in the adopted workspace by building a correct mapping between a spatio-temporal sequence of sensory inputs and maneuvering outputs on a neural structure. The experimental results showed that sufficient training generated rigid dynamical structure of a fixed point and limit cycling in the sensory-based state space, which realized robust navigations of homing and cyclic routing even against certain changes of environment as well as miscellaneous noises in the real world.",https://ieeexplore.ieee.org/document/716991/,"Proceedings of 1993 International Conference on Neural Networks (IJCNN-93-Nagoya, Japan)",25-29 Oct. 1993,ieeexplore
10.1109/ROMAN.2010.5598659,Learning grasp stability based on tactile data and HMMs,IEEE,Conferences,"In this paper, the problem of learning grasp stability in robotic object grasping based on tactile measurements is studied. Although grasp stability modeling and estimation has been studied for a long time, there are few robots today able of demonstrating extensive grasping skills. The main contribution of the work presented here is an investigation of probabilistic modeling for inferring grasp stability based on learning from examples. The main objective is classification of a grasp as stable or unstable before applying further actions on it, e.g. lifting. The problem cannot be solved by visual sensing which is typically used to execute an initial robot hand positioning with respect to the object. The output of the classification system can trigger a regrasping step if an unstable grasp is identified. An off-line learning process is implemented and used for reasoning about grasp stability for a three-fingered robotic hand using Hidden Markov models. To evaluate the proposed method, experiments are performed both in simulation and on a real robot system.",https://ieeexplore.ieee.org/document/5598659/,19th International Symposium in Robot and Human Interactive Communication,13-15 Sept. 2010,ieeexplore
10.1109/ROBOT.2004.1307981,Learning human tracking and intercepting skill,IEEE,Conferences,"Robot tracking and intercepting fast-maneuvering object is a classical and important issue. Many research results were published in recent years. Most of them employed model-based methods which require robot's model in advance. However, it is difficult and time-consuming to obtain robot's mathematical model. In this paper, we present a novel approach which needs no mathematical model. The proposed approach is based on learning tracking strategy from human beings. With human's demonstrations, the robot can learn and abstract human tracking and intercepting skill using cascade neural network. Preliminarily simulation results attest the feasibility of this novel approach. Furthermore, experiment is done on a real-time human face tracking system and the results verify the validity and efficiency of the approach.",https://ieeexplore.ieee.org/document/1307981/,"IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004",26 April-1 May 2004,ieeexplore
10.1109/IROS.2010.5651719,Learning interaction protocols using Augmented Baysian Networks applied to guided navigation,IEEE,Conferences,"Research in robot navigation usually concentrates on implementing navigation algorithms that allow the robot to navigate without human aid. In many real world situations, it is desirable that the robot is able to understand natural gestures from its user or partner and use this understanding to guide its navigation. Some algorithms already exist for learning natural gestures and/or their associated actions but most of these systems does not allow the robot to automatically generate the associated controller that allows it to actually navigate in the real environment. Furthermore, a technique is needed to combine the gestures/actions learned from interacting with multiple users or partners. This paper resolves these two issues and provides a complete system that allows the robot to learn interaction protocols and act upon them using only unsupervised learning techniques and enables it to combine the protocols learned from multiple users/partners. The proposed approach is general and can be applied to other interactive tasks as well. This paper also provides a real world experiment involving 18 subjects and 72 sessions that supports the ability of the proposed system to learn the needed gestures and to improve its knowledge of different gestures and their associations to actions over time.",https://ieeexplore.ieee.org/document/5651719/,2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,18-22 Oct. 2010,ieeexplore
10.1109/IJCNN.2008.4634277,Learning of sensorimotor behaviors by a SASE agent for vision-based navigation,IEEE,Conferences,"In this paper, we propose a model to develop robotspsila covert and overt behaviors by using reinforcement and supervised learning jointly. The covert behaviors are handled by a motivational system, which is achieved through reinforcement learning. The overt behaviors are directly selected by imposing supervised signals. Instead of dealing with problems in controlled environments with a low-dimensional state space, our model is applied for the learning in non-stationary environments. Locally balanced incremental hierarchical discriminant regression (LBIHDR) tree is introduce to be the engine of cognitive mapping. Its balanced coarse-to-fine tree structure guarantees real-time retrieval in self-generated high-dimensional state space. Furthermore, K-nearest neighbor strategy is adopted to reduce training time complexity. Vision-based outdoor navigation are used as challenging task examples. In the experiment, the mean square error of heading direction is 0deg for re-substitution test and 1.1269deg for disjoint test, which allows the robot to drive without a big deviation from the correct path we expected. Compared with IHDR (W.S. Hwang and J. Weng, 2007), LBIHDR reduced the mean square error by 0.252deg and 0.5052deg, using re-substitution and disjoint test, respectively.",https://ieeexplore.ieee.org/document/4634277/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/IROS.2014.6943031,Learning robot tactile sensing for object manipulation,IEEE,Conferences,"Tactile sensing is a fundamental component of object manipulation and tool handling skills. With robots entering unstructured environments, tactile feedback also becomes an important ability for robot manipulation. In this work, we explore how a robot can learn to use tactile sensing in object manipulation tasks. We first address the problem of in-hand object localization and adapt three pose estimation algorithms from computer vision. Second, we employ dynamic motor primitives to learn robot movements from human demonstrations and record desired tactile signal trajectories. Then, we add tactile feedback to the control loop and apply relative entropy policy search to learn the parameters of the tactile coupling. Additionally, we show how the learning of tactile feedback can be performed more efficiently by reducing the dimensionality of the tactile information through spectral clustering and principal component analysis. Our approach is implemented on a real robot, which learns to perform a scraping task with a spatula in an altered environment.",https://ieeexplore.ieee.org/document/6943031/,2014 IEEE/RSJ International Conference on Intelligent Robots and Systems,14-18 Sept. 2014,ieeexplore
10.1109/ICRA.2016.7487506,Learning time series models for pedestrian motion prediction,IEEE,Conferences,"Robot systems deployed in real-world environments often need to interact with other dynamic objects, such as pedestrians, cars, bicycles or other vehicles. In such cases, it is useful to have a good predictive model of the object's motion to factor in when optimizing the robot's own behaviour. In this paper we consider motion models cast in the Predictive Linear Gaussian (PLG) model, and propose two learning approaches for this framework: one based on the method of moments and the other on a least-squares criteria. We evaluate the approaches on several synthetic datasets, and deploy the system on a wheelchair robot, to improve its ability to follow a walking companion.",https://ieeexplore.ieee.org/document/7487506/,2016 IEEE International Conference on Robotics and Automation (ICRA),16-21 May 2016,ieeexplore
10.1109/IROS.2018.8594204,Learning to Fly by MySelf: A Self-Supervised CNN-Based Approach for Autonomous Navigation,IEEE,Conferences,"Nowadays, Unmanned Aerial Vehicles (UAVs)are becoming increasingly popular facilitated by their extensive availability. Autonomous navigation methods can act as an enabler for the safe deployment of drones on a wide range of real-world civilian applications. In this work, we introduce a self-supervised CNN-based approach for indoor robot navigation. Our method addresses the problem of real-time obstacle avoidance, by employing a regression CNN that predicts the agent's distance-to-collision in view of the raw visual input of its on-board monocular camera. The proposed CNN is trained on our custom indoor-flight dataset which is collected and annotated with real-distance labels, in a self-supervised manner using external sensors mounted on an UAV. By simultaneously processing the current and previous input frame, the proposed CNN extracts spatio-temporal features that encapsulate both static appearance and motion information to estimate the robot's distance to its closest obstacle towards multiple directions. These predictions are used to modulate the yaw and linear velocity of the UAV, in order to navigate autonomously and avoid collisions. Experimental evaluation demonstrates that the proposed approach learns a navigation policy that achieves high accuracy on real-world indoor flights, outperforming previously proposed methods from the literature.",https://ieeexplore.ieee.org/document/8594204/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ICCVW.2019.00309,Learning to Navigate Robotic Wheelchairs from Demonstration: Is Training in Simulation Viable?,IEEE,Conferences,"Learning from demonstration (LfD) enables robots to learn complex relationships between their state, perception and actions that are hard to express in an optimization framework. While people intuitively know what they would like to do in a given situation, they often have difficulty representing their decision process precisely enough to enable an implementation. Here, we are interested in robots that carry passengers, such as robotic wheelchairs, where user preferences, comfort and the feeling of safety are important for autonomous navigation. Balancing these requirements is not straightforward. While robots can be trained in an LfD framework in which users drive the robot according to their preferences, performing these demonstrations can be time-consuming, expensive, and possibly dangerous. Inspired by recent efforts for generating synthetic data for training autonomous driving systems, we investigate whether it is possible to train a robot based on simulations to reduce the time requirements, cost and potential risk. A key characteristic of our approach is that the input is not images, but the locations of people and obstacles relative to the robot. We argue that this allows us to transfer the classifier from the simulator to the physical world and to previously unseen environments that do not match the appearance of the training set. Experiments with 14 subjects providing physical and simulated demonstrations validate our claim.",https://ieeexplore.ieee.org/document/9022271/,2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW),27-28 Oct. 2019,ieeexplore
10.1109/IROS.1997.655110,Learning to build visual categories from perception-action associations,IEEE,Conferences,"In this paper we describe how a mobile robot can autonomously learn and ""recognize"" simple objects present somewhere in an indoor visual scene. The experiment involves transposing a classical conditioning experiment on a mobile robot. We propose the use of a selective attention mechanism to reduce the amount of computation involved by the complete image analysis. Objects are categorized according to their associated actions that are learned in accordance with a reward/punishment procedure. Our approach emphasizes the importance of a movement reflex mechanism based on the use of the same egocentric representation from the visual information to the motor output. Finally, we highlight the impact of information coding in self organised topological maps on the robot performances.",https://ieeexplore.ieee.org/document/655110/,Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS '97,11-11 Sept. 1997,ieeexplore
10.1109/ICSMC.1993.390770,Learning to coordinate behaviors for real-time path planning of autonomous systems,IEEE,Conferences,"We present a neural network (NN) system which learns the appropriate simultaneous activation of primitive behaviors in order to execute more complex robot behaviors. The NN implementation is part of an architecture for the execution of mobile robot tasks which are composed of several primitive behaviors in a simultaneous or concurrent fashion. We use a supervised learning technique with a human trainer generating appropriate training for the simultaneous activation of behavior in a simulated environment. The NN implementation has been tested within OPMOR, a simulation environment for mobile robots and several results are presented. The performance of the neural network is adequate. Portions of this work has been implemented in the EEC ESPRIT 2483 PANORAMA Project.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/390770/,Proceedings of IEEE Systems Man and Cybernetics Conference - SMC,17-20 Oct. 1993,ieeexplore
10.1109/ROBOT.2009.5152362,Learning to recognize familiar faces in the real world,IEEE,Conferences,"We present an incremental and unsupervised face recognition system and evaluate it offline using data which were automatically collected by Mertz, a robotic platform embedded in real human environment. In an eight-day-long experiment, the robot autonomously detects, tracks, and segments face images during spontaneous interactions with over 500 passersby in public spaces and automatically generates a data set of over 100,000 face images. We describe and evaluate a novel face clustering algorithm using these data (without any manual processing) and also on an existing face recognition database. The face clustering algorithm yields good and robust performance despite the extremely noisy data segmented from the realistic and difficult public environment. In an incremental recognition scheme evaluation, the system is correct 74% of the time when it declares ldquoI don't know this personrdquo and 75.1% of the time when it declares ldquoI know this person, he/she is ...rdquo The latter accuracy improves to 83.8% if the system is allowed some learning curve delay in the beginning.",https://ieeexplore.ieee.org/document/5152362/,2009 IEEE International Conference on Robotics and Automation,12-17 May 2009,ieeexplore
10.1109/ROBIO.2009.5420526,Learning-based action planning for real-time robot telecontrol with binocular vision in enhanced reality environment,IEEE,Conferences,"Action planning is one of the pivot issues in robot telecontrol, in which the action instructions are often given by the controller from remote site with the help of vision systems. In this paper, we present a learning-based strategy for action planning in robot telecontrol, in which the parameters of sophisticated actions of the remote robot equipped with a binocular vision system could be pre-scheduled with a virtual robot at the control terminal. The remote robot will then be 'taught' with the scheduled action plan with a series of parameter sets obtained form try-outs with the virtual robot and object in the enhanced environment, thus implementing dedicated actions assigned correctly. The action planning process is implemented within a enhanced reality environment, in which both the virtual and the real robot will be displayed simultaneously for the purpose of being deeply immersed. Experiment results demonstrate that the proposed method is capable of promoting the action precision of the remote robot, and effective and valid to designated applications, where action precision plays a critical role.",https://ieeexplore.ieee.org/document/5420526/,2009 IEEE International Conference on Robotics and Biomimetics (ROBIO),19-23 Dec. 2009,ieeexplore
10.1109/HRI.2019.8673212,Lifespan Design of Conversational Agent with Growth and Regression Metaphor for the Natural Supervision on Robot Intelligence,IEEE,Conferences,"Human's direct supervision on robot's erroneous behavior is crucial to enhance a robot intelligence for a `flawless' human-robot interaction. Motivating humans to engage more actively for this purpose is however difficult. To alleviate such strain, this research proposes a novel approach, a growth and regression metaphoric interaction design inspired from human's communicative, intellectual, social competence aspect of developmental stages. We implemented the interaction design principle unto a conversational agent combined with a set of synthetic sensors. Within this context, we aim to show that the agent successfully encourages the online labeling activity in response to the faulty behavior of robots as a supervision process. The field study is going to be conducted to evaluate the efficacy of our proposal by measuring the annotation performance of real-time activity events in the wild. We expect to provide a more effective and practical means to supervise robot by real-time data labeling process for long-term usage in the human-robot interaction.",https://ieeexplore.ieee.org/document/8673212/,2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI),11-14 March 2019,ieeexplore
10.1109/HSI49210.2020.9142636,Lightweight Convolutional Neural Network for Real-Time Face Detector on CPU Supporting Interaction of Service Robot,IEEE,Conferences,"Face detection plays an essential role in the success of the interaction between service robots and consumers. This method is the initial stage for face-related applications. Practical applications require face detection to work in real-time and can be implemented on low-cost devices such as CPU. Traditional methods have problems when the face is not frontal, blocked, and partially covered, but real-time speed is not an obstacle. On the other hand, deep learning has succeeded in accurately distinguishing facial features and backgrounds. Face sizes that tend to be medium and large when robot interaction with consumers so it can employ Convolutional Neural Networks (CNN) with light weights. In this paper, a real-time face detector is built that can work on the CPU. This detector will be implemented explicitly in service robots to support interactions with consumers. It can overcome the occlusion and not-frontal face. Detector architecture consists of the backbone as rapidly features extractor, transition module as a transformer of prediction map, and the dual-detection layer is head of a network prediction based on scale assignment. As a result, the detector can work at speeds of 301 frames per second on CPU without ignoring the accuracy.",https://ieeexplore.ieee.org/document/9142636/,2020 13th International Conference on Human System Interaction (HSI),6-8 June 2020,ieeexplore
10.1109/ISCAS.2015.7169038,Live demonstration: Spiking neural circuit based navigation inspired by C. elegans thermotaxis,IEEE,Conferences,"We demonstrate a Spiking Neural Network (SNN) driven autonomous navigation system implemented on a robot. The neural architecture is inspired by those in nematode Caenorhabditis elegans used for thermotaxis, the behavior of tracking thermal isotherms. Our network uses light intensity as the sensor input, instead of temperature in the worm. The network is able to detect the gradations in sensor-input based on local information, and to make decisions in real time. This enables the robot to do a random search and to track specific intensity regions.",https://ieeexplore.ieee.org/document/7169038/,2015 IEEE International Symposium on Circuits and Systems (ISCAS),24-27 May 2015,ieeexplore
10.23919/ChiCC.2018.8483251,Local Gaussian Processes for Identifying Complex Mobile robot System,IEEE,Conferences,"Nonparametric Gaussian processes regression (GPR) is an important tool in machine learning, can be applied in identifying nonlinear models from experimental data, especially, the prediction of mean and variance present the useful advantage. However, when dealing with the large number of training data for the prediction of a complex dynamics system, GPR is not suitable to implement in real-time learning systems. To reduce the computation effort, local learning algorithm is introduced to improve the global Gaussian processes (GP) model in this paper. In this paper, a convenient and effective method for building local model network is proposed and then local GP for weighted regression is performed. The proposed local GPR method is implemented on a simulated example of online identification and prediction fast for a complex dynamic system of wheeled mobile robot.",https://ieeexplore.ieee.org/document/8483251/,2018 37th Chinese Control Conference (CCC),25-27 July 2018,ieeexplore
10.1109/IROS.2004.1389735,Localization for robot mowers covering unmarked operational area,IEEE,Conferences,"The accurate localization is significant for both the accurate terrain acquisition and the successful area covering. Our research aims at the operational area without any manmade marks, the robot utilizes its localization system to establish the digital boundaries of the unmarked operational area. According to the specialties of outdoor environment and the practical mowing requirements, the localization system with combined sensors and the localization algorithm based on neural network are designed. The results of experiment show that the designed neural network can make the accuracy of the localization well improved. With the measurements of the ultrasonic sensors, an effective error-correction method based on the database of environmental features knowledge is proposed for the robot mower to correct its position errors in the real-time coverage operation. The localization information is reliable to ensure the intelligent behaviors of the robot mower. The technical presentations in this paper can facilitate the development of the environmental robotics.",https://ieeexplore.ieee.org/document/1389735/,2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),28 Sept.-2 Oct. 2004,ieeexplore
10.1109/ICRA.2013.6630936,Locally Weighted Learning Model Predictive Control for nonlinear and time varying dynamics,IEEE,Conferences,"This paper proposes an online learning control system that uses the strategy of Model Predictive Control (MPC) in a model based locally weighted learning framework. The new approach, named Locally Weighted Learning Model Predictive Control (LWL-MPC), is proposed as a solution to learn to control robotic systems with nonlinear and time varying dynamics. This paper demonstrates the capability of LWL-MPC to perform online learning while controlling the joint trajectories of a low cost, three degree of freedom elastic joint robot. The learning performance is investigated in both an initial learning phase, and when the system dynamics change due to a heavy object added to the tool point. The experiment on the real elastic joint robot is presented and LWL-MPC is shown to successfully learn to control the system with and without the object. The results highlight the capability of the learning control system to accommodate the lack of mechanical consistency and linearity in a low cost robot arm.",https://ieeexplore.ieee.org/document/6630936/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/IROS40897.2019.8968004,Long Range Neural Navigation Policies for the Real World,IEEE,Conferences,"Learned Neural Network based policies have shown promising results for robot navigation. However, most of these approaches fall short of being used on a real robot due to the extensive simulated training they require. These simulations lack the visuals and dynamics of the real world, which makes it infeasible to deploy on a real robot. We present a novel Neural Net based policy, NavNet, which allows for easy deployment on a real robot. It consists of two sub policies - a high level policy which can understand real images and perform long range planning expressed in high level commands; a low level policy that can translate the long range plan into low level commands on a specific platform in a safe and robust manner. For every new deployment, the high level policy is trained on an easily obtainable scan of the environment modeling its visuals and layout. We detail the design of such an environment and how one can use it for training a final navigation policy. Further, we demonstrate a learned low-level policy. We deploy the model in a large office building and test it extensively, achieving 0.80 success rate over long navigation runs and outperforming SLAM-based models in the same settings.",https://ieeexplore.ieee.org/document/8968004/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/SOCC.2016.7905478,Low-power real-time intelligent SoCs for smart machines,IEEE,Conferences,"In this paper, we introduce low-power and real-time intelligent SoCs aimed at smart machines. To implement intelligent functions under low-power consumption, machine learning methods are tightly integrated with the traditional algorithms. At first, an object recognition processor (ORP) accelerating scale-invariant feature transform (SIFT) is presented with a visual attention based on convolutional neural network (CNN). For user interface (UI), a speech and gesture recognition processor (SGRP) based on convolutional deep belief network (CDBN) is presented with a voice activity detection (VAD) and a hand segmentation. At last, an artificial intelligence processor (AIP) for autonomous navigation is presented using A* tree search for path planning and reinforcement learning (RL) for dynamic obstacle avoidance. As a result, a prototype robot system integrating the presented SoCs is implemented and successfully demonstrated in the indoor environment.",https://ieeexplore.ieee.org/document/7905478/,2016 29th IEEE International System-on-Chip Conference (SOCC),6-9 Sept. 2016,ieeexplore
10.1109/CVPRW.2019.00020,M2U-Net: Effective and Efficient Retinal Vessel Segmentation for Real-World Applications,IEEE,Conferences,"In this paper, we present a novel neural network architecture for retinal vessel segmentation that improves over the state of the art on two benchmark datasets, is the first to run in real time on high resolution images, and its small memory and processing requirements make it deployable in mobile and embedded systems. The M2U-Net has a new encoder-decoder architecture that is inspired by the U-Net. It adds pretrained components of MobileNetV2 in the encoder part and novel contractive bottleneck blocks in the decoder part that, combined with bilinear upsampling, drastically reduce the parameter count to 0.55M compared to 31.03M in the original U-Net. We have evaluated its performance against a wide body of previously published results on three public datasets. On two of them, the M2U-Net achieves new state-of-the-art performance by a considerable margin. When implemented on a GPU, our method is the first to achieve real-time inference speeds on high-resolution fundus images. We also implemented our proposed network on an ARM-based embedded system where it segments images in between 0.6 and 15 sec, depending on the resolution. Thus, the M2U-Net enables a number of applications of retinal vessel structure extraction, such as early diagnosis of eye diseases, retinal biometric authentication systems, and robot assisted microsurgery.",https://ieeexplore.ieee.org/document/9025339/,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),16-17 June 2019,ieeexplore
10.1109/MEMSTECH.2018.8365721,MEMS accelerometer in hexapod intellectual control,IEEE,Conferences,The paper presents the results of three-axis MEMS accelerometer practical Introduction into the hexapod control system to solve the problem of classifying its states in real time. An experiment was conducted in which machine learning various methods possibilities were studied to solve the problem of classifying the current state of a walking robot. The best results for the accuracy parameter were shown by the method Medium KNN.,https://ieeexplore.ieee.org/document/8365721/,2018 XIV-th International Conference on Perspective Technologies and Methods in MEMS Design (MEMSTECH),18-22 April 2018,ieeexplore
10.1109/AIM43001.2020.9158805,MISO Model Free Adaptive Control of Single Joint Rehabilitation Robot Driven by Pneumatic Artificial Muscles,IEEE,Conferences,"Pneumatic artificial muscles (PAMs) are widely used as actuators in the field of rehabilitation robots, but their intrinsic compliance properties make it difficult to control precisely. In this paper, an improved multiple input single output model free adaptive control (MISO-IMFAC) method is proposed for the modeling the uncertainty, high nonlinearity and time-variability of the single joint rehabilitation robot driven by antagonistic PAMs, so as to realize the high-precision control of the joint angle. Considering the influence of the error change of adjacent time on the actual control effect, a new control law is formed by adding a term representing error change to the original control input criterion function. The experiment is carried out on a real rehabilitation robot and four types of errors are used to evaluate the effectiveness of the control system. The results show that the control algorithm can improve the accuracy of angle trajectory tracking at different amplitudes. Compared with original algorithm, the experiment errors of MISO-IMFAC were significantly reduced. In addition, the MISO-IMFAC still maintains stable performance in the process of load variation and external disturbance.",https://ieeexplore.ieee.org/document/9158805/,2020 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM),6-9 July 2020,ieeexplore
10.1109/WACV.2009.5403083,ML-fusion based multi-model human detection and tracking for robust human-robot interfaces,IEEE,Conferences,"A novel stereo vision system for real-time human detection and tracking on a mobile service robot is presented in this paper. The system integrates the individually enhanced stereo-based human detection, HOG-based human detection, color-based tracking, and motion estimation for the robust detection and tracking of humans with large appearance and scale variations in real-world environments. A new framework of maximum likelihood based multi-model fusion is proposed to fuse these four human detection and tracking models according to the detection-track associations in 3D space, which is robust to the possible missed detections, false detections, and duplicated responses from the individual models. Multi-person tracking is implemented in a sequential near-to-far way, which well alleviates the difficulties caused by human-over-human occlusions. Extensive experimental results demonstrate the robustness of the proposed system under real-world scenarios with large variations in lighting conditions, cluttered backgrounds, human clothes and postures, and complex occlusion situations. Significant improvements in human detection and tracking have been achieved. The system has been deployed on six robot butlers to serve drinks, and showed encouraging performance in open ceremony events.",https://ieeexplore.ieee.org/document/5403083/,2009 Workshop on Applications of Computer Vision (WACV),7-8 Dec. 2009,ieeexplore
10.1109/ComPE49325.2020.9200129,Machine Learning Algorithm based Disease Detection in Tomato with Automated Image Telemetry for Vertical Farming,IEEE,Conferences,"This paper is highlighting an outline of disease detection in tomato using computer vision and machine learning algorithms. Readily available hardware is used to build a system where a camera mounted system can detect and identify spot disease in tomatoes in real-time. As an initial prototype only spot disease can be detected. The complete development can be divided into two parts. The first part is the software and algorithm which aimed to detect and identify disease in crops and generate a report for the user. It is successful in building the algorithm and GUI (graphical user interface) for the user which can detect spot disease in tomatoes. Using the Viola-Jones algorithm and Haar like feature extraction method for the machine learning process in MATLAB, an XML (an image trained file) file for spot disease in tomatoes is designed using 377 images of infected tomatoes. The second part is the hardware implementation which consists of a simple robot rig that carries the camera and the system scans the tomatoes for the disease. For the vast majority of the time, spot detection is accurate. Many other diseases which exist for the animal, human and crops can easily be added to the system. In terms of reliability, the system is a success with acceptable false positives.",https://ieeexplore.ieee.org/document/9200129/,2020 International Conference on Computational Performance Evaluation (ComPE),2-4 July 2020,ieeexplore
10.1109/ICRA.2019.8793485,Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks,IEEE,Conferences,"Contact-rich manipulation tasks in unstructured environments often require both haptic and visual feedback. However, it is non-trivial to manually design a robot controller that combines modalities with very different characteristics. While deep reinforcement learning has shown success in learning control policies for high-dimensional inputs, these algorithms are generally intractable to deploy on real robots due to sample complexity. We use self-supervision to learn a compact and multimodal representation of our sensory inputs, which can then be used to improve the sample efficiency of our policy learning. We evaluate our method on a peg insertion task, generalizing over different geometry, configurations, and clearances, while being robust to external perturbations. We present results in simulation and on a real robot.",https://ieeexplore.ieee.org/document/8793485/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/AIKE.2018.00051,Management of Subdivided Dynamic Indoor Environments by Autonomous Scanning System,IEEE,Conferences,"With the development of sensing technologies, various spatial applications have been expanding into indoor spaces. For smooth spatial services, grasping indoor space information is most essential task. However, the indoor spaces is not only becoming increasingly complex, but also frequently changed than outdoor spaces. This makes it hard to provide an accurate location based service in an indoor space. This paper propose a way of managing a dynamic indoor environment by defining a multi-layered indoor model in terms of an object mobility. It allows an indoor space to be managed more elaborate and realistic than up-to-date indoor models which only consider an indoor floor plan. We firstly define a classification of indoor objects based on their characteristic to frequently change location, and propose three-layers indoor model followed by the classified objects with its mobility. Secondly, we design and implement an autonomous scanning system to understand changes of indoor situation quickly and automatically. The system is made up of a combination of IoT devices, including a programmable robot, lidar scanner and single-board computer. Finally, we demonstrate an implementation of the system with constructing the proposed model from a real indoor environment.",https://ieeexplore.ieee.org/document/8527483/,2018 IEEE First International Conference on Artificial Intelligence and Knowledge Engineering (AIKE),26-28 Sept. 2018,ieeexplore
10.1109/MFI-2003.2003.1232635,Map generation based on the interaction between robot body and its surrounding environment,IEEE,Conferences,"This paper presents a method for map generation based on the interaction between a robot body and its surrounding environment. While a robot moves in the environment, the robot interacts with its surrounding environment. If the effect of the environment on the robot changes, such interactions also change. By observing the robot's body, our method detects such change of the interaction and generates a description representing the type of change and the location where such change is observed. In the current implementation, we assume that there are two types of the change in the interaction. The real robot experiments are conducted in order to show the validity of our method.",https://ieeexplore.ieee.org/document/1232635/,"Proceedings of IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems, MFI2003.",1-1 Aug. 2003,ieeexplore
10.1109/IEMBS.2008.4650151,Measurement of reaching movement with 6-DOF upper rehabilitation system “Robotherapist”,IEEE,Conferences,"In recent years, the needs for rehabilitation support systems are increasing, which use robot technology and virtual reality technology. Applying these technologies make efficient rehabilitation possible. We have developed 6-degrees-of-freedom (DOF) upper rehabilitation support system to evaluate synergy pattern of stroke survivors and to train stroke survivors, named “Robotherapist”. When stroke survivors who can move plural joints only along a certain constant pattern called synergy pattern do reaching movement, some of them cannot keep their posture of the arm normal, but can move their hand along the aim orbit. In this study, we experiment on a measurement of reaching movement with our system and make a model of movement peculiar to stroke survivors and a model of movement of healthy people. Additionally, we propose application software for reaching training with this model. In this paper, we report measurement of reaching movement and propose application software for reaching training with our system.",https://ieeexplore.ieee.org/document/4650151/,2008 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society,20-25 Aug. 2008,ieeexplore
10.1109/SSCI.2016.7850169,Memetic robot control evolution and adaption to reality,IEEE,Conferences,"Inspired by animals' ability to learn and adapt to changes in their environment during life, hybrid evolutionary algorithms have been developed and successfully applied in a number of research areas. This paper explores the effects of learning combined with a genetic algorithm to evolve control system parameters for a four-legged robot. Here, learning corresponds to the application of a local search algorithm on individuals during evolution. Two types of learning were implemented and tested, i.e. Baldwinian and Lamarckian learning. On the direct results from evolution in simulation, Lamarckian learning showed promising results, with a significant increase in final fitness compared with the results from evolution without learning. Further experiments with learning on the real robot demonstrated an efficient adaptation of the robot gait to the real world environment, and increased the performance to the level measured in simulation. This paper demonstrates that Lamarckian evolution is effective in improving the performance of robot controller evolution, and that the same learning process on the physical robot efficiently reduces the negative impact of the simulation-reality gap.",https://ieeexplore.ieee.org/document/7850169/,2016 IEEE Symposium Series on Computational Intelligence (SSCI),6-9 Dec. 2016,ieeexplore
10.1109/ICRA40945.2020.9196540,Meta Reinforcement Learning for Sim-to-real Domain Adaptation,IEEE,Conferences,"Modern reinforcement learning methods suffer from low sample efficiency and unsafe exploration, making it infeasible to train robotic policies entirely on real hardware. In this work, we propose to address the problem of sim-to-real domain transfer by using meta learning to train a policy that can adapt to a variety of dynamic conditions, and using a task-specific trajectory generation model to provide an action space that facilitates quick exploration. We evaluate the method by performing domain adaptation in simulation and analyzing the structure of the latent space during adaptation. We then deploy this policy on a KUKA LBR 4+ robot and evaluate its performance on a task of hitting a hockey puck to a target. Our method shows more consistent and stable domain adaptation than the baseline, resulting in better overall performance.",https://ieeexplore.ieee.org/document/9196540/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ICMLC.2010.71,Microcontroller Based Neural Network Controlled Low Cost Autonomous Vehicle,IEEE,Conferences,"In this paper, design of a low cost autonomous vehicle based on neural network for navigation in unknown environments is presented. The vehicle is equipped with four ultrasonic sensors for hurdle distance measurement, a wheel encoder for measuring distance traveled, a compass for heading information, a GPS receiver for goal position information, a GSM modem for changing destination place on run time and a nonvolatile RAM for storing waypoint data; all interfaced to a low cost AT89C52 microcontroller. The microcontroller processes the information acquired from the sensors and generates robot motion commands accordingly through neural network. The neural network running inside the microcontroller is a multilayer feed-forward network with back-propagation training algorithm. The network is trained offline with tangent-sigmoid as activation function for neurons and is implemented in real time with piecewise linear approximation of tangent-sigmoid function. Results have shown that upto twenty neurons can be implemented in hidden layer with this technique. The vehicle is tested with varying destination places in outdoor environments containing stationary as well as moving obstacles and is found to reach the set targets successfully.",https://ieeexplore.ieee.org/document/5460762/,2010 Second International Conference on Machine Learning and Computing,9-11 Feb. 2010,ieeexplore
10.1109/PUNECON.2018.8745403,Military Surveillance Robot Implementation Using Robot Operating System,IEEE,Conferences,"Robots are becoming more and more prevalent in many real world scenarios. Housekeeping, medical aid, human assistance are a few common implementations of robots. Military and Security are also major areas where robotics is being researched and implemented. Robots with the purpose of surveillance in war zones and terrorist scenarios need specific functionalities to perform their tasks with precision and efficiency. In this paper, we present a model of Military Surveillance Robot developed using Robot Operating System. The map generation based on Kinect sensor is presented and some test case scenarios are discussed with results.",https://ieeexplore.ieee.org/document/8745403/,2018 IEEE Punecon,30 Nov.-2 Dec. 2018,ieeexplore
10.1109/AIVR50618.2020.00017,Mirrorlabs - creating accessible Digital Twins of robotic production environment with Mixed Reality,IEEE,Conferences,How to visualize recorded production data in Virtual Reality? How to use state of the art Augmented Reality displays that can show robot data? This paper introduces an opensource ICT framework approach for combining Unity-based Mixed Reality applications with robotic production equipment using ROS Industrial. This publication gives details on the implementation and demonstrates the use as a data analysis tool in the context of scientific exchange within the area of Mixed Reality enabled human-robot co-production.,https://ieeexplore.ieee.org/document/9319071/,2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),14-18 Dec. 2020,ieeexplore
10.23919/CCC50068.2020.9189320,Mobile Robot Path Planning Based on Improved Ant Colony Optimization Algorithm,IEEE,Conferences,"ACO (ant colony algorithm) is a kind of bionic optimization algorithm developed in recent decades, which has shown its excellent performance and great development potential in solving many complex problems. Q-learning, a type of reinforcement learning, has gained increasing popularity in autonomous mobile robot path recently. In order to effectively solve mobile robot path planning problem in obstacle avoidance environment, a path planning model and search algorithm based on improved ant colony optimization algorithm are proposed. The incentive model of reinforcement learning mechanism is introduced with the volatilization of pheromone concentration, establishing dynamic volatile function table.The group intelligent search iterative process of global position selection and local position selection is exploited to combine the volatilization of pheromone concentration with ant colony algorithm, dynamically adjusting the empirical parameter of the reward function by strengthening the data training experiment of Q-learning. To determine the constant parameters for simulation experiment, once the distance between the robot and the obstacle is less than a certain thresholds value, the 0-1 random number is used to randomly adjust the moving direction, avoiding the occurrence of mobile robot path matching deadlock. The study case shows that the proposed algorithm is proved to be better efficient and effective, thereby improving the search intensity and accuracy of the mobile robot path planning problem. And the experimental simulation shows that the proposed model and algorithm effectively solve mobile robot path planning problem that the parameter selection and the actual scene cannot be adapted in real time in traditional path planning problem.",https://ieeexplore.ieee.org/document/9189320/,2020 39th Chinese Control Conference (CCC),27-29 July 2020,ieeexplore
10.1109/SISY.2009.5291131,Mobile robot control using self-learning neural network,IEEE,Conferences,"The paper describes the concept of the navigation system for a mobile robot. The system is using a navigation algorithm based on self-learning neural network, necessary to form a movement plan for a robot. The algorithm is adapted and implemented to navigate real platform of a mobile robot equipped by two independent wheel drives, encoders and a set of short-range sonars. Navigation algorithm is placed into a PC, which is connected to mobile robot by wireless and wired links. Experiments have shown ability of collision-free navigation of mobile robot in real time.",https://ieeexplore.ieee.org/document/5291131/,2009 7th International Symposium on Intelligent Systems and Informatics,25-26 Sept. 2009,ieeexplore
10.1109/ROBOT.1998.681416,Mobile robot exploration and map-building with continuous localization,IEEE,Conferences,"Our research addresses how to integrate exploration and localization for mobile robots. A robot exploring and mapping an unknown environment needs to know its own location, but it may need a map in order to determine that location. In order to solve this problem, we have developed ARIEL, a mobile robot system that combines frontier based exploration with continuous localization. ARIEL explores by navigating to frontiers, regions on the boundary between unexplored space and space that is known to be open. ARIEL finds these regions in the occupancy grid map that it builds as it explores the world. ARIEL localizes by matching its recent perceptions with the information stored in the occupancy grid. We have implemented ARIEL on a real mobile robot and tested ARIEL in a real-world office environment. We present quantitative results that demonstrate that ARIEL can localize accurately while exploring, and thereby build accurate maps of its environment.",https://ieeexplore.ieee.org/document/681416/,Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),20-20 May 1998,ieeexplore
10.1109/ICSAI.2018.8599478,Mobile robot multi-resolution full coverage path planning algorithm,IEEE,Conferences,"The mobile robot can independently run the core as SLAM and path planning [1]. In the grid method drawing, high-precision positioning requires a high-resolution grid. When a mobile robot covers a certain working area, since the coverage width is constant each time, when high-efficiency coverage is required, a low-resolution grid is required for path planning, and a multi-resolution raster problem occurs. For the full coverage path planning problem of multi-resolution mobile robots, this paper proposes the use of high-precision grid positioning, low-resolution raster path planning coverage. In the normal grid traversal process, this paper adopts a mobile robot full coverage path planning algorithm based on bio-excitation network, which can be autonomous exploration traversal. This paper actually models its algorithm, and increases direction guidance and robot into dead zone. When escaping from the dead zone as soon as possible according to greedy thoughts, the algorithm has good real-time performance, can automatically avoid obstacles and escape from the dead zone, and there will be no large-scale folding back. Especially in the field of cleaning, the follow-on mobile robot can effectively clean the narrow area. It can make the cleaning car recycle garbage and has high cleaning efficiency. In the process of high resolution to low resolution, there are both moving obstacles and movable motion grids. This paper uses quadtree segmentation and Hilbert curve to traverse the motion grid to improve coverage and efficiency. The edge of the rule explores the purpose of reciprocating the entire region by reciprocating the unknown environment. In the experiment, it is proved that the algorithm of this paper has higher coverage efficiency by comparing with the original biological excitation network algorithm.",https://ieeexplore.ieee.org/document/8599478/,2018 5th International Conference on Systems and Informatics (ICSAI),10-12 Nov. 2018,ieeexplore
10.1109/ICRoM.2017.8466169,Mobile robot navigation based on Fuzzy Cognitive Map optimized with Grey Wolf Optimization Algorithm used in Augmented Reality,IEEE,Conferences,"This work presents a control technique for Mobile Robot Navigation using augmented reality (AR). This navigation technique is based on optimized Fuzzy Cognitive Map (FCM) and AR's Glyphs. AR's symbols are provided by the overhead camera. The patterns are made up of glyphs and a clear path. Six practical test are manipulated to examine the strength of optimizing FCM by a mobile robot for navigation with AR's symbols. The experiment examined the effectiveness of a Grey Wolf Optimization Algorithm (GWOA) in optimizing the FCM. Two practical experiments confirm that AR's Glyphs are an effective symbol for a robot to navigation in an unknown environment. A practical experiment reveals that a robot can use AR to manage its intended movement. Augmented reality, such as the Glyphs and a simplified map, are an effective tool for mobile robots to use in navigation in unknown environments. A prototype system is made to navigate the mobile robot by using AR and FCM.",https://ieeexplore.ieee.org/document/8466169/,2017 5th RSI International Conference on Robotics and Mechatronics (ICRoM),25-27 Oct. 2017,ieeexplore
10.1109/AMC.2006.1631674,Mobile robot navigation in an unknown environment,IEEE,Conferences,"This paper discusses application of an intelligent system in order to navigate in real-time a small size, four wheeled, indoor mobile robot accurately using ultra-light (160 gr), inexpensive laser range finder without prior information of the environment. A recurrent neural network is used to find the best path to the target of the robot. An accurate grid-based map is generated using a laser range finder scene and location found by a modified dead reckoning system. Finally a motion control method is presented. These approaches are implemented and tested in Resquake mobile robot",https://ieeexplore.ieee.org/document/1631674/,"9th IEEE International Workshop on Advanced Motion Control, 2006.",27-29 March 2006,ieeexplore
10.1109/VRAIS.1995.512486,Model based vision as feedback for virtual reality robotics environments,IEEE,Conferences,"Task definition methods for robotic systems are often difficult to use. The ""on-line"" programming methods are often time expensive or risky for the human operator or the robot itself. On the other hand, ""off-line"" techniques are tedious and complex. In addition operator training is costly and time consuming. In a Virtual Reality Robotics Environment (VRRE), users are not asked to write down complicated functions, but can operate complex robotic systems in an intuitive and cost-effective way. However a VRRE is only effective if all the environment changes and object movements are fed-back to the virtual manipulating system. The paper describes the use of a VRRE for a semi-autonomous robot system comprising an industrial 5-axis robot, its virtual equivalent and a model based vision system used as feed-back. The user is immersed in a 3-D space built out of models of the robot's environment. He directly interacts with the virtual ""components"", defining tasks and dynamically optimizing them. A model based vision system locates objects in the real workspace to update the VRRE through a bi-directional communication link. In order to enhance the capabilities of the VRRE, a reflex-type behavior based on vision has been implemented. By locally (independently of the VRRE) controlling the real robot, the operator is discharged of small environmental changes due to transmission delays. Thus once the tasks have been optimized on the VRRE, they are sent to the real robot and a semi autonomous process ensures their correct execution thanks to a camera directly mounted on the robot's end effector. On the other hand if the environmental changes are too important, the robot stops, re-actualizes the VRRE with the new environmental configuration, and waits for task redesign. Because the operator interacts with the robotic system at a task oriented high level, VRRE systems are easily portable to other robotics environments (mobile robotics and micro assembly).",https://ieeexplore.ieee.org/document/512486/,Proceedings Virtual Reality Annual International Symposium '95,11-15 March 1995,ieeexplore
10.1109/ICARM49381.2020.9195341,Model-Based Reinforcement Learning For Robot Control,IEEE,Conferences,"Model-free deep reinforcement learning (MFRL) algorithms have achieved many impressive results. But they are generally stricken with high sample complexity, which puts forward a critical challenge for their application to real-world robots. Dynamic models are essential for robot control laws, but it is often hard to obtain accurate analytical dynamic models. Therefore a data-driven approach to learning models becomes significant for reinforcement learning to increase data efficiency. Model-based algorithms are effective methods to reduce sample complexity by learning the system dynamic model. However, in certain environments, it has been proven that learning an accurate system dynamic model is a formidable problem, and their asymptotic performance cannot achieve to the same level as model-free algorithms. In our work, we use an ensemble of deep neural networks to learn system dynamics and incorporate model uncertainty. Then in order to merge the high asymptotic performance of the advanced model-free methods, the deep deterministic policy gradient (DDPG) algorithm is adopted to optimize robot control policy. Furthermore, it has been implemented within ROS for controlling a Baxter robot in the simulation environment.",https://ieeexplore.ieee.org/document/9195341/,2020 5th International Conference on Advanced Robotics and Mechatronics (ICARM),18-21 Dec. 2020,ieeexplore
10.1109/ROBOT.1992.220046,Model-driven pose correction,IEEE,Conferences,"Pose determination for robot navigation is discussed. The problem is to maintain the system's instantaneous precept of its position and orientation in space for performing various tasks. The authors describe a system in which models were used to guide the sensory interpretation and to correct expectations. In this system, simulated images were used to analyze the real images and to correct the pose parameters. The reported techniques have been implemented and experiments with real images in a real environment have been performed.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/220046/,Proceedings 1992 IEEE International Conference on Robotics and Automation,12-14 May 1992,ieeexplore
10.1109/ICRAS49812.2020.9135058,Modified Keyframe Selection Algorithm and Map Visualization Based on ORB-SLAM2,IEEE,Conferences,"Recently, Simultaneous Localization and Mapping (SLAM) has becoming an important technology for mobile robot. Real time performance and localization accuracy are two main indicators for SLAM. Traditional SLAM algorithms (i.e. ORB-SLAM2) adopt interframe motion time based method, which depends on keyframes similarity detection to select keyframes. In contrast to the old keyframe selection method that generates excessive keyframes and sparser pointclouds. We propose a novel method called repeated motion detection (RMD) to modify the keyframe selection section. RMD can effectively detect and eliminate the redundant keyframes generated by the camera’s back and forth motion, and thus improve the real-time performance, mapping and localization accuracy of the algorithm. Furthermore, we use this modified algorithm to build the Octomap and 2D occupancy grid map and compare ours with classic SLAM algorithm ORB-SLAM2. The experiment results show that our method achieve better result in both real time performance and localization accuracy.",https://ieeexplore.ieee.org/document/9135058/,2020 4th International Conference on Robotics and Automation Sciences (ICRAS),12-14 June 2020,ieeexplore
10.1109/SECON.2014.6950737,Modified reinforcement learning for sequential action behaviors and its application to robotics,IEEE,Conferences,"When developing a robot or other automaton, the efficacy of the agent is highly dependent on the performance of the behaviors which underpin the control system. Especially in the case of agents which must act in real world or disorganized environments, the design of robust behaviors can be both difficult and time consuming, and often requires the use of sensitive tuning. In response to this need, we present a behavioral, goal-oriented, reinforcement-based machine learning strategy which is flexible, simple to implement, and designed for application in real-world environments, but with the capability of software-based training. In this paper, we will explain our design paradigms, the formal implementation thereof, and the algorithm proper. We will show that the algorithm is able to emulate standard reinforcement learning within comparable training time, and to extend the capabilities thereof as well. We also demonstrate extension of learning beyond the scope of training examples, and present an example of a physical robot which learns a sequential action behavior by experimentation.",https://ieeexplore.ieee.org/document/6950737/,IEEE SOUTHEASTCON 2014,13-16 March 2014,ieeexplore
10.1109/iCMLDE.2018.00023,Monocular SLAM and Obstacle Removal for Indoor Navigation,IEEE,Conferences,"Visual Simultaneous Localization and Mapping (SLAM) is one of the hot topics in computer vision. For the past few years, the AI and deep learning technology research have been widespread used in self-driving technology and surveillance system etc., gaining more and more attention from researchers and public media. The combination of AI technology and robot perception is inevitably going to be a trend. This paper aims at removing the obstacle to enhance the SLAM system performance that based on popular open source framework ORB-SLAM2 in dynamic environment. Moving objects will bring noise in camera pose estimation, besides, when in re-localization, the robot returns to the previous place finding the previous landmark mismatches because of its movement. The system will be confused and misdirected. A novel approach is proposed to remove the obstacle in real environment by using convolutional neural network (CNN) to generate a segmentation mask of obstacle object so as to eliminate the interference by moving object. Our experiment result shows an impressive outcome of practical use and benchmark dataset test.",https://ieeexplore.ieee.org/document/8614006/,2018 International Conference on Machine Learning and Data Engineering (iCMLDE),3-7 Dec. 2018,ieeexplore
10.1109/ICARM.2019.8834284,Motion Control of Non-Holonomic Constrained Mobile Robot Using Deep Reinforcement Learning,IEEE,Conferences,"For the motion control problem of non-holonomic constrained mobile robots, a point stabilization kinematic control law for mobile robot based on deep reinforcement learning is proposed. Firstly, a kinematic model of mobile robot is constructed to build memory for deep reinforcement learning, including the current state of the robot, the control action, the reward and the next state of the robot, which is generated through the connection between mobile robot and environment. Then, value network parameters in the real-time network are updated by a loss function, which is composed of a state-action value in current moment came from the value network of real-time network and a target value, the state-action value of next moment generated by the value network in target network. Next, the parameters of policy network of real-time network are updated according to the state-action value generated by value network of the real-time network in current moment. Finally, the parameters in the real-time network are weighted and averaged with the parameters in the target network, so the parameters of target network are updated to control mobile robot to stabilize with desired point. The simulation and experiment results show that the control algorithm based on deep reinforcement learning could effectively realize the point stabilization control of nonholonomic mobile robots.",https://ieeexplore.ieee.org/document/8834284/,2019 IEEE 4th International Conference on Advanced Robotics and Mechatronics (ICARM),3-5 July 2019,ieeexplore
10.1109/CBS46900.2019.9114416,"Motion Prediction of Virtual Patterns, Human Hand Motions, and a simplified Hand Manipulation Task with Hierarchical Temporal Memory",IEEE,Conferences,"In this paper we utilize Numenta's Hierarchical Temporal Memory implementation NuPIC for online visual motion pattern prediction and test its performance on virtual animations as well as real world human motion data. For evaluation we run a series of progressively more complex experiments testing specific capabilities: Prediction of fixed-time noise-free motion animations, prediction of protocol-directed tasks with real-world camera captured human motion data, and lastly prediction of repetitive tasks performed without a strict protocol. Results show that the presented setup is able to predict time sequenced images as well as highly variable human motions increasingly well over several iterations. Limits are faced for non sequential variable hand motion execution: Here, predictions are made but do not improve in quality over time. The network runs online in real time and can be transferred to different tasks without expert knowledge. These characteristics qualify the setup for human robot interaction scenarios without the need for verified prediction accuracy.",https://ieeexplore.ieee.org/document/9114416/,2019 IEEE International Conference on Cyborg and Bionic Systems (CBS),18-20 Sept. 2019,ieeexplore
10.1109/IROS.2005.1545310,"Motion control of two-link flexible-joint robot with actuator nonlinearities, using backstepping and neural networks",IEEE,Conferences,"We present a state-feedback control of a two-link flexible-joint robot. The control algorithm does not require the mathematical model representing the robot. Three-layer neural networks approximate the unknown plant functions. The neural network weights are adapted on-line. We use backstepping control structure. We use variable structure control to provide robustness to all uncertainties. For simulation, we obtain parameter values of the Euler-Lagrange model from real experiment. We, then, add backlash, deadzone, and additive disturbances to the Euler-Lagrange model to closely replicate the actual robot. We show through simulation that our controller can handle these actuator nonlinearities effectively.",https://ieeexplore.ieee.org/document/1545310/,2005 IEEE/RSJ International Conference on Intelligent Robots and Systems,2-6 Aug. 2005,ieeexplore
10.1109/CIMSA.2009.5069917,Motion planning in unknown environment using an interval fuzzy type-2 and neural network classifier,IEEE,Conferences,"This paper describes environmental recognition and motion control using weightless neural network classifier and interval type-2 fuzzy logic controller. The weightless neural network classifies geometric feature such as U-shape, corridor and left or right corner using ultrasonic sensors. The neural network utilizes previous sensor data and analyzes the situation of the current environment. The behavior of mobile robot is implemented by means of fuzzy control rules. Based on the performance criteria the quality of controller is evaluated to make navigation decisions. This functionality is demonstrated on a mobile robot using modular platform and containing several microcontrollers implies the implementation of a robust architecture. The proposed architecture implemented using low cost range sensor and low cost microprocessor. The experiment results show that the mobile robot can recognize the current environment and was able to successfully avoid obstacle in real time.",https://ieeexplore.ieee.org/document/5069917/,2009 IEEE International Conference on Computational Intelligence for Measurement Systems and Applications,11-13 May 2009,ieeexplore
10.1109/ROMAN.2010.5598692,Motion rendering system for emotion expression of human form robots based on Laban movement analysis,IEEE,Conferences,"A method for adding a target emotion to arbitrary body movements of a human form robot (HFR) is developed. The additional emotion is pleasure, anger, sadness or relaxation. This paper proposes a motion rendering system that modifies arbitrary basic movements of a certain real HFR to add the target emotion at intended strength. The system is developed on the assumption that movements can be emotive by processed on the basis of the correlations between movement features and expressed emotions. The movement features based on Laban movement analysis (LMA) are adopted. An experiment using a real HFR are conducted to test how well our system adds a target emotion to arbitrary movements at intended strength. The results of experiments suggest that our method succeeded in adding a target emotion to arbitrary movements.",https://ieeexplore.ieee.org/document/5598692/,19th International Symposium in Robot and Human Interactive Communication,13-15 Sept. 2010,ieeexplore
10.1109/SSCI.2016.7850240,Multi-Channel Bayesian ART for robot fusion perception,IEEE,Conferences,"Multiple sensor data fusion is the technique of associate information from a number of different sensors to produce a robust and comprehensive description. Data fusion pose is using in various robotics application such as environment mapping, object recognition and robot localization. Their relation is generally hard coded and difficult to learn incrementally if new objects or events arise. In this paper, we propose a new learning architecture termed as Multi-Channel Bayesian ART which is very flexible can be adapted to new domains or different sensor configurations easily. The other advantages of the proposed method are: (1) it is capable of incremental on-line learning without forgetting previously-learned knowledge (2) It can process data real time and does not require any prior training to make it work in natural environment. The effectiveness of our proposed method is validated by real experimental results implemented on robot.",https://ieeexplore.ieee.org/document/7850240/,2016 IEEE Symposium Series on Computational Intelligence (SSCI),6-9 Dec. 2016,ieeexplore
10.1109/ICTAI50040.2020.00088,Multi-Robot Collision Avoidance with Map-based Deep Reinforcement Learning,IEEE,Conferences,"Multi-robot collision avoidance in a communication-free environment is one of the key issues for mobile robotics and autonomous driving. In this paper, we propose a map-based deep reinforcement learning (DRL) approach for collision avoidance of multiple robots, where robots do not communicate with each other and only sense other robots' positions and the obstacles around them. We use the egocentric grid map of a robot to represent the environmental information around it, which can be easily generated by using multiple sensors or sensor fusion. The learned policy generated from the DRL model directly maps 3 frames of egocentric grid maps and the robot's relative local goal positions into low-level robot control commands. We first train a convolutional neural network for the navigation policy in a simulator of multiple mobile robots using proximal policy optimization (PPO). Then we deploy the trained model to real robots to perform collision avoidance in their navigation. We evaluate the approach with various scenarios both in the simulator and on three differential-drive mobile robots in the real world. Both qualitative and quantitative experiments show that our approach is efficient with a high success rate. The demonstration video can be found at https://youtu.be/jcLKlEXuFuk.",https://ieeexplore.ieee.org/document/9288300/,2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI),9-11 Nov. 2020,ieeexplore
10.1109/ICCNC.2019.8685667,Multi-Robot Enhanced Intelligent Multi-User Millimeter-Wave MIMO Systems under Uncertain Environment,IEEE,Conferences,"This paper investigates how to maximize the practical communication quality of multi-user millimeter-wave (mmWave) MIMO systems with uncertain environment through effectively using the mobility from multi-robots as dynamic relays and adopting machine learning techniques. mmWave MIMO has been considered as a promising wireless communication technology due to the high frequency usage efficiency from beamforming. However, the uncertain environment could seriously affect the effectiveness and practicality of beamforming since wireless channels may have a more complicated structure, and the coordination among multiple nodes could be more difficult. For instance, the uncertain distribution of mobile users could significantly affect the performance of wireless channels, and then significantly degrade practical communication quality. Therefore, this paper presents a novel Multi-Robot Enhanced Intelligent Multi-User Millimeter-Wave MIMO (MREI-MU-MIMO) system that adopt both dynamic codebook based beam training protocol and online reinforcement learning to supervise the mobility of multi-robot-relay as well as handle the serious effects form the uncertain environment. Firstly, a novel dynamic codebook development is presented that cannot only lower the complexity of existing beamforming codebooks and also handle the complicated channel structure under uncertainty during multi-user beam training. Then, a decentralized Deep Q-Network (DQN) rein-forcement learning algorithm has been developed to intelligently manage multi-robot mobility and further effectively assign the optimal MIMO to handle the uncertainty from environment. The effectiveness of the proposed design has been demonstrated through real-time simulation and experiment.",https://ieeexplore.ieee.org/document/8685667/,"2019 International Conference on Computing, Networking and Communications (ICNC)",18-21 Feb. 2019,ieeexplore
10.1109/INFOCOM42981.2021.9488669,Multi-Robot Path Planning for Mobile Sensing through Deep Reinforcement Learning,IEEE,Conferences,"Mobile sensing is an effective way to collect environmental data such as air quality, humidity and temperature at low costs. However, mobile robots are typically battery powered and have limited travel distances. To accelerate data collection in large geographical areas, it is beneficial to deploy multiple robots to perform tasks in parallel. In this paper, we investigate the Multi-Robot Informative Path Planning (MIPP) problem, namely, to plan the most informative paths in a target area subject to the budget constraints of multiple robots. We develop two deep reinforcement learning (RL) based cooperative strategies: independent learning through credit assignment and sequential rollout based learning for MIPP. Both strategies are highly scalable with the number of robots. Extensive experiments are conducted to evaluate the performance of the proposed and baseline approaches using real-world WiFi Received Signal Strength (RSS) data. In most cases, the RL based solutions achieve superior or similar performance as a baseline genetic algorithm (GA)-based solution but at only a fraction of running time during inference. Furthermore, when the budgets and initial positions of the robots change, the pre-trained policies can be applied directly.",https://ieeexplore.ieee.org/document/9488669/,IEEE INFOCOM 2021 - IEEE Conference on Computer Communications,10-13 May 2021,ieeexplore
10.1109/HUMANOIDS.2018.8624918,Multi-Sensor Fusion Based Robot Self-Activity Recognition,IEEE,Conferences,"Robots play more and more important roles in our daily life. To better complete assigned tasks, it is necessary for the robots to have the ability to recognize their self-activities in real time. To perceive the environment, robots usually equipped with rich sensors, which can be used to recognize their self-activities. However, the intrinsics of the sensors such as accelerometer, servomotor and gyroscope may have significant differences, individual sensor usually exhibits weak performance in perceiving the environment. Therefore, multi-sensor fusion becomes a promising technique so that to achieve better performance. In this paper, facing the issue of robot self-activity recognition, we propose a framework to fuse information from multiple sensory streams. Our framework takes Recurrent Neural Network(RNN) that uses Long Short-Term Memory(LSTM) units to model temporal information conveyed in multiple sensory streams. In the architecture, a hierarchy structure is used to learn the sensor-specific features, a shared layer is used to fuse the features extracted from multiple sensory streams. We collect a dataset on PKU-HR6.0 robot to evaluate the proposed framework. The experiment results demonstrate the effectiveness of the proposed framework.",https://ieeexplore.ieee.org/document/8624918/,2018 IEEE-RAS 18th International Conference on Humanoid Robots (Humanoids),6-9 Nov. 2018,ieeexplore
10.1109/FUZZ.2002.1005041,Multi-axis fuzzy control and performance analysis for an industrial robot,IEEE,Conferences,"Robot control systems can be considered as complex systems, the design of the controller involving the determination of the dynamic model for the system. Fuzzy logic provides functional capability without the use of a system model or the characteristics associated with capturing the approximate, varying values found in real world systems. Development of a multi-axis fuzzy logic control system was implemented on an industrial robot, replacing the existing control and hardware systems with a new developmental system. During robot control no adaptation of the rule base or membership functions was carried out online; only system gain was modified in relation to link speed and joint error within predetermined design parameters. The fuzzy control system had to manage the effects of frictional and gravitational forces whilst compensating for the varying inertia components when each linkage is moving. Testing based on ISO 9283 for path accuracy and repeatability verified that real time control of three axes was achievable with values of 938 /spl mu/m and 864 /spl mu/m recorded for accuracy and repeatability, respectively.",https://ieeexplore.ieee.org/document/1005041/,2002 IEEE World Congress on Computational Intelligence. 2002 IEEE International Conference on Fuzzy Systems. FUZZ-IEEE'02. Proceedings (Cat. No.02CH37291),12-17 May 2002,ieeexplore
10.1109/IROS.2015.7354094,Multi-robot 6D graph SLAM connecting decoupled local reference filters,IEEE,Conferences,"Teams of mobile robots can be deployed in search and rescue missions to explore previously unknown environments. Methods for joint localization and mapping constitute the basis for (semi-)autonomous cooperative action, in particular when navigating in GPS-denied areas. As communication losses may occur, a decentralized solution is required. With these challenges in mind, we designed a submap-based SLAM system that relies on inertial measurements and stereo-vision to create multi-robot dense 3D maps. For online pose and map estimation, we integrate the results of keyframe-based local reference filters through incremental graph SLAM. To the best of our knowledge, we are the first to combine these two methods to benefit from their particular advantages for 6D multi-robot localization and mapping: Local reference filters on each robot provide real-time, long-term stable state estimates that are required for stabilization, control and fast obstacle avoidance, whereas online graph optimization provides global multi-robot pose and map estimates needed for cooperative planning. We propose a novel graph topology for a decoupled integration of local filter estimates from multiple robots into a SLAM graph according to the filters' uncertainty estimates and independence assumptions and evaluated its benefits on two different robots in indoor, outdoor and mixed scenarios. Further, we performed two extended experiments in a multi-robot setup to evaluate the full SLAM system, including visual robot detections and submap matches as inter-robot loop closure constraints.",https://ieeexplore.ieee.org/document/7354094/,2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),28 Sept.-2 Oct. 2015,ieeexplore
10.1109/FUZZY.1997.616431,Multilayered fuzzy behavior fusion for reactive control of an autonomous mobile robot,IEEE,Conferences,"Fuzzy linguistic rules provide an intuitive and powerful means for defining control behavior. Most applications that use fuzzy control feature a single layer of fuzzy inference, mapping a function from one or two inputs to equally few outputs. Highly complex systems, however, may benefit from qualitative rules as well if the control task is properly partitioned. This paper presents a modular fuzzy control architecture and inference engine. A control function is broken down into multiple agents, each of which samples a subset of a large sensor input space. Additional fuzzy agents are employed to fuse the recommendations of the local agents. Real-time implementation without special hardware is possible by using singleton output values during fuzzy rule evaluation. Using this system, a fuzzy behavior-based reactive control system has been implemented on an autonomous mobile robot MARGE, with great success.",https://ieeexplore.ieee.org/document/616431/,Proceedings of 6th International Fuzzy Systems Conference,5-5 July 1997,ieeexplore
10.1109/ISKE.2010.5680764,Multilevel fuzzy navigation control scheme applied to a monitoring mobile robot,IEEE,Conferences,"The design, construction and real time performance of a mobile monitoring system based on a Khepera mobile robot are presented. The functions performed by the system are: (a) line following, (b) obstacle avoidance, (c) identification of test points along the path, (d) recognition of the mark (bar code) located at each test point and, (e) measuring of a physical parameter. For the navigation, an innovative multilevel fuzzy control scheme is implemented in which the fuzzy sensor fusion, related to the perception of the environment, reduces the complexity of the navigation function. Other distinctive characteristics are the identification of test points by means of a Kohonen's neural network and the processing of a one-dimensional video signal for recognition of landmarks located at each test point.",https://ieeexplore.ieee.org/document/5680764/,2010 IEEE International Conference on Intelligent Systems and Knowledge Engineering,15-16 Nov. 2010,ieeexplore
10.1109/ROMAN.1995.531939,Multimedia sensing system for robot,IEEE,Conferences,"The purpose of this study is to realize a multimedia sensing system for robot. Using both image and sound processing, the system makes a robot track the person who is speaking. The sound direction is calculated from the phase difference between the sounds arriving at the right and left microphones (ears) of the robot. Then by detecting the synchronization between the sound and image changes, the system identifies the speaker. Furthermore, by introducing a multi-level synchronization checking and context analysis, the action pattern of the robot can be regulated to make the robot perform in a complicated environment with plural speakers. All the processes are performed in real-time. The proposed system is implemented in the information assistant robot ""Hadaly"".",https://ieeexplore.ieee.org/document/531939/,Proceedings 4th IEEE International Workshop on Robot and Human Communication,5-7 July 1995,ieeexplore
10.1109/ICRA48506.2021.9561586,Multimodal Anomaly Detection based on Deep Auto-Encoder for Object Slip Perception of Mobile Manipulation Robots,IEEE,Conferences,"Object slip perception is essential for mobile manipulation robots to perform manipulation tasks reliably in the dynamic real-world. Traditional approaches to robot arms’ slip perception use tactile or vision sensors. However, mobile robots still have to deal with noise in their sensor signals caused by the robot’s movement in a changing environment. To solve this problem, we present an anomaly detection method that utilizes multisensory data based on a deep autoencoder model. The proposed framework integrates heterogeneous data streams collected from various robot sensors, including RGB and depth cameras, a microphone, and a force-torque sensor. The integrated data is used to train a deep autoencoder to construct latent representations of the multisensory data that indicate the normal status. Anomalies can then be identified by error scores measured by the difference between the trained encoder’s latent values and the latent values of reconstructed input data. In order to evaluate the proposed framework, we conducted an experiment that mimics an object slip by a mobile service robot operating in a real-world environment with diverse household objects and different moving patterns. The experimental results verified that the proposed framework reliably detects anomalies in object slip situations despite various object types and robot behaviors, and visual and auditory noise in the environment.",https://ieeexplore.ieee.org/document/9561586/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/MILTECHS.2017.7988861,Multiple people detection and identification system integrated with a dynamic simultaneous localization and mapping system for an autonomous mobile robotic platform,IEEE,Conferences,"This paper presents the integration of a multiple people detection and identification system with a dynamic simultaneous localization and mapping system for an autonomous robotic platform. This integration allows the exploration and navigation of the robot considering people identification. The robotic platform consists of a Pioneer 3DX robot equipped with an RGBD camera, a Sick Lms200 sensor laser and a computer using the robot operating system (ROS). The idea is to integrate the people detection and identification system to the simultaneous localization and mapping (SLAM) system of the robot using ROS. The people detection and identification system is performed in two steps. The first one is for detecting multiple people on scene and the other one is for an individual person identification. Both steps are implemented as ROS nodes that works integrated with the SLAM ROS node. The multiple people detection's node uses a manual feature extraction technique based on HOG (Histogram of Oriented Gradients) detectors, implemented using the PCL library (Point Cloud Library) in C ++. The person's identification node is based on a Deep Convolutional Neural Network (CNN) that are implemented using the MatLab MatConvNet library. This step receives the detected people centroid from the previous step and performs the classification of a specific person. After that, the desired person centroid is send to the SLAM node, that consider it during the mapping process. Tests were made objecting the evaluation of accurateness in the people's detection and identification process. It allowed us to evaluate the people detection system during the navigation and exploration of the robot, considering the real time interaction of people recognition in a semi-structured environment.",https://ieeexplore.ieee.org/document/7988861/,2017 International Conference on Military Technologies (ICMT),31 May-2 June 2017,ieeexplore
10.1109/ROBOT.2010.5509154,Multiple relative pose graphs for robust cooperative mapping,IEEE,Conferences,"This paper describes a new algorithm for cooperative and persistent simultaneous localization and mapping (SLAM) using multiple robots. Recent pose graph representations have proven very successful for single robot mapping and localization. Among these methods, incremental smoothing and mapping (iSAM) gives an exact incremental solution to the SLAM problem by solving a full nonlinear optimization problem in real-time. In this paper, we present a novel extension to iSAM to facilitate online multi-robot mapping based on multiple pose graphs. Our main contribution is a relative formulation of the relationship between multiple pose graphs that avoids the initialization problem and leads to an efficient solution when compared to a completely global formulation. The relative pose graphs are optimized together to provide a globally consistent multi-robot solution. Efficient access to covariances at any time for relative parameters is provided through iSAM, facilitating data association and loop closing. The performance of the technique is illustrated on various data sets including a publicly available multi-robot data set. Further evaluation is performed in a collaborative helicopter and ground robot experiment.",https://ieeexplore.ieee.org/document/5509154/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/CEC.2007.4424774,Multiple sensors data integration using MFAM for mobile robot navigation,IEEE,Conferences,"The mobile robot navigation with complex environment needs more input space to match the environmental data into robot outputs in order to perform realistic task. At the same time, the number of rules at the rule base needs to be optimized to reduce the computing time and to provide the possibilities for real time operation. In this paper, the optimization of fuzzy rules using a modified fuzzy associative memory (MFAM) is designed and implemented. MFAM provides good flexibility to use multiple input space and reduction of rule base for robot navigation. This paper presents the MFAM model to generate the rule base for robot navigation. The behavior rules obtained from MFAM model are tested using simulation and real world experiments, and the results are discussed in the paper and compared with the existing methods.",https://ieeexplore.ieee.org/document/4424774/,2007 IEEE Congress on Evolutionary Computation,25-28 Sept. 2007,ieeexplore
10.1109/IROS45743.2020.9341372,Multiplicative Controller Fusion: Leveraging Algorithmic Priors for Sample-efficient Reinforcement Learning and Safe Sim-To-Real Transfer,IEEE,Conferences,"Learning-based approaches often outperform hand-coded algorithmic solutions for many problems in robotics. However, learning long-horizon tasks on real robot hardware can be intractable, and transferring a learned policy from simulation to reality is still extremely challenging. We present a novel approach to model-free reinforcement learning that can leverage existing sub-optimal solutions as an algorithmic prior during training and deployment. During training, our gated fusion approach enables the prior to guide the initial stages of exploration, increasing sample-efficiency and enabling learning from sparse long-horizon reward signals. Importantly, the policy can learn to improve beyond the performance of the sub-optimal prior since the prior's influence is annealed gradually. During deployment, the policy's uncertainty provides a reliable strategy for transferring a simulation-trained policy to the real world by falling back to the prior controller in uncertain states. We show the efficacy of our Multiplicative Controller Fusion approach on the task of robot navigation and demonstrate safe transfer from simulation to the real world without any fine-tuning. The code for this project is made publicly available at https://sites.google.com/view/mcf-nav/home.",https://ieeexplore.ieee.org/document/9341372/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/IROS.2018.8593899,Multisensor Online Transfer Learning for 3D LiDAR-Based Human Detection with a Mobile Robot,IEEE,Conferences,"Human detection and tracking is an essential task for service robots, where the combined use of multiple sensors has potential advantages that are yet to be fully exploited. In this paper, we introduce a framework allowing a robot to learn a new 3D LiDAR-based human classifier from other sensors over time, taking advantage of a multisensor tracking system. The main innovation is the use of different detectors for existing sensors (i.e. RGB-D camera, 2D LiDAR) to train, online, a new 3D LiDAR-based human classifier based on a new “trajectory probability”. Our framework uses this probability to check whether new detection belongs to a human trajectory, estimated by different sensors and/or detectors, and to learn a human classifier in a semi-supervised fashion. The framework has been implemented and tested on a real-world dataset collected by a mobile robot. We present experiments illustrating that our system is able to effectively learn from different sensors and from the environment, and that the performance of the 3D LiDAR-based human classification improves with the number of sensors/detectors used.",https://ieeexplore.ieee.org/document/8593899/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ICMLC.2016.7872960,Muscle-gesture robot hand control based on sEMG signals with wavelet transform features and neural network classifier,IEEE,Conferences,"In this paper, we propose a muscle gesture-computer interface (MGCI) system for a five-fingered robotic hand control employing a commercial wearable MYO gesture armband. Eight channels of surface EMG (sEMG) signals were acquired and segmented. Then four levels of Daubechies 5 Wavelet family were performed to analyze the EMG signal. Totally 72 features were extracted from the EMG raw data for 16 hand motions recognition utilizing artificial Neural Networks. The average of best overall classification rate during off-line training is 87.8%. Consequently, real-time hand gesture recognition was implemented to evaluate the performance of the proposed system and the average recognition accuracy was 89.38%. Finally, it was applied to control a five-fingered robot hand.",https://ieeexplore.ieee.org/document/7872960/,2016 International Conference on Machine Learning and Cybernetics (ICMLC),10-13 July 2016,ieeexplore
10.1109/IECON.2000.972604,NN controller of the constrained robot under unknown constraint,IEEE,Conferences,"In this paper, the problems faced in the constrained force control is studied (uncertainties in dynamic model and the unknown constraints). A neural network (NN) controller is proposed based on the derived dynamic model of robot in the task space. The feed-forward neural network is used to adaptively compensate for the uncertainties in the robot dynamics. Training signals are proposed for the feed-forward neural network controller. The NN weights are tuned online, with no off-line learning phase required. An online estimation algorithm is developed to estimate the local shape of the constraint surface by using measured data on the force and position of the end-effector. The suggested controller is simple in structure and can be implemented easily. Real-time experiments are conducted using the five-bar robot to demonstrate the effectiveness of the proposed controller.",https://ieeexplore.ieee.org/document/972604/,"2000 26th Annual Conference of the IEEE Industrial Electronics Society. IECON 2000. 2000 IEEE International Conference on Industrial Electronics, Control and Instrumentation. 21st Century Technologies",22-28 Oct. 2000,ieeexplore
10.1109/ICMA52036.2021.9512587,Natural Residual Reinforcement Learning for Bicycle Robot Control,IEEE,Conferences,"This work focuses on motion control of the bicycle robot by using the proposed NRRL algorithm. Unlike the traditional RL algorithm, decomposing the main tasks into subtasks manually and introducing qualitative prior knowledge to the agent have been applied in the NRRL algorithm. Simulation results show that better performance and better sample efficiency of the proposed NRRL algorithm have been achieved in terms of balance control and path tracking of bicycle robot. It's believed that the NRRL algorithm is available on the real physical bicycle robot, and the deployment of the algorithm will be realized soon, as the real physical bicycle robot has been constructed currently.",https://ieeexplore.ieee.org/document/9512587/,2021 IEEE International Conference on Mechatronics and Automation (ICMA),8-11 Aug. 2021,ieeexplore
10.1109/ICNSC.2009.4919323,Navigation and path search for roving robot using reinforcement learning,IEEE,Conferences,"The robot technology is rapidly developing in recent years. In connection with this technology, a robot activity is expected in various places or various environments. Therefore, this study describes 1) how the location of the destination of the robot in real world is measured based on the image obtained by one camera and 2) how the robot is navigated to the destination where a user points out on the display, on which the forward scene is imaged. The cases where there are some obstacles on the way to the destination are considered. The roving robot tries to find the shortest way to the destination based on the information on the locations of the obstacles and the destination by using the reinforcement learning, which is a hopeful candidate in the autonomous control technique. In addition, the measurement method for the indicated location based on the image is described, the simulation result for the path search by using the reinforcement leaning is shown, and the experiment result of navigation in real field is shown. Finally, the main conclusions are summarized.",https://ieeexplore.ieee.org/document/4919323/,"2009 International Conference on Networking, Sensing and Control",26-29 March 2009,ieeexplore
10.1109/ITNG.2011.116,Nerve: A Lightweight Middleware for Quality-of-service Networked Robotics,IEEE,Conferences,"Social robots must adapt to dynamic environments, human interaction partners and challenging new stringent tasks. Their inner software should be designed and deployed carefully because slight changes in the robot's requirements can have an important impact in the existing code. This paper focus on the design and implementation of a lightweight middleware for networked robotics called \textit{Nerve}, which guarantees the scalability and quality-of-service requirements for this kind of real-time software. Its benefits have been proved through its use in a Robot Learning by Imitation control architecture, but its design guidelines are general enough to be also applied with common distributed and real-time embedded applications.",https://ieeexplore.ieee.org/document/5945314/,2011 Eighth International Conference on Information Technology: New Generations,11-13 April 2011,ieeexplore
10.1109/ICEE.2018.8472657,Neural Control of Mobile Robot Motion Based on Feedback Error Learning and Mimetic Structure,IEEE,Conferences,"Mobile robots motion control is a basic problem in robotics and there are still some control difficulties such as uncertainty in a real implementation which should be considered. This paper is concerned with the neural control of wheeled mobile robots trajectory tracking and posture stabilization. In the trajectory-tracking problem, the Feedback Error Learning (FEL) structure is used and for the posture stabilization problem, the Mimetic structure is employed. These neural based structures use a classic controller, Dynamic Feedback Linearization (DFL), and help to improve the adaptiveness of it. The effectiveness of the proposed controllers is verified by simulation in Webots robotic simulator and on the e-puck which is a differential wheeled mobile robot. The simulation results verify the ability of the proposed methods for controlling the robot and handling uncertainties.",https://ieeexplore.ieee.org/document/8472657/,"Electrical Engineering (ICEE), Iranian Conference on",8-10 May 2018,ieeexplore
10.1109/CIMCA.2008.133,Neural Dynamic Control of a Nonholonomic Mobile Robot Incorporating the Actuator Dynamics,IEEE,Conferences,"In this paper, a trajectory tracking control for a nonholonomic mobile robot by the integration of a kinematic controller and neural dynamic controller is investigated, where the wheel actuator (e.g., dc motor) dynamics is integrated with mobile robot dynamics and kinematics so that the actuator input voltages are the control inputs. The proposed neural dynamic controller (PNDC), based on the sliding mode theory, is applied to compensate the mobile robot dynamics, bounded unknown disturbances, and influence of payload. This controller is obtained by modeling the Radial Basis Functions Neural Networks (RBFNNs) of the centripetal and Coriolis matrix through of the inertia matrix of the mobile robot dynamics. Thus, PNDC is constituted of static RBFNNs only, what makes possible the reduction of the size of the RBFNNs, of the computational load and the implementation in real time. Stability analysis and numerical simulations are provided to show the effectiveness of the PNDC.",https://ieeexplore.ieee.org/document/5172687/,2008 International Conference on Computational Intelligence for Modelling Control & Automation,10-12 Dec. 2008,ieeexplore
10.1109/AIM.2009.5229901,Neural Q-Learning controller for mobile robot,IEEE,Conferences,"In recent years, increasing trend in application of autonomous mobile robot worldwide has highlighted the importance of path planning controller in robotics-related fields, especially where dynamic and unknown environment is involved. Writing a good robot controller program can be a very time consuming process. It is inevitably wasting of resources and efforts if we have to rewrite the controller over and over again whenever there is emergence of changes in the environment. Reinforcement Learning (RL) algorithms and Artificial Neural Network (ANN) are used to assist autonomous mobile robot to learn in an unrecognized environment. This research study is focused on exploring integration of multi-layer neural network and Q-Learning as an online learning controller. Learning process is divided into two stages. In the initial stage the agent will map the environment through collecting state-action information according to the Q-Learning procedure. Second training process involves neural network training which will utilize the state-action information gathered in earlier phase as training samples. During final application of the controller, Q-Learning would be used as the primary navigating tool whereas the trained neural network will be employed when approximation is needed. MATLAB simulation was developed to verify the validity of the algorithm before it is real-time implemented on the real world using Team AmigoBottrade robot. The results obtained from both simulation and actual application confirmed on-spot learning ability of the controller accompanied with certain degree of flexibility and robustness.",https://ieeexplore.ieee.org/document/5229901/,2009 IEEE/ASME International Conference on Advanced Intelligent Mechatronics,14-17 July 2009,ieeexplore
10.1109/IROS.1991.174585,Neural network approach to path planning for two dimensional robot motion,IEEE,Conferences,"A method for robot obstacle avoidance and path planning is proposed. The algorithm is based on a camera image feedback loop utilizing a neural network for image processing. The method can successfully generate collision-free paths in a 2D robot workspace containing randomly-placed polygonal obstacles. The control algorithm is simple and robust and has low computational requirements. Controller simulation implemented on a personal computer can generate collision-free robot paths in real time, requiring approximately 1 sec. per robot move.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174585/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/ICIT.2004.1490796,Neural network based control of a four rotor helicopter,IEEE,Conferences,"In this paper the design and development of an intelligent controller based on neural networks for a hoverable flying robot to be capable of achieving vertical take off and landing and to be able to sustain a specified attitude is presented. The ability to be able to autonomously navigate through a predefined path was designated for a future phase. This work is different from most autonomous flying robots as it focuses on a four-propeller configuration. This is a very rare helicopter design because of its inherent instability and it is believed that an autonomous robot of this configuration has not yet been successfully developed. In addition, this project uses fixed pitch propellers instead of variable pitch rotors resulting in a greatly reduced cost and mechanical complexity. The downside is that this introduces significant additional challenges in the control. Relative stability was achieved in three axis and all the supporting modules were successfully designed and implemented. However, significant challenges were encountered including the complexities of creating a neural networks controller (NNC) to work in real-time in a slow microcontroller as well as to develop the training process.",https://ieeexplore.ieee.org/document/1490796/,"2004 IEEE International Conference on Industrial Technology, 2004. IEEE ICIT '04.",8-10 Dec. 2004,ieeexplore
10.1109/ROBOT.1995.525344,Neural network based iterative learning controller for robot manipulators,IEEE,Conferences,"An efficient neural network based learning control scheme is proposed to solve the trajectory tracking controI problem of robot manipulators. The proposed approach has four distinctive characteristics: 1) good tracking performance can be achieved during the first learning trial; 2) learning algorithm for adjusting neural network weights is independent of the manipulator dynamic model, thus displays strong robustness to torque disturbances and model parameter uncertainty; 3) no acceleration measurement or estimation is needed; and 4) real-time implementation with a higher sampling rate is readily possible. Simulation results on a 3 degree-of-freedom manipulator are presented to show its validity.",https://ieeexplore.ieee.org/document/525344/,Proceedings of 1995 IEEE International Conference on Robotics and Automation,21-27 May 1995,ieeexplore
10.1109/COASE.2008.4626446,Neural network based path planning for a multi-robot system with moving obstacles,IEEE,Conferences,"Recently, a coordinated hybrid agent (CHA) framework was proposed for the control of multi-agent systems (MASs). In the past few years, it has been applied to both homogeneous and heterogeneous multi-agent systems. In previous studies, the coordination among agents were implemented based on the designerpsilas knowledge of the system. For large complex systems, it would be desirable if we can plan the coordination among agents dynamically. It was demonstrated that an intelligent planner can be designed for the CHA framework to automatically generate desired actions for multiple robots in a multi-agent system. However, in previous studies, only static obstacles in the environment were considered. In this paper, a neural network based approach is proposed for a multi-robot system with moving obstacles. A biologically inspired neural network based intelligent planner is designed for the coordination of multi-agent systems. The dynamics of each neuron in the topologically organized neural network is characterized by a shunting neural equation. A landscape of the neural activities for all neurons of a CHA agent contains information about the agentpsilas local goal, and moving obstacles. The objective for building the intelligent planner is to plan actions for multiple mobile robots to coordinate with others and to achieve the global goal. The proposed approach is able to plan the paths for multiple robots while avoiding moving obstacles. The proposed approach is simulated using both Matlab and Vortex. The virtual physical world is built using Vortex to test and develop navigation strategies for robot platforms. The Vortex module executes control commands from the control system module, and provides the outputs describing the vehicle state and terrain information, which are in turn used in the control module to produce the control commands. Simulation results show that an intelligent planner can be designed for the CHA framework to control a large complex system so that coordination among agents can be achieved.",https://ieeexplore.ieee.org/document/4626446/,2008 IEEE International Conference on Automation Science and Engineering,23-26 Aug. 2008,ieeexplore
10.1109/ISESD.2016.7886710,Neural network implementation for invers kinematic model of arm drawing robot,IEEE,Conferences,"Nowadays, the research in robotics field is growing. One of the studies in robotics is the control method of the robotic arm movement. In this research, a 3 DOF arm drawing robot was built. An inverse kinematic models of the robot arm is made using artificial neural network method. Artificial neural network model was implemented in a GUI application. The ANN model can work in real-time to control arm robot movement to reach certain coordinates. Based on test results, the inverse kinematic models of the arm drawing robot had an error rate under 2%. It is of 0.16% for X coordinate and 0.46% for Y coordinate.",https://ieeexplore.ieee.org/document/7886710/,2016 International Symposium on Electronics and Smart Devices (ISESD),29-30 Nov. 2016,ieeexplore
10.1109/IJCNN.1991.170673,Neural network servo control of a robot manipulator joint in real-time,IEEE,Conferences,"Empirical results are presented for a real-time experiment where a feedforward neural network is used to replace an existing proportional-derivative (P-D) servo controller and trained online in real-time using a performance measure to control positioning of a robot manipulator joint. The optimized neural network controller was tested online as both a fixed and adaptive controller, with step and ramp input commands, under different joint loading conditions. The results are compared to the existing P-D controller.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/170673/,[Proceedings] 1991 IEEE International Joint Conference on Neural Networks,18-21 Nov. 1991,ieeexplore
10.1109/IJCNN.2001.938487,Neuro-controller for high performance induction motor drives in robots,IEEE,Conferences,"Presents an approach to the speed control of an induction motor (IM) as a robust high performance drive (HPD) using an online self-tuning adapted artificial neural network (ANN). Based on motor dynamics and nonlinear unknown load characteristics such as robot systems, a neuro speed controller is developed. The proposed controller is very simple and serves as an identifier and a controller at the same time. The combination of the adaptive learning rate with the epochs used through the online training offers a unique feature of system identification and adaptive control. The performance of the controller was evaluated under various operating conditions to track different speed trajectories. The results validate the efficacy of the ANN for the precise tracking control of IM. Furthermore the use of the ANN makes the drive system robust, accurate, and insensitive to parameter variations. Also the drive system is implemented in real-time using a digital signal processor (DSP) TMS320C31.",https://ieeexplore.ieee.org/document/938487/,IJCNN'01. International Joint Conference on Neural Networks. Proceedings (Cat. No.01CH37222),15-19 July 2001,ieeexplore
10.1109/IJCNN.1998.687181,Neuro-fuzzy posture estimation for visual vehicle guidance,IEEE,Conferences,"This paper presents a neuro-fuzzy approach to visual guidance of a mobile robot vehicle in local manoeuvres. It is based on the transfer of the skills of an experienced driver to an automatic controller. The resulting controller processes video sensor data to generate corresponding steering and velocity commands in real time. Neither a geometric environment model nor analytic models of the video sensor or the vehicle kinematics are required. In contrast to previous work of the authors, the controller commands are generated by a two-stage processing structure. A first stage estimates the vehicle posture relative to the desired goal based on the video images. A guidance controller uses the estimated posture to calculate appropriate commands in a second stage. The approach is exemplified and validated by the design and implementation of a visual parking controller for the experimental robot vehicle MACROBE.",https://ieeexplore.ieee.org/document/687181/,1998 IEEE International Joint Conference on Neural Networks Proceedings. IEEE World Congress on Computational Intelligence (Cat. No.98CH36227),4-9 May 1998,ieeexplore
10.1109/CCMB.2014.7020689,Neuromodulation based control of autonomous robots in ROS environment,IEEE,Conferences,"The paper presents a control approach based on vertebrate neuromodulation and its implementation on autonomous robots in the open-source, open-access environment of robot operating system (ROS) within a cloud computing framework. A spiking neural network (SNN) is used to model the neuromodulatory function for generating context based behavioral responses of the robots to sensory input signals. The neural network incorporates three types of neurons- cholinergic and noradrenergic (ACh/NE) neurons for attention focusing and action selection, dopaminergic (DA) neurons for rewards- and curiosity-seeking, and serotonergic (5-HT) neurons for risk aversion behaviors. The model depicts description of neuron activity that is biologically realistic but computationally efficient to allow for large-scale simulation of thousands of neurons. The model is implemented using graphics processing units (GPUs) for parallel computing in real-time using the ROS environment. The model is implemented to study the risk-taking, risk-aversive, and distracted behaviors of the neuromodulated robots in single- and multi-robot configurations. The entire process is implemented in a distributed computing framework using ROS where the robots communicate wirelessly with the computing nodes through the on-board laptops. Results are presented for both single- and multi-robot configurations demonstrating interesting behaviors.",https://ieeexplore.ieee.org/document/7020689/,"2014 IEEE Symposium on Computational Intelligence, Cognitive Algorithms, Mind, and Brain (CCMB)",9-12 Dec. 2014,ieeexplore
10.1109/IROS.2003.1250614,Non-learning artificial neural network approach to motion planning for the Pioneer robot,IEEE,Conferences,This paper describes the implementation of a biologically-inspired non-learning artificial neural network for robot motion planning on the Pioneer 2DX robot. This motion planner fits within the Saphira operating system. The deliberative ANN motion planner is able to respond to changing situations in real time and complements the reactive behaviours.,https://ieeexplore.ieee.org/document/1250614/,Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453),27-31 Oct. 2003,ieeexplore
10.1109/IECON.2005.1568899,Nonlinear motor control using dual feedback controller,IEEE,Conferences,"This paper is concerned with the control of multiple nonlinearities included in a humanoid robot system. A humanoid robot has some problems of the structural instability basically, which leads to consider the control of multiple nonlinearities caused by driver parts as well as gear reducer. Saturation and backlash are typical examples of nonlinearities in the system. The conventional algorithms of backlash control are based on fuzzy algorithm, disturbance observer and neural network, etc. However, it is not easy to control the system that is employed by only single algorithm because the system includes multiple nonlinearities. In this paper, a switching PID is considered for a control of saturation, and a dual feedback algorithm is proposed for a backlash control. To implement the above algorithms, the system identification is firstly performed for the minimization of the difference between simulation and experiment. After that, the switching PID gains are determined using genetic algorithm for removing limit cycle by saturation. The control algorithm is applied by dual feedback concept based on disturbance observer. All the processes are investigated through simulations and are verified experimentally in a real humanoid system.",https://ieeexplore.ieee.org/document/1568899/,"31st Annual Conference of IEEE Industrial Electronics Society, 2005. IECON 2005.",6-10 Nov. 2005,ieeexplore
10.1109/IJCNN.1999.832713,Nonlinear system adaptive trajectory tracking by dynamic neural control,IEEE,Conferences,"In this article, new nonlinear control techniques based on dynamic neural networks are presented. The authors discuss the implementation of a modified identification algorithm using dynamic neural networks as well as a control law, based on the neural identifier, which eliminates modeling error effects via sliding mode techniques. Simulation and real time results are presented for systems like an inverted pendulum and a full actuated robot manipulator.",https://ieeexplore.ieee.org/document/832713/,IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339),10-16 July 1999,ieeexplore
10.1109/IRC.2019.00061,"ORC—A Lightweight, Lightning-Fast Middleware",IEEE,Conferences,"Robotic tasks are commonly solved by integrating numerous different software and hardware modules into one working application. The necessary integration work typically contributes a considerable share of the total work required for a project, which is why past research on robotics computing has pushed towards generating higher-level abstraction layers, like middlewares. However, the current state-of-the-art cannot provide reliable, low-latency communication performance as we will show in the experimental evaluation. In this paper we propose the Open Robot Communication framework (ORC). Compared to previous middlewares, ORC is lightweight and geared towards applications with high-performance requirements. We consider ORC especially useful for applications with Human Robot Interaction or collaborative tasks involving multiple robots. In the paper, we compare the runtime performance of ORC to the robot operating system (ROS). We can show that ORC enables message transfer with delays far below one millisecond and we demonstrate the real-time capabilities of ORC in a force-control task implemented in Python.",https://ieeexplore.ieee.org/document/8675625/,2019 Third IEEE International Conference on Robotic Computing (IRC),25-27 Feb. 2019,ieeexplore
10.1109/ICCIS.2017.8274769,Object detection and recognition of intelligent service robot based on deep learning,IEEE,Conferences,"Object detection and recognition is the premise and foundation for intelligent service robot to understand the surrounding environment and make intelligent decisions. In this paper, aiming at the accuracy and real-time performance of object detection and recognition of service robot in complex scenes, an end to end object detection and recognition algorithm based on deep learning is proposed. Firstly, the local multi branch deep convolution neural network is adopted to enhance the feature representation capability of the model by enhancing the convolution module function. Then, combining the anchor point mechanism, the object class and position regression prediction is carried out on the multi-layer feature map. When the local features and the global features are fully fused, the natural multi-scale detection and recognition is realized on multiple receptive fields. Finally, a network acceleration module is designed for GPU parallel acceleration on high performance NVIDIA TX1 embedded board. The experiment was carried out on SIASUN second generation intelligent service robot. The experimental results show that the algorithm has both good accuracy and real-time performance.",https://ieeexplore.ieee.org/document/8274769/,"2017 IEEE International Conference on Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics, Automation and Mechatronics (RAM)",19-21 Nov. 2017,ieeexplore
10.1109/ICRA.2016.7487351,Object discovery and grasp detection with a shared convolutional neural network,IEEE,Conferences,"Grasp an object from a stack of objects in real-time is still a challenge in robotics. This requires the robot to have the ability of both fast object discovery and grasp detection: a target object should be picked out from the stack first and then a proper grasp configuration is applied to grasp the object. In this paper, we propose a shared convolutional neural network (CNN) which can simultaneously implement these two tasks in real-time. The processing speed of the model is about 100 frames per second on a GPU which largely satisfies the requirement. Meanwhile, we also establish a labeled RGBD dataset which contains scenes of stacked objects for robotic grasping. At last, we demonstrate the implementation of our shared CNN model on a real robotic platform and show that the robot can accurately discover a target object from the stack and successfully grasp it.",https://ieeexplore.ieee.org/document/7487351/,2016 IEEE International Conference on Robotics and Automation (ICRA),16-21 May 2016,ieeexplore
10.1109/ROBIO.2009.4913200,Object orientation recognition based on SIFT and SVM by using stereo camera,IEEE,Conferences,"The goal of this research is to recognize an object and its orientation in space by using stereo camera. The principle of object orientation recognition in this paper was based on the scale invariant feature transform (SIFT) and support vector machine (SVM). SIFT has been successfully implemented on object recognition but it had a problem recognizing the object orientation. For many autonomous robotics applications, such as using a vision-guided industrial robot to grab a product, not only correct object recognition will be needed in this process but also object orientation recognition is required. In this paper we used SVM to recognize object orientation. SVM has been known as a promising method for classification accuracy and its generalization ability. The stereo camera system adopted in this research provided more useful information compared to single camera one. The object orientation recognition technique was implemented on an industrial robot in a real application. The proposed camera system and recognition algorithms were used to recognize a specific object and its orientation and then guide the industrial robot to perform some alignment operations on the object.",https://ieeexplore.ieee.org/document/4913200/,2008 IEEE International Conference on Robotics and Biomimetics,22-25 Feb. 2009,ieeexplore
10.1109/IConSCS.2012.6502471,Object recognition based on radial basis function neural networks: Experiments with RGB-D camera embedded on mobile robots,IEEE,Conferences,"An object recognition strategy based on artificial radial basis functions neural networks is presented in this paper. The general context of this work is to recognize object from captures made by a mobile robot. Unlike classical approaches which always select the closest object, our method outputs a set of potential candidates if the input information is not enough discriminant. There are three main steps in our approach: objects segmentation, signature extraction and classification. Segmentation is inspired from previous works and is shortly described. Signature extraction based on global geometric and color features is detailed. Classification based on artificial neural networks is also explained and architecture of the network is justified. Finally a real experiment made with a RGB-D camera mounted on a mobile robot is presented and classification results is criticized.",https://ieeexplore.ieee.org/document/6502471/,2012 1st International Conference on Systems and Computer Science (ICSCS),29-31 Aug. 2012,ieeexplore
10.1109/IECON.2006.347441,Obstacle avoidance algorithm based on biological patterns for anthropomorphic robot manipulator,IEEE,Conferences,"This study addresses the problem of collision-free controlling of 3-DOF (degree of freedom) anthropomorphic manipulators with given a priori unrestricted trajectory. The robot constraints resulting from the physical robot's actuators are also taken into account during the robot movement. Obstacle avoidance algorithm is based on penalty function, which is minimized when collision is predicted. Mathematical construction of penalty function and minimization process allows modeling of variety behaviors of robot elusion moves. Implementation of artificial neural network (ANN) inside the control process gives the additional flexibility needed to remember most important robot behaviors based on biological pattern of human arm moves. Thanks to the fast collisions' detection, the presented algorithm appears to be applicable to the industrial real-time implementations. Numerical simulations of the anthropomorphic manipulator operating in three dimensional space with obstacles is also presented",https://ieeexplore.ieee.org/document/4152937/,IECON 2006 - 32nd Annual Conference on IEEE Industrial Electronics,6-10 Nov. 2006,ieeexplore
10.1109/SSCI.2017.8280907,Obstacle avoidance of hexapod robots using fuzzy Q-learning,IEEE,Conferences,"Safe and autonomous obstacle avoidance plays an important role in the navigation control of hexapod robots. In this paper, we combine the method of reinforcement learning with fuzzy control to achieve the autonomous obstacle avoidance for a hexapod robot in complex environments. A fuzzy Q-learning algorithm is first presented and an obstacle avoidance approach is proposed using the Fuzzy Q-learning algorithm regarding the specific requirements of the hexapod robot. Then, the proposed approach is implemented for a real hexapod robot system that uses ultrasonic sensors to detect the obstacles in an unknown environment and learns an optimal policy to avoid the obstacles. Several groups of experiments are carried out to verify the performance of the proposed approach.",https://ieeexplore.ieee.org/document/8280907/,2017 IEEE Symposium Series on Computational Intelligence (SSCI),27 Nov.-1 Dec. 2017,ieeexplore
10.1109/ROBOT.2004.1307138,Obstacle avoidance through incremental learning with attention selection,IEEE,Conferences,"This work presents a learning-based approach to the task of generating local reactive obstacle avoidance. The learning is performed online in real-time by a mobile robot. The robot operated in an unknown bounded 2-D environment populated by static or moving obstacles (with slow speeds) of arbitrary shape. The sensory perception was based on a laser range finder. To greatly reduce the number of training samples needed, an attentional mechanism was used. An efficient, real-time implementation of the approach had been tested, demonstrating smooth obstacle-avoidance behaviors in a corridor with a crowd of moving students as well as static obstacles.",https://ieeexplore.ieee.org/document/1307138/,"IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004",26 April-1 May 2004,ieeexplore
10.1109/ICMLC.2005.1527447,Obstacle avoidance with multi-objective optimization by PSO in dynamic environment,IEEE,Conferences,"The second order motion model is one of the fundamental questions, a mostly important object in motion planning research of mobile robots, especially in complex environment. Based on the research of the second order motion model, this paper puts forward a new method for adjusting robots to avoid obstacles in dynamic environment. A mathematical model is first established in which environmental information such as, destination of a mobile robot, velocity and direction of obstacles are considered. Secondly, a new particle swarm optimization (PSO) algorithm is used to search for solution of the multi-objective optimization problem as described in the mathematical model. Finally, by adjusting the velocity and direction of the mobile robot to avoid obstacles in real time, the robot can reach the goal safely. Simulation experiment shows that this method is better than tradition artificial potential field (APF) algorithm and its improved algorithm based on genetic algorithm for obstacle avoidance.",https://ieeexplore.ieee.org/document/1527447/,2005 International Conference on Machine Learning and Cybernetics,18-21 Aug. 2005,ieeexplore
10.1109/ICRA48506.2021.9561790,Occupancy Map Inpainting for Online Robot Navigation,IEEE,Conferences,"In this work, we focus on mobile robot navigation in indoor environments where occlusions and field-of-view limitations hinder onboard sensing capabilities. We show that the footprint of a camera mounted on a robot can be drastically improved using learning-based approaches. Specifically, we consider the task of building an occupancy map for autonomous navigation of a robot equipped with a depth camera. In our approach, a local occupancy map is first computed using measurements from the camera directly. Afterwards, an inpainting network adds further information, the occupancy probabilities of unseen grid cells, to the map. A novel aspect of our approach is that rather than direct supervision from ground truth, we combine the information from a second camera with a better field-of-view for supervision. The training focuses on predicting extensions of the sensed data. To test the effectiveness of our approach, we use a robot setup with a single camera placed at 0.5m above the ground. We compare the navigation performance using raw maps from only this camera’s input (baseline) versus using inpainted maps augmented with our network. Our method outperforms the baseline approach even in completely new environments not included in the training set and can yield 21% shorter paths than the baseline approach. A real-time implementation of our method on a mobile robot is also tested in home and office environments.",https://ieeexplore.ieee.org/document/9561790/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICRA.2013.6630740,Off-line path integral reinforcement learning using stochastic robot dynamics approximated by sparse pseudo-input Gaussian processes: Application to humanoid robot motor learning in the real environment,IEEE,Conferences,"We develop fast reinforcement learning (RL) framework using the approximated dynamics of a humanoid robot. Although RL is a useful non-linear optimizer, applying it to real robotic systems is usually difficult due to the large number of iterations required to acquire suitable policies. In this study, we approximate the dynamics using data from a real robot with sparse pseudo-input Gaussian processes (SPGPs). By using SPGPs, we estimated the probability distribution considering both the input vector and output signal variances. In real environments, since the observations from robotic sensors include large noise, SPGPs can suitably approximate the stochastic dynamics of a real humanoid robot. We use the approximated dynamics to improve the performance of a movement task in a path integral RL framework, which updates a policy from the sampled trajectories of the state and action vectors and the cost. We implemented our proposed method on a real humanoid robot and tested on a via-point reaching task. The robot achieved successful performance with fewer number of interactions with the real environment by using the proposed method than a conventional approach which dose not use the simulated dynamics.",https://ieeexplore.ieee.org/document/6630740/,2013 IEEE International Conference on Robotics and Automation,6-10 May 2013,ieeexplore
10.1109/ROBIO.2013.6739747,Omnidirectional vision based mobile robot topological localization,IEEE,Conferences,"A robust omni-directional vision based localization method that allows us to obtain accurate mobile robot pose of large indoor environments is proposed. To implement the localization based on vision. In a learning step, the robot is manually guided on a path and an omni-directional image frames sequence is recorded. From this sequence a topological map is built with robust affine and scale invariant features extraction and matching algorithm. Each topological node represented by a set of panoramic images described with affine and scale invariant features. In the on-line localization stage, the robot localizes itself to the most likely node through robust Monte Carlo localization algorithm, and ambiguous robot pose estimation is resolved by this high probability distribution method. This enables the system to deal with perceptual aliasing or absence of reliable observation data. Experiment results carried out with a real robot in an indoor environment show the performance of the proposed method.",https://ieeexplore.ieee.org/document/6739747/,2013 IEEE International Conference on Robotics and Biomimetics (ROBIO),12-14 Dec. 2013,ieeexplore
10.1109/URAI.2018.8441890,On Humanoid Co-Robot Locomotion when Mechanically Coupled to a Human Partner,IEEE,Conferences,"This work focuses on the implementation of mechanically coupled tasks between a humanoid robot and a human. The latter focus comes from the push for robots to work with humans in everyday life as an overarching goal for the field. Co-robots, or robots that work alongside humans, may be guided by the humans through physical contact, such as the human grasping the robot's hand to gently guide it along a desired path. In this work the single-handed mechanically coupled task of guiding a robot through a course is implemented with four different methods of human input. These methods include: 1) using only force-torque sensors in the wrist of the robot for the control input from the human while the arm is under high-gain position control, creating a rigid coupling between the human and the robot, 2) using the force-torque sensors in the wrist of the robot for the control input while the arm is under low-gain position control with gravity compensation, creating compliant coupling between the human and the robot, 3) using the position of the end-effector of the robot for the control input while the arm is under low-gain position control with gravity compensation, and 4) using the force-torque sensors in the wrist and the position of the end-effector of the robot for the control input while the arm is under low-gain position control with gravity compensation. Tests are performed on the real-world and simulated adult-size humanoid robot DRC-Hubo++. During these tests the human and robot are walking together “hand in hand” with the human guiding the robot in a “figure eight” path. These tests show that having a compliant arm on the robot, when the human is guiding it via moving its end-effector, is beneficial over a rigid arm.",https://ieeexplore.ieee.org/document/8441890/,2018 15th International Conference on Ubiquitous Robots (UR),26-30 June 2018,ieeexplore
10.1109/ICAS.2006.40,On the conception of an autonomous and modular robot based on an Event Driven OSEK System with deterministic real-time behavior,IEEE,Conferences,"In this paper, we are interested in the design of an autonomous and modular self-reconfigurable robot having self-assembly capability and deterministic behavior. The ability of a modular robot to meet its mission strongly depends on the artificial intelligence software and on the underlying hardware and software architecture. The artificial intelligence software of a robot is mapped into several elementary tasks with different real-time constraints. We propose in this paper a real-time analysis taking into account kernel overheads for the validation of the real-time behavior of an artificial intelligence software. We study the OSEK operating system that requires few hardware resources and is cost effective. The overheads are due to the context switching mechanism which activates, terminates, and reschedules tasks, and to the periodic timer used to create the time base which is necessary for the periodic tasks model. We show how to take into account those overheads in the feasibility conditions. We compare the theoretical worst case response time obtained with kernel overheads to the response time obtained on a task set, on a real robot, based on the event driven OSEK implementation. We show that the kernel overheads cannot be neglected and that the theoretical results are valid and can be used to ensure a deterministic behavior of the robot",https://ieeexplore.ieee.org/document/1690225/,International Conference on Autonomic and Autonomous Systems (ICAS'06),19-21 July 2006,ieeexplore
10.1109/MWSCAS.1991.251981,On the fast robot dynamic parameters learning,IEEE,Conferences,"A computationally efficient solution to the problem of identifying the dynamic parameters of a robot manipulator is presented. The identification procedure is based on a simplified form of the dynamics. The approach has three important characteristics. First, being based on the Lagrangian representation, the equations are linear in the dynamic parameters, which makes possible the application of linear identification techniques. Second, the dynamic parameters are easily recognized, extracted, and grouped. Third, the equations are amenable to the implementation of parallel processing schemes. For the identification a recursive least squares algorithm is used. The algorithm is distributed over a network of transputers. Real-time results have been produced to demonstrate the speedup and efficiency of the proposed technique. A case study is given for the first three links of the Stanford Arm positioning system.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/251981/,[1991] Proceedings of the 34th Midwest Symposium on Circuits and Systems,14-17 May 1992,ieeexplore
10.1109/ICMA.2019.8816298,Online Learning of the Inverse Dynamics with Parallel Drifting Gaussian Processes: Implementation of an Approach for Feedforward Control of a Parallel Kinematic Industrial Robot,IEEE,Conferences,"The present paper deals with an online approach to learn the inverse dynamics of any robot. This is realized by the use of Gaussian Processes drifting parallel along the system data. An extension by a database enables the efficient use of data points from the past. The central component of this work is the implementation of such a method in a controller in order to achieve the actual goal: the feedforward control of an industrial robot by means of machine learning. This is done by splitting the procedure into two threads running parallel so that the prediction is decoupled from the computing-intensive training of the models. Experiments show that the method reduces the tracking errors more clearly than an elaborately identified rigid body model including friction. For a defined trajectory, the squared areas of the tracking errors of all axes are reduced by more than 54% compared to motion without pre-control. In addition, a highly dynamic pick-and-place experiment is used to investigate the possible changes in system dynamics. Compared to an offline trained model, the approximation error of the proposed online approach is smaller for the remaining time of the experiment after an initial phase. Furthermore, this error is smaller throughout the experiment for online learning with parallel drifting Gaussian Processes than when using a single one.",https://ieeexplore.ieee.org/document/8816298/,2019 IEEE International Conference on Mechatronics and Automation (ICMA),4-7 Aug. 2019,ieeexplore
10.1109/ICRA40945.2020.9196769,Online LiDAR-SLAM for Legged Robots with Robust Registration and Deep-Learned Loop Closure,IEEE,Conferences,"In this paper, we present a 3D factor-graph LiDAR-SLAM system which incorporates a state-of-the-art deeply learned feature-based loop closure detector to enable a legged robot to localize and map in industrial environments. Point clouds are accumulated using an inertial-kinematic state estimator before being aligned using ICP registration. To close loops we use a loop proposal mechanism which matches individual segments between clouds. We trained a descriptor offline to match these segments. The efficiency of our method comes from carefully designing the network architecture to minimize the number of parameters such that this deep learning method can be deployed in real-time using only the CPU of a legged robot, a major contribution of this work. The set of odometry and loop closure factors are updated using pose graph optimization. Finally we present an efficient risk alignment prediction method which verifies the reliability of the registrations. Experimental results at an industrial facility demonstrated the robustness and flexibility of our system, including autonomous following paths derived from the SLAM map.",https://ieeexplore.ieee.org/document/9196769/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/ICRA.2012.6224998,Online audio beat tracking for a dancing robot in the presence of ego-motion noise in a real environment,IEEE,Conferences,"This paper presents the design and implementation of a real-time real-world beat tracking system which runs on a dancing robot. The main problem of such a robot is that, while it is moving, ego noise is generated due to its motors, and this directly degrades the quality of the audio signal features used for beat tracking. Therefore, we propose to incorporate ego noise reduction as a pre-processing stage prior to our tempo induction and beat tracking system. The beat tracking algorithm is based on an online strategy of competing agents sequentially processing a continuous musical input, while considering parallel hypotheses regarding tempo and beats. This system is applied to a humanoid robot processing the audio from its embedded microphones on-the-fly, while performing simplistic dancing motions. A detailed and multi-criteria based evaluation of the system across different music genres and varying stationary/non-stationary noise conditions is presented. It shows improved performance and noise robustness, outperforming our conventional beat tracker (i.e., without ego noise suppression) by 15.2 points in tempo estimation and 15.0 points in beat-times prediction.",https://ieeexplore.ieee.org/document/6224998/,2012 IEEE International Conference on Robotics and Automation,14-18 May 2012,ieeexplore
10.1109/ROBOT.2008.4543481,Online constraint network optimization for efficient maximum likelihood map learning,IEEE,Conferences,"In this paper, we address the problem of incrementally optimizing constraint networks for maximum likelihood map learning. Our approach allows a robot to efficiently compute configurations of the network with small errors while the robot moves through the environment. We apply a variant of stochastic gradient descent and use a tree-based parameterization of the nodes in the network. By integrating adaptive learning rates in the parameterization of the network, our algorithm can use previously computed solutions to determine the result of the next optimization run. Additionally, our approach updates only the parts of the network which are affected by the newly incorporated measurements and starts the optimization approach only if the new data reveals inconsistencies with the network constructed so far. These improvements yield an efficient solution for this class of online optimization problems. Our approach has been implemented and tested on simulated and on real data. We present comparisons to recently proposed online and offline methods that address the problem of optimizing constraint network. Experiments illustrate that our approach converges faster to a network configuration with small errors than the previous approaches.",https://ieeexplore.ieee.org/document/4543481/,2008 IEEE International Conference on Robotics and Automation,19-23 May 2008,ieeexplore
10.1109/IROS.2016.7759410,Online joint learning of object concepts and language model using multimodal hierarchical Dirichlet process,IEEE,Conferences,"One of the biggest challenges in intelligent robotics is to build robots that can learn to use language. To this end, we think that the practical long-term on-line concept/word learning algorithm for robots is a key issue to be addressed. In this paper, we develop an unsupervised on-line learning algorithm that uses Bayesian nonparametrics for categorizing multimodal sensory signals such as audio, visual, and haptic information for robots. The robot uses its physical body to grasp and observe an object from various viewpoints as well as listen to the sound during the observation. The most important property of the proposed framework is to learn multimodal concepts and the language model simultaneously. This mutual learning framework of concepts and language significantly improves both speech recognition and multimodal categorization performances. We conducted a long-term experiment where a human subject interacted with a real robot over 100 hours using 499 objects. Some interesting results of the experiment are discussed in this paper.",https://ieeexplore.ieee.org/document/7759410/,2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),9-14 Oct. 2016,ieeexplore
10.1109/IROS.2017.8202247,Online learning for human classification in 3D LiDAR-based tracking,IEEE,Conferences,"Human detection and tracking are essential aspects to be considered in service robotics, as the robot often shares its workspace and interacts closely with humans. This paper presents an online learning framework for human classification in 3D LiDAR scans, taking advantage of robust multi-target tracking to avoid the need for data annotation by a human expert. The system learns iteratively by retraining a classifier online with the samples collected by the robot over time. A novel aspect of our approach is that errors in training data can be corrected using the information provided by the 3D LiDAR-based tracking. In order to do this, an efficient 3D cluster detector of potential human targets has been implemented. We evaluate the framework using a new 3D LiDAR dataset of people moving in a large indoor public space, which is made available to the research community. The experiments analyse the real-time performance of the cluster detector and show that our online learned human classifier matches and in some cases outperforms its offline version.",https://ieeexplore.ieee.org/document/8202247/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/ICSMC.1998.726546,Online learning neural network controller for pneumatic robot position control,IEEE,Conferences,"This paper presents the implementation of online learning neural network controller in the pneumatic robot position servo control. The advantages of this design include: the ability to compensate for nonlinearities, and it is insensitive to system parameter time-varying. The traditional PID controller is replaced by neural network controller trained online to learn the inverse model of the pneumatic manipulator by backpropagation of the performance error. The simulation studies and experimental results on the PID controller, online learning neural network controller and off-line training neural network controller, are presented and discussed.",https://ieeexplore.ieee.org/document/726546/,"SMC'98 Conference Proceedings. 1998 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.98CH36218)",14-14 Oct. 1998,ieeexplore
10.1109/ICMA.2012.6285128,Online learning of COM trajectory for humanoid robot locomotion,IEEE,Conferences,"Center Of Mass (COM) trajectory is an essential factor for stable and natural robot locomotion. Unlike previous research in which COM trajectory either restricted by ZMP trajectory or directly predefined by simple function such as sinusoid, this research aims to establish the COM trajectory by online autonomous learning under the objective of locomotion stability and naturalness, which is expressed as a self-consistent measure in this paper. It provides an alternative that may avoid or weaken the mismatch between theoretical planning and practical implementation. The experimental results on a real humanoid robot PKU-HR4 show its effectiveness and promising future.",https://ieeexplore.ieee.org/document/6285128/,2012 IEEE International Conference on Mechatronics and Automation,5-8 Aug. 2012,ieeexplore
10.1109/IROS.2017.8206344,Online multi-target learning of inverse dynamics models for computed-torque control of compliant manipulators,IEEE,Conferences,"Inverse dynamics models are applied to a plethora of robot control tasks such as computed-torque control, which are essential for trajectory execution. The analytical derivation of such dynamics models for robotic manipulators can be challenging and depends on their physical characteristics. This paper proposes a machine learning approach for modeling inverse dynamics and provides information about its implementation on a physical robotic system. The proposed algorithm can perform online multi-target learning, thus allowing efficient implementations on real robots. Our approach has been tested both offline, on datasets captured from three different robotic systems and online, on a physical system. The proposed algorithm exhibits state-of-the-art performance in terms of generalization ability and convergence. Furthermore, it has been implemented within ROS for controlling a Baxter robot. Evaluation results show that its performance is comparable to the built-in inverse dynamics model of the robot.",https://ieeexplore.ieee.org/document/8206344/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/IJCNN.2009.5178844,Online temporal pattern learning,IEEE,Conferences,"This paper describes a biologically motivated approach, using hierarchical temporal memory (HTM), to build a high-level self-organizing visual system for a soccer bot. Meanwhile it presents two unsupervised online learning algorithms for temporal patterns in HTMs. The algorithms were implemented in a simulated soccer bot for a real-world evaluation. After a training phase, the robot was able to recognize different static objects in the soccer field. It also learned and recognized high-level objects that are composed of simpler objects, with position invariance and was also able to learn and recognize motions in the objects, all in a completely unsupervised manner.",https://ieeexplore.ieee.org/document/5178844/,2009 International Joint Conference on Neural Networks,14-19 June 2009,ieeexplore
10.1109/HUMANOIDS47582.2021.9555670,Open-Ended Fine-Grained 3D Object Categorization by Combining Shape and Texture Features in Multiple Colorspaces,IEEE,Conferences,"As a consequence of an ever-increasing number of service robots, there is a growing demand for highly accurate real-time 3D object recognition. Considering the expansion of robot applications in more complex and dynamic environments, it is evident that it is not possible to pre-program all object categories and anticipate all exceptions in advance. Therefore, robots should have the functionality to learn about new object categories in an open-ended fashion while working in the environment. Towards this goal, we propose a deep transfer learning approach to generate a scale- and pose-invariant object representation by considering shape and texture information in multiple color spaces. The obtained global object representation is then fed to an instance-based object category learning and recognition, where a non-expert human user exists in the learning loop and can interactively guide the process of experience acquisition by teaching new object categories, or by correcting insufficient or erroneous categories. In this work, shape information encodes the common patterns of all categories, while texture information is used to describes the appearance of each instance in detail. Multiple color space combinations and network architectures are evaluated to find the most descriptive system. Experimental results showed that the proposed network architecture outperformed the selected state-of-the-art in terms of object classification accuracy and scalability. Furthermore, we performed a real robot experiment in the context of serve_a_beer scenario to show the real-time performance of the proposed approach.",https://ieeexplore.ieee.org/document/9555670/,2020 IEEE-RAS 20th International Conference on Humanoid Robots (Humanoids),19-21 July 2021,ieeexplore
10.23919/ACC45564.2020.9147898,Optimal Control of Wheeled Mobile Robots: From Simulation to Real World,IEEE,Conferences,"We study the problem of taking simulations to the real world (RW) for autonomous robotic systems with dynamic uncertainties and unknown disturbances while maintaining the optimal performance and stability of the designed controller designed in simulation. In general, an optimal and robust controller that is designed through simulation often does not perform similarly when deployed in the RW. We focus on using simulations to generate an optimal control policy utilizing the Memetic algorithm (MA) iteratively. The simulation-to-RW performance and stability are realized by using an adaptive fuzzy system to learn the uncertain part of the dynamic model, disturbance and noises. We demonstrate experimentally that this method permits the development of optimal control design in simulations and integrates adaptive learning rules to enable precise and repetitive trajectory tracking for the wheeled mobile robot (WMR) with disturbances and uncertainties.",https://ieeexplore.ieee.org/document/9147898/,2020 American Control Conference (ACC),1-3 July 2020,ieeexplore
10.1109/CACS.2015.7378370,Optimal robot path planning system by using a neural network-based approach,IEEE,Conferences,"This paper proposes an optimal robot path planning system that can build map, plan optimal paths, and maneuver mobile robots. The system constructs a grid-based map by using information on the locations of the origin and static obstacles. The system calculates the optimal trajectory by using a simplified neural network model and accordingly maneuvers a mobile robot. For dynamic obstacles, the mobile robot can sense the ambient environment and avoid possible collisions. A practical experiment using an Arduino-based platform was conducted to illustrate the effectiveness of the proposed methodology.",https://ieeexplore.ieee.org/document/7378370/,2015 International Automatic Control Conference (CACS),18-20 Nov. 2015,ieeexplore
10.1109/SII.2012.6426933,Optimization of obstacle avoidance using reinforcement learning,IEEE,Conferences,Walking through narrow space for multi-legged robot is optimized using reinforcement learning in this paper. The walking is generated by the virtual repulsive force from the estimated obstacle position and the virtual impedance field. The resulted action depends on the parameter of the virtual impedance coefficients. The reinforcement learning is employed to find an optimal motion. The temporal walking through motion consists of each parameter optimized for a situation. Optimization of integrated walking through motion is finally achieved evaluating walking in compound encountering obstacle on simulator. The resulted motion is implemented to a real multi-legged robot and results show the effectiveness of the proposed method.,https://ieeexplore.ieee.org/document/6426933/,2012 IEEE/SICE International Symposium on System Integration (SII),16-18 Dec. 2012,ieeexplore
10.1109/UR49135.2020.9144838,Outdoor Robot Navigation System using Game-Based DQN and Augmented Reality,IEEE,Conferences,"This paper presents a deep reinforcement learning based robot outdoor navigation method using visual information. The deep q network (DQN) maps the visual data to robot action in a goal location reaching task. An advantage of the proposed method is that the implemented DQN is trained in the first-person shooter (FPS) game-based simulated environment provided by ViZDoom. The FPS simulated environment reduces the differences between the training and the real environments resulting in a good performance of trained DQNs. In our implementation a marker-based augmented reality algorithm with a simple object detection method is used to train the DQN. The proposed outdoor navigation system is tested in the simulation and real robot implementation, with no additional training. Experimental results showed that the navigation system trained inside the game-based simulation can guide the real robot in outdoor goal directed navigation tasks.",https://ieeexplore.ieee.org/document/9144838/,2020 17th International Conference on Ubiquitous Robots (UR),22-26 June 2020,ieeexplore
10.1109/IROS.1997.655095,Output methods for an associative operation of programmable artificial retinas,IEEE,Conferences,"The introduction of intelligence near each photosensitive element in focal plane arrays (FPA) leads to sensory devices-called artificial retinas-which may no longer output raw images but, rather, much more concentrated forms of information. In particular, when the on-sensor image processing facilities are powerful enough to allow some structural pattern recognition, lists of pixels of interest become an output format of choice from retina to microprocessor. This implies the development of specific output techniques and operators to be integrated in the focal plane. After an in-depth presentation of the motivations in the context of programmable artificial retinas (PAR) for robot vision, two original solutions to the problem are presented, corresponding to two different trade-offs between efficiency and VLSI implementation cost. The first one is a compact hardware solution, which allows to sense pixels of interest from the sides of the 2D pixel array. The second one, a mainly software technique, exploits the mathematical concept of de Bruijn arrays for a distributed encoding of pixel addresses on the PAR.",https://ieeexplore.ieee.org/document/655095/,Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS '97,11-11 Sept. 1997,ieeexplore
10.1109/ICMTMA.2009.402,Overall Inverse Kinematics Analysis of Parallel Robot Leg for Rescue Based on Rodrigues Parameters,IEEE,Conferences,"A new method to describe the position-stance of parallel robot leg was proposed based on the Rodrigues theory. Comparing with others methods, the kinematic model with Rodrigues parameters has the advantages including least computational parameters, no trigonometric function calculation and convenient real-time control. The model of the inverse kinematics was established and the inverse solutions of the position-stance were obtained by analyzing the topologic structure of the parallel robot leg with 3-RPS limb. According to the vectors of the manipulator, the velocity and acceleration models of moving platform, limbs and end-effector were deduced. By comparing with the normal walking gait of a human subject, the end-point trajectory of the parallel robot leg was better programmed. The experiment results showed the structure characteristics of the parallel robot leg and validated the model of the inverse kinematics. It was concluded that the parallel robot leg can fulfil the kinematic demand in the unconfigurable environment.",https://ieeexplore.ieee.org/document/5203157/,2009 International Conference on Measuring Technology and Mechatronics Automation,11-12 April 2009,ieeexplore
10.1109/ROBOT.1991.131722,Parallel robot motion planning,IEEE,Conferences,"A fast, parallel method for computing configuration space maps is presented. The method is made possible by recognizing that one can compute a family of primitive maps which can be combined by superposition based on the distribution of real obstacles. This motion planner has been implemented for the first three degrees-of-freedom of a Puma robot in *Lisp on a Connection Machine with 8 K processors. A six degree-of-freedom version of the algorithm which performs a sequential search of the six-dimensional configuration space, building three-dimensional cross sections in parallel, has also been implemented.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/131722/,Proceedings. 1991 IEEE International Conference on Robotics and Automation,9-11 April 1991,ieeexplore
10.1109/CDC.2006.377499,Path Generation Using Matrix Representations of Previous Robot State Data,IEEE,Conferences,"Humans learn by repetition and using past experiences. It is possible for robots to act in a similar fashion. By representing past path traversal experiences with matrices, a new path can be generated without relying on calculations of complex dynamics or control laws. This paper presents one approach for allowing robots to use past experience to generate new paths and control actions. This approach relies on using several matrices to associate each new input value with previous robot states. An example is provided and analyzed which shows a successful simulated implementation of this approach. In addition a real world test of the approach was conducted which demonstrates that the implementation not only generates new paths, but does so fast enough to be feasible for real time systems",https://ieeexplore.ieee.org/document/4178112/,Proceedings of the 45th IEEE Conference on Decision and Control,13-15 Dec. 2006,ieeexplore
10.1109/IWECAI50956.2020.00019,Path Planning Obstacle Avoidance Algorithm Based on Wheeled Robot,IEEE,Conferences,"There are many obstacles and movements in the indoor environment. Indoor robots need to cope with the changing environment. This paper studies the obstacle avoidance problem of wheeled robots moving in an unknown environment. Firstly, the dynamic path planning algorithm for robot autonomous obstacle avoidance is studied, and the algorithm is implemented in C# language. Then use the Unity3D game engine to simulate the algorithm. The innovations of this algorithm are as follows: 1. Vectorize the path of the robot; 2. Summarize the motion state of the obstacle and the robot into six cases. During the movement process, the obstacle movement state is continuously judged, and the speed and direction of the obstacle are analyzed. The judgment result must belong to six situations. The experiment proves that the algorithm can solve the obstacle avoidance problem when encountering obstacles of different speeds and sizes, and has stronger applicability.",https://ieeexplore.ieee.org/document/9221693/,2020 International Workshop on Electronic Communication and Artificial Intelligence (IWECAI),12-14 June 2020,ieeexplore
10.1109/DISA.2018.8490605,Path Planning on Robot Based on D* Lite Algorithm,IEEE,Conferences,"The increasing need of autonomous behavior of robots in fields of science and technology formed the requirement for path planning implemented by the robot without the human assistance. In this paper, D* Lite, which is a path planning graph-based algorithm, was used in order to compute the shortest path from a start to goal point in a real environment and make a Pepper robot move in a computed trajectory. The movement of robot was conducted in a static environment, with the map of the environment already known. This paper is a first step in the research focusing on a creation of a so-called intelligent workspace.",https://ieeexplore.ieee.org/document/8490605/,2018 World Symposium on Digital Intelligence for Systems and Machines (DISA),23-25 Aug. 2018,ieeexplore
10.23919/ICINS43215.2020.9134006,Path Planning with Improved Artificial Potential Field Method Based on Decision Tree,IEEE,Conferences,"Path planning is one of the key research directions in the field of mobile robots. It ensures that moving objects can reach the target point safely and without collision in a complex obstacle environment. The path planning is to search an optimal path from the starting point to the target point for the mobile robot in an environment with obstacles, according to certain evaluation criteria (such as the time, the best path, the minimum energy consumption, etc.). The path planning based on artificial potential field method has been paid more and more attention because of its advantages such as convenient calculation, simple implementation of hardware and outstanding real-time performance. However, the artificial potential field method has some limitations, such as the local minimum, the oscillation of moving objects among obstacles and so on. To solve these problems, we can introduce the idea of decision tree into the artificial potential field method for improvement. In machine learning, decision tree is usually used for classification. It is a prediction model, which represents a mapping relationship between object attributes and object values. By utilizing the advantages of decision tree in rule expression and extraction, an improved artificial potential field path planning model based on decision tree is constructed, which can realize real-time and accurate identification of current behavior and fast decision-making of next time behavior in path planning. Aiming at the dynamic path planning problem of mobile robots in indoor complex environment, based on the traditional artificial potential field method, this paper introduces the distance term into the potential field function, and proposes an improved artificial potential field method based on the idea of decision tree, to solve the local minimum, the oscillation between obstacles and concave obstacle problems. According to repulsion coefficient, deflection angle of resultant force and velocity, a reasonable classification decision is made to meet the needs of different obstacle distribution scenarios, and the effectiveness of the proposed method is verified by simulation experiments. Simulation results show that, compared with the traditional artificial potential field method, the planning time of improved algorithm is reduced by 50%, and the smoothness of path planning by the improved algorithm is increased by 43.3%.",https://ieeexplore.ieee.org/document/9134006/,2020 27th Saint Petersburg International Conference on Integrated Navigation Systems (ICINS),25-27 May 2020,ieeexplore
10.1109/SICE.2002.1195737,Path planning for mobile robots using an improved reinforcement learning scheme,IEEE,Conferences,"The current method for establishing travel routes provides modeled environmental information. However, it is difficult to create an environment model for the environments in which mobile robot travel because the environment changes constantly due to the existence of moving objects, Including pedestrians. In this study, we propose a path planning system for mobile robots using reinforcement-learning systems and cerebellar model articulation controllers (CMACs). We selected the best travel route utilizing these reinforcement-learning systems. When a CMAC learns the value function of Q-learning, it improves learning speed by utilizing the generalizing action. CMACs enable us to reduce the time needed to select the best travel route. Using simulation and real robots, we performed a path-planning experiment. We report the results of simulation and experiment on traveling by online learning.",https://ieeexplore.ieee.org/document/1195737/,Proceedings of the 41st SICE Annual Conference. SICE 2002.,5-7 Aug. 2002,ieeexplore
10.1109/URAI.2012.6463006,Path planning through maze routing for a mobile robot with nonholonomic constraints,IEEE,Conferences,"A comprehensive technique to plan path for a mobile robot with nonholonomic constraints through maze routing technique has been presented. Our robot uses a stereo vision based approach to detect the obstacles by creating dense 3D point clouds from the stereo images. ROS packages have been implemented on the robot for specific tasks of providing: i) Linear and angular velocity commands, ii) Calibration and rectification of the stereo images for generating point clouds, iii) Simulating the URDF (Unified Robot Description Format) module in real time, with respect to the real robot and iv) For visualizing the sensor data. For efficient path planning a hybrid technique using Lee's algorithm, modified by Hadlock and Soukup's algorithm has been implemented. Different path planning results have been shown using the maze routing algorithms. Preliminary results shows that Lee's algorithm is more time consuming in comparison with other algorithms. A hybrid of Lee's with Soukup's algorithm is more efficient but unpredictable for minimal path. A hybrid of Lee's with Hadlock's algorithm is the most efficient and least time consuming.",https://ieeexplore.ieee.org/document/6463006/,2012 9th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI),26-28 Nov. 2012,ieeexplore
10.1109/CRV52889.2021.00019,PathBench: A Benchmarking Platform for Classical and Learned Path Planning Algorithms,IEEE,Conferences,"Path planning is a key component in mobile robotics. A wide range of path planning algorithms exist, but few attempts have been made to benchmark the algorithms holistically or unify their interface. Moreover, with the recent advances in deep neural networks, there is an urgent need to facilitate the development and benchmarking of such learning-based planning algorithms. This paper presents PathBench, a platform for developing, visualizing, training, testing, and benchmarking of existing and future, classical and learned 2D and 3D path planning algorithms, while offering support for Robot Operating System (ROS). Many existing path planning algorithms are supported; e.g. A*, wavefront, rapidly-exploring random tree, value iteration networks, gated path planning networks; and integrating new algorithms is easy and clearly specified. We demonstrate the benchmarking capability of PathBench by comparing implemented classical and learned algorithms for metrics, such as path length, success rate, computational time and path deviation. These evaluations are done on built-in PathBench maps and external path planning environments from video games and real world databases. PathBench is open source <sup>1</sup>.",https://ieeexplore.ieee.org/document/9469507/,2021 18th Conference on Robots and Vision (CRV),26-28 May 2021,ieeexplore
10.1109/VRAIS.1995.512499,Pen-based force display for precision manipulation in virtual environments,IEEE,Conferences,"We describe the structure of a force display recently implemented for precision manipulation of scaled or virtual environments. We discuss the advantages of direct-drive parallel manipulators over geared serial manipulators for human-robot interaction application and introduce the serial-parallel structure we chose for our robot which interfaces with the human operator either at the fingertip or at the tip of a freely held pen-like instrument. We derive the statics and the dynamics, and then introduce the optimization criteria that allowed us to choose the dimensional parameters for the force display. Finally we show some of the potential application for this device.",https://ieeexplore.ieee.org/document/512499/,Proceedings Virtual Reality Annual International Symposium '95,11-15 March 1995,ieeexplore
10.1109/ICSMC.1996.571370,Perception-action method for mobile robot plan and control based on driving experience,IEEE,Conferences,"A method of navigation and control for mobile robot is introduced. It combines task planning and path tracking together with the principle of ""perception-action"" under the guidance of ""goal planning"". First, we discuss the behavior of the mobile robot in an outdoor real world for the purpose of setting up a mixed layered architecture with ""perception-action"" and ""goal planning"". Then a simple but effective approach of sensor based navigation and control is described for the implementation of the architecture. Finally, we give some improvements based on the human-driving experience concerning path tracking and control for the mobile robot moving on outdoor semistructured roads. The experiments carried out on our THMR-III (Tsinghua Mobile Robot III) mobile robot navigating in the real world showed the method described was effective and robust.",https://ieeexplore.ieee.org/document/571370/,"1996 IEEE International Conference on Systems, Man and Cybernetics. Information Intelligence and Systems (Cat. No.96CH35929)",14-17 Oct. 1996,ieeexplore
10.1109/ICECCT.2015.7226205,Performance analysis of path planning techniques for autonomous mobile robots,IEEE,Conferences,"This paper presents a comparative study on path planning techniques for autonomous mobile robots in a cluttered environment. It investigates four well known path planning algorithms and compares their performance with the proposed free configuration eigen-spaces (FCE) path planning method. In total, five path planning algorithms are considered towards the solution of the path planning problem under certain working parameters. These working parameters are the computation time needed to find a solution, the distance traveled and the amount of turning by the autonomous mobile robot. A comparison of results has been analyzed. This study will enable readers to identify, which of the proposed methods is most suitable for application under the working parameters the user wants to optimize. The findings have been summarized in the conclusion section. The techniques were implemented in the real-time robotic software Player/Stage. Further analysis were done using MATLAB mathematical computation software.",https://ieeexplore.ieee.org/document/7226205/,"2015 IEEE International Conference on Electrical, Computer and Communication Technologies (ICECCT)",5-7 March 2015,ieeexplore
10.1109/ICRA.2011.5979792,Physical human robot interaction in imitation learning,IEEE,Conferences,"This video presents our recent research on the integration of physical human-robot interaction (pHRI) into imitation learning. First, a marker control approach for real time human motion imitation is shown. Secondly, physical coaching in addition to observational learning is applied for the incremental learning of motion primitives. Last, we extend imitation learning to learning pHRI which includes the establishment of intended physical contacts. The proposed methods were implemented and tested using the IRT humanoid robot and DLR's humanoid upper-body robot Justin.",https://ieeexplore.ieee.org/document/5979792/,2011 IEEE International Conference on Robotics and Automation,9-13 May 2011,ieeexplore
10.1109/ROMAN.2009.5326164,Physical interaction learning: Behavior adaptation in cooperative human-robot tasks involving physical contact,IEEE,Conferences,"In order for humans and robots to engage in direct physical interaction several requirements have to be met. Among others, robots need to be able to adapt their behavior in order to facilitate the interaction with a human partner. This can be achieved using machine learning techniques. However, most machine learning scenarios to-date do not address the question of how learning can be achieved for tightly coupled, physical touch interactions between the learning agent and a human partner. This paper presents an example for such human in-the-loop learning scenarios and proposes a computationally cheap learning algorithm for this purpose. The efficiency of this method is evaluated in an experiment, where human care givers help an android robot to stand up.",https://ieeexplore.ieee.org/document/5326164/,RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication,27 Sept.-2 Oct. 2009,ieeexplore
10.1109/CNSC.2014.6906671,Pixelwise object class segmentation based on synthetic data using an optimized training strategy,IEEE,Conferences,"In this paper we present an approach for low-level body part segmentation based on RGB-D data. The RGB-D sensor is thereby placed at the ceiling and observes a shared workspace for human-robot collaboration in the industrial domain. The pixelwise information about certain body parts of the human worker is used by a cognitive system for the optimization of interaction and collaboration processes. In this context, for rational decision making and planning, the pixelwise predictions must be reliable despite the high variability of the appearance of the human worker. In our approach we treat the problem as a pixelwise classification task, where we train a random decision forest classifier on the information contained in depth frames produced by a synthetic representation of the human body and the ceiling sensor, in a virtual environment. As shown in similar approaches, the samples used for training need to cover a broad spectrum of the geometrical characteristics of the human, and possible transformations of the body in the scene. In order to reduce the number of training samples and the complexity of the classifier training, we therefore apply an elaborated and coupled strategy for randomized training data sampling and feature extraction. This allows us to reduce the training set size and training time, by decreasing the dimensionality of the sampling parameter space. In order to keep the creation of synthetic training samples and real-world ground truth data simple, we use a highly reduced virtual representation of the human body, in combination with KINECT skeleton tracking data from a calibrated multi-sensor setup. The optimized training and simplified sample creation allows us to deploy standard hardware for the realization of the presented approach, while yielding a reliable segmentation in real-time, and high performance scores in the evaluation.",https://ieeexplore.ieee.org/document/6906671/,2014 First International Conference on Networks & Soft Computing (ICNSC2014),19-20 Aug. 2014,ieeexplore
10.1109/ICRA.2018.8462927,Planning Ergonomic Sequences of Actions in Human-Robot Interaction,IEEE,Conferences,"In this paper, we define the problem of human-robot collaboration as a combined task and motion planning problem which is extended to the multi-agent case (human and robot). Our proposed approach allows us to explicitly take into account ergonomic cost, synchrony and concurrency of behavior in an optimization formulation. We show simulated results as well as an experiment with a real robot combined with a user study. Results show that optimizing over a sequence of actions leads to more ergonomic situations.",https://ieeexplore.ieee.org/document/8462927/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/IROS.1991.174701,Planning based sensing and task executing in an autonomous machine,IEEE,Conferences,"Implementing a control system for an autonomous machine is a challenging task. Several techniques have to be applied, such as task planning, hierarchical and/or distributed control, and advanced sensing techniques. In addition, to be useful these various techniques have to be integrated into a system that has to operate more or less in real-time. The authors present a control scheme based on hierarchically organized planning-executing-monitoring-cycles which is used to solve some of the problems related to real-time control of an autonomous machine. The implementation is also presented in which the control system is applied in a pilot system based on an industrial robot.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/174701/,Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91,3-5 Nov. 1991,ieeexplore
10.1109/CIRA.2005.1554245,Plenary talk June 29; The 3<sup>rd</sup>Generation of Robotics: Ubiquitous Robot,IEEE,Conferences,"This talk shows its possibility of implementation in real life through demonstrations using a Sobot, Rity: i) continuous interface between physical and virtual worlds ii) seamless transmission of Sobot between a PC and a Mobot, and iii) omnipresence of Sobot. Rity, developed at the Robot Intelligence Technology (RIT) Laboratory, KAIST, is a Sobot implemented as a 12 DOF artificial creature in the virtual 3D world created in a PC. It has virtual sensors to survive in the virtual world and physical sensors attached to the PC to interact with the real world. Based on sensor information it can express its emotion, and interact with human beings through a web camera in the real world. It can generate behaviors autonomously and has its own IP. This means that it can be accessed through a network at anywhere and anytime using any device. With this technique omnipresence of Sobot can be realized in a ubiquitous space. The eventual goal of this research is to integrate Sobot, Embot, and Mobot to build up a Ubibot so that ubiquitous services through it can be available in a ubiquitous era",https://ieeexplore.ieee.org/document/1554245/,2005 International Symposium on Computational Intelligence in Robotics and Automation,27-30 June 2005,ieeexplore
10.1109/ICRA48506.2021.9561387,Pointing at Moving Robots: Detecting Events from Wrist IMU Data,IEEE,Conferences,"We propose a practical approach for detecting the event that a human wearing an IMU-equipped bracelet points at a moving robot; the approach uses a learned classifier to verify if the robot motion (as measured by its odometry) matches the wrist motion, and does not require that the relative pose of the operator and robot is known in advance. To train the model and validate the system, we collect datasets containing hundreds of real-world pointing events. Extensive experiments quantify the performance of the classifiers and relevant metrics of the resulting detectors; the approach is implemented in a real-world demonstrator that allows users to land quadrotors by pointing at them.",https://ieeexplore.ieee.org/document/9561387/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/GCCE50665.2020.9291969,Policy Transfer from Simulation to Real World for Autonomous Control of an Omni Wheel Robot,IEEE,Conferences,"We aim to develop an autonomous mobile robot which supports workers in warehouse to reduce their burden. The robot acquire state-action policy to avoid obstacles and reach a destination by reinforcement learning using LiDAR sensor. In case of real-world application of reinforcement learning, the policy learned previously under simulation environment are generally diverted to real robots because of uncertainties that is unexpected under simulation environment, for example, friction, sensor noise and so on. In this paper, we proposed a method to refine action control of an omni wheel robot by transfer learning on real environment to deal with this problem. We conduct the experiment of searching the route for reaching a goal on real environment using transfer learning's results and verify the effectiveness of the policy acquired.",https://ieeexplore.ieee.org/document/9291969/,2020 IEEE 9th Global Conference on Consumer Electronics (GCCE),13-16 Oct. 2020,ieeexplore
10.1109/ICTAI.2006.96,Polynomial Regression with Automated Degree: A Function Approximator for Autonomous Agents,IEEE,Conferences,"In order for an autonomous agent to behave robustly in a variety of environments, it must have the ability to learn approximations to many different functions. The function approximator used by such an agent is subject to a number of constraints that may not apply in a traditional supervised learning setting. Many different function approximators exist and are appropriate for different problems. This paper proposes a set of criteria for function approximators for autonomous agents. Additionally, for those problems on which polynomial regression is a candidate technique, the paper presents an enhancement that meets these criteria. In particular, using polynomial regression typically requires a manual choice of the polynomial's degree, trading off between function accuracy and computational and memory efficiency. Polynomial regression with automated degree (PRAD) is a novel function approximation method that uses training data to automatically identify an appropriate degree for the polynomial. PRAD is fully implemented. Empirical tests demonstrate its ability to efficiently and accurately approximate both a wide variety of synthetic functions and real-world data gathered by a mobile robot",https://ieeexplore.ieee.org/document/4031933/,2006 18th IEEE International Conference on Tools with Artificial Intelligence (ICTAI'06),13-15 Nov. 2006,ieeexplore
10.1109/IROS.2013.6696568,Pose and paste — An intuitive interface for remote navigation of a multi-robot system,IEEE,Conferences,"We present Pose and Paste (P&amp;P) - an intuitive interface designed to facilitate interaction between a single user and a number of robots equipped with cameras. With this interface, a user wearing a head-mounted display is able to cycle through the real-time video streams originating from the robots' cameras. The user is also able to select a robot and remotely position it by simply walking or turning his/her head, i.e., control the robot's motion in a master/slave-type fashion. We report the results of an initial hardware experiment where a user located in the USA is tasked to position two quadrotor robots within a motion capture laboratory located in Germany. These results suggest that P&amp;P is a feasible approach to remotely inspect disaster affected sites. Lastly, we conduct a user study to compare P&amp;P with a baseline interface composed of a traditional computer monitor and a video game controller. The quantitative results and qualitative discussions resulting from this user study highlight how such multi-robot interfaces can be further improved.",https://ieeexplore.ieee.org/document/6696568/,2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,3-7 Nov. 2013,ieeexplore
10.1109/ISIE.2008.4677070,Position control of a robotic manipulator using a Radial Basis Function Network and a simple vision system,IEEE,Conferences,"This paper describes a new practical approach for approximating the inverse kinematics of a manipulator using a RBFN (radial basis function network). In fact, there are several traditional methods based on the known geometry of the manipulator to calculate the relationship between the joint variable space and the world coordinate space. However, these traditional methods are impractical if the manipulator geometry cannot be easily determined, in a robot-vision system for example. Therefore, a neural network with its inherent learning ability can be an effective alternative solution for the inverse kinematics problem. In this paper, a training approach using the strict interpolation method combined with the LMS (least mean square) is presented. The strict interpolation method with regularly spaced position training patterns in the workspace can produce an appropriate approximation of the inverse kinematic function. Additionally, the LMS algorithm can improve the approximate function iteratively through on-line training with arbitrary position patterns. The combination of these techniques can deal with variation in the set-up of the visual system used to measure the position of the manipulator in the workspace. To verify the performance of the proposed approach, a practical experiment has been performed using a Mitsubishi PA10-6CE manipulator observed by a webcam. All application programmes, such as robot servo control, neural network, and image processing tool, were written in C/C++ and run in a real robotic system. The experimental results prove that the proposed approach is effective.",https://ieeexplore.ieee.org/document/4677070/,2008 IEEE International Symposium on Industrial Electronics,30 June-2 July 2008,ieeexplore
10.1109/ICRA.2014.6907470,Posture control of a three-segmented tracked robot with torque minimization during step climbing,IEEE,Conferences,"In this paper, we present a posture control scheme for step climbing by an in-house developed three-segmented tracked robot, miniUGV. The posture control scheme results in minimum torque at the actuated joints of the segments. Non-linear optimization is carried out offline for progressively decreasing distance of the robot from the step with torque minimization as objective function and force balance, motor torque limits, slippage avoidance and interference avoidance constraints. The resulting angles of the joints are fitted to a third degree polynomial as a function of the robot distance from the step and the step height. It is shown that a single set of polynomial functions is sufficient for climbing steps of all permissible heights and angles of attack of the front segment. The methodology has been verified through simulation followed by implementation on the real robot. As a consequence of this optimization we find that the average current reduced by more than thirty percent, reducing power consumption and confirming the efficacy of the optimization framework.",https://ieeexplore.ieee.org/document/6907470/,2014 IEEE International Conference on Robotics and Automation (ICRA),31 May-7 June 2014,ieeexplore
10.1109/IJCNN.2014.6889830,Predictive Hebbian association of time-delayed inputs with actions in a developmental robot platform,IEEE,Conferences,"The work described here explores a neural network architecture that can be embedded directly in the realtime sensorimotor coordination loop of a developmental robot platform. We take inspiration from the way children are able to learn while interacting with a teacher, in particular the use of prediction of the teacher actions to improve own learning. The architecture is based on two neural networks that operate online, and in parallel, one for learning and one for prediction. A Hebbian learning rule is used to associate the high-dimensional afferent sensor input at different time-delays with the current efferent motor commands corresponding to the teacher demonstration. The predictions of future motor commands are used to limit the growth of the neural network weights, and to enable the robot to smoothly continue movements the teacher has begun. Results on a simulated iCub robot learning object interaction tasks are presented, including an analysis of the sensitivity to changes in the task setup. We also outline the first implementation on the real iCub platform.",https://ieeexplore.ieee.org/document/6889830/,2014 International Joint Conference on Neural Networks (IJCNN),6-11 July 2014,ieeexplore
10.1109/ROBIO.2012.6491183,Primitive action learning using fuzzy neural networks,IEEE,Conferences,"The learning of primitive actions, or affordances as often called, has always been one of the top items in the research agenda of the robotics community. In this paper we propose fuzzy neural networks as a viable solution for their computational efficiency, their ability to approximate smooth non-linear functions and their transparency of the underlying mechanisms of the trained network. More specifically we benchmark the Takaki-Sugeno Fuzzy Neural Network (TSFNN) in an experimental scenario where the robot learns to control its arm velocity to push a rolling object in a requested position. The experimental scenario was kept simple and of linear nature in order to benchmark the TSFNN with a least squares linear model. The real time experiments using a PR2 robot have been conducted to verify the proposed method. The experimental results have shown that the TSFNN is able to reliably and robustly learn and demonstrate the pushing action.",https://ieeexplore.ieee.org/document/6491183/,2012 IEEE International Conference on Robotics and Biomimetics (ROBIO),11-14 Dec. 2012,ieeexplore
10.1109/RO-MAN46459.2019.8956461,Privacy First: Designing Responsible and Inclusive Social Robot Applications for in the Wild Studies,IEEE,Conferences,"Deploying social robots applications in public spaces for conducting in the wild studies is a significant challenge but critical to the advancement of social robotics. Real world environments are complex, dynamic, and uncertain. Human-Robot interactions can be unstructured and unanticipated. In addition, when the robot is intended to be a shared public resource, management issues such as user access and user privacy arise, leading to design choices that can impact on users' trust and the adoption of the designed system. In this paper we propose a user registration and login system for a social robot and report on people's preferences when registering their personal details with the robot to access services. This study is the first iteration of a larger body of work investigating potential use cases for the Pepper social robot at a government managed centre for startups and innovation. We prototyped and deployed a system for user registration with the robot, which gives users control over registering and accessing services with either face recognition technology or a QR code. The QR code played a critical role in increasing the number of users adopting the technology. We discuss the need to develop social robot applications that responsibly adhere to privacy principles, are inclusive, and cater for a broad spectrum of people.",https://ieeexplore.ieee.org/document/8956461/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/ARITH.2019.00047,Privacy-Preserving Deep Learning via Additively Homomorphic Encryption,IEEE,Conferences,"We aim at creating a society where we can resolve various social challenges by incorporating the innovations of the fourth industrial revolution (e.g. IoT, big data, AI, robot, and the sharing economy) into every industry and social life. By doing so the society of the future will be one in which new values and services are created continuously, making people's lives more conformable and sustainable. This is Society 5.0, a super-smart society. Security and privacy are key issues to be addressed to realize Society 5.0. Privacy-preserving data analytics will play an important role. In this talk we show our recent works on privacy-preserving data analytics such as privacy-preserving logistic regression and privacy-preserving deep learning. Finally, we show our ongoing research project under JST CREST “AI”. In this project we are developing privacy-preserving financial data analytics systems that can detect fraud with high security and accuracy. To validate the systems, we will perform demonstration tests with several financial institutions and solve the problems necessary for their implementation in the real world.",https://ieeexplore.ieee.org/document/8877418/,2019 IEEE 26th Symposium on Computer Arithmetic (ARITH),10-12 June 2019,ieeexplore
10.1109/IROS.2018.8594180,Proactive Robot Assistants for Freeform Collaborative Tasks Through Multimodal Recognition of Generic Subtasks,IEEE,Conferences,"Successful human-robot collaboration depends on a shared understanding of task state and current goals. In nonlinear or freeform tasks without an explicit task model, robot partners are unable to provide assistance without the ability to translate perception into meaningful task knowledge. In this paper, we explore the utility of multimodal recurrent neural networks (RNNs) with long short-term memory (LSTM) units for real-time subtask recognition in order to provide context-aware assistance during generic assembly tasks. We train RNNs to recognize specific subtasks in individual modalities, then combine the high-level representations of these networks through a nonlinear connection layer to create a multimodal subtask recognition system. We report results from implementing the system on a robot that uses the subtask recognition system to provide predictive assistance to a human partner during a laboratory experiment involving a human-robot team completing an assembly task. Generalizability of the system is evaluated through training and testing on separate tasks with some similar subtasks. Our results demonstrate the value of such a system in providing assistance to human partners during a freeform assembly scenario and increasing humans' perception of the robot's agency and usefulness.",https://ieeexplore.ieee.org/document/8594180/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/IMTC.1999.776982,Problems and solutions in acquisition and interpretation of sensorial data on a mobile robot,IEEE,Conferences,"We discuss some guidelines to cope with problems that arise when using cheap and simple sensors on mobile, autonomous, robotic agents. In particular we focus on the perceptual aliasing problem and on the possibility to perform active sensor data acquisition. We present a robotic architecture that we have implemented on a real robot following the proposed guidelines. The obtained mobile robot satisfies the design specifications, navigating autonomously in an unstructured environment.",https://ieeexplore.ieee.org/document/776982/,IMTC/99. Proceedings of the 16th IEEE Instrumentation and Measurement Technology Conference (Cat. No.99CH36309),24-26 May 1999,ieeexplore
10.1109/EURBOT.1997.633565,Q-learning of complex behaviours on a six-legged walking machine,IEEE,Conferences,"We present work on a six-legged walking machine that uses a hierarchical version of Q-learning (HQL) to learn both the elementary swing and stance movements of individual legs as well as the overall coordination scheme to perform forward movements. The architecture consists of a hierarchy of local controllers implemented in layers. The lowest layer consists of control modules performing elementary actions, like moving a leg up, down, left or right to achieve the elementary swing and stance motions for individual legs. The next level consists of controllers that learn to perform more complex tasks like forward movement by using the previously learned, lower level modules. On the third the highest layer in the architecture presented here the previously learned complex movements are themselves reused to achieve goals in the environment using external sensory input. The work is related to similar, although simulation-based, work by Lin (1993) on hierarchical reinforcement learning and Singh (1994) on compositional Q-learning. We report on the HQL architecture as well as on its implementation on the walking machine SIR ARTHUR. Results from experiments carried out on the real robot are reported to show the applicability of the HQL approach to real world robot problems.",https://ieeexplore.ieee.org/document/633565/,Proceedings Second EUROMICRO Workshop on Advanced Mobile Robots,22-24 Oct. 1997,ieeexplore
10.1109/IJCNN.2014.6889947,Qualitative approach for inverse kinematic modeling of a Compact Bionic Handling Assistant trunk,IEEE,Conferences,"Compact Bionic Handling Assistant (CBHA) is a continuum manipulator, with pneumatic-based actuation and compliant gripper. This bionic arm is attached to a mobile robot named Robotino. Inspired by the elephant's trunk, it can reproduce biological behaviors of trunks, tentacles, or snakes. Unlike rigid link robot manipulators, the development of high performance control algorithm of continuum robot manipulators remains a challenge, particularly due to their complex mechanical design, hyper-redundancy and presence of uncertainties. Numerous studies have been investigated for modeling of such complex systems. Such continuum robots, like the CBHA present a set of nonlinearities and uncertainties, making difficult to build an accurate analytical model, which can be used for control strategies development. Hence, learning approach becomes a suitable tool in such scenarios in order to capture un-modeled nonlinear behaviors of the continuous robots. In this paper, we present a qualitative modeling approach, based on neuronal model of the inverse kinematic of CBHA. A penalty term constraint is added to the inverse objective function into Distal Supervised Learning (DSL) scheme to select one particular inverse model from the redundancy manifold. The inverse kinematic neuronal model is validated by conducting a real-time implementation on a CBHA trunk.",https://ieeexplore.ieee.org/document/6889947/,2014 International Joint Conference on Neural Networks (IJCNN),6-11 July 2014,ieeexplore
10.1109/IROS40897.2019.8968551,RONet: Real-time Range-only Indoor Localization via Stacked Bidirectional LSTM with Residual Attention,IEEE,Conferences,"In this study, a three-layered bidirectional Long Short-term Memory (Bi-LSTM) with residual attention, named as RONet, is proposed to achieve localization using range measurements. Accordingly, we acquired our own datasets and tested RONet using realistic conditions. It is shown that the RONet can estimate the position of the mobile robot in real time using the Nvidia Jetson AGX Xavier based only on range measurements. We also analyzed the sequence length of LSTM as a type of hyperparameters. We found that optimal sequence length is eight for more than eight anchors and twelve for fewer anchors compared to sequences with different lengths, given that construction of the network with the optimal sequence length estimates the position precisely and accounts for uncertainties. As verified experimentally, RONet yields more precise performance and results in increased robustness against outliers compared to a conventional range-only approach based on a particle filtering and the other conventional deep-learning-based approaches. We set three cases, reduced the number of anchors, and verified that the RONet was a robust solution. We also confirmed that it is the best solution that yields the smallest Root-Mean-Square-Error (RMSE) values, equal to 4.466 cm, 3.210 cm, and 3.090 cm, in the cases where three, five, and eight anchors were deployed, respectively.",https://ieeexplore.ieee.org/document/8968551/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/AIAR.2018.8769798,ROS2Unity3D; High-Performance Plugin to Interface ROS with Unity3d engine,IEEE,Conferences,"In this paper, we propose a novel highperformance method to interface ROS (Robot Operating System) from the Unity3d engine. In this regard, we introduce a message passing middleware to perform decentralized and efficient data transfer. We utilize the ZeroMQ; Google Protobuf and GStreamer libraries to achieve these aims. For evaluation, we compare our approach with state of the art Siemens ROS# U nity3D plugin. On the other hand, we simulate various essential robotic sensors such as LIDAR, RGBD, and Monocular cameras in Unity3D to experiment our solution in complex enough robotic scenarios. As Unity3D support a variety of devices and VR (Virtual Reality) capabilities, this solution may help researchers to perform better human-computer interaction using ROS and Unity3d engine. Besides, for developers who are not familiar with URDF and programming side of ROS Gazebo Sim, this will be a more natural way to exporting their 3D meshes to the Unity3D engine and simulate robotic experiments with ROS.",https://ieeexplore.ieee.org/document/8769798/,2018 9th Conference on Artificial Intelligence and Robotics and 2nd Asia-Pacific International Symposium,10-10 Dec. 2018,ieeexplore
10.1109/ICECTECH.2011.5941831,Radar-infrared sensor track correlation algorithm based on neural network fusion system,IEEE,Conferences,"Simultaneous capture of the texture and shape of a moving object in real time is expected to be applicable to various fields including virtual reality and object recognition. There are several difficulties must be overcome to develop a sensor able to achieve this feature: fast capturing of shape and the simultaneous capture of texture and shape. This paper presents a new type of neural network base fusion system infrared sensor, which is compatible to standard process. The proposed infrared sensor adopts a suspended n-well containing several p+/n-well diodes as infrared sensing element. The thermal analysis indicates that the sensor exhibits excellent steady-state and transient thermal property. In order to predigest the calculation, the measurement data are to be classified and selected. The fuzzy neuron network information fusion based on the T-S model is used to avoid obstacle for the mobile robot, which fully utilized the information coming from the sensors. Finally, the experiment with the autonomous robot proved that the method is really feasible and efficient.",https://ieeexplore.ieee.org/document/5941831/,2011 3rd International Conference on Electronics Computer Technology,8-10 April 2011,ieeexplore
10.1109/ICRA.2017.7989184,Rapidly exploring learning trees,IEEE,Conferences,"Inverse Reinforcement Learning (IRL) for path planning enables robots to learn cost functions for difficult tasks from demonstration, instead of hard-coding them. However, IRL methods face practical limitations that stem from the need to repeat costly planning procedures. In this paper, we propose Rapidly Exploring Learning Trees (RLT*), which learns the cost functions of Optimal Rapidly Exploring Random Trees (RRT*) from demonstration, thereby making inverse learning methods applicable to more complex tasks. Our approach extends Maximum Margin Planning to work with RRT* cost functions. Furthermore, we propose a caching scheme that greatly reduces the computational cost of this approach. Experimental results on simulated and real-robot data from a social navigation scenario show that RLT* achieves better performance at lower computational cost than existing methods. We also successfully deploy control policies learned with RLT* on a real telepresence robot.",https://ieeexplore.ieee.org/document/7989184/,2017 IEEE International Conference on Robotics and Automation (ICRA),29 May-3 June 2017,ieeexplore
10.1109/EMRTS.1999.777446,Rate modulation of soft real-time tasks in autonomous robot control systems,IEEE,Conferences,"Due to the high number of sensors managed and need to perform complex reasoning activities, real-time control systems of autonomous robots exhibit a high potential for overload, i.e., real-time tasks missing their deadlines. In these systems overload should be regarded as a likely occurrence and hence managed accordingly. In this paper we illustrate a novel scheduling technique for adaptation of soft real-time load to available computational capacity in the context of autonomous robot control architectures. The technique is based on rate modulation of a set of periodic tasks in a range of admissible rates. The technique is shown to be easily computable and several variations in implementation are reviewed within the paper.",https://ieeexplore.ieee.org/document/777446/,Proceedings of 11th Euromicro Conference on Real-Time Systems. Euromicro RTS'99,9-11 June 1999,ieeexplore
10.1109/ICRA48506.2021.9562075,Reaching Pruning Locations in a Vine Using a Deep Reinforcement Learning Policy,IEEE,Conferences,"We outline a neural network-based pipeline for perception, control and planning of a 7 DoF robot for tasks that involve reaching into a dormant grapevine canopy. The proposed system consists of a 6 DoF industrial robot arm and a linear slider that can actuate on an entire grape vine. Our approach uses Convolutional Neural Networks to detect buds in dormant grape vines and a Reinforcement Learning based control strategy to reach desired cut-point locations for pruning tasks. Within this framework, three methodologies are developed and compared to reach the desired locations: the learned policy-based approach (RL), a hybrid method that uses the learned policy and an inverse kinematics solver (RL+IK), and lastly a classical approach commonly used in robotics. We first tested and validated the suitability of the proposed learning methodology in a simulated environment that resembled laboratory conditions. A reaching accuracy of up to 61.90% and 85.71% for the RL and RL+IK approaches respectively was obtained for a vine that the agent observed while learning. When testing in a new vine, the accuracy was up to 66.66% and 76.19% for RL and RL+IK, respectively. The same methods were then deployed on a real system in an end to end procedure: autonomously scan the vine using a vision system, create its model and finally use the learned policy to reach cutting points. The reaching accuracy obtained in these tests was 73.08%.",https://ieeexplore.ieee.org/document/9562075/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ISIC.1992.225088,Reactive behavior design tools,IEEE,Conferences,"The reactive behavior of an autonomous agent can be described as collections of logical behaviors, each member of the collection controlling some aspect of the agent and working in conjunction with all the other behaviors. Such collections of reactive behaviors can be defined as combined, synchronous finite-state automata, using real-time programming languages which have strong formal components. These language tools, such as COSPAN and ESTEREL, require sophisticated users who have deep knowledge of both the syntax and semantics of the language. The authors use the simplicity of graphical finite-state automata editing to specify concurrent synchronous finite-state automata, and from those they produce COSPAN descriptions of these behaviors for analysis, and C language programs to implement the designed behaviors. The usefulness and validity of this approach was confirmed by the design, verification and implementation of several examples, including a controller demon for a robot arm.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/225088/,Proceedings of the 1992 IEEE International Symposium on Intelligent Control,11-13 Aug. 1992,ieeexplore
10.1109/ISIE.2005.1529114,Real time implementation of a selective attention model for the intelligent robot with autonomous mental development,IEEE,Conferences,"We propose a biologically motivated selective attention model to find an object based on context free search for an intelligent robot with an autonomous mental development (AMD) mechanism. For real-time operation of the selective attention model in the robot system, we have considered a way to reduce the computational load of the selective attention model, which uses a simplified symmetry operation with retina-topic sampling and look-up table in the localized candidate attention region. As a result, our model can perform within 270 ms at Pentium-4 2.8Ghz, and obtain a plausible human-like visual scan path in order to pay attention to an object preferentially. Then, we implemented an intelligent mobile robot with selective attention for an AMD mechanism.",https://ieeexplore.ieee.org/document/1529114/,"Proceedings of the IEEE International Symposium on Industrial Electronics, 2005. ISIE 2005.",20-23 June 2005,ieeexplore
10.1109/IJCNN.1993.714313,Real time learning algorithm for redundant manipulator movement control,IEEE,Conferences,"We propose a new learning control strategy to solve the ill-posed inverse kinematics of a redundant robot manipulator. Four distinct characteristics are observed: 1) the inverse solution is context-sensitive, which is a requisite when the manipulator starts from an arbitrary joint configuration or moves in a complex environment; 2) learning and execution are both memory-based and can be implemented in real time; 3) the property of conventional pseudoinverse control, i.e. keeping the incremental changes of joint angles minimum, is intrinsic in our scheme; and 4) control is goal-directed in that only the current end-effector position relative to the goal position is needed.",https://ieeexplore.ieee.org/document/714313/,"Proceedings of 1993 International Conference on Neural Networks (IJCNN-93-Nagoya, Japan)",25-29 Oct. 1993,ieeexplore
10.1109/ICRAI.2012.6413407,Real time localization of mobile robotic platform via fusion of Inertial and Visual Navigation System,IEEE,Conferences,"Inertial Navigation System (INS) is one of the most important component of a mobile robotic platform, be it ground or air based. It is used to localize the mobile robotic platform in the real world and identify its location in terms of latitudes and longitudes or other related coordinate systems. Highly accurate and precise INS is quite expensive and is therefore not suitable for more general purpose applications. It is, therefore, a standard approach in mobile robotics to use a low grade commercial INS coupled with another navigation device to provide a more accurate triangulation. Generally, INS and Global Positioning System (GPS) are integrated using Kalman Filters to provide accurate localization information about the mobile robots. Although, in certain scenarios, the mobile robot is not able to acquire a GPS fix for long durations of time especially when navigating in indoor environments or in areas with inadequate GPS satellite coverage. In such cases, an additional source of location fix is required. This paper describes an accurate and stable data fusion filter which integrates the position of a mobile robot from a Visual Navigation System (VNS) with the position from an INS to accurately localize the robot in absence of GPS data. This research proposes a seven error states model and uses it in Kalman Filter for data fusion. The filter is tuned and tested using dynamic and static data from INS and VNS. Simulation and experimentation results show that the seven error states model based Kalman Filter provides a good balance between accuracy, robustness and processing efficiency for a real time implementation. Experiments also show that in absence of GPS data only a couple of fixes from the VNS are sufficient to quickly correct the position of the mobile robotic platform and three fixes at different times are sufficient for velocity correction of INS.",https://ieeexplore.ieee.org/document/6413407/,2012 International Conference of Robotics and Artificial Intelligence,22-23 Oct. 2012,ieeexplore
10.1109/WCICA.2000.863435,Real time path smoothing schemes in teleoperation system,IEEE,Conferences,"The Robot Teleoperation System (RTS) based on telepresence, which is aided financially by the National 863 High-Tech Development Plan, was set up by the State Key Laboratory of Intelligence Technology and Systems. This system consists of three main parts: robot control, stereo vision and hand gesture tracking. The controlled robot and the operator form a closed loop, and the operator views the robot's status and the environment through the stereo vision subsystem. RTS is developed from SAROT (an intelligent assembly robot system), which is logically divided into 5 layers: real time control, monitoring and coordination, motion planning, task scheduling and task planning. The paper proposes several active ""path smoothing"" schemes implemented in the system, which carry out the operator's hand gesture tracking in 7 DOF (position: 3, orientation: 3, and pitch: 1).",https://ieeexplore.ieee.org/document/863435/,Proceedings of the 3rd World Congress on Intelligent Control and Automation (Cat. No.00EX393),26 June-2 July 2000,ieeexplore
10.1109/RISSP.2003.1285735,Real time reactive strategies based on potential fields for robot soccer,IEEE,Conferences,"Soccer robot games are rapidly becoming a major research tool in field of AI, machine vision and motion control. The dynamism of the environment in the size of state space makes such a design challenging. In this paper we develop optimal reactive strategies for the game using groundtruth data from experts, with potential fields as base of the strategies. Experiment shows that the strategy has good active characteristics and can satisfy the game demand.",https://ieeexplore.ieee.org/document/1285735/,"IEEE International Conference on Robotics, Intelligent Systems and Signal Processing, 2003. Proceedings. 2003",8-13 Oct. 2003,ieeexplore
10.1109/WCICA.2000.863455,Real time tracking in robot teleoperation system,IEEE,Conferences,"The robot teleoperation system based on stereo vision was developed by the State Key Lab of Intelligent Technology and System of Tsinghua University. The paper presents the design frame of the whole system, and describes in detail some of the key design and implementation problems. Finally, the paper analyses the difficulty of applying this technology to virtual reality and augmented reality systems, and some suggestions are provided. The success of this system can contribute to further research on augmented reality.",https://ieeexplore.ieee.org/document/863455/,Proceedings of the 3rd World Congress on Intelligent Control and Automation (Cat. No.00EX393),26 June-2 July 2000,ieeexplore
10.1109/ECCTD.2005.1522965,Real time vision by FPGA implemented CNNs,IEEE,Conferences,"In order to get real time image processing for mobile robot vision, we propose to use a discrete time cellular neural network implementation by a convolutional structure on Altora FPGA using VHDL language. We obtain at least 9 times faster processing than other emulations for the same problem.",https://ieeexplore.ieee.org/document/1522965/,"Proceedings of the 2005 European Conference on Circuit Theory and Design, 2005.",2-2 Sept. 2005,ieeexplore
10.1109/OCEANSKOBE.2018.8559422,Real-Time Automated Evaluation of COLREGS-Constrained Interactions Between Autonomous Surface Vessels and Human Operated Vessels in Collaborative Human-Machine Partnering Missions,IEEE,Conferences,"This paper explores an extension of the real-time evaluation of COLREGS-based collision avoidance interactions between autonomous surface vessels and human-operated surface vessels. Our previous work developed the algorithms that evaluate and quantify a ship's compliance with the collision regulations, safety, and mission efficiencies with respect to the overall goal(s). Our previous work is extended in this paper by establishing a light-weight program to assign penalties to offenders of safety or protocol violations during human-machine collaborative on-water interactions. Vessels interacting in this DARPA-sponsored Aquaticus mission are grouped into teams consisting of both human and robot counterparts. These teams play a “capture the flag” like game while being required to obey the maritime collision avoidance regulations. This paper is a first step in the field toward evaluating collision avoidance rules in the context of a human or robotic vehicle cheating the COLREGS against its opponent to gain a mission advantage. The problem is representative of interactions likely seen on the open ocean using a combination of autonomous and human-operated multi-vehicle collision avoidance interactions to larger scale maritime vessel traffic interactions operating under COLREGS protocol constraints. The vessels deploy in a distributed collaborative pattern to compete against the opposing team. Upon detection of a violation, the offending vessel(s) are required to complete their penalty actions prior to being allowed to proceed in their mission goal. Human offenders are able to be linked to haptic devices that give real-time feedback using vibrations or similar queuing.",https://ieeexplore.ieee.org/document/8559422/,2018 OCEANS - MTS/IEEE Kobe Techno-Oceans (OTO),28-31 May 2018,ieeexplore
10.1109/ICIA.2006.305830,Real-Time Fusion of Multimodal Tracking Data and Generalization of Motion Patterns for Trajectory Prediction,IEEE,Conferences,"A sensor-based model of a service robot's environment is a prerequisite for interaction. Such a model should contain the positions of the robot's interaction partners. Many reasonable applications require this knowledge in realtime. It could for example be used to realize efficient path planning for delivery tasks. Additionally to the actual positions of the partners it is important for the service robot to predict their possible future positions. In this paper we propose an extensible framework that combines different sensor modalities in a general real-time tracking system. Exemplarily, a tracking system is implemented that fuses tracking algorithms in laser range scans as well as in camera images by a particle filter. Furthermore, human trajectories are predicted by deducing them from learned motion patterns. The observed trajectories are generalized to trajectory patterns by a novel method which uses self organizing maps. Those patterns are used to predict trajectories of the currently observed persons. Practical experiments show that multimodality increases the system's robustness to incorrect measurements of single sensors. It is also demonstrated that a self organizing map is suitable for learning and generalizing trajectories. Convenient predictions of future trajectories are presented which are deduced from these generalizations.",https://ieeexplore.ieee.org/document/4097763/,2006 IEEE International Conference on Information Acquisition,20-23 Aug. 2006,ieeexplore
10.1109/ICMLC.2006.259112,Real-Time Implementation of a PD+DFNNS Controller for Compliance Robot,IEEE,Conferences,"This paper presents the compliance control of a robot manipulator under a constrained environment. The controller design proposed herein is based on the intelligence adaptive control scheme. In this design, the DFNNs (dynamic fuzzy neural networks) and PD feedback controllers control the position and the contact force of robot end-effector. The DFNNs controller is employed to compensate for environmental variations such as payload mass and disturbance torque during the operation process; PD feedback controllers control the position and the contact force of end-effector. Applying these controllers allows us to adapt the manipulator to the unknown surface of the surrounding environment and to have close contact with the curved surface",https://ieeexplore.ieee.org/document/4028106/,2006 International Conference on Machine Learning and Cybernetics,13-16 Aug. 2006,ieeexplore
10.1109/Cybermatics_2018.2018.00131,Real-Time Object Recognition Based on NAO Humanoid Robot,IEEE,Conferences,"This paper focuses on the real-time object recognition based indoor humanoid robots like Nao robots. Improving the perceptive ability of service robot has always been a research hotspot. The breakthrough of computer vision technology represented by object recognition provides a broader idea for this purpose. We deployed a micro-cloud layer that connects the robot with the computer vision, thereby realized the concepts of RaaS (Robot as a service). In this paper, in order to make the Nao robot to detect objects faster. We present an architecture about real-time object recognition on Nao, and offload the task of control and data collection from robot to a PC. Next, the image data is transmitted over Ethernet to the workstation, which runs multiple parallel image processing services. These services are built with the current popular deep neural network by TensorFlow and running on a GPU GTX1080 Ti. In the micro-cloud layer, we designed a universal robotic visual task queue model, and a PC registers the task queue to the LAN. There are multiple workers in the LAN, and each worker is an independent service processer. Service processer obtains the task queue from the network and processes the queue, and then the processer puts the results back to the manager. The experimental results of the Nao robot in the simulation and real word show that our model and method are effective. The robot can recognize about 90 kinds of common objects, and each frame of image processing time is about 100 milliseconds.",https://ieeexplore.ieee.org/document/8726687/,"2018 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)",30 July-3 Aug. 2018,ieeexplore
10.1109/ICMLC.2005.1527001,Real-Time Path Planning for Mobile Robots,IEEE,Conferences,"A new on-line real-time approach with obstacle avoidance for mobile robots moving in an uncertain environment has been proposed and implemented. With the integration of global planning and local planning, this path planning approach is based on polar coordinates in which the desirable direction angle is taken into consideration as an optimization index. Detecting unknown obstacles with local feedback information by robot’s sensor system, this approach orients the desirable direction of mobile robot so as to generate local sub-goal in every planning window. As a result, the difference between real direction angle and desirable direction angle of robot motion steers the mobile robot to detour collisions and advance toward the target without stopping to re-plan a path when new sensor data become available. This approach is not only simple and flexible, but also overcomes flaws of global planning and local planning. The effectiveness, feasibility, real-time performance, optimization capability, high precision and perfect stability are demonstrated by means of simulation examples.",https://ieeexplore.ieee.org/document/1527001/,2005 International Conference on Machine Learning and Cybernetics,18-21 Aug. 2005,ieeexplore
10.1109/IROS45743.2020.9341760,Real-Time Robot End-Effector Pose Estimation with Deep Network,IEEE,Conferences,"In this paper, we propose a novel algorithm that estimates the pose of the robot end effector using depth vision. The input to our system is the segmented robot hand point cloud from a depth sensor. Then a neural network takes a point cloud as input and outputs the position and orientation of the robot end effector in the camera frame. The estimated pose can serve as the input of the controller of the robot to reach a specific pose in the camera frame. The training process of the neural network takes the simulated rendered point cloud generated from different poses of the robot hand mesh. At test time, one estimation of a single robot hand pose is reduced to 10ms on gpu and 14ms on cpu, which makes it suitable for close loop robot control system that requires to estimate hand pose in an online fashion. We design a robot hand pose estimation experiment to validate the effectiveness of our algorithm working in the real situation. The platform we used includes a Kinova Jaco 2 robot arm and a Kinect v2 depth sensor. We describe all the processes that use vision to improve the accuracy of pose estimation of the robot end-effector. We demonstrate the possibility of using point cloud to directly estimate the robot's end-effector pose and incorporate the estimated pose into the controller design of the robot arm.",https://ieeexplore.ieee.org/document/9341760/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/I2CACIS.2019.8825093,Real-Time Robotic Grasping and Localization Using Deep Learning-Based Object Detection Technique,IEEE,Conferences,"This work aims to increase the impact of computer vision on robotic positioning and grasping in industrial assembly lines. Real-time object detection and localization problem is addressed for robotic grasp-and-place operation using Selective Compliant Assembly Robot Arm (SCARA). The movement of SCARA robot is guided by deep learning-based object detection for grasp task and edge detection-based position measurement for place task. Deep Convolutional Neural Network (CNN) model, called KSSnet, is developed for object detection based on CNN Alexnet using transfer learning approach. SCARA training dataset with 4000 images of two object categories associated with 20 different positions is created and labeled to train KSSnet model. The position of the detected object is included in prediction result at the output classification layer. This method achieved the state-of-the-art results at 100% precision of object detection, 100% accuracy for robotic positioning and 100% successful real-time robotic grasping within 0.38 seconds as detection time. A combination of Zerocross and Canny edge detectors is implemented on a circular object to simplify the place task. For accurate position measurement, the distortion of camera lens is removed using camera calibration technique where the measured position represents the desired location to place the grasped object. The result showed that the robot successfully moved to the measured position with positioning Root Mean Square Error (0.361, 0.184) mm and 100% for successful place detection.",https://ieeexplore.ieee.org/document/8825093/,2019 IEEE International Conference on Automatic Control and Intelligent Systems (I2CACIS),29-29 June 2019,ieeexplore
10.1109/EIIS.2017.8298584,Real-time 3D object detection in unstructured environments,IEEE,Conferences,"Real-time specific 3D object detection plays an important role in intelligent service robot or intelligent surveillance fields. A novel discriminative learning based method is proposed to detect a specific 3D object in unstructured environments with a single RGB image. This method contains two stages: the candidate extraction stage and the recognition stage. On the candidate extraction stage, we use a simple, fast, and high quality objectness measure Binarized Normed Gradients (BING) to highlight the target candidate regions. On the recognition stage, each candidate region is verified by the designed cascade classifiers in order to be classified into different classes based on multi features including color, shape and texture contents. Our method is evaluated by its performance on our proposed challenging new dataset consisting of 3 objects and is compared in two public challenging dataset with other approaches for single RGB image based 3D object detection. The experiment results show that the proposed method can not only achieve a high precision (97%) at 90% recall, but also can meet the real-time processing requirement of about 22 fps on video sequences.",https://ieeexplore.ieee.org/document/8298584/,2017 First International Conference on Electronics Instrumentation & Information Systems (EIIS),3-5 June 2017,ieeexplore
10.1109/SYSOSE.2015.7151922,Real-time FPGA decentralized inverse optimal neural control for a Shrimp robot,IEEE,Conferences,"This paper presents a field programmable gate array (FPGA) implementation for a decentralized inverse optimal neural controller for unknown nonlinear systems, in presence of external disturbances and parameter uncertainties. This controller is based on two techniques: first, an identifier using a discrete-time recurrent high order neural network (RHONN) trained with an extended Kalman filter (EKF) algorithm; second, on the basis of the neural identifier a controller which uses inverse optimal control, is designed to avoid solving the Hamilton Jacobi Bellman (HJB) equation. The proposed scheme is implemented in real-time to control a Shrimp robot.",https://ieeexplore.ieee.org/document/7151922/,2015 10th System of Systems Engineering Conference (SoSE),17-20 May 2015,ieeexplore
10.1109/CRV50864.2020.00032,Real-time Motion Planning for Robotic Teleoperation Using Dynamic-goal Deep Reinforcement Learning,IEEE,Conferences,"We propose Dynamic-goal Deep Reinforcement Learning (DGDRL) method to address the problem of robot arm motion planning in telemanipulation applications. This method intuitively maps human hand motions to a robot arm in real-time, while avoiding collisions, joint limits and singularities. We further propose a novel hardware setup, based on the HTC VIVE VR system, that enables users to smoothly control the robot tool position and orientation with hand motions, while monitoring its movements in a 3D virtual reality environment. A VIVE controller captures 6D hand movements and gives them as reference trajectories to a deep neural policy network for controlling the robot's joint movements. Our DGDRL method leverages the state-of-art Proximal Policy Optimization (PPO) algorithm for deep reinforcement learning to train the policy network with the robot joint values and reference trajectory observed at each iteration. Since training the network on a real robot is time-consuming and unsafe, we developed a simulation environment called RobotPath which provides kinematic modeling, collision analysis and a 3D VR graphical simulation of industrial robots. The deep neural network trained using RobotPath is then deployed on a physical robot (ABB IRB 120) to evaluate its performance. We show that the policies trained in the simulation environment can be successfully used for trajectory planning on a real robot. The the codes, data and video presenting our experiments are available at https://github.com/kavehkamali/ppoRobotPath.",https://ieeexplore.ieee.org/document/9108691/,2020 17th Conference on Computer and Robot Vision (CRV),13-15 May 2020,ieeexplore
10.1109/LifeTech52111.2021.9391811,Real-time Object Detection with Deep Learning for Robot Vision on Mixed Reality Device,IEEE,Conferences,"Mixed reality device sensing capabilities are valuable for robots, for example, the inertial measurement unit (IMU) sensor and time-of-flight (TOF) depth sensor can support the robot in navigating its environment. This paper demonstrates a deep learning (YOLO model) background, realtime object detection system implemented on mixed reality device. The goal of the system is to create a real-time communication system between HoloLens and Ubuntu systems to enable real-time object detection using the YOLO model. The experimental results show that the proposed method has a fast speed to achieve real-time object detection using HoloLens. This enables Microsoft HoloLens as a device for robot vision. To enhance human-robot interaction, we will apply it to a wearable robot arm system to automatically grasp objects in the future.",https://ieeexplore.ieee.org/document/9391811/,2021 IEEE 3rd Global Conference on Life Sciences and Technologies (LifeTech),9-11 March 2021,ieeexplore
10.1109/ECMR.2019.8870936,Real-time Vision-based Depth Reconstruction with NVidia Jetson,IEEE,Conferences,"Vision-based depth reconstruction is a challenging problem extensively studied in computer vision but still lacking universal solution. Reconstructing depth from single image is particularly valuable to mobile robotics as it can be embedded to the modern vision-based simultaneous localization and mapping (vSLAM) methods providing them with the metric information needed to construct accurate maps in real scale. Typically, depth reconstruction is done nowadays via fully-convolutional neural networks (FCNNs). In this work we experiment with several FCNN architectures and introduce a few enhancements aimed at increasing both the effectiveness and the efficiency of the inference. We experimentally determine the solution that provides the best performance/accuracy tradeoff and is able to run on NVidia Jetson with the framerates exceeding 16FPS for 320 × 240 input. We also evaluate the suggested models by conducting monocular vSLAM of unknown indoor environment on NVidia Jetson TX2 in real-time. Open-source implementation of the models and the inference node for Robot Operating System (ROS) are available at https://github.com/CnnDepth/tx2_fcnn_node.",https://ieeexplore.ieee.org/document/8870936/,2019 European Conference on Mobile Robots (ECMR),4-6 Sept. 2019,ieeexplore
10.1109/CEC.2003.1299618,Real-time adaptation technique to real robots: an experiment with a humanoid robot,IEEE,Conferences,"We introduce a technique that allows a real robot to execute a real-time learning, in which GP and RL are integrated. In our former research, we showed the result of an experiment with a real robot ""AIBO"" and proved the technique performed better than the traditional Q-learning method. Based on the proposed technique, we can acquire the common programs using a GP, applicable to various types of robots. We execute reinforcement learning with the acquired program in a real robot. In this way, the robot can adapt to its own operational characteristics and learn effective actions. In this paper, we show the experimental results in which a humanoid robot ""HOAP-1"" has been evolved to perform effectively to solve the box-moving task.",https://ieeexplore.ieee.org/document/1299618/,"The 2003 Congress on Evolutionary Computation, 2003. CEC '03.",8-12 Dec. 2003,ieeexplore
10.1109/ICCAS.2008.4694293,Real-time adaptive control of robot manipulator based on neural network compensator,IEEE,Conferences,"This paper presents two kinds of adaptive control schemes for robot manipulator which has the parametric uncertainties. In order to compensate these uncertainties, we use the NN (neural network system) that has the capability to approximate any nonlinear function over the compact input space. In the proposed control schemes, we need not derive the linear formulation of robot dynamic equation and tune the parameters. We also suggest the robust adaptive control laws in all proposed schemes for decreasing the effect of approximation error. To reduce the number of neural of network, we consider the properties of robot dynamics and the decomposition of the uncertainty function. The proposed controllers are robust not only to the structured uncertainty such as payload parameter, but also to the unstructured one such as friction model and disturbance. The validity of the control scheme is shown by computer simulations and experiment of dual-arm robot manipulator.",https://ieeexplore.ieee.org/document/4694293/,"2008 International Conference on Control, Automation and Systems",14-17 Oct. 2008,ieeexplore
10.1109/WCICA.2000.863254,Real-time bilateral control of Internet-based teleoperation,IEEE,Conferences,"The growth of the Internet has been accompanied by an increase in its applications. One of the most interesting of these is teleoperation, where the Internet is used as a bridge between operators and machines. However, teleoperation over the Internet comes with several problems: delay, lost packets and disconnection. All of these limitations may cause instability in teleoperation systems, especially for those systems include haptic feedback. Most of the previous work in Internet based teleoperation rests on many limiting assumptions, for example, time delay is constant or has an upper bound, control is not in real-time. This paper presents a new real time haptic feedback system that deals with these limitations and difficulties without making any assumptions regarding the time delay. The approach is based on the event based control, which has been implemented or a mobile robot over the Internet. The haptic information include real-time feedback of force and video.",https://ieeexplore.ieee.org/document/863254/,Proceedings of the 3rd World Congress on Intelligent Control and Automation (Cat. No.00EX393),26 June-2 July 2000,ieeexplore
10.1109/CCA.1994.381367,Real-time control of a robot using neural networks,IEEE,Conferences,"The real-time computation of the robot kinematics is very important. The basic transformations are the direct kinematic transformation (DKT) and the inverse kinematic transformation (IKT). The DKT can be computed in a straightforward way using the Denavit-Hartenberg notation. No such general method yet exists for the IKT, although this transformation is of major interest for control purposes. In this paper a neural network is presented that maps the IKT independent of the type of robot. After training, the network achieves very good accuracy and may easily be implemented in real-time. The performance of the algorithm is tested an the RTX robot, a SCARA-type robot with six degrees of freedom. This robot is controlled by a distributed control system. A host computer realizes the continuous path control and a network of 5 slave-transputers is used to compute the local controls and to drive the DC servomotors.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/381367/,1994 Proceedings of IEEE International Conference on Control and Applications,24-26 Aug. 1994,ieeexplore
10.1109/IJCNN.2013.6706785,Real-time decentralized inverse optimal neural control for a Shrimp robot,IEEE,Conferences,"This paper deals with a decentralized inverse optimal neural controller for MIMO discrete-time unknown nonlinear systems, in a presence of external disturbances and parameter uncertainties. It uses two techniques: first, an identifier based on a discrete-time recurrent high order neural network (RHONN) trained with an extended Kalman filter (EKF) algorithm; second, on the basis of the real identifier a controller which uses inverse optimal control, is designed to avoid solving the Hamilton Jacobi Bellman (HJB) equation. The proposed scheme is implemented in real-time to control a Shrimp robot.",https://ieeexplore.ieee.org/document/6706785/,The 2013 International Joint Conference on Neural Networks (IJCNN),4-9 Aug. 2013,ieeexplore
10.1109/CCA.2009.5280998,Real-time decentralized neural backstepping controller for a robot manipulator,IEEE,Conferences,This paper deals with adaptive trajectory tracking for discrete-time MIMO nonlinear systems. A high order neural network (HONN) is used to approximate a decentralized control law designed by the backstepping technique as applied to a block strict feedback form (BSFF). The HONN learning is performed online by an Extended Kalman Filter (EKF) algorithm. The proposed scheme is implemented in real-time to control a two DOF robot manipulator.,https://ieeexplore.ieee.org/document/5280998/,"2009 IEEE Control Applications, (CCA) & Intelligent Control, (ISIC)",8-10 July 2009,ieeexplore
10.1109/IROS.2009.5354338,Real-time decentralized neural block controller for a robot manipulator,IEEE,Conferences,"This paper presents a discrete-time decentralized control scheme for identification and trajectory tracking of a two degrees of freedom (DOF) robot manipulator. A recurrent high order neural network (RHONN) structure is used to identify the plant model and based on this model, a discrete-time control law is derived, which combines discrete-time block control and sliding modes techniques. The neural network learning is performed online by Kalman filtering. A controller is designed for each joint, using only local angular position and velocity measurements. These simple local joint controllers allow trajectory tracking with reduced computations. The proposed scheme is implemented in real-time to control a two DOF robot manipulator.",https://ieeexplore.ieee.org/document/5354338/,2009 IEEE/RSJ International Conference on Intelligent Robots and Systems,10-15 Oct. 2009,ieeexplore
10.1109/INTECH.2017.8102423,Real-time emotional state detection from facial expression on embedded devices,IEEE,Conferences,"From the last decade, researches on human facial emotion recognition disclosed that computing models built on regression modelling can produce applicable performance. However, many systems need extensive computing power to be run that prevents its wide applications such as robots and smart devices. In this proposed system, a real-time automatic facial expression system was designed, implemented and tested on an embedded device such as FPGA that can be a first step for a specific facial expression recognition chip for a social robot. The system was built and simulated in MATLAB and then was built on FPGA and it can carry out real time continuously emotional state recognition at 30 fps with 47.44% accuracy. The proposed graphic user interface is able to display the participant video and two dimensional predict labels of the emotion in real time together.",https://ieeexplore.ieee.org/document/8102423/,2017 Seventh International Conference on Innovative Computing Technology (INTECH),16-18 Aug. 2017,ieeexplore
10.1109/ROBOT.2003.1241979,Real-time estimation of facial expression intensity,IEEE,Conferences,"Changing facial expressions is a natural and powerful way of conveying personal intention, expressing emotion and regulating interpersonal communication. Automatic estimation of human facial expression intensity is an important step in enhancing the capability of human-robot interfaces. In this research, we have developed a system which can automatically estimate the intensity of facial expression in real-time. Based on isometric feature mapping, the intensity of expression is extracted from training facial transition sequences. Then, intelligent models including cascade neural networks and support vector machines are applied to model the relationship between the trajectories of facial feature points and expression intensity level. We have implemented a vision system which can estimate the expression intensity of happiness, anger and sadness in real-time.",https://ieeexplore.ieee.org/document/1241979/,2003 IEEE International Conference on Robotics and Automation (Cat. No.03CH37422),14-19 Sept. 2003,ieeexplore
10.1109/ROMAN.1996.568870,Real-time facial interaction between human and 3D face robot agent,IEEE,Conferences,"We attempt to introduce a 3D realistic human-like animate face robot to human-robot communication modality. The face robot can recognize human facial expressions as well as produce realistic facial expressions in real time. For the animate face robot to communicate interactively, we propose a new concept of ""active human interface"", and we investigate the performance of real-time recognition of facial expressions by neutral network (NN) and the expression ability of facial messages on the face robot. We found that the NN recognition of facial expressions and face robots performance in generating facial expressions are of almost the same level as that in humans. We integrate these two component technologies for the face to produce facial expression in reaction to the recognition result of human facial expression in real time. This implies a high technological potential for the animate face robot to undertakes interactive communication with human when an artificial emotion being implemented.",https://ieeexplore.ieee.org/document/568870/,Proceedings 5th IEEE International Workshop on Robot and Human Communication. RO-MAN'96 TSUKUBA,11-14 Nov. 1996,ieeexplore
10.1109/ISIC.2010.5612924,Real-time five DOF robot control using a decentralized neural backstepping scheme,IEEE,Conferences,This paper presents a discrete-time decentralized control scheme for trajectory tracking of a five degrees of freedom (DOF) redundant robot. A high order neural network (HONN) is used to approximate a decentralized control law designed by the backstepping technique as applied to a block strict feedback form (BSFF). The neural network learning is performed on-line by Kalman filtering. The controllers are designed for each joint using only local angular position and velocity measurements. These simple local joint controllers allow trajectory tracking with reduced computations. The applicability of the proposed scheme is illustrated via real-time implementation.,https://ieeexplore.ieee.org/document/5612924/,2010 IEEE International Symposium on Intelligent Control,8-10 Sept. 2010,ieeexplore
10.1109/IRIA53009.2021.9588681,Real-time gesture control UAV with a low resource framework,IEEE,Conferences,"This study showcases a low-resource framework that enables people with no technical know-how to interact with drones, it also explores the capabilities of 2D- computer vision and deep learning techniques for gesture based interface systems on a low-cost micro drone with an onboard RGB camera. This Human-Robot Interaction system processes the real-time human pose to allow a user to command the drone, i.e., by providing direction to move and execute actions. A linear PD controller and image processing techniques are implemented to track humans whilst maintaining a safe distance from the user by perceiving depth information through pose estimation. We incorporated the gesture recognition results into a drone using the Robot Operating System (ROS) and evaluated system performance indoor and outdoor. This low computation framework can be applied further to control robotic arms or mobile robots.",https://ieeexplore.ieee.org/document/9588681/,2021 International Symposium of Asian Control Association on Intelligent Robotics and Industrial Automation (IRIA),20-22 Sept. 2021,ieeexplore
10.1109/ROMAN.2016.7745248,Real-time human detection for robots using CNN with a feature-based layered pre-filter,IEEE,Conferences,"Convolutional neural networks (CNNs), in combination with big data, are increasingly being used to engineer robustness into visual classification systems including human detection. One significant challenge to using a CNN on a mobile robot, however, is the associated computational cost and detection rate of running the network. In this work, we demonstrate how fusion with a feature-based layered classifier can help. Not only does score-level fusion of a CNN with the layered classifier improve precision/recall for detecting people on a mobile robot, but using the layered system as a pre-filter can substantially reduce the computational cost of running a CNN - reducing the number of objects that need to be classified while still improving precision. The combined real-time system is implemented and evaluated on a two robots with very different GPU capabilities.",https://ieeexplore.ieee.org/document/7745248/,2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),26-31 Aug. 2016,ieeexplore
10.1109/ROBOT.1993.291973,Real-time implementation of neural network learning control of a flexible Space manipulator,IEEE,Conferences,"A neural network approach to online learning control and real-time implementation for a flexible space robot manipulator is presented. An overview of the motivation and system development of the self-mobile space modulator (SM/sup 2/) is given. The neural network learns control by updating feedforward dynamics based on feedback control input. Implementation issues associated with online training strategies are addressed and a single stochastic training scheme is presented. A recurrent neural network architecture with improved performance is proposed. Using the proposed learning scheme, the manipulator tracking error is reduced by 85% compared to that of conventional proportional-integral-derivative (PID) control. The approach possesses a high degree of generality and adaptability to various applications. It will be a valuable learning control method for robots working in unconstructed environments.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/291973/,[1993] Proceedings IEEE International Conference on Robotics and Automation,2-6 May 1993,ieeexplore
10.1109/BIOROB.2008.4762823,Real-time isometric pinch force prediction from sEMG,IEEE,Conferences,"This paper describes a real-time isometric pinch force prediction algorithm using surface electromyogram (sEMG). The activities of seven muscles related to the movements of the thumb and index finger joints, which are observable using surface electrodes, were recorded during pinch force experiments. For the successful implementation of the real-time prediction algorithm, an off-line analysis was performed using the recorded activities. From the seven muscles, four muscles were selected for monitoring using the Fisher linear discriminant paradigm in an off-line analysis, and the recordings from these four muscles provided the most effective information for mapping sEMG to the pinch force. An ANN structure was designed to perform efficient training and to avoid both under-fitting and over-fitting problems. Finally, the pinch force prediction algorithm was tested with five volunteers and the results were evaluated using two criteria: normalized root mean squared error (NRMSE) and correlation (CORR). The training time for the subjects was only 2 min 29 sec, but the prediction results were successful with NRMSE = 0.093 plusmn0.047 and CORR = 0.957 plusmn0.031. These results imply that the proposed algorithm is useful to measure the generated pinch force without force sensors. The possible applications of the proposed method include controlling bionic finger robot systems to overcome finger paralysis or amputation.",https://ieeexplore.ieee.org/document/4762823/,2008 2nd IEEE RAS & EMBS International Conference on Biomedical Robotics and Biomechatronics,19-22 Oct. 2008,ieeexplore
10.1109/ICAR.1997.620222,Real-time navigation of a mobile robot using Kohonen's topology conserving neural network,IEEE,Conferences,"This paper proposes a real-time sensor based navigation method using Kohonen's topology conserving network for navigation of a mobile robot in any uncertain environment. The sensory information including target location with respect to current location of the mobile robot, have been discretely conserved using a two dimensional Kohonen lattice. Reinforcement learning based on a stochastic real valued technique have been implemented to compute the action space for this Kohonen lattice. The proposed scheme learns the input and output weight space of the Kohonen lattice which is generalized to any workspace. The effectiveness of the proposed scheme has been established by simulation where the complete domain of the input-space is quantized based on experience on sensory data encountered in real-time. The input-output mapping conserved by the Kohonen lattice during simulation was used to guide a mobile robot in a real-time environment. Successful navigation of the mobile robot without further training confirms the robustness of the proposed scheme.",https://ieeexplore.ieee.org/document/620222/,1997 8th International Conference on Advanced Robotics. Proceedings. ICAR'97,7-9 July 1997,ieeexplore
10.1109/ACIIW.2019.8925192,Real-time pain detection in facial expressions for health robotics,IEEE,Conferences,"Automatic pain detection is an important challenge in health computing. In this paper we report on our efforts to develop a real-time, real-world pain detection system from human facial expressions. Although many studies addressed this challenge, most of them use the same dataset for training and testing. There is no cross-check with other datasets or implementation in real-time to check performance on new data. This is problematic, as evidenced in this paper, because the classifiers overtrain on dataset-specific features. This limits realtime, real-world usage. In this paper, we investigate different methods of real-time pain detection. The training data uses a combination of pain and emotion datasets, unlike other papers. The best model shows an accuracy of 88.4% on a dataset including pain and 7 non-pain emotional expressions. Results suggest that convolutional neural networks (CNN) are not the best methods in some cases as they easily overtrain if the dataset is biased. Finally we implemented our pain detection method on a humanoid robot for physiotherapy. Our work highlights the importance of cross-corpus evaluation &amp; real-time testing, as well as the need for a well balanced and ecologically valid pain dataset.",https://ieeexplore.ieee.org/document/8925192/,2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW),3-6 Sept. 2019,ieeexplore
10.1109/ROBOT.2001.932598,Real-time robot learning,IEEE,Conferences,"This paper presents the design, implementation and testing of a real-time system using computer vision and machine learning techniques to demonstrate learning behavior in a miniature mobile robot. The miniature robot, through environmental sensing, learns to navigate a maze choosing the optimum route. Several reinforcement learning based algorithms, such as the Q-learning, Q(/spl lambda/)-learning, fast online Q(/spl lambda/)-learning and DYNA structure, are considered. Experimental results based on simulation and an integrated real-time system are presented for varying density of obstacles in a 15/spl times/15 maze.",https://ieeexplore.ieee.org/document/932598/,Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164),21-26 May 2001,ieeexplore
10.1109/SII.2010.5708353,Realization and analysis of giant-swing motion using Q-Learning,IEEE,Conferences,"Many research papers have reported studies on sports robots that realize giant-swing motion. However, almost all these robots were controlled using trajectory planning methods, and few robots realized giant-swing motion by learning. Consequently, in this study, we attempted to construct a humanoid robot that realizes giant-swing motion by Q-learning, a reinforcement learning technique. The significant aspect of our study is that few robotic models were constructed beforehand; the robot learns giant-swing motion only by interaction with the environment during simulations. Our implementation faced several problems such as imperfect perception of the velocity state and robot posture issues caused by using only the arm angle. However, our real robot realized giant-swing motion by averaging the Q value and by using rewards - the absolute angle of the foot angle and the angular velocity of the arm angle-in the simulated learning data; the sampling time was 250 ms. Furthermore, the feasibility of generalization of learning for realizing selective motion in the forward and backward rotational directions was investigated; it was revealed that the generalization of learning is feasible as long as it does not interfere with the robot's motions.",https://ieeexplore.ieee.org/document/5708353/,2010 IEEE/SICE International Symposium on System Integration,21-22 Dec. 2010,ieeexplore
10.1109/ICACEH51803.2020.9366217,Realization of Human and Fish Robot Interaction with Artificial Intelligence Using Hand Gesture,IEEE,Conferences,This study mimicked a real fish movement in the aquarium which was controlled by hand signals. The main idea to develop an aquarium robotic fish with hand gestures. Control actions include directions and stop and go of the fish. The inputs are given by human hands known as bio-mimetic ornamental. We implemented control algorithms to recognize hand gestures. The experimental results showed the effective control of robot fish with hand gestures.,https://ieeexplore.ieee.org/document/9366217/,"2020 IEEE 2nd International Conference on Architecture, Construction, Environment and Hydraulics (ICACEH)",25-27 Dec. 2020,ieeexplore
10.1109/ICRA.2019.8794179,Realizing Learned Quadruped Locomotion Behaviors through Kinematic Motion Primitives,IEEE,Conferences,"Humans and animals are believed to use a very minimal set of trajectories to perform a wide variety of tasks including walking. Our main objective in this paper is two fold 1) Obtain an effective tool to realize these basic motion patterns for quadrupedal walking, called the kinematic motion primitives (kMPs), via trajectories learned from deep reinforcement learning (D-RL) and 2) Realize a set of behaviors, namely trot, walk, gallop and bound from these kinematic motion primitives in our custom four legged robot, called the “Stoch”. D-RL is a data driven approach, which has been shown to be very effective for realizing all kinds of robust locomotion behaviors, both in simulation and in experiment. On the other hand, kMPs are known to capture the underlying structure of walking and yield a set of derived behaviors. We first generate walking gaits from D-RL, which uses policy gradient based approaches. We then analyze the resulting walking by using principal component analysis. We observe that the kMPs extracted from PCA followed a similar pattern irrespective of the type of gaits generated. Leveraging on this underlying structure, we then realize walking in Stoch by a straightforward reconstruction of joint trajectories from kMPs. This type of methodology improves the transferability of these gaits to real hardware, lowers the computational overhead on-board, and also avoids multiple training iterations by generating a set of derived behaviors from a single learned gait.",https://ieeexplore.ieee.org/document/8794179/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/SMC.2019.8914044,Realizing an assembly task through virtual capture,IEEE,Conferences,"Modern manufacturing strategy requires the robotic infrastructure to be able to adapt to new products or to accomplish new tasks quickly. In order to respond to this demand, teaching a robot to realize a task by demonstration has regained popularity in recent years, especially for dual-arm or humanoid robots. One of the main issues using this method is to adapt the captured motion from the human demonstration to the robot's specific kinematics and control. In this paper we present a method where the motion and grasping adaptation is tackled during the capture. We demonstrate the validity of this method with an experiment where a humanoid robot realizes an assembly previously demonstrated by a user wearing a Head Mounted Display (HMD) performing an assembly task in a virtual environment.",https://ieeexplore.ieee.org/document/8914044/,"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)",6-9 Oct. 2019,ieeexplore
10.1109/GTSD50082.2020.9303087,Receptionist and Security Robot Using Face Recognition with Standardized Data Collecting Method,IEEE,Conferences,"Face recognition has become the front runner for deep learning applications in the real world and this paper focuses on its implementation in a human-robot interaction and security system. For this specific project, it is inherent that restraints are created to allow the system to produce greater performance within the requirements of a receptionist and security robot. A k-nearest neighbors classifier is applied to further enhance the accuracy of face recognition. By sequencing images from videos, we create large datasets to train our own classifier in various conditions to increase its accuracy and lower false-positive rates in poor lighting environments. With the goal of creating a service robot, we have standardized our method of data collection for new inputs that will assist the recognition process in variable conditions of operation. The resulting product is a system that can accurately predict known and unknown faces with Asian features.",https://ieeexplore.ieee.org/document/9303087/,2020 5th International Conference on Green Technology and Sustainable Development (GTSD),27-28 Nov. 2020,ieeexplore
10.1109/IRDS.2002.1043897,Recognizing and remembering individuals: online and unsupervised face recognition for humanoid robot,IEEE,Conferences,"Individual recognition is a widely reported phenomenon in the animal world, where it contributes to successful maternal interaction, parental care, group breeding, cooperation, mate choice, etc. This work addresses the question of how one may implement such social competence in a humanoid robot. We argue that the robot must be able to recognize people and learn about their various characteristics through embodied social interaction. Thus, we proposed an initial implementation of an online and unsupervised face recognition system for Kismet, our sociable robotic platform. We show how specific features of this particular application drove our decision and implementation process, challenged by the difficulty of the face recognition problem, which has so far been explored in the supervised manner. Experimental results are reported to illustrate what was solved and the lessons learned from the current implementation.",https://ieeexplore.ieee.org/document/1043897/,IEEE/RSJ International Conference on Intelligent Robots and Systems,30 Sept.-4 Oct. 2002,ieeexplore
10.1109/ECAI.2014.7090222,Reconfigurable robotic system based on mono-camera guidance,IEEE,Conferences,"The paper proposes an intelligent robotic system which is able to be (re)configured, at demand, for two deployment scenarios. a) The first task is to move the platform after a trajectory determined by the direction to a fixed point and avoid any obstacles occurring in the route. a) The second task is to identify and track a spherical object. The robot is equipped with a navigation system designed to maintain direction in case of interruption of video contact with the target (landmark), meaning when an obstacle interposes. It has two main subsystems: the mobile platform, which is equipped with a video camera and sensors for path correction, and the central processing system for the analysis of received information. The task control is based on extracted features from images. The communication between them is done via a wireless protocol. Algorithms for controlling the mobile platform are implemented on the embedded microcontroller and algorithms for image processing are implemented on the central system.",https://ieeexplore.ieee.org/document/7090222/,"Proceedings of the 2014 6th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)",23-25 Oct. 2014,ieeexplore
10.1109/BioRob49111.2020.9224392,Reinforcement Learning Assist-as-needed Control for Robot Assisted Gait Training,IEEE,Conferences,"The primary goal of an assist-as-needed (AAN) controller is to maximize subjects' active participation during motor training tasks while allowing moderate tracking errors to encourage human learning of a target movement. Impedance control is typically employed by AAN controllers to create a compliant force-field around the desired motion trajectory. To accommodate different individuals with varying motor abilities, most of the existing AAN controllers require extensive manual tuning of the control parameters, resulting in a tedious and time-consuming process. In this paper, we propose a reinforcement learning AAN controller that can autonomously reshape the force-field in real-time based on subjects' training performances. The use of action-dependent heuristic dynamic programming enables a model-free implementation of the proposed controller. To experimentally validate the controller, a group of healthy individuals participated in a gait training session wherein they were asked to learn a modified gait pattern with the help of a powered ankle-foot orthosis. Results indicated the potential of the proposed control strategy for robot-assisted gait training.",https://ieeexplore.ieee.org/document/9224392/,2020 8th IEEE RAS/EMBS International Conference for Biomedical Robotics and Biomechatronics (BioRob),29 Nov.-1 Dec. 2020,ieeexplore
10.1109/ICRA.2019.8793627,Reinforcement Learning Meets Hybrid Zero Dynamics: A Case Study for RABBIT,IEEE,Conferences,"The design of feedback controllers for bipedal robots is challenging due to the hybrid nature of its dynamics and the complexity imposed by high-dimensional bipedal models. In this paper, we present a novel approach for the design of feedback controllers using Reinforcement Learning (RL) and Hybrid Zero Dynamics (HZD). Existing RL approaches for bipedal walking are inefficient as they do not consider the underlying physics, often requires substantial training, and the resulting controller may not be applicable to real robots. HZD is a powerful tool for bipedal control with local stability guarantees of the walking limit cycles. In this paper, we propose a non traditional RL structure that embeds the HZD framework into the policy learning. More specifically, we propose to use RL to find a control policy that maps from the robot's reduced order states to a set of parameters that define the desired trajectories for the robot's joints through the virtual constraints. Then, these trajectories are tracked using an adaptive PD controller. The method results in a stable and robust control policy that is able to track variable speed within a continuous interval. Robustness of the policy is evaluated by applying external forces to the torso of the robot. The proposed RL framework is implemented and demonstrated in OpenAI Gym with the MuJoCo physics engine based on the well-known RABBIT robot model.",https://ieeexplore.ieee.org/document/8793627/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/CIRA.2007.382878,Reinforcement Learning with a Supervisor for a Mobile Robot in a Real-world Environment,IEEE,Conferences,"This paper describes two experiments with supervised reinforcement learning (RL) on a real, mobile robot. Two types of experiments were preformed. One tests the robot's reliability in implementing a navigation task it has been taught by a supervisor. The other, in which new obstacles are placed along the previously learned path to the goal, measures the robot's robustness to changes in environment. Supervision consisted of human-guided, remote-controlled runs through a navigation task during the initial stages of reinforcement learning. The RL algorithms deployed enabled the robot to learn a path to a goal yet retain the ability to explore different solutions when confronted with a new obstacle. Experimental analysis was based on measurements of average time to reach the goal, the number of failed states encountered during an episode, and how closely the RL learner matched the supervisor's actions.",https://ieeexplore.ieee.org/document/4269878/,2007 International Symposium on Computational Intelligence in Robotics and Automation,20-23 June 2007,ieeexplore
10.1109/FUZZY.1998.687475,Reinforcement function design and bias for efficient learning in mobile robots,IEEE,Conferences,"The main paradigm in sub-symbolic learning robot domain is the reinforcement learning method. Various techniques have been developed to deal with the memorization/generalization problem, demonstrating the superior ability of artificial neural network implementations. In this paper, we address the issue of designing the reinforcement so as to optimize the exploration part of the learning. We also present and summarize works relative to the use of bias intended to achieve the effective synthesis of the desired behavior. Demonstrative experiments involving a self-organizing map implementation of the Q-learning and real mobile robots (Nomad 200 and Khepera) in a task of obstacle avoidance behavior synthesis are described.",https://ieeexplore.ieee.org/document/687475/,1998 IEEE International Conference on Fuzzy Systems Proceedings. IEEE World Congress on Computational Intelligence (Cat. No.98CH36228),4-9 May 1998,ieeexplore
10.1109/ROBOT.2010.5509336,Reinforcement learning of motor skills in high dimensions: A path integral approach,IEEE,Conferences,"Reinforcement learning (RL) is one of the most general approaches to learning control. Its applicability to complex motor systems, however, has been largely impossible so far due to the computational difficulties that reinforcement learning encounters in high dimensional continuous state-action spaces. In this paper, we derive a novel approach to RL for parameterized control policies based on the framework of stochastic optimal control with path integrals. While solidly grounded in optimal control theory and estimation theory, the update equations for learning are surprisingly simple and have no danger of numerical instabilities as neither matrix inversions nor gradient learning rates are required. Empirical evaluations demonstrate significant performance improvements over gradient-based policy learning and scalability to high-dimensional control problems. Finally, a learning experiment on a robot dog illustrates the functionality of our algorithm in a real-world scenario. We believe that our new algorithm, Policy Improvement with Path Integrals (PI<sup>2</sup>), offers currently one of the most efficient, numerically robust, and easy to implement algorithms for RL in robotics.",https://ieeexplore.ieee.org/document/5509336/,2010 IEEE International Conference on Robotics and Automation,3-7 May 2010,ieeexplore
10.1109/ICSMC.2012.6377767,Reinforcement learning-based tracking control for wheeled mobile robot,IEEE,Conferences,This paper proposes a new method to design a reinforcement learning-based integrated kinematic and dynamic tracking control scheme for a nonholonomic wheeled mobile robot. The scheme uses just only one neural network to design an online adaptive synchronous policy iteration algorithm implemented as an actor critic structure. Our tuning law for the single neural network not only learns online a tracking-HJB equation to approximate both the optimal cost and the optimal adaptive control law but also guarantees closed-loop stability in real-time. The convergence and stability of the overall system are proven by Lyapunov theory. The simulation results for wheeled mobile robot verify the effectiveness of the proposed controller.,https://ieeexplore.ieee.org/document/6377767/,"2012 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",14-17 Oct. 2012,ieeexplore
10.1109/CYBER.2012.6392582,Reinforecement learning-based optimal tracking control for wheeled mobile robot,IEEE,Conferences,This paper proposes a new method to design a reinforcement learning-based integrated kinematic and dynamic tracking control scheme for a nonholonomic wheeled mobile robot. The scheme uses just only one neural network to design an online adaptive synchronous policy iteration algorithm implemented as an actor critic structure. Our tuning law for the single neural network not only learns online a tracking-HJB equation to approximate both the optimal cost and the optimal control law but also guarantees closed-loop stability in real-time. The convergence and stability of the overall system are proven by Lyapunov theory. The simulation results for wheeled mobile robot verify the effectiveness of the proposed controller.,https://ieeexplore.ieee.org/document/6392582/,"2012 IEEE International Conference on Cyber Technology in Automation, Control, and Intelligent Systems (CYBER)",27-31 May 2012,ieeexplore
10.1109/WCICA.2008.4593442,Research and realization on multi-robot parking mission strategy,IEEE,Conferences,"Aiming at the complexity and unknown of the modern robot-team parking mission environment, we proposed the maximal obsidional uniform distribution principle, the first nearest parking-point was enclosed by another parking-point according to uniform distribution. Based on it, we used the ldquoHungary Methodrdquo to realize the shortest total path length parking strategy. It was to form a benefit matrix which was composed of each the outside path length of the inclosing circle from robots to parking points, and then the best assignment was obtained by using ldquoHungary Methodrdquo. In this paper, itpsilas also considered two parking assignment strategies, which were shortest system executing time strategy and scope of inclosing circle seeable view strategy. The experiment result is shown that the robot-team can complete the reconnaissance parking mission efficiently. Additionally, the real-time performance is also fine.",https://ieeexplore.ieee.org/document/4593442/,2008 7th World Congress on Intelligent Control and Automation,25-27 June 2008,ieeexplore
10.1109/IAI50351.2020.9262210,Research on Hardware-in-loop Simulation Platform of Anti-swing Control for Helicopter Suspension,IEEE,Conferences,"In order to solve the problems of long preparation period, high cost and high risk in anti-swing control test for real helicopter, a hardware-in-loop(HIL) simulation platform of anti-swing control for helicopter slung load system is designed. 6-DOF robot is employed to imitate the movement of the slung load for helicopter, and the large swing of the slung load in the longitudinal direction the fuselage is simulated by external control rail with robot arm. In this paper, the anti-swing controller is designed to realize the anti-swing control of the helicopter slung-load, at the same time, hardware-in-loop simulation experiment is carried out. The experimental results show that the swing angle/angular velocity of the slung load which relative to the fuselage in the lateral and longitudinal directions can converge and close to zero gradually, meanwhile the vibration amplitude of the robot becomes more and more smaller. So it proves that the hardware-in-loop simulation platform can be used to study anti-swing control for helicopter suspension.",https://ieeexplore.ieee.org/document/9262210/,2020 2nd International Conference on Industrial Artificial Intelligence (IAI),23-25 Oct. 2020,ieeexplore
10.1109/ACCTCS52002.2021.00055,Research on Loop Closure Detection Method Based on ResNet,IEEE,Conferences,"SLAM technology is an important basis for autonomous navigation of robots, and loop closure detection is an important part of SLAM technology. Its task is to identify whether the robot has moved to its current position, which has a good role in drawing map. In this paper, a feature extraction model is obtained by training the custom data set on the ResNet50 residual network, which can extract features with better robustness. Then, the twin-network and terny-loss function are introduced to improve the network performance through weak supervised training. Finally, the cosine similarity method is used to calculate the similarity<sup>[6]</sup>. If the similarity exceeds the threshold, it is considered that there is a loop. After the comparison experiment between the proposed method and the traditional method on the open data set, it is found that the ResNet50 network model improves the feature extraction ability and the loop detection accuracy, which proves the feasibility and application value of this paper.",https://ieeexplore.ieee.org/document/9407669/,2021 Asia-Pacific Conference on Communications Technology and Computer Science (ACCTCS),22-24 Jan. 2021,ieeexplore
10.1109/IWECAI50956.2020.00040,Research on Multi-robot Task Allocation Algorithm Based on HADTQL,IEEE,Conferences,"This paper proposes forward a Heuristically Accelerated Dynamic Team Q-learning (HADTQL) algorithm for solving multi-robot collaborative task allocation problem based on multi-agent reinforcement learning. It aims at making multiple robots collaborate to avoid all obstacles and accomplish all tasks while optimizing the path they took relatively. Firstly, the author constructs an appropriate state action space according to the specific information about the environment. Secondly, the whole learning process is divided into two stages by using dynamic exploration coefficient, which ensures the diversity of the early learning and the stability of the later learning. Thirdly, in order to help robots with reasonable action selection, the improved reward function is adopted to provide real-time rewards by utilizing the experience generated by the reinforcement learning of multiple agents. Finally, the heuristic function is introduced to guide the multi-agent reinforcement learning for the next action selection. The simulation experiment shows that the proposed algorithm can find an optimal task execution sequence and complete all tasks collaboratively with a relatively optimal path under the premise of avoiding obstacles in the environment automatically. Compared with the Team Q-learning (TQL) algorithm, this algorithm can allocate tasks reasonably with the high effectiveness and practicability.",https://ieeexplore.ieee.org/document/9221763/,2020 International Workshop on Electronic Communication and Artificial Intelligence (IWECAI),12-14 June 2020,ieeexplore
10.1109/AIID51893.2021.9456477,Research on Privacy Protection Technology in Face Identity Authentication System Based on Edge Computing,IEEE,Conferences,"In today's society, the rapid development of the Internet makes People's Daily life become more intelligent and diversified. Today's society has entered a multifaceted era where everything is interconnected. Artificial intelligence technology is gradually replacing some traditional human services, such as intelligent robot customer service instead of traditional human customer service, intelligent face scanning security check in railway stations instead of traditional manual ticket checking, unmanned supermarket automatic checkout has liberated some social labor costs. All these changes are the result of the development of artificial intelligence technology in today's society. In recent years, unicorn startups focused on biometrics have sprung up all around us, such as BTU and its MEG VII (Face ++). Thanks to the development of Internet and artificial intelligence technology, in many application fields, the traditional access control and identity authentication technology based on password verification is gradually transforming to the scheme based on biometric identification verification. Secure identity authentication is very important to the application of Internet. Face recognition is the most popular technology among all biometric identification technologies. In the field of biometric identification technology, it has become the most widely used technology in the field of identity authentication because of its unique non-invasive, support for infrared and visible light, no need for user cooperation and many other advantages. In the field of education, examinee identification, pedestrian identification detection at the entrance of railway stations, face electronic payment, intelligent video surveillance system, intelligent attendance and access control system, intelligent unmanned supermarkets and customs clearance ports become the pioneer fields of face recognition applications. It can be seen that the era of “national face brushing” has arrived, and the application of face recognition technology will only be more and more widespread in the current era and in the future. However, due to the sensitivity of biometric data and the heterogeneity and openness of network environment, the privacy leakage of biometric data is difficult to avoid. At present, fog computing and edge computing have been paid more and more attention in many fields. In the case that cloud service providers are unable to provide sufficient security, edge computing shows its advantages. In this paper, mobile edge computing is introduced for the first time into the face privacy protection identity authentication system based on cloud server outsourcing computing. It can not only greatly reduce the interaction frequency between users and cloud server, improve the availability and fault tolerance of the system, but also contribute to the implementation of privacy protection scheme. A deep constitutional neural network for face feature extraction is trained using deep learning framework Cafe. Cosine similarity is used to complete face verification. A privacy protection scheme based on the secure nearest neighbor algorithm is proposed, which can not only protect the security of the face feature data at the edge computing node, but also allow the edge computing node to complete the face recognition operation against the encrypted face feature data. In addition, the encryption scheme does not require large computing resources, and the accuracy of face recognition in cipher text is exactly the same as that in explain. At present, most of the solutions either have high computational complexity or poor security performance. How to reduce the computational complexity and improve the real-time performance of the system while ensuring the high security of the private data has important research significance and value. Therefore, in the cloud server outsourcing computing environment, how to complete biometric identification on the premise of protecting the privacy of biological data has become a research hot spot.",https://ieeexplore.ieee.org/document/9456477/,2021 IEEE International Conference on Artificial Intelligence and Industrial Design (AIID),28-30 May 2021,ieeexplore
10.1109/CESA.2006.4281951,Research on RBF-PID Control for the 6-DOF Motion Base in Construction Tele-robot System,IEEE,Conferences,"In this paper, according to the real experiment device, we deduced the model of the electro-hydraulic servo valve and the dissymmetric hydraulic cylinder, a new RBF-PID controller was developed based on it to form a closed-loop system for the 6-DOF motion base in a tele-robotic system. To verify the validity of the design, a simulation is done. The simulation results show that RBF neural network is effective for electro hydraulic servo control systems. To control the 6-DOF realistic motions according to the signals of six acceleration sensors on the construction tele-robot, an experiment is also done. The validity of the control system was confirmed by experiment result. The control system performs steadily. And the experimental result indicates that the RBF neural network can enhances the robust control, which has reality significance.",https://ieeexplore.ieee.org/document/4281951/,"The Proceedings of the Multiconference on ""Computational Engineering in Systems Applications""",4-6 Oct. 2006,ieeexplore
10.1109/ICMA.2019.8816557,Research on V-SLAM Methods,IEEE,Conferences,"With the development of intelligent mobile robots, SLAM, especially V-SLAM, as the basic technology of robot localization and navigation, has the advantages of strong adaptability, high precision and strong intelligence compared with the traditional localization technology. It is widely used in smart devices such as unmanned aerial vehicle, automatic driving and sweeping robots. According to different implementation methods, the visual SLAM is divided into: filter V-SLAM based on probability model, key frame BA-based V-SLAM using nonlinear optimization theory, direct tracking of V-SLAM under the assumption of luminosity invariance, space occupying V-SLAM that focuses on building three-dimensional dense maps. This paper focuses on representative systems of various V-SLAMs and gives their respective applicable scenarios and characteristics. Finally, this article forecasts the development of V-SLAM combining with multi-information fusion technology, semantic deep and learning technology.",https://ieeexplore.ieee.org/document/8816557/,2019 IEEE International Conference on Mechatronics and Automation (ICMA),4-7 Aug. 2019,ieeexplore
10.1109/RCAR49640.2020.9303274,Research on navigation system of AMR based on ROS,IEEE,Conferences,"With the coming of the era of artificial intelligence, AMR brings convenience to many fields and becomes the research hotspot in the field of robot.This paper designs an AMR based on the ROS operating system, which uses the lidar as the sensing sensor and the self-made wire controlled chassis as the mobile platform.AMR combines cartographer algorithm and move base path planning algorithm to achieve the rapid tracking of the surrounding environment and target points.It can be seen from the experiment that AMR can quickly and accurately build the global map without any deviation in the process of moving, and its mapping accuracy is relatively stable.",https://ieeexplore.ieee.org/document/9303274/,2020 IEEE International Conference on Real-time Computing and Robotics (RCAR),28-29 Sept. 2020,ieeexplore
10.1109/RCAR47638.2019.9044114,Research on omnidirectional mobile robot motion control based on integration of traction and steering wheel,IEEE,Conferences,"In order to solve the automatic transportation of heavy materials under the limited working space of production workshops and warehouses, two sets of heavy-duty omnidirectional mobile robot motion control systems with steering wheel drive units were designed. The steering wheel combination drive unit of the “walking + steering” set is used to build the mobile robot chassis, and the mechatronics servo system and mathematical model of multi-motor coordinated motion are constructed. The communication between the controller and the steering wheel combination drive unit is established through the CAN bus. The specific implementation is to capture and analyze the control signal through the controller to obtain the desired motion mode, to obtain the motion of each set of steering wheel unit through the mathematical model, and to realize the desired motion through the synthesis of each set of steering wheel unit motion. It has been verified by experiments that the two sets of steering wheel unit-driven mobile robot control system realizes the zero turning radius, 360-degree omnidirectional movement of the robot and rotation during the movement. It can be used for flexible work in tight spaces.",https://ieeexplore.ieee.org/document/9044114/,2019 IEEE International Conference on Real-time Computing and Robotics (RCAR),4-9 Aug. 2019,ieeexplore
10.1109/WCICA.2004.1343675,Research on remote controlled robot motion control system based on agent theory,IEEE,Conferences,"This paper introduces remote controlled robot motion control system based on agent theory. Task planning and reactive behavior control are discussed and implemented. This paper describes design of manager agent and motion control agent in detail. Agent theory are implemented in the robot control system to realize distributed intelligence based on M/A/R(Man/Agent/Robot) architecture. Thereby autonomy, reliability and real-time operation are improved.",https://ieeexplore.ieee.org/document/1343675/,Fifth World Congress on Intelligent Control and Automation (IEEE Cat. No.04EX788),15-19 June 2004,ieeexplore
10.1109/ICRA.2019.8794127,Residual Reinforcement Learning for Robot Control,IEEE,Conferences,"Conventional feedback control methods can solve various types of robot control problems very efficiently by capturing the structure with explicit models, such as rigid body equations of motion. However, many control problems in modern manufacturing deal with contacts and friction, which are difficult to capture with first-order physical modeling. Hence, applying control design methodologies to these kinds of problems often results in brittle and inaccurate controllers, which have to be manually tuned for deployment. Reinforcement learning (RL) methods have been demonstrated to be capable of learning continuous robot controllers from interactions with the environment, even for problems that include friction and contacts. In this paper, we study how we can solve difficult control problems in the real world by decomposing them into a part that is solved efficiently by conventional feedback control methods, and the residual which is solved with RL. The final control policy is a superposition of both control signals. We demonstrate our approach by training an agent to successfully perform a real-world block assembly task involving contacts and unstable objects.",https://ieeexplore.ieee.org/document/8794127/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/BWCCA.2014.115,Response Surface Learning for Face Misalignment Correction,IEEE,Conferences,"Face recognition is an important technique for Natural User Interface (NUI) and Human Robot Interaction (HRI) and many of the current state-of-the-art face recognition techniques are based on the local features which are extracted from a face alignment method like Constrained Local Model (CLM). But, in a real world environment, face alignment methods often fail to correctly localize the features because of extreme variations in pose and illumination. In this paper, we propose a learning-based misalinment detection and correction method. From the experiment, it is shown that the accuracy of the existing face alignment methods can be improved using the proposed method which re-aligns a misaligned result with a corrected parameter.",https://ieeexplore.ieee.org/document/7016133/,"2014 Ninth International Conference on Broadband and Wireless Computing, Communication and Applications",8-10 Nov. 2014,ieeexplore
10.1109/ICCSCE.2015.7482163,Review on simultaneous localization and mapping (SLAM),IEEE,Conferences,"Simultaneous localization and mapping (SLAM) is a technique applied in artificial intelligence mobile robot for a self-exploration in numerous geographical environment. SLAM becomes fundamental research area in recent days as it promising solution in solving most of problems which related to the self-exploratory oriented artificial intelligence mobile robot field. For example, the capability to explore without any prior knowledge on environment it explores and without any human interference. The unique feature in SLAM is that the process of mapping and localization is done concurrently and recursively. Since SLAM introduction, many SLAM algorithms have been proposed to apply SLAM technique in real practice. The aim of this paper is to provide an insightful review on information background, recent development, feature, implementation and recent issue in SLAM.",https://ieeexplore.ieee.org/document/7482163/,"2015 IEEE International Conference on Control System, Computing and Engineering (ICCSCE)",27-29 Nov. 2015,ieeexplore
10.1109/ICRA.2012.6225085,Risk-Sensitive Optimal Feedback Control for Haptic Assistance,IEEE,Conferences,"While human behavior prediction can increase the capability of a robotic partner to generate anticipatory behavior during physical human robot interaction (pHRI), predictions in uncertain situations can lead to large disturbances for the human if they do not match the human intentions. In this paper we present a novel control concept in which the assistive control parameters are adapted to the uncertainty in the sense that a the robot takes a more or less active role depending on its confidence in the human behavior prediction. The approach is based on risk-sensitive optimal feedback control. The human behavior is modeled using probabilistic learning methods and any unexpected disturbance is considered as a source of noise. The proposed approach is validated in situations with different uncertainties, process noise and risk-sensitivities in a tow- Degree-of-Freedom virtual reality experiment.",https://ieeexplore.ieee.org/document/6225085/,2012 IEEE International Conference on Robotics and Automation,14-18 May 2012,ieeexplore
10.1109/IROS45743.2020.9341469,Risk-Sensitive Sequential Action Control with Multi-Modal Human Trajectory Forecasting for Safe Crowd-Robot Interaction,IEEE,Conferences,"This paper presents a novel online framework for safe crowd-robot interaction based on risk-sensitive stochastic optimal control, wherein the risk is modeled by the entropic risk measure. The sampling-based model predictive control relies on mode insertion gradient optimization for this risk measure as well as Trajectron++, a state-of-the-art generative model that produces multimodal probabilistic trajectory forecasts for multiple interacting agents. Our modular approach decouples the crowd-robot interaction into learning-based prediction and model-based control, which is advantageous compared to end-to-end policy learning methods in that it allows the robot's desired behavior to be specified at run time. In particular, we show that the robot exhibits diverse interaction behavior by varying the risk sensitivity parameter. A simulation study and a real-world experiment show that the proposed online framework can accomplish safe and efficient navigation while avoiding collisions with more than 50 humans in the scene.",https://ieeexplore.ieee.org/document/9341469/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ROBIO49542.2019.8961517,Robot Control in Human Environment using Deep Reinforcement Learning and Convolutional Neural Network,IEEE,Conferences,"Deep reinforcement learning (DRL) has been employed in numerous applications where complex decision-making is needed. Robot control in a human environment is an example. Such algorithm offers possibilities to achieve end-to-end training which learns from image directly. However, training on a physical robotic system under human environments using DRL is inefficient and even dangerous. Several recent works have used simulators for training models before implementing to physical robots. Although simulation provides efficiency to obtain DRL trained models, it poses challenges for the transformation from simulation to reality. Since a human environment is often cluttered, dynamic and complex, the policy trained with simulation images is not applicable for reality. Therefore, in this paper, we propose a DRL method to achieve end-to-end training in simulation, as well as to adapt to reality without any further finetune. Firstly, a Deep Deterministic Policy Gradient algorithm (DDPG) is employed to learn policy for robot control. Secondly, a pre-trained Convolutional Neural Network algorithm (CNN) is used to visually track the target in image. This technique provides the efficient and safe DRL training in simulation while offering robust application when a real robot is placed in dynamic human environment. Simulation and experiment are conducted for validation and can be seen in the attached video. The results have shown successful demonstration under various complex environments.",https://ieeexplore.ieee.org/document/8961517/,2019 IEEE International Conference on Robotics and Biomimetics (ROBIO),6-8 Dec. 2019,ieeexplore
10.1109/SAIS53221.2021.9483964,Robot First Aid: Autonomous Vehicles Could Help in Emergencies,IEEE,Conferences,"Safety is of critical importance in designing autonomous vehicles (AVs) that will be able to perform effectively in complex, mixed-traffic, real-world urban environments. Some prior research has looked at how to proactively avoid accidents with safe distancing and driver monitoring, but currently little research has explored strategies to recover afterwards from emergencies, from crime to natural disasters. The current short paper reports on our ongoing work using a speculative prototyping approach to explore this expansive design space, in the context of how a robot inside an AV could be deployed to support first aid. As a result, we present some proposals for how to detect emergencies, and examine and help victims, as well as lessons learned in prototyping. Thereby, our aim is to stimulate discussion and ideation that-by considering the prevalence of Murphy's law in our complex world, and the various technical, ethical, and practical concerns raised-could potentially lead to useful safety innovations.",https://ieeexplore.ieee.org/document/9483964/,2021 Swedish Artificial Intelligence Society Workshop (SAIS),14-15 June 2021,ieeexplore
10.1109/IROS.2010.5650949,Robot Learning by Demonstration with local Gaussian process regression,IEEE,Conferences,"In recent years there was a tremendous progress in robotic systems, and however also increased expectations: A robot should be easy to program and reliable in task execution. Learning from Demonstration (LfD) offers a very promising alternative to classical engineering approaches. LfD is a very natural way for humans to interact with robots and will be an essential part of future service robots. In this work we first review heteroscedastic Gaussian processes and show how these can be used to encode a task. We then introduce a new Gaussian process regression model that clusters the input space into smaller subsets similar to the work in [11]. In the next step we show how these approaches fit into the Learning by Demonstration framework of [2], [3]. At the end we present an experiment on a real robot arm that shows how all these approaches interact.",https://ieeexplore.ieee.org/document/5650949/,2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,18-22 Oct. 2010,ieeexplore
10.1109/IROS40897.2019.8968306,Robot Learning via Human Adversarial Games,IEEE,Conferences,"Much work in robotics has focused on “humanin-the-loop” learning techniques that improve the efficiency of the learning process. However, these algorithms have made the strong assumption of a cooperating human supervisor that assists the robot. In reality, human observers tend to also act in an adversarial manner towards deployed robotic systems. We show that this can in fact improve the robustness of the learned models by proposing a physical framework that leverages perturbations applied by a human adversary, guiding the robot towards more robust models. In a manipulation task, we show that grasping success improves significantly when the robot trains with a human adversary as compared to training in a self-supervised manner.",https://ieeexplore.ieee.org/document/8968306/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ICNSC48988.2020.9238090,Robot Navigation with Map-Based Deep Reinforcement Learning,IEEE,Conferences,"This paper proposes an end-to-end deep reinforcement learning approach for mobile robot navigation with dynamic obstacles avoidance. Using experience collected in a simulation environment, a convolutional neural network (CNN) is trained to predict proper steering actions of a robot from its egocentric local occupancy maps, which accommodate various sensors and fusion algorithms. The trained neural network is then transferred and executed on a real-world mobile robot to guide its local path planning. The new approach is evaluated both qualitatively and quantitatively in simulation and realworld robot experiments. The results show that the map-based end-to-end navigation model is easy to be deployed to a robotic platform, robust to sensor noise and outperforms other existing DRL-based models in many indicators.",https://ieeexplore.ieee.org/document/9238090/,"2020 IEEE International Conference on Networking, Sensing and Control (ICNSC)",30 Oct.-2 Nov. 2020,ieeexplore
10.1109/RCAR49640.2020.9303282,Robot Programming by Demonstration with Oral Instructions for Assembly,IEEE,Conferences,"Programming by demonstration has been seen as a feasible solution for transferring human's skills to robots without too much time and labor cost. So far, applications of programming by demonstration in industrial assembly have attracted many researchers' attention. In practice, the robot control policy must give consideration to both efficiency and precision. Furthermore, it is difficult for one policy to handle the whole assembly process. To deal with these issues, a programming by demonstration with oral instructions method is developed in this article. With oral instructions, the demonstration data are segmented into pre-assembly phase and precise assembly phase. Moreover two related assembly policies are learned independently. Task-parametrized Gaussian mixture model and dynamic movement primitive are selected to prestructure the assembly policies for the two phases respectively on accounting of their properties. Effectiveness of the proposed method has been demonstrated by an assembly experiment.",https://ieeexplore.ieee.org/document/9303282/,2020 IEEE International Conference on Real-time Computing and Robotics (RCAR),28-29 Sept. 2020,ieeexplore
10.1109/IJCNN.2010.5596709,Robot guiding with obstacle avoidance algorithm for uncertain enviroments based on DTCNN,IEEE,Conferences,"This paper introduces two applications of Discrete Time Cellular Non-Linear Networks (DTCNN) in a robot guiding avoiding obstacles algorithm and prove the feasibility of both applications: a high data rate one, using a CMOS camera, and small data rate one, using ultrasonic sensors. The key value of DTCNNs is the locally connections and the parallelism in processing. These characteristics permit a hardware implementation, in our case over a Field Programmable Gate Arraw (FPGA) and a real time template based algorithm processing. A camera and an ultrasonic sensor are used as avoiding obstacles system, requiring both implementations, different inputs informations: the first one complex environment information and the later for basic situations information where impulsive response is required. Both input can have an enhanced behaviour within DTCNN structure.",https://ieeexplore.ieee.org/document/5596709/,The 2010 International Joint Conference on Neural Networks (IJCNN),18-23 July 2010,ieeexplore
10.1109/MECHATRONIKA.2014.7018286,Robot imitation of human arm via Artificial Neural Network,IEEE,Conferences,"In this study, a robot arm that can imitate human arm is designed and presented. The potentiometers are located to the joints of the human arm in order to detect movements of human gestures, and data were collected by this way. The collected data named as “movement of human arm” are classified by the help of Artificial Neural Network (ANN). The robot performs its movements according to the classified movements of the human. Real robot and real data are used in this study. Obtained results show that the learning application of imitating human action via the robot was successfully implemented. With this application, the platforms of robot arm in an industrial environment can be controlled more easily; on the other hand, robotic automation systems which have the capability of making a standard movements of a human can become more resistant to the errors.",https://ieeexplore.ieee.org/document/7018286/,Proceedings of the 16th International Conference on Mechatronics - Mechatronika 2014,3-5 Dec. 2014,ieeexplore
10.1109/ICRA48506.2021.9561545,Robot in a China Shop: Using Reinforcement Learning for Location-Specific Navigation Behaviour,IEEE,Conferences,"Robots need to be able to work in multiple different environments. Even when performing similar tasks, different behaviour should be deployed to best fit the current environment. In this paper, We propose a new approach to navigation, where it is treated as a multi-task learning problem. This enables the robot to learn to behave differently in visual navigation tasks for different environments while also learning shared expertise across environments. We evaluated our approach in both simulated environments as well as real-world data. Our method allows our system to converge with a 26% reduction in training time, while also increasing accuracy.",https://ieeexplore.ieee.org/document/9561545/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/ICSMC.2008.4811760,Robot navigation using KFLANN place field,IEEE,Conferences,"This paper presents an implementation of place cells for a robot navigation using the K-iterations fast learning artificial neural networks (KFLANN) clustering algorithm. The KFLANN possesses several desirable properties suitable for place cell robot navigation tasks. The technique proposed is able to autonomously adjust the resolution of cells according to the complexity of the environment. This is achieved through two parameters known as the tolerance and the vigilance of the network. In addition, a navigation system consisting of a topological map building and a place cell path planning strategy is presented. A physical implementation of the system was developed on an autonomous platform and actual results were obtained. The experimental results obtained indicate that the system was able to navigate successfully through the experimental space and also tolerate unexpected discrepancies arising from motor and sensor errors present in a real environment. Furthermore, despite abrupt changes in an environment due to the deliberate introduction of obstacles, the system was still able to cope without changes to the program. The experiment was also extended to include a kidnapped robot scenario and the results were favorable, indicating a positive use of allothetic cue recognition capabilities.",https://ieeexplore.ieee.org/document/4811760/,"2008 IEEE International Conference on Systems, Man and Cybernetics",12-15 Oct. 2008,ieeexplore
10.1109/IISA.2017.8316452,Robot painting recognition based on deep belief learning,IEEE,Conferences,"In a society where the number of elderly people is increasing rapidly, autonomous wheelchair robots are expected to be widely used for mobility of elderly people. In this paper we focus on how we can utilize wheelchair robots operating in museums. In this paper, we propose a deep learning based painting recognition and its application for the wheelchair robot. We consider the case when the user clicks on the painting he/she wants to see. The robot searches, recognizes and reaches the painting using deep learning. This is in difference from the most traditional methods where the robot explains the exhibited objects in a sequential order. The deep neural network generates a series of high dimensional features for each painting resulting in a high recognition rate. In our implementation, the wheelchair robot recognizes the painting in real time using the video stream.",https://ieeexplore.ieee.org/document/8316452/,"2017 8th International Conference on Information, Intelligence, Systems & Applications (IISA)",27-30 Aug. 2017,ieeexplore
10.1109/SMC.2016.7844958,Robot position control in pipes using Q Learning,IEEE,Conferences,"In the most critical hydro crisis in Brazil, 37 percent of the whole amount of treated water is wasted before reaching consumers. A robot with a position control to travel inside a pipe is an important step in the pursuit of an autonomous solution to detect and correct pipes failures. This paper shows a Q Learning controller algorithm implemented using a microcontroller in a mechanical body of a commercial pipe inspection robot. Using only the measurements of a gyroscope, and controlling the wheels' motors on the left and right sides, the controller learned the best set of movements to ride inside a 300mm sewer pipe, in the tested conditions. Real tests in a 300mm pipe were performed using the developed algorithm and it was compared to a random movement and to a straight forward movement.",https://ieeexplore.ieee.org/document/7844958/,"2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",9-12 Oct. 2016,ieeexplore
10.1145/1957656.1957814,Robot self-initiative and personalization by learning through repeated interactions,IEEE,Conferences,"We have developed a robotic system that interacts with the user, and through repeated interactions, adapts to the user so that the system becomes semi-autonomous and acts proactively. In this work we show how to design a system to meet a user's preferences, show how robot pro-activity can be learned and provide an integrated system using verbal instructions. All these behaviors are implemented in a real platform that achieves all these behaviors and is evaluated in terms of user acceptability and efficiency of interaction.",https://ieeexplore.ieee.org/document/6281377/,2011 6th ACM/IEEE International Conference on Human-Robot Interaction (HRI),8-11 March 2011,ieeexplore
10.1109/ROBIO.2011.6181679,"Robot self-preservation and adaptation to user preferences in game play, a preliminary study",IEEE,Conferences,"It is expected that in a near future, personal robots will be endowed with enough autonomy to function and live in an individual's home. This is while commercial robots are designed with default configuration and factory settings which may often be different to an individual's operating preferences. This paper presents how reinforcement learning is applied and utilised towards personalisation of a robot's behaviour. Two-level reinforcement learning has been implemented: first level is in charge of energy autonomy, i.e. how to survive, and second level is involved in adapting robot's behaviour to user's preferences. In both levels Q-learning algorithm has been applied. First level actions have been learnt in a simulated environment and then the results have been transferred to the real robot. Second level has been fully implemented in the real robot and learnt by human-robot interaction. Finally, experiments showing the performance of the system are presented.",https://ieeexplore.ieee.org/document/6181679/,2011 IEEE International Conference on Robotics and Biomimetics,7-11 Dec. 2011,ieeexplore
10.1109/ROMAN.1995.531984,Robot teaching with operating stick using the virtual reality system,IEEE,Conferences,"A new robot teaching system using the virtual reality technology is constructed. Operations in the point-to-point type robot teaching system are classified. Problems in the conventional system with data glove input device are clarified. Instead of data glove input, a new method using operating stick is proposed and the corresponding robot teaching with operating stick is presented. Experiments on robot teaching using operating stick are carried out and the results are discussed in detail. The effectiveness of the new method was confirmed by the experiment results.",https://ieeexplore.ieee.org/document/531984/,Proceedings 4th IEEE International Workshop on Robot and Human Communication,5-7 July 1995,ieeexplore
10.1109/RO-MAN47096.2020.9223428,Robot-Assisted Mindfulness Practice: Analysis of Neurophysiological Responses and Affective State Change,IEEE,Conferences,"Mindfulness is the state of paying attention to the present moment on purpose and meditation is the technique to obtain this state. This study aims to develop a robot assistant that facilitates mindfulness training by means of a Brain-Computer Interface (BCI) system. To achieve this goal, we collected EEG signals from two groups of subjects engaging in a meditative vs. non-meditative human-robot interaction (HRI) and evaluated cerebral hemispheric asymmetry, which is recognized as a well-defined indicator of emotional states. Moreover, using self-reported affective states, we strived to explain asymmetry changes based on pre- and post-experiment mood alterations. We found that unlike earlier meditation studies, the fronto-central activations in alpha and theta frequency bands were not influenced by robot-guided mindfulness practice, however there was a significantly greater right-sided activity in the occipital gamma band of Meditation group, which is attributed to increased sensory awareness and open monitoring. In addition, there was a significant main effect of Time on participant's self-reported affect, indicating an improved mood after interaction with the robot regardless of the interaction type. Our results suggest that EEG responses during robot-guided meditation hold promise in real-time detection and neurofeedback of mindful state to the user, however the experienced neurophysiological changes may differ based on the meditation practice and recruited tools. This study is the first to report EEG changes during mindfulness practice with a robot. We believe that our findings driven from an ecologically valid setting, can be used in development of future BCI systems that are integrated with social robots for health applications.",https://ieeexplore.ieee.org/document/9223428/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore
10.1109/ROBOT.2001.933270,Robotic Antarctic meteorite search: outcomes,IEEE,Conferences,"Automation of the search for and classification of Antarctic meteorites offers a unique case for early demonstration of robotics in a scenario analogous to geological exploratory missions to other planets and to the Earth's extremes. Moreover, the discovery of new meteorite samples is of great value because meteorites are the only significant source of extraterrestrial material available to scientists. In this paper we focus on the primary outcomes and technical lessons learned from the first field demonstration of autonomous search and in situ classification of Antarctic meteorites by a robot. Using a novel autonomous control architecture, specialized science sensing, combined manipulation and visual servoing, and Bayesian classification, the Nomad robot classified five indigenous meteorites during an expedition to the remote site of Elephant Moraine in January 2000. Nomad's expedition proved the rudiments of science autonomy and exemplified the merits of machine learning techniques for autonomous geological classification in real-world settings. On the other hand, the expedition showcased the difficulty in executing reliable robotic deployment of science sensors and a limited performance in the speed and coverage of autonomous search.",https://ieeexplore.ieee.org/document/933270/,Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164),21-26 May 2001,ieeexplore
10.1109/SMC.2016.7844571,Robotic attention manager using fuzzy controller with fractal analysis,IEEE,Conferences,"This paper is focused on the application of fractal analysis in the attention management of humanoid robot. We designed a fuzzy controller to combine the face detection, movement detection and the fractal dimension signals to control the head movement of robot Nao. Also, the gaze problem is addressed by the controller. Implementation details are included in the paper, including configuration parameters, which we found optimal according to subjective analysis and possibilities of current hardware. We found the fuzzy controller to be advantageous for implementation of attention manager because of smoothing of the movement of robot when compared to the simple rule based implementation, and also because the fuzzy controller implementation of manager is more clear than a naive if-then heuristics code. We also found the fractal dimension to be useful additional signal for attention management of robot, which can be computed in near real-time on current hardware and static input images.",https://ieeexplore.ieee.org/document/7844571/,"2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",9-12 Oct. 2016,ieeexplore
10.1109/C-CODE.2017.7918964,Robotic navigation based on logic-based planning,IEEE,Conferences,"Logic and Planning are interesting artificial intelligence problems in the context of robotic systems, i.e., robotic navigation. For such an autonomous system one of the requisites is that the goal has to be achieved without intervention of human being. We present a practical implementation of autonomous robotic navigation based on logic-based planning. We achieve this by using strength of PROLOG in order to generate plan to reach goal position from an initial. We utilize First Order Logic (FOL) that automatically asserts and retracts facts at runtime dynamically. All possible plans are computed using local search strategies (e.g., Depth and Breadth First) on state space representing a real, dynamic, and unpredictable environment. In order to navigate in the environment following optimized plan - one with fewest states, a balanced size 4-wheel differential drive robot has been carefully constructed. It can turn 90° and actuate forward by controlling linear (ν<sub>t</sub> = 0.25m/s) and angular (ω<sub>t</sub> = Π/8 rad/s) velocities of two rear motorized wheels. It is also equipped with an Ultrasonic sensor to avoid collision with obstacles. The system is evaluated in an environment comprising of corridors with adjacent rooms. Graphical User Interface (GUI) is developed in .Net (C#) to map situation in Prolog and transmit plan to hardware for execution. Average time calculated for a plan to generate is 0.065 seconds. The robot moves block by block where each block in the state space represents 2m<sup>2</sup> area. In addition to minors, our major contribution is that we offer a unified scheme for robotic navigation without calculating odometry data with the assumption the robot cannot be kidnapped nor slipped.",https://ieeexplore.ieee.org/document/7918964/,"2017 International Conference on Communication, Computing and Digital Systems (C-CODE)",8-9 March 2017,ieeexplore
10.1109/ICRA.2019.8793720,Robots Learn Social Skills: End-to-End Learning of Co-Speech Gesture Generation for Humanoid Robots,IEEE,Conferences,"Co-speech gestures enhance interaction experiences between humans as well as between humans and robots. Most existing robots use rule-based speech-gesture association, but this requires human labor and prior knowledge of experts to be implemented. We present a learning-based co-speech gesture generation that is learned from 52 h of TED talks. The proposed end-to-end neural network model consists of an encoder for speech text understanding and a decoder to generate a sequence of gestures. The model successfully produces various gestures including iconic, metaphoric, deictic, and beat gestures. In a subjective evaluation, participants reported that the gestures were human-like and matched the speech content. We also demonstrate a co-speech gesture with a NAO robot working in real time.",https://ieeexplore.ieee.org/document/8793720/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/ICRA.2018.8462969,Robust Human Following by Deep Bayesian Trajectory Prediction for Home Service Robots,IEEE,Conferences,"The capability of following a person is crucial in service-oriented robots for human assistance and cooperation. Though a vast variety of following systems exist, they lack robustness against dynamic changes of the environment and relocating to continue following a lost target. Here we present a robust human following system that has the extendability to commercial service robot platforms having a RGB-D camera. The proposed framework integrates deep learning methods for perception and variational Bayesian techniques for trajectory prediction. Deep learning modules enable robots to accompany a person by detecting the target, learning the target and following while avoiding collision within the dynamic home environment. The variational Bayesian techniques robustly predict the trajectory of the target by empowering the following ability of the robot when target is lost. We experimentally demonstrate the capability of the deep Bayesian trajectory prediction method on real-time usage, following abilities, collision avoidance and trajectory prediction of the system. The proposed system was deployed at the RoboCup@Home 2017 Social Standard Platform League and successfully demonstrated its robust functions and smooth person following capability resulting in winning the 1st place.",https://ieeexplore.ieee.org/document/8462969/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/CVPR46437.2021.00844,Robust Neural Routing Through Space Partitions for Camera Relocalization in Dynamic Indoor Environments,IEEE,Conferences,"Localizing the camera in a known indoor environment is a key building block for scene mapping, robot navigation, AR, etc. Recent advances estimate the camera pose via optimization over the 2D/3D-3D correspondences established between the coordinates in 2D/3D camera space and 3D world space. Such a mapping is estimated with either a convolution neural network or a decision tree using only the static input image sequence, which makes these approaches vulnerable to dynamic indoor environments that are quite common yet challenging in the real world. To address the aforementioned issues, in this paper, we propose a novel outlier-aware neural tree which bridges the two worlds, deep learning and decision tree approaches. It builds on three important blocks: (a) a hierarchical space partition over the indoor scene to construct the decision tree; (b) a neural routing function, implemented as a deep classification network, employed for better 3D scene understanding; and (c) an outlier rejection module used to filter out dynamic points during the hierarchical routing process. Our proposed algorithm is evaluated on the RIO-10 benchmark developed for camera relocalization in dynamic indoor environments. It achieves robust neural routing through space partitions and outperforms the state-of-the-art approaches by around 30% on camera pose accuracy, while running comparably fast for evaluation.",https://ieeexplore.ieee.org/document/9577932/,2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),20-25 June 2021,ieeexplore
10.1109/IROS.2018.8594067,Robust Object Recognition Through Symbiotic Deep Learning In Mobile Robots,IEEE,Conferences,"Despite the recent success of state-of-the-art deep learning algorithms in object recognition, when these are deployed as-is on a mobile service robot, we observed that they failed to recognize many objects in real human environments. In this paper, we introduce a learning algorithm in which robots address this flaw by asking humans for help, also known as a symbiotic autonomy approach. In particular, we bootstrap YOLOv2, a state-of-the-art deep neural network and train a new neural network, that we call HHELP, using only data collected from human help. Using an RGB camera and an onboard tablet, the robot proactively seeks human input to assist it in labeling surrounding objects. Pepper, located at CMU, and Monarch Mbot, located at ISR-Lisbon, were the service robots that we used to validate the proposed approach. We conducted a study in a realistic domestic environment over the course of 20 days with 6 research participants. To improve object detection, we used the two neural networks, YOLOv2 + HHELP, in parallel. Following this methodology, the robot was able to detect twice the number of objects compared to the initial YOLOv2 neural network, and achieved a higher mAP (mean Average Precision) score. Using the learning algorithm the robot also collected data about where an object was located and to whom it belonged to by asking humans. This enabled us to explore a future use case where robots can search for a specific person's object. We view the contribution of this work to be relevant for service robots in general, in addition to Pepper, and Mbot.",https://ieeexplore.ieee.org/document/8594067/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/RO-MAN47096.2020.9223566,Robust Real-Time Hand Gestural Recognition for Non-Verbal Communication with Tabletop Robot Haru,IEEE,Conferences,"In this paper, we present our work in close-distance non-verbal communication with tabletop robot Haru through hand gestural interaction. We implemented a novel hand gestural understanding system by training a machine-learning architecture for real-time hand gesture recognition with the Leap Motion. The proposed system is activated based on the velocity of a user's palm and index finger movement, and subsequently labels the detected movement segments under an early classification scheme. Our system is able to combine multiple gesture labels for recognition of consecutive gestures without clear movement boundaries. System evaluation is conducted on data simulating real human-robot interaction conditions, taking into account relevant performance variables such as movement style, timing and posture. Our results show robustness in hand gesture classification performance under variant conditions. We furthermore examine system behavior under sequential data input, paving the way towards seamless and natural real-time close-distance hand-gestural communication in the future.",https://ieeexplore.ieee.org/document/9223566/,2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),31 Aug.-4 Sept. 2020,ieeexplore
10.1109/CCDC.2019.8832613,Robust Zhang Neural Network for Tracking Control of Parallel Robot Manipulators With Unknown Parameters,IEEE,Conferences,"Under the situation of parameter uncertainty, the tracking control of parallel robot manipulators is a challenging problem in robotic research. Unlike conventional Zhang neural network (ZNN) relying on the assumption that the robot parameter information is fully and accurately known, this paper proposes a robust Zhang neural network (RZNN) for tracking control problems solving of parallel robot manipulators in the absence of parameter information. The proposed RZNN features the full utilization of effector feedback information, and shows a robust tracking performance even with unknown robot parameter information. Then, the continuous-time model of the RZNN is discretized via Euler forward formula (EFF) for numerical implementation. Finally, comprehensive simulative experiments including robustness test verify the effectiveness of the RZNN model for the real-time tracking control of parallel robot manipulators with unknown parameters.",https://ieeexplore.ieee.org/document/8832613/,2019 Chinese Control And Decision Conference (CCDC),3-5 June 2019,ieeexplore
10.1109/HUMANOIDS.2014.7041487,Robust fall detection with an assistive humanoid robot,IEEE,Conferences,"Summary form only given. In this video we introduce a robot assistant that monitors a person in a household environment to promptly detect fall events. In contrast to the use of a fixed sensor, the humanoid robot will track and keep the moving person in the scene while performing daily activities. For this purpose, we extended the humanoid Nao<sup>1</sup> with a depth sensor<sup>2</sup> attached to its head. The tracking framework implemented with OpenNI<sup>3</sup> segments and tracks the person's position and body posture. We use a learning neural framework for processing the extracted body features and detecting abnormal behaviors, e.g. a fall event [1]. The neural architecture consists of a hierarchy of self-organizing neural networks for attenuating noise caused by tracking errors and detecting fall events from video stream in real time. The tracking application, the neural framework, and the humanoid actuators communicate over Robot Operating System (ROS)<sup>4</sup>. We use communication over the ROS network implemented with publisher-subscriber nodes. When a fall event is detected, Nao will approach the person and ask whether assistance is needed. In any case, Nao will take a picture of the scene that can be sent to the caregiver or a relative for further human evaluation and agile intervention. The combination of this sensor technology with our neural network approach allows to tailor the robust detection of falls independently from the background surroundings and in the presence of noise (tracking errors and occlusions) introduced by a real-world scenario. The video shows experiments run in a home-like environment.",https://ieeexplore.ieee.org/document/7041487/,2014 IEEE-RAS International Conference on Humanoid Robots,18-20 Nov. 2014,ieeexplore
10.1109/SII.2011.6147636,Robust localization system using online / offline hybrid learning,IEEE,Conferences,"In this paper, we propose an online motion model parameter estimation method. To achieve accurate localization, accurate estimation of motion model parameters is needed. However, the true values of motion model parameters change sequentially according to alteration of surrounding environments. Therefore the online estimation is absolutely imperative. As a typical method to estimate motion model parameters sequentially, Augmented Kalman Filter (AKF) is there. AKF achieves parameter estimation through Kalman filtering algorithm. However, AKF has serious problems to be implemented in real robot operation. These problems are the accuracy of observation and the limitation to motion control of robots. To solve these problems and achieve accurate motion model parameter estimation, proposed method introduces discriminative training. The introduction of discriminative training increases the convergence performance and stability of parameter estimation through AKF. The proposal method achieves accurate motion model parameter estimation in real robot operation. This paper describes the efficiency of our technique through simulations and an outdoor experiment.",https://ieeexplore.ieee.org/document/6147636/,2011 IEEE/SICE International Symposium on System Integration (SII),20-22 Dec. 2011,ieeexplore
10.1109/EURCON.2007.4400663,Role Selection Mechanism for the Soccer Robot System using Petri Net,IEEE,Conferences,"Robot soccer is a challenging platform for multi-agent research, involving topics such as real-time image processing and control, robot path planning, obstacle avoidance and machine learning. The system consists of a supervisory controller, and controllers for defending and goalkeeping robots. These controllers are designed using Petri net. The robot soccer game presents an uncertain and dynamic environment for cooperating agents. Dynamic role switching and formation control are crucial for a successful game. A soccer robot has to take an appropriate decision based on environment situation. With the role of a robot fixed as goalkeeper, the supervisor, according to the game situation, assigns the role of attacking or defending to the other robots and then respective controllers control the robots. The Petri net model is implemented in Petri net toolbox under MATLAB environment.",https://ieeexplore.ieee.org/document/4400663/,"EUROCON 2007 - The International Conference on ""Computer as a Tool""",9-12 Sept. 2007,ieeexplore
10.1109/ICIAS.2012.6306173,SCARA robot control using neural networks,IEEE,Conferences,"A SCARA industrial robot model is identified based on a 4-axis structure using Lagrangian mechanics, also the dynamic model for the electromechanical actuator and motion transmission systems is identified. A conventional PD controller is implemented and compared to neural networks control system to achieve precise position control of SCARA manipulator. The performance of the modeled system is simulated using several desired tracking motion for each joint. Neural networks control method has shown a remarkable improvement of tracking capabilities for the SCARA robot over conventional PD controller. The proposed neural network controller has the potential to accurately control real-time manipulator applications.",https://ieeexplore.ieee.org/document/6306173/,2012 4th International Conference on Intelligent and Advanced Systems (ICIAS2012),12-14 June 2012,ieeexplore
10.1109/EIECS53707.2021.9587961,SE-OHFM: A surgical phase recognition network with SE attention module,IEEE,Conferences,"With the development of robot-assisted minimally invasive surgery, enhanced automatic context recognition of surgical procedures is becoming critical to improve surgeon performance and patient safety. Deep neural networks can be efficiency at identifying surgical phases and analyzing surgical procedures. However, hard-to-identify frames in surgical videos tend to reduce the accuracy of recognition. This research adds the SE attention mechanism to ResNeXt101 to extract image features and recognize surgical phases, while using the Online Hard Frame Mapper (OHFM) to assist in recognizing hard frames. The experiment results show that the network with added attention can effectively extract the features of laparoscopic images. The proposed method achieved an accuracy of 85.8% on the M2CAI16 workflow challenge dataset.",https://ieeexplore.ieee.org/document/9587961/,2021 International Conference on Electronic Information Engineering and Computer Science (EIECS),23-26 Sept. 2021,ieeexplore
10.1109/ICRA48506.2021.9561020,SQRP: Sensing Quality-aware Robot Programming System for Non-expert Programmers,IEEE,Conferences,"Robot programming typically makes use of a set of mechanical skills that is acquired by machine learning. Because there is in general no guarantee that machine learning produces robot programs that are free of surprising behavior, the safe execution of a robot program must utilize monitoring modules that take sensor data as inputs in real time to ensure the correctness of the skill execution. Owing to the fact that sensors and monitoring algorithms are usually subject to physical restrictions and that effective robot programming is sensitive to the selection of skill parameters, these considerations may lead to different sensor input qualities such as the view coverage of a vision system that determines whether a skill can be successfully deployed in performing a task. Choosing improper skill parameters may cause the monitoring modules to delay or miss the detection of important events such as a mechanical failure. These failures may reduce the throughput in robotic manufacturing and could even cause a destructive system crash. To address above issues, we propose a sensing quality-aware robot programming system that automatically computes the sensing qualities as a function of the robot’s environment and uses the information to guide non-expert users to select proper skill parameters in the programming phase. We demonstrate our system framework on a 6DOF robot arm for an object pick-up task.",https://ieeexplore.ieee.org/document/9561020/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.23919/ACC.2018.8430770,Safe Reinforcement Learning: Learning with Supervision Using a Constraint-Admissible Set,IEEE,Conferences,"Despite recent advances in Reinforcement Learning (RL), its applications in real-world engineering systems are still rare. The primary reason is that RL algorithms involve exploratory actions that can lead to system constraint violations. These violations can damage physical systems and even cause safety issues, e.g., battery overheat, robot breakdown, and car crashes, hindering RL deployment in many engineering applications. In this paper, we develop a novel safe RL framework that guarantees safety during learning by exploiting a constraint-admissible set for supervision. System knowledge and recursive feasibility techniques are exploited to construct a state-dependent constraint-admissible set. We develop a new learning scheme where the constraint-admissible set regulates the exploratory actions from the RL agent and simultaneously guides the agent to learn the system constraints with a penalty for control regulation. The proposed safe RL algorithm is demonstrated in an adaptive cruise control example where a nonlinear fuel economy cost function is optimized without violating system constraints. We demonstrate that the safe RL agent is able to learn the system constraints to gradually fade out the control supervisor.",https://ieeexplore.ieee.org/document/8430770/,2018 Annual American Control Conference (ACC),27-29 June 2018,ieeexplore
10.1109/IROS40897.2019.8967834,Sample-efficient Deep Reinforcement Learning with Imaginary Rollouts for Human-Robot Interaction,IEEE,Conferences,"Deep reinforcement learning has proven to be a great success in allowing agents to learn complex tasks. However, its application to actual robots can be prohibitively expensive. Furthermore, the unpredictability of human behavior in human-robot interaction tasks can hinder convergence to a good policy. In this paper, we present an architecture that allows agents to learn models of stochastic environments and use them to accelerate learning. We descirbe how an environment model can be learned online and used to generate synthetic transitions, as well as how an agent can leverage these synthetic data to accelerate learning. We validate our approach using an experiment in which a robotic arm has to complete a task composed of a series of actions based on human gestures. Results show that our approach leads to significantly faster learning, requiring much less interaction with the environment. Furthermore, we demonstrate how learned models can be used by a robot to produce optimal plans in real world applications.",https://ieeexplore.ieee.org/document/8967834/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/RoboSoft48309.2020.9116004,Scalable sim-to-real transfer of soft robot designs,IEEE,Conferences,"The manual design of soft robots and their controllers is notoriously challenging, but it could be augmented-or, in some cases, entirely replaced-by automated design tools. Machine learning algorithms can automatically propose, test, and refine designs in simulation, and the most promising ones can then be manufactured in reality (sim2real). However, it is currently not known how to guarantee that behavior generated in simulation can be preserved when deployed in reality. Although many previous studies have devised training protocols that facilitate sim2real transfer of control polices, little to no work has investigated the simulation-reality gap as a function of morphology. This is due in part to an overall lack of tools capable of systematically designing and rapidly manufacturing robots. Here we introduce a low cost, open source, and modular soft robot design and construction kit, and use it to simulate, fabricate, and measure the simulation-reality gap of minimally complex yet soft, locomoting machines. We prove the scalability of this approach by transferring an order of magnitude more robot designs from simulation to reality than any other method. The kit and its instructions can be found here: github.com/skriegman/sim2real4designs.",https://ieeexplore.ieee.org/document/9116004/,2020 3rd IEEE International Conference on Soft Robotics (RoboSoft),15 May-15 July 2020,ieeexplore
10.1109/ROBIO.2017.8324700,Search control in an unknown environment using shortest path calculation and Lyapunov technique,IEEE,Conferences,"Search control in an unknown space is a basic function of mobile autonomous robots. For search control, robustness against environmental change is important because environmental information is measured and updated at every moment. Robustness can be guaranteed by feedback controllers generated by global control Lyapunov functions (CLFs). To endow search control with the robustness properties of CLFs, Akiba et al. proposed search control based on a Lyapunov technique in an unknown space using a Q-learning algorithm. They showed that the robot reaches its destination with conventional control even if the destination is unknown. However, conventional control requires an offline calculation because the Q-learning algorithm has high calculation costs; hence, an online search is not achieved. Further, conventional control cannot be applied to complex environments such as those where humans live. In this research, we propose a Lyapunov based on search control in an unknown plane space. The proposed control employs Dijkstra's algorithm, and has lower calculation costs than conventional search control. Further, we successfully apply our method to mapping data in real environments via a simulation experiment.",https://ieeexplore.ieee.org/document/8324700/,2017 IEEE International Conference on Robotics and Biomimetics (ROBIO),5-8 Dec. 2017,ieeexplore
10.1109/CCIOT45285.2018.9032441,Segmental Deployment of Neural Network in Cloud Robotic System,IEEE,Conferences,"In this paper, we describe a new method for ep neural networks in the field of computer vision, which can effectively solve the difficulty of applying deep learning in the cloud robotic system. By segmenting the trained network, most of the computing tasks can be cut out and offloaded to the cloud. By effective feature extraction and compression methods, the computing power of robot and cloud can be integrated and coordinated. A method of selecting the split points of the network model and a method of data transmission and compression in the communication between robots and cloud after segmenting are given based on the characteristics of machine vision tasks, and the theoretical analysis is carried out. In the experiment, the effectiveness of all the above methods is verified by comparing the compression capability, response time and network performance of the actual network model. The experimental results show that with the use of segmental methods in cloud robotic system, the task of deep network is processed in real time, while the performance is almost guaranteed.",https://ieeexplore.ieee.org/document/9032441/,2018 IEEE 3rd International Conference on Cloud Computing and Internet of Things (CCIOT),20-21 Oct. 2018,ieeexplore
10.1109/ICRA.2019.8793744,Segmenting Unknown 3D Objects from Real Depth Images using Mask R-CNN Trained on Synthetic Data,IEEE,Conferences,"The ability to segment unknown objects in depth images has potential to enhance robot skills in grasping and object tracking. Recent computer vision research has demonstrated that Mask R-CNN can be trained to segment specific categories of objects in RGB images when massive hand-labeled datasets are available. As generating these datasets is time-consuming, we instead train with synthetic depth images. Many robots now use depth sensors, and recent results suggest training on synthetic depth data can transfer successfully to the real world. We present a method for automated dataset generation and rapidly generate a synthetic training dataset of 50,000 depth images and 320,000 object masks using simulated heaps of 3D CAD models. We train a variant of Mask R-CNN with domain randomization on the generated dataset to perform category-agnostic instance segmentation without any hand-labeled data and we evaluate the trained network, which we refer to as Synthetic Depth (SD) Mask R-CNN, on a set of real, high-resolution depth images of challenging, densely-cluttered bins containing objects with highly-varied geometry. SD Mask R-CNN outperforms point cloud clustering baselines by an absolute 15% in Average Precision and 20% in Average Recall on COCO benchmarks, and achieves performance levels similar to a Mask R-CNN trained on a massive, hand-labeled RGB dataset and fine-tuned on real images from the experimental setup. We deploy the model in an instance-specific grasping pipeline to demonstrate its usefulness in a robotics application. Code, the synthetic training dataset, and supplementary material are available at https://bit.ly/2letCuE.",https://ieeexplore.ieee.org/document/8793744/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/CIMCA.2005.1631415,Self-Organization of Spiking Neural Network Generating Autonomous Behavior in a Real Mobile Robot,IEEE,Conferences,"In this paper, we study the relation between neural dynamics and robot behavior to develop self-organization algorithm of spiking neural network applicable to autonomous robot. We first formulated a spiking neural network model whose inputs and outputs were analog. We then implemented it into a miniature mobile robot Khepera. In order to see whether or not a solution(s) for the given task exists with the spiking neural network, the robot was evolved with the genetic algorithm (GA) in an environment. The robot acquired the obstacle avoidance and navigation task successfully, exhibiting the presence of the solution. Then, a self-organization algorithm based on the use-dependent synaptic potentiation and depotentiation was formulated and implemented into the robot. In the environment, the robot gradually organized the network and the obstacle avoidance behavior was formed. The time needed for the training was much less than with genetic evolution, approximately one fifth (1/5)",https://ieeexplore.ieee.org/document/1631415/,"International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC'06)",28-30 Nov. 2005,ieeexplore
10.1109/ICRA.2018.8460655,Self-Supervised Deep Reinforcement Learning with Generalized Computation Graphs for Robot Navigation,IEEE,Conferences,"Enabling robots to autonomously navigate complex environments is essential for real-world deployment. Prior methods approach this problem by having the robot maintain an internal map of the world, and then use a localization and planning method to navigate through the internal map. However, these approaches often include a variety of assumptions, are computationally intensive, and do not learn from failures. In contrast, learning-based methods improve as the robot acts in the environment, but are difficult to deploy in the real-world due to their high sample complexity. To address the need to learn complex policies with few samples, we propose a generalized computation graph that subsumes value-based model-free methods and model-based methods, with specific instantiations interpolating between model-free and model-based. We then instantiate this graph to form a navigation model that learns from raw images and is sample efficient. Our simulated car experiments explore the design decisions of our navigation model, and show our approach outperforms single-step and <i>N</i>-step double Q-learning. We also evaluate our approach on a real-world RC car and show it can learn to navigate through a complex indoor environment with a few hours of fully autonomous, self-supervised training. Videos of the experiments and code can be found at github.com/gkahn13/gcg.",https://ieeexplore.ieee.org/document/8460655/,2018 IEEE International Conference on Robotics and Automation (ICRA),21-25 May 2018,ieeexplore
10.1109/CEC.2002.1006258,Self-adaptive systems using a massive multi-agent system,IEEE,Conferences,"We deal with systems using massive multi-agent organizations and expressing complex problems like the representation of the world sub-system managing the behavior of a robot. We propose an analysis and an operating representation of multi-agent organization in a geometric way, using specific multi-agent organization in a morphologic agent space. We propose also an architecture expressing the behavior of the massive multi-agent organization. So we open the way to the implementation of self-adaptive systems. We present an application for the behavior of an autonomous robot.",https://ieeexplore.ieee.org/document/1006258/,Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600),12-17 May 2002,ieeexplore
10.1109/ICRA.2016.7487178,Self-learning and adaptation in a sensorimotor framework,IEEE,Conferences,"We present a general framework to autonomously achieve the task of finding a sequence of actions that result in a desired state. Autonomy is acquired by learning sensorimotor patterns of a robot, while it is interacting with its environment. Gaussian processes (GP) with automatic relevance determination are used to learn the sensorimotor mapping. In this way, relevant sensory and motor components can be systematically found in high-dimensional sensory and motor spaces. We propose an incremental GP learning strategy, which discerns between situations, when an update or an adaptation must be implemented. The Rapidly exploring Random Tree (RRT*) algorithm is exploited to enable long-term planning and generating a sequence of states that lead to a given goal; while a gradient-based search finds the optimum action to steer to a neighbouring state in a single time step. Our experimental results prove the suitability of the proposed framework to learn a joint space controller with high data dimensions (10×15). It demonstrates short training phase (less than 12 seconds), real-time performance and rapid adaptations capabilities.",https://ieeexplore.ieee.org/document/7487178/,2016 IEEE International Conference on Robotics and Automation (ICRA),16-21 May 2016,ieeexplore
10.1109/ROBOT.2000.844830,Self-learning vision-guided robots for searching and grasping objects,IEEE,Conferences,"An approach to control vision-guided robots is introduced. It allows searching and grasping differently shaped objects that may be located anywhere in the robot's work space, even not visible in the initial fields of view of cameras. It eliminates the need for a calibration of the robot and of the vision system, it uses no world coordinates and no inverse perspective or kinematic transformations, and it comprises an automatic adaptation to changing parameters. The approach has been implemented on a calibration-free vision-guided manipulator with five degrees of freedom (DOF) and was evaluated in real-word experiments.",https://ieeexplore.ieee.org/document/844830/,Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065),24-28 April 2000,ieeexplore
10.1109/IJCNN.2002.1005521,Self-organization of behavioral primitives as multiple attractor dynamics: a robot experiment,IEEE,Conferences,"I investigated how behavior primitives are self-organized in my previously (Tani, 2001) proposed ""forwarding forward model"" neural network model in the context of robot imitation learning. The model is characterized with the so-called parametric biases which adaptively modulate for embedding different behavior patterns in a single recurrent neural net in a distributed way. My experiments, using a real robot, showed that a set of end-point and oscillatory behavior patterns are learned as fixed points and limit cycle dynamics respectively with adapting parametric bias for each. Further analysis showed that diverse behavior patterns other than learned patterns were also generated because of self-organization of the nonlinear map between the parametric biases and behavior patterns. It is concluded that such diversity emerges because primitives are represented distributedly in the network.",https://ieeexplore.ieee.org/document/1005521/,Proceedings of the 2002 International Joint Conference on Neural Networks. IJCNN'02 (Cat. No.02CH37290),12-17 May 2002,ieeexplore
10.1109/ROBOT.2002.1014331,Self-organized flocking with agent failure: Off-line optimization and demonstration with real robots,IEEE,Conferences,"This paper presents an investigation of flocking by teams of autonomous mobile robots using principles of Swarm Intelligence. First, we present a simple flocking task, and we describe a leaderless distributed flocking algorithm (LD) that is more conducive to implementation on embodied agents than the established algorithms used in computer animation. Next, we use an embodied simulator and reinforcement learning techniques to optimize LD performance under different conditions, showing that this method can be used not only to improve performance but also to gain insight into which algorithm components contribute most to system behavior. Finally, we demonstrate that a group of real robots executing LD with emulated sensors can successfully flock (even in the presence of individual agent failure) and that systematic characterization (and therefore optimization) of real robot flocking performance is achievable.",https://ieeexplore.ieee.org/document/1014331/,Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292),11-15 May 2002,ieeexplore
10.1109/ICSMC.1997.625763,Self-organized learning and its implementation of robot movements,IEEE,Conferences,The self-organizing map algorithm using an artificial neural network originally developed by Kohonen and extended and modified later provides a distributed and autonomous learning procedure in engineering modeling of the human sensory-motor mapping mechanism. Its extension and adaptation to a control problem of a robot manipulator has been intensively discussed in past years. In this article the application of the self-organizing map algorithm to the generation of a visuo-motor map is focused on. A task-oriented inverse kinematic solution to a redundant manipulator is formed and real-time implementation of the map on a mechanical manipulator is performed.,https://ieeexplore.ieee.org/document/625763/,"1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation",12-15 Oct. 1997,ieeexplore
10.1109/ROBOT.2006.1642213,Self-organizing approach for robot's behavior imitation,IEEE,Conferences,"In this paper, an approach for behavior imitation using visual information was introduced. The imitation process is done by a self organizing neural network module. From several demonstrations of task operation, a vision system captures movement of the demonstrator mobile robot and associated objects in an operation field. Then, the movement features are extracted to present to an imitation engine. Finally, skill or decision policy from teacher's demonstration is extracted and embedded into a self organizing neural network without explicit external supervisory signals. A simple action selection algorithm for choosing action from learned network is proposed. The algorithm was implemented and tested on a simulated robot and a real mobile robot to imitate two simple robot soccer behaviors: approaching the target and obstacle avoidance. Furthermore, the concept of similarity measure is introduced to evaluate imitation performance from the demonstrator",https://ieeexplore.ieee.org/document/1642213/,"Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006.",15-19 May 2006,ieeexplore
10.1109/FPA.1994.636137,Self-organizing map for reinforcement learning: obstacle-avoidance with Khepera,IEEE,Conferences,We present a self-organizing map implementation of the Q-learning algorithm. Our goal is to overcome the problems of reinforcement learning: memory requirement and generalization. We consider the map as an associative memory and we use it for obstacle avoidance with the mobile robot Khepera. Results allow real world applications to be envisaged using neural reinforcement learning.,https://ieeexplore.ieee.org/document/636137/,Proceedings of PerAc '94. From Perception to Action,7-9 Sept. 1994,ieeexplore
10.1109/IJCNN.2016.7727359,Self-repairing mobile robotic car using astrocyte-neuron networks,IEEE,Conferences,"A self-repairing robot utilising a spiking astrocyte-neuron network is presented in this paper. It uses the output spike frequency of neurons to control the motor speed and robot activation. A software model of the astrocyte-neuron network previously demonstrated self-detection of faults and its self-repairing capability. In this paper the application demonstrator of mobile robotics is employed to evaluate the fault-tolerant capabilities of the astrocyte-neuron network when implemented in a hardware-based robotic car system. Results demonstrated that when 20% or less synapses associated with a neuron are faulty, the robot car can maintain system performance and complete the task of forward motion correctly. If 80% synapses are faulty, the system performance shows a marginal degradation, however this degradation is much smaller than that of conventional fault-tolerant techniques under the same levels of faults. This is the first time that astrocyte cells merged within spiking neurons demonstrates a self-repairing capabilities in the hardware system for a real application.",https://ieeexplore.ieee.org/document/7727359/,2016 International Joint Conference on Neural Networks (IJCNN),24-29 July 2016,ieeexplore
10.1109/IROS45743.2020.9340814,SelfieDroneStick: A Natural Interface for Quadcopter Photography,IEEE,Conferences,"A physical selfie stick extends the user's reach, enabling the acquisition of personal photos that include more of the background scene. Similarly, a quadcopter can capture photos from vantage points unattainable by the user; but teleoperating a quadcopter to good viewpoints is a difficult task. This paper presents a natural interface for quadcopter photography, the SelfieDroneStick that allows the user to guide the quadcopter to the optimal vantage point based on the phone's sensors. Users specify the composition of their desired long-range selfies using their smartphone, and the quadcopter autonomously flies to a sequence of vantage points from where the desired shots can be taken. The robot controller is trained from a combination of real-world images and simulated flight data. This paper describes two key innovations required to deploy deep reinforcement learning models on a real robot: 1) an abstract state representation for transferring learning from simulation to the hardware platform, and 2) reward shaping and staging paradigms for training the controller. Both of these improvements were found to be essential in learning a robot controller from simulation that transfers successfully to the real robot.",https://ieeexplore.ieee.org/document/9340814/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ROMAN.2008.4600739,Semantic category acquisition in dialogue for interactive object learning,IEEE,Conferences,"An important aspect of humanoid robots in a natural environment is the ability to acquire new knowledge through learning mechanisms, which enhances an artificial system with the ability to adapt to a changing or new environment. In contrast to most learning algorithms applied in machine learning today, which mainly work with offline learning on training samples, such learning mechanisms need to be performed autonomously and through interaction with the environment or with other agents/humans. In this paper we describe a learning algorithm as a dialogue approach for learning semantic categories and object description in object learning. New objects are introduced to the robot and learning dialogues are conducted as a means of information acquisition. In dialogue, the robot can acquire semantic categories, type and properties of objects, learn new words for object descriptions and learn and association to visual identification from object recognition. In contrast to existing work, this approach combines recognition of real objects, new words learning and semantic categories in one learning dialogue. The presented approach has been implemented in a dialogue system and evaluated on the humanoid robot Armar III.",https://ieeexplore.ieee.org/document/4600739/,RO-MAN 2008 - The 17th IEEE International Symposium on Robot and Human Interactive Communication,1-3 Aug. 2008,ieeexplore
10.1109/ROBOT.1996.506506,Semantic learning by an autonomous mobile robot,IEEE,Conferences,Describes the design and implementation of a learning system for control of an autonomous mobile robot. The robot learns reactive behaviors that allow it to retreat from potential collisions and to explore its environment by seeking out nearby objects. No external teaching input is required. Results from experiments with a real robot are presented. The learned reactive behaviors become the basis for the acquisition of more complex behaviors. Sensory/motor states are classified and then associated with lexical items to form a simple command language which is then used to direct the robot.,https://ieeexplore.ieee.org/document/506506/,Proceedings of IEEE International Conference on Robotics and Automation,22-28 April 1996,ieeexplore
10.1109/IROS.2017.8206048,Sensor fusion for robot control through deep reinforcement learning,IEEE,Conferences,"Deep reinforcement learning is becoming increasingly popular for robot control algorithms, with the aim for a robot to self-learn useful feature representations from unstructured sensory input leading to the optimal actuation policy. In addition to sensors mounted on the robot, sensors might also be deployed in the environment, although these might need to be accessed via an unreliable wireless connection. In this paper, we demonstrate deep neural network architectures that are able to fuse information generated by multiple sensors and are robust to sensor failures at runtime. We evaluate our method on a search and pick task for a robot both in simulation and the real world.",https://ieeexplore.ieee.org/document/8206048/,2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24-28 Sept. 2017,ieeexplore
10.1109/ICCIS.2004.1460763,Sensor fusion system for improving the recognition of 3D object,IEEE,Conferences,"Human being recognizes the physical world by integrating a great variety of sensory inputs, the information acquired by their own action, and their knowledge of the world using hierarchically parallel-distributed mechanism. In this paper, authors propose the sensor fusion system that can recognize multiple 3D objects from 2D projection images and tactile information. The proposed system focuses on improving object recognition rate. Unlike the conventional object recognition system that uses image sensor alone, the proposed method uses tactual sensors in addition to visual sensor. Tactual signals are obtained from the reaction force by the pressure sensors at the fingertips when unknown objects are grasped by four-fingered robot hand. The experiment evaluates the recognition rate and the number of learning iterations of various objects. The experimental results show that the proposed system can improve recognition rate and reduce learning time. These results verify the effectiveness of the proposed sensor fusion system as 3D object recognition scheme",https://ieeexplore.ieee.org/document/1460763/,"IEEE Conference on Cybernetics and Intelligent Systems, 2004.",1-3 Dec. 2004,ieeexplore
10.1109/RO-MAN50785.2021.9515358,Sequential Prediction with Logic Constraints for Surgical Robotic Activity Recognition,IEEE,Conferences,"Many real-world time-sensitive and high-stake applications (e.g., surgical, rescue, and recovery robotics) exhibit sequential nature; thus, applying Recurrent Neural Network (RNN)-based sequential models is an attractive approach to detect robotic activity. One limitation of such approaches is data scarcity. As a result, limited training samples may lead to over-fitting, producing incorrect predictions during deployment. Nevertheless, abundant domain knowledge may still be available, which may help formulate logic constraints. In this paper, we propose a novel way to integrate domain knowledge into RNN-based sequential prediction. We build a Markov Logic Network (MLN)-based classifier that automatically learns constraint weights from data. We propose two methods to incorporate this MLN-based prediction: (i) PriorLayer, in which the values of the hidden layer of the RNN are combined with weights learned from logic constraints in an additional neural network layer, and (ii) Conflation, in which class probabilities from RNN predictions and constraint weights are combined based on the conflation of class probabilities. We evaluate robotic activity classification methods on a simulated OpenAI Gym environment and a real-world DESK dataset for surgical robotics. We observe that our proposed MLN-based approaches boost the performance of LSTM-based networks. In particular, MLN boosts the accuracy of LSTM from 71% to 84% on the Gym dataset and from 68% to 72% on the Taurus robot dataset. Furthermore, MLN (i.e., PriorLayer) shows regularization capability where it improves accuracy in initial LSTM training while avoiding over-fitting early, thus improves the final classification accuracy on unseen data. The code is available at https://github.com/masud99r/prediction-with-logic-constraints.",https://ieeexplore.ieee.org/document/9515358/,2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN),8-12 Aug. 2021,ieeexplore
10.1109/KIMAS.2003.1245110,Sharing learning policies between multiple mobile robots,IEEE,Conferences,"Learning of a complex task usually requires a long learning period. In order to reduce the time of learning, the task is divided into several subtasks. Multiple agents can be used to serve a complex task by learning these subtasks concurrently. With a good knowledge sharing mechanism, the learning policy can be shared or exchanged among these agents and can enhance their learning efficiency. The learning policy is a mapping from system states to actions. The mechanism of sharing or exchanging learning knowledge among multiagent system is proposed. An index of expertise, which indicates the skill level of each learning agent, is presented. This index is used to select the best preferable advice among multiple advices, which can increase the probability of finding solution in the search space. The experiment in which the learning knowledge is exchanged between a mobile robot and a computer simulated agent is implemented in order to verify the validity of the proposed algorithm. The experimental results show that the learning efficiency of the advisor agent is increased and the advisee robot can use the given advice for avoiding collision with obstacle successfully in the real world implementation.",https://ieeexplore.ieee.org/document/1245110/,IEMC '03 Proceedings. Managing Technologically Driven Organizations: The Human Side of Innovation and Change (IEEE Cat. No.03CH37502),30 Sept.-4 Oct. 2003,ieeexplore
10.1109/FUZZ.2002.1006736,Sharing of exploring information using belief measure for multi robot exploration,IEEE,Conferences,"We consider the problem of sharing knowledge in multi-robot exploration. It is difficult for each robot to explore accurately because of sensor errors and dead reckoning errors. We use the belief measure as the expression of sensor values in each robot for exploring an unknown environment. Then, multiple robots share the knowledge about some targets or some obstacles of the environment considering the degree of trust for other robots. The key point of this method is that robots have not a common map, but each robot has his map for sharing exploring information. The effectiveness of our approach is demonstrated by a real experiment for the case of two mobile robots.",https://ieeexplore.ieee.org/document/1006736/,2002 IEEE World Congress on Computational Intelligence. 2002 IEEE International Conference on Fuzzy Systems. FUZZ-IEEE'02. Proceedings (Cat. No.02CH37291),12-17 May 2002,ieeexplore
10.1109/CVPR.2019.01165,Sim-Real Joint Reinforcement Transfer for 3D Indoor Navigation,IEEE,Conferences,"There has been an increasing interest in 3D indoor navigation, where a robot in an environment moves to a target according to an instruction. To deploy a robot for navigation in the physical world, lots of training data is required to learn an effective policy. It is quite labour intensive to obtain sufficient real environment data for training robots while synthetic data is much easier to construct by render-ing. Though it is promising to utilize the synthetic environments to facilitate navigation training in the real world, real environment are heterogeneous from synthetic environment in two aspects. First, the visual representation of the two environments have significant variances. Second, the houseplans of these two environments are quite different. There-fore two types of information,i.e. visual representation and policy behavior, need to be adapted in the reinforce mentmodel. The learning procedure of visual representation and that of policy behavior are presumably reciprocal. We pro-pose to jointly adapt visual representation and policy behavior to leverage the mutual impacts of environment and policy. Specifically, our method employs an adversarial feature adaptation model for visual representation transfer anda policy mimic strategy for policy behavior imitation. Experiment shows that our method outperforms the baseline by 19.47% without any additional human annotations.",https://ieeexplore.ieee.org/document/8953924/,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),15-20 June 2019,ieeexplore
10.1109/ICRA40945.2020.9197512,Sim-to-Real Transfer for Optical Tactile Sensing,IEEE,Conferences,"Deep learning and reinforcement learning methods have been shown to enable learning of flexible and complex robot controllers. However, the reliance on large amounts of training data often requires data collection to be carried out in simulation, with a number of sim-to-real transfer methods being developed in recent years. In this paper, we study these techniques for tactile sensing using the TacTip optical tactile sensor, which consists of a deformable tip with a camera observing the positions of pins inside this tip. We designed a model for soft body simulation which was implemented using the Unity physics engine, and trained a neural network to predict the locations and angles of edges when in contact with the sensor. Using domain randomisation techniques for sim-to-real transfer, we show how this framework can be used to accurately predict edges with less than 1 mm prediction error in real-world testing, without any real-world data at all.",https://ieeexplore.ieee.org/document/9197512/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/LARS-SBR-WRE48964.2019.00060,Sim-to-Real in Reinforcement Learning for Everyone,IEEE,Conferences,"In reinforcement learning (RL), it remains a challenge to have a robotic agent perform a task in the real world for which it was trained in simulation. In this paper, we present our work training a low-cost robotic arm in simulation to move towards a predefined target in space, represented by a red ball in an RGB image, and transferring the capability to the real arm. We exercised the entire end-to-end flow including the 3D modeling of the arm, training of a state-of-the-art RL policy in simulation with multiple actors in a distributed fashion, domain randomization in order to close the sim-to-real gap, and finally the execution of the trained model in the real robot. We also implemented a mechanism to edit the image captured from the camera before sending it to the model for inference, which allowed us to automate reward computation in the physical world. Our work highlights important challenges of training RL agents and moving them to the real world, validating important aspects shown by other works as well as detailing steps not explained by some of them (e.g. how to compute the reward in the real world). The conducted experiments show the improvements observed as the techniques were added to the final solution.",https://ieeexplore.ieee.org/document/9018558/,"2019 Latin American Robotics Symposium (LARS), 2019 Brazilian Symposium on Robotics (SBR) and 2019 Workshop on Robotics in Education (WRE)",23-25 Oct. 2019,ieeexplore
10.1109/ICRAE48301.2019.9043822,Sim-to-real: Six-legged Robot Control with Deep Reinforcement Learning and Curriculum Learning,IEEE,Conferences,"Six-Iegged robots have higher stability and balance, which helps them face more complex terrain conditions, such as sand, swamp, mine and so forth. Therefore, it is necessary to study the gait planning of six-legged robot to adapt to complex terrain. In order to control six-legged robots to adapt to different terrains, we adopt the method of deep reinforcement learning (DRL) to plan the gait of six-legged robots. The main idea is training the robot through Actor-Critic network with proximal policy optimization (PPO), in which outputs are step length, step height and orientation of the robot. This is an end-to-end approach, which tries to make the robot learn by itself and finally achieve its safe arrival to the target point through complex terrains. In order to train a good model for our robots, simplified environment is adopted to accelerate the training process. We also use curriculum learning to speed up and optimize the training. Then, we verify the reliability of the method in simulation platform and finally transfer the learned model to real robot. Our experiment shows the effectiveness of deep reinforcement learning for locomotion of six-legged robots, the acceleration of the training process by means of curriculum learning, and the improvement of the training effect.",https://ieeexplore.ieee.org/document/9043822/,2019 4th International Conference on Robotics and Automation Engineering (ICRAE),22-24 Nov. 2019,ieeexplore
10.1109/EMBC44109.2020.9176182,Simple Kinematic Feedback Enhances Autonomous Learning in Bio-Inspired Tendon-Driven Systems,IEEE,Conferences,"Error feedback is known to improve performance by correcting control signals in response to perturbations. Here we show how adding simple error feedback can also accelerate and robustify autonomous learning in a tendon-driven robot. We have implemented two versions of the General-to-Particular (G2P) autonomous learning algorithm using a tendon-driven leg with two joints and three tendons: one with and one without real-time kinematic feedback. We have performed a rigorous study on the performance of each system, for both simulation and physical implementation cases, over a wide range of tasks. As expected, feedback improved performance in simulation and hardware. However, we see these improvements even in the presence of sensory delays of up to 100 ms and when experiencing substantial contact collisions. Importantly, feedback accelerates learning and enhances G2P's continual refinement of the initial inverse map by providing the system with more relevant data to train on. This allows the system to perform well even after only 60 seconds of initial motor babbling.",https://ieeexplore.ieee.org/document/9176182/,2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),20-24 July 2020,ieeexplore
10.1109/IJCNN.2000.859462,"Simulating the evolution of 2D pattern recognition on the CAM-Brain Machine, an evolvable hardware tool for building a 75 million neuron artificial brain",IEEE,Conferences,"This paper presents some simulation results of the evolution of 2D visual pattern recognizers to be implemented very shortly on real hardware, namely the ""CAM-Brain Machine"" (CBM), an FPGA based piece of evolvable hardware which implements a genetic algorithm (GA) to evolve a 3D cellular automata (CA) based neural network circuit module, of approximately 1,000 neurons, in about a second, i.e. a complete run of a GA, with tens of thousands of circuit growths and performance evaluations. Up to 65,000 of these modules, each of which is evolved with a humanly specified function, can be downloaded into a large RAM space, and interconnected according to humanly specified artificial brain architectures. This RAM, containing an artificial brain with up to 75 million neurons, is then updated by the CBM at a rate of 130 billion CA cells per second. Such speeds will enable real time control of robots and hopefully the birth of a new research field that we call ""brain building"". The first such artificial brain, to be built at STARLAB in 2000 and beyond, will be used to control the behaviors of a life sized kitten robot called ""Robokitty"". This kitten robot will need 2D pattern recognizers in the visual section of its artificial brain. This paper presents simulation results on the evolvability and generalization properties of such recognizers.",https://ieeexplore.ieee.org/document/859462/,Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium,27-27 July 2000,ieeexplore
10.1109/IROS.2018.8593518,Simultaneous End-User Programming of Goals and Actions for Robotic Shelf Organization,IEEE,Conferences,"Arrangement of items on shelves in stores or warehouses is a tedious, repetitive task that can be feasible for robots to perform. The diversity of products that are available in stores and the different setups and preferences of each store makes pre-programming a robot for this task extremely challenging. Instead, our work argues for enabling end-users to customize the robot to their specific objects and setup at deployment time by programming it themselves. To that end, this paper contributes (i) a task representation for shelf arrangements based on a large dataset of grocery store shelf images, (ii) a method for inferring goal configurations from user inputs including demonstrations and direct parameter specifications, and (iii) a system implementation of the proposed approach that allows simultaneously learning task goals and actions. We evaluate our goal inference approach with ten different teaching strategies that combine alternative user inputs in different ways on the large dataset of grocery configurations, as well as with real human teachers through an online user study (N=32). We evaluate our full system implemented on a Fetch mobile manipulator on eight benchmark tasks that demonstrate end-to-end programming and execution of shelf arrangement tasks.",https://ieeexplore.ieee.org/document/8593518/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ICAR.2015.7251437,Simultaneous human-robot adaptation for effective skill transfer,IEEE,Conferences,"In this paper, we propose and implement a human-in-the loop robot skill synthesis framework that involves simultaneous adaptation of the human and the robot. In this framework, the human demonstrator learns to control the robot in real-time to make it perform a given task. At the same time, the robot learns from the human guided control creating a non-trivial coupled dynamical system. The research question we address is how this system can be tuned to facilitate faster skill transfer or improve the performance level of the transferred skill. In the current paper we report our initial work for the latter. At the beginning of the skill transfer session, the human demonstrator controls the robot exclusively as in teleoperation. As the task performance improves the robot takes increasingly more share in control, eventually reaching full autonomy. The proposed framework is implemented and shown to work on a physical cart-pole setup. To assess whether simultaneous learning has advantage over the standard sequential learning (where the robot learns from the human observation but does not interfere with the control) experiments with two groups of subjects were performed. The results indicate that the final autonomous controller obtained via simultaneous learning has a higher performance measured as the average deviation from the upright posture of the pole.",https://ieeexplore.ieee.org/document/7251437/,2015 International Conference on Advanced Robotics (ICAR),27-31 July 2015,ieeexplore
10.1109/IROS.1990.262374,"Single leg walking with integrated perception, planning and control",IEEE,Conferences,"Describes an integrated system capable of walking over rugged terrain using a single leg suspended below a carriage that rolls along rails. To walk, the system uses a laser scanner to find a foothold, positions the leg above the foothold, contacts the terrain with the foot, and applies force enough to advance the carriage along the rails. Walking both forward and backward, the system has traversed hundreds of meters of rugged terrain including obstacles too tall to step over, trenches too deep to step in, closely spaced rocks, and sand hills. The implemented system consists of a number of task-specific processes (two for planning, two for perception, one for real-time control) and a central control process that directs the flow of communication between processes. Implementing this integrated system is a significant step toward the goal of the CMU Planetary Rover project: to prototype a autonomous six-legged robot for planetary exploration.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/262374/,"EEE International Workshop on Intelligent Robots and Systems, Towards a New Frontier of Applications",3-6 July 1990,ieeexplore
10.1109/ICCVW.2017.84,SkiMap++: Real-Time Mapping and Object Recognition for Robotics,IEEE,Conferences,"We introduce SkiMap++, an extension to the recently proposed SkiMap mapping framework for robot navigation [1]. The extension deals with enriching the map with semantic information concerning the presence in the environment of certain objects that may be usefully recognized by the robot, e.g. for the sake of grasping them. More precisely, the map can accommodate information about the spatial locations of certain 3D object features, as determined by matching the visual features extracted from the incoming frames through a random forest learned off-line from a set of object models. Thereby, evidence about the presence of object features is gathered from multiple vantage points alongside with the standard geometric mapping task, so to enable recognizing the objects and estimating their 6 DOF poses. As a result, SkiMap++ can reconstruct the geometry of large scale environments as well as localize some relevant objects therein (Fig.1) in real-time on CPU. As an additional contribution, we present an RGB-D dataset featuring ground-truth camera and object poses, which may be deployed by researchers interested in pursuing SLAM alongside with object recognition, a topic often referred to as Semantic SLAM<sup>1</sup>.",https://ieeexplore.ieee.org/document/8265293/,2017 IEEE International Conference on Computer Vision Workshops (ICCVW),22-29 Oct. 2017,ieeexplore
10.1109/IROS.2018.8593856,"Skill-Oriented Designer of Conceptual Robotic Structures*This work was supported by CDTI under expedient IDI-20150289 (BOTBLOQ: Ecosistema integral para el diseño, fabricación y programación de robots DIY).",IEEE,Conferences,"This communication presents an application for the use of ontologies in the generation of robot structures. The ontology developed for this app relies on the IEEE Standard Ontologies for Robotics and Automation (ORA) and it incorporates a set of concepts, relations and axioms that link robotic skills with the structural parts needed for their realization. The user can select a base configuration and/or a set of desired skills that the robot should be able to perform. Then, the application evaluates the axioms and returns an abstract structure that can carry out the requested skills. The final implementation of the structure can be achieved with any modular robotic platform that could identify each structural part with a physical device.",https://ieeexplore.ieee.org/document/8593856/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/ICHR.2010.5686285,SkyAI: Highly modularized reinforcement learning library,IEEE,Conferences,"This paper introduces a software library of reinforcement learning (RL) methods, named SkyAI. SkyAI is a highly modularized RL library for real/simulated robots to learn behaviors. Our ultimate goal is to develop an artificial intelligence (AI) program with which the robots can learn to behave as their users' wish. In this paper, we describe the concepts, the requirements, and the current implementation of SkyAI. SkyAI provides two conflicting features: high execution-speed enough for real robot systems and high flexibility to design learning systems. We also demonstrate the applications to crawling tasks of both a humanoid robot in simulation and a real spider robot.",https://ieeexplore.ieee.org/document/5686285/,2010 10th IEEE-RAS International Conference on Humanoid Robots,6-8 Dec. 2010,ieeexplore
10.1109/ICCSE49874.2020.9201679,Small Agricultural Phenotype Robot and Its Navigation and Obstacle Avoidance in Parallel Walls,IEEE,Conferences,"With the development of robotics, computer vision and artificial intelligence, the study of Plant phenotyping has entered a stage of rapid growth. For robots can be used for a large-scale, automatic and sustainable phenotype collection and data processing, it has also been followed closely by more and more research institutions and international seed giants, but currently the more mature phenotype robots are huge in size and expensive in configuration. Although their accuracy are high, but the popularity are poor, so it is difficult to popularize on a large scale, which is not conducive to collect plant phenotype data in a wider space and for the more plant varieties. On the other side, the small phenotype robots have low cost, simple operation, and are more suitable for large-scale promotion. The current research on plant phenotype small robots is mainly based on small wheeled robots. The robot is equipped with visual and optical sensors for collecting plant information, and uses machine vision and various sensors to achieve the robot's movement, positioning and obstacle avoidance. This paper uses the small wheeled mobile robot to simulate the navigation and obstacle avoidance of the phenotype collecting robot in parallel walls, and its effectiveness is proved by simulation experiment and real machine test.",https://ieeexplore.ieee.org/document/9201679/,2020 15th International Conference on Computer Science & Education (ICCSE),18-22 Aug. 2020,ieeexplore
10.1109/SaCoNeT.2018.8585616,Smart Navigation of Mobile Robot Using Neural Network Controller,IEEE,Conferences,"The field of autonomous navigation of mobile robot is advancing so fast especially with the development of machine learning algorithms. This study aims to introduce a neural network controller that controls the trajectory and the obstacle avoidance of a non-holonomic mobile robot.We train the robot in environment containing multiple obstacles with different places. This paper includes both a kinematic and a dynamic study of a mobile robot. Different training schemes have been studied that tackle the learning objectives differently. The trained controller is producing the Pulse Width Modulation (PWM) signals that could be implemented in a microprocessor and validated by simulations. Unlike some other recent approaches, this work was validated by a 3D simulation which is similar to the real model.",https://ieeexplore.ieee.org/document/8585616/,2018 International Conference on Smart Communications in Network Technologies (SaCoNeT),27-31 Oct. 2018,ieeexplore
10.1109/ISC2.2016.7580798,SmartSEAL: A ROS based home automation framework for heterogeneous devices interconnection in smart buildings,IEEE,Conferences,"With this paper we present the SmartSEAL inter-connection system developed for the nationally founded SEAL project. SEAL is a research project aimed at developing Home Automation (HA) solutions for building energy management, user customization and improved safety of its inhabitants. One of the main problems of HA systems is the wide range of communication standards that commercial devices use. Usually this forces the designer to choose devices from a few brands, limiting the scope of the system and its capabilities. In this context, SmartSEAL is a framework that aims to integrate heterogeneous devices, such as sensors and actuators from different vendors, providing networking features, protocols and interfaces that are easy to implement and dynamically configurable. The core of our system is a Robotics middleware called Robot Operating System (ROS). We adapted the ROS features to the HA problem, designing the network and protocol architectures for this particular needs. These software infrastructure allows for complex HA functions that could be realized only levering the services provided by different devices. The system has been tested in our laboratory and installed in two real environments, Palazzo Fogazzaro in Schio and “Le Case” childhood school in Malo. Since one of the aim of the SEAL project is the personalization of the building environment according to the user needs, and the learning of their patterns of behaviour, in the final part of this work we also describe the ongoing design and experiments to provide a Machine Learning based re-identification module implemented with Convolutional Neural Networks (CNNs). The description of the adaptation module complements the description of the SmartSEAL system and helps in understanding how to develop complex HA services through it.",https://ieeexplore.ieee.org/document/7580798/,2016 IEEE International Smart Cities Conference (ISC2),12-15 Sept. 2016,ieeexplore
10.1109/ROMAN.2002.1045681,Socially interactive robots. Why our current beliefs about them still work,IEEE,Conferences,"Discussion about the application of scientific knowledge in robotics in order to build people helpers is widespread. The issue herein addressed is philosophically poignant, that of robots that are 'people'. It is currently popular to speak about robots and the image of Man. Behind this lurks the dialogical mind and the questions on its artificial existence. Without intending to defend or refute the discourse in favour of 'recreating' Man, a lesser familiar question is brought forth: 'Given that we are capable of creating a man (constructing a robot-person), what would the consequences of this be and would we be satisfied with such technology?' Thorny topic; it questions the entire knowledge foundation upon which strong AI/Robotics is positioned. The author argues for improved monitoring of technological progress and thus favours 'soft' (weak) implementation techniques.",https://ieeexplore.ieee.org/document/1045681/,Proceedings. 11th IEEE International Workshop on Robot and Human Interactive Communication,27-27 Sept. 2002,ieeexplore
10.1109/ROBOT.2004.1308781,Software approach for the autonomous inspection robot MAKRO,IEEE,Conferences,"The sewer inspection robot MAKRO is an autonomous multi-segment robot with worm-like shape driven by wheels. It is currently under development in the project MAKRO-PLUS. The robot has to navigate autonomously within sewer systems. Its first tasks is to take water probes, analyze them onboard, and measure positions of manholes and pipes to detect pollution loaded sewage and to improve current maps of sewer systems. One of the challenging problems is the control software, which should enable the robot to navigate in the sewer system and perform the inspection tasks autonomously, while always taking care of its own safety. Tests in our test environment and in a real sewer system show promising results. This paper focuses on the software approach. To manage the complexity a layered architecture has been chosen, each layer defining a different level of abstraction. After determining the abstraction levels, we use different methods for implementation. For the highest abstraction level a standard AI-planning algorithm is used. For the next level, finite state automata has been chosen. For ""simple"" task implementation we use a modular C++ based method (MCA2), which is also used on the lowest software level.",https://ieeexplore.ieee.org/document/1308781/,"IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004",26 April-1 May 2004,ieeexplore
10.1109/HPCS48598.2019.9188104,Staged deployment of interactive multi-application HPC workflows,IEEE,Conferences,"Running scientific workflows on a supercomputer can be a daunting task for a scientific domain specialist. Workflow management solutions (WMS) are a standard method for reducing the complexity of application deployment on high performance computing (HPC) infrastructure. We introduce the design for a middleware system that extends and combines the functionality from existing solutions in order to create a high-level, staged usercentric operation/deployment model. This design addresses the requirements of several use cases in the life sciences, with a focus on neuroscience. In this manuscript we focus on two use cases: 1) three coupled neuronal simulators (for three different space/time scales) with in-transit visualization and 2) a closed-loop workflow optimized by machine learning, coupling a robot with a neural network simulation. We provide a detailed overview of the application-integrated monitoring in relationship with the HPC job. We present here a novel usage model for large scale interactive multi-application workflows running on HPC systems which aims at reducing the complexity of deployment and execution, thus enabling new science.",https://ieeexplore.ieee.org/document/9188104/,2019 International Conference on High Performance Computing & Simulation (HPCS),15-19 July 2019,ieeexplore
10.1109/ROBOT.1996.506888,Stereo sketch: stereo vision-based target reaching behavior acquisition with occlusion detection and avoidance,IEEE,Conferences,"In this paper, we proposed a method by which a stereo vision-based mobile robot learns to reach a target by detecting and avoiding occlusions. We call the internal representation that describes the learning behavior ""stereo sketch"". First, an input scene is segmented into homogeneous regions by the enhanced ISODATA algorithm with minimum description length principle in terms of image coordinates and disparity information obtained from the fast stereo matching unit based on the coarse-to-fine control method. Then, in terms of the segmented regions including the target area and their occlusion status identified during the stereo and motion disparity estimation process, we construct a state space for the reinforcement learning method to obtain a target reaching behavior. As a result the robot can avoid obstacles without explicitly describing them. We give the computer simulation results and real robot implementation to show the validity of our method.",https://ieeexplore.ieee.org/document/506888/,Proceedings of IEEE International Conference on Robotics and Automation,22-28 April 1996,ieeexplore
10.1109/ICCE46568.2020.9042995,Stroke Signs Detection System by SNS Agency Robot,IEEE,Conferences,"This paper proposes a system which implements the Cincinnati Prehospital Stroke Scale (CPSS), the widely used screening method for the initial symptoms of a stroke, in a communication robot. AI on cloud analyses an acquired video through a conversation with the robot in real time and automatically determines the abnormalities. The judgement result is informed to his/her families by SNS. This study implemented two of the three CPSS scales such as “Arms” and “Speech”, we confirmed that the system enables to acquire, analyze and notify the information in real time.",https://ieeexplore.ieee.org/document/9042995/,2020 IEEE International Conference on Consumer Electronics (ICCE),4-6 Jan. 2020,ieeexplore
10.1109/IMCEC.2018.8469727,Study on Interactive Robots with Contingent Responses,IEEE,Conferences,"In the study of human-robot interaction, how to engage humans with robots and how to measure the engagement level are the important questions. Current study and technology achieved user habit adaptable intelligent system, whereas this technology relies heavily on the history of user behaviour and it always take a long time for the robots to make adjustments. However, this technology can hardly meet the demand from society anymore as people are expecting robots to adapt to user preferences in a shorter period. Due to the massive calculation for computer and complexity of system, research on robots with contingent response is still at early stage. Most relevant studies focus on one specific task that involves interacting with users and there is one project that focuses on finding elements that determine user behaviours. An experiment is designed to better investigate the factors that determine user engagement level.",https://ieeexplore.ieee.org/document/8469727/,"2018 2nd IEEE Advanced Information Management,Communicates,Electronic and Automation Control Conference (IMCEC)",25-27 May 2018,ieeexplore
10.1109/WCICA.2008.4592802,Study on robot perception system of multi-sensors information fusion based on fuzzy neural network,IEEE,Conferences,"This paper developed three subsystems of robot perceptive system: visual, aural and olfactory for a three DOF robot perceptive system, which can get the primary location of the target by aural sensor, the exact location and tailing of the target, and estimation the location parameter by CCD camera. The olfactory sensor was used to detect whether there were dangerous gases around or not. The multi-sensor fusion model and arithmetic based on fuzzy neural network were presented in this paper, design the input and output of every layer, utilized BP arithmetic to adjust the weight and the parameter of the fuzzy neural network and obtained different subject functions thereby created relevant fuzzy rules to actualize fuzzy decision. Finish the precise location and real-time tracking. Simulating the perceptive process of the robot used Matlab, obtained the curves of the practical output and the experiment output, validated the validity of using fuzzy neural network to fuse the visual and aural heterogeneous-sensors.",https://ieeexplore.ieee.org/document/4592802/,2008 7th World Congress on Intelligent Control and Automation,25-27 June 2008,ieeexplore
10.1109/IJCNN.2008.4634389,Supporting mixed initiative human-robot interaction: A script-based cognitive architecture approach,IEEE,Conferences,"As complex indoor-robot systems are developed and deployed into the real-world, the demand for human-robot interaction is increasing. Mixed-initiative human-robot interaction is a good method to coordinate actions of a human and a robot in a complementary fashion. In order to support such interactions, we employ scripts that are rich, flexible, and extensible for a robotpsilas interactions in a variety of situations. Scripts are amenable for expressing knowledge in an applicable form, especially describing a sequence of actions in organizing tasks. In this paper, we propose a script-based cognitive architecture for collaboration, which is based on three-level cognitive models. It incorporates dynamic Bayesian network (DBN) to automatically govern action sequences in the scripts and detect userpsilas intention or goal. Starting from an understanding of user initiatives, our intelligent task manager suggests the most relevant initiatives for an efficient collaboration. DBN has been evaluated in real indoor task scenarios for its efficacy in interaction reduction, error minimization, and task satisfaction.",https://ieeexplore.ieee.org/document/4634389/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/IJCNN.2003.1223978,Systemic intelligence: methods for growing up artefacts that live,IEEE,Conferences,"The ideas of systemic intelligence provide a set of methodologies and paradigms that are, beside other advantages, suitable for constructing control systems that are capable of growing up. In particular the promising methods of systemic architecture, schedule of structural development, memory organization and rules for learning and adaptation are presented and discussed with respect to grow up an artifact. Of special interest is the concept of growth in the sense of growing up from a kind of infantile stage to a fully matured entity. To grow up an artifact from an infantile stage via a sequence of learned abilities to,a fully matured entity is still a feature of life not yet sufficiently transposed onto technical systems. To enable the capability to grow up artifacts, a set of methodologies and principles is presented in this paper. The developed methodologies are already implemented into physically existing test beds that operate, adapt (and grow up) in real time and in the real world to prove that the proposed approach is feasible under real conditions. Two realizations (robot control, audio signal processing) of a systemic architecture for an up-growing system are presented in this paper.",https://ieeexplore.ieee.org/document/1223978/,"Proceedings of the International Joint Conference on Neural Networks, 2003.",20-24 July 2003,ieeexplore
10.1109/IIAI-AAI.2014.4,Table of contents,IEEE,Conferences,The following topics are dealt with: data mining; Japanese WordNet synonym misplacement detection; social network; recommender system; sentiment analysis; workshop-based instruction; Japanese public libraries; machine learning methods; collaborative Web presentation support system; SMS4 ultracompact hardware implementation; wireless sensor networks; personalized public transportation recommendation system; adaptive user interface; NIS-Apriori algorithm; GetRNIA software tool; rough set-based rule generation; tree-Ga bump hunting; neural network model; weighted citation network analysis; sound proofing ventilation unit; touch interaction; mutually dependent Markov decision processes; ozone treatment; dynamic query optimization; big data; learner activity recognition; IoT-security approach; nutrition-based vegetable production; farm product cultivation; polynomial time mat learning; C-deterministic regular formal graph system; article abstract key expression extraction; English text comprehension; online social games; knowledge creation; knowledge utilization; online stock trading; customer behavior analysis; project-based collaborative learning; in-field mobile game-based learning activities; e-portfolio system design; self-regulated learning ontological model; mobile augmented reality based scaffolding platform; context-aware mobile Japanese conversation learning system; English writing error classification; image processing; outside-class learning; exercise-centric teaching materials; UML modeling; online historical document reading literacy; MMORPG-based learning environment; computer courses; undergraduate education; energy management system; higher education; decentralised auction-based bandwidth allocation; wireless networked control systems; resource scheduling algorithm; embedded cloud computing; Poisson distribution; Japanese seismic activity; suspect vehicle detection; 3D network traffic visualization; Web information retrieval; agent based disaster evacuation assist system; electroencephalogram; random number generator; multiagent simulations; multicore environment; CPU scheduler; multithreaded processes; reserve-price biddings; real-time traffic signal control; evolutionary computation; robot-assisted rehabilitation system; hybrid automata; Batik motif classification; color-texture-based feature extraction; backpropagation; multimedia storytelling; e-tourism service; Web mining; search engine; simulation-based e-learning mobile application software; library classification training system; WebQuest learning strategy; context-aware ubiquitous English learning; support vector machine; RFID tag ownership transfer protocol; cognitive linguistics; collaborative software engineering learning; write-access reduction method; NVM-DRAM hybrid memory; garbage collection; parallel indexing scheme; lazy-updating snoop cache protocol; distributed storage system; ITS application; software engineering education; ophthalmic multimodal imaging system; injected bug classification; secure live virtual machine migration; flash memory management; genetic programming; heterogeneous databases; time series similarity search; concurrency control program generation; incremental data migration; multidatabase system; software release time decision making; analytic hierarchy process; interactive genetic algorithm; biometric intelligence; talking robots; archaeological ruin analysis; GIS; optical wireless pedestrian-support systems; visual impairment; extreme programming; Japanese e-commerce Web sites; Chinese sign language animation; hearing-impaired people mammography inspection; geographical maps; electroculogram; XML element retrieval technique; image recognition; reinforcement learning; ECU formal verification; gasoline direct injection engines; earthquake disaster simulation; smart devices for autistic children; RoboCup rescue simulation; inductive logic programming; master-slave asynchronous evolutionary hybrid algorithm; VANET routing optimization; and Web image sharing services.,https://ieeexplore.ieee.org/document/6913248/,2014 IIAI 3rd International Conference on Advanced Applied Informatics,31 Aug.-4 Sept. 2014,ieeexplore
10.1109/ICMA52036.2021.9512666,Target Detection and Tracking of Ground Mobile Robot Based on Improved Single Shot Multibox Detector Network,IEEE,Conferences,"To solve the problems of slow labeling speed of the traditional labellmg data set establishment method, and slow running speed of target classification and detection algorithm based on Single Shot Multibox Detector(SSD) deep learning network, this paper proposes a fast data set labeling algorithm and a fast SSD network for target real-time detection and tracking research. First, a data set is established quickly by using TLD target detection and tracking algorithms, cropping and mirroring methods are used to strengthen the data set. Then, SSD backbone network is improved based on depth-wise separable convolution to establish a fast SSD network. Finally, the ground mobile robot in RoboMasters(RM) competition is used as the detection and tracking target indoors and outdoors, as well as with other different scenarios with shield to test the real-time performance, accuracy and effectiveness of the algorithm. The results show that compared with traditional SSD network research, in terms of the analysis and processing system deployed on low-performance hardware, the improved fast SSD network can better meet the real-time requirements of target detection and tracking.",https://ieeexplore.ieee.org/document/9512666/,2021 IEEE International Conference on Mechatronics and Automation (ICMA),8-11 Aug. 2021,ieeexplore
10.1109/CIRA.1997.613854,Task decomposition and dynamic policy merging in the distributed Q-learning classifier system,IEEE,Conferences,A distributed reinforcement learning system is designed and implemented on a mobile robot for the study of complex task decomposition and dynamic policy merging in real robot learning environments. The distributed Q-learning classifier system (DBLCS) is evolved from the standard LCS proposed by Holland (1996). We address two of the limitations of the LCS through the use of Q-learning as the apportionment of credit component and a distributed learning architecture to facilitate complex task decomposition. The Q-learning update equation is derived and its advantages over the complex bucket brigade algorithm (BBA) are discussed. Holistic and monolithic shaping approaches are used to distribute reward among the learning modules of the DBLCS and allow dynamic policy merging in a variety of real robot learning experiments.,https://ieeexplore.ieee.org/document/613854/,Proceedings 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA'97. 'Towards New Computational Principles for Robotics and Automation',10-11 July 1997,ieeexplore
10.1109/IROS.1999.812762,Task-model based human robot cooperation using vision,IEEE,Conferences,"In order to assist a human, the robot must recognize human motion in real time by vision, and must plan and execute the needed assistance motion based on the task purpose and the context. In this research, we tried to solve such problems. We defined the abstract task model, analyzed the human demonstration by using events and an event stack, and automatically generated the task models needed in the assistance by the robot. The robot planned and executed the appropriate assistance motions based on the task: models according to the human motions in the cooperation with the human. We implemented a 3D object recognition system and a human grasp recognition system by using trinocular stereo color cameras and a real time range finder. The effectiveness of these methods was tested through an experiment in which the human and the robotic hand assembled toy parts in cooperation.",https://ieeexplore.ieee.org/document/812762/,Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289),17-21 Oct. 1999,ieeexplore
10.1109/IEEECONF49454.2021.9382607,Teaching System for Multimodal Object Categorization by Human-Robot Interaction in Mixed Reality,IEEE,Conferences,"As service robots are becoming essential to support aging societies, teaching them how to perform general service tasks is still a major challenge preventing their deployment in daily-life environments. In addition, developing an artificial intelligence for general service tasks requires bottom-up, unsupervised approaches to let the robots learn from their own observations and interactions with the users. However, compared to the top-down, supervised approaches such as deep learning where the extent of the learning is directly related to the amount and variety of the pre-existing data provided to the robots, and thus relatively easy to understand from a human perspective, the learning status in bottom-up approaches is by their nature much harder to appreciate and visualize. To address these issues, we propose a teaching system for multimodal object categorization by human-robot interaction through Mixed Reality (MR) visualization. In particular, our proposed system enables a user to monitor and intervene in the robot's object categorization process based on Multimodal Latent Dirichlet Allocation (MLDA) to solve unexpected results and accelerate the learning. Our contribution is twofold by 1) describing the integration of a service robot, MR interactions, and MLDA object categorization in a unified system, and 2) proposing an MR user interface to teach robots through intuitive visualization and interactions.",https://ieeexplore.ieee.org/document/9382607/,2021 IEEE/SICE International Symposium on System Integration (SII),11-14 Jan. 2021,ieeexplore
10.1109/EIT51626.2021.9491894,Teaching Vehicles to Steer Themselves with Deep Learning,IEEE,Conferences,Traditional approaches for steering a vehicle using machine vision require large amounts of robust hand-crafted software which is both time consuming and expensive. The presented method uses a deep neural network to teach cars to steer themselves without any additional software. We created a labeled dataset for the ACTor (Autonomous Campus TranspORt) electric vehicle by pairing real world images taken during a drive with the associated steering wheel angle. We trained a model end to end using modern deep learning techniques including convolutional neural networks and transfer learning to automatically detect relevant features in the input and provide a predicted output. This means that no traditional hand engineered algorithm features were required for this implementation. We currently use an pretrained inception network on the ImageNet dataset to leverage the high level features learned from ImageNet to the steering problem through transfer learning. We removed the top portion of the network and replaced it with a linear regression node to provide the output. The model is trained end to end using backpropagation. The trained model is integrated with vehicle software on ROS (Robot Operating System) to read image data and provide a corresponding steering angle in real time. The current model achieves 15.2 degree error on average. As development continues the model may replace the current lane centering software and will be used for IGVC Self-Drive competition and campus transportation.,https://ieeexplore.ieee.org/document/9491894/,2021 IEEE International Conference on Electro Information Technology (EIT),14-15 May 2021,ieeexplore
10.1109/CEC.2015.7257174,Teaching a series of actions by the universal evaluations of each sensory information,IEEE,Conferences,"Various studies related to reinforcement learning(RL) have been performed. RL is a simple and powerful learning method so it is used for a real robot. In ordinary RL, a reward function is designed to teach a given task. Generally the design of this function is difficult and laborious work because of the need of the consideration about a given task and environment beforehand and the need of the expert knowledge about a reward. This means an agent learned from external sources, not autonomously. To solve this problem, we proposed the method of machine learning through interactions which is independent of any task and environment. In previous works for path planning problem, the method can lead an agent to a goal point by the interaction of an agent with a human and environment. But the effects from a human and environment were mixed and we did not confirm that a human can teach an agent a series of actions under the condition that environment forces an agent to take different actions. In this paper, we recruit four men as participants and instruct them not to lead a goal but to teach a route. We experiment with path planning problem and confirm that a human can teach an agent his/her intention perfectly.",https://ieeexplore.ieee.org/document/7257174/,2015 IEEE Congress on Evolutionary Computation (CEC),25-28 May 2015,ieeexplore
10.1109/FIE.2008.4720346,"Teaching concepts in fuzzy logic using low cost robots, PDAs, and custom software",IEEE,Conferences,"Fuzzy logic is a topic traditionally taught in artificial intelligence, machine learning, and robotics courses. Students receive the necessary mathematical and theoretical foundation in lecture format. The final learning experience may require that students create and code their own fuzzy logic application that solves a real world problem. This can be an issue when the target is a bioengineering course that introduces classical control theory, fuzzy logic, neural networks, genetic algorithms and genetic programming through the use of a low cost robot, personal digital assistant (PDA) handheld computer, and custom PDA software. In this course, the concepts and theories discussed in lecture are reinforced and extended in a corresponding laboratory through the use of wireless robots and PDAs. Fuzzy logic libraries and software modules for laptops and desktop computers are readily available, however, when it comes to handheld computers no such libraries exist. Students are able to spend more time experimenting with different fuzzy logic controllers when a custom fuzzy logic library and PDA graphical user interface are utilized. In this paper we introduce and discuss a unique low cost wireless robot, a custom fuzzy logic library, a custom fuzzy logic GUI for the PDA, and the implementation results for the fuzzy logic section in a newly created bioengineering course. Diagnostic and summative assessment in the form of a pre-test and post-test was administered for each section of the course, however, only the results for the fuzzy logic section will be provided.",https://ieeexplore.ieee.org/document/4720346/,2008 38th Annual Frontiers in Education Conference,22-25 Oct. 2008,ieeexplore
10.1109/IROS.2013.6696802,Teaching mobile robots to cooperatively navigate in populated environments,IEEE,Conferences,"Mobile service robots are envisioned to operate in environments that are populated by humans and therefore ought to navigate in a socially compliant way. Since the desired behavior of the robots highly depends on the application, we need flexible means for teaching a robot a certain navigation policy. We present an approach that allows a mobile robot to learn how to navigate in the presence of humans while it is being teleoperated in its designated environment. Our method applies feature-based maximum entropy learning to derive a navigation policy from the interactions with the humans. The resulting policy maintains a probability distribution over the trajectories of all the agents that allows the robot to cooperatively avoid collisions with humans. In particular, our method reasons about multiple homotopy classes of the agents' trajectories, i. e., on which sides the agents pass each other. We implemented our approach on a real mobile robot and demonstrate that it is able to successfully navigate in an office environment in the presence of humans relying only on on-board sensors.",https://ieeexplore.ieee.org/document/6696802/,2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,3-7 Nov. 2013,ieeexplore
10.1109/WCICA.2006.1713788,Tele-Lightsaber - A Kind of Competitive Teleoperation<sup>*</sup>,IEEE,Conferences,"To improve the performance of telerobot system, which takes complex tasks with strong interaction under unexpected environment, a branch of teleoperation, competitive teleoperation, has been deeply studied. A kind of attack-defend competitive teleoperation experiment, which name Tele-Lightsaber (TLS), has been designed on TTRP (teleoperation/telegame robot platform) to imitate the action of two intelligent agents in real world. The design of TLS is presented in detail in this paper",https://ieeexplore.ieee.org/document/1713788/,2006 6th World Congress on Intelligent Control and Automation,21-23 June 2006,ieeexplore
10.1109/ICARSC.2015.19,Testing a Fully Autonomous Robotic Salesman in Real Scenarios,IEEE,Conferences,"Over the past decades, the number of robots deployed in museums, trade shows and exhibitions have grown steadily. This new application domain has become a key research topic in the robotics community. Therefore, new robots are designed to interact with people in these domains, using natural and intuitive channels. Visual perception and speech processing have to be considered for these robots, as they should be able to detect people in their environment, recognize their degree of accessibility and engage them in social conversations. They also need to safely navigate around dynamic, uncontrolled environments. They must be equipped with planning and learning components, that allow them to adapt to different scenarios. Finally, they must attract the attention of the people, be kind and safe to interact with. In this paper, we describe our experience with Gualzru, a salesman robot endowed with the cognitive architecture RoboCog. This architecture synchronizes all previous processes in a social robot, using a common inner representation as the core of the system. The robot has been tested in crowded, public daily life environments, where it interacted with people that had never seen it before nor had a clue about its functionality. Experimental results presented in this paper demonstrate the capabilities of the robot and its limitations in these real scenarios, and define future improvement actions.",https://ieeexplore.ieee.org/document/7101621/,2015 IEEE International Conference on Autonomous Robot Systems and Competitions,8-10 April 2015,ieeexplore
10.1109/ICIA.2006.305788,The Design and Implementation of OpenGL-based Comprehensive Educational Robot System,IEEE,Conferences,"In this paper, the authors present the design and implementation of MountTai, a cost effective OpenGL based comprehensive educational robot system for China's primary and high school education. Firstly the system's goal and framework is introduced, then it is described the MountTai robot's functions and construction in hardware. The paper expatiates at length how VR technology is used to implement the system software as well as how the software's functions are designed to illustrate robotics in different perspectives relating to mechanics, electronics, communication, artificial intelligence, language programming. The Web-based teaching course dedicated to robot-DIY tutorials is also shown. Finally, concluding remarks for future works are given.",https://ieeexplore.ieee.org/document/4097992/,2006 IEEE International Conference on Information Acquisition,20-23 Aug. 2006,ieeexplore
10.1109/RCAR52367.2021.9517509,The Measuring ZMP of Self-Balancing Exoskeleton Robot is Calibrated by Using The Neural Network,IEEE,Conferences,"The exoskeleton robot is an auxiliary device to help the disabled people walk, and the self-balancing exoskeleton robot is one which is to keep balance without the assistance of external crutches. In order to keep the balance of the self-balancing exoskeleton robot, it is necessary to get the position of the Zero Moment Point by measuring the pressure of the footplate, and make the position of ZMP in range of supporting area. In this experiment, the footplate is used with the double-deck structure, this structure is compared with the single-deck structure, the double-dack structure will not lose the information of the collected ZMP without direct touch with the sensor, and it is lighter than another structure with dozens of sensors. But there is an inevitable structural coupling in the double-deck structure, which makes the ZMP have a large measurement error. In order to solve this problem, a novel idea is proposed, with the help of the powerful processing and learning capabilities of the neural network, four kinds of neural networks are used to calibrate measured position of ZMP so that reducing error of the measured ZMP. By comparing position of the actual ZMP before and after the calibration with the ideal position of ZMP and computing the errors to judge the effect of the calibration. Through experimental comparison, it is concluded that the different neural networks eliminate error of the measured ZMP in different extent. When the GRNN neural network is used to calibrate position of ZMP, the effect is the most ideal.",https://ieeexplore.ieee.org/document/9517509/,2021 IEEE International Conference on Real-time Computing and Robotics (RCAR),15-19 July 2021,ieeexplore
10.1109/ICMLC.2002.1174408,The approach of extracting features from the local environment for mobile robot,IEEE,Conferences,"A new data fusion method to extract features from the local environment for a mobile robot's navigation has been developed and implemented. This method, named the obstacle group, compresses data in a series of levels in order to reduce the quantity of data for communication between modules in a distributed single-robot system, or between all the robots and the central station in a multi-robot system. The method based on a grid map and an active window has strong adaptability and is real-time in a crowded environment. Experimental results demonstrate that the robot can successfully avoid collisions and plan its path by using this method.",https://ieeexplore.ieee.org/document/1174408/,Proceedings. International Conference on Machine Learning and Cybernetics,4-5 Nov. 2002,ieeexplore
10.1109/IJCNN.2008.4633777,"The development of a hybrid, distributed architecture for multiagent systems and its application in robot soccer",IEEE,Conferences,"Several issues still need to be unraveled in the development of multiagent systems equipped with global vision, as in robot soccer leagues. Here, we underscore three of them (1) real-time constraints on recognition of scene objects; (2) acquisition of environment knowledge; and (3) distribution and allocation of control competencies shared between the repertoire of the agentpsilas reactive behavior, and the central control entitypsilas strategic and deliberative behavior. The objective of this article is to describe the implementation of a distributed and hybrid reactive-deliberative control architecture for a multiagent system, equipped with global vision camera and agent local sensor and cameras. This multiple agent system was developed for application in robot soccer. We present the digital image processing techniques applied, as well as the proposed control architecture aimed at satisfying the constraints of this kind of application.",https://ieeexplore.ieee.org/document/4633777/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/DEVLRN.2002.1011728,The development of gaze following as a Bayesian systems identification problem,IEEE,Conferences,"We propose a view of gaze following in which infants act as Bayesian learners actively attempting to identify the operating characteristics of the systems with which they interact. We present results of an experiment in which 28 infants (average age 10 months) interacted for a 3 minute period with a non-humanoid robot. For half the infants the robot simulated contingency structure typically produced by human beings. In particular it provided causal information about the existence of a line of regard. For the other 14 infants, the robot behaved in a manner which was not contingent with the environment. We found that a few minutes of interaction with the contingent robot was sufficient to elicit statistically detectable gaze following. There were clear signs that some of these infants were actively attempting to identify whether or not the robot was responsive to them. We propose that the infant brain is equipped to learn and analyze the contingency structure of real-time social interactions. Contingency is a fundamental perceptual dimension used by infants to recognize the operational properties of humans and to generalize existing behaviors to new social partners.",https://ieeexplore.ieee.org/document/1011728/,Proceedings 2nd International Conference on Development and Learning. ICDL 2002,12-15 June 2002,ieeexplore
10.1109/VECIMS.2009.5068923,The hand shape recognition of Human Computer Interaction with Artificial Neural Network,IEEE,Conferences,"The hand gestures used in Human Computer Interaction (HCI) are generally posed by complicated and large amplitude actions of arm /hand. Thus usable HCI instructions are few and HCI efficiency is low. This paper presents new hand shapes and the corresponding recognition system for the HCI with robot or Coordinate Measuring Machine. Using a touch pad to precept the touching of fingers, hand shapes posed to express HCI instructions are defined by the combinations of 2 binary status, i.e. status of touching /detaching on touch pad and status of stretching /retracting over touch pad, of Index, Middle, Ring and Little fingers. Method of extracting the features in hand shape image is presented. Based on Neural Network, a decision binary tree is used in the real-time recognition of the hand shapes. A correctness ratio of about 95% is obtained when implemented by DSP processor in the recognition of 12 hand shapes.",https://ieeexplore.ieee.org/document/5068923/,"2009 IEEE International Conference on Virtual Environments, Human-Computer Interfaces and Measurements Systems",11-13 May 2009,ieeexplore
10.1109/ICSESS.2015.7339119,The research and implementation of artificial intelligence in mobile applications,IEEE,Conferences,"This paper designs and implements the bionic robot which is as an implementation of soldiers in the strategy game, and the robot has three parts: perception system, target and path system and decision-making system. The perception system is responsible for perceiving information inside the scene; the target and path system is to find the best position for attacking and the optimal path for the robot; the decision-making system determines the behavior of the robot in the next frame. This paper also introduces map information updated in real time in the game. The bionic robot system designed has a good expansibility, and soldiers of different arms using this system, the game is running well.",https://ieeexplore.ieee.org/document/7339119/,2015 6th IEEE International Conference on Software Engineering and Service Science (ICSESS),23-25 Sept. 2015,ieeexplore
10.1109/CECNET.2011.5768706,The research application of inspection robot for the smart grid,IEEE,Conferences,"Catering to the new strategic project of smart grid, this paper introduces a design of high-voltage transmission inspection robot, which worked on earth wire and so that automatically inspection on the entire transmission line becomes the reality. Robot control system using hierarchical control structure, included remote management host, robot control ontology and motor drives. Under the auto-operation mode, it makes its own decisions for planning the sequence of operations according to knowledge data base without the upper layer's involvement. Using image recognition obstacle and expert data base, the combined method of using laser sensor over obstacles, the inspection robot autonomous obstacle had came true. The experiment and test results show that the inspection robot system has possessed the capabilities of navigation and inspection tasks on the power lines. It has a good application prospect.",https://ieeexplore.ieee.org/document/5768706/,"2011 International Conference on Consumer Electronics, Communications and Networks (CECNet)",16-18 April 2011,ieeexplore
10.1109/ISIE.1998.711559,The sensor-control Jacobian as a basis for controlling calibration-free robots,IEEE,Conferences,"A method for controlling the motions of robots is presented. It is based on the newly introduced sensor-control Jacobian matrix and avoids all quantitative modeling of the robot and the sensor system. The sensor-control Jacobian contains the coefficients that relate those changes in sensor data which are caused by a motion of the robot to the robot control words that caused the robot to move and, thus, the sensor data to change. A wide variety of tasks of robots can be reduced to minimizing the differences between actual sensor data and a set of hypothetical sensor data corresponding to some desired state. All these tasks can be solved by this method. The method is especially useful for calibration-free robots, since neither quantitative models of the mechanical, kinematic and control characteristics of the robot, nor knowledge of the sensor characteristics are required. The sensor-control Jacobian may be determined automatically in real time while the robot is operating. This yields a high degree of adaptability and flexibility against unforeseen changes in the robot's parameters. Because the concept has an open structure it allows further extensions and improvements, e.g., in terms of the utilization of sensor data redundancy and machine learning. For the purpose of evaluation, the concept has been implemented on a calibration-free camera-manipulator system. Real-world grasping experiments have demonstrated the effectiveness of the method.",https://ieeexplore.ieee.org/document/711559/,IEEE International Symposium on Industrial Electronics. Proceedings. ISIE'98 (Cat. No.98TH8357),7-10 July 1998,ieeexplore
10.1109/ACSSC.2003.1292255,The use of CNN models and vertical rectification for a direct trigonometric recovery of 3D scene geometry from a stream of images,IEEE,Conferences,"The exploration of unknown environment autonomously and intelligently by autonomous mobile robot is one of the main problems that still have to be solved. From the biological systems it appears that it is not only a matter of computational power but also the right sensors and methods of implementation. In this work we understood that the invention of the powerful and practically realizable, emerging paradigm called cellular nonlinear network (CNN) fully realized the concept of real-time handling of time signals coining from space distribution sources. On the other hand inertial gyro sensor can increase the robustness and computing efficiency of vision system, which is subject to signal degradation and high computational expense, by providing a frame-to-frame prediction of camera orientation and position. Since most of the earlier or recent studies have tackled the artificial vision with two or three views in account, in this work we present a direct trigonometric recovery of 3D scene geometry from a stream of images. These images are vertically rectified using gyroscopes' output to minimize the token relative displacements between each frame. To match this vertically rectified stream of images in real-tune we borrow the strength of CNN, and the matching results are trigonometrically processed for 3D range estimation.",https://ieeexplore.ieee.org/document/1292255/,"The Thrity-Seventh Asilomar Conference on Signals, Systems & Computers, 2003",9-12 Nov. 2003,ieeexplore
10.1109/ICRoM.2015.7367775,Time optimized digital image processing of ball and plate system using artificial neural network,IEEE,Conferences,"Regarding robot interaction with moving objects and the necessity for robot controller to react in a timely manner having the objects current position, finding an efficient positioning method has always been a challenge. As ball and plate system is considered to be a standard experimental system in control laboratories. The system is consisted of the following pieces: a horizontal plate which gets tilted along each horizontal axes. The ball, which is located on the plate; is controlled by the system in a way to be placed in any point on the plate. In fact, the ball and plate system is an extension of the classical ball on beam experiment that is often used to study various types of control and stability problems.",https://ieeexplore.ieee.org/document/7367775/,2015 3rd RSI International Conference on Robotics and Mechatronics (ICROM),7-9 Oct. 2015,ieeexplore
10.1109/BEC.2010.5631008,Timed Automata based provably correct robot control,IEEE,Conferences,"This paper presents a feasibility study on the usage of Uppaal Timed Automata (UPTA) for deliberative level robotic control. The study is based on the Scrub Nurse Robot case-study. Our experience confirms that UPTA model based control enables the control loop to be defined and maintained during the robot operation autonomously with minimum human intervention. Specifically, in our robot architecture the control model is constructed automatically using unsupervised learning. Correctness of the model is verified on-the-fly against safety, reachability, and performance requirements. Finally, it is demonstrated that UPTA model based robot control, action planning and model updates have natural implementation based on existing model execution and conformance testing tool Uppaal Tron.",https://ieeexplore.ieee.org/document/5631008/,2010 12th Biennial Baltic Electronics Conference,4-6 Oct. 2010,ieeexplore
10.1109/ICRA.2011.5980333,To look or not to look: A hierarchical representation for visual planning on mobile robots,IEEE,Conferences,"Mobile robots are increasingly being used in real-world applications due to the ready availability of high fidelity sensors and the development of sophisticated information processing algorithms. However, one key challenge to the widespread deployment of mobile robots equipped with multiple sensors and processing algorithms is the ability to autonomously tailor sensing and information processing to the task at hand. This paper poses this challenge as the task of planning under uncertainty, and more specifically as an instance of probabilistic sequential decision-making. A novel hierarchy of partially observable Markov decision processes (POMDPs) is incorporated, which uses constrained-convolutional policies and automatic belief propagation to achieve efficient and reliable operation on mobile robots. All algorithms are implemented and evaluated on simulated and physical robot platforms for the task of searching for target objects in dynamic indoor environments.",https://ieeexplore.ieee.org/document/5980333/,2011 IEEE International Conference on Robotics and Automation,9-13 May 2011,ieeexplore
10.1109/IECON.2016.7793038,Tool compensation in walk-through programming for admittance-controlled robots,IEEE,Conferences,"This paper describes a walk-through programming technique, based on admittance control and tool dynamics compensation, to ease and simplify the process of trajectory learning in common industrial setups. In the walk-through programming, the human operator grabs the tool attached at the robot end-effector and “walks” the robot through the desired positions. During the teaching phase, the robot records the positions and then it will be able to interpolate them to reproduce the trajectory back. In the proposed control architecture, the admittance control allows to provide a compliant behavior during the interaction between the human operator and the robot end-effector, while the algorithm of compensation of the tool dynamics allows to directly use the real tool in the teaching phase. In this way, the setup used for the teaching can directly be the one used for performing the reproduction task. Experiments have been performed to validate the proposed control architecture and a pick and place example has been implemented to show a possible application in the industrial field.",https://ieeexplore.ieee.org/document/7793038/,IECON 2016 - 42nd Annual Conference of the IEEE Industrial Electronics Society,23-26 Oct. 2016,ieeexplore
10.1109/CoASE.2014.6899348,Toward safe close-proximity human-robot interaction with standard industrial robots,IEEE,Conferences,"Allowing humans and robots to interact in close proximity to each other has great potential for increasing the effectiveness of human-robot teams across a large variety of domains. However, as we move toward enabling humans and robots to interact at ever-decreasing distances of separation, effective safety technologies must also be developed. While new, inherently human-safe robot designs have been established, millions of industrial robots are already deployed worldwide, which makes it attractive to develop technologies that can turn these standard industrial robots into human-safe platforms. In this work, we present a real-time safety system capable of allowing safe human-robot interaction at very low distances of separation, without the need for robot hardware modification or replacement. By leveraging known robot joint angle values and accurate measurements of human positioning in the workspace, we can achieve precise robot speed adjustment by utilizing real-time measurements of separation distance. This, in turn, allows for collision prevention in a manner comfortable for the human user.We demonstrate our system achieves latencies below 9.64 ms with 95% probability, 11.10 ms with 99% probability, and 14.08 ms with 99.99% probability, resulting in robust real-time performance.",https://ieeexplore.ieee.org/document/6899348/,2014 IEEE International Conference on Automation Science and Engineering (CASE),18-22 Aug. 2014,ieeexplore
10.1109/ASAP.2018.8445099,Towards Hardware Accelerated Reinforcement Learning for Application-Specific Robotic Control,IEEE,Conferences,"Reinforcement Learning (RL) is an area of machine learning in which an agent interacts with the environment by making sequential decisions. The agent receives reward from the environment based on how good the decisions are and tries to find an optimal decision-making policy that maximises its longterm cumulative reward. This paper presents a novel approach which has showon promise in applying accelerated simulation of RL policy training to automating the control of a real robot arm for specific applications. The approach has two steps. First, design space exploration techniques are developed to enhance performance of an FPGA accelerator for RL policy training based on Trust Region Policy Optimisation (TRPO), which results in a 43% speed improvement over a previous FPGA implementation, while achieving 4.65 times speed up against deep learning libraries running on GPU and 19.29 times speed up against CPU. Second, the trained RL policy is transferred to a real robot arm. Our experiments show that the trained arm can successfully reach to and pick up predefined objects, demonstrating the feasibility of our approach.",https://ieeexplore.ieee.org/document/8445099/,"2018 IEEE 29th International Conference on Application-specific Systems, Architectures and Processors (ASAP)",10-12 July 2018,ieeexplore
10.1109/ROBOT.2007.364220,Towards Mapping of Cities,IEEE,Conferences,"Map learning is a fundamental task in mobile robotics because maps are required for a series of high level applications. In this paper, we address the problem of building maps of large-scale areas like villages or small cities. We present our modified car-like robot which we use to acquire the data about the environment. We introduce our localization system which is based on an information filter and is able to merge the information obtained by different sensors. We furthermore describe out mapping technique that is able to compactly model three-dimensional scenes and allows us efficient and accurate incremental map learning. We additionally apply a global optimization techniques in order to accurately close loops in the environment. Our approach has been implemented and deeply tested on a real car equipped with a series of sensors. Experiments described in this paper illustrate the accuracy and efficiency of the presented techniques.",https://ieeexplore.ieee.org/document/4209838/,Proceedings 2007 IEEE International Conference on Robotics and Automation,10-14 April 2007,ieeexplore
10.1109/RO-MAN50785.2021.9515348,Towards Out-of-Sight Predictive Tracking for Long-Term Indoor Navigation of Non-Holonomic Person Following Robot<sup>*</sup>,IEEE,Conferences,"The ability to predict the movements of the target person allows a person following robot (PFR) to coexist with the person while still complying with the social norms. In human-robot collaboration, this is an essential requisite for long-term time-dependent navigation and not losing sight of the person during momentary occlusions that may arise from a crowd due to static or dynamic obstacles, other human beings, or intersections in the local surrounding. The PFR must not only traverse to the previously unknown goal position but also relocate the target person after the miss, and resume following. In this paper, we try to solve this as a coupled motion-planning and control problem by formulating a model predictive control (MPC) controller with non-linear constraints for a wheeled differential-drive robot. And, using a human motion prediction strategy based on the recorded pose and trajectory information of both the moving target person and the PFR, add additional constraints to the same MPC, to recompute the optimal controls to the wheels. We make comparisons with RNNs like LSTM and Early Relocation for learning the best-predicted reference path.MPC is best suited for complex constrained problems because it allows the PFR to periodically update the tracking information, as well as to adapt to the moving person’s stride. We show the results using a simulated indoor environment and lay the foundation for its implementation on a real robot. Our proposed method offers a robust person following behaviour without the explicit need for policy learning or offline computation, allowing us to design a generalized framework.",https://ieeexplore.ieee.org/document/9515348/,2021 30th IEEE International Conference on Robot & Human Interactive Communication (RO-MAN),8-12 Aug. 2021,ieeexplore
10.1109/ICRA40945.2020.9197446,Towards Plan Transformations for Real-World Mobile Fetch and Place,IEEE,Conferences,"In this paper, we present an approach and an implemented framework for applying plan transformations to real-world mobile manipulation plans, in order to specialize them to the specific situation at hand. The framework can improve execution cost and achieve better performance by autonomously transforming robot's behavior at runtime. To demonstrate the feasibility of our approach, we apply three example transformations to the plan of a PR2 robot performing simple table setting and cleaning tasks in the real world. Based on a large amount of experiments in a fast plan projection simulator, we make conclusions on improved execution performance.",https://ieeexplore.ieee.org/document/9197446/,2020 IEEE International Conference on Robotics and Automation (ICRA),31 May-31 Aug. 2020,ieeexplore
10.1109/AIVR.2018.00060,Towards a Music Visualization on Robot (MVR) Prototype,IEEE,Conferences,"This paper presents a Music Visualization on Robot (MVR) prototype system which automatically links the flashlight, color and emotion of a robot through music. The MVR system is divided into three portions. Firstly, the system calculates the waiting time for a flashlight by beat tracking. Secondly, the system calculates the emotion correlated with music mood. Thirdly, the system links the color with emotion. To illustrate the prototype on a robot, the prototype implementation is based on a programmable robot called Zenbo because Zenbo has 8 LED light colors on 2 wheels and 24 face emotions to support various compositions.",https://ieeexplore.ieee.org/document/8613679/,2018 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),10-12 Dec. 2018,ieeexplore
10.1109/IROS40897.2019.8968166,Towards a Robot Architecture for Situated Lifelong Object Learning,IEEE,Conferences,"The ability to acquire knowledge incrementally and after deployment is of utmost importance for robots operating in the real world. Moreover, robots that have to operate alongside people need to be able to interact in a way that is intuitive for the users, e.g., by understanding and producing natural language. In this paper we present a first prototype of a robot architecture developed for situated lifelong object learning. The system is able to communicate with its users through natural language and perform object learning and recognition on the spot through situated interactions. In this first stage, we evaluate the system in terms of recognition accuracy which gives an indirect measure of the quality of the collected data with the proposed pipeline. Our results show that the robot can use this data for both learning and recognition with acceptable incremental performance. We also discuss limitations and steps that are necessary in order to improve performance as well as to shed some light on system usability.",https://ieeexplore.ieee.org/document/8968166/,2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),3-8 Nov. 2019,ieeexplore
10.1109/ROBOT.1990.126044,Towards a real-time architecture for obstacle avoidance and path planning in mobile robots,IEEE,Conferences,"The design and partial implementation of a real-time architecture for a mobile robot, aimed particularly towards a vehicle developed for factory automation, is described. The authors develop a layered design to equip the robot with a number of behavioral competences. They examine sensing and a potential field algorithm especially to achieve modification of behavior at a speed close to the robot's operational speed. It is shown how the layered architecture interfaces to the original onboard architecture, which provided sophisticated localization but no ability to deal with environmental exceptions.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/126044/,"Proceedings., IEEE International Conference on Robotics and Automation",13-18 May 1990,ieeexplore
10.1109/AIM43001.2020.9158908,Towards accelerated robotic deployment by supervised learning of latent space observer and policy from simulated experiments with expert policies,IEEE,Conferences,"Up until today robotic tasks in highly variable environments remain very difficult to solve. We propose accelerated robotic deployment through task solving on low-level sensor data in simulation. A simulation allows for a lot of data, which is usually not available in a real world robotic setup due to cost and feasibility. Solving tasks in simulation is safe and a lot easier due to the huge amount of feedback from virtual sensory data. We present a novel sim2real architecture for converting simulated low level sensor data policies to high level real world policies. After solving a task we let the robot complete it a number of times in simulation using domain randomization, while doing so we save the simulated sensor data corresponding to the real robotic setup and actions taken. Given these sensor data and actions a task specific policy can be trained using our architecture. In this paper we work towards a proof of concept by simulating a simple low cost manipulator in pybullet to pick and place an object based on image observations.",https://ieeexplore.ieee.org/document/9158908/,2020 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM),6-9 July 2020,ieeexplore
10.1109/IROS.2015.7354134,Towards bridging the reality gap between tensegrity simulation and robotic hardware,IEEE,Conferences,"Using a new hardware implementation of our designs for tunably compliant spine-like tensegrity robots, we show that the NASA Tensegrity Robotics Toolkit can effectively generate and predict desirable locomotion strategies for these many degree of freedom systems. Tensegrity, which provides structural integrity through a tension network, shows promise as a design strategy for more compliant robots capable of interaction with rugged environments, such as a tensegrity interplanetary probe prototype surviving multi-story drops. Due to the complexity of tensegrity structures, modeling through physics simulation and machine learning improves our ability to design and evaluate new structures and their controllers in a dynamic environment. The kinematics of our simulator, the open source NASA Tensegrity Robotics Toolkit, have been previously validated within 1.3% error on position through motion capture of the six strut robot ReCTeR. This paper provides additional validation of the dynamics through the direct comparison of the simulator to forces experienced by the latest version of the Tetraspine robot. These results give us confidence in our strategy of using tensegrity to impart future robotic systems with properties similar to biological systems such as increased flexibility, power, and mobility in extreme terrains.",https://ieeexplore.ieee.org/document/7354134/,2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),28 Sept.-2 Oct. 2015,ieeexplore
10.1109/INDIN.2012.6301137,Towards hierarchical self-optimization in autonomous groups of mobile robots,IEEE,Conferences,"We present a real-world scenario for investigating and demonstrating hierarchical self-optimization in autonomous groups of mobile robots. The scenario is highly dynamic and easily expandable. It offers adequate starting points for the integration of hierarchical self-optimization. Reinforcement learning, e. g., can be introduced in order to improve the individual behavior of a single robot. Also swarm intelligence algorithms can improve the overall team behavior with respect to common goals. A reference behavior system incorporating a dynamic role assignment and hierarchical state machines was implemented and has been applied to the miniature robot BeBot. The system was evaluated by conducting several tests.",https://ieeexplore.ieee.org/document/6301137/,IEEE 10th International Conference on Industrial Informatics,25-27 July 2012,ieeexplore
10.1109/DEVLRN.2011.6037332,Towards incremental learning of task-dependent action sequences using probabilistic parsing,IEEE,Conferences,"We study an incremental process of learning where a set of generic basic actions are used to learn higher-level task-dependent action sequences. A task-dependent action sequence is learned by associating the goal given by a human demonstrator with the task-independent, general-purpose actions in the action repertoire. This process of contextualization is done using probabilistic parsing. We propose stochastic context-free grammars as the representational framework due to its robustness to noise, structural flexibility, and easiness on defining task-independent actions. We demonstrate our implementation on a real-world scenario using a humanoid robot and report implementation issues we had.",https://ieeexplore.ieee.org/document/6037332/,2011 IEEE International Conference on Development and Learning (ICDL),24-27 Aug. 2011,ieeexplore
10.1109/ICAR46387.2019.8981600,Towards the Usage of Synthetic Data for Marker-Less Pose Estimation of Articulated Robots in RGB Images,IEEE,Conferences,"Pose estimation is a necessity for many applications in robotics incorporating interaction between the robot and external camera-equipped devices, e.g. mobile robots or Augmented Reality devices. In the practice of monocular cameras, one mostly takes advantage of pose estimation through fiducial marker detection. We propose a novel approach for marker-less robot pose estimation through monocular cameras utilizing 2D keypoint detection and 3D keypoint determination through readings from the encoders and forward kinematics. In particular, 2D-3D point correspondences enable the pose estimation through solving the Perspective-n-Point problem for calibrated cameras. The method does not rely on any depth data or initializations. The robust 2D keypoint detection is implemented by modern Convolutional Neural Networks trained on different dataset configurations of real and synthetic data in order to quantitatively evaluate robustness, precision and data efficiency. We demonstrate that the method provides robust pose estimation for random joint poses and benchmark the performance of different (synthetic) dataset configurations. Furthermore, we compare the accuracies to marker pose estimation and give an outlook towards enhancements and realtime capability.",https://ieeexplore.ieee.org/document/8981600/,2019 19th International Conference on Advanced Robotics (ICAR),2-6 Dec. 2019,ieeexplore
10.1109/IJCNN.2008.4633874,Tracking a moving object with mobile robot based on vision,IEEE,Conferences,"The paper proposes a real-time tracking algorithm for a moving object with mobile robot based on vision using adaptive color matching and Kalman filter. The adaptive color matching can limit the region containing moving object on vision image plane. It can adjust color matching threshold to reduce the influence of lighting variations in the scene. Kalman filter is used as our prediction module to calculate motion vectors of moving object in the robot coordinate system. A view window containing the position of moving object estimated by Kalman filter is determined on image plane to reduce the image processing area. Color matching threshold can adjust itself adaptively in view window, which is used as an updating module. Experimental results show that the algorithm can adapt to lighting variations and has good tracking precision. It can also be implemented in real time.",https://ieeexplore.ieee.org/document/4633874/,2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence),1-8 June 2008,ieeexplore
10.1109/ICCICT.2012.6398104,Tracking of a target person using face recognition by surveillance robot,IEEE,Conferences,"In this paper we designed an experimental setup in order to have human-robot interaction i.e. first we are going to detect the face and after that we recognise the detected face. Afterwards we get the persons upper body torso color as a key feature. As we extracted the color feature we can compute the moments and also evaluate the motion parameters so that the surveillance robot can track the person accordingly. We also had introduced Speech module in order to have a interaction between the remote and base station. Surveillance robot must track the targeted person in a robust manner in indoor and outdoor environment in different light and dynamic varying conditions. In our proposed setup we use PCA which is going to recognise the person in a real time environment and should communicate to the person via speech module deployed in the surveillance robot, as face recognition works on real time environment we are getting average recognition rate of 98%. Experiment demonstration validates the efficient performance of the approach.",https://ieeexplore.ieee.org/document/6398104/,"2012 International Conference on Communication, Information & Computing Technology (ICCICT)",19-20 Oct. 2012,ieeexplore
10.1109/LARS/SBR/WRE.2018.00068,Traffic Signs Recognition System with Convolution Neural Networks,IEEE,Conferences,"The purpose of this paper is to develop an automatic traffic sign recognition system, making use of computation vision techniques and convolution neural networks. The work is divided in two phases, namely detection and classification, and here is presented a different approach on the detection phase. The tests were performed in a simulator and in a real controlled environment using the framework ROS (Robot Operating System) and implemented with the AmigoBot robot.",https://ieeexplore.ieee.org/document/8588574/,"2018 Latin American Robotic Symposium, 2018 Brazilian Symposium on Robotics (SBR) and 2018 Workshop on Robotics in Education (WRE)",6-10 Nov. 2018,ieeexplore
10.1109/WHC.2017.7989900,Training in divergent and convergent force fields during 6-DOF teleoperation with a robot-assisted surgical system,IEEE,Conferences,"The technical skills of surgeons directly affect patient outcomes, yet how to train surgeons in a way that maximizes their learning speed and optimizes their performance is an open question. Recent studies in human motor learning have shown benefits of using force fields during training in point-to-point reaching tasks. Teleoperation systems enable the application of these force fields during the learning of more complex and real-world activities. We performed a study in which participants used the da Vinci Research Kit, a teleoperated robot-assisted surgical system, to perform a peg transfer task - a standard manipulation task used in minimally invasive surgery training. We investigated the effect on learning of training in three different groups: (1) without applying any force, (2) with a divergent force field, which pushes the user away from the desired path if they deviate from it, and (3) with a convergent force field, which pushes the user back to the desired path. We found no statistically significant differences in performance among the different training groups at the end of the experiment, but some differences were evident throughout the training. Thus, training in the divergent and convergent fields may involve different learning mechanisms, but does not worsen performance.",https://ieeexplore.ieee.org/document/7989900/,2017 IEEE World Haptics Conference (WHC),6-9 June 2017,ieeexplore
10.1109/ICINFA.2010.5512384,Trajectory planning of autonomous robot using advanced fuzzy controller,IEEE,Conferences,"To move a obstacle from a certain position to the predefined destination, robot needs various kinds of elements, like control algorithm, hardware, etc. General human can selects the distance between him and destination by numerical supervised learning, and establish the moving plan to the destination, generally called `Trajectory planning.' He(or she) can make a trajectory planning against the obstacles which is placed on the path to the destination. The kinds of obstacle can be active obstacle, which is moving on the trajectory, or passive obstacle, which is stationary one. For the kinds of stationary obstacle is height difference between road and sidewalk, stairs, a ramp. And the active obstacles include a human, a vehicle that shows active motion. To make a trajectory planning for the stationary obstacle, autonomous mobile robot can be assume that it is placed at the center of the map, and from the distance information between autonomous mobile robot and obstacles using the advanced fuzzy controller, mobile robot can make a trajectory planning. But in case of active moving obstacle, there are many components and information is needed to process because its moving trace should be considered in real time. As mentioned above, for the proposed algorithm, various kinds of things should be considered to move to the destination. Obviously, autonomous driving of the mobile robot can provide conveniences to the human-being with the various kinds of aspects. In this paper, obstacle avoidance algorithm for the trajectory planning using advanced fuzzy controller is described in detail, and demonstrated proposed algorithm through the real experiment.",https://ieeexplore.ieee.org/document/5512384/,The 2010 IEEE International Conference on Information and Automation,20-23 June 2010,ieeexplore
10.1109/ROMOCO.2005.201413,Trajectory realization with collision avoidance algorithm,IEEE,Conferences,"This paper describes the approach to collision avoidance problem for 3-DOF anthropomorphic robot manipulators. The novelty of the approach is the decomposition of 3D space to two 2D spaces. Resulting is the computationally efficient algorithm, suitable for implementation in the real-time systems. Simulation of the anthropomorphic manipulator operating in three dimensional space with obstacles is also presented.",https://ieeexplore.ieee.org/document/1554392/,"Proceedings of the Fifth International Workshop on Robot Motion and Control, 2005. RoMoCo '05.",23-25 June 2005,ieeexplore
10.1109/ROBIO.2017.8324512,Trajectory tracking control of a unicycle-type mobile robot with a new planning algorithm,IEEE,Conferences,"Trajectory tracking control is one of the core techniques that impacts the auto-driving performance of a mobile robot. Whereas, there lacks enough work on reference trajectory generation and controller design for practical usage. This paper considers mobile robots with unicycle vehicle model on which most of automatic guided vehicles (AGVs) in real world are built. A new trajectory planning algorithm is developed, and is applied along with a control law considering constraints of the unicycle model and limited motor capabilities. The proposed algorithm is easy to be implemented on real world AGVs, and it yields a fast, accurate and robust trajectory tracking performance. The effectiveness of the algorithm is validated by simulation tests.",https://ieeexplore.ieee.org/document/8324512/,2017 IEEE International Conference on Robotics and Biomimetics (ROBIO),5-8 Dec. 2017,ieeexplore
10.1109/ICACR51161.2020.9265509,Transfer of Inter-Robotic Inductive Classifier,IEEE,Conferences,"In multi-robot deployments, the robots need to share and integrate their own experience and perform transfer learning. Under the assumption that the robots have the same morphology and carry equivalent sensory equipment, the problem of transfer learning can be considered incremental learning. Thus, the transfer learning problem inherits the challenges of incremental learning, such as catastrophic forgetting and concept drift. In catastrophic forgetting, the model abruptly forgets the previously learned knowledge during the learning process. The concept drift arises with different experiences between consecutively sampled models. However, state-of-the-art robotic transfer learning approaches do not address both challenges at once. In this paper, we propose to use an incremental classifier on a transfer learning problem. The feasibility of the proposed approach is demonstrated in a real deployment. The robot consistently merges two classifiers learned on two different tasks into a classifier that performs well on both tasks.",https://ieeexplore.ieee.org/document/9265509/,"2020 4th International Conference on Automation, Control and Robots (ICACR)",11-13 Oct. 2020,ieeexplore
10.1109/RO-MAN46459.2019.8956420,Trust Repair in Human-Swarm Teams+,IEEE,Conferences,"Swarm robots are coordinated via simple control laws to generate emergent behaviors such as flocking, rendezvous, and deployment. Human-swarm teaming has been widely proposed for scenarios, such as human-supervised teams of unmanned aerial vehicles (UAV) for disaster rescue, UAV and ground vehicle cooperation for building security, and soldier-UAV teaming in combat. Effective cooperation requires an appropriate level of trust, between a human and a swarm. When an UAV swarm is deployed in a real-world environment, its performance is subject to real-world factors, such as system reliability and wind disturbances. Degraded performance of a robot can cause undesired swarm behaviors, decreasing human trust. This loss of trust, in turn, can trigger human intervention in UAVs' task executions, decreasing cooperation effectiveness if inappropriate. Therefore, to promote effective cooperation we propose and test a trust-repairing method (Trust-repair) restoring performance and human trust in the swarm to an appropriate level by correcting undesired swarm behaviors. Faulty swarms caused by both external and internal factors were simulated to evaluate the performance of the Trust-repair algorithm in repairing swarm performance and restoring human trust. Results show that Trust-repair is effective in restoring trust to a level intermediate between normal and faulty conditions.",https://ieeexplore.ieee.org/document/8956420/,2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-18 Oct. 2019,ieeexplore
10.1109/ICRA.2019.8793644,Underwater Communication Using Full-Body Gestures and Optimal Variable-Length Prefix Codes,IEEE,Conferences,"In this paper we consider inter-robot communication in the context of joint activities. In particular, we focus on convoying and passive communication for radio-denied environments by using whole-body gestures to provide cues regarding future actions. We develop a communication protocol whereby information described by codewords is transmitted by a series of actions executed by a swimming robot. These action sequences are chosen to optimize robustness and transmission duration given the observability, natural activity of the robot and the frequency of different messages. Our approach uses a convolutional network to make core observations of the pose of the robot being tracked, which is sending messages. The observer robot then uses an adaptation of classical decoding methods to infer a message that is being transmitted. The system is trained and validated using simulated data, tested in the pool and is targeted for deployment in the open ocean. Our decoder achieves.94 precision and.66 recall on real footage of robot gesture execution recorded in a swimming pool.",https://ieeexplore.ieee.org/document/8793644/,2019 International Conference on Robotics and Automation (ICRA),20-24 May 2019,ieeexplore
10.1109/MED48518.2020.9183337,Unsupervised Learning for Subterranean Junction Recognition Based on 2D Point Cloud,IEEE,Conferences,"This article proposes a novel unsupervised learning framework for detecting the number of tunnel junctions in subterranean environments based on acquired 2D point clouds. The implementation of the framework provides valuable information for high level mission planners to navigate an aerial platform in unknown areas or robot homing missions. The framework utilizes spectral clustering, which is capable of uncovering hidden structures from connected data points lying on non-linear manifolds. The spectral clustering algorithm computes a spectral embedding of the original 2D point cloud by utilizing the eigen decomposition of a matrix that is derived from the pairwise similarities of these points. We validate the developed framework using multiple data-sets, collected from multiple realistic simulations, as well as from real flights in underground environments, demonstrating the performance and merits of the proposed methodology.",https://ieeexplore.ieee.org/document/9183337/,2020 28th Mediterranean Conference on Control and Automation (MED),15-18 Sept. 2020,ieeexplore
10.1109/IROS.2013.6696581,Unsupervised learning of predictive parts for cross-object grasp transfer,IEEE,Conferences,"We present a principled solution to the problem of transferring grasps across objects. Our approach identifies, through autonomous exploration, the size and shape of object parts that consistently predict the applicability of a grasp across multiple objects. The robot can then use these parts to plan grasps onto novel objects. By contrast to most recent methods, we aim to solve the part-learning problem without the help of a human teacher. The robot collects training data autonomously by exploring different grasps on its own. The core principle of our approach is an intensive encoding of low-level sensorimotor uncertainty with probabilistic models, which allows the robot to generalize the noisy autonomously-generated grasps. Object shape, which is our main cue for predicting grasps, is encoded with surface densities, that model the spatial distribution of points that belong to an object's surface. Grasp parameters are modeled with grasp densities, that correspond to the spatial distribution of object-relative gripper poses that lead to a grasp. The size and shape of grasp-predicting parts are identified by sampling the cross-object correlation of local shape and grasp parameters. We approximate sampling and integrals via Monte Carlo methods to make our computer implementation tractable. We demonstrate the applicability of our method in simulation. A proof of concept on a real robot is also provided.",https://ieeexplore.ieee.org/document/6696581/,2013 IEEE/RSJ International Conference on Intelligent Robots and Systems,3-7 Nov. 2013,ieeexplore
10.1109/ROBOT.1998.680515,Unsupervised learning to recognize environments from behavior sequences in a mobile robot,IEEE,Conferences,"We describe the development of a mobile robot which does unsupervised learning for recognizing environments from behavior sequences. Most studies on recognizing an environment have tried to build precise geometric maps with high sensitive and global sensors. However such precise and global information may not be obtained in real environments. Furthermore unsupervised-learning is necessary for recognition in unknown environments without help of a teacher. Thus we attempt to build a mobile robot which does unsupervised-learning to recognize environments with low sensitivity and local sensors. The mobile robot is behavior-based and does wall-following in enclosures. Then the sequences of behaviors executed in each enclosure are transformed into input vectors for a self-organizing network. Learning without a teacher is done, and the robot becomes able to identify enclosures. Moreover we developed a method to identify environments independent of a start point using a partial sequence. We have fully implemented the system with a real mobile robot, and made experiments for evaluating the ability. As a result, we found out that the environment recognition was done well and our method was adaptive to noisy environments.",https://ieeexplore.ieee.org/document/680515/,Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),20-20 May 1998,ieeexplore
10.1109/HRI.2019.8673298,Using Decision Support Systems for Juries in Court: Comparing the Use of Real and CG Robots,IEEE,Conferences,"In this report, we investigate the factor of social presence of a robot by using an actual robot and comparing it with a CG robot studied in our previous study. A laboratory experiment is conducted using a simple jury decision-making task, where participants play the role of a jury and make decisions regarding the length of the sentence for a particular crime. During the task, a robot with expert knowledge provides suggestions regarding the length of the sentence based on other similar cases. Results show that participants who engaged with an actual robot showed higher conformity with the suggested length of a sentence compared to the participants who engaged with a CG robot presented through a computer monitor. This study shows results that are consistent with those of previous studies in that interacting with physically aware robots is more engaging and also shows its effects on decision-making in a court.",https://ieeexplore.ieee.org/document/8673298/,2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI),11-14 March 2019,ieeexplore
10.1109/iFUZZY50310.2020.9297367,Using Interval Type-2 Recurrent Fuzzy Cerebellar Model Articulation Controller Based on Improved Differential Evolution for Cooperative Carrying Controller of Mobile Robots,IEEE,Conferences,"Mobile robot is widely utilized in various fields such as navigation control, obstacle avoidance and object carrying. For keeping away from obstacles to avoid collision and preventing object carrying from dropping down, we propose a state manager (SM) designed to assist the mobile robots so that they can switch operation between wall-following carrying (WFC) and toward goal carrying (TGC) by different external condition. In this controlling model, interval type-2 recurrent fuzzy cerebellar model articulation controller (IT2RFCMAC), embedded with a modified evolutionary optimization and dynamic grouping differential evolution (DGDE), is implemented for WFC and TGC. By adopting reinforcement learning strategy, mobile robots equip with adaptively wall-following control to make cooperative carrying control in real.",https://ieeexplore.ieee.org/document/9297367/,2020 International Conference on Fuzzy Theory and Its Applications (iFUZZY),4-7 Nov. 2020,ieeexplore
10.1109/SPW50608.2020.00045,Using Taint Analysis and Reinforcement Learning (TARL) to Repair Autonomous Robot Software,IEEE,Conferences,"It is important to be able to establish formal performance bounds for autonomous systems. However, formal verification techniques require a model of the environment in which the system operates; a challenge for autonomous systems, especially those expected to operate over longer timescales. This paper describes work in progress to automate the monitor and repair of ROS-based autonomous robot software written for an apriori partially known and possibly incorrect environment model. A taint analysis method is used to automatically extract the dataflow sequence from input topic to publish topic, and instrument that code. A unique reinforcement learning approximation of MDP utility is calculated, an empirical and non-invasive characterization of the inherent objectives of the software designers. By comparing design (a-priori) utility with deploy (deployed system) utility, we show, using a small but real ROS example, that it's possible to monitor a performance criterion and relate violations of the criterion to parts of the software. The software is then patched using automated software repair techniques and evaluated against the original off-line utility.",https://ieeexplore.ieee.org/document/9283859/,2020 IEEE Security and Privacy Workshops (SPW),21-21 May 2020,ieeexplore
10.1109/IDAACS-SWS50031.2020.9297062,Using a COTS Smartphone to Control an Autonomous Self-Driving Platform,IEEE,Conferences,"Recent interest in self-driving cars has boosted related fields like autonomous systems and robotics. This paper describes a simple and inexpensive small-scale self driving platform called ASV, which is based on a lowcost microcontroller and a COTS smartphone connected via WiFi. The camera of the phone, which is fixed to the platform, acquires images which are processed in a Convolutional Neural Network (CNN) inspired by the Nvidia's PilotNet. The network is trained in end-to-end learning to produce steering command to follow highway style lanes with markers on both sides. On the microcontroller, the steering commands are used for motor actuation and control of the physical movement of the platform. This paper presents the structure and implementation of ASV and evaluates its real-time performance and latency. For typical speeds encountered in small-scale systems, the performance is found more than sufficient for lane following with the CNN, leaving plenty of room for extensions. The platform's simplicity allows it to be used in research, education, and to spark interest in self-driving systems and neural networks. It can form the basis for general robot control.",https://ieeexplore.ieee.org/document/9297062/,2020 IEEE 5th International Symposium on Smart and Wireless Systems within the Conferences on Intelligent Data Acquisition and Advanced Computing Systems (IDAACS-SWS),17-18 Sept. 2020,ieeexplore
10.1109/IROS.2018.8593799,Utility Model Re-description within a Motivational System for Cognitive Robotics,IEEE,Conferences,"This paper describes a re-descriptive approach to the efficient acquisition of ever higher level and more precise utility models within the motivational system (MotivEn) of a cognitive architecture. The approach is based on a two-step process whereby, as a first step, simple imprecise sensor correlation related utility models are obtained from the interaction traces of the robot. These utility models allow the robot to increase the frequency of achieving goals, and thus, provide lots of traces that can be used to try to train precise value functions implemented as artificial neural networks. The approach is tested experimentally on a real robotic setup that involves the coordination of two robots.",https://ieeexplore.ieee.org/document/8593799/,2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),1-5 Oct. 2018,ieeexplore
10.1109/HNICEM.2018.8666242,Utilization of Fuzzy Logic Control in a Waste Robot,IEEE,Conferences,"This research aimed to design and develop an autonomous robot to feasibly address waste disposal issues in common indoor places. The researchers explored opportunities to improve path planning using Fuzzy Logic Control (FLC). The researchers utilized a Microcontroller Unit (MCU) to control input proximity, sound, and infrared sensors, and output geared Direct Current (DC) motors through machine learning and electromechanical interface. The researchers simulated an adaptive algorithm using Mamdani-type FLC model, implemented using C programming language, then downloaded as machine code to a real prototype. Based on significant test results, the waste robot accurately detected human interference, a feature that would be pivotal in overcoming individual indifferences on waste management.",https://ieeexplore.ieee.org/document/8666242/,"2018 IEEE 10th International Conference on Humanoid, Nanotechnology, Information Technology,Communication and Control, Environment and Management (HNICEM)",29 Nov.-2 Dec. 2018,ieeexplore
10.1109/AERO.2015.7119180,Utilizing Artificial Intelligence to achieve a robust architecture for future robotic spacecraft,IEEE,Conferences,"This paper presents a novel failure-tolerant architecture for future robotic spacecraft. It is based on the Time and Space Partitioning (TSP) principle as well as a combination of Artificial Intelligence (AI) and traditional concepts for system failure detection, isolation and recovery (FDIR). Contrary to classic payload that is separated from the platform, robotic devices attached onto a satellite become an integral part of the spacecraft itself. Hence, the robot needs to be integrated into the overall satellite FDIR concept in order to prevent fatal damage upon hardware or software failure. In addition, complex dexterous manipulators as required for onorbit servicing (OOS) tasks may reach unexpected failure states, where classic FDIR methods reach the edge of their capabilities with respect to successfully detecting and resolving them. Combining, and partly replacing traditional methods with flexible AI approaches aims to yield a control environment that features increased robustness, safety and reliability for space robots. The developed architecture is based on a modular on-board operational framework that features deterministic partition scheduling, an OS abstraction layer and a middleware for standardized inter-component and external communication. The supervisor (SUV) concept is utilized for exception and health management as well as deterministic system control and error management. In addition, a Kohonen self-organizing map (SOM) approach was implemented yielding a real-time robot sensor confidence analysis and failure detection. The SOM features nonsupervized training given a typical set of defined world states. By compiling a set of reviewable three-dimensional maps, alternative strategies in case of a failure can be found, increasing operational robustness. As demonstrator, a satellite simulator was set up featuring a client satellite that is to be captured by a servicing satellite with a 7-DoF dexterous manipulator. The avionics and robot control were integrated on an embedded, space-qualified Airbus e.Cube on-board computer. The experiments showed that the integration of SOM for robot failure detection positively complemented the capabilities of traditional FDIR methods.",https://ieeexplore.ieee.org/document/7119180/,2015 IEEE Aerospace Conference,7-14 March 2015,ieeexplore
10.1109/IROS45743.2020.9341569,Velocity Regulation of 3D Bipedal Walking Robots with Uncertain Dynamics Through Adaptive Neural Network Controller,IEEE,Conferences,"This paper presents a neural-network based adaptive feedback control structure to regulate the velocity of 3D bipedal robots under dynamics uncertainties. Existing Hybrid Zero Dynamics (HZD)-based controllers regulate velocity through the implementation of heuristic regulators that do not consider model and environmental uncertainties, which may significantly affect the tracking performance of the controllers. In this paper, we address the uncertainties in the robot dynamics from the perspective of the reduced dimensional representation of virtual constraints and propose the integration of an adaptive neural network-based controller to regulate the robot velocity in the presence of model parameter uncertainties. The proposed approach yields improved tracking performance under dynamics uncertainties. The shallow adaptive neural network used in this paper does not require training a priori and has the potential to be implemented on the real-time robotic controller. A comparative simulation study of a 3D Cassie robot is presented to illustrate the performance of the proposed approach under various scenarios.",https://ieeexplore.ieee.org/document/9341569/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.1109/ICRA48506.2021.9561936,ViNG: Learning Open-World Navigation with Visual Goals,IEEE,Conferences,"We propose a learning-based navigation system for reaching visually indicated goals and demonstrate this system on a real mobile robot platform. Learning provides an appealing alternative to conventional methods for robotic navigation: instead of reasoning about environments in terms of geometry and maps, learning can enable a robot to learn about navigational affordances, understand what types of obstacles are traversable (e.g., tall grass) or not (e.g., walls), and generalize over patterns in the environment. However, unlike conventional planning algorithms, it is harder to change the goal for a learned policy during deployment. We propose a method for learning to navigate towards a goal image of the desired destination. By combining a learned policy with a topological graph constructed out of previously observed data, our system can determine how to reach this visually indicated goal even in the presence of variable appearance and lighting. Three key insights, waypoint proposal, graph pruning and negative mining, enable our method to learn to navigate in real-world environments using only offline data, a setting where prior methods struggle. We instantiate our method on a real outdoor ground robot and show that our system, which we call ViNG, outperforms previously-proposed methods for goal-conditioned reinforcement learning, including other methods that incorporate reinforcement learning and search. We also study how ViNG generalizes to unseen environments and evaluate its ability to adapt to such an environment with growing experience. Finally, we demonstrate ViNG on a number of real-world applications, such as last-mile delivery and warehouse inspection. We encourage the reader to visit the project website for videos of our experiments and demonstrations <sup>1</sup>.",https://ieeexplore.ieee.org/document/9561936/,2021 IEEE International Conference on Robotics and Automation (ICRA),30 May-5 June 2021,ieeexplore
10.1109/IROS.2001.977179,View-based imitation learning by conflict resolution with epipolar geometry,IEEE,Conferences,"Existing robotic approaches have focused on the behavior generation assuming the observation of the internal model of the demonstrator, but have not paid any attention on how to build such a model from the learner's perception. This paper presents a computational model of view-based imitation learning without any internal model of the demonstrator. Instead, based on the stereo epipolar constraint, the robot learns to imitate the demonstrator's motion by applying adaptive visual servoing that minimizes the residual between the recovered demonstrator's body parts supposed to be viewed by the demonstrator and the learner's ones in the learner's stereo image planes, and then reproducing the recovered demonstrator's trajectories without any reconstruction of the 3D trajectories. The computer simulation and real experiment are shown and discussion is given.",https://ieeexplore.ieee.org/document/977179/,Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180),29 Oct.-3 Nov. 2001,ieeexplore
10.1109/VR.2019.8798186,Virtual Reality and Photogrammetry for Improved Reproducibility of Human-Robot Interaction Studies,IEEE,Conferences,"Collecting data in robotics, especially human-robot interactions, traditionally requires a physical robot in a prepared environment, that presents substantial scalability challenges. First, robots provide many possible points of system failure, while the availability of human participants is limited. Second, for tasks such as language learning, it is important to create environments that provide interesting' varied use cases. Traditionally, this requires prepared physical spaces for each scenario being studied. Finally, the expense associated with acquiring robots and preparing spaces places serious limitations on the reproducible quality of experiments. We therefore propose a novel mechanism for using virtual reality to simulate robotic sensor data in a series of prepared scenarios. This allows for a reproducible dataset that other labs can recreate using commodity VR hardware. We demonstrate the effectiveness of this approach with an implementation that includes a simulated physical context, a reconstruction of a human actor, and a reconstruction of a robot. This evaluation shows that even a simple “sandbox” environment allows us to simulate robot sensor data, as well as the movement (e.g., view-port) and speech of humans interacting with the robot in a prescribed scenario.",https://ieeexplore.ieee.org/document/8798186/,2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),23-27 March 2019,ieeexplore
10.1109/IROS45743.2020.9341344,Virtual Reality for Robots,IEEE,Conferences,"This paper applies the principles of Virtual Reality (VR) to robots, rather than living organisms. A simulator, of either physical states or information states, renders outputs to custom displays that fool the robot's sensors. This enables a robot to experience a combination of real and virtual sensor inputs, combining the efficiency of simulation and the benefits of real world sensor inputs. Thus, the robot can be taken through targeted experiences that are more realistic than pure simulation, yet more feasible and controllable than pure real-world experiences. We define two distinctive methods for applying VR to robots, namely black box and white box; based on these methods we identify potential applications, such as testing and verification procedures that are better than simulation, the study of spoofing attacks and anti-spoofing techniques, and sample generation for machine learning. A general mathematical framework is presented, along with a simple experiment, detailed examples, and discussion of the implications.",https://ieeexplore.ieee.org/document/9341344/,2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),24 Oct.-24 Jan. 2021,ieeexplore
10.23919/WAC50355.2021.9559586,Virtual Testing and Policy Deployment Framework for Autonomous Navigation of an Unmanned Ground Vehicle Using Reinforcement Learning,IEEE,Conferences,"The use of deep reinforcement learning (DRL) as a framework for training a mobile robot to perform optimal navigation in an unfamiliar environment is a suitable choice for implementing AI with real-time robotic systems. In this study, the environment and surrounding obstacles of an Ackermann-steered UGV are reconstructed into a virtual setting for training the UGV to centrally learn the optimal route (guidance actions to be taken at any given state) towards a desired goal position using Multi-Agent Virtual Exploration in Deep Q-Learning (MVEDQL) for various model configurations. The trained model policies are to be transferred to a physical vehicle and compared based on their individual effectiveness for performing autonomous waypoint navigation. Prior to incorporating the learned model with the physical UGV for testing, this paper outlines the development of a GUI application to provide an interface for remotely deploying the vehicle and a virtual reality framework reconstruction of the training environment to assist safely testing the system using the reinforcement learning model.",https://ieeexplore.ieee.org/document/9559586/,2021 World Automation Congress (WAC),1-5 Aug. 2021,ieeexplore
10.1109/SMICND.2005.1558827,Virtual environment for robots interfaces design and testing,IEEE,Conferences,"This paper refers to the implementation of a virtual environment for the robot interfaces testing. This software environment is very useful because, comparing to the experiments with real robots, it allow the testing and evaluation of different types of interfaces and different working environments with diverse configurations. A very important facility of this interactive software environment is the fact that the designers of the robots sensors and interfaces are able to work in parallel to design test, optimize and realize different control devices for the robot",https://ieeexplore.ieee.org/document/1558827/,"CAS 2005 Proceedings. 2005 International Semiconductor Conference, 2005.",3-5 Oct. 2005,ieeexplore
10.1109/ISWCS.2019.8877305,Visible Light Positioning for Location-Based Services in Industry 4.0,IEEE,Conferences,"Industry 4.0 refers to the evolution in manufacturing from computerization to fully cyberphysical systems that exploit rich sensor data, adaptive real-time safety-critical control, and machine learning. An important aspect of this vision is the sensing and subsequent association of objects in the physical world with their cyber and virtual counterparts. In this paper we propose Visible Light Positioning (VLP) as an enabler for these Industry 4.0 applications. We also explore sensing techniques, including cameras (and depth sensors), and other light-based solutions for object positioning and detection along with their respective limitations. We then demonstrate an application of positioning for real time robot control in an interactive multiparty cyber-physical-virtual deployment. Lastly, based on our experience with this cyberphysical-virtual application, we propose Ray-Surface Positioning (RSP), a novel VLP technique, as a low cost positioning system for Industry 4.0.",https://ieeexplore.ieee.org/document/8877305/,2019 16th International Symposium on Wireless Communication Systems (ISWCS),27-30 Aug. 2019,ieeexplore
10.1109/ICGEC.2012.151,Vision-Based Coordinate Transformation with Back Propagation Neural Networks on Mobile Robots,IEEE,Conferences,"Target tracking is important for vision-based robots to implement tasks of grasping, assembling and avoiding obstacles. the purpose of a target tracking system is to identify a target and then to estimate the position of the target. the targets' positions are usually described by various coordinate systems for different purposes. This study focuses on the problem of coordinate transformation on mobile robots and employs the techniques of Back-Propagation Neural Networks to discover the prediction models. with such prediction models, coordinate transformation can be done with less processing time. the techniques have been implemented and integrated with a four-wheeled vision-based security robot and has been verified in real environments. the experimental results show that the proposed method is able to produce simple and precise transformation models and improves the robot's performances.",https://ieeexplore.ieee.org/document/6456866/,2012 Sixth International Conference on Genetic and Evolutionary Computing,25-28 Aug. 2012,ieeexplore
10.1109/I2MTC.2019.8826921,Vision-Based Deep Learning Approach for Real-Time Detection of Weeds in Organic Farming,IEEE,Conferences,"Vision-based detection and classification systems for identifying crops and weeds in captured color images have recently being extensively researched due to the advantages that they offer. The use of chemical or synthetic pesticides could drastically be reduced. One of the critical aspects of these systems is the requirement for high data volumes and the resulting lack of real time capability. This paper presents a method for detecting weeds in carrot fields in real time without segmentation and the need of a large dataset. In most vision-based measurement systems the task is divided into multiple processes like separating the objects from the background followed by the detection of the object and lastly the object classification. Our approach uses a convolution neural network to localize and classify the plants simultaneously. A precision of 89 % was achieved with a calculation rate of 18,56 FPS. A lower precision was accepted in favor of a higher calculation rate of about 56 FPS. We implemented and evaluated our system using a multi-platform robot on an organic carrot field located in Germany.",https://ieeexplore.ieee.org/document/8826921/,2019 IEEE International Instrumentation and Measurement Technology Conference (I2MTC),20-23 May 2019,ieeexplore
10.23919/ChiCC.2019.8865406,Vision-Based Position/Impedance Control for Robotic Assembly Task,IEEE,Conferences,"In robotic assembly processes, detecting target pose is indispensable for robot manipulation algorithms. Such a tedious work hinders the further application of robot manipulation algorithms to real industrial processes. In this paper, a vision-based position/impedance control framework is proposed. Therein, the objective pose is firstly obtained by a motion capture system, where a kinematic equation is solved to Figure out the target assembly pose. Next the robot arm motion is approximated by an impedance model, in this way, the position/impedance control law of the robot is derived, which drives the robot to perform a compliant assembly manipulation. Finally, a memory stick assembly experiment is conducted on a 6-DOF robot arm equipped with a motion capture system and a force-torque sensor. Experiment shows the efficiency of the vision-based position/impedance hybrid controller in terms of autonomous positioning and compliant assembly. Due to its convenience and generality, the present controller can be expected to apply to more general industrial scenarios.",https://ieeexplore.ieee.org/document/8865406/,2019 Chinese Control Conference (CCC),27-30 July 2019,ieeexplore
10.1109/ROBOT.1995.525277,Vision-based reinforcement learning for purposive behavior acquisition,IEEE,Conferences,"This paper presents a method of vision-based reinforcement learning by which a robot learns to shoot a ball into a goal, and discusses several issues in applying the reinforcement learning method to a real robot with vision sensor. First, a ""state-action deviation"" problem is found as a form of perceptual aliasing in constructing the state and action spaces that reflect the outputs from physical sensors and actuators, respectively. To cope with this, an action set is constructed in such a way that one action consists of a series of the same action primitive which is successively executed until the current state changes. Next, to speed up the learning time, a mechanism of learning form easy missions (or LEM) which is a similar technique to ""shaping"" in animal learning is implemented. LEM reduces the learning time from the exponential order in the size of the state space to about the linear order in the size of the state space. The results of computer simulations and real robot experiments are given.",https://ieeexplore.ieee.org/document/525277/,Proceedings of 1995 IEEE International Conference on Robotics and Automation,21-27 May 1995,ieeexplore
10.1109/ICSTCC.2019.8885611,Visual Analytics Framework for Condition Monitoring in Cyber-Physical Systems,IEEE,Conferences,"One of the biggest challenges facing the factory of the future today is to reduce the time-to-market access and increase through the improvement of competitiveness and efficiency. In order to achieve this target, data analytics in Industrial Cyber-Physical System becomes a feasible option. In this paper, a visual analytics framework for condition monitoring of the machine tool is presented with the aim to manage events and alarms at factory level. The framework is assessed in a particular use case that consists in a multi-threaded cloud-based solution for the global analysis of the behaviour of variables acquired from PLC, CNC and robot manipulator. A human-machine interface is also designed for the real-time visualization of the key performance indicators according to the user's criteria. This tool implemented is a great solution for condition monitoring and decision-making process based on data analytics from simple statistics to complex machine learning methods. The results achieved are part of the vision and implementation of the industrial test bed of “Industry and Society 5.0” platform.",https://ieeexplore.ieee.org/document/8885611/,"2019 23rd International Conference on System Theory, Control and Computing (ICSTCC)",9-11 Oct. 2019,ieeexplore
10.1109/IECON.2019.8926916,Visual Subterranean Junction Recognition for MAVs based on Convolutional Neural Networks,IEEE,Conferences,"This article proposes a novel visual framework for detecting tunnel crossings/junctions in underground mine areas towards the autonomous navigation of Micro Aerial Vehicles (MAVs). Usually mine environments have complex geometries, including multiple crossings with different tunnels that challenge the autonomous planning of aerial robots. Towards the envisioned scenario of autonomous or semi-autonomous deployment of MAVs with limited Line-of-Sight in subterranean environments, the proposed module acknowledges the existence of junctions by providing crucial information to the autonomy and planning layers of the aerial vehicle. The capability for a junction detection is necessary in the majority of mission scenarios, including unknown area exploration, known area inspection and robot homing missions. The proposed novel method has the ability to feed the image stream from the vehicles on-board forward facing camera in a Convolutional Neural Network (CNN) classification architecture, expressed in four categories: 1) left junction, 2) right junction, 3) left &amp; right junction, and 4) no junction in the local vicinity of the vehicle. The core contribution stems for the incorporation of AlexNet in a transfer learning scheme for detecting multiple branches in a subterranean environment. The validity of the proposed method has been validated through multiple data-sets collected from real underground environments, demonstrating the performance and merits of the proposed module.",https://ieeexplore.ieee.org/document/8926916/,IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society,14-17 Oct. 2019,ieeexplore
10.1109/FSKD.2017.8393254,Visual control system design of wheeled inverted pendulum robot based on Beaglebone Black,IEEE,Conferences,"The wheeled inverted pendulum robot has broad prospects of applications in real life. It can use two coaxial wheels to achieve the body self-balancing, forward moving and turning. But the general wheeled inverted pendulum robot seldom has vision function to perceive enviromental change. In order to realize the robust visual control, a wheeled inverted-pendulum vision robot with attitude sensors, photoelectric encoders, ultrasonic sensors and so on is designed based on Beaglebone Black board. The moving object is separated in the space domain by obtaining the image sequence which is sent by a robot-mounted camera, and the modeling, identification and tracking of target sequence are implemented in the time domain. The balance PD, speed PI and steering PD controllers are designed to realize the dynamic balance, forward and steering function of the robot. To satisfy the functional requirements of the visual tracking system, an improved tracking-learning-detection algorithm based on kernelized correlation filtering is used, and a tracking anomaly based on spatial context is detected to determine the tracking state and reduce the error rate. Experimental results show that the robot reaches the requirement of design and achieves better visual control effectiveness.",https://ieeexplore.ieee.org/document/8393254/,"2017 13th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)",29-31 July 2017,ieeexplore
10.1109/CNNA.2002.1035063,Visual feedback by using a CNN chip prototype system,IEEE,Conferences,"Robot locomotion control passes through a series of sensors that, according to information from the environment, allow the robot to adapt, in real time, its locomotion scheme or trajectory. When the goal of the robot is to reach a target in a non-structured environment the best approach is visual control realized by a fast image processing system. Fast parallel image processing of the CNN-UM cP4000 chip prototype permits one to obtain good performance, even in a real time control problem. The robot controlled by the implemented CNN visual feedback has a hexapod configuration and its locomotion system is also implemented by a multi-layer CNN structure. In this paper a CNN approach for both locomotion generation and visual control of the bio-inspired robot is presented.",https://ieeexplore.ieee.org/document/1035063/,Proceedings of the 2002 7th IEEE International Workshop on Cellular Neural Networks and Their Applications,24-24 July 2002,ieeexplore
10.1109/ROBOT.1991.131999,Visual navigation around curved obstacles,IEEE,Conferences,"An approach to path-planning around smooth obstacles that exploits visually derived geometry is proposed. A moving robot can scan the silhouette or apparent contour of an obstacle and estimate a minimum length path. This is done by seeking geodesics which can be extrapolated smoothly, around the obstacle and towards the goal. Preliminary implementation of this idea uses a real-time visual contour tracker running at 16 Hz, with a camera mounted on an Adept robot arm. The camera first dithers to generate visual motion, a safe path is estimated, and the robot steers the camera around the obstacle with a clearance of a few millimeters.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/131999/,Proceedings. 1991 IEEE International Conference on Robotics and Automation,9-11 April 1991,ieeexplore
10.1109/IROS.1997.655065,Visual navigation in an open environment without map,IEEE,Conferences,We describe how a mobile robot controlled only by visual information can retrieve a particular goal location in an open environment. Our model does not need a precise map nor to learn all the possible positions in the environment. The system is a neural architecture inspired from neurobiological studies using the recognition of visual patterns called landmarks. The robot merges this visual information and its azimuth to build a plastic representation of its location. This representation is used to learn the best movement to reach the goal. A simple and fast online learning of a few places located near the goal allows the robot to reach the goal from anywhere in its neighborhood. The system uses only an egocentric representation of the robot environment and presents very high generalization capabilities. We describe an efficient implementation tested on our robot in two real indoor environments. We show the limitations of the model and its possible extensions to create autonomous robots only guided by visual information.,https://ieeexplore.ieee.org/document/655065/,Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS '97,11-11 Sept. 1997,ieeexplore
10.1109/ICRoM.2014.6990935,Visual servoing control of robot manipulator with Jacobian matrix estimation,IEEE,Conferences,"Visual servoing system is a system to control a robot by visual feedback. This paper presents a visual servoing control that drives the end-effector of a real robot manipulator from any arbitrary start position to the desired positions. The control law is obtained using inverse Jacobian matrix. Since there is not access to the model of the robot, artificial neural networks are used to estimate of inverse Jacobian matrix. There are many challenges in practical implementation such as: how to calculate Jacobian matrix, determining the intelligent structure for estimation of Jacobian matrix, recognition coordinate of each joint with image processing and changes in illumination. We proposed appropriate solutions to solve the mentioned challenges. The experimental results in the real robot show that the control system can move the end-effector to target positions from any arbitrary start position with good accuracy.",https://ieeexplore.ieee.org/document/6990935/,2014 Second RSI/ISM International Conference on Robotics and Mechatronics (ICRoM),15-17 Oct. 2014,ieeexplore
10.1109/IROS.1997.649086,Visually-guided obstacle avoidance in unstructured environments,IEEE,Conferences,"This paper presents an autonomous vision-based obstacle avoidance system. The system consists of three independent vision modules for obstacle detection, each of which is computationally simple and uses a different criterion for detection purposes. These criteria are based on brightness gradients, RGB (red, green, blue) color, and HSV (hue, saturation, value) color, respectively. Selection of which modules are used to command the robot proceeds exclusively from the outputs of the modules themselves. The system is implemented on a small monocular mobile robot and uses very lour resolution images. It has been tested for over 200 hours in diverse environments.",https://ieeexplore.ieee.org/document/649086/,Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS '97,11-11 Sept. 1997,ieeexplore
10.1109/ICMLA.2007.19,Web-based maze robot learning using fuzzy motion control system,IEEE,Conferences,"In this study, a Web based maze robot system has been designed and implemented for solving different maze algorithms with the help of machine learning approaches. The robot system has a map-based heuristic maze solving algorithm. The algorithm used for solving the maze is based on map creation and produces a control signal for robot direction. Robot motions were controlled by a fuzzy motion control system running on a chip. The control algorithm can be easily changed with the help of an algorithm via web interface controlled by the control center. The control center program powered by MATLAB functions and special libraries (image and control) in DELPHI manage all robotic activities. These activities are: command interpreter, image capturing, processing and serving, machine learning techniques, Web serving, database management, communication with robot, and compiling microcontroller programs. The results have shown that the proposed, designed and implemented system provides amazing new features to the applicants doing their real-time programming exercises on Web.",https://ieeexplore.ieee.org/document/4457243/,Sixth International Conference on Machine Learning and Applications (ICMLA 2007),13-15 Dec. 2007,ieeexplore
10.1109/ICCA.2009.5410442,Wheeled mobile robot control using virtual pheromones and neural networks,IEEE,Conferences,"This paper presents a novel approach on the implementation of the concept of ¿virtual pheromones¿ for use in controlling autonomous mobile robots. Rather than being deployed in the environment, the virtual pheromones are stored in a map of the environment maintained and updated by a ¿pheromone server¿. This map acts like a shared memory for all the agents, by means of a radio communication link between each agent and the pheromone server. No direct communication between agents is required. The pheromone server can be implemented on a regular computer, a handheld device, or an embedded controller carried by a leader robot. The technique described is equally applicable for guiding individual robot and robot swarms. The experiments, performed with mobile robot Pioneer 3-DX show that this method allows significant simplification and cost reduction of the autonomous agents. Several possible applications are discussed.",https://ieeexplore.ieee.org/document/5410442/,2009 IEEE International Conference on Control and Automation,9-11 Dec. 2009,ieeexplore
10.1109/ICAE50557.2020.9350386,XNOR-YOLO: The High Precision of The Ball and Goal Detecting on The Barelang-FC Robot Soccer,IEEE,Conferences,"The essential part in developing the humanoid robot which is able to play soccer is the vision system. The vision system needs to be fast and accurate in detecting the surrounding objects on the field such as the ball, goal, teammates, or even the opponent. One of the powerful methods which was able to generate the object detection quickly with high accuracy was the deep learning. However, this method proceeded a huge computation. Even if it was generated on the GPU, it would still generat a low speed of detecting. Therefore, the high precision and fast detecting of the object method need to be considered in this area. In order to overcome this problem, we proposed the combination of the XNOR-Network (XNOR-Net) towards YOLOv3 running on the GPU with the same layer configuration as the tinyYOLO. To testify the performance of this method, some experiments has been carried out in real-time application by implementing it in the NVDIA Jetson TX1 GPU. From the experiment results, this method is able to detect the object faster than other object detection in detecting the ball and goal colored by white and generated 30 FPS in detecting each object.",https://ieeexplore.ieee.org/document/9350386/,2020 3rd International Conference on Applied Engineering (ICAE),7-8 Oct. 2020,ieeexplore
10.1109/ICITSI.2016.7858181,[Title page],IEEE,Conferences,"The following topics are dealt with: SDLC SPASI v. 4.0. business process; information extraction; statistics indicator tables; rule generalizations; ontology; conventional learning system; ICT-based learning; job training system; time-series data; RAID; software-based accelerator; virtualization environment; enterprise architecture government organization; TOGAF ADM; SONA; e- library; modified quantitative models for performance measurement system method; business process improvement; district government innovation service case study; government organization; m-government implementation evaluation; trusted Big Data; official statistics study case; data profiling; data quality improvement; secure internet access; copyright protection; color images; transform domain; luminance component; information network architecture; local government; software as a service; expert system; meningitis disease; certainty factor method; digital asset management system; broadcasting organizations; e-portofolio definition; system security requirement identification; electronic payment system; Internet-based long distance education; operational model data governance; requirement engineering; open government information network development; process capability assessment; information security management; information security governance; national cyber physical systems; e-learning readiness; remote control system; serial communications mobile; microcontroller; knowledge sharing; indonesia higher educational institutions; cultural heritage metadata; geo linked open data; NUSANTARA: knowledge management system; adaptive personalized learning system; interactive learning media; RPP ICT; government human capital management; knowledge management tools utilization; knowledge management readiness; analytic hierarchy process; government institutions; usability testing; scrum methodology; assistant information system; automatic arowana raiser; pSPEA2; strength Pareto evolutionary algorithm 2; early diagnosis expert system deficiency; digital forensic; user acceptance; human resource information system; automated plasmodium detection; malaria diagnosis; thin blood smear image; 3D virtual game; MOODLE; SLOODLE; open simulator case study; color-based segmentation; feature detection; ball post; goal post; mobile soccer robot game field; smart farming; real time q-log-based feature normalization; distant speech recognition; Monte Carlo localization; robot operating system; finite element method; 3D DC resistivity modeling; multi GPU; breast cancer lesions; adaptive thresholding; morphological operation; gamification framework; online training; collaborative working system; classification breast cancer ultrasound images; posterior features; three-wheeled omnidirectional robot controller; public services satisfaction; sentiment analysis; color blind test quantification; RGB primary color cluster; ERP modules requirement; micro, small and medium enterprise fashion industry; small culinary enterprises; business system requirement; small craft companies ; power analysis attack; DES and IT value model.",https://ieeexplore.ieee.org/document/7858181/,2016 International Conference on Information Technology Systems and Innovation (ICITSI),24-27 Oct. 2016,ieeexplore
10.1109/AICAS51828.2021.9458401,iELAS: An ELAS-Based Energy-Efficient Accelerator for Real-Time Stereo Matching on FPGA Platform,IEEE,Conferences,"Stereo matching is a critical task for robot navigation and autonomous vehicles, providing the depth estimation of surroundings. Among all stereo matching algorithms, Efficient Large-scale Stereo (ELAS) offers one of the best tradeoffs between efficiency and accuracy. However, due to the inherent iterative process and unpredictable memory access pattern, ELAS can only run at 1.5-3 fps on high-end CPUs and difficult to achieve real-time performance on low-power platforms. In this paper, we propose an energy-efficient architecture for real-time ELAS-based stereo matching on FPGA platform. Moreover, the original computational-intensive and irregular triangulation module is reformed in a regular manner with points interpolation, which is much more hardware-friendly. optimizations, including memory management, parallelism, and pipelining, are further utilized to reduce memory footprint and improve throughput. Compared with Intel i7 CPU and the state-of-the-art $\mathrm{C}\mathrm{P}\mathrm{U}+$FPGA implementation, our FPGA realization achieves up to $ 38.4\times$ and $ 3.32\times$ frame rate improvement, and up to $ 27.1\times$ and $ 1.13\times$ energy efficiency improvement, respectively.",https://ieeexplore.ieee.org/document/9458401/,2021 IEEE 3rd International Conference on Artificial Intelligence Circuits and Systems (AICAS),6-9 June 2021,ieeexplore
10.1109/RCAR47638.2019.9043946,libSmart: an Open-Source Tool for Simple Integration of Deep Learning into Intelligent Robotic Systems,IEEE,Conferences,"Intelligent robotic systems can be empowered by advanced deep learning techniques. Robotic operations such as object recognition are well investigated by researchers involved in machine learning. However, these solutions have often led to ad-hoc implementation in experimental settings. Less reported is systematic implementation of deep learning models in industrial robots. The lack of standard implementation platforms has impeded widespread use of deep learning modules in industrial robots. It is of great importance to have development platforms that can coordinate several deep learning modules of a complex system. In this paper, a scalable deep-learning friendly robot task organization system named libSmart is introduced. Similar to ROS, the architecture of the proposed system allows users to plug and play various devices but the proposed architecture is also highly compatible with deep learning modules. Specifically, the deployment of deep learning models is handled using a novel data graph method with distributed computing. In this way, the computationally expensive training and inferencing processes of deep learning models can be handled with isolated accelerating hardware to reduce the overall system latency. Successful implementation of simultaneous object recognition and pose estimation by an industrial robot has been presented as a case study. The proposed system is open source for all users to build their own intelligent systems with customized deep-learning models. (https://github.com/RustIron/libSmart.git).",https://ieeexplore.ieee.org/document/9043946/,2019 IEEE International Conference on Real-time Computing and Robotics (RCAR),4-9 Aug. 2019,ieeexplore
10.1109/CBS.2018.8612261,sEMG-Based Torque Estimation Using Time-Delay ANN for Control of an Upper-Limb Rehabilitation Robot,IEEE,Conferences,"Robotic-assisted rehabilitation of the upper limb following neurological injury can achieve best possible functional recovery when patients are engaged in the therapy. However, implementation of active training is still difficult as it's challenging to detect human motion intention online and impose corresponding robot control. This paper introduces a novel upper-limb rehabilitation robot, and proposes a sEMG-driven (sEMG: surface Electromyography) torque estimation model based on artificial neural networks (ANN). The robot has three DOFs, of which the first two DOFs adopt a planar parallel structure, and the wrist module has an exoskeleton form. In this study, we design an impedance controller and an admittance controller for the first two DOFs and the wrist module, respectively. Specifically, for the first two DOFs, the assistance/resistance force at the end-effector was controlled according to its motions and desired interaction impedance; for the wrist module, an sEMG armband was used to collect 8 channels of sEMG signals from the forearm muscles, and a time-delay ANN model was developed to estimate the wrist pronation/supination torque, based on which the wrist rotation was controlled according to the human motion intention. To overcome the overfitting problem, besides the experimental samples of wrist rotation, both resting and co-contraction samples were collected for training. Finally, combining with the design of a virtual reality game and force fields, the proposed methods were implemented and tested experimentally on the upper-limb rehabilitation robot.",https://ieeexplore.ieee.org/document/8612261/,2018 IEEE International Conference on Cyborg and Bionic Systems (CBS),25-27 Oct. 2018,ieeexplore
10.1109/TSMCC.2004.840063,"""Sticky Hands"": learning and generalization for cooperative physical interactions with a humanoid robot",IEEE,Journals,"""Sticky Hands"" is a physical game for two people involving gentle contact with the hands. The aim is to develop relaxed and elegant motion together, achieve physical sensitivity-improving reactions, and experience an interaction at an intimate yet comfortable level for spiritual development and physical relaxation. We developed a control system for a humanoid robot allowing it to play Sticky Hands with a human partner. We present a real implementation including a physical system, robot control, and a motion learning algorithm based on a generalizable intelligent system capable itself of generalizing observed trajectories' translation, orientation, scale and velocity to new data, operating with scalable speed and storage efficiency bounds, and coping with contact trajectories that evolve over time. Our robot control is capable of physical cooperation in a force domain, using minimal sensor input. We analyze robot-human interaction and relate characteristics of our motion learning algorithm with recorded motion profiles. We discuss our results in the context of realistic motion generation and present a theoretical discussion of stylistic and affective motion generation based on, and motivating cross-disciplinary research in computer graphics, human motion production and motion perception.",https://ieeexplore.ieee.org/document/1522534/,"IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)",Nov. 2005,ieeexplore
10.1109/ACCESS.2020.2983488,3D Semantic Map Construction Using Improved ORB-SLAM2 for Mobile Robot in Edge Computing Environment,IEEE,Journals,"Although the existing localization and mapping (SLAM) technology of indoor mobile robot has made great development, its intelligence and environmental perception ability still cannot meet the needs of service and inspection. Therefore, based on edge computing environment, a 3D semantic map construction of mobile robot based on improved ORB-SALM2 is proposed. Firstly, the improved yolov3 algorithm is used to detect indoor objects, and then the real-time semantic segmentation network model based on deep learning is used to segment indoor objects to achieve the classification of pixel points of objects on two-dimensional images, and BAFF feature fusion algorithm is introduced to improve the accuracy of semantic segmentation model. Then, through the SLAM system, we estimate the pose of the image in the result of semantic segmentation, and use the depth information to project it into the three-dimensional environment to build the three-dimensional semantic map. Finally, the experiment platform of mobile robot is built to verify the stability of ORB-D and thermal imaging sensor registration technology, the accuracy and real-time of building three-dimensional environment thermal field map, and the accuracy of robot positioning using thermal infrared and depth image.",https://ieeexplore.ieee.org/document/9047931/,IEEE Access,2020,ieeexplore
10.1109/TAMD.2011.2112766,A Biologically Inspired Architecture for an Autonomous and Social Robot,IEEE,Journals,"Lately, lots of effort has been put into the construction of robots able to live among humans. This fact has favored the development of personal or social robots, which are expected to behave in a natural way. This implies that these robots could meet certain requirements, for example, to be able to decide their own actions (autonomy), to be able to make deliberative plans (reasoning), or to be able to have an emotional behavior in order to facilitate human-robot interaction. In this paper, the authors present a bioinspired control architecture for an autonomous and social robot, which tries to accomplish some of these features. In order to develop this new architecture, authors have used as a base a prior hybrid control architecture (AD) that is also biologically inspired. Nevertheless, in the later, the task to be accomplished at each moment is determined by a fix sequence processed by the Main Sequencer. Therefore, the main sequencer of the architecture coordinates the previously programmed sequence of skills that must be executed. In the new architecture, the main sequencer is substituted by a decision making system based on drives, motivations, emotions, and self-learning, which decides the proper action at every moment according to robot's state. Consequently, the robot improves its autonomy since the added decision making system will determine the goal and consequently the skills to be executed. A basic version of this new architecture has been implemented on a real robotic platform. Some experiments are shown at the end of the paper.",https://ieeexplore.ieee.org/document/5711644/,IEEE Transactions on Autonomous Mental Development,Sept. 2011,ieeexplore
10.1109/ACCESS.2018.2851841,A Brain-Inspired Multi-Modal Perceptual System for Social Robots: An Experimental Realization,IEEE,Journals,"We propose a multi-modal perceptual system that is inspired by the inner working of the human brain; in particular, the hierarchical structure of the sensory cortex and the spatial-temporal binding criteria. The system is context independent and can be applied to many on-going problems in social robotics, including but not limited to person recognition, emotion recognition, and multi-modal robot doctor to name a few. The system encapsulates the parallel distributed processing of real-world stimuli through different sensor modalities and encoding them into features vectors which in turn are processed via a number of dedicated processing units (DPUs) through hierarchical paths. DPUs are algorithmic realizations of the cell assemblies in neuroscience. A plausible and realistic perceptual system is presented via the integration of the outputs from these units by spiking neural networks. We will also discuss other components of the system including top-down influences and the integration of information through temporal binding with fading memory and suggest two alternatives to realize these criteria. Finally, we will demonstrate the implementation of this architecture on a hardware platform as a social robot and report experimental studies on the system.",https://ieeexplore.ieee.org/document/8400512/,IEEE Access,2018,ieeexplore
10.1109/TCDS.2020.2968056,A Framework of Hybrid Force/Motion Skills Learning for Robots,IEEE,Journals,"Human factors and human-centered design philosophy are highly desired in today's robotics applications such as human-robot interaction (HRI). Several studies showed that endowing robots of human-like interaction skills can not only make them more likeable but also improve their performance. In particular, skill transfer by imitation learning can increase the usability and acceptability of robots by users without computer programming skills. In fact, besides positional information, muscle stiffness of the human arm and contact force with the environment also play important roles in understanding and generating human-like manipulation behaviors for robots, e.g., in physical HRI and teleoperation. To this end, we present a novel robot learning framework based on dynamic movement primitives (DMPs), taking into consideration both the positional and contact force profiles for human-robot skills transferring. Distinguished from the conventional method involving only the motion information, the proposed framework combines two sets of DMPs, which are built to model the motion trajectory and the force variation of the robot manipulator, respectively. Thus, a hybrid force/motion control approach is taken to ensure the accurate tracking and reproduction of the desired positional and force motor skills. Meanwhile, in order to simplify the control system, a momentum-based force observer is applied to estimate the contact force instead of employing force sensors. To deploy the learned motion-force robot manipulation skills to a broader variety of tasks, the generalization of these DMP models in actual situations is also considered. Comparative experiments have been conducted using a Baxter robot to verify the effectiveness of the proposed learning framework on real-world scenarios like cleaning a table.",https://ieeexplore.ieee.org/document/8964480/,IEEE Transactions on Cognitive and Developmental Systems,March 2021,ieeexplore
10.1109/TAMD.2011.2164404,A Multiple Context Brain for Experiments With Robot Consciousness,IEEE,Journals,"The PURR-PUSS system (PP) is a versatile model of a human-like brain, designed to be implemented in parallel hardware and embodied in the head of a robot moving in the real world. The aim of the research with PP is to try out mechanisms for learning, intelligence and consciousness. Limitations of resources have dictated that the experiments with PP are made on a personal computer by simulating the brain and robot body in a microworld. The unique features of PP are multiple context and novelty-seeking. In this paper, a squash-pop microworld is described first, so that concrete examples can be given for a brief review of the PP system, followed by two new features called trail memory, to realize Baars' global workspace, and belief memory, to realize Rosenthal's higher order thoughts and Johnson-Laird's conscious reasoning. The extended system, PP*, is designed to give consciousness to the subconscious PP, but higher order thoughts and conscious reasoning prove to be elusive. A definition of a conscious robot provides a measure of progress.",https://ieeexplore.ieee.org/document/5986693/,IEEE Transactions on Autonomous Mental Development,Dec. 2011,ieeexplore
10.1109/ACCESS.2021.3124386,A Multiple Pheromone Communication System for Swarm Intelligence,IEEE,Journals,"Pheromones are chemical substances essential for communication among social insects. In the application of swarm intelligence to real micro mobile robots, the deployment of a single virtual pheromone has emerged recently as a powerful real-time method for indirect communication. However, these studies usually exploit only one kind of pheromones in their task, neglecting the crucial fact that in the world of real insects, multiple pheromones play important roles in shaping stigmergic behaviors such as foraging or nest building. To explore the multiple pheromones mechanism which enable robots to solve complex collective tasks efficiently, we introduce an artificial multiple pheromone system (ColCOS<inline-formula> <tex-math notation=""LaTeX"">$\Phi $ </tex-math></inline-formula>) to support swarm intelligence research by enabling multiple robots to deploy and react to multiple pheromones simultaneously. The proposed system ColCOS<inline-formula> <tex-math notation=""LaTeX"">$\Phi $ </tex-math></inline-formula> uses optical signals to emulate different evaporating chemical substances i.e. pheromones. These emulated pheromones are represented by trails displayed on a wide LCD display screen positioned horizontally, on which multiple miniature robots can move freely. The color sensors beneath the robots can detect and identify lingering “pheromones” on the screen. Meanwhile, the release of any pheromone from each robot is enabled by monitoring its positional information over time with an overhead camera. No other communication methods apart from virtual pheromones are employed in this system. Two case studies have been carried out which have verified the feasibility and effectiveness of the proposed system in achieving complex swarm tasks as empowered by multiple pheromones. This novel platform is a timely and powerful tool for research into swarm intelligence.",https://ieeexplore.ieee.org/document/9594791/,IEEE Access,2021,ieeexplore
10.1109/TSMC.2013.2297398,A Multiple-Feature and Multiple-Kernel Scene Segmentation Algorithm for Humanoid Robot,IEEE,Journals,"This paper presents a multiple-feature and multiple-kernel support vector machine (MFMK-SVM) methodology to achieve a more reliable and robust segmentation performance for humanoid robot. The pixel wise intensity, gradient, and C1 SMF features are extracted via the local homogeneity model and Gabor filter, which would be used as inputs of MFMK-SVM model. It may provide multiple features of the samples for easier implementation and efficient computation of MFMK-SVM model. A new clustering method, which is called feature validity-interval type-2 fuzzy C-means (FV-IT2FCM) clustering algorithm, is proposed by integrating a type-2 fuzzy criterion in the clustering optimization process to improve the robustness and reliability of clustering results by the iterative optimization. Furthermore, the clustering validity is employed to select the training samples for the learning of the MFMKSVM model. The MFMK-SVM scene segmentation method is able to fully take advantage of the multiple features of scene image and the ability of multiple kernels. Experiments on the BSDS dataset and real natural socene images demonstrate the superior performance of our proposed method.",https://ieeexplore.ieee.org/document/6717184/,IEEE Transactions on Cybernetics,Nov. 2014,ieeexplore
10.1109/ACCESS.2017.2787738,A Neuro-Fuzzy Visual Servoing Controller for an Articulated Manipulator,IEEE,Journals,"The challenges of selecting appropriate image features, optimizing complex nonlinear computations, and minimizing the approximation errors always exist in visual servoing. A fuzzy neural network controller is developed for a six-degrees-of-freedom robot manipulator to perform visual servoing is proposed to tackle these problems. To increase the accuracy of the image preprocesses, a synthetic image process performs feature extraction for the controller. The method combines a support vector machine contour recognition algorithm and a color-based feature recognition algorithm. For visual servoing, a control method based on the fuzzy cerebellar model articulation controller with the Takagi-Sugeno framework is proposed to directly map an image feature error vector to a desired robot end-effector velocity. This approach achieves visual servoing control without the need of computing the inverse interaction matrix. The control variables are learned and updated by the T-S fuzzy inference. This simplifies the implementation of visual servoing in real-time applications. The proposed control method is used to control an articulated manipulator with an eye-in-hand configuration. The results of simulations and experiments demonstrate that the proposed visual servoing controller has good performance, in terms of stability and convergence.",https://ieeexplore.ieee.org/document/8247175/,IEEE Access,2018,ieeexplore
10.1109/ACCESS.2020.2973756,A New Automatic Real-Time Crop Row Recognition Based on SoC-FPGA,IEEE,Journals,"With the development of artificial intelligence technology, agricultural robot plays a significantly important role for agricultural intelligence. Crop row line detection is a critical and fundamental step for agricultural robot navigation. Although there are some crop row lines detection methods, few of them can meet the real-time requirement for agricultural robot under complex fields conditions. In view of this, a real-time crop detection system implemented on a SoC FPGA (System-on-a-Chip Field Programmable Gate Array) is first proposed in this paper, which contains crop segmentation and crop row detection, where we design parallel pipeline architecture to enhance real-time performance by using line buffer and sliding windows technologies. At the same time, the fixed point representation is used to reduce the memory resource in this system. The proposed system is evaluated and implemented on Xilinx Zynq UltraScale+ MPSoC ZCU102 SoC-FPGA. The experimental results show that the proposed system can process an image with 1920×1080 resolution only within 210 ms with the average accuracy of 89.7%, which satisfies the real-time requirements of the crop rows recognition.",https://ieeexplore.ieee.org/document/8998211/,IEEE Access,2020,ieeexplore
10.1109/ACCESS.2019.2946848,A New Multi-Agent Reinforcement Learning Method Based on Evolving Dynamic Correlation Matrix,IEEE,Journals,"Multi-agent reinforcement learning approaches can be roughly classified into two categories. One is the agent-based approach which can be implemented in real distributed systems, though most approaches of this type cannot provide meaningful theoretical verifications. The other can be seen as the more formalized approach, which can provide theoretical results. However, most of current algorithms usually require unrealistic global communication, which makes them impractical for real distributed systems. In this article, we propose a dynamic correlation matrix based multi-agent reinforcement learning approach where the meta-parameters are evolved using an evolutionary algorithm. We believe that our approach is able to fill the gap between the two kinds of traditional multi-agent reinforcement learning approaches by providing both agent-level implementation and system-level convergence verification. The basic idea of this approach is that agents learn not only from local environmental feedback, i.e., their own experiences and rewards, but also from other agents' experiences. In this way, the agents' learning speed can be increased significantly. The performance of the proposed algorithm is demonstrated on a number of application scenarios, including blackjack games, urban traffic control systems and multi-robot foraging.",https://ieeexplore.ieee.org/document/8864051/,IEEE Access,2019,ieeexplore
10.1109/TSMC.2019.2956321,A Novel Approach to Image-Sequence-Based Mobile Robot Place Recognition,IEEE,Journals,"Visual place recognition is a challenging problem in simultaneous localization and mapping (SLAM) due to a large variability of the scene appearance. A place is usually described by a single-frame image in conventional place recognition algorithms. However, it is unlikely to completely describe the place appearance using a single frame image. Moreover, it is more sensitive to the change of environments. In this article, a novel image-sequence-based framework for place detection and recognition is proposed. Rather than a single frame image, a place is represented by an image sequence in this article. Position invariant robust feature (PIRF) descriptors are extracted from images and processed by the incremental bag-of-words (BoWs) for feature extraction. The robot automatically partitions the sequentially acquired images into different image sequences according to the change of the environmental appearance. Then, the echo state network (ESN) is applied to model each image sequence. The resultant states of the ESN are used as features of the corresponding image sequence for place recognition. The proposed method is evaluated on two public datasets. Experimental comparisons with the FAB-MAP 2.0 and SeqSLAM are conducted. Finally, a real-world experiment on place recognition with a mobile robot is performed to further verify the proposed method.",https://ieeexplore.ieee.org/document/8931657/,"IEEE Transactions on Systems, Man, and Cybernetics: Systems",Sept. 2021,ieeexplore
10.1109/ACCESS.2021.3105102,A Novel Maximin-Based Multi-Objective Evolutionary Algorithm Using One-by-One Update Scheme for Multi-Robot Scheduling Optimization,IEEE,Journals,"With the continuous development of E-commerce, warehouse logistics is also facing emerging challenges, including more batches of orders and shorter order processing cycles. When more orders need to be processed simultaneously, some existing task scheduling methods may not be able to give a suitable plan, which delays order processing and reduces the efficiency of the warehouse. Therefore, the intelligent warehouse system that uses autonomous robots for automated storage and intelligent order scheduling is becoming mainstream. Based on this concept, we propose a multi-robot cooperative scheduling system in the intelligent warehouse. The aim of the multi-robot cooperative scheduling system of the intelligent storage is to drive many robots in an intelligent warehouse to perform the distributed tasks in an optimal (e.g., time-saving and energy-conserved) way. In this paper, we propose a multi-robot cooperative task scheduling model in the intelligent warehouse. For this model, we design a maximin-based multi-objective algorithm, which uses a one-by-one update scheme to select individuals. In this algorithm, two indicators are devised to discriminate the equivalent individuals with the same maximin fitness value in the environmental selection process. The results on benchmark test suite show that our algorithm is indeed a useful optimizer. Then it is applied to settle the multi-robot scheduling problem in the intelligence warehouse. Simulation experiment results demonstrate the efficiency of the proposed algorithm on the real-world scheduling problem.",https://ieeexplore.ieee.org/document/9514575/,IEEE Access,2021,ieeexplore
10.1109/TCYB.2019.2946090,A Robust Collision Perception Visual Neural Network With Specific Selectivity to Darker Objects,IEEE,Journals,"Building an efficient and reliable collision perception visual system is a challenging problem for future robots and autonomous vehicles. The biological visual neural networks, which have evolved over millions of years in nature and are working perfectly in the real world, could be ideal models for designing artificial vision systems. In the locust's visual pathways, a lobula giant movement detector (LGMD), that is, the LGMD2, has been identified as a looming perception neuron that responds most strongly to darker approaching objects relative to their backgrounds; similar situations which many ground vehicles and robots are often faced with. However, little has been done on modeling the LGMD2 and investigating its potential in robotics and vehicles. In this article, we build an LGMD2 visual neural network which possesses the similar collision selectivity of an LGMD2 neuron in locust via the modeling of biased-ON and -OFF pathways splitting visual signals into parallel ON/OFF channels. With stronger inhibition (bias) in the ON pathway, this model responds selectively to darker looming objects. The proposed model has been tested systematically with a range of stimuli including real-world scenarios. It has also been implemented in a micro-mobile robot and tested with real-time experiments. The experimental results have verified the effectiveness and robustness of the proposed model for detecting darker looming objects against various dynamic and cluttered backgrounds.",https://ieeexplore.ieee.org/document/8922628/,IEEE Transactions on Cybernetics,Dec. 2020,ieeexplore
10.1109/JSEN.2020.3042665,A Searching Space Constrained Partial to Full Registration Approach With Applications in Airport Trolley Deployment Robot,IEEE,Journals,"For airports with high passenger and luggage flows, a large number of staff members have to be hired to deploy the scattered passenger luggage trolleys. To release humans from the repetitive and laborious job, we develop an autonomous trolley deployment robot to detect, transport and collect the scattered idle trolleys to recycling points. This paper will firstly illustrate the entire collection pipeline of the deployment robot system and then address the key challenge: partial to full point set registration. With the perception framework, the robot can detect the idle trolleys and acquire the pose of the trolleys on the ground, and then capture the trolley from behind, along the same direction for subsequent grasping and manipulation. With RGB-D camera and a segmentation Convolutional Neural Network, the robot can generate a partial surface point cloud of the detected trolley. The resulting point cloud, data and a pre-scanned full trolley point cloud, model, are matched by an implicit pose. To tackle the low accuracy and long computation time issues, a novel searching space-constrained point set registration algorithm is proposed to register the two overlapping point sets. Based on Branch-and-Bound (BnB) mechanism, the error between data and model is iteratively optimized. The constraint of searching space speeds up the global searching of the optimal pose, by pruning the candidate spaces which is impossible to contain the optimal result. To evaluate the performance, an airport trolley segmentation dataset and a point cloud dataset for registration are constructed. Experimental results on the datasets and synthetic dataset show that our method achieves higher accuracy and success rate than the previous methods. The experiments demonstrated in video clips validate the developed system works in real-world applications.",https://ieeexplore.ieee.org/document/9281085/,IEEE Sensors Journal,"15 May15, 2021",ieeexplore
10.1109/ACCESS.2020.3003991,A Software Architecture for Service Robots Manipulating Objects in Human Environments,IEEE,Journals,"This paper presents a software architecture for robots providing manipulation services autonomously in human environments. In an unstructured human environment, a service robot often needs to perform tasks even without human intervention and prior knowledge about tasks and environments. For autonomous execution of tasks, varied processes are necessary such as perceiving environments, representing knowledge, reasoning with the knowledge, and planning for task and motion. While developing each of the processes is important, integrating them into a working system for deployment is also important as a robotic system can bring tangible outcomes when it works in real world. However, such an architecture has been rarely realized in the literature owing to the difficulties of a full integration, deployment, understanding high-level goals without human interventions. In this work, we suggest a software architecture that integrates the components necessary to perform tasks by a real robot without human intervention. We show our architecture composed of deep learning based perception, symbolic reasoning, AI task planning, and geometric motion planning. We implement a deep neural network that produces information about the environment, which are then stored in a knowledge base. We implement a reasoner that processes the knowledge to use the result for task planning. We show our implementation of the symbolic task planner that generates a sequence of motion predicates. We implement an interface that computes geometric information necessary for motion planning to execute the symbolic task plans. We describe the deployment of the architecture through the result of lab tests and a public demonstration. The architecture is developed based on Robot Operating System (ROS) so compatible with any robot that is capable of object manipulation and mobile navigation running in ROS. We deploy the architecture to two different robot platforms to show the compatibility.",https://ieeexplore.ieee.org/document/9122008/,IEEE Access,2020,ieeexplore
10.1109/TASE.2020.2980628,A System Architecture for CAD-Based Robotic Assembly With Sensor-Based Skills,IEEE,Journals,"Specifying assembly tasks in computer-aided design (CAD) level is a promising approach to intuitively program complex robot skills. In this article, a three-layered system architecture is presented to generate sensor-based robot skills from an assembly task instance. The architecture consists of an application layer where the user instantiates assembly tasks by specifying CAD constraints between geometric primitives pairs. A process layer infers the most suitable robot skills and their appropriate parameters. This inference is made possible by reasoning on a knowledge database represented as an ontology. The ontology contains semantic models of relevant classes such as tasks, skills, and geometric primitives as well as the relations between them. A control layer executes the sensor-based skills in real time using the eTaSL programming framework. A software implementation for the three layers is presented. The application layer is implemented in FreeCAD, whereas the process layer consists of a Web ontology language (OWL) ontology, a Prolog-based reasoner, and fuzzy inference to correctly select the skill and generate its parameters. In the control layer, the instantiated eTaSL skills execute the assembly tasks by sending an optimized control command to the robot. The system is validated on two challenging assembly cases with two distinct robot types, thus demonstrating the system's capability across different scenarios. Note to Practitioners-The widespread use of computer-aided design (CAD) models for describing parts assembly has motivated the research community to create systems that automatically generate robot programs satisfying the assembly goal. While most of the existing literature focuses on generating the assembly sequence, this article deals with the aspect of translation from CAD-level assembly specification to executable robot motion, also called skills. This article systematically addresses the problem by dividing it into different layers and solving them separately. Parameters that influence the successful execution of an assembly task are identified and categorized into application- and process-related parameters. Different inference techniques are employed to address each parameter category. Experimental results show that the proposed system can successfully generate and execute robot skills for assembly scenarios of an air compressor and an electric motor.",https://ieeexplore.ieee.org/document/9061146/,IEEE Transactions on Automation Science and Engineering,July 2020,ieeexplore
10.1109/JPROC.2018.2840045,A Value-Driven Eldercare Robot: Virtual and Physical Instantiations of a Case-Supported Principle-Based Behavior Paradigm,IEEE,Journals,"In this paper, a case-supported principle-based behavior paradigm is proposed to help ensure ethical behavior of autonomous machines. We argue that ethically significant behavior of autonomous systems should be guided by explicit ethical principles determined through a consensus of ethicists. Such a consensus is likely to emerge in many areas in which autonomous systems are apt to be deployed and for the actions they are liable to undertake. We believe that this is the case since we are more likely to agree on how machines ought to treat us than on how human beings ought to treat one another. Given such a consensus, particular cases of ethical dilemmas where ethicists agree on the ethically relevant features and the right course of action can be used to help discover principles that balance these features when they are in conflict. Such principles not only help ensure ethical behavior of complex and dynamic systems but also can serve as a basis for justification of this behavior. The requirements, methods, implementation, and evaluation components of the paradigm are detailed as well as its instantiation in both a simulated and real robot functioning in the domain of eldercare.",https://ieeexplore.ieee.org/document/8500162/,Proceedings of the IEEE,March 2019,ieeexplore
10.1109/TASE.2020.3032075,A Virtual Mechanism Approach for Exploiting Functional Redundancy in Finishing Operations,IEEE,Journals,"We propose a new approach to programming by the demonstration of finishing operations. Such operations can be carried out by industrial robots in multiple ways because an industrial robot is typically functionally redundant with respect to a finishing task. In the proposed system, a human expert demonstrates a finishing operation, and the demonstrated motion is recorded in the Cartesian space. The robot’s kinematic model is augmented with a virtual mechanism, which is defined according to the applied finishing tool. This way, the kinematic model is expanded with additional degrees of freedom that can be exploited to compute the optimal joint space motion of the robot without altering the essential aspects of the Cartesian space task execution as demonstrated by the human expert. Finishing operations, such as polishing and grinding, occur in contact with the treated workpiece. Since information about the contact point position is needed to control the robot during the operation, we have developed a novel approach for accurate estimation of contact points using the measured forces and torques. Finally, we applied iterative learning control to refine the demonstrated operations and compensate for inaccurate calibration and different dynamics of the robot and human demonstrator. The proposed method was verified on real robots and real polishing and grinding tasks. <italic>Note to Practitioners</italic>—This work was motivated by the need for automation of finishing operations, such as polishing and grinding, on contemporary industrial robots. Existing approaches are both too complex and too time-consuming to be applied in flexible and small-scale production, which often requires the frequent deployment of new applications. Our approach is based on programming by demonstration and enables the programming of finishing operations also for users who are not specialists in robot programming. Programming by demonstration is especially useful for teaching finishing operations because it enables the transfer of expert knowledge about finishing skills to robots without providing lengthy task descriptions or manual coding. Besides the human demonstration of the desired operation, the proposed approach also requires the availability of the kinematic model for the machine tool applied to carry out the finishing operation. We provide several practical examples of grinding and polishing tools and how to integrate them into our approach. Another feature of the proposed system is that user demonstrations of finishing operations can be transferred between different combinations of robots and machine tools.",https://ieeexplore.ieee.org/document/9246671/,IEEE Transactions on Automation Science and Engineering,Oct. 2021,ieeexplore
10.1109/TIE.2017.2764849,A Vision-Aided Approach to Perching a Bioinspired Unmanned Aerial Vehicle,IEEE,Journals,"This paper presents the implementation of a machine learning approach for replicating highly adaptive avian perching behavior. With full consideration of both the configuration of flying vehicles and perching principles, a bioinspired aerial robot comprising one flight subsystem and one perching subsystem is designed. Based on the real-time landing speed and attitude, a novel type of soft grasping mechanism for dexterous perching is proposed to provide adhesive force and absorb impact force. During the critical perching phase, the dynamics of the perching actuator change with the touchdown conditions and the type of perching target. A hybrid automation of a time-to-contact theory-based attitude controller and a robust self-localization system are utilized to regulate the desired perching maneuvers. The experimental results are provided to attest to the effectiveness of the proposed perching method.",https://ieeexplore.ieee.org/document/8074761/,IEEE Transactions on Industrial Electronics,May 2018,ieeexplore
10.1109/TSMC.2019.2912715,A Visual Leader-Following Approach With a T-D-R Framework for Quadruped Robots,IEEE,Journals,"The quadruped robot imitates the motions of four-legged animals with a superior flexibility and adaptability to complex terrains, compared with the wheeled and tracked robots. Its leader-following ability is unique to help a human to accomplish complex tasks in a more convenient way. However, long-term following is severely obstructed due to the high-frequency vibration of the quadruped robot and the unevenness of terrains. To solve this problem, a visual approach under a novel T-D-R framework is proposed. The proposed T-D-R framework is composed of a visual tracker based on correlation filter, a person detector with deep learning, and a person re-identification (re-ID) module. The result of the tracker is verified by the detector to improve tracking performance. Especially, the re-ID module is introduced to handle distractions and occlusion caused by other persons, where the convolutional correlation filter (CCF) is employed to discriminate the leader among multiple persons through recording the appearance information in the long run. By comparing the results of the tracker and the detector as well as their similarity scores with the leader identified by the re-ID module, a stable and real-time tracking of the leader can be guaranteed. Experiments reveal that our approach is effective in handling distractions, appearance changes, and illumination variations. A long-distance experiment on a quadruped robot indicates the validity of the proposed approach.",https://ieeexplore.ieee.org/document/8709995/,"IEEE Transactions on Systems, Man, and Cybernetics: Systems",April 2021,ieeexplore
10.1109/70.88099,A behavior-based arm controller,IEEE,Journals,"The author presents a working, implemented controller for an actual mobile robot arm. The goal of the system is to locate and retrieve empty soda cans in an unstructured environment using a variety of local sensors. The controller, however, is not a centralized sequential program, but rather a collection of 15 independent behaviors. Each of these behaviors contains some grain of expertise concerning the collection task and cooperates with the others to accomplish its goal. These behaviors run concurrently, in real time, on a set of eight loosely coupled on-board 8-bit microprocessors. The author describes the methodology used to decompose the collection task and discusses the types of implicit spatial representation and reasoning used by the system.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/88099/,IEEE Transactions on Robotics and Automation,Dec. 1989,ieeexplore
10.1109/JAS.2017.7510622,A facial expression emotion recognition based human-robot interaction system,IEEE,Journals,"A facial expression emotion recognition based human-robot interaction (FEER-HRI) system is proposed, for which a four-layer system framework is designed. The FEER-HRI system enables the robots not only to recognize human emotions, but also to generate facial expression for adapting to human emotions. A facial emotion recognition method based on 2D-Gabor, uniform local binary pattern (LBP) operator, and multiclass extreme learning machine (ELM) classifier is presented, which is applied to real-time facial expression recognition for robots. Facial expressions of robots are represented by simple cartoon symbols and displayed by a LED screen equipped in the robots, which can be easily understood by human. Four scenarios, i.e., guiding, entertainment, home service and scene simulation are performed in the human-robot interaction experiment, in which smooth communication is realized by facial expression recognition of humans and facial expression generation of robots within 2 seconds. As a few prospective applications, the FEER-HRI system can be applied in home service, smart home, safe driving, and so on.",https://ieeexplore.ieee.org/document/8039024/,IEEE/CAA Journal of Automatica Sinica,2017,ieeexplore
10.1109/TNSRE.2020.3038175,AI Therapist Realizing Expert Verbal Cues for Effective Robot-Assisted Gait Training,IEEE,Journals,"Repetitive and specific verbal cues by a therapist are essential in aiding a patient's motivation and improving the motor learning process. The verbal cues comprise various expressions, sentences, volumes, and timings, depending on the therapist's proficiency. This paper proposes an AI therapist (AI-T) that implements the verbal cues of professional therapists having extensive experience with robot-assisted gait training using the SUBAR for stroke patients. The AI-T was developed using a neuro-fuzzy system, a machine learning technique leveraging the benefits of fuzzy logic and artificial neural networks. The AI-T was trained with the professional therapist's verbal cue data, as well as clinical and robotic data collected from robot-assisted gait training with real stroke patients. Ten clinical data and 16 robotic data are input variables, and six verbal cues are output variables. Fifty-eight stroke patients wore the SUBAR, a gait training robot, and participated in the robot-assisted gait training. A total of 9059 verbal cue data, 580 clinical data of stroke patients, and 144 944 robotic data were collected from 693 training sessions. Test results show that the trained AI-T can implement six types of verbal cues with 93.7% accuracy for the 1812 verbal cue data of the professional therapist. Currently, the trained AI-T is deployed in the SUBAR and provides six verbal cues to stroke patients in robot-assisted gait training.",https://ieeexplore.ieee.org/document/9260225/,IEEE Transactions on Neural Systems and Rehabilitation Engineering,Dec. 2020,ieeexplore
10.1162/NECO_a_00376,ANUBIS: Artificial Neuromodulation Using a Bayesian Inference System,MIT Press,Journals,"Gain tuning is a crucial part of controller design and depends not only on an accurate understanding of the system in question, but also on the designer's ability to predict what disturbances and other perturbations the system will encounter throughout its operation. This letter presents ANUBIS (artificial neuromodulation using a Bayesian inference system), a novel biologically inspired technique for automatically tuning controller parameters in real time. ANUBIS is based on the Bayesian brain concept and modifies it by incorporating a model of the neuromodulatory system comprising four artificial neuromodulators. It has been applied to the controller of EchinoBot, a prototype walking rover for Martian exploration. ANUBIS has been implemented at three levels of the controller; gait generation, foot trajectory planning using Bézier curves, and foot trajectory tracking using a terminal sliding mode controller. We compare the results to a similar system that has been tuned using a multilayer perceptron. The use of Bayesian inference means that the system retains mathematical interpretability, unlike other intelligent tuning techniques, which use neural networks, fuzzy logic, or evolutionary algorithms. The simulation results show that ANUBIS provides significant improvements in efficiency and adaptability of the three controller components; it allows the robot to react to obstacles and uncertainties faster than the system tuned with the MLP, while maintaining stability and accuracy. As well as advancing rover autonomy, ANUBIS could also be applied to other situations where operating conditions are likely to change or cannot be accurately modeled in advance, such as process control. In addition, it demonstrates one way in which neuromodulation could fit into the Bayesian brain framework.",https://ieeexplore.ieee.org/document/6797771/,Neural Computation,Jan. 2013,ieeexplore
10.1109/TRO.2006.878969,Acquisition of intermediate goals for an agent executing multiple tasks,IEEE,Journals,"In this paper, an algorithm that acquires the intermediate goals between the initial and goal states is proposed for an agent executing multiple tasks. We demonstrate the algorithm in the problem of rearranging multiple objects. The result shows that the moving distance to transfer the entire objects to their goal configuration is 1/15 of that without using intermediate goals. We experiment using a real robot to confirm that the intermediate goal can be adapted to a real environment. Our experimental results showed that an agent could adapt the intermediate goals, which were acquired in the simulation, to the experimental environment",https://ieeexplore.ieee.org/document/1705594/,IEEE Transactions on Robotics,Oct. 2006,ieeexplore
10.1109/TCDS.2018.2846778,Adaptive Behavior Acquisition of a Robot Based on Affective Feedback and Improvised Teleoperation,IEEE,Journals,"In socially assistive robotics, especially for children with autism spectrum disorder (ASD), adapting the behavior of the robot according to the personal characteristics of each individual is one of the important challenges. Machine learning techniques are promising approaches to endow a robot with the capability of adapting its behavior through the interaction. It is critical to prepare a rich data set such as a set of behaviors with teaching signals for each individual with ASD to allow application of the state-of-the-art machine learning techniques; however, this is typically difficult to prepare in advance owing to the diverseness of ASD and the complexity of the motion design of the robot. This paper proposes a framework to acquire the personalized behavior set of a robot by combining a robot teleoperation method and a wearable device for detecting the affective cue of a child with ASD while interacting with the robot. The developed system allows the human operator to improvise the robot's behavior flexibly in real-time to explore the preferred interaction manner and motion patterns of each child. The preferred motion patterns are extracted and evaluated based on the affective state of the child estimated by the wearable device, and stored in the personal database for each individual with ASD. We conducted a free-interaction experiment with ten participants with ASD and demonstrated that the proposed system successfully described the interaction between the robot and the participant for acquiring the appropriate behaviors of the robot.",https://ieeexplore.ieee.org/document/8383948/,IEEE Transactions on Cognitive and Developmental Systems,Sept. 2019,ieeexplore
10.1109/ACCESS.2020.2973169,Adaptive Exploration Strategy With Multi-Attribute Decision-Making for Reinforcement Learning,IEEE,Journals,"Reinforcement Learning (RL) agents often encounter the bottleneck of the performance when the dilemma of exploration and exploitation arises. In this study, an adaptive exploration strategy with multi-attribute decision-making is proposed to address the trade-off problem between exploration and exploitation. Firstly, the proposed method decomposes a complex task into several sub-tasks and trains each sub-task using the same training method individually. Then, the proposed method uses a multi-attribute decision-making method to develop an action policy integrating the training results of these trained sub-tasks. There are practical advantages to improve learning performance by allowing multiple learners to learn in parallel. An adaptive exploration strategy determines the probability of exploration depending on the information entropy instead of the suffocating work of empirical tuning. Finally, transfer learning extends the applicability of the proposed method. The experiment of the robot migration, the robot confrontation, and the real wheeled mobile robot are used to demonstrate the availability and practicability of the proposed method.",https://ieeexplore.ieee.org/document/8993720/,IEEE Access,2020,ieeexplore
10.1109/TFUZZ.2020.2991147,Adaptive Image-Based Visual Servoing Using Reinforcement Learning With Fuzzy State Coding,IEEE,Journals,"Image-based visual servoing (IBVS) allows precise control of positioning and motion for relatively stationary targets using visual feedback. For IBVS, a mixture parameter β allows better approximation of the image Jacobian matrix, which has a significant effect on the performance of IBVS. However, the setting for the mixture parameter depends on the camera's realtime posture; there is no clear way to define the change rules for most IBVS applications. Using simple model-free reinforcement learning, Q-learning, this article proposes a method to adaptively adjust the image Jacobian matrix for IBVS. If the state-space is discretized, traditional Q-learning encounters problems with the resolution that can cause sudden changes in the action, so the visual servoing system performs poorly. Besides, a robot in a real-world environment also cannot learn on as large a scale as virtual agents, so the efficiency with which agents learn must be increased. This article proposes a method that uses fuzzy state coding to accelerate learning during the training phase and to produce a smooth output in the application phase of the learning experience. A method that compensates for delay also allows more accurate extraction of features in a real environment. The results for simulation and experiment demonstrate that the proposed method performs better than other methods, in terms of learning speed, movement trajectory, and convergence time.",https://ieeexplore.ieee.org/document/9082110/,IEEE Transactions on Fuzzy Systems,Dec. 2020,ieeexplore
10.1109/TIE.2016.2538741,Adaptive Impedance Control for an Upper Limb Robotic Exoskeleton Using Biological Signals,IEEE,Journals,"This paper presents adaptive impedance control of an upper limb robotic exoskeleton using biological signals. First, we develop a reference musculoskeletal model of the human upper limb and experimentally calibrate the model to match the operator's motion behavior. Then, the proposed novel impedance algorithm transfers stiffness from human operator through the surface electromyography (sEMG) signals, being utilized to design the optimal reference impedance model. Considering the unknown deadzone effects in the robot joints and the absence of the precise knowledge of the robot's dynamics, an adaptive neural network control incorporating with a high-gain observer is developed to approximate the deadzone effect and robot's dynamics and drive the robot tracking desired trajectories without velocity measurements. In order to verify the robustness of the proposed approach, the actual implementation has been performed using a real robotic exoskeleton and a human operator.",https://ieeexplore.ieee.org/document/7426396/,IEEE Transactions on Industrial Electronics,Feb. 2017,ieeexplore
10.1109/TMECH.2015.2396114,Adaptive Neural Network Control of a Compact Bionic Handling Arm,IEEE,Journals,"In this paper, autonomous control problem of a class of bionic continuum robots named “Compact Bionic Handling Arm” (CBHA) is addressed. These robots can reproduce biological behaviors of trunks, tentacles, or snakes. The modeling problem associated with continuum robots includes nonlinearities, structured and unstructured uncertainties, and the hyperredundancy. In addition to these problems, the CBHA comprises the hysteresis behavior of its actuators and a memory phenomenon related to its structure made of polyamide materials. These undesirable effects make it difficult to design a control system based on quantitative models of the CBHA. Thus, two subcontrollers are proposed in this paper. One, encapsulated in the other, and both implemented in real time allow controlling of the CBHA's end-effector position. The first subcontroller controls the CBHA's kinematics based on a distal supervised learning scheme. The second subcontroller controls the CBHA's kinetics based on an adaptive neural control. These subcontrollers allow a better assessment of the stability of the control architecture while ensuring the convergence of Cartesian errors. The obtained experimental results using a CBHA robot show an accurate tracking of the CBHA's end-effector position.",https://ieeexplore.ieee.org/document/7057549/,IEEE/ASME Transactions on Mechatronics,Dec. 2015,ieeexplore
10.1109/TCST.2012.2191969,Adaptive PD Controller Modeled via Support Vector Regression for a Biped Robot,IEEE,Journals,"The real-time balance control of an eight link biped robot using a zero moment point (ZMP) dynamic model is difficult due to the processing time of the corresponding equations. To overcome this limitation, an intelligent computing control technique is used. This technique is based on support vector regression (SVR). The method uses the ZMP error and its variation as inputs, and the output is the correction of the robot's torso necessary for its sagittal balance. The SVR is trained based on simulation data and their performance is verified with a real biped robot. The ZMP is calculated by reading four force sensors placed under each robot's foot. The gait implemented in this biped is similar to a human gait that is acquired and adapted to the robot's size. Some experiments are presented, and the results show that the implemented gait combined with the SVR controller can be used to control this biped robot. The SVR controller performs the control in 0.2 ms.",https://ieeexplore.ieee.org/document/6180212/,IEEE Transactions on Control Systems Technology,May 2013,ieeexplore
10.1109/TNNLS.2012.2204771,Adaptive Visual and Auditory Map Alignment in Barn Owl Superior Colliculus and Its Neuromorphic Implementation,IEEE,Journals,"Adaptation is one of the most important phenomena in biology. A young barn owl can adapt to imposed environmental changes, such as artificial visual distortion caused by wearing a prism. This adjustment process has been modeled mathematically and the model replicates the sensory map realignment of barn owl superior colliculus (SC) through axonogenesis and synaptogenesis. This allows the biological mechanism to be transferred to an artificial computing system and thereby imbue it with a new form of adaptability to the environment. The model is demonstrated in a real-time robot environment. Results of the experiments are compared with and without prism distortion of vision, and show improved adaptability for the robot. However, the computation speed of the embedded system in the robot is slow. A digital and analog mixed signal very-large-scale integration (VLSI) circuit has been fabricated to implement adaptive sensory pathway changes derived from the SC model at higher speed. VLSI experimental results are consistent with simulation results.",https://ieeexplore.ieee.org/document/6255791/,IEEE Transactions on Neural Networks and Learning Systems,Sept. 2012,ieeexplore
10.1109/JIOT.2020.2979413,Adversarial Learning-Enabled Automatic WiFi Indoor Radio Map Construction and Adaptation With Mobile Robot,IEEE,Journals,"Location-based service (LBS) has become an indispensable part of our daily lives. Realizing accurate LBS in indoor environments is still a challenging task. WiFi fingerprinting-based indoor positioning system (IPS) has achieved encouraging results recently, but the time and labor overhead of constructing a dense WiFi radio map remains the key bottleneck that hinders it for real-world large-scale implementation. In this article, we propose WiGAN an automatic fine-grained indoor ratio map construction and the adaptation scheme empowered by the Gaussian process regression conditioned least-squares generative adversarial networks (GPR-GANs) with a mobile robot. First, we develop a mobile robotic platform that constructs the spatial map and radio map simultaneously in the easily accessed free space. GPR-GAN first establishes a Gaussian process regression (GPR) model using the real received signal strength (RSS) measurements collected by our robotic platform via LiDAR SLAM in the free space. Then, the outputs of the GPR are adopted as the input of GAN's generator. The learning objective of GAN is to synthesize realistic RSS data in a constrained space where it has not been covered and model the irregular RSS distributions in complex indoor environments. Real-world experiments were conducted in a real-world indoor environment, which confirms the feasibility, high accuracy, and superiority of WiGAN over existing solutions in terms of both RSS estimation accuracy and localization accuracy.",https://ieeexplore.ieee.org/document/9031749/,IEEE Internet of Things Journal,Aug. 2020,ieeexplore
10.1109/LRA.2020.2965911,Aggressive Perception-Aware Navigation Using Deep Optical Flow Dynamics and PixelMPC,IEEE,Journals,"Recently, vision-based control has gained traction by leveraging the power of machine learning. In this work, we couple a model predictive control (MPC) framework to a visual pipeline. We introduce deep optical flow (DOF) dynamics, which is a combination of optical flow and robot dynamics. Using the DOF dynamics, MPC explicitly incorporates the predicted movement of relevant pixels into the planned trajectory of a robot. Our implementation of DOF is memory-efficient, data-efficient, and computationally cheap so that it can be computed in real-time for use in an MPC framework. The suggested Pixel Model Predictive Control (PixelMPC) algorithm controls the robot to accomplish a high-speed racing task while maintaining visibility of the important features (gates). This improves the reliability of vision-based estimators for localization and can eventually lead to safe autonomous flight. The proposed algorithm is tested in a photorealistic simulation with a high-speed drone racing task.",https://ieeexplore.ieee.org/document/8957291/,IEEE Robotics and Automation Letters,April 2020,ieeexplore
10.1109/TASE.2020.3043636,An Ergodic Measure for Active Learning From Equilibrium,IEEE,Journals,"This article develops KL-ergodic exploration from equilibrium (KL-E<sup>3</sup>), a method for robotic systems to integrate stability into actively generating informative measurements through ergodic exploration. Ergodic exploration enables robotic systems to indirectly sample from informative spatial distributions globally, avoiding local optima, and without the need to evaluate the derivatives of the distribution against the robot dynamics. Using a hybrid systems theory, we derive a controller that allows a robot to exploit equilibrium policies (i.e., policies that solve a task) while allowing the robot to explore and generate informative data using an ergodic measure that can extend to high-dimensional states. We show that our method is able to maintain Lyapunov attractiveness with respect to the equilibrium task while actively generating data for learning tasks such, as Bayesian optimization, model learning, and off-policy reinforcement learning. In each example, we show that our proposed method is capable of generating an informative distribution of data while synthesizing smooth control signals. We illustrate these examples using simulated systems and provide simplification of our method for real-time online learning in robotic systems. <italic>Note to Practitioners</italic>—Robotic systems need to adapt to sensor measurements and learn to exploit an understanding of the world around them such that they can truly begin to experiment in the real world. Standard learning methods do not have any restrictions on how the robot can explore and learn, making the robot dynamically volatile. Those that do are often too restrictive in terms of the stability of the robot, resulting in a lack of improved learning due to poor data collection. Applying our method would allow robotic systems to be able to adapt online without the need for human intervention. We show that considering both the dynamics of the robot and the statistics of where the robot has been, we are able to naturally encode where the robot needs to explore and collect measurements for efficient learning that is dynamically safe. With our method, we are able to effectively learn while being energetically efficient compared with state-of-the-art active learning methods. Our approach accomplishes such tasks in a single execution of the robotic system, i.e., the robot does not need human intervention to reset it. Future work will consider multiagent robotic systems that actively learn and explore in a team of collaborative robots.",https://ieeexplore.ieee.org/document/9312988/,IEEE Transactions on Automation Science and Engineering,July 2021,ieeexplore
10.1109/OJCS.2020.3001839,An Instrument for Remote Kissing and Engineering Measurement of Its Communication Effects Including Modified Turing Test,IEEE,Journals,"Various communication systems have been developed to integrate the haptic channel in digital communication. Future directions of such haptic technologies are moving towards realistic virtual reality applications and human-robot social interaction. With the digitisation of touch, robots equipped with touch sensors and actuators can communicate with humans on a more emotional and intimate level, such as sharing a hug or kiss just like humans do. This paper presents the design guideline, implementation and evaluations of a novel haptic kissing machine for smart phones - the Kissenger machine. The key novelties and contributions of the paper are: (i) A novel haptic kissing device for mobile phones, which uses dynamic perpendicular force stimulation to transmit realistic sensations of kissing in order to enhance intimacy and emotional connection of digital communication; (ii) Extensive evaluations of the Kissenger machine, including a lab experiment that compares mediated kissing with Kissenger to real kissing, a unique haptic Turing test that involves the first academic study of human-machine kiss, and a field study of the effects of Kissenger on long distance relationships. The first experiment showed that mediated kissing with Kissenger elicited similar ratings for pleasure, arousal and user experience as real kissing. Experiment 2 confirmed our hypothesis that interrogators have a higher chance of winning the Imitation Game (Turing test) when Kissenger is used during the game. Results from experiment 3 showed that long relationship couples who used Kissenger for a week experienced increased relationship satisfaction and decreased perceived stress.",https://ieeexplore.ieee.org/document/9119758/,IEEE Open Journal of the Computer Society,2020,ieeexplore
10.1109/TIE.2020.2979561,An Intelligent Non-Integer PID Controller-Based Deep Reinforcement Learning: Implementation and Experimental Results,IEEE,Journals,"In this article, a noninteger proportional integral derivative (PID)-type controller based on the deep deterministic policy gradient algorithm is developed for the tracking problem of a mobile robot. This robot system is a typical case of nonholonomic plants and is exposed to the measurement noises and external disturbances. To accomplish the control methodology, two control mechanisms are established independently: a kinematic controller (which is designed based on the kinematic model of the vehicle), and a dynamic controller (which is realized according to the physical specifications of the vehicle dynamics). In particular, an optimal noninteger PID controller is initially designed as the primary dynamic controller for the tracking problem of a nonholonomic wheeled mobile robot. Then, a DDPG algorithm with the actor-critic framework is established for the supplementary dynamic controller, which is beneficial to the tracking stabilization by adapting to the uncertainties and disturbances. This strategy implements the supplementary based control to compensate for what the original controller is unable to handle. A prototype of the WMR was also adopted to investigate the applicability of the suggested controller from a real-time platform perspective. The outcomes in experimental environments are presented to affirm the effectiveness of the suggested control methodology.",https://ieeexplore.ieee.org/document/9042812/,IEEE Transactions on Industrial Electronics,April 2021,ieeexplore
10.1109/JTEHM.2018.2822681,An IoT-Enabled Stroke Rehabilitation System Based on Smart Wearable Armband and Machine Learning,IEEE,Journals,"Surface electromyography signal plays an important role in hand function recovery training. In this paper, an IoT-enabled stroke rehabilitation system was introduced which was based on a smart wearable armband (SWA), machine learning (ML) algorithms, and a 3-D printed dexterous robot hand. User comfort is one of the key issues which should be addressed for wearable devices. The SWA was developed by integrating a low-power and tiny-sized IoT sensing device with textile electrodes, which can measure, pre-process, and wirelessly transmit bio-potential signals. By evenly distributing surface electrodes over user's forearm, drawbacks of classification accuracy poor performance can be mitigated. A new method was put forward to find the optimal feature set. ML algorithms were leveraged to analyze and discriminate features of different hand movements, and their performances were appraised by classification complexity estimating algorithms and principal components analysis. According to the verification results, all nine gestures can be successfully identified with an average accuracy up to 96.20%. In addition, a 3-D printed five-finger robot hand was implemented for hand rehabilitation training purpose. Correspondingly, user's hand movement intentions were extracted and converted into a series of commands which were used to drive motors assembled inside the dexterous robot hand. As a result, the dexterous robot hand can mimic the user's gesture in a real-time manner, which shows the proposed system can be used as a training tool to facilitate rehabilitation process for the patients after stroke.",https://ieeexplore.ieee.org/document/8356006/,IEEE Journal of Translational Engineering in Health and Medicine,2018,ieeexplore
10.1109/21.3461,An approach to an expert robot welding system,IEEE,Journals,"Adaptive control and sensory processing techniques in robotic arc welding are discussed. The gas metal arc welding and gas tungsten arc welding processes are considered, along with a literature review of aspects of welding automation. Topics covered include process modeling, detection and measurement of process features, real-time control, and implementation considerations. An approach for an adaptive welding system is presented. The proposed architecture fits within the scope of an ambitious project to develop an expert welding robot. Different levels of automation are discussed, from the decision level to the closed-loop control of process variables and torch trajectory.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/3461/,"IEEE Transactions on Systems, Man, and Cybernetics",March-April 1988,ieeexplore
10.1109/70.68083,An automatic navigation system for vision guided vehicles using a double heuristic and a finite state machine,IEEE,Journals,"A navigation system for automatic vision-guided vehicles which uses an efficient double heuristic search algorithm for path planning is presented. It is capable of avoiding unknown obstacles and recovering from unidentifiable locations. A linked list representation of the path network database makes the implementation feasible in any high-level language and renders it suitable for real-time application. Extensive simulated experiments have been conducted to verify the validity of the proposed algorithms. The combination of the techniques of robot navigation in unexplored terrain and the global map method proved to be a valid technique for automated guided vehicle (AGV) guidance. A learning mechanism is used in the AGV by updating the path network during navigation. Simulated results supported all the theoretically expected conclusions, since the robot planned its path correctly between the requested nodes and maneuvered its way around the obstacles. Overall, the results were very encouraging.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/68083/,IEEE Transactions on Robotics and Automation,Feb. 1991,ieeexplore
10.1109/ACCESS.2019.2958092,Automatic Elevator Button Localization Using a Combined Detecting and Tracking Framework for Multi-Story Navigation,IEEE,Journals,"Simultaneous localization and mapping (SLAM) is an important function for service robots to self-navigate modernized buildings. However, only a few existing applications allow them to automatically move between stories through elevator. Some approaches have accomplished with the aid of hardware; however, this study shows that computer vision can be a promising alternative for button localization. In this paper, we proposed a real-time multi-story SLAM system which overcomes the problem of detecting elevator buttons using a localization framework that combines tracking and detecting approaches. A two-stage deep neural network initially locates the original positions of the target buttons, and a part-based tracker follows the target buttons in real-time. A positive-negative classifier and deep learning neural network (particular for button shape detection) modify the tracker's output in every frame. To allow the robot to self-navigate, a 2D grid mapping approach was used for the localization and mapping. Then, when the robot navigates a floor, the A* algorithm generates the shortest path. In the experiment, two dynamic scenes (which include common elevator button localization challenges) were used to evaluate the efficiency of our approach, and compared it with other state-of-the-art methods. Our approach was also tested on a prototype robot system to assesses how well it can navigate a multi-story building. The results show that our method could overcome the common background challenges that occur inside an elevator, and in doing so, it enables the mobile robot to autonomously navigate a multi-story building.",https://ieeexplore.ieee.org/document/8926334/,IEEE Access,2020,ieeexplore
10.1109/TFUZZ.2004.832532,Automatic design of fuzzy controllers for car-like autonomous robots,IEEE,Journals,"This paper describes the design and implementation of a fuzzy control system for a car-like autonomous vehicle. The problem addressed is the diagonal parking in a constrained space, a typical problem in motion control of nonholonomic robots. The architecture proposed for the fuzzy controller is a hierarchical scheme which combines seven modules working in series and in parallel. The rules of each module employ the adequate fuzzy operators for its task (making a decision or generating a smoothly varying control output), and they have been obtained from heuristic knowledge and numerical data (with geometric information) depending on the module requirements (some of them are constrained to provide paths of near-minimal lengths). The computer-aided design tools of the environment Xfuzzy 3.0 (developed by some of the authors) have been employed to automate the different design stages: 1) translation of heuristic knowledge into fuzzy rules; 2) extraction of fuzzy rules from numerical data and their tuning to give paths of near-minimal lengths; 3) offline verification of the control system behavior; and 4) its synthesis to be implemented in a true robot and be verified on line. Real experiments with the autonomous vehicle ROMEO 4R (designed and built at the Escuela Superior de Ingenieros, University of Seville, Seville, Spain) demonstrate the efficiency of the described controller and of the methodology followed in its design.",https://ieeexplore.ieee.org/document/1321074/,IEEE Transactions on Fuzzy Systems,Aug. 2004,ieeexplore
10.1109/ACCESS.2021.3079427,Autonomous Endoscope Robot Positioning Using Instrument Segmentation With Virtual Reality Visualization,IEEE,Journals,"This paper presents a method for endoscope's autonomous positioning by a robotic endoscope holder for minimally invasive surgery. The method improves human-robot cooperation in robot-assisted surgery by allowing the endoscope holder to acknowledge the surgeon's view projection and navigate the camera without manual control. The real-time prediction of next desired camera location is estimated using segmented instrument's tip locations from endoscope video and surgeon's attention focus given by tracked virtual reality headset. To tackle the issue of real-time surgical instrument segmentation for more precise instrument tip localization, we propose the YOLOv3 and ResNet Combined Neural Network. The method showed an 86.6% IoU across MICCAI'17 Endovis datasets with 30 frames per second processing speed. The proposed pipeline was implemented in ROS on Ubuntu with visualization running under Windows operating system in Unity3D. The simulation demonstrates the robotic arm, endoscope, and surgical environment visualized in 3D in the virtual reality headset to provide a stable view of the endoscope and improve the surgeon's perception of the operating environment.",https://ieeexplore.ieee.org/document/9429186/,IEEE Access,2021,ieeexplore
10.1109/TSMCA.2003.811766,Autonomous fuzzy parking control of a car-like mobile robot,IEEE,Journals,"This paper is devoted to design and implement a car-like mobile robot (CLMR) that possesses autonomous garage-parking and parallel-parking capability by using real-time image processing. For fuzzy garage-parking control (FGPC) and fuzzy parallel-parking control (FPPC), feasible reference trajectories are provided for the fuzzy logic controller to maneuver the steering angle of the CLMR. We propose two FGPC methods and two FPPC methods to back-drive or head-in the CLMR to the garage and the parking lot, respectively. Simulation results illustrate the effectiveness of the developed schemes. The overall experimental setup of the parking system developed in this paper is composed of a host computer, a communication module, a CLMR, and a vision system. Finally, the image-based real-time implementation experiments of the CLMR demonstrate the feasibility and effectiveness of the proposed schemes.",https://ieeexplore.ieee.org/document/1235979/,"IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans",July 2003,ieeexplore
10.1109/TSMCB.2004.843270,Autonomous stair-climbing with miniature jumping robots,IEEE,Journals,"The problem of vision-guided control of miniature mobile robots is investigated. Untethered mobile robots with small physical dimensions of around 10 cm or less do not permit powerful onboard computers because of size and power constraints. These challenges have, in the past, reduced the functionality of such devices to that of a complex remote control vehicle with fancy sensors. With the help of a computationally more powerful entity such as a larger companion robot, the control loop can be closed. Using the miniature robot's video transmission or that of an observer to localize it in the world, control commands can be computed and relayed to the inept robot. The result is a system that exhibits autonomous capabilities. The framework presented here solves the problem of climbing stairs with the miniature Scout robot. The robot's unique locomotion mode, the jump, is employed to hop one step at a time. Methods for externally tracking the Scout are developed. A large number of real-world experiments are conducted and the results discussed.",https://ieeexplore.ieee.org/document/1408060/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",April 2005,ieeexplore
10.1109/ACCESS.2021.3093340,Ball Motion Control in the Table Tennis Robot System Using Time-Series Deep Reinforcement Learning,IEEE,Journals,"One of the biggest challenges hindering a table tennis robot to play as well as a professional player is the ball’s accurate motion control, which depends on various factors such as the incoming ball’s position, linear, spin velocity and so forth. Unfortunately, some factors are almost impossible to be directly measured in real practice, such as the ball’s spin velocity, which is difficult to be estimated from vision due to the little texture on the ball’s surface. To perform accurate motion control in table tennis, this study proposes to learn a ball stroke strategy to guarantee desirable “target landing location” and the “over-net height” which are two key indicators to evaluate the quality of a stroke. To overcome the spin velocity challenge, a deep reinforcement learning (DRL) based stroke approach is developed with the spin velocity estimation capability, through which the system can predict the relative spin velocity of the ball and stroke it back accurately by iteratively learning from the robot-environment interactions. To pre-train the DRL-based strategy effectively, this paper develops a virtual table tennis playing environment, through which various simulated data can be collected. For the real table tennis robot implementation, experimental results demonstrate the superior performance of the proposed control strategy compared to that of the traditional aerodynamics-based method with an average landing error around 80mm and the landing-within-table probability higher than 70%.",https://ieeexplore.ieee.org/document/9467347/,IEEE Access,2021,ieeexplore
10.1109/LRA.2017.2737046,Baxter's Homunculus: Virtual Reality Spaces for Teleoperation in Manufacturing,IEEE,Journals,"We demonstrate a low-cost telerobotic system that leverages commercial virtual reality (VR) technology and integrates it with existing robotics control infrastructure. The system runs on a commercial gaming engine using off-the-shelf VR hardware and can be deployed on multiple network architectures. The system is based on the homunculus model of mind wherein we embed the user in a VR control room. The control room allows for multiple sensor displays, and dynamic mapping between the user and robot. This dynamic mapping allows for selective engagement between the user and the robot. We compared our system with state-of-the-art automation algorithms and standard VR-based telepresence systems by performing a user study. The study showed that new users were faster and more accurate than the automation or a direct telepresence system. We also demonstrate that our system can be used for pick and place, assembly, and manufacturing tasks.",https://ieeexplore.ieee.org/document/8003431/,IEEE Robotics and Automation Letters,Jan. 2018,ieeexplore
10.1109/LRA.2021.3111416,Binarized P-Network: Deep Reinforcement Learning of Robot Control from Raw Images on FPGA,IEEE,Journals,"This letter explores a deep reinforcement learning (DRL) approach for designing image-based control for edge robots to be implemented on Field Programmable Gate Arrays (FPGAs). Although FPGAs are more power-efficient than CPUs and GPUs, a typical DRL method cannot be applied since they are composed of many Logic Blocks (LBs) for high-speed logical operations but low-speed real-number operations. To cope with this problem, we propose a novel DRL algorithm called Binarized P-Network (BPN), which learns image-input control policies using Binarized Convolutional Neural Networks (BCNNs). To alleviate the instability of reinforcement learning caused by a BCNN with low function approximation accuracy, our BPN adopts a robust value update scheme called Conservative Value Iteration, which is tolerant of function approximation errors. We confirmed the BPN's effectiveness through applications to a visual tracking task in simulation and real-robot experiments with FPGA.",https://ieeexplore.ieee.org/document/9534708/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/TSMCB.2009.2018138,Cerebellar-Inspired Adaptive Control of a Robot Eye Actuated by Pneumatic Artificial Muscles,IEEE,Journals,"In this paper, a model of cerebellar function is implemented and evaluated in the control of a robot eye actuated by pneumatic artificial muscles. The investigated control problem is stabilization of the visual image in response to disturbances. This is analogous to the vestibuloocular reflex (VOR) in humans. The cerebellar model is structurally based on the adaptive filter, and the learning rule is computationally analogous to least-mean squares, where parameter adaptation at the parallel fiber/Purkinje cell synapse is driven by the correlation of the sensory error signal (carried by the climbing fiber) and the motor command signal. Convergence of the algorithm is first analyzed in simulation on a model of the robot and then tested online in both one and two degrees of freedom. The results show that this model of neural function successfully works on a real-world problem, providing empirical evidence for validating: 1) the generic cerebellar learning algorithm; 2) the function of the cerebellum in the VOR; and 3) the signal transmission between functional neural components of the VOR.",https://ieeexplore.ieee.org/document/4814555/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",Dec. 2009,ieeexplore
10.1109/ACCESS.2018.2845855,Color Transfer Pulse-Coupled Neural Networks for Underwater Robotic Visual Systems,IEEE,Journals,"With rapid developments in cloud computing, artificial intelligence, and robotic systems, ever more complex tasks, such as space and ocean exploration, are being implemented by intelligent robots. Here, we propose an underwater image enhancement scheme for robotic visual systems. The proposed algorithm and its implementation enhances and outputs an image captured by an underwater robot in real time. In this scheme, pulse-coupled neural network (PCNN)-based image enhancement and color transfer algorithms are combined to enhance the underwater image. To avoid color imbalance in the underwater image and enhance details while suppressing noise, color correction is first carried out on the underwater image before converting it into the hue-saturation-intensity domain and enhancing it by PCNN. The enhanced result improves the color and contrast of the source image and enhances the details and edges of darker regions. Experiments are performed on real world data to demonstrate the effectiveness of the proposed scheme.",https://ieeexplore.ieee.org/document/8377996/,IEEE Access,2018,ieeexplore
10.1109/TII.2020.2991764,Continuous Image Generation From Low-Update-Rate Images and Physical Sensors Through a Conditional GAN for Robot Teleoperation,IEEE,Journals,"When a robot is teleoperated, its operator control is based on transmitted images. Network limitations and/or a remote distance usually cause delays or interruptions of the image transmission, which is one of the reasons for the instability of teleoperation systems. In this article, we propose a high-update-rate image generation method using past low update image and current grip position and electrical motor current of gripper received by sensors during teleoperation via a conditional generative adversarial network. The main challenge is that such a network can generate current high-update-rate images from past low-update-rate one, the current high-update-rate grip force, and the grip angle. We equipped a robot gripper with a camera and a grip force sensor and collected a large data set of robot vision, grip force, and grip angle sequences; objects with deformation, including irregular deformation, and rigid objects were tested in the experiment to verify the possibility of high-update-rate image generation under various grip conditions. We found that the proposed network allows the generation of current images with high update rate.",https://ieeexplore.ieee.org/document/9084292/,IEEE Transactions on Industrial Informatics,March 2021,ieeexplore
10.1109/TSMCB.2006.874131,Control Architecture for Human–Robot Integration: Application to a Robotic Wheelchair,IEEE,Journals,"Completely autonomous performance of a mobile robot within noncontrolled and dynamic environments is not possible yet due to different reasons including environment uncertainty, sensor/software robustness, limited robotic abilities, etc. But in assistant applications in which a human is always present, she/he can make up for the lack of robot autonomy by helping it when needed. In this paper, the authors propose human-robot integration as a mechanism to augment/improve the robot autonomy in daily scenarios. Through the human-robot-integration concept, the authors take a further step in the typical human-robot relation, since they consider her/him as a constituent part of the human-robot system, which takes full advantage of the sum of their abilities. In order to materialize this human integration into the system, they present a control architecture, called architecture for human-robot integration, which enables her/him from a high decisional level, i.e., deliberating a plan, to a physical low level, i.e., opening a door. The presented control architecture has been implemented to test the human-robot integration on a real robotic application. In particular, several real experiences have been conducted on a robotic wheelchair aimed to provide mobility to elderly people",https://ieeexplore.ieee.org/document/1703648/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",Oct. 2006,ieeexplore
10.1109/TIE.2015.2425359,Coordination of Multiple Robotic Fish With Applications to Underwater Robot Competition,IEEE,Journals,"This paper is concerned with the coordination control of multiple biomimetic robotic fish in highly dynamic aquatic environments by building a hybrid centralized system. With the aid of the results of biorobotics and control techniques, a radio-controlled multijoint robotic fish and its locomotion control are developed. To enable a closed control loop, a visual subsystem that is responsible for tracking of multiple moving objects is constructed and implemented in real time. Furthermore, a behavior-based hierarchical architecture in conjunction with fuzzy reinforcement learning is proposed to accomplish effective coordination among multiple swimming robots. Finally, experiments on 2vs2 water polo game are carried out to verify the proposed coordination control scheme. Over the past eight years, this multirobot platform has been successfully applied to international underwater robot competitions to promote innovative research and education in underwater robotics.",https://ieeexplore.ieee.org/document/7091905/,IEEE Transactions on Industrial Electronics,Feb. 2016,ieeexplore
10.1109/ACCESS.2020.3016893,Coping With Multiple Visual Motion Cues Under Extremely Constrained Computation Power of Micro Autonomous Robots,IEEE,Journals,"The perception of different visual motion cues is crucial for autonomous mobile robots to react to or interact with the dynamic visual world. It is still a great challenge for a micro mobile robot to cope with dynamic environments due to the restricted computational resources and the limited functionalities of its visual systems. In this study, we propose a compound visual neural system to automatically extract and fuse different visual motion cues in real-time using the extremely constrained computation power of micro mobile robots. The proposed visual system contains multiple bio-inspired visual motion perceptive neurons each with a unique role, for example to extract collision visual cues, darker collision cue and directional motion cues. In the embedded system, these multiple visual neurons share a similar presynaptic network to minimise the consumption of computation resources. In the postsynaptic part of the system, visual cues pass results to corresponding action neurons using lateral inhibition mechanism. The translational motion cues, which are identified by comparing pairs of directional cues, are given the highest priority, followed by the darker colliding cues and approaching cues. Systematic experiments with both virtual visual stimuli and real-world scenarios have been carried out to validate the system's functionality and reliability. The proposed methods have demonstrated that (1) with extremely limited computation power, it is still possible for a micro mobile robot to extract multiple visual motion cues robustly in a complex dynamic environment; (2) the cues extracted can be fused with a lateral inhibited postsynaptic network, thus enabling the micro robots to respond effectively with different actions, accordingly to different states, in real-time. The proposed embedded visual system has been modularised and can be easily implemented in other autonomous mobile platforms for real-time applications. The system could also be used by neurophysiologists to test new hypotheses pertaining to biological visual neural systems.",https://ieeexplore.ieee.org/document/9167216/,IEEE Access,2020,ieeexplore
10.1109/LRA.2020.3004325,Cross-View Semantic Segmentation for Sensing Surroundings,IEEE,Journals,"Sensing surroundings plays a crucial role in human spatial perception, as it extracts the spatial configuration of objects as well as the free space from the observations. To facilitate the robot perception with such a surrounding sensing capability, we introduce a novel visual task called Cross-view Semantic Segmentation as well as a framework named View Parsing Network (VPN) to address it. In the cross-view semantic segmentation task, the agent is trained to parse the first-view observations into a top-down-view semantic map indicating the spatial location of all the objects at pixel-level. The main issue of this task is that we lack the real-world annotations of top-down-view data. To mitigate this, we train the VPN in 3D graphics environment and utilize the domain adaptation technique to transfer it to handle real-world data. We evaluate our VPN on both synthetic and real-world agents. The experimental results show that our model can effectively make use of the information from different views and multi-modalities to understanding spatial information. Our further experiment on a LoCoBot robot shows that our model enables the surrounding sensing capability from 2D image input. Code and demo videos can be found at https://view-parsing-network.github.io.",https://ieeexplore.ieee.org/document/9123682/,IEEE Robotics and Automation Letters,July 2020,ieeexplore
10.1109/ACCESS.2021.3065105,Deep Neural Network–Based Double-Check Method for Fall Detection Using IMU-L Sensor and RGB Camera Data,IEEE,Journals,"Existing methods for fall detection may not detect a fall when it occurs or may generate a false alarm when a fall does not occur. In order to overcome these limitations and detect falls with 100% accuracy, a double-check method for fall detection in elderly people via an inertial measurement unit-location (IMU-L) sensor and a red-green-blue (RGB) camera is proposed. The IMU-L sensor is a combination of an IMU sensor (accelerometer and gyroscope) and an ultrawideband signal-based location sensor; the RGB sensor is mounted on a robot. The proposed method involves detecting and confirming the fall of an elderly individual via the IMU-L sensor and an RGB image, respectively. The IMU-L sensor is worn on the body to detect falls. When a potential fall occurs, the individual's location information is synchronized with the motion data. During detection, because of the sequential nature of IMU data, a deep learning technique called a recurrent neural network (RNN) is trained to classify falls. When the IMU indicates a suspected fall situation, the robot moves to the corresponding location and confirms whether a fall has occurred. During the confirmation stage, a convolutional neural network-based technique is applied to the RGB image data to recognize and confirm the fall. Repeated confirmed fall detections using this method classified falls more accurately than existing methods that use only an IMU sensor. We conducted a real-time experiment to validate our method using a dataset developed in a laboratory and achieved 100% accuracy in our experimental environment.",https://ieeexplore.ieee.org/document/9374404/,IEEE Access,2021,ieeexplore
10.1109/LRA.2020.3003256,Denoising IMU Gyroscopes With Deep Learning for Open-Loop Attitude Estimation,IEEE,Journals,"This article proposes a learning method for denoising gyroscopes of Inertial Measurement Units (IMUs) using ground truth data, and estimating in real time the orientation (attitude) of a robot in dead reckoning. The obtained algorithm outperforms the state-of-the-art on the (unseen) test sequences. The obtained performances are achieved, thanks to a well-chosen model, a proper loss function for orientation increments, and through the identification of key points when training with high-frequency inertial data. Our approach builds upon a neural network based on dilated convolutions, without requiring any recurrent neural network. We demonstrate how efficient our strategy is for 3D attitude estimation on the EuRoC and TUM-VI datasets. Interestingly, we observe our dead reckoning algorithm manages to beat top-ranked visual-inertial odometry systems in terms of attitude estimation although it does not use vision sensors. We believe this article offers new perspectives for visual-inertial localization and constitutes a step toward more efficient learning methods involving IMUs. Our open-source implementation is available at https://github.com/mbrossar/denoise-imu-gyro.",https://ieeexplore.ieee.org/document/9119813/,IEEE Robotics and Automation Letters,July 2020,ieeexplore
10.1109/TASE.2020.2978881,Depth Estimation of Hard Inclusions in Soft Tissue by Autonomous Robotic Palpation Using Deep Recurrent Neural Network,IEEE,Journals,"Accurately detecting tumors and estimating the depth of tumors is essential in the surgical removal of tumors. In robotic-assisted surgery, autonomous robotic palpation has the potential to provide more precise detection, tumors' depth estimation, and less intrusion when normal tissues surround tumors. In this article, by mimicking the human finger touch, we propose a tactile sensing-based deep recurrent neural network (DRNN) with long short-term memory (LSTM) architecture to improve the accuracy of the detection and depth estimation of tumors embedded in soft tissue. In the experimental setup, the hard inclusions simulate the tumors, while the phantom tissue is fabricated by silicon to simulate the soft tissue. During the experiment, the data from the force sensor and displacement of the robot palpation probe are for detection and depth estimation purposes. The collected sequential data set of the force and the displacement of the probe during one completed palpation process will go through the proposed DRNN network with deep LSTM architecture, in which the temporal dependencies of the sequential data will be captured in the cell states in the deep LSTM layers. Subsequently, the softmax classifier is adopted to determine if there is any hard inclusion exists and offer the depth estimation of the hard inclusions. Experiments based on 396 real data sets demonstrate that the detection accuracy for the testing data set is 99.2% and the depth estimation accuracy for the testing data set is 95.8%. The accuracy of the proposed method is best when comparing with other widely used methods. Note to Practitioners-The palpation of tumors motivated this article in the robot-assisted surgical systems through tactile feedback. In order to mimic the human touch on the soft tissue, this article presents a deep-learning-based approach to estimate the depth of the hard inclusions in the phantom tissue through force information. The displacement of the palpation probe and the touch force during one palpation are recorded as data sequences to train the deep model, which aims to capture dynamics and long-term dependence of the palpation process. In this article, we made the first successful attempt to accurately estimate the depth of the hard inclusions buried at different locations of the phantom tissue using only force information. The proposed approach can work in different robot-assisted scenarios, such as master-slave robotic surgery. In the clinic applications, the force sensor will be integrated at the end-effector of the robotic manipulator. According to the specific requirements, the force sensor and the robotic manipulator might be different from those used in this article. For some applications, such as the laparoscopic interventions, the complete vertical contact tends to be difficult to obtain due to the laparoscopic port effects. The projection of the recorded force data and displacement can obtain the information in the normal direction. The future work is going to be extended to tissue environments with arbitrary surface and tumors with various shapes/depths for more complex and prospective clinical applications.",https://ieeexplore.ieee.org/document/9042819/,IEEE Transactions on Automation Science and Engineering,Oct. 2020,ieeexplore
10.1109/ACCESS.2020.3033550,Developing a Lightweight Rock-Paper-Scissors Framework for Human-Robot Collaborative Gaming,IEEE,Journals,"We present a novel implementation of a Rock-Paper-Scissors (RPS) game interaction with a social robot. The framework is tailored to be computationally lightweight, as well as entertaining and visually appealing through collaboration with designers and animators. The fundamental gesture recognition pipeline employs a Leap motion device and two separate machine learning architectures to evaluate kinematic hand data on-the-fly. The first architecture is used to recognize and segment human motion activity in order to initialize the RPS play, and the second architecture is used to classify hand gestures into rock, paper or scissors. The employed tabletop robot interacts in the RPS play through unique animated gestural movements and vocalizations designed by animators which communicate the robot's choices as well as cognitive reflection on winning, losing and draw states. Performance of both learning architectures is carefully evaluated with respect to accuracy, reliability and run time performance under different feature and classifier types. Moreover, we assess our system during an interactive RPS play between robot and human. Experimental results show that the proposed system is robust to user variations and play style in real environment conditions. As such, it offers a powerful application for the subsequent exploration of social human-machine interaction.",https://ieeexplore.ieee.org/document/9239276/,IEEE Access,2020,ieeexplore
10.1109/3516.537045,Development and integration of generic components for a teachable vision-based mobile robot,IEEE,Journals,"This paper presents a mobile robotic system for human assistance in navigation-the robot navigates by receiving visual instructions from a human being and is able to replicate them autonomously. We describe three generic components defined as the HOST, the VISION, and the CONTROL components as well as their integration in our teachable mobile robot. These components are connected to each other via a transputer serial link, namely they are loosely coupled, they work in parallel and are asynchronous with each other. Each component is described with a peculiar feature of extensibility. Especially in the VISION component, there are two major features. The first one is a correlator which each vision board possesses. The correlator does block-matching between the template and the grabbed images in real-time. The other is the PIM library which manages the visual tasks over limited parallel visual resources of the mobile robot. These features of our design enable the system to be real-time and allow for efficient and extensible software development. In order to show the feasibility of our system design, we present a preliminary experiment of the route teaching on our mobile robot.",https://ieeexplore.ieee.org/document/537045/,IEEE/ASME Transactions on Mechatronics,Sept. 1996,ieeexplore
10.1109/TMECH.2013.2294180,Development of a Laser-Range-Finder-Based Human Tracking and Control Algorithm for a Marathoner Service Robot,IEEE,Journals,"This paper presents a human detection algorithm and an obstacle avoidance algorithm for a marathoner service robot (MSR) that provides a service to a marathoner while training. To be used as a MSR, the mobile robot should have the abilities to follow a running human and avoid dynamically moving obstacles in an unstructured outdoor environment. To detect a human by a laser range finder (LRF), we defined features of the human body in LRF data and employed a support vector data description method. In order to avoid moving obstacles while tracking a running person, we defined a weighted radius for each obstacle using the relative velocity between the robot and an obstacle. For smoothly bypassing obstacles without collision, a dynamic obstacle avoidance algorithm for the MSR is implemented, which directly employed a real-time position vector between the robot and the shortest path around the obstacle. We verified the feasibility of these proposed algorithms through experimentation in different outdoor environments.",https://ieeexplore.ieee.org/document/6690173/,IEEE/ASME Transactions on Mechatronics,Dec. 2014,ieeexplore
10.1109/TSMCB.2004.831151,Development of a biomimetic robotic fish and its control algorithm,IEEE,Journals,"This paper is concerned with the design of a robotic fish and its motion control algorithms. A radio-controlled, four-link biomimetic robotic fish is developed using a flexible posterior body and an oscillating foil as a propeller. The swimming speed of the robotic fish is adjusted by modulating joint's oscillating frequency, and its orientation is tuned by different joint's deflections. Since the motion control of a robotic fish involves both hydrodynamics of the fluid environment and dynamics of the robot, it is very difficult to establish a precise mathematical model employing purely analytical methods. Therefore, the fish's motion control task is decomposed into two control systems. The online speed control implements a hybrid control strategy and a proportional-integral-derivative (PID) control algorithm. The orientation control system is based on a fuzzy logic controller. In our experiments, a point-to-point (PTP) control algorithm is implemented and an overhead vision system is adopted to provide real-time visual feedback. The experimental results confirm the effectiveness of the proposed algorithms.",https://ieeexplore.ieee.org/document/1315762/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",Aug. 2004,ieeexplore
10.1109/56.802,Dynamic multi-sensor data fusion system for intelligent robots,IEEE,Journals,"The objective of the authors is to develop an intelligent robot workstation capable of integrating data from multiple sensors. The investigation is based on a Unimation PUMA 560 robot and various external sensors. These include overhead vision, eye-in-hand vision, proximity, tactile array, position, force/torque, cross-fire, overload, and slip-sensing devices. The efficient fusion of data from different sources will enable the machine to respond promptly in dealing with the 'real world'. Towards this goal, the general paradigm of a sensor data fusion system has been developed, and some simulation results, as well as results from the actual implementation of certain concepts of sensor data fusion, have been demonstrated.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/802/,IEEE Journal on Robotics and Automation,Aug. 1988,ieeexplore
10.1109/TSMCA.2012.2210408,Emotional State Classification in Patient–Robot Interaction Using Wavelet Analysis and Statistics-Based Feature Selection,IEEE,Journals,"Due to a major shortage of nurses in the U.S., future healthcare service robots are expected to be used in tasks involving direct interaction with patients. Consequently, there is a need to design nursing robots with the capability to detect and respond to patient emotional states and to facilitate positive experiences in healthcare. The objective of this study was to develop a new computational algorithm for accurate patient emotional state classification in interaction with nursing robots during medical service. A simulated medicine delivery experiment was conducted at two nursing homes using a robot with different human-like features. Physiological signals, including heart rate (HR) and galvanic skin response (GSR), as well as subjective ratings of valence (happy-unhappy) and arousal (excited-bored) were collected on elderly residents. A three-stage emotional state classification algorithm was applied to these data, including: (1) physiological feature extraction; (2) statistical-based feature selection; and (3) a machine-learning model of emotional states. A pre-processed HR signal was used. GSR signals were nonstationary and noisy and were further processed using wavelet analysis. A set of wavelet coefficients, representing GSR features, was used as a basis for current emotional state classification. Arousal and valence were significantly explained by statistical features of the HR signal and GSR wavelet features. Wavelet-based de-noising of GSR signals led to an increase in the percentage of correct classifications of emotional states and clearer relationships among the physiological response and arousal and valence. The new algorithm may serve as an effective method for future service robot real-time detection of patient emotional states and behavior adaptation to promote positive healthcare experiences.",https://ieeexplore.ieee.org/document/6301777/,IEEE Transactions on Human-Machine Systems,Jan. 2013,ieeexplore
10.1109/TPAMI.2019.2899570,End-to-End Active Object Tracking and Its Real-World Deployment via Reinforcement Learning,IEEE,Journals,"We study active object tracking, where a tracker takes visual observations (i.e., frame sequences) as input and produces the corresponding camera control signals as output (e.g., move forward, turn left, etc.). Conventional methods tackle tracking and camera control tasks separately, and the resulting system is difficult to tune jointly. These methods also require significant human efforts for image labeling and expensive trial-and-error system tuning in the real world. To address these issues, we propose, in this paper, an end-to-end solution via deep reinforcement learning. A ConvNet-LSTM function approximator is adopted for the direct frame-to-action prediction. We further propose an environment augmentation technique and a customized reward function, which are crucial for successful training. The tracker trained in simulators (ViZDoom and Unreal Engine) demonstrates good generalization behaviors in the case of unseen object moving paths, unseen object appearances, unseen backgrounds, and distracting objects. The system is robust and can restore tracking after occasional lost of the target being tracked. We also find that the tracking ability, obtained solely from simulators, can potentially transfer to real-world scenarios. We demonstrate successful examples of such transfer, via experiments over the VOT dataset and the deployment of a real-world robot using the proposed active tracker trained in simulation.",https://ieeexplore.ieee.org/document/8642452/,IEEE Transactions on Pattern Analysis and Machine Intelligence,1 June 2020,ieeexplore
10.1109/70.650165,Environment prediction for a mobile robot in a dynamic environment,IEEE,Journals,"The problem of navigating a mobile robot among moving obstacles is usually solved on the condition of knowing the velocity of obstacles. However, it is difficult to provide such information to a robot in real time. In this paper, we present an environment predictor that provides an estimate of future environment configuration by fusing multisensor data in real time. The predictor is implemented by an artificial neural network (ANN) trained using a relative-error-backpropagation (REBP) algorithm. The REBP algorithm enables the ANN to provide output data with a minimum relative error, which is better than conventional backpropagation (BP) algorithms in this prediction application. The mobile robot can, therefore, respond to anticipated changes in the environment. The performance is verified by prediction simulation and navigation experiments.",https://ieeexplore.ieee.org/document/650165/,IEEE Transactions on Robotics and Automation,Dec. 1997,ieeexplore
10.1109/3477.499791,Evolution of homing navigation in a real mobile robot,IEEE,Journals,In this paper we describe the evolution of a discrete-time recurrent neural network to control a real mobile robot. In all our experiments the evolutionary procedure is carried out entirely on the physical robot without human intervention. We show that the autonomous development of a set of behaviors for locating a battery charger and periodically returning to it can be achieved by lifting constraints in the design of the robot/environment interactions that were employed in a preliminary experiment. The emergent homing behavior is based on the autonomous development of an internal neural topographic map (which is not pre-designed) that allows the robot to choose the appropriate trajectory as function of location and remaining energy.,https://ieeexplore.ieee.org/document/499791/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",June 1996,ieeexplore
10.1109/TRO.2019.2929015,Fault Detection in a Swarm of Physical Robots Based on Behavioral Outlier Detection,IEEE,Journals,"The ability to reliably detect faults is essential in many real-world tasks that robot swarms have the potential to perform. Most studies on fault detection in swarm robotics have been conducted exclusively in simulation, and they have focused on a single type of fault or a specific task. In a series of previous studies, we have developed a robust fault-detection approach in which robots in a swarm learn to distinguish between normal and faulty behaviors online. In this paper, we assess the performance of our fault-detection approach on a swarm of seven physical mobile robots. We experiment with three classic swarm robotics tasks and consider several types of faults in both sensors and actuators. Experimental results show that the robots are able to reliably detect the presence of hardware faults in one another even when the swarm behavior is changed during operation. This paper is thus an important step toward making robot swarms sufficiently reliable and dependable for real-world applications.",https://ieeexplore.ieee.org/document/8787875/,IEEE Transactions on Robotics,Dec. 2019,ieeexplore
10.1109/TIM.2021.3089240,Fault Diagnosis of Harmonic Drive With Imbalanced Data Using Generative Adversarial Network,IEEE,Journals,"Harmonic drive is the core component of the industrial robot, and its fault diagnosis is crucial to the reliability and performance of the equipment. Most machine learning methods achieve good results based on the assumption of data balance. However, the scarce fault data of harmonic drive is difficult to collect, resulting in various imbalanced health status samples, which has an adverse effect on fault diagnosis. In this article, we propose a data generation method based on generative adversarial networks (GANs) to solve the problem of data imbalance and utilize the multiscale convolutional neural network (MSCNN) to realize the fault diagnosis of the harmonic drive. First, the data collected from three vibration acceleration sensors are preprocessed by fast Fourier transform (FFT) to obtain the frequency spectrum of the vibration signal. Second, multiple GANs were adopted to generate various fault spectrum data and the data selection module (DSM) is elaborately designed to filter and purify these data. Third, the filtered generated data will be combined with the real data to form a balanced dataset, and then the MSCNN is used to achieve multiclassification of the health status of the harmonic drive. Finally, the experiments have been implemented on an industrial robot vibration test bench to validate the effectiveness of our approach. The results have shown the fault multiclassification accuracy as 98.49% under imbalanced fault data conditions, which outperforms that of the other compared methods.",https://ieeexplore.ieee.org/document/9454583/,IEEE Transactions on Instrumentation and Measurement,2021,ieeexplore
10.1109/LRA.2021.3096192,Formulation and Validation of an Intuitive Quality Measure for Antipodal Grasp Pose Evaluation,IEEE,Journals,"This letter describes a novel grasp quality measure that we developed for evaluating antipodal grasp poses in real-time. To quantify the grasp quality, we compute a set of object movement features from analyzing the interaction between the gripper and the object's projections in the image space. The normalization and weights of the features are tuned to make practical and intuitive grasp quality predictions. To evaluate our grasp quality measure, we conducted a real robot grasping experiment with 1000 robot grasp trials on 10 household objects to examine the relationship between our grasp scores and the actual robot grasping results. The results show that the average grasp success rate increases, and the average amount of undesired object movement decreases as the calculated grasp score increases. We achieved a 100% grasp success rate from 100 grasps of the 10 objects when using our grasp quality measure in planning top quality grasps. In addition, we compared our quality measure with the Q measure and deep learning-based quality measures.",https://ieeexplore.ieee.org/document/9483652/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/TCST.2017.2756962,Full-State Tracking Control for Flexible Joint Robots With Singular Perturbation Techniques,IEEE,Journals,"This paper proposes a practical method to realize multivariable full-state tracking control for industrial robots with elastic joints. Unlike existing methods, the proposed method does not require high-order derivatives of the link states such as acceleration and jerk. Therefore, the proposed method does not suffer from chatter related to inaccurate estimation of high-order derivatives. The method is derived by adopting a singular perturbation technique. A decoupled error dynamics is achieved by two decoupling control loops: a fast loop that controls the deflection error and a slow loop for tracking control on the link side. Our stability analysis based on a linear system shows that the proposed control system is stable as long as the fast system is at least twice as fast as the slow system. A practical method to select the gain is also presented such that the closed-loop poles are placed at the desired locations. In simulation, we compare the proposed method with feedback linearization. The results indicate that in an ideal scenario the proposed method can obtain a similar performance as feedback linearization. However, the proposed method obtains a superior performance in a realistic scenario. A real-world experiment with a six degree-of-freedom commercial industrial robot is carried out to further validate our approach.",https://ieeexplore.ieee.org/document/8065027/,IEEE Transactions on Control Systems Technology,Jan. 2019,ieeexplore
10.1109/TOH.2017.2753233,Functional Contour-following via Haptic Perception and Reinforcement Learning,IEEE,Journals,"Many tasks involve the fine manipulation of objects despite limited visual feedback. In such scenarios, tactile and proprioceptive feedback can be leveraged for task completion. We present an approach for real-time haptic perception and decision-making for a haptics-driven, functional contour-following task: the closure of a ziplock bag. This task is challenging for robots because the bag is deformable, transparent, and visually occluded by artificial fingertip sensors that are also compliant. A deep neural net classifier was trained to estimate the state of a zipper within a robot's pinch grasp. A Contextual Multi-Armed Bandit (C-MAB) reinforcement learning algorithm was implemented to maximize cumulative rewards by balancing exploration versus exploitation of the state-action space. The C-MAB learner outperformed a benchmark Q-learner by more efficiently exploring the state-action space while learning a hard-to-code task. The learned C-MAB policy was tested with novel ziplock bag scenarios and contours (wire, rope). Importantly, this work contributes to the development of reinforcement learning approaches that account for limited resources such as hardware life and researcher time. As robots are used to perform complex, physically interactive tasks in unstructured or unmodeled environments, it becomes important to develop methods that enable efficient and effective learning with physical testbeds.",https://ieeexplore.ieee.org/document/8039205/,IEEE Transactions on Haptics,1 Jan.-March 2018,ieeexplore
10.1109/LRA.2019.2955941,Generative Localization With Uncertainty Estimation Through Video-CT Data for Bronchoscopic Biopsy,IEEE,Journals,"Robot-assisted endobronchial intervention requires accurate localization based on both intra- and pre-operative data. Most existing methods achieve this by registering 2D videos with 3D CT models according to a defined similarity metric with local features. Instead, we formulate the bronchoscopic localization as a learning-based global localisation using deep neural networks. The proposed network consists of two generative architectures and one auxiliary learning component. The cycle generative architecture bridges the domain variance between the real bronchoscopic videos and virtual views derived from pre-operative CT data so that the proposed approach can be trained through a large number of generated virtual images but deployed through real images. The auxiliary learning architecture leverages complementary relative pose regression to constrain the search space, ensuring consistent global pose predictions. Most importantly, the uncertainty of each global pose is obtained through variational inference by sampling within the learned underlying probability distribution. Detailed validation results demonstrate the localization accuracy with reasonable uncertainty achieved and its potential clinical value. A demonstration video demo can be found on the website <uri>https://youtu.be/ci9LMY49aF8</uri>.",https://ieeexplore.ieee.org/document/8913461/,IEEE Robotics and Automation Letters,Jan. 2020,ieeexplore
10.1109/ACCESS.2019.2938366,Grasping Objects From the Floor in Assistive Robotics: Real World Implications and Lessons Learned,IEEE,Journals,"This paper presents a system enabling a mobile robot to autonomously pick-up objects a human is pointing at from the floor. The system does not require object models and is designed to grasp unknown objects. The robot decides by itself if an object is suitable for grasping by considering measures of size, position and the environment suitability. The implementation is built on the second prototype of the home care robot Hobbit, thereby verifying that complex robotic manipulation tasks can be performed with economical hardware. The presented system was already tested in real apartments with elderly people. We highlight this by discussing the additional complexity for complete autonomous behavior in apartments compared with tests in labs.",https://ieeexplore.ieee.org/document/8819885/,IEEE Access,2019,ieeexplore
10.1109/ACCESS.2020.3043662,Ground-Level Mapping and Navigating for Agriculture Based on IoT and Computer Vision,IEEE,Journals,"Autonomous agricultural systems are a promising solution to bridge the gap between labor shortage for agriculture tasks and the continuing needs for increasing productivity in agriculture. Automated mapping and navigation system will be a cornerstone of most autonomous agricultural system. Accordingly, we propose a ground-level mapping and navigating system based on computer vision technology (Mesh Simultaneous Localization and Mapping algorithm, Mesh-SLAM) and Internet of Things (IoT), to generate a 3D farm map on both the edge side and cloud. The innovation of this system includes three layers as sub-systems that are 1) ground-level robot vehicles' layer for conducting frames collection only with a monocular camera, 2) edge node layer for image feature data edge computing and communication, and 3) cloud layer for general management and deep computing. High efficiency and speed of mapping stage are enabled by making the robot vehicles directly stream continuous frames to their corresponding edge node. Then each edge node, that coordinate a certain range of robots, applies a new Mesh-SLAM frame by frame, whose core is reconstructing the features map by a mesh-based algorithm with scalable units and reduce the feature data size by a filtering algorithm. Additionally, the cloud-computing allows comprehensive arrangement and heavily deep computing. The system is scalable to larger-scale fields and more complex environment by taking advantage of dynamically distributing the computation power to edges. Our evaluation indicates that: 1) this Mesh-SLAM algorithm outperforms in mapping and localization precision, accuracy, and yield prediction error (resolution at centimeter); and 2) The scalability and flexibility of the IoT architecture make the system modularized, easy adding/removing new functional modules or IoT sensors. We conclude the trade-off between cost and performance widely augments the feasibility and practical implementation of this system in real farms.",https://ieeexplore.ieee.org/document/9288741/,IEEE Access,2020,ieeexplore
10.1109/LRA.2020.2979656,Guided Constrained Policy Optimization for Dynamic Quadrupedal Robot Locomotion,IEEE,Journals,"Deep reinforcement learning (RL) uses model-free techniques to optimize task-specific control policies. Despite having emerged as a promising approach for complex problems, RL is still hard to use reliably for real-world applications. Apart from challenges such as precise reward function tuning, inaccurate sensing and actuation, and non-deterministic response, existing RL methods do not guarantee behavior within required safety constraints that are crucial for real robot scenarios. In this regard, we introduce guided constrained policy optimization (GCPO), an RL framework based upon our implementation of constrained proximal policy optimization (CPPO) for tracking base velocity commands while following the defined constraints. We introduce schemes which encourage state recovery into constrained regions in case of constraint violations. We present experimental results of our training method and test it on the real ANYmal quadruped robot. We compare our approach against the unconstrained RL method and show that guided constrained RL offers faster convergence close to the desired optimum resulting in an optimal, yet physically feasible, robotic control behavior without the need for precise reward function tuning.",https://ieeexplore.ieee.org/document/9028178/,IEEE Robotics and Automation Letters,April 2020,ieeexplore
10.1109/TIE.2006.888791,Hardware Implementation of a Real-Time Neural Network Controller With a DSP and an FPGA for Nonlinear Systems,IEEE,Journals,"In this paper, we implement the intelligent neural network controller hardware with a field programmable gate array (FPGA)-based general purpose chip and a digital signal processing (DSP) board to solve nonlinear system control problems. The designed intelligent control hardware can perform real-time control of the backpropagation learning algorithm of a neural network. The basic proportional-integral-derivative (PID) control algorithms are implemented in an FPGA chip and a neural network controller is implemented in a DSP board. By using a high capacity of an FPGA chip, the additional hardware such as an encoder counter and a pulsewidth modulation (PWM) generator is implemented in a single FPGA chip. As a result, the controller becomes cost effective. It was tested for controlling nonlinear systems such as a robot finger and an inverted pendulum on a moving cart to show performance of the controller",https://ieeexplore.ieee.org/document/4084734/,IEEE Transactions on Industrial Electronics,Feb. 2007,ieeexplore
10.1109/3477.499796,Hidden state and reinforcement learning with instance-based state identification,IEEE,Journals,"Real robots with real sensors are not omniscient. When a robot's next course of action depends on information that is hidden from the sensors because of problems such as occlusion, restricted range, bounded field of view and limited attention, we say the robot suffers from the hidden state problem. State identification techniques use history information to uncover hidden state. Some previous approaches to encoding history include: finite state machines, recurrent neural networks and genetic programming with indexed memory. A chief disadvantage of all these techniques is their long training time. This paper presents instance-based state identification, a new approach to reinforcement learning with state identification that learns with much fewer training steps. Noting that learning with history and learning in continuous spaces both share the property that they begin without knowing the granularity of the state space, the approach applies instance-based (or ""memory-based"") learning to history sequences-instead of recording instances in a continuous geometrical space, we record instances in action-percept-reward sequence space. The first implementation of this approach, called Nearest Sequence Memory, learns with an order of magnitude fewer steps than several previous approaches.",https://ieeexplore.ieee.org/document/499796/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",June 1996,ieeexplore
10.1109/ACCESS.2021.3063782,Hierarchical Decomposed-Objective Model Predictive Control for Autonomous Casualty Extraction,IEEE,Journals,"In recent years, several robots have been developed and deployed to perform casualty extraction tasks. However, the majority of these robots are overly complex, and require teleoperation via either a skilled operator or a specialised device, and often the operator must be present at the scene to navigate safely around the casualty. Instead, improving the autonomy of such robots can reduce the reliance on expert operators and potentially unstable communication systems, while still extracting the casualty in a safe manner. There are several stages in the casualty extraction procedure, from navigating to the location of the emergency, safely approaching and loading the casualty, to finally navigating back to the medical assistance location. In this paper, we propose a Hierarchical Decomposed-Objective based Model Predictive Control (HiDO-MPC) method for safely approaching and manoeuvring around the casualty. We implement this controller on ResQbot — a proof-of-concept mobile rescue robot we previously developed — capable of safely rescuing an injured person lying on the ground, i.e. performing the casualty extraction procedure. HiDO-MPC achieves the desired casualty extraction behaviour by decomposing the main objective into multiple sub-objectives with a hierarchical structure. At every time step, the controller evaluates this hierarchical decomposed objective and generates the optimal control decision. We have conducted a number of experiments both in simulation and using the real robot to evaluate the proposed method’s performance, and compare it with baseline approaches. The results demonstrate that the proposed control strategy gives significantly better results than baseline approaches in terms of accuracy, robustness, and execution time, when applied to casualty extraction scenarios.",https://ieeexplore.ieee.org/document/9369351/,IEEE Access,2021,ieeexplore
10.1109/ACCESS.2018.2873597,Hierarchical Semantic Mapping Using Convolutional Neural Networks for Intelligent Service Robotics,IEEE,Journals,"The introduction of service robots in the public domain has introduced a paradigm shift in how robots are interacting with people, where robots must learn to autonomously interact with the untrained public instead of being directed by trained personnel. As an example, a hospital service robot is told to deliver medicine to Patient Two in Ward Three. Without awareness of what “Patient Two” or “Ward Three” is, a service robot must systematically explore the environment to perform this task, which requires a long time. The implementation of a Semantic Map allows for robots to perceive the environment similar to people by associating semantic information with spatial information found in geometric maps. Currently, many semantic mapping works provide insufficient or incorrect semantic-metric information to allow a service robot to function dynamically in human-centric environments. This paper proposes a semantic map with a hierarchical semantic organization structure based on a hybrid metric-topological map leveraging convolutional neural networks and spatial room segmentation methods. Our results are validated using multiple simulated and real environments on our lab's custom developed mobile service robot and demonstrate an application of semantic maps by providing only vocal commands. We show that this proposed method provides better capabilities in terms of semantic map labeling and retain multiple levels of semantic information.",https://ieeexplore.ieee.org/document/8490234/,IEEE Access,2018,ieeexplore
10.1109/ACCESS.2020.3035725,Highlighted Map for Mobile Robot Localization and Its Generation Based on Reinforcement Learning,IEEE,Journals,"This article proposes a new kind of map for mobile robot localization and its generation method. We call the map a highlighted map, on which uniquely shaped objects (landmarks) in monotonous environments are highlighted. By using this map, robots can use such landmarks as clues for localization, and thus, their localization performance can be improved without having to update their sensors or online computation. Furthermore, this map can be easily combined with many other existing localization algorithms. We formulate the problem of making a highlighted map and propose a numerical optimization method based on reinforcement learning. This optimization method automatically identifies and emphasizes the important landmarks on the map. The generated highlighted map is adapted to situations such as the sensor characteristics and robot dynamics because this method uses the actual sensor measurement data. It is proven that the optimization converges under certain technical assumptions. We performed a numerical simulation and real-world experiment showing that the highlighted map provides better localization accuracy than a conventional map.",https://ieeexplore.ieee.org/document/9247228/,IEEE Access,2020,ieeexplore
10.1109/JSEN.2019.2956901,Human Action Recognition Using Deep Learning Methods on Limited Sensory Data,IEEE,Journals,"In recent years, due to the widespread usage of various sensors action recognition is becoming more popular in many fields such as person surveillance, human-robot interaction etc. In this study, we aimed to develop an action recognition system by using only limited accelerometer and gyroscope data. Several deep learning methods like Convolutional Neural Network(CNN), Long-Short Term Memory (LSTM) with classical machine learning algorithms and their combinations were implemented and a performance analysis was carried out. Data balancing and data augmentation methods were applied and accuracy rates were increased noticeably. We achieved new state-of-the-art result on the UCI HAR dataset by 97.4% accuracy rate with using 3 layer LSTM model. Also, we implemented same model on collected dataset (ETEXWELD) and 99.0% accuracy rate was obtained which means a solid contribution. Moreover, the performance analysis is not only based on accuracy results, but also includes precision, recall and f1-score metrics. Additionally, a real-time application was developed by using 3 layer LSTM network for evaluating how the best model classifies activities robustly.",https://ieeexplore.ieee.org/document/8918509/,IEEE Sensors Journal,"15 March15, 2020",ieeexplore
10.1109/TOH.2020.3029043,Human-Inspired Haptic Perception and Control in Robot-Assisted Milling Surgery,IEEE,Journals,"Bone milling is one of the most widely used and high-risk procedures in various types of surgeries, and it is important to be noted that the experienced surgeon can perform such an operation safely. The objective of this article is to enhance the safety of the robot-assisted milling operation with the inspiration of human haptic perception. The emergence, coding and perception of the human haptic are introduced. Following this, a single axis accelerometer that measures the vibration of the surgical power tool is mounted in the robot arm, and the recorded acceleration signal is encoded as parallel stream of binary data. The data are subsequently inputted to the Hopfield network so as to identify the milling state. Inspired by human inference procedure, the fuzzy logic controller is introduced to control the robot to track the desired state when performing bone milling operations. A real-time implementation of the proposed method on a digital signal processing is also described. The experimental results in milling porcine spines prove that the robot accurately discriminates different milling states even when the additive noise is serious, and the safe motion control of the robot is also realized.",https://ieeexplore.ieee.org/document/9220848/,IEEE Transactions on Haptics,1 April-June 2021,ieeexplore
10.1109/ACCESS.2019.2949835,Hybrid Path Planning Algorithm Based on Membrane Pseudo-Bacterial Potential Field for Autonomous Mobile Robots,IEEE,Journals,"A hybrid path planning algorithm based on membrane pseudo-bacterial potential field (MemPBPF) is proposed. Membrane-inspired algorithms can reach an evolutionary behavior based on biochemical processes to find the best parameters for generating a feasible and safe path. The proposed MemPBPF algorithm uses a combination of the structure and rules of membrane computing. In that sense, the proposed MemPBPF algorithm contains dynamic membranes that include a pseudo-bacterial genetic algorithm for evolving the required parameters in the artificial potential field method. This hybridization between membrane computing, the pseudo-bacterial genetic algorithm, and the artificial potential field method provides an outperforming path planning algorithm for autonomous mobile robots. Computer simulation results demonstrate the effectiveness of the proposed MemPBPF algorithm in terms of path length considering collision avoidance and smoothness. Comparisons with two different versions employing a different number of elementary membranes and with other artificial potential field based algorithms are presented. The proposed MemPBPF algorithm yields improved performance in terms of time execution by using a parallel implementation on a multi-core computer. Therefore, the MemPBPF algorithm achieves high performance yielding competitive results for autonomous mobile robot navigation in complex and real scenarios.",https://ieeexplore.ieee.org/document/8884165/,IEEE Access,2019,ieeexplore
10.1109/ACCESS.2019.2894524,Hybrid Stochastic Exploration Using Grey Wolf Optimizer and Coordinated Multi-Robot Exploration Algorithms,IEEE,Journals,"Multi-robot exploration is a search of uncertainty in restricted space seeking to build a finite map by a group of robots. It has the main task to distribute the search assignments among robots in real time. In this paper, we proposed a stochastic optimization for multi-robot exploration that mimics the coordinated predatory behavior of grey wolves via simulation. Here, the robot movement is computed by the combined deterministic and metaheuristic techniques. It uses the Coordinated Multi-Robot Exploration and GreyWolf Optimizer algorithms as a new method called the hybrid stochastic exploration. Initially, the deterministic cost and utility determine the precedence of adjacent cells around a robot. Then, the stochastic optimization improves the overall solution. It implies that the robots evaluate the environment by the deterministic approach and move on using the metaheuristic algorithm. The proposed hybrid method was implemented on simple and complex maps and compared with the Coordinated Multi-Robot Exploration algorithm. The simulation results show that the stochastic optimization enhances the deterministic approach to completely explore and map out the areas.",https://ieeexplore.ieee.org/document/8631022/,IEEE Access,2019,ieeexplore
10.1109/TMECH.2013.2245337,Image-Based Visual Servoing of a 7-DOF Robot Manipulator Using an Adaptive Distributed Fuzzy PD Controller,IEEE,Journals,"This paper is concerned with the design and implementation of a distributed proportional-derivative (PD) controller of a 7-degrees of freedom (DOF) robot manipulator using the Takagi-Sugeno (T-S) fuzzy framework. Existing machine learning approaches to visual servoing involve system identification of image and kinematic Jacobians. In contrast, the proposed approach actuates a control signal primarily as a function of the error and derivative of the error in the desired visual feature space. This approach leads to a significant reduction in the computational burden as compared to model-based approaches, as well as existing learning approaches to model inverse kinematics. The simplicity of the controller structure will make it attractive in industrial implementations where PD/PID type schemes are in common use. While the initial values of PD gain are learned with the help of model-based controller, an online adaptation scheme has been proposed that is capable of compensating for local uncertainties associated with the system and its environment. Rigorous experiments have been performed to show that visual servoing tasks such as reaching a static target and tracking of a moving target can be achieved using the proposed distributed PD controller. It is shown that the proposed adaptive scheme can dynamically tune the controller parameters during visual servoing, so as to improve its initial performance based on parameters obtained while mimicking the model-based controller. The proposed control scheme is applied and assessed in real-time experiments using an uncalibrated eye-in-hand robotic system with a 7-DOF PowerCube robot manipulator.",https://ieeexplore.ieee.org/document/6471828/,IEEE/ASME Transactions on Mechatronics,April 2014,ieeexplore
10.1109/TAMD.2011.2106781,Implicit Sensorimotor Mapping of the Peripersonal Space by Gazing and Reaching,IEEE,Journals,"Primates often perform coordinated eye and arm movements, contextually fixating and reaching towards nearby objects. This combination of looking and reaching to the same target is used by infants to establish an implicit visuomotor representation of the peripersonal space, useful for both oculomotor and arm motor control. In this work, taking inspiration from such behavior and from primate visuomotor mechanisms, a shared sensorimotor map of the environment, built on a radial basis function framework, is configured and trained by the coordinated control of eye and arm movements. Computational results confirm that the approach seems especially suitable for the problem at hand, and for its implementation on a real humanoid robot. By exploratory gazing and reaching actions, either free or goal-based, the artificial agent learns to perform direct and inverse transformations between stereo vision, oculomotor, and joint-space representations. The integrated sensorimotor map that allows to contextually represent the peripersonal space through different vision and motor parameters is never made explicit, but rather emerges thanks to the interaction of the agent with the environment.",https://ieeexplore.ieee.org/document/5703113/,IEEE Transactions on Autonomous Mental Development,March 2011,ieeexplore
10.1109/TIE.2018.2864707,Incremental Updating Multirobot Formation Using Nonlinear Model Predictive Control Method With General Projection Neural Network,IEEE,Journals,"In this paper, an incremental centralized formation system is developed for controlling the multirobot formation with joining robots, and a nonlinear model predictive control (NMPC) method is implemented as the controller. The incremental updating method is used to update the system's state in real time, when there is a new robot joining during the formation process. Then, an NMPC approach is developed to reformulate the formation system into a convex nonlinear minimization problem, which can be further transformed into a quadratic programming (QP) with constraints. Then, a general projection neural network (GPNN) is implemented for solving this QP problem online to get the optimal inputs. In the end, two examples of incremental multirobot formation are demonstrated to verify the effectiveness of this method.",https://ieeexplore.ieee.org/document/8437254/,IEEE Transactions on Industrial Electronics,June 2019,ieeexplore
10.1109/TSMCC.2007.897491,Integration of Coordination Architecture and Behavior Fuzzy Learning in Quadruped Walking Robots,IEEE,Journals,"This paper presents the design and implementation of a coordination architecture for quadruped walking robots to learn and execute soccer-playing behaviors. A typical hybrid architecture combing reactive behaviors with deliberative reasoning is developed. The reactive behaviors directly map spatial information extracted from sensors into actions. The deliberative reasoning represents temporal constraints of a robot's strategy in terms of finite state machines. In order to achieve real-time and robust control performance in reactive behaviors, fuzzy logic controllers (FLCs) are used to encode the behaviors, and a two-stage learning scheme is adopted to make these FLCs adaptive to complex situations. The experimental results are provided to show the suitability of the architecture and effectiveness of the proposed learning scheme.",https://ieeexplore.ieee.org/document/4252246/,"IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)",July 2007,ieeexplore
10.1109/TSMCA.2009.2033029,Interactive Teaching for Vision-Based Mobile Robots: A Sensory-Motor Approach,IEEE,Journals,"For the last decade, we have been developing a vision-based architecture for mobile robot navigation. Using our bio-inspired model of navigation, robots can perform sensory-motor tasks in real time in unknown indoor as well as outdoor environments. We address here the problem of autonomous incremental learning of a sensory-motor task, demonstrated by an operator guiding a robot. The proposed system allows for semisupervision of task learning and is able to adapt the environmental partitioning to the complexity of the desired behavior. A real dialogue based on actions emerges from the interactive teaching. The interaction leads the robot to autonomously build a precise sensory-motor dynamics that approximates the behavior of the teacher. The usability of the system is highlighted by experiments on real robots, in both indoor and outdoor environments. Accuracy measures are also proposed in order to evaluate the learned behavior as compared to the expected behavioral attractor. These measures, used first in a real experiment and then in a simulated experiment, demonstrate how a real interaction between the teacher and the robot influences the learning process.",https://ieeexplore.ieee.org/document/5345874/,"IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans",Jan. 2010,ieeexplore
10.1109/ACCESS.2021.3057808,Intuitive Robot Teleoperation Through Multi-Sensor Informed Mixed Reality Visual Aids,IEEE,Journals,"Mobile robotic systems have evolved to include sensors capable of truthfully describing robot status and operating environment as accurately and reliably as never before. This possibility is challenged by effective sensor data exploitation, because of the cognitive load an operator is exposed to, due to the large amount of data and time-dependency constraints. This paper addresses this challenge in remote-vehicle teleoperation by proposing an intuitive way to present sensor data to users by means of using mixed reality and visual aids within the user interface. We propose a method for organizing information presentation and a set of visual aids to facilitate visual communication of data in teleoperation control panels. The resulting sensor-information presentation appears coherent and intuitive, making it easier for an operator to catch and comprehend information meaning. This increases situational awareness and speeds up decision-making. Our method is implemented on a real mobile robotic system operating outdoor equipped with on-board internal and external sensors, GPS, and a reconstructed 3D graphical model provided by an assistant drone. Experimentation verified feasibility while intuitive and comprehensive visual communication was confirmed through an assessment, which encourages further developments.",https://ieeexplore.ieee.org/document/9349454/,IEEE Access,2021,ieeexplore
10.1109/LRA.2020.3013937,Invariant Transform Experience Replay: Data Augmentation for Deep Reinforcement Learning,IEEE,Journals,"Deep Reinforcement Learning (RL) is a promising approach for adaptive robot control, but its current application to robotics is currently hindered by high sample requirements. To alleviate this issue, we propose to exploit the symmetries present in robotic tasks. Intuitively, symmetries from observed trajectories define transformations that leave the space of feasible RL trajectories invariant and can be used to generate new feasible trajectories, which could be used for training. Based on this data augmentation idea, we formulate a general framework, called Invariant Transform Experience Replay that we present with two techniques: (i) Kaleidoscope Experience Replay exploits reflectional symmetries and (ii) Goal-augmented Experience Replay which takes advantage of lax goal definitions. In the Fetch tasks from OpenAI Gym, our experimental results show significant increases in learning rates and success rates. Particularly, we attain a 13, 3, and 5 times speedup in the pushing, sliding, and pick-and-place tasks respectively in the multi-goal setting. Performance gains are also observed in similar tasks with obstacles and we successfully deployed a trained policy on a real Baxter robot. Our work demonstrates that invariant transformations on RL trajectories are a promising methodology to speed up learning in deep RL. Code, video, and supplementary materials are available at [1].",https://ieeexplore.ieee.org/document/9158366/,IEEE Robotics and Automation Letters,Oct. 2020,ieeexplore
10.1109/TRA.2002.803459,LOST: localization-space trails for robot teams,IEEE,Journals,"We describe localization-space trails (LOST), a method that enables a team of robots to navigate between places of interest in an initially unknown environment using a trail of landmarks. The landmarks are not physical; they are waypoint coordinates generated online by each robot and shared with teammates. Waypoints are specified in each robot's local coordinate system, and contain references to features in the world that are relevant to the team's task and common to all robots. Using these task-level references, robots can share waypoints without maintaining a global coordinate system. The method is tested in a series of real-world multirobot experiments. The results demonstrate that the method: 1) copes with accumulating odometry error; 2) is robust to the failure of individual robots; 3) converges to the best route discovered by any robot in the team. In one experiment, a team of four autonomous mobile robots performs a resource transportation task in our uninstrumented office building. Despite significant divergence of their local coordinate systems, the robots are able to share waypoints, forming and following a common trail between two predetermined locations for more than three hours, traveling a total of 8.2 km (5.1 miles) before running out of power. Designed to scale to large populations, LOST is fully distributed, with low costs in processing, memory, and bandwidth. It combines metric data about the position of features in the world with instructions on how to get from one place to another; producing something between a map and a plan.",https://ieeexplore.ieee.org/document/1067999/,IEEE Transactions on Robotics and Automation,Oct. 2002,ieeexplore
10.1109/LRA.2020.3010739,Learning Force Control for Contact-Rich Manipulation Tasks With Rigid Position-Controlled Robots,IEEE,Journals,"Reinforcement Learning (RL) methods have been proven successful in solving manipulation tasks autonomously. However, RL is still not widely adopted on real robotic systems because working with real hardware entails additional challenges, especially when using rigid position-controlled manipulators. These challenges include the need for a robust controller to avoid undesired behavior, that risk damaging the robot and its environment, and constant supervision from a human operator. The main contributions of this work are, first, we proposed a learning-based force control framework combining RL techniques with traditional force control. Within said control scheme, we implemented two different conventional approaches to achieve force control with position-controlled robots; one is a modified parallel position/force control, and the other is an admittance control. Secondly, we empirically study both control schemes when used as the action space of the RL agent. Thirdly, we developed a fail-safe mechanism for safely training an RL agent on manipulation tasks using a real rigid robot manipulator. The proposed methods are validated both on simulation and a real robot with an UR3 e-series robotic arm.",https://ieeexplore.ieee.org/document/9145608/,IEEE Robotics and Automation Letters,Oct. 2020,ieeexplore
10.1109/LRA.2021.3061374,Learning Variable Impedance Control via Inverse Reinforcement Learning for Force-Related Tasks,IEEE,Journals,"Many manipulation tasks require robots to interact with unknown environments. In such applications, the ability to adapt the impedance according to different task phases and environment constraints is crucial for safety and performance. Although many approaches based on deep reinforcement learning (RL) and learning from demonstration (LfD) have been proposed to obtain variable impedance skills on contact-rich manipulation tasks, these skills are typically task-specific and could be sensitive to changes in task settings. This letter proposes an inverse reinforcement learning (IRL) based approach to recover both the variable impedance policy and reward function from expert demonstrations. We explore different action space of the reward functions to achieve a more general representation of expert variable impedance skills. Experiments on two variable impedance tasks (Peg-in-Hole and Cup-on-Plate) were conducted in both simulations and on a real FANUC LR Mate 200iD/7 L industrial robot. The comparison results with behavior cloning and force-based IRL proved that the learned reward function in the gain action space has better transferability than in the force space. Experiment videos are available at https://msc.berkeley.edu/research/impedance-irl.html.",https://ieeexplore.ieee.org/document/9361101/,IEEE Robotics and Automation Letters,April 2021,ieeexplore
10.1109/JETCAS.2020.3033135,<italic>Learning to Walk</italic>: Bio-Mimetic Hexapod Locomotion via Reinforcement-Based Spiking Central Pattern Generation,IEEE,Journals,"Online learning for the legged robot locomotion under performance and energy constraints remains to be a challenge. Methods such as stochastic gradient, deep reinforcement learning (RL) have been explored for bipeds, quadrupeds and hexapods. These techniques are computationally intensive and thus difficult to implement on edge computing platforms. These methods are also inefficient in energy consumption and throughput because of their reliance on complex sensors and pre-processing of data. On the other hand, neuromorphic computing paradigms, such as spiking neural networks (SNN), become increasingly favorable in low power computing on edge intelligence. SNN has exhibited the capability of performing reinforcement learning mechanisms with biomimetic spike time-dependent plasticity (STDP) of synapses. However, training a legged robot to walk in the synchronized gait patterns generated by a central pattern generator (CPG) in an SNN framework has not yet been explored. Such a method can combine the efficiency of SNNs with the synchronized locomotion of CPG based systems - providing breakthrough performance improvement of end-to-end learning in mobile robotics. In this paper, we propose a reinforcement based stochastic learning technique for training a spiking CPG for a hexapod robot which learns to walk using bio-inspired tripod gait without prior knowledge. The whole system is implemented on a lightweight raspberry pi platform with integrated sensors. Our method opens new opportunities for online learning with limited edge computing resources.",https://ieeexplore.ieee.org/document/9235477/,IEEE Journal on Emerging and Selected Topics in Circuits and Systems,Dec. 2020,ieeexplore
10.1109/TAMD.2015.2507439,Lifelong Augmentation of Multimodal Streaming Autobiographical Memories,IEEE,Journals,"Robot systems that interact with humans over extended periods of time will benefit from storing and recalling large amounts of accumulated sensorimotor and interaction data. We provide a principled framework for the cumulative organization of streaming autobiographical data so that data can be continuously processed and augmented as the processing and reasoning abilities of the agent develop and further interactions with humans take place. As an example, we show how a kinematic structure learning algorithm reasons a-posteriori about the skeleton of a human hand. A partner can be asked to provide feedback about the augmented memories, which can in turn be supplied to the reasoning processes in order to adapt their parameters. We employ active, multimodal remembering, so the robot as well as humans can gain insights of both the original and augmented memories. Our framework is capable of storing discrete and continuous data in real-time. The data can cover multiple modalities and several layers of abstraction (e.g., from raw sound signals over sentences to extracted meanings). We show a typical interaction with a human partner using an iCub humanoid robot. The framework is implemented in a platform-independent manner. In particular, we validate its multi platform capabilities using the iCub, Baxter and NAO robots. We also provide an interface to cloud based services, which allow automatic annotation of episodes. Our framework is geared towards the developmental robotics community, as it: 1) provides a variety of interfaces for other modules; 2) unifies previous works on autobiographical memory; and 3) is licensed as open source software.",https://ieeexplore.ieee.org/document/7350228/,IEEE Transactions on Cognitive and Developmental Systems,Sept. 2016,ieeexplore
10.1109/TASE.2017.2783342,MASD: A Multimodal Assembly Skill Decoding System for Robot Programming by Demonstration,IEEE,Journals,"Programming by demonstration (PBD) transforms the robot programming from the code level to automated interface between robot and human, promoting the flexibility of robotized automation. In this paper, we focus on programming the industrial robot for assembly tasks by parsing the human demonstration into a series of assembly skills and compiling the skill to the robot executables. To achieve this goal, an identification system using multimodal information to recognize the assembly skill, called MASD, is proposed including: 1) an initial learning stage using a hierarchical model to recognize the action by considering the features from action-object effect, gesture, and trajectory and 2) a retrospective thinking stage using a segmentation method to cut the continuous demonstrations into multiple assembly skills optimally. Using MASD, the demonstration of assembly tasks can be explained with high accuracy in real time, driving a hypothesis that a PBD system on the top of MASD can be extended to more realistic assembly tasks beyond pure positional moving and picking. In experiments, the skill identification module is used to recognize the five kinds of assembly skills in demonstrations of both single and multiple assembly skills, and outperforms the comparative action identification methods. Besides integrated with the MASD, the PBD system can generate the program based on the demonstration and successfully enable an ABB industrial robotic arm simulator to assemble a flashlight and a switch, verifying the initial hypothesis. Note to Practitioners-In the conventional robotized automation, the key role of the robot mainly owes to its capacity for repeating a wide variety of tasks with high speed and accuracy in long term, with a cost of days to months of programming for deployment. On the other hand, the new trend of customization brings the new characteristics: production in short cycle and small volume. This irreversible momentum urges the robot to switch from task to task efficiently. The biggest bottleneck here is the tedious programming, which also has high prerequisites for most practitioners in manufacturing. This situation motivates the development of a PBD system that can understand the assembly skills performed by the human experts in the demonstration and accordingly generate the program for robot's execution of the taught task. In this paper, we present a skill decoding system to parse the observational raw demonstration into symbolic sequences, which is the crucial bridge to enable the automatic programming. The system achieves high performance in recognition and is tailored for the PBD in assembly tasks by considering both advantages and disadvantages in the background of assembly, such as controllable environment and limited computational resources. It is particularly useful for assembly tasks with modularized actions based on a set of standard parts. At the perspective of industrial application, the PBD upon the proposed system is a promising solution to improve the flexibility of manufacture, which is expected to be true in midterm but an important step toward this goal.",https://ieeexplore.ieee.org/document/8263146/,IEEE Transactions on Automation Science and Engineering,Oct. 2018,ieeexplore
10.1109/TVT.2019.2952926,Mechanism Design for Wireless Powered Spatial Crowdsourcing Networks,IEEE,Journals,"Wireless power transfer (WPT) is a promising technology to prolong the lifetime of the sensors and communication devices, i.e., workers, in completing crowdsourcing tasks by providing continuous and cost-effective energy supplies. In this paper, we propose a wireless powered spatial crowdsourcing framework which consists of two mutually dependent phases: task allocation phase and data crowdsourcing phase. In the task allocation phase, we propose a Stackelberg game based mechanism for the spatial crowdsourcing platform to efficiently allocate spatial tasks and wireless charging power to each worker. In the data crowdsourcing phase, the workers may have an incentive to misreport its real working location to improve its utility, which causes adverse effects to the spatial crowdsourcing platform. To address this issue, we present three strategyproof deployment mechanisms for the spatial crowdsourcing platform to place a mobile base station, e.g., vehicle or robot, which is responsible for transferring the wireless power and collecting the crowdsourced data. As the benchmark, we first apply the classical median mechanism and evaluate its worst-case performance. Then, we design a conventional strategyproof deployment mechanism to improve the expected utility of the spatial crowdsourcing platform under the condition that the workers' locations follow a known geographical distribution. For a more general case with only the historical location data available, we propose a deep learning based strategyproof deployment mechanism to maximize the spatial crowdsourcing platform's utility. Extensive experimental results based on synthetic and real-world datasets reveal the effectiveness of the proposed framework in allocating tasks and charging power to workers while avoiding the dishonest worker's manipulation.",https://ieeexplore.ieee.org/document/8895988/,IEEE Transactions on Vehicular Technology,Jan. 2020,ieeexplore
10.1109/TII.2012.2205395,Minimal Resource Allocating Networks for Discrete Time Sliding Mode Control of Robotic Manipulators,IEEE,Journals,"This paper presents a discrete-time sliding mode control based on neural networks designed for robotic manipulators. Radial basis function neural networks are used to learn about uncertainties affecting the system. The online learning algorithm combines the growing criterion and the pruning strategy of the minimal resource allocating network technique with an adaptive extended Kalman filter to update all the parameters of the networks. A method to improve the run-time performance for the real-time implementation of the learning algorithm has been considered. The analysis of the control stability is given and the controller is evaluated on the ERICC robot arm. Experiments show that the proposed controller produces good trajectory tracking performance and it is robust in the presence of model inaccuracies, disturbances and payload perturbations.",https://ieeexplore.ieee.org/document/6221995/,IEEE Transactions on Industrial Informatics,Nov. 2012,ieeexplore
10.1109/41.704895,Modeling of ultrasonic range sensors for localization of autonomous mobile robots,IEEE,Journals,"This paper presents a probabilistic model of ultrasonic range sensors using backpropagation neural networks trained on experimental data. The sensor model provides the probability of detecting mapped obstacles in the environment, given their position and orientation relative to the transducer. The detection probability can be used to compute the location of an autonomous vehicle from those obstacles that are more likely to be detected. The neural network model is more accurate than other existing approaches, since it captures the typical multilobal detection pattern of ultrasonic transducers. Since the network size is kept small, implementation of the model on a mobile robot can be efficient for real-time navigation. An example that demonstrates how the credence could be incorporated into the extended Kalman filter (EKF) and the numerical values of the final neural network weights are provided in the appendices.",https://ieeexplore.ieee.org/document/704895/,IEEE Transactions on Industrial Electronics,Aug. 1998,ieeexplore
10.1109/LRA.2020.3010456,Multi-Robot Active Sensing and Environmental Model Learning With Distributed Gaussian Process,IEEE,Journals,"This letter deals with the problem of multiple robots working together to explore and gather at the global maximum of the unknown field. Given noisy sensor measurements obtained at the location of robots with no prior knowledge about the environmental map, Gaussian process regression can be an efficient solution to construct a map that represents spatial information with confidence intervals. However, because the conventional Gaussian process algorithm operates in a centralized manner, it is difficult to process information coming from multiple distributed sensors in real-time. In this work, we propose a multi-robot exploration algorithm that deals with the following challenges: i) distributed environmental map construction using networked sensing platforms; ii) online learning using successive measurements suitable for a multi-robot team; iii) multi-agent coordination to discover the highest peak of an unknown environmental field with collision avoidance. We demonstrate the effectiveness of our algorithm via simulation and a topographic survey experiment with multiple UAVs.",https://ieeexplore.ieee.org/document/9144385/,IEEE Robotics and Automation Letters,Oct. 2020,ieeexplore
10.1109/ACCESS.2019.2899940,Multi-Task Cascaded Convolutional Networks Based Intelligent Fruit Detection for Designing Automated Robot,IEEE,Journals,"Effective and efficient fruit detection is considered crucial for designing automated robot (AuRo) for yield estimation, disease control, harvesting, sorting, and grading. Several fruit detection schemes for designing AuRo have been developed during the last decades. However, conventional fruit detection methods are deficient in the real-time response, accuracy, and extensibility. This paper proposes an improved multi-task cascaded convolutional network-based intelligent fruit detection method. This method has the capability to make the AuRo work in real time with high accuracy. Moreover, based on the relationship between the diversity samples of the dataset and the parameters of neural networks' evolution, this paper presents an improved augmented method, a procedure that is based on image fusion to improve the detector performance. The experiment results demonstrated that the proposed detector performed immaculately both in terms of accuracy and time-cost. Furthermore, the extensive experiment also demonstrated that the proposed technique has the capacity and good portability to work with other akin objects conveniently.",https://ieeexplore.ieee.org/document/8643367/,IEEE Access,2019,ieeexplore
10.1109/41.499811,Multilayered fuzzy behavior fusion for real-time reactive control of systems with multiple sensors,IEEE,Journals,"Fuzzy linguistic rules provide an intuitive and powerful means for defining control behavior. Most applications that use fuzzy control feature a single layer of fuzzy inference, mapping a function from one or two inputs to equally few outputs. Highly complex systems, with large numbers of inputs, may also benefit from the use of qualitative linguistic rules if the control task is properly partitioned. This paper presents a modular fuzzy control architecture and inference engine that can be used to control complex systems. The control function is broken down into multiple local agents, each of which samples a subset of a large sensor input space. Additional fuzzy agents are employed to fuse the recommendations of the local agents. Real-time implementation without special hardware is possible by using singleton output values during fuzzy rule evaluation. A development tool is used to translate a fuzzy programming language offline for fast execution at run time. Using this system, a multilayered fuzzy behavior fusion based reactive control system has been implemented on an autonomous mobile robot, MARGE, with great success. MARGE won first place in Event III of the 1993 Robot Competition sponsored by the American Association for Artificial Intelligence.",https://ieeexplore.ieee.org/document/499811/,IEEE Transactions on Industrial Electronics,June 1996,ieeexplore
10.1109/TAMD.2010.2086453,Multilevel Darwinist Brain (MDB): Artificial Evolution in a Cognitive Architecture for Real Robots,IEEE,Journals,"The multilevel Darwinist brain (MDB) is a cognitive architecture that follows an evolutionary approach to provide autonomous robots with lifelong adaptation. It has been tested in real robot on-line learning scenarios obtaining successful results that reinforce the evolutionary principles that constitute the main original contribution of the MDB. This preliminary work has lead to a series of improvements in the computational implementation of the architecture so as to achieve realistic operation in real time, which was the biggest problem of the approach due to the high computational cost induced by the evolutionary algorithms that make up the MDB core. The current implementation of the architecture is able to provide an autonomous robot with real time learning capabilities and the capability for continuously adapting to changing circumstances in its world, both internal and external, with minimal intervention of the designer. This paper aims at providing an overview or the architecture and its operation and defining what is required in the path towards a real cognitive robot following a developmental strategy. The design, implementation and basic operation of the MDB cognitive architecture are presented through some successful real robot learning examples to illustrate the validity of this evolutionary approach.",https://ieeexplore.ieee.org/document/5599851/,IEEE Transactions on Autonomous Mental Development,Dec. 2010,ieeexplore
10.1109/TIE.2007.903993,Multimodal Approach to Human-Face Detection and Tracking,IEEE,Journals,"The constructive need for robots to coexist with humans requires human-machine interaction. It is a challenge to operate these robots in such dynamic environments, which requires continuous decision-making and environment-attribute update in real-time. An autonomous robot guide is well suitable in places such as museums, libraries, schools, hospital, etc. This paper addresses a scenario where a robot tracks and follows a human. A neural network is utilized to learn the skin and nonskin colors. The skin-color probability map is utilized for skin classification and morphology-based preprocessing. Heuristic rule is used for face-ratio analysis and Bayesian cost analysis for label classification. A face-detection module, based on a 2D color model in the and YUV color space, is selected over the traditional skin-color model in a 3D color space. A modified continuously adaptive mean shift tracking mechanism in a 1D hue, saturation, and value color space is developed and implemented onto the mobile robot. In addition to the visual cues, the tracking process considers 16 sonar scan and tactile sensor readings from the robot to generate a robust measure of the person's distance from the robot. The robot thus decides an appropriate action, namely, to follow the human subject and perform obstacle avoidance. The proposed approach is orientation invariant under varying lighting conditions and invariant to natural transformations such as translation, rotation, and scaling. Such a multimodal solution is effective for face detection and tracking.",https://ieeexplore.ieee.org/document/4392479/,IEEE Transactions on Industrial Electronics,March 2008,ieeexplore
10.1109/TNNLS.2020.2980038,Mutual-Collision-Avoidance Scheme Synthesized by Neural Networks for Dual Redundant Robot Manipulators Executing Cooperative Tasks,IEEE,Journals,"Collision between dual robot manipulators during working process will lead to task failure and even robot damage. To avoid mutual collision of dual robot manipulators while doing collaboration tasks, a novel recurrent neural network (RNN)-based mutual-collision-avoidance (MCA) scheme for solving the motion planning problem of dual manipulators is proposed and exploited. Because of the high accuracy and low computation complexity, the linear variational inequality-based primal-dual neural network is used to solve the proposed scheme. The proposed scheme is applied to the collaboration trajectory tracking and cup-stacking tasks, and shows its effectiveness for avoiding collision between the dual robot manipulators. Through network iteration and online learning, the dual robot manipulators will learn the ability of MCA. Moreover, a line-segment-based distance measure algorithm is proposed to calculate the minimum distance between the dual manipulators. If the computed minimum distance is less than the first safe-related distance threshold, a speed brake operation is executed and guarantees that the robot cannot exceed the second safe-related distance threshold. Furthermore, the proposed MCA strategy is formulated as a standard quadratic programming problem, which is further solved by an RNN. Computer simulations and a real dual robot experiment further verify the effectiveness, accuracy, and physical realizability of the RNN-based MCA scheme when manipulators cooperatively execute the end-effector tasks.",https://ieeexplore.ieee.org/document/9072323/,IEEE Transactions on Neural Networks and Learning Systems,March 2021,ieeexplore
10.1109/TLA.2019.8896824,Navigation System for MACÁBOT an Autonomous Surface Vehicles Using GPS Aided Strapdown Inertial Navigation System,IEEE,Journals,"In this work the design, implementation and real-time tests of a navigation system for the autonomous surface vehicle MACÁBOT is presented. This vehicle represents a versatile platform to perform several tasks in the marine environment, such as; ports maintenance, marine productive ecosystems studies and bathymetries. The navigation system is responsible for accurately determining the position, velocity and attitude of the vehicle. It represents a fundamental component to autonomously carry out any of the aforementioned tasks. In this work, the navigation system is developed based on a GPS aided strap-down inertial navigation system using an extended Kalman filter sensor fusion algorithm. In order to provide an adaptive approach to the sensor fusion algorithm tuning a fuzzy inference system is used. The navigation system was implemented as a package for the Robot Operating System, benefiting from the advantages of heterogeneity, integration and hardware abstraction. Real time tests of the MACÁBOT on a local creek were carried out, showing satisfactory performance of the navigation system in both position and velocity estimates. In addition to these tests, simulations of GPS outages were carried out with the registered data to evaluate the performance of the navigation system in such cases.",https://ieeexplore.ieee.org/document/8896824/,IEEE Latin America Transactions,June 2019,ieeexplore
10.1109/ACCESS.2018.2863736,Noise-Resistant Discrete-Time Neural Dynamics for Computing Time-Dependent Lyapunov Equation,IEEE,Journals,"Z-type neural dynamics, which is a powerful calculating tool, is widely used to compute various time-dependent problems. Most Z-type neural dynamics models are usually investigated in a noise-free situation. However, noises will inevitably exist in the implementation process of a neural dynamics model. To deal with such an issue, this paper considers a new discrete-time Z-type neural dynamics model, which is analyzed and investigated to calculate the real-time-dependent Lyapunov equation in the form A<sup>T</sup>(t)X(t) + X(t)A(t) + C(t) = 0 in different types of noisy circumstances. Related theoretical analyses are provided to illustrate that, the proposed neural dynamics model is intrinsically noise-resistant and has the advantage of high precision in real-time calculation. This model is called the noise-resistant discrete-time Z-type neural dynamics (NRDTZND) model. For comparison, the conventional discrete-time Z-type neural dynamics model is also proposed and used for solving the same time-dependent problem in noisy environments. Finally, three illustrative examples, including a real-life application to the inverse kinematics motion planning of a robot arm, are performed and analyzed to prove the validity and superiority of the proposed NRDTZND model in computing the real-time-dependent Lyapunov equation under various types of noisy situations.",https://ieeexplore.ieee.org/document/8425977/,IEEE Access,2018,ieeexplore
10.1109/TIE.2005.847576,Obstacle avoidance of a mobile robot using hybrid learning approach,IEEE,Journals,"in this paper, a hybrid learning approach for obstacle avoidance of a mobile robot is presented. the key features of the approach are, firstly, innate hardwired behaviors which are used to bootstrap learning in the mobile robot system. a neuro-fuzzy controller is developed from a pre-wired or innate controller based on supervised learning in a simulation environment. the fuzzy inference system has been constructed based on the generalized dynamic fuzzy neural networks learning algorithm of Wu and Er, whereby structure and parameters identification are carried out automatically and simultaneously. Secondly, the neuro-fuzzy controller is capable of re-adapting in a new environment. After carrying out the learning phase on a simulated robot, the controller is implemented on a real robot. A reinforcement learning method based on the fuzzy actor-critic learning algorithm is employed so that the system can re-adapt to a new environment without human intervention. In this phase, the structure of the fuzzy inference system and the parameters of the antecedent parts of fuzzy rules are frozen, and reinforcement learning is applied to further tune the parameters in the consequent parts of the fuzzy rules. Through the hybrid learning approach, an efficient and compact neuro-fuzzy system is generated for obstacle avoidance of a mobile robot in the real world.",https://ieeexplore.ieee.org/document/1435700/,IEEE Transactions on Industrial Electronics,June 2005,ieeexplore
10.1109/JPROC.2019.2898267,"On Proactive, Transparent, and Verifiable Ethical Reasoning for Robots",IEEE,Journals,"Previous work on ethical machine reasoning has largely been theoretical, and where such systems have been implemented, it has, in general, been only initial proofs of principle. Here, we address the question of desirable attributes for such systems to improve their real world utility, and how controllers with these attributes might be implemented. We propose that ethically critical machine reasoning should be proactive, transparent, and verifiable. We describe an architecture where the ethical reasoning is handled by a separate layer, augmenting a typical layered control architecture, ethically moderating the robot actions. It makes use of a simulation-based internal model and supports proactive, transparent, and verifiable ethical reasoning. To do so, the reasoning component of the ethical layer uses our Python-based belief-desire-intention (BDI) implementation. The declarative logic structure of BDI facilitates both transparency, through logging of the reasoning cycle, and formal verification methods. To prove the principles of our approach, we use a case study implementation to experimentally demonstrate its operation. Importantly, it is the first such robot controller where the ethical machine reasoning has been formally verified.",https://ieeexplore.ieee.org/document/8648363/,Proceedings of the IEEE,March 2019,ieeexplore
10.1109/LRA.2021.3076955,On the Emergence of Whole-Body Strategies From Humanoid Robot Push-Recovery Learning,IEEE,Journals,"Balancing and push-recovery are essential capabilities enabling humanoid robots to solve complex locomotion tasks. In this context, classical control systems tend to be based on simplified physical models and hard-coded strategies. Although successful in specific scenarios, this approach requires demanding tuning of parameters and switching logic between specifically-designed controllers for handling more general perturbations. We apply model-free Deep Reinforcement Learning for training a general and robust humanoid push-recovery policy in a simulation environment. Our method targets high-dimensional whole-body humanoid control and is validated on the iCub humanoid. Reward components incorporating expert knowledge on humanoid control enable fast learning of several robust behaviors by the same policy, spanning the entire body. We validate our method with extensive quantitative analyses in simulation, including out-of-sample tasks which demonstrate policy robustness and generalization, both key requirements towards real-world robot deployment.",https://ieeexplore.ieee.org/document/9420230/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/LRA.2021.3108510,Online Learning of Unknown Dynamics for Model-Based Controllers in Legged Locomotion,IEEE,Journals,"The performance of a model-based controller can severely suffer when its model inaccurately represents the real world dynamics. We propose to learn a time-varying, locally linear residual model along the robot's current trajectory, to compensate for the prediction errors of the controller's model. Supervised learning is performed online, as the robot is running in the unknown environment, using data collected from its immediate past. We theoretically investigate our method in its general formulation, then apply it to a bipedal controller derived from the full-order dynamics of virtual constraints, and a quadrupedal controller derived from a simplified model of contact forces. For a biped in simulation, our method consistently outperforms the baseline and a recent learning-based method. We also experiment with a 12 kg quadruped in simulation and real world, where the baseline fails to walk with 10 kg of payload but our method succeeds.",https://ieeexplore.ieee.org/document/9525285/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/ACCESS.2020.3048877,"Online Measuring of Robot Positions Using Inertial Measurement Units, Sensor Fusion and Artificial Intelligence",IEEE,Journals,"This research introduces a new method to estimate the position of a robot's Tool Center Point (TCP) using Inertial Measurement Units (IMUs), sensor fusion and Artificial Neural Networks (ANNs). The objective is to make an accurate estimate of TCP navigation, using the signals from an IMU as resources of a neural network capable of predicting the position. Considering that the IMU sensors suffer noise in the measurements and the noise progresses over time, this proposal employs a technique that eliminates the filtering step, and the process is done internally by the network. The work employs a non-parametric approach to reset the reference dynamically, minimize noise from sensors, and converge positioning to a nominal result. This method offers a solution for fast, cheap, and efficient robot calibration. The work does not want to replace current techniques but to introduce a new design to the literature. The concept does not require sophisticated mechanical parts and the production line to be idle during the calibration process, and the results show that the developed technique can accurately predict the TCP position with millimeter errors and in real-time. The study also implemented the concept with other neural networks, for which it used a smaller set of data in an attempt to reduce training time. The research used the Multilayer Perceptron and XGBRegressor networks to test the approach introduced with others algorithms. Different applications that need real-time positioning can benefit from the proposal.",https://ieeexplore.ieee.org/document/9312193/,IEEE Access,2021,ieeexplore
10.1109/LRA.2019.2894217,Persistent and Robust Execution of MAPF Schedules in Warehouses,IEEE,Journals,"Multi-agent path finding (MAPF) is a well-studied problem in artificial intelligence that can be solved quickly in practice when using simplified agent assumptions. However, real-world applications, such as warehouse automation, require physical robots to function over long time horizons without collisions. We present an execution framework that can use existing single-shot MAPF planners and ensures robust execution in the presence of unknown or time-varying higher-order dynamic limits, unforeseen robot slow-downs, and unpredictable obstacle appearances. Our framework also naturally enables the overlap of re-planning and execution for persistent operation and requires little communication between robots and the centralized planner. We demonstrate our approach in warehouse simulations and in a mixed reality experiment using differential drive robots. We believe that our solution closes the gap between recent research in the artificial intelligence community and real-world applications.",https://ieeexplore.ieee.org/document/8620328/,IEEE Robotics and Automation Letters,April 2019,ieeexplore
10.1109/TNSRE.2017.2692520,Portable and Reconfigurable Wrist Robot Improves Hand Function for Post-Stroke Subjects,IEEE,Journals,"Rehabilitation robots have become increasingly popular for stroke rehabilitation. However, the high cost of robots hampers their implementation on a large scale. This paper implements the concept of a modular and reconfigurable robot, reducing its cost and size by adopting different therapeutic end effectors for different training movements using a single robot. The challenge is to increase the robot's portability and identify appropriate kinds of modular tools and configurations. Because literature on the effectiveness of this kind of rehabilitation robot is still scarce, this paper presents the design of a portable and reconfigurable rehabilitation robot and describes its use with a group of post-stroke patients for wrist and forearm training. Seven stroke subjects received training using a reconfigurable robot for 30 sessions, lasting 30 min per session. Post-training, statistical analysis showed significant improvement of 3.29 points (16.20%, p = 0.027) on the Fugl-Meyer assessment scale for forearm and wrist components. Significant improvement of active range of motion was detected in both pronation-supination (75.59%, p = 0.018) and wrist flexion-extension (56.12%, p = 0.018) after the training. These preliminary results demonstrate that the developed reconfigurable robot could improve subjects' wrist and forearm movement.",https://ieeexplore.ieee.org/document/7894193/,IEEE Transactions on Neural Systems and Rehabilitation Engineering,Oct. 2017,ieeexplore
10.1109/TNN.2006.877534,Prune-Able Fuzzy ART Neural Architecture for Robot Map Learning and Navigation in Dynamic Environments,IEEE,Journals,"Mobile robots must be able to build their own maps to navigate in unknown worlds. Expanding a previously proposed method based on the fuzzy ART neural architecture (FARTNA), this paper introduces a new online method for learning maps of unknown dynamic worlds. For this purpose the new Prune-able fuzzy adaptive resonance theory neural architecture (PAFARTNA) is introduced. It extends the FARTNA self-organizing neural network with novel mechanisms that provide important dynamic adaptation capabilities. Relevant PAFARTNA properties are formulated and demonstrated. A method is proposed for the perception of object removals, and then integrated with PAFARTNA. The proposed methods are integrated into a navigation architecture. With the new navigation architecture the mobile robot is able to navigate in changing worlds, and a degree of optimality is maintained, associated to a shortest path planning approach implemented in real-time over the underlying global world model. Experimental results obtained with a Nomad 200 robot are presented demonstrating the feasibility and effectiveness of the proposed methods",https://ieeexplore.ieee.org/document/1687933/,IEEE Transactions on Neural Networks,Sept. 2006,ieeexplore
10.1109/LRA.2020.2998414,RILaaS: Robot Inference and Learning as a Service,IEEE,Journals,"Programming robots is complicated due to the lack of `plug-and-play' modules for skill acquisition. Virtualizing deployment of deep learning models can facilitate large-scale use/re-use of off-the-shelf functional behaviors. Deploying deep learning models on robots entails real-time, accurate and reliable inference service under varying query load. This letter introduces a novel Robot-Inference-and-Learning-as-a-Service (RILaaS) platform for low-latency and secure inference serving of deep models that can be deployed on robots. Unique features of RILaaS include: 1) low-latency and reliable serving with gRPC under dynamic loads by distributing queries over multiple servers on Edge and Cloud, 2) SSH based authentication coupled with SSL/TLS based encryption for security and privacy of the data, and 3) front-end REST API for sharing, monitoring and visualizing performance metrics of the available models. We report experiments to evaluate the RILaaS platform under varying loads of batch size, number of robots, and various model placement hosts on Cloud, Edge, and Fog for providing benchmark applications of object recognition and grasp planning as a service. We address the complexity of load balancing with a reinforcement learning algorithm that optimizes simulated profiles of networked robots; outperforming several baselines including round robin, least connections, and least model time with 68.30% and 14.04% decrease in round-trip latency time across models compared to the worst and the next best baseline respectively. Details and updates are available at: https://sites.google.com/view/rilaas.",https://ieeexplore.ieee.org/document/9103220/,IEEE Robotics and Automation Letters,July 2020,ieeexplore
10.1109/TCSI.2004.827654,Reaction-diffusion navigation robot control: from chemical to VLSI analogic processors,IEEE,Journals,"We introduce a new methodology and experimental implementations for real-time wave-based robot navigation in a complex, dynamically changing environment. The main idea behind the approach is to consider the robot arena as an excitable medium, in which moving objects-obstacles and the target-are represented by sites of autowave generation: the target generates attractive waves, while the obstacles repulsive ones. The moving robot detects traveling and colliding wave fronts and uses the information about dynamics of the autowaves to adapt its direction of collision-free motion toward the target. This approach allows us to achieve a highly adaptive robot behavior and thus an optimal path along which the robot reaches the target while avoiding obstacles. At the computational and experimental levels, we adopt principles of computation in reaction-diffusion (RD) nonlinear active media. Nonlinear media where autowaves are used for information processing purposes can therefore be considered as RD computing devices. In this paper, we design and experiment with three types of RD processors: experimental and computational Belousov-Zhabotinsky chemical processor, computational CNN processor, and experimental RD-CNN very large-scale integration chip-the complex analog and logic computing engine (CACE1k). We demonstrate how to experimentally implement robot navigation using space-time snapshots of active chemical medium and how to overcome low-speed limitation of this ""wetware"" implementation in CNN-based silicon processors.",https://ieeexplore.ieee.org/document/1296805/,IEEE Transactions on Circuits and Systems I: Regular Papers,May 2004,ieeexplore
10.1109/LRA.2018.2798286,Real-Time 3-D Shape Instantiation From Single Fluoroscopy Projection for Fenestrated Stent Graft Deployment,IEEE,Journals,"Robot-assisted deployment of fenestrated stent grafts in fenestrated endovascular aortic repair (FEVAR) requires accurate geometrical alignment. Currently, this process is guided by two-dimensional (2-D) fluoroscopy, which is insufficiently informative and error prone. In this letter, a real-time framework is proposed to instantiate the 3-D shape of a fenestrated stent graft by utilizing only a single low-dose 2-D fluoroscopic image. First, markers were placed on the fenestrated stent graft. Second, the 3-D pose of each stent segment was instantiated by the robust perspective-n-point method. Third, the 3-D shape of the whole stent graft was instantiated via graft gap interpolation. Focal UNet was proposed to segment the markers from 2-D fluoroscopic images to achieve semiautomatic marker detection. The proposed framework was validated on five patient-specific 3-D printed aortic aneurysm phantoms and three stent grafts with new marker placements, showing an average distance error of 1-3 mm and an average angular error of 4°. Shape instantiation codes are available online.",https://ieeexplore.ieee.org/document/8269290/,IEEE Robotics and Automation Letters,April 2018,ieeexplore
10.1109/TDSC.2019.2903049,Real-Time Error Detection in Nonlinear Control Systems Using Machine Learning Assisted State-Space Encoding,IEEE,Journals,"Successful deployment of autonomous systems in a wide range of societal applications depends on error-free operation of the underlying signal processing and control functions. Real-time error detection in nonlinear systems has mostly relied on redundancy at the component or algorithmic level causing expensive area and power overheads. This paper describes a real-time error detection methodology for nonlinear control systems for detecting sensor and actuator degradations as well as malfunctions due to soft errors in the execution of the control algorithm on a digital processor. Our approach is based on creation of a redundant check state in such a way that its value can be computed from the current states of the system as well as from a history of prior observable state values and inputs (via machine learning algorithms). By checking for consistency between the two, errors are detected with low latency. The method is demonstrated on two test case simulations - an inverted pendulum balancing problem and a sliding mode controller driven brake-by-wire (BBW) system. In addition, hardware results from error injection experiments in an ARM core representation on an FPGA and artificial sensor degradations on a self-balancing robot prove the practical feasibility of implementation.",https://ieeexplore.ieee.org/document/8658148/,IEEE Transactions on Dependable and Secure Computing,1 March-April 2021,ieeexplore
10.1109/TCYB.2013.2275291,Real-Time Multiple Human Perception With Color-Depth Cameras on a Mobile Robot,IEEE,Journals,"The ability to perceive humans is an essential requirement for safe and efficient human-robot interaction. In real-world applications, the need for a robot to interact in real time with multiple humans in a dynamic, 3-D environment presents a significant challenge. The recent availability of commercial color-depth cameras allow for the creation of a system that makes use of the depth dimension, thus enabling a robot to observe its environment and perceive in the 3-D space. Here we present a system for 3-D multiple human perception in real time from a moving robot equipped with a color-depth camera and a consumer-grade computer. Our approach reduces computation time to achieve real-time performance through a unique combination of new ideas and established techniques. We remove the ground and ceiling planes from the 3-D point cloud input to separate candidate point clusters. We introduce the novel information concept, depth of interest, which we use to identify candidates for detection, and that avoids the computationally expensive scanning-window methods of other approaches. We utilize a cascade of detectors to distinguish humans from objects, in which we make intelligent reuse of intermediary features in successive detectors to improve computation. Because of the high computational cost of some methods, we represent our candidate tracking algorithm with a decision directed acyclic graph, which allows us to use the most computationally intense techniques only where necessary. We detail the successful implementation of our novel approach on a mobile robot and examine its performance in scenarios with real-world challenges, including occlusion, robot motion, nonupright humans, humans leaving and reentering the field of view (i.e., the reidentification challenge), human-object and human-human interaction. We conclude with the observation that the incorporation of the depth information, together with the use of modern techniques in new ways, we are able to create an accurate system for real-time 3-D perception of humans by a mobile robot.",https://ieeexplore.ieee.org/document/6583249/,IEEE Transactions on Cybernetics,Oct. 2013,ieeexplore
10.1109/LRA.2021.3102318,Real-Time Obstacle Avoidance Using Dual-Type Proximity Sensor for Safe Human-Robot Interaction,IEEE,Journals,"This letter introduces a dual-type proximity sensor and a control strategy for a robot manipulator to realize safe human-robot interactions (HRI) by using the sensor. Safety is an essential condition for HRI in practical scenarios. To achieve this condition, information about the relationship between an external objects and the robot is required. To obtain this information, we employ a dual-type proximity sensor, which consists of capacitive and inductive transducers and can detect the distance between a robot and external objects. Further, we propose a real-time trajectory planning method to deal with obstacles by using admittance control and distance measurements. To update the motion of the manipulator according to our control strategy, a Weight-Prioritized solution based on a QP (quadratic programming) formalism was applied. Further, the problem of self-sensing is solved via machine learning using a training dataset consisting of data corresponding to random joint positions. The proposed method was implemented on a collaborate robot (UR10). Experiments were conducted considering realistic human-robot interactions, and safety improvement was validated.",https://ieeexplore.ieee.org/document/9508896/,IEEE Robotics and Automation Letters,Oct. 2021,ieeexplore
10.1109/70.265922,Real-time vision-based robot localization,IEEE,Journals,"This paper describes an algorithm for determining robot location from visual landmarks. This algorithm determines both the correspondence between observed landmarks (in this case vertical edges in the environment) and a stored map, and computes the location of the robot using those correspondences. The primary advantages of this algorithm are its use of a single geometric tolerance to describe observation error, its ability to recognize ambiguous sets of correspondences, its ability to compute bounds on the error in localization, and fast execution. The algorithm has been implemented and tested on a mobile robot system. In several hundred trials it has never failed, and computes location accurate to within a centimeter in less than 0.5 s.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/265922/,IEEE Transactions on Robotics and Automation,Dec. 1993,ieeexplore
10.1109/ACCESS.2020.3018026,Reinforcement Learning for Position Control Problem of a Mobile Robot,IEEE,Journals,"Due to the increase in complexity in autonomous vehicles, most of the existing control systems are proving to be inadequate. Reinforcement Learning is gaining traction as it is posed to overcome these difficulties in a natural way. This approach allows an agent that interacts with the environment to get rewards for appropriate actions, learning to improve its performance continuously. The article describes the design and development of an algorithm to control the position of a wheeled mobile robot using Reinforcement Learning. One main advantage of this approach concerning traditional control algorithms is that the learning process is carried out automatically with a recursive procedure forward in time. Moreover, given the fidelity of the model for the particular implementation described in this work, the whole learning process can be carried out in simulation. This fact avoids damages to the actual robot during the learning stage. It shows that the position control of the robot (or similar specific tasks) can be done without the need to know the dynamic model of the system explicitly. Its main drawback is that the learning stage can take a long time to finish and that it depends on the complexity of the task and the availability of adequate hardware resources. This work provides a comparison between the proposed approach and traditional existing control laws in simulation and real environments. The article also discusses the main effects of using different controlled variables in the performance of the developed control law.",https://ieeexplore.ieee.org/document/9171241/,IEEE Access,2020,ieeexplore
10.1109/LRA.2021.3057055,Robot Learning With Crash Constraints,IEEE,Journals,"In the past decade, numerous machine learning algorithms have been shown to successfully learn optimal policies to control real robotic systems. However, it is common to encounter failing behaviors as the learning loop progresses. Specifically, in robot applications where failing is undesired but not catastrophic, many algorithms struggle with leveraging data obtained from failures. This is usually caused by (i) the failed experiment ending prematurely, or (ii) the acquired data being scarce or corrupted. Both complicate the design of proper reward functions to penalize failures. In this letter, we propose a framework that addresses those issues. We consider failing behaviors as those that violate a constraint and address the problem of learning with crash constraints, where no data is obtained upon constraint violation. The no-data case is addressed by a novel GP model (GPCR) for the constraint that combines discrete events (failure/success) with continuous observations (only obtained upon success). We demonstrate the effectiveness of our framework on simulated benchmarks and on a real jumping quadruped, where the constraint threshold is unknown a priori. Experimental data is collected, by means of constrained Bayesian optimization, directly on the real robot. Our results outperform manual tuning and GPCR proves useful on estimating the constraint threshold.",https://ieeexplore.ieee.org/document/9345965/,IEEE Robotics and Automation Letters,April 2021,ieeexplore
10.1109/TCST.2019.2914634,Robust Regressor-Free Control of Rigid Robots Using Function Approximations,IEEE,Journals,"This paper develops a novel regressor-free robust controller for rigid robots whose dynamics can be described using the Euler-Lagrange equations of motion. The function approximation technique (FAT) is used to represent the robot's inertia matrix, the Coriolis matrix, and the gravity vector as finite linear combinations of orthonormal basis functions. The proposed controller establishes a robust FAT control framework that uses a fixed control structure. The control objectives are to track reference trajectories in worst case scenarios where the robot dynamics are too costly to develop or otherwise unavailable. Detailed stability analysis via Lyapunov functions, the passivity property, and continuous switching laws shows uniform ultimate boundedness of the closed-loop dynamics. The simulation results of a three-degree-of-freedom (DOF) robot when the robot parameters are perturbed from their nominal values show good robustness of the proposed controller when compared with some well-established control methods. We also demonstrate success in the real-time experimental implementation of the proposed controller, which validates practicality for real-world robotic applications.",https://ieeexplore.ieee.org/document/8718993/,IEEE Transactions on Control Systems Technology,July 2020,ieeexplore
10.1109/TETC.2017.2769705,Robust Robot Tracking for Next-Generation Collaborative Robotics-Based Gaming Environments,IEEE,Journals,"The collaboration between humans and robots is one of the most disruptive and challenging research areas. Even considering advances in design and artificial intelligence, humans and robots could soon ally to perform together a number of different tasks. Robots could also became new playmates. In fact, an emerging trend is associated with the so-called phygital gaming, which builds upon the idea of merging the physical world with a virtual one in order to let physical and virtual entities, such as players, robots, animated characters and other game objects interact seamlessly as if they were all part of the same reality. This paper specifically focuses on mixed reality gaming environments that can be created by using floor projection, and tackles the issue of enabling accurate and robust tracking of off-the-shelf robots endowed with limited sensing capabilities. The proposed solution is implemented by fusing visual tracking data gathered via a fixed camera in a smart environment with odometry data obtained from robot's on-board sensors. The solution has been tested within a phygital gaming platform in a real usage scenario, by experimenting with a robotic game that exhibits many challenging situations which would be hard to manage using conventional tracking techniques.",https://ieeexplore.ieee.org/document/8094867/,IEEE Transactions on Emerging Topics in Computing,1 July-Sept. 2020,ieeexplore
10.1109/TASE.2019.2940543,Robust Visual Localization in Dynamic Environments Based on Sparse Motion Removal,IEEE,Journals,"Visual localization has been well studied in recent decades and applied in many fields as a fundamental capability in robotics. However, the success of the state of the arts usually builds on the assumption that the environment is static. In dynamic scenarios where moving objects are present, the performance of the existing visual localization systems degrades a lot due to the disturbance of the dynamic factors. To address this problem, we propose a novel sparse motion removal (SMR) model that detects the dynamic and static regions for an input frame based on a Bayesian framework. The similarity between the consecutive frames and the difference between the current frame and the reference frame are both considered to reduce the detection uncertainty. After the detection process is finished, the dynamic regions are eliminated while the static ones are fed into a feature-based visual simultaneous localization and mapping (SLAM) system for further visual localization. To verify the proposed method, both qualitative and quantitative experiments are performed and the experimental results have demonstrated that the proposed model can significantly improve the accuracy and robustness for visual localization in dynamic environments.&lt;;/p&gt;&lt;;p&gt;&lt;;italic&gt;Note to Practitioners&lt;;/italic&gt;-This article was motivated by the visual localization problem in dynamic environments. Visual localization is well applied in many robotic fields such as path planning and exploration as the basic capability for a mobile robot. In the GPS-denied environments, one robot needs to localize itself through perceiving the unknown environment based on a visual sensor. In real-world scenes, the existence of the moving objects will significantly degrade the localization accuracy, which makes the robot implementation unreliable. In this article, an SMR model is designed to handle this problem. Once receiving a frame, the proposed model divides it into dynamic and static regions through a Bayesian framework. The dynamic regions are eliminated, while the static ones are maintained and fed into a feature-based visual SLAM system for further visual localization. The proposed method greatly improves the localization accuracy in dynamic environments and guarantees the robustness for robotic implementation.",https://ieeexplore.ieee.org/document/8855084/,IEEE Transactions on Automation Science and Engineering,April 2020,ieeexplore
10.1109/TNN.2009.2032183,SVR Versus Neural-Fuzzy Network Controllers for the Sagittal Balance of a Biped Robot,IEEE,Journals,"The real-time balance control of an eight-link biped robot using a zero moment point (ZMP) dynamic model is difficult due to the processing time of the corresponding equations. To overcome this limitation, two alternative intelligent computing control techniques were compared: one based on support vector regression (SVR) and another based on a first-order Takagi-Sugeno-Kang (TSK)-type neural-fuzzy (NF) network. Both methods use the ZMP error and its variation as inputs and the output is the correction of the robot's torso necessary for its sagittal balance. The SVR and the NF were trained based on simulation data and their performance was verified with a real biped robot. Two performance indexes are proposed to evaluate and compare the online performance of the two control methods. The ZMP is calculated by reading four force sensors placed under each robot's foot. The gait implemented in this biped is similar to a human gait that was acquired and adapted to the robot's size. Some experiments are presented and the results show that the implemented gait combined either with the SVR controller or with the TSK NF network controller can be used to control this biped robot. The SVR and the NF controllers exhibit similar stability, but the SVR controller runs about 50 times faster.",https://ieeexplore.ieee.org/document/5276806/,IEEE Transactions on Neural Networks,Dec. 2009,ieeexplore
10.1109/TSMCA.2003.809171,Self-organization of behavioral primitives as multiple attractor dynamics: A robot experiment,IEEE,Journals,"This paper investigates how behavior primitives are self-organized in a neural network model utilizing a distributed representation scheme. The model is characterized by so-called parametric biases which adaptively modulate the encoding of different behavior patterns in a single recurrent neural net (RNN). Our experiments, using a real robot arm, showed that a set of end-point and oscillatory behavior patterns are learned by self-organizing fixed points and limit cycle dynamics that form behavior primitives. It was also found that diverse novel behavior patterns can be generated by modulating the parametric biases arbitrarily. Our analysis showed that such diversity in behavior generation emerges because a nonlinear map is self-organized between the space of parametric biases and that of the behavior patterns. The origin of the observed nonlinearity from the distributed representation is discussed. This paper investigates how behavior primitives are self-organized in a neural network model utilizing a distributed representation scheme. Our robot experiments showed that a set of end-point and oscillatory behavior patterns are learned by self-organizing fixed points and limit cycle dynamics that form behavior primitives. It was also found that diverse novel behavior patterns, in addition to previously learned patterns, can be generated by taking advantage of nonlinear effects that emerge from the distributed representation.",https://ieeexplore.ieee.org/document/1235981/,"IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans",July 2003,ieeexplore
10.1109/LRA.2017.2665694,Shakey 2016—How Much Does it Take to Redo Shakey the Robot?,IEEE,Journals,"Shakey the robot was one of the first autonomous robots that showed impressive capabilities of navigation and mobile manipulation. Since then, robotics research has made great progress, showing more and more capable robotic systems for a large variety of application domains and tasks. In this letter, we look back on decades of research by rebuilding Shakey with modern robotics technology in the open-source Shakey 2016 system. Hereby, we demonstrate the impact of research by showing that ideas from the original Shakey are still alive in state-of-the-art systems, while robotics in general has improved to deliver more robust and more capable software and hardware. Our Shakey 2016 system has been implemented on real robots and leverages mostly open-source software. We experimentally evaluate the system in real-world scenarios on a PR2 robot and a Turtlebot-based robot and particularly investigate the development effort. The experiments documented in this letter demonstrate that results from robotics research are readily available for building complex robots such as Shakey within a short amount of time and little effort.",https://ieeexplore.ieee.org/document/7847341/,IEEE Robotics and Automation Letters,April 2017,ieeexplore
10.1109/LRA.2020.3013848,Sim2Real Predictivity: Does Evaluation in Simulation Predict Real-World Performance?,IEEE,Journals,"Does progress in simulation translate to progress on robots? If one method outperforms another in simulation, how likely is that trend to hold in reality on a robot? We examine this question for embodied PointGoal navigation - developing engineering tools and a research paradigm for evaluating a simulator by its sim2real predictivity. First, we develop Habitat-PyRobot Bridge (HaPy), a library for seamless execution of identical code on simulated agents and robots - transferring simulation-trained agents to a LoCoBot platform with a one-line code change. Second, we investigate the sim2real predictivity of Habitat-Sim M. Savva et al., for PointGoal navigation. We 3D-scan a physical lab space to create a virtualized replica, and run parallel tests of 9 different models in reality and simulation. We present a new metric called Sim-vs-Real Correlation Coefficient (SRCC) to quantify predictivity. We find that SRCC for Habitat as used for the CVPR19 challenge is low (0.18 for the success metric), suggesting that performance differences in this simulator-based challenge do not persist after physical deployment. This gap is largely due to AI agents learning to exploit simulator imperfections - abusing collision dynamics to `slide' along walls, leading to shortcuts through otherwise non-navigable space. Naturally, such exploits do not work in the real world. Our experiments show that it is possible to tune simulation parameters to improve sim2real predictivity (e.g. improving SRCC<sub>Succ</sub> from 0.18 to 0.844) - increasing confidence that in-simulation comparisons will translate to deployed systems in reality.",https://ieeexplore.ieee.org/document/9158349/,IEEE Robotics and Automation Letters,Oct. 2020,ieeexplore
10.1109/JSYST.2008.925270,Sonar-Based Rover Navigation for Single or Multiple Platforms: Forward Safe Path and Target Switching Approach,IEEE,Journals,"In this paper, we have proposed a sensor fusion scheme along with the geometrical modeling of mobile robot navigation path in an unknown environment. In this scheme, the physical placement of sonars, their ranging limits and beam opening angles are considered. A simple 2-D axis transformation is proposed to relate local robot frame with the actual navigation environment. forward safe path (FSP) and target switching approach (TSA) are proposed for efficient obstacle avoidance and target tracking of mobile robot. FSP greatly simplifies the environment conditions as sensed by the robot and also provides minimum turning path during avoidance of obstacles. This method also removes the ldquooscillationrdquo in the mobile robot navigation path. TSA technique gives highest priority on the target tracking during the obstacle avoidance and seeks minimum distance path towards the target. These methods remove unnecessary turning of mobile robot during navigation. A scheme for target directional motion is also proposed. So, mobile robot takes the minimum turning path required towards the target. These methods also ensure the avoidance of ldquodead cycle problemrdquo. These schemes are successfully implemented on a model of <i>PatrolBot</i> mobile robot from <i>ActivMedia</i> Robotics. The overview of current research work on multi-domain robotic system namely system-of-systems is also presented. This paper also describes the Global Positioning System-based navigation of rovers. Results of real-time experiments with Pioneer II P2AT-8 from <i>ActivMedia</i> are included in this paper to show the future aspect of this research work.",https://ieeexplore.ieee.org/document/4550588/,IEEE Systems Journal,June 2008,ieeexplore
10.1109/TCDS.2016.2565542,Spatial Concept Acquisition for a Mobile Robot That Integrates Self-Localization and Unsupervised Word Discovery From Spoken Sentences,IEEE,Journals,"In this paper, we propose a novel unsupervised learning method for the lexical acquisition of words related to places visited by robots, from human continuous speech signals. We address the problem of learning novel words by a robot that has no prior knowledge of these words except for a primitive acoustic model. Furthermore, we propose a method that allows a robot to effectively use the learned words and their meanings for self-localization tasks. The proposed method is nonparametric Bayesian spatial concept acquisition method (SpCoA) that integrates the generative model for self-localization and the unsupervised word segmentation in uttered sentences via latent variables related to the spatial concept. We implemented the proposed method SpCoA on SIGVerse, which is a simulation environment, and TurtleBot2, which is a mobile robot in a real environment. Further, we conducted experiments for evaluating the performance of SpCoA. The experimental results showed that SpCoA enabled the robot to acquire the names of places from speech sentences. They also revealed that the robot could effectively utilize the acquired spatial concepts and reduce the uncertainty in self-localization.",https://ieeexplore.ieee.org/document/7467531/,IEEE Transactions on Cognitive and Developmental Systems,Dec. 2016,ieeexplore
10.1109/ACCESS.2021.3111706,Tennis Robot Design via Internet of Things and Deep Learning,IEEE,Journals,"To efficiently integrate deep learning (DL) and Internet of Things (IoT) with tennis robot research, the concept and characteristics of mask region-convolutional neural network (Mask R-CNN) under DL are analyzed. Then, the IoT radio frequency identification (RFID) is introduced and the suitable RFID structure is established. Moreover, the real-time intelligent image recognition tennis robot is designed, and simulation experiment on the robot is performed. The results show that when the positioning label is eight, the convergence speed of the optimized algorithm is improved relative to the unoptimized one, and the error is reduced by 0.82. The positioning algorithm proposed in this research has high convergence speed and small system error. The positioning accuracy of the tennis robot is improved by at least 6%, the positioning targets are close to the target to be located, and the tennis robot has the best shortest path effect. In addition, the tennis recognition algorithm based on Mask R-CNN can accurately distinguish dense tennis balls with high accuracy. It shows that the tennis robot positioning algorithm and target recognition algorithm proposed in this research are of practical adoption value.",https://ieeexplore.ieee.org/document/9535167/,IEEE Access,2021,ieeexplore
10.1109/JIOT.2021.3068736,Terra: A Smart and Sensible Digital Twin Framework for Robust Robot Deployment in Challenging Environments,IEEE,Journals,"Digital twin (DT) systems that replicate the physical world digitally are powerful tools for monitoring physical systems and evaluating algorithms, but current DT systems are commonly not applicable for robotic deployment and investigation. Meanwhile, current 3-D simulation-based robotic platforms do not model the dynamics of the physical world on-the-fly as done in DT systems, limiting their potential for the development of robotics in challenging environments. To tackle this issue, we propose the first robot-centered smart DT framework, namely, Terra, to facilitate the deployment of robots in challenging environments. The proposed Terra framework introduces a comprehensive DT representation to encode the useful real-time dynamics of both the physical world and the robot agent deployed therein. A multiview multimodality perception module is further devised for Terra to obtain high-level semantics and deliver a precise description of the current status of the environment and the robot agent. By mapping the perceived results to the virtual replica of the physical environment, Terra actively updates the action policy and sends it back to the agent, forming an integral and real-time information feedback loop. In practice, to help demonstrate the effectiveness and feasibility of the proposed framework, we deliberately set up a challenging unordered physical environment with many obstacles and a very simple robot aiming to fulfill a navigation task. Empirical results show that the proposed Terra framework successfully facilitates the robot to accomplish the task without causing hazards.",https://ieeexplore.ieee.org/document/9386242/,IEEE Internet of Things Journal,"15 Sept.15, 2021",ieeexplore
10.1109/ACCESS.2020.2978077,The Experience-Memory Q-Learning Algorithm for Robot Path Planning in Unknown Environment,IEEE,Journals,"In order to solve the problem of slow convergence speed and long planned path when the robot plans a path in unknown environment by using Q-learning algorithm, we propose the Experience-Memory Q-Learning (EMQL) algorithm based on the continuous update of the shortest distance from the current state node to the start point. The autonomous learning ability of the robot is enhanced by the different role assignments of two tables in the proposed algorithm. EM table with $(m*1)$ dimension is designed to record the distance information, reflecting the learning process of the robot. Q table is adopted as an auxiliary guidance for the experience transfer strategy and experience reuse strategy, and these strategies enable the robot accomplish the task even if the destination is changed or the path is blocked. Further, the learning efficiency of the robot in the EMQL algorithm is improved by the dual reward mechanism consisting of static reward and dynamic reward. The static reward is designed to prevent the robot from exploring a state node excessively. The dynamic reward is responsible for helping the robot avoid searching blindly in unknown environment. We test the effectiveness of the proposed algorithm on both grid maps and road network maps. The comparison results in planning time, iteration times and path length show that the performance of the EMQL algorithm is superior to Q-learning algorithm in convergence speed and optimization ability. Additionally, the practicability of the proposed algorithm is validated in a real-world experiment using the Turtlebot3 burger robot.",https://ieeexplore.ieee.org/document/9022975/,IEEE Access,2020,ieeexplore
10.1109/TRO.2012.2228134,The Impact of Human–Robot Interfaces on the Learning of Visual Objects,IEEE,Journals,"This paper studies the impact of interfaces, allowing nonexpert users to efficiently and intuitively teach a robot to recognize new visual objects. We present challenges that need to be addressed for real-world deployment of robots capable of learning new visual objects in interaction with everyday users. We argue that in addition to robust machine learning and computer vision methods, well-designed interfaces are crucial for learning efficiency. In particular, we argue that interfaces can be key in helping nonexpert users to collect good learning examples and, thus, improve the performance of the overall learning system. Then, we present four alternative human-robot interfaces: Three are based on the use of a mediating artifact (smartphone, wiimote, wiimote and laser), and one is based on natural human gestures (with a Wizard-of-Oz recognition system). These interfaces mainly vary in the kind of feedback provided to the user, allowing him to understand more or less easily what the robot is perceiving and, thus, guide his way of providing training examples differently. We then evaluate the impact of these interfaces, in terms of learning efficiency, usability, and user's experience, through a real world and large-scale user study. In this experiment, we asked participants to teach a robot 12 different new visual objects in the context of a robotic game. This game happens in a home-like environment and was designed to motivate and engage users in an interaction where using the system was meaningful. We then discuss results that show significant differences among interfaces. In particular, we show that interfaces such as the smartphone interface allows nonexpert users to intuitively provide much better training examples to the robot, which is almost as good as expert users who are trained for this task and are aware of the different visual perception and machine learning issues. We also show that artifact-mediated teaching is significantly more efficient for robot learning, and equally good in terms of usability and user's experience, than teaching thanks to a gesture-based human-like interaction.",https://ieeexplore.ieee.org/document/6384810/,IEEE Transactions on Robotics,April 2013,ieeexplore
10.1109/70.88137,The vector field histogram-fast obstacle avoidance for mobile robots,IEEE,Journals,"A real-time obstacle avoidance method for mobile robots which has been developed and implemented is described. This method, named the vector field histogram (VFH), permits the detection of unknown obstacles and avoids collisions while simultaneously steering the mobile robot toward the target. The VFH method uses a two-dimensional Cartesian histogram grid as a world model. This world model is updated continuously with range data sampled by onboard range sensors. The VFH method subsequently uses a two-stage data-reduction process to compute the desired control commands for the vehicle. Experimental results from a mobile robot traversing densely cluttered obstacle courses in smooth and continuous motion and at an average speed of 0.6-0.7 m/s are shown. A comparison of the VFN method to earlier methods is given.&lt;<ETX>&gt;</ETX>",https://ieeexplore.ieee.org/document/88137/,IEEE Transactions on Robotics and Automation,June 1991,ieeexplore
10.1109/TCDS.2017.2712712,Toward Brain-Inspired Learning With the Neuromorphic Snake-Like Robot and the Neurorobotic Platform,IEEE,Journals,"Neurorobotic mimics the structural and functional principles of living creature systems. Modeling a single system by robotic hardware and software has existed for decades. However, an integrated toolset studying the interaction of all systems has not been demonstrated yet. We present a hybrid neuromorphic computing paradigm to bridge this gap by combining the neurorobotics platform (NRP) with the neuromorphic snake-like robot (NeuroSnake). This paradigm encompasses the virtual models, neuromorphic sensing and computing capabilities, and physical bio-inspired bodies, with which an experimenter can design and execute both in-silico and in-vivo robotic experimentation easily. The NRP is a public Web-based platform for easily testing brain models with virtual bodies and environments. The NeuroSnake is a bio-inspired robot equipped with a silico-retina sensor and neuromorphic computer for power-efficiency applications. We illustrate the efficiencies of our paradigm with an easy designing of a visual pursuit experiment in the NRP. We study two automatic behavior learning tasks which are further integrated into a complex task of semi-autonomous pole climbing. The result shows that robots could build new learning rules in a less explicit manner inspired by living creatures. Our method gives an alternative way to efficiently develop complex behavior control of the ro As spiking neural network is a bio-inspired neural network and the NeuroSnake robot is equipped with a spike-based silicon retina camera, the control system can be easily implemented via spiking neurons simulated on neuromorphic hardware, such as SpiNNaker.bot.",https://ieeexplore.ieee.org/document/7945270/,IEEE Transactions on Cognitive and Developmental Systems,March 2019,ieeexplore
10.1109/TASE.2017.2731371,Toward Socially Aware Robot Navigation in Dynamic and Crowded Environments: A Proactive Social Motion Model,IEEE,Journals,"Safe and social navigation is the key to deploying a mobile service robot in a human-centered environment. Widespread acceptability of mobile service robots in daily life is hindered by robot's inability to navigate in crowded and dynamic human environments in a socially acceptable way that would guarantee human safety and comfort. In this paper, we propose an effective proactive social motion model (PSMM) that enables a mobile service robot to navigate safely and socially in crowded and dynamic environments. The proposed method considers not only human states (position, orientation, motion, field of view, and hand poses) relative to the robot but also social interactive information about human-object and human group interactions. This allows development of the PSMM that consists of elements of an extended social force model and a hybrid reciprocal velocity obstacle technique. The PSMM is then combined with a path planning technique to generate a motion planning system that drives a mobile robot in a socially acceptable manner and produces respectful and polite behaviors akin to human movements. Note to Practitioners-In this paper, we validated the effectiveness and feasibility of the proposed proactive social motion model (PSMM) through both simulation and real-world experiments under the newly proposed human comfortable safety indices. To do that, we first implemented the entire navigation system using the open-source robot operating system. We then installed it in a simulated robot model and conducted experiments in a simulated shopping mall-like environment to verify its effectiveness. We also installed the proposed algorithm on our mobile robot platform and conducted experiments in our office-like laboratory environment. Our results show that the developed socially aware navigation framework allows a mobile robot to navigate safely, socially, and proactively while guaranteeing human safety and comfort in crowded and dynamic environments. In this paper, we examined the proposed PSMM with a set of predefined parameters selected based on our empirical experiences about the robot mechanism and selected social environment. However, in fact a mobile robot might need to adapt to various contextual and cultural situations in different social environments. Thus, it should be equipped with an online adaptive interactive learning mechanism allowing the robot to learn to auto-adjust their parameters according to such embedded environments. Using machine learning techniques, e.g., inverse reinforcement learning [1] to optimize the parameter set for the PSMM could be a promising research direction to improve adaptability of mobile service robots in different social environments. In the future, we will evaluate the proposed framework based on a wider variety of scenarios, particularly those with different social interaction situations and dynamic environments. Furthermore, various kinds of social cues and signals introduced in [2] and [3] will be applied to extend the proposed framework in more complicated social situations and contexts. Last but not least, we will investigate different machine learning techniques and incorporate them in the PSMM in order to allow the robot to automatically adapt to diverse social environments.",https://ieeexplore.ieee.org/document/8011466/,IEEE Transactions on Automation Science and Engineering,Oct. 2017,ieeexplore
10.1109/ACCESS.2021.3080517,Towards Open and Expandable Cognitive AI Architectures for Large-Scale Multi-Agent Human-Robot Collaborative Learning,IEEE,Journals,"Learning from Demonstration (LfD) constitutes one of the most robust methodologies for constructing efficient cognitive robotic systems. Despite the large body of research works already reported, current key technological challenges include those of multi-agent learning and long-term autonomy. Towards this direction, a novel cognitive architecture for multi-agent LfD robotic learning is introduced in this paper, targeting to enable the reliable deployment of open, scalable and expandable robotic systems in large-scale and complex environments. In particular, the designed architecture capitalizes on the recent advances in the Artificial Intelligence (AI) (and especially the Deep Learning (DL)) field, by establishing a Federated Learning (FL)-based framework for incarnating a multi-human multi-robot collaborative learning environment. The fundamental conceptualization relies on employing multiple AI-empowered cognitive processes (implementing various robotic tasks) that operate at the edge nodes of a network of robotic platforms, while global AI models (underpinning the aforementioned robotic tasks) are collectively created and shared among the network, by elegantly combining information from a large number of human-robot interaction instances. Regarding pivotal novelties, the designed cognitive architecture a) introduces a new FL-based formalism that extends the conventional LfD learning paradigm to support large-scale multi-agent operational settings, b) elaborates previous FL-based self-learning robotic schemes so as to incorporate the human in the learning loop and c) consolidates the fundamental principles of FL with additional sophisticated AI-enabled learning methodologies for modelling the multi-level inter-dependencies among the robotic tasks. The applicability of the proposed framework is explained using an example of a real-world industrial case study (subject to ongoing research activities) for agile production-based Critical Raw Materials (CRM) recovery.",https://ieeexplore.ieee.org/document/9431107/,IEEE Access,2021,ieeexplore
10.1109/ACCESS.2020.3046730,Tracking In-Cabin Astronauts Using Deep Learning and Head Motion Clues,IEEE,Journals,"A person-following robot is under development for astronaut assistance on the Chinese Space Station. Real-time astronaut detection and tracking are the most important prerequisites for in-cabin flying assistant robots so that they can follow a specific astronaut and offer him/her assistance. In the limited space in the space station cabin, astronauts stand close to each other when working collaboratively; thus, large regions of their bodies tend to overlap in the image. In addition, because astronauts wear the same clothes most of the time, it is difficult to distinguish an individual astronaut using human body features. In this paper, we distinguish the astronauts by tracking their heads in the image. A deep learning model trained using big data is proposed for effective head detection. In addition, a motion model based on spatial clues is combined with the head detection results to track astronauts in the scene. A complete pipeline of the algorithm has been implemented and run efficiently on the Tegra X2 embedded AI microprocessor. A set of experiments were carried out and successfully validated the effectiveness of the proposed tracking algorithm. This algorithm is a step toward the implementation of robot assistants, especially in resource-limited environments.",https://ieeexplore.ieee.org/document/9305234/,IEEE Access,2021,ieeexplore
10.1109/LRA.2021.3070305,Underwater Soft Robot Modeling and Control With Differentiable Simulation,IEEE,Journals,"Underwater soft robots are challenging to model and control because of their high degrees of freedom and their intricate coupling with water. In this letter, we present a method that leverages the recent development in differentiable simulation coupled with a differentiable, analytical hydrodynamic model to assist with the modeling and control of an underwater soft robot. We apply this method to Starfish, a customized soft robot design that is easy to fabricate and intuitive to manipulate. Our method starts with data obtained from the real robot and alternates between simulation and experiments. Specifically, the simulation step uses gradients from a differentiable simulator to run system identification and trajectory optimization, and the experiment step executes the optimized trajectory on the robot to collect new data to be fed into simulation. Our demonstration on Starfish shows that proper usage of gradients from a differentiable simulator not only narrows down its simulation-to-reality gap but also improves the performance of an open-loop controller in real experiments.",https://ieeexplore.ieee.org/document/9392257/,IEEE Robotics and Automation Letters,July 2021,ieeexplore
10.1109/TAMD.2010.2097260,Using the Rhythm of Nonverbal Human–Robot Interaction as a Signal for Learning,IEEE,Journals,"Human-robot interaction is a key issue in order to build robots for everyone. The difficulty for people to understand how robots work and how they must be controlled will be one of the mains limit for broad robotics. In this paper, we study a new way of interacting with robots without needing to understand how robots work or to give them explicit instructions. This work is based on psychological data showing that synchronization and rhythm are very important features for pleasant interaction. We propose a biologically inspired architecture using rhythm detection to build an internal reward for learning. After showing the results of keyboard interactions, we present and discuss the results of real human-robots (Aibo and Nao) interactions. We show that our minimalist control architecture allows the discovery and learning of arbitrary sensorimotor associations games with expert users. With nonexpert users, we show that using only the rhythm information is not sufficient for learning all the associations due to the different strategies used by the human. Nevertheless, this last experiment shows that the rhythm is still allowing the discovery of subsets of associations, being one of the promising signal of tomorrow social applications.",https://ieeexplore.ieee.org/document/5664771/,IEEE Transactions on Autonomous Mental Development,March 2011,ieeexplore
10.1109/LRA.2019.2894216,VR-Goggles for Robots: Real-to-Sim Domain Adaptation for Visual Control,IEEE,Journals,"In this letter, we deal with the reality gap from a novel perspective, targeting transferring deep reinforcement learning (DRL) policies learned in simulated environments to the real-world domain for visual control tasks. Instead of adopting the common solutions to the problem by increasing the visual fidelity of synthetic images output from simulators during the training phase, we seek to tackle the problem by translating the real-world image streams back to the synthetic domain during the deployment phase, to make the robot feel at home. We propose this as a lightweight, flexible, and efficient solution for visual control, as first, no extra transfer steps are required during the expensive training of DRL agents in simulation; second, the trained DRL agents will not be constrained to being deployable in only one specific real-world environment; and third, the policy training and the transfer operations are decoupled, and can be conducted in parallel. Besides this, we propose a simple yet effective shift loss that is agnostic to the downstream task, to constrain the consistency between subsequent frames which is important for consistent policy outputs. We validate the shift loss for artistic style transfer for videos and domain adaptation, and validate our visual control approach in indoor and outdoor robotics experiments.",https://ieeexplore.ieee.org/document/8620258/,IEEE Robotics and Automation Letters,April 2019,ieeexplore
10.1109/70.508435,Virtual-reality-based point-and-direct robotic inspection in manufacturing,IEEE,Journals,"This paper explores a flexible manufacturing paradigm in which robot grasping is interactively specified and skeletal images are efficiently used in combination to allow rapidly setting up surface flaw identification tasks in small-quantity/large-variety manufacturing. Two complementary technologies are combined to make implementation of inspection as rapid as possible. First, a novel material handling approach is described for robotic picking and placing of parts onto an inspection table using virtual tools. This allows an operator to point and give directives to set up robotic inspection tasks. Second, since specification may be approximate using this method, a fast and flexible means of identifying images of perfect and flawed parts is explored that avoids rotational or translational restrictions on workpiece placement. This is accomplished by using skeleton pixel counts as neural network inputs. The total system, including material handling and skeleton-based inspection, features flexibility during manufacturing set-up, and reduces the process time and memory requirements for workpiece inspection.",https://ieeexplore.ieee.org/document/508435/,IEEE Transactions on Robotics and Automation,Aug. 1996,ieeexplore
10.1109/LRA.2018.2851148,Visual Navigation for Biped Humanoid Robots Using Deep Reinforcement Learning,IEEE,Journals,"In this letter, we propose a map-less visual navigation system for biped humanoid robots, which extracts information from color images to derive motion commands using deep reinforcement learning (DRL). The map-less visual navigation policy is trained using the Deep Deterministic Policy Gradients (DDPG) algorithm, which corresponds to an actor-critic DRL algorithm. The algorithm is implemented using two separate networks, one for the actor and one for the critic, but with similar structures. In addition to convolutional and fully connected layers, Long Short-Term Memory (LSTM) layers are included to address the limited observability present in the problem. As a proof of concept, we consider the case of robotic soccer using humanoid NAO V5 robots, which have reduced computational capabilities, and low-cost Red - Green - Blue (RGB) cameras as main sensors. The use of DRL allowed to obtain a complex and high performant policy from scratch, without any prior knowledge of the domain, or the dynamics involved. The visual navigation policy is trained in a robotic simulator and then successfully transferred to a physical robot, where it is able to run in 20 ms, allowing its use in real-time applications.",https://ieeexplore.ieee.org/document/8398461/,IEEE Robotics and Automation Letters,Oct. 2018,ieeexplore
10.1109/LRA.2021.3068106,Visual Navigation in Real-World Indoor Environments Using End-to-End Deep Reinforcement Learning,IEEE,Journals,"Visual navigation is essential for many applications in robotics, from manipulation, through mobile robotics to automated driving. Deep reinforcement learning (DRL) provides an elegant map-free approach integrating image processing, localization, and planning in one module, which can be trained and therefore optimized for a given environment. However, to date, DRL-based visual navigation was validated exclusively in simulation, where the simulator provides information that is not available in the real world, e.g., the robot's position or segmentation masks. This precludes the use of the learned policy on a real robot. Therefore, we present a novel approach that enables a direct deployment of the trained policy on real robots. We have designed a new powerful simulator capable of domain randomization. To facilitate the training, we propose visual auxiliary tasks and a tailored reward scheme. The policy is fine-tuned on images collected from real-world environments. We have evaluated the method on a mobile robot in a real office environment. The training took approximately 30 hours on a single GPU. In 30 navigation experiments, the robot reached a 0.3-meter neighbourhood of the goal in more than 86.7% of cases. This result makes the proposed method directly applicable to tasks like mobile manipulation.",https://ieeexplore.ieee.org/document/9384194/,IEEE Robotics and Automation Letters,July 2021,ieeexplore
10.1109/TSMCB.2010.2089978,"Walking Motion Generation, Synthesis, and Control for Biped Robot by Using PGRL, LPI, and Fuzzy Logic",IEEE,Journals,"This paper proposes the implementation of fuzzy motion control based on reinforcement learning (RL) and Lagrange polynomial interpolation (LPI) for gait synthesis of biped robots. First, the procedure of a walking gait is redefined into three states, and the parameters of this designed walking gait are determined. Then, the machine learning approach applied to adjusting the walking parameters is policy gradient RL (PGRL), which can execute real-time performance and directly modify the policy without calculating the dynamic function. Given a parameterized walking motion designed for biped robots, the PGRL algorithm automatically searches the set of possible parameters and finds the fastest possible walking motion. The reward function mainly considered is first the walking speed, which can be estimated from the vision system. However, the experiment illustrates that there are some stability problems in this kind of learning process. To solve these problems, the desired zero moment point trajectory is added to the reward function. The results show that the robot not only has more stable walking but also increases its walking speed after learning. This is more effective and attractive than manual trial-and-error tuning. LPI, moreover, is employed to transform the existing motions to the motion which has a revised angle determined by the fuzzy motion controller. Then, the biped robot can continuously walk in any desired direction through this fuzzy motion control. Finally, the fuzzy-based gait synthesis control is demonstrated by tasks and point- and line-target tracking. The experiments show the feasibility and effectiveness of gait learning with PGRL and the practicability of the proposed fuzzy motion control scheme.",https://ieeexplore.ieee.org/document/5640679/,"IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",June 2011,ieeexplore
10.1109/ACCESS.2020.3030963,Waypoint Mobile Robot Exploration Based on Biologically Inspired Algorithms,IEEE,Journals,"This article proposes stochastic exploration algorithms for mobile robot exploration problems. Navigation with uncertain conditions in the absence of initial parameters is a situation wherein precomputation and prediction are impossible for a robot. Therefore, stochastic optimization techniques were applied to find the optimal solution for the robot exploration problem. Driving to the unknown areas, the robot updates the frontier line of sensor visibility during the exploration mission. The points of the frontier line are assumed as the swarm population with their own positions and costs, which allows the computation of the next global waypoint. The calculation of global waypoints is carried out by a nature-inspired optimization algorithm that can place a waypoint in uncertainties. This study offers to apply three metaheuristic algorithms individually, such as Whale Optimization, Grey Wolf Optimizer, and Particle Swarm Optimization algorithms, for comparison and testing their performances in the mobile robotics. At first, the simulations based on the proposed exploration algorithms were implemented and evaluated in a created environment. The results were compared in a single and average cases. Then, the real-world experiments using Grey Wolf Optimizer exploration algorithm were conducted in the different types of environments using MATLAB-ROS integration tool. These results proved the effectiveness and applicability of the bio-inspired optimization algorithm in the mobile robotics.",https://ieeexplore.ieee.org/document/9223657/,IEEE Access,2020,ieeexplore
10.1109/ACCESS.2021.3056625,Wheel Loader Scooping Controller Using Deep Reinforcement Learning,IEEE,Journals,"This article presents a deep reinforcement learning-based controller for an unmanned ground vehicle with a custom-built scooping mechanism. The robot's aim is to autonomously perform earth scooping cycles with three degrees of freedom: lift, tilt and the robot's velocity. While the majority of previous studies on automated scooping processes are based on data recorded by expert operators, we present a method to autonomously control a wheel loader to perform the scooping cycle using deep reinforcement learning methods without any user-provided demonstrations. The controller's learning approach is based on the actorcritic, Deep Deterministic Policy Gradient algorithm which we use to map online sensor data as input to continuously update the actuator commands. The training of the scooping policy network is done solely in a simplified simulation environment using a virtual physics engine, which converges to an average of a 65% fill factor from the full bucket capacity and a 5 [sec] average cycle time. We illustrate the performance of the trained policy in simulations and in real-world experiments with 3 different inclination angles of the earth. An additional scooping experiment compared the performance of our controller to remote manual human control. Overall, the deep reinforcement learning-based controller exhibited good performance in terms of both achieved visually bucket fill with varying scooped earth weights of 4.1 - 7.2[kg], and a 5.1 - 7.1[sec] cycle time. The experimental results confirm the ability of our planner to fill bucket as required, indicating that our controller can be used for excavation purposes.",https://ieeexplore.ieee.org/document/9344588/,IEEE Access,2021,ieeexplore
10.1109/LRA.2019.2961598,When Your Robot Breaks: Active Learning During Plant Failure,IEEE,Journals,"Detecting and adapting to catastrophic failures in robotic systems requires a robot to learn its new dynamics quickly and safely to best accomplish its goals. To address this challenging problem, we propose probabilistically-safe, online learning techniques to infer the altered dynamics of a robot at the moment a failure (e.g., physical damage) occurs. We combine model predictive control and active learning within a chance-constrained optimization framework to safely and efficiently learn the new plant model of the robot. We leverage a neural network for function approximation in learning the latent dynamics of the robot under failure conditions. Our framework generalizes to various damage conditions while being computationally light-weight to advance real-time deployment. We empirically validate within a virtual environment that we can regain control of a severely damaged aircraft in seconds and require only 0.1 seconds to find safe, information-rich trajectories, outperforming state-of-the-art approaches.",https://ieeexplore.ieee.org/document/8938725/,IEEE Robotics and Automation Letters,April 2020,ieeexplore
10.1109/JIOT.2020.2986685,WiFi-Based Indoor Robot Positioning Using Deep Fuzzy Forests,IEEE,Journals,"Addressing the positioning problem of a mobile robot remains challenging to date despite many years of research. Indoor robot positioning strategies developed in the literature either rely on sophisticated computer vision techniques to handle visual inputs or require strong domain knowledge for nonvisual sensors. Although some systems have been deployed, the former may be lacking due to the intrinsic limitation of cameras (such as calibration, data association, system initialization, etc.) and the latter usually only works under certain environment layouts and additional equipment. To cope with those issues, we design a lightweight indoor robot positioning system which operates on cost-effective WiFi-based received signal strength (RSS) and could be readily pluggable into any existing WiFi network infrastructures. Moreover, a novel deep fuzzy forest is proposed to inherit the merits of decision trees and deep neural networks within an end-to-end trainable architecture. Real-world indoor localization experiments are conducted and results demonstrate the superiority of the proposed method over the existing approaches.",https://ieeexplore.ieee.org/document/9060874/,IEEE Internet of Things Journal,Nov. 2020,ieeexplore
10.1109/JSEN.2020.3024094,k-Nearest Neighbor Classification for Pattern Recognition of a Reference Source Light for Machine Vision System,IEEE,Journals,"The design of machine vision applications allows automatic inspection, measuring systems, and robot guidance. Typical applications of industrial robots are based on no-contact sensors to give the robot information about the environment. Robot's machine vision requires photosensors or video cameras to make intelligent decisions about its localization. Video cameras used as image-capturing equipment are too costly in comparison with optical scanning systems (OSS). The OSS system provides spatial coordinates measurements that can be exploited to solve a wide variety of structural problems in real-time. Localization and guidance using machine learning (ML) techniques offer advantages due to signals captured can be transformed and be reduced for processing, storage, and displaying. The use of algorithms of ML enhances the performance of the optical system based on localization and guidance. Feature extraction represents an important part of ML techniques to transform the original raw data onto a low-dimensional subspace and holding relevant information. This work presents an improvement of an optical system based on <i>k</i>-nearest neighbor ( <i>k</i>-NN) technique to solve the object detection and localization problem. The utility of this improvement allows the optical system can discriminate between the reference source and the optical noise or interference. The OSS system presented in this article has been implemented in structural health monitoring to measure the angular position even under “lighting and weather conditions”. The feature extraction techniques used in this article were linear predictive coding (LPC), quartiles ( <i>Q</i><sub>iquartile</sub>), and autocorrelation coefficients (ACC). The results of using <i>k</i>-NN and autocorrelation coefficients and quartiles predicted more than 98% of correct classification by using a reference source light as a class 1 and a light bulb as an optical noise and called class 2.",https://ieeexplore.ieee.org/document/9195874/,IEEE Sensors Journal,"15 May15, 2021",ieeexplore
